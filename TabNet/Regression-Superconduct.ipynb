{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","machine_shape":"hm","authorship_tag":"ABX9TyNbV38k/IlynzLY+ub+ev1M"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["!wget https://huggingface.co/datasets/puhsu/tabular-benchmarks/resolve/main/data.tar -O tabular-dl-tabr.tar.gz\n","!tar -xvf tabular-dl-tabr.tar.gz"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pulqlCAgJDEt","executionInfo":{"status":"ok","timestamp":1729001022346,"user_tz":-480,"elapsed":64381,"user":{"displayName":"Jonindo Pasaribu","userId":"10958990953097471082"}},"outputId":"26a1ab41-7c7e-4862-db8f-1ce7caa8bbac"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["--2024-10-15 14:02:37--  https://huggingface.co/datasets/puhsu/tabular-benchmarks/resolve/main/data.tar\n","Resolving huggingface.co (huggingface.co)... 18.239.50.103, 18.239.50.80, 18.239.50.16, ...\n","Connecting to huggingface.co (huggingface.co)|18.239.50.103|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://cdn-lfs.hf.co/repos/1b/25/1b25d6e2556c827abfaf6ba9da6021338691cafc39fe9d77986955ae0a69243d/0d74e4b96febb48fbe4dd2d851f8638b5738354f82c3183f92adbd2abf2f256b?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27data.tar%3B+filename%3D%22data.tar%22%3B&response-content-type=application%2Fx-tar&Expires=1729260158&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcyOTI2MDE1OH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5oZi5jby9yZXBvcy8xYi8yNS8xYjI1ZDZlMjU1NmM4MjdhYmZhZjZiYTlkYTYwMjEzMzg2OTFjYWZjMzlmZTlkNzc5ODY5NTVhZTBhNjkyNDNkLzBkNzRlNGI5NmZlYmI0OGZiZTRkZDJkODUxZjg2MzhiNTczODM1NGY4MmMzMTgzZjkyYWRiZDJhYmYyZjI1NmI%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qJnJlc3BvbnNlLWNvbnRlbnQtdHlwZT0qIn1dfQ__&Signature=bb7YUXWVnTfzTk89aAcSjubbzaI7ECTLWsmSwUQe6VrkrUwwr1oX8IJmIuCNyExXYbstVk62Md0sByRoBlJ8pSKiMcSJqBICx5a4ekodwI-Nt32%7ED1-PvabABk7aeoh122ep7-KgYVGg4nBSMT7tp2bTv%7EkYPEfvTEUvcLImLMso6mTfDI4ZKs1QWK-3M78dAh-4yMgooUyHXpq2rEpqYqsXQBaYTsEymLSLCbI1ldg8lJnTc4x3VsH1vWrOkTQWHL0apa53NiKK4FsgFU1hitjFVIMZ1%7Eo%7EZ68PeqbIceZR0e-FzCNmh-T9YW5W1ohc4eYA-ZRMV7ADp-YQh1hYgw__&Key-Pair-Id=K3RPWS32NSSJCE [following]\n","--2024-10-15 14:02:38--  https://cdn-lfs.hf.co/repos/1b/25/1b25d6e2556c827abfaf6ba9da6021338691cafc39fe9d77986955ae0a69243d/0d74e4b96febb48fbe4dd2d851f8638b5738354f82c3183f92adbd2abf2f256b?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27data.tar%3B+filename%3D%22data.tar%22%3B&response-content-type=application%2Fx-tar&Expires=1729260158&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcyOTI2MDE1OH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5oZi5jby9yZXBvcy8xYi8yNS8xYjI1ZDZlMjU1NmM4MjdhYmZhZjZiYTlkYTYwMjEzMzg2OTFjYWZjMzlmZTlkNzc5ODY5NTVhZTBhNjkyNDNkLzBkNzRlNGI5NmZlYmI0OGZiZTRkZDJkODUxZjg2MzhiNTczODM1NGY4MmMzMTgzZjkyYWRiZDJhYmYyZjI1NmI%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qJnJlc3BvbnNlLWNvbnRlbnQtdHlwZT0qIn1dfQ__&Signature=bb7YUXWVnTfzTk89aAcSjubbzaI7ECTLWsmSwUQe6VrkrUwwr1oX8IJmIuCNyExXYbstVk62Md0sByRoBlJ8pSKiMcSJqBICx5a4ekodwI-Nt32%7ED1-PvabABk7aeoh122ep7-KgYVGg4nBSMT7tp2bTv%7EkYPEfvTEUvcLImLMso6mTfDI4ZKs1QWK-3M78dAh-4yMgooUyHXpq2rEpqYqsXQBaYTsEymLSLCbI1ldg8lJnTc4x3VsH1vWrOkTQWHL0apa53NiKK4FsgFU1hitjFVIMZ1%7Eo%7EZ68PeqbIceZR0e-FzCNmh-T9YW5W1ohc4eYA-ZRMV7ADp-YQh1hYgw__&Key-Pair-Id=K3RPWS32NSSJCE\n","Resolving cdn-lfs.hf.co (cdn-lfs.hf.co)... 18.239.83.30, 18.239.83.87, 18.239.83.31, ...\n","Connecting to cdn-lfs.hf.co (cdn-lfs.hf.co)|18.239.83.30|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 3094384640 (2.9G) [application/x-tar]\n","Saving to: ‘tabular-dl-tabr.tar.gz’\n","\n","tabular-dl-tabr.tar 100%[===================>]   2.88G  54.2MB/s    in 54s     \n","\n","2024-10-15 14:03:32 (54.3 MB/s) - ‘tabular-dl-tabr.tar.gz’ saved [3094384640/3094384640]\n","\n","data/\n","data/regression-num-medium-0-Ailerons/\n","data/regression-num-medium-0-Ailerons/X_num_val.npy\n","data/regression-num-medium-0-Ailerons/Y_val.npy\n","data/regression-num-medium-0-Ailerons/X_num_train.npy\n","data/regression-num-medium-0-Ailerons/info.json\n","data/regression-num-medium-0-Ailerons/READY\n","data/regression-num-medium-0-Ailerons/X_num_test.npy\n","data/regression-num-medium-0-Ailerons/Y_test.npy\n","data/regression-num-medium-0-Ailerons/Y_train.npy\n","data/regression-cat-medium-0-house_sales/\n","data/regression-cat-medium-0-house_sales/X_num_val.npy\n","data/regression-cat-medium-0-house_sales/Y_val.npy\n","data/regression-cat-medium-0-house_sales/X_bin_val.npy\n","data/regression-cat-medium-0-house_sales/X_num_train.npy\n","data/regression-cat-medium-0-house_sales/X_bin_train.npy\n","data/regression-cat-medium-0-house_sales/info.json\n","data/regression-cat-medium-0-house_sales/READY\n","data/regression-cat-medium-0-house_sales/X_bin_test.npy\n","data/regression-cat-medium-0-house_sales/X_num_test.npy\n","data/regression-cat-medium-0-house_sales/Y_test.npy\n","data/regression-cat-medium-0-house_sales/Y_train.npy\n","data/classif-cat-medium-2-KDDCup09_upselling/\n","data/classif-cat-medium-2-KDDCup09_upselling/X_cat_val.npy\n","data/classif-cat-medium-2-KDDCup09_upselling/X_num_val.npy\n","data/classif-cat-medium-2-KDDCup09_upselling/Y_val.npy\n","data/classif-cat-medium-2-KDDCup09_upselling/X_bin_val.npy\n","data/classif-cat-medium-2-KDDCup09_upselling/X_num_train.npy\n","data/classif-cat-medium-2-KDDCup09_upselling/X_cat_test.npy\n","data/classif-cat-medium-2-KDDCup09_upselling/X_bin_train.npy\n","data/classif-cat-medium-2-KDDCup09_upselling/X_cat_train.npy\n","data/classif-cat-medium-2-KDDCup09_upselling/info.json\n","data/classif-cat-medium-2-KDDCup09_upselling/READY\n","data/classif-cat-medium-2-KDDCup09_upselling/X_bin_test.npy\n","data/classif-cat-medium-2-KDDCup09_upselling/X_num_test.npy\n","data/classif-cat-medium-2-KDDCup09_upselling/Y_test.npy\n","data/classif-cat-medium-2-KDDCup09_upselling/Y_train.npy\n","data/regression-num-medium-2-isolet/\n","data/regression-num-medium-2-isolet/X_num_val.npy\n","data/regression-num-medium-2-isolet/Y_val.npy\n","data/regression-num-medium-2-isolet/X_num_train.npy\n","data/regression-num-medium-2-isolet/info.json\n","data/regression-num-medium-2-isolet/READY\n","data/regression-num-medium-2-isolet/X_num_test.npy\n","data/regression-num-medium-2-isolet/Y_test.npy\n","data/regression-num-medium-2-isolet/Y_train.npy\n","data/regression-cat-medium-1-Brazilian_houses/\n","data/regression-cat-medium-1-Brazilian_houses/X_cat_val.npy\n","data/regression-cat-medium-1-Brazilian_houses/X_num_val.npy\n","data/regression-cat-medium-1-Brazilian_houses/Y_val.npy\n","data/regression-cat-medium-1-Brazilian_houses/X_bin_val.npy\n","data/regression-cat-medium-1-Brazilian_houses/X_num_train.npy\n","data/regression-cat-medium-1-Brazilian_houses/X_cat_test.npy\n","data/regression-cat-medium-1-Brazilian_houses/X_bin_train.npy\n","data/regression-cat-medium-1-Brazilian_houses/X_cat_train.npy\n","data/regression-cat-medium-1-Brazilian_houses/info.json\n","data/regression-cat-medium-1-Brazilian_houses/READY\n","data/regression-cat-medium-1-Brazilian_houses/X_bin_test.npy\n","data/regression-cat-medium-1-Brazilian_houses/X_num_test.npy\n","data/regression-cat-medium-1-Brazilian_houses/Y_test.npy\n","data/regression-cat-medium-1-Brazilian_houses/Y_train.npy\n","data/regression-num-medium-2-wine_quality/\n","data/regression-num-medium-2-wine_quality/X_num_val.npy\n","data/regression-num-medium-2-wine_quality/Y_val.npy\n","data/regression-num-medium-2-wine_quality/X_num_train.npy\n","data/regression-num-medium-2-wine_quality/info.json\n","data/regression-num-medium-2-wine_quality/READY\n","data/regression-num-medium-2-wine_quality/X_num_test.npy\n","data/regression-num-medium-2-wine_quality/Y_test.npy\n","data/regression-num-medium-2-wine_quality/Y_train.npy\n","data/regression-num-medium-0-california/\n","data/regression-num-medium-0-california/X_num_val.npy\n","data/regression-num-medium-0-california/Y_val.npy\n","data/regression-num-medium-0-california/X_num_train.npy\n","data/regression-num-medium-0-california/info.json\n","data/regression-num-medium-0-california/READY\n","data/regression-num-medium-0-california/X_num_test.npy\n","data/regression-num-medium-0-california/Y_test.npy\n","data/regression-num-medium-0-california/Y_train.npy\n","data/classif-num-medium-2-wine/\n","data/classif-num-medium-2-wine/X_num_val.npy\n","data/classif-num-medium-2-wine/Y_val.npy\n","data/classif-num-medium-2-wine/X_num_train.npy\n","data/classif-num-medium-2-wine/info.json\n","data/classif-num-medium-2-wine/READY\n","data/classif-num-medium-2-wine/X_num_test.npy\n","data/classif-num-medium-2-wine/Y_test.npy\n","data/classif-num-medium-2-wine/Y_train.npy\n","data/classif-num-medium-1-phoneme/\n","data/classif-num-medium-1-phoneme/X_num_val.npy\n","data/classif-num-medium-1-phoneme/Y_val.npy\n","data/classif-num-medium-1-phoneme/X_num_train.npy\n","data/classif-num-medium-1-phoneme/info.json\n","data/classif-num-medium-1-phoneme/READY\n","data/classif-num-medium-1-phoneme/X_num_test.npy\n","data/classif-num-medium-1-phoneme/Y_test.npy\n","data/classif-num-medium-1-phoneme/Y_train.npy\n","data/regression-num-medium-1-isolet/\n","data/regression-num-medium-1-isolet/X_num_val.npy\n","data/regression-num-medium-1-isolet/Y_val.npy\n","data/regression-num-medium-1-isolet/X_num_train.npy\n","data/regression-num-medium-1-isolet/info.json\n","data/regression-num-medium-1-isolet/READY\n","data/regression-num-medium-1-isolet/X_num_test.npy\n","data/regression-num-medium-1-isolet/Y_test.npy\n","data/regression-num-medium-1-isolet/Y_train.npy\n","data/churn/\n","data/churn/X_cat_val.npy\n","data/churn/X_num_val.npy\n","data/churn/Y_val.npy\n","data/churn/X_bin_val.npy\n","data/churn/X_num_train.npy\n","data/churn/X_cat_test.npy\n","data/churn/X_bin_train.npy\n","data/churn/X_cat_train.npy\n","data/churn/info.json\n","data/churn/READY\n","data/churn/X_bin_test.npy\n","data/churn/X_num_test.npy\n","data/churn/Y_test.npy\n","data/churn/Y_train.npy\n","data/regression-num-medium-2-sulfur/\n","data/regression-num-medium-2-sulfur/X_num_val.npy\n","data/regression-num-medium-2-sulfur/Y_val.npy\n","data/regression-num-medium-2-sulfur/X_num_train.npy\n","data/regression-num-medium-2-sulfur/info.json\n","data/regression-num-medium-2-sulfur/READY\n","data/regression-num-medium-2-sulfur/X_num_test.npy\n","data/regression-num-medium-2-sulfur/Y_test.npy\n","data/regression-num-medium-2-sulfur/Y_train.npy\n","data/regression-cat-large-0-diamonds/\n","data/regression-cat-large-0-diamonds/X_cat_val.npy\n","data/regression-cat-large-0-diamonds/X_num_val.npy\n","data/regression-cat-large-0-diamonds/Y_val.npy\n","data/regression-cat-large-0-diamonds/X_num_train.npy\n","data/regression-cat-large-0-diamonds/X_cat_test.npy\n","data/regression-cat-large-0-diamonds/X_cat_train.npy\n","data/regression-cat-large-0-diamonds/info.json\n","data/regression-cat-large-0-diamonds/READY\n","data/regression-cat-large-0-diamonds/X_num_test.npy\n","data/regression-cat-large-0-diamonds/Y_test.npy\n","data/regression-cat-large-0-diamonds/Y_train.npy\n","data/classif-cat-large-0-road-safety/\n","data/classif-cat-large-0-road-safety/X_cat_val.npy\n","data/classif-cat-large-0-road-safety/X_num_val.npy\n","data/classif-cat-large-0-road-safety/Y_val.npy\n","data/classif-cat-large-0-road-safety/X_num_train.npy\n","data/classif-cat-large-0-road-safety/X_cat_test.npy\n","data/classif-cat-large-0-road-safety/X_cat_train.npy\n","data/classif-cat-large-0-road-safety/info.json\n","data/classif-cat-large-0-road-safety/READY\n","data/classif-cat-large-0-road-safety/X_num_test.npy\n","data/classif-cat-large-0-road-safety/Y_test.npy\n","data/classif-cat-large-0-road-safety/Y_train.npy\n","data/classif-num-medium-1-MagicTelescope/\n","data/classif-num-medium-1-MagicTelescope/X_num_val.npy\n","data/classif-num-medium-1-MagicTelescope/Y_val.npy\n","data/classif-num-medium-1-MagicTelescope/X_num_train.npy\n","data/classif-num-medium-1-MagicTelescope/info.json\n","data/classif-num-medium-1-MagicTelescope/READY\n","data/classif-num-medium-1-MagicTelescope/X_num_test.npy\n","data/classif-num-medium-1-MagicTelescope/Y_test.npy\n","data/classif-num-medium-1-MagicTelescope/Y_train.npy\n","data/regression-num-medium-0-wine_quality/\n","data/regression-num-medium-0-wine_quality/X_num_val.npy\n","data/regression-num-medium-0-wine_quality/Y_val.npy\n","data/regression-num-medium-0-wine_quality/X_num_train.npy\n","data/regression-num-medium-0-wine_quality/info.json\n","data/regression-num-medium-0-wine_quality/READY\n","data/regression-num-medium-0-wine_quality/X_num_test.npy\n","data/regression-num-medium-0-wine_quality/Y_test.npy\n","data/regression-num-medium-0-wine_quality/Y_train.npy\n","data/adult/\n","data/adult/X_cat_val.npy\n","data/adult/X_num_val.npy\n","data/adult/Y_val.npy\n","data/adult/X_bin_val.npy\n","data/adult/X_num_train.npy\n","data/adult/X_cat_test.npy\n","data/adult/X_bin_train.npy\n","data/adult/X_cat_train.npy\n","data/adult/info.json\n","data/adult/READY\n","data/adult/X_bin_test.npy\n","data/adult/X_num_test.npy\n","data/adult/Y_test.npy\n","data/adult/Y_train.npy\n","data/classif-num-medium-1-kdd_ipums_la_97-small/\n","data/classif-num-medium-1-kdd_ipums_la_97-small/X_num_val.npy\n","data/classif-num-medium-1-kdd_ipums_la_97-small/Y_val.npy\n","data/classif-num-medium-1-kdd_ipums_la_97-small/X_num_train.npy\n","data/classif-num-medium-1-kdd_ipums_la_97-small/info.json\n","data/classif-num-medium-1-kdd_ipums_la_97-small/READY\n","data/classif-num-medium-1-kdd_ipums_la_97-small/X_num_test.npy\n","data/classif-num-medium-1-kdd_ipums_la_97-small/Y_test.npy\n","data/classif-num-medium-1-kdd_ipums_la_97-small/Y_train.npy\n","data/regression-num-medium-0-superconduct/\n","data/regression-num-medium-0-superconduct/X_num_val.npy\n","data/regression-num-medium-0-superconduct/Y_val.npy\n","data/regression-num-medium-0-superconduct/X_num_train.npy\n","data/regression-num-medium-0-superconduct/info.json\n","data/regression-num-medium-0-superconduct/READY\n","data/regression-num-medium-0-superconduct/X_num_test.npy\n","data/regression-num-medium-0-superconduct/Y_test.npy\n","data/regression-num-medium-0-superconduct/Y_train.npy\n","data/regression-num-medium-0-house_16H/\n","data/regression-num-medium-0-house_16H/X_num_val.npy\n","data/regression-num-medium-0-house_16H/Y_val.npy\n","data/regression-num-medium-0-house_16H/X_num_train.npy\n","data/regression-num-medium-0-house_16H/info.json\n","data/regression-num-medium-0-house_16H/READY\n","data/regression-num-medium-0-house_16H/X_num_test.npy\n","data/regression-num-medium-0-house_16H/Y_test.npy\n","data/regression-num-medium-0-house_16H/Y_train.npy\n","data/weather-big/\n","data/weather-big/X_num_val.npy\n","data/weather-big/Y_val.npy\n","data/weather-big/X_bin_val.npy\n","data/weather-big/X_num_train.npy\n","data/weather-big/X_bin_train.npy\n","data/weather-big/LICENSE.md\n","data/weather-big/info.json\n","data/weather-big/READY\n","data/weather-big/X_bin_test.npy\n","data/weather-big/X_num_test.npy\n","data/weather-big/Y_test.npy\n","data/weather-big/Y_train.npy\n","data/classif-num-large-0-Higgs/\n","data/classif-num-large-0-Higgs/X_num_val.npy\n","data/classif-num-large-0-Higgs/Y_val.npy\n","data/classif-num-large-0-Higgs/X_num_train.npy\n","data/classif-num-large-0-Higgs/info.json\n","data/classif-num-large-0-Higgs/READY\n","data/classif-num-large-0-Higgs/X_num_test.npy\n","data/classif-num-large-0-Higgs/Y_test.npy\n","data/classif-num-large-0-Higgs/Y_train.npy\n","data/regression-cat-medium-2-analcatdata_supreme/\n","data/regression-cat-medium-2-analcatdata_supreme/X_num_val.npy\n","data/regression-cat-medium-2-analcatdata_supreme/Y_val.npy\n","data/regression-cat-medium-2-analcatdata_supreme/X_bin_val.npy\n","data/regression-cat-medium-2-analcatdata_supreme/X_num_train.npy\n","data/regression-cat-medium-2-analcatdata_supreme/X_bin_train.npy\n","data/regression-cat-medium-2-analcatdata_supreme/info.json\n","data/regression-cat-medium-2-analcatdata_supreme/READY\n","data/regression-cat-medium-2-analcatdata_supreme/X_bin_test.npy\n","data/regression-cat-medium-2-analcatdata_supreme/X_num_test.npy\n","data/regression-cat-medium-2-analcatdata_supreme/Y_test.npy\n","data/regression-cat-medium-2-analcatdata_supreme/Y_train.npy\n","data/regression-cat-large-0-black_friday/\n","data/regression-cat-large-0-black_friday/X_cat_val.npy\n","data/regression-cat-large-0-black_friday/X_num_val.npy\n","data/regression-cat-large-0-black_friday/Y_val.npy\n","data/regression-cat-large-0-black_friday/X_bin_val.npy\n","data/regression-cat-large-0-black_friday/X_num_train.npy\n","data/regression-cat-large-0-black_friday/X_cat_test.npy\n","data/regression-cat-large-0-black_friday/X_bin_train.npy\n","data/regression-cat-large-0-black_friday/X_cat_train.npy\n","data/regression-cat-large-0-black_friday/info.json\n","data/regression-cat-large-0-black_friday/READY\n","data/regression-cat-large-0-black_friday/X_bin_test.npy\n","data/regression-cat-large-0-black_friday/X_num_test.npy\n","data/regression-cat-large-0-black_friday/Y_test.npy\n","data/regression-cat-large-0-black_friday/Y_train.npy\n","data/classif-num-medium-1-wine/\n","data/classif-num-medium-1-wine/X_num_val.npy\n","data/classif-num-medium-1-wine/Y_val.npy\n","data/classif-num-medium-1-wine/X_num_train.npy\n","data/classif-num-medium-1-wine/info.json\n","data/classif-num-medium-1-wine/READY\n","data/classif-num-medium-1-wine/X_num_test.npy\n","data/classif-num-medium-1-wine/Y_test.npy\n","data/classif-num-medium-1-wine/Y_train.npy\n","data/regression-cat-medium-0-visualizing_soil/\n","data/regression-cat-medium-0-visualizing_soil/X_num_val.npy\n","data/regression-cat-medium-0-visualizing_soil/Y_val.npy\n","data/regression-cat-medium-0-visualizing_soil/X_bin_val.npy\n","data/regression-cat-medium-0-visualizing_soil/X_num_train.npy\n","data/regression-cat-medium-0-visualizing_soil/X_bin_train.npy\n","data/regression-cat-medium-0-visualizing_soil/info.json\n","data/regression-cat-medium-0-visualizing_soil/READY\n","data/regression-cat-medium-0-visualizing_soil/X_bin_test.npy\n","data/regression-cat-medium-0-visualizing_soil/X_num_test.npy\n","data/regression-cat-medium-0-visualizing_soil/Y_test.npy\n","data/regression-cat-medium-0-visualizing_soil/Y_train.npy\n","data/regression-cat-medium-1-Mercedes_Benz_Greener_Manufacturing/\n","data/regression-cat-medium-1-Mercedes_Benz_Greener_Manufacturing/X_cat_val.npy\n","data/regression-cat-medium-1-Mercedes_Benz_Greener_Manufacturing/Y_val.npy\n","data/regression-cat-medium-1-Mercedes_Benz_Greener_Manufacturing/X_bin_val.npy\n","data/regression-cat-medium-1-Mercedes_Benz_Greener_Manufacturing/X_cat_test.npy\n","data/regression-cat-medium-1-Mercedes_Benz_Greener_Manufacturing/X_bin_train.npy\n","data/regression-cat-medium-1-Mercedes_Benz_Greener_Manufacturing/X_cat_train.npy\n","data/regression-cat-medium-1-Mercedes_Benz_Greener_Manufacturing/info.json\n","data/regression-cat-medium-1-Mercedes_Benz_Greener_Manufacturing/READY\n","data/regression-cat-medium-1-Mercedes_Benz_Greener_Manufacturing/X_bin_test.npy\n","data/regression-cat-medium-1-Mercedes_Benz_Greener_Manufacturing/Y_test.npy\n","data/regression-cat-medium-1-Mercedes_Benz_Greener_Manufacturing/Y_train.npy\n","data/classif-num-medium-0-kdd_ipums_la_97-small/\n","data/classif-num-medium-0-kdd_ipums_la_97-small/X_num_val.npy\n","data/classif-num-medium-0-kdd_ipums_la_97-small/Y_val.npy\n","data/classif-num-medium-0-kdd_ipums_la_97-small/X_num_train.npy\n","data/classif-num-medium-0-kdd_ipums_la_97-small/info.json\n","data/classif-num-medium-0-kdd_ipums_la_97-small/READY\n","data/classif-num-medium-0-kdd_ipums_la_97-small/X_num_test.npy\n","data/classif-num-medium-0-kdd_ipums_la_97-small/Y_test.npy\n","data/classif-num-medium-0-kdd_ipums_la_97-small/Y_train.npy\n","data/regression-num-medium-1-MiamiHousing2016/\n","data/regression-num-medium-1-MiamiHousing2016/X_num_val.npy\n","data/regression-num-medium-1-MiamiHousing2016/Y_val.npy\n","data/regression-num-medium-1-MiamiHousing2016/X_num_train.npy\n","data/regression-num-medium-1-MiamiHousing2016/info.json\n","data/regression-num-medium-1-MiamiHousing2016/READY\n","data/regression-num-medium-1-MiamiHousing2016/X_num_test.npy\n","data/regression-num-medium-1-MiamiHousing2016/Y_test.npy\n","data/regression-num-medium-1-MiamiHousing2016/Y_train.npy\n","data/regression-cat-medium-0-OnlineNewsPopularity/\n","data/regression-cat-medium-0-OnlineNewsPopularity/X_num_val.npy\n","data/regression-cat-medium-0-OnlineNewsPopularity/Y_val.npy\n","data/regression-cat-medium-0-OnlineNewsPopularity/X_bin_val.npy\n","data/regression-cat-medium-0-OnlineNewsPopularity/X_num_train.npy\n","data/regression-cat-medium-0-OnlineNewsPopularity/X_bin_train.npy\n","data/regression-cat-medium-0-OnlineNewsPopularity/info.json\n","data/regression-cat-medium-0-OnlineNewsPopularity/READY\n","data/regression-cat-medium-0-OnlineNewsPopularity/X_bin_test.npy\n","data/regression-cat-medium-0-OnlineNewsPopularity/X_num_test.npy\n","data/regression-cat-medium-0-OnlineNewsPopularity/Y_test.npy\n","data/regression-cat-medium-0-OnlineNewsPopularity/Y_train.npy\n","data/regression-num-medium-1-elevators/\n","data/regression-num-medium-1-elevators/X_num_val.npy\n","data/regression-num-medium-1-elevators/Y_val.npy\n","data/regression-num-medium-1-elevators/X_num_train.npy\n","data/regression-num-medium-1-elevators/info.json\n","data/regression-num-medium-1-elevators/READY\n","data/regression-num-medium-1-elevators/X_num_test.npy\n","data/regression-num-medium-1-elevators/Y_test.npy\n","data/regression-num-medium-1-elevators/Y_train.npy\n","data/regression-num-medium-0-pol/\n","data/regression-num-medium-0-pol/X_num_val.npy\n","data/regression-num-medium-0-pol/Y_val.npy\n","data/regression-num-medium-0-pol/X_num_train.npy\n","data/regression-num-medium-0-pol/info.json\n","data/regression-num-medium-0-pol/READY\n","data/regression-num-medium-0-pol/X_num_test.npy\n","data/regression-num-medium-0-pol/Y_test.npy\n","data/regression-num-medium-0-pol/Y_train.npy\n","data/classif-num-medium-2-kdd_ipums_la_97-small/\n","data/classif-num-medium-2-kdd_ipums_la_97-small/X_num_val.npy\n","data/classif-num-medium-2-kdd_ipums_la_97-small/Y_val.npy\n","data/classif-num-medium-2-kdd_ipums_la_97-small/X_num_train.npy\n","data/classif-num-medium-2-kdd_ipums_la_97-small/info.json\n","data/classif-num-medium-2-kdd_ipums_la_97-small/READY\n","data/classif-num-medium-2-kdd_ipums_la_97-small/X_num_test.npy\n","data/classif-num-medium-2-kdd_ipums_la_97-small/Y_test.npy\n","data/classif-num-medium-2-kdd_ipums_la_97-small/Y_train.npy\n","data/classif-num-medium-0-phoneme/\n","data/classif-num-medium-0-phoneme/X_num_val.npy\n","data/classif-num-medium-0-phoneme/Y_val.npy\n","data/classif-num-medium-0-phoneme/X_num_train.npy\n","data/classif-num-medium-0-phoneme/info.json\n","data/classif-num-medium-0-phoneme/READY\n","data/classif-num-medium-0-phoneme/X_num_test.npy\n","data/classif-num-medium-0-phoneme/Y_test.npy\n","data/classif-num-medium-0-phoneme/Y_train.npy\n","data/regression-num-medium-0-sulfur/\n","data/regression-num-medium-0-sulfur/X_num_val.npy\n","data/regression-num-medium-0-sulfur/Y_val.npy\n","data/regression-num-medium-0-sulfur/X_num_train.npy\n","data/regression-num-medium-0-sulfur/info.json\n","data/regression-num-medium-0-sulfur/READY\n","data/regression-num-medium-0-sulfur/X_num_test.npy\n","data/regression-num-medium-0-sulfur/Y_test.npy\n","data/regression-num-medium-0-sulfur/Y_train.npy\n","data/regression-cat-medium-0-analcatdata_supreme/\n","data/regression-cat-medium-0-analcatdata_supreme/X_num_val.npy\n","data/regression-cat-medium-0-analcatdata_supreme/Y_val.npy\n","data/regression-cat-medium-0-analcatdata_supreme/X_bin_val.npy\n","data/regression-cat-medium-0-analcatdata_supreme/X_num_train.npy\n","data/regression-cat-medium-0-analcatdata_supreme/X_bin_train.npy\n","data/regression-cat-medium-0-analcatdata_supreme/info.json\n","data/regression-cat-medium-0-analcatdata_supreme/READY\n","data/regression-cat-medium-0-analcatdata_supreme/X_bin_test.npy\n","data/regression-cat-medium-0-analcatdata_supreme/X_num_test.npy\n","data/regression-cat-medium-0-analcatdata_supreme/Y_test.npy\n","data/regression-cat-medium-0-analcatdata_supreme/Y_train.npy\n","data/classif-num-medium-2-phoneme/\n","data/classif-num-medium-2-phoneme/X_num_val.npy\n","data/classif-num-medium-2-phoneme/Y_val.npy\n","data/classif-num-medium-2-phoneme/X_num_train.npy\n","data/classif-num-medium-2-phoneme/info.json\n","data/classif-num-medium-2-phoneme/READY\n","data/classif-num-medium-2-phoneme/X_num_test.npy\n","data/classif-num-medium-2-phoneme/Y_test.npy\n","data/classif-num-medium-2-phoneme/Y_train.npy\n","data/regression-cat-large-0-SGEMM_GPU_kernel_performance/\n","data/regression-cat-large-0-SGEMM_GPU_kernel_performance/X_num_val.npy\n","data/regression-cat-large-0-SGEMM_GPU_kernel_performance/Y_val.npy\n","data/regression-cat-large-0-SGEMM_GPU_kernel_performance/X_bin_val.npy\n","data/regression-cat-large-0-SGEMM_GPU_kernel_performance/X_num_train.npy\n","data/regression-cat-large-0-SGEMM_GPU_kernel_performance/X_bin_train.npy\n","data/regression-cat-large-0-SGEMM_GPU_kernel_performance/info.json\n","data/regression-cat-large-0-SGEMM_GPU_kernel_performance/READY\n","data/regression-cat-large-0-SGEMM_GPU_kernel_performance/X_bin_test.npy\n","data/regression-cat-large-0-SGEMM_GPU_kernel_performance/X_num_test.npy\n","data/regression-cat-large-0-SGEMM_GPU_kernel_performance/Y_test.npy\n","data/regression-cat-large-0-SGEMM_GPU_kernel_performance/Y_train.npy\n","data/regression-num-medium-1-wine_quality/\n","data/regression-num-medium-1-wine_quality/X_num_val.npy\n","data/regression-num-medium-1-wine_quality/Y_val.npy\n","data/regression-num-medium-1-wine_quality/X_num_train.npy\n","data/regression-num-medium-1-wine_quality/info.json\n","data/regression-num-medium-1-wine_quality/READY\n","data/regression-num-medium-1-wine_quality/X_num_test.npy\n","data/regression-num-medium-1-wine_quality/Y_test.npy\n","data/regression-num-medium-1-wine_quality/Y_train.npy\n","data/regression-num-medium-0-cpu_act/\n","data/regression-num-medium-0-cpu_act/X_num_val.npy\n","data/regression-num-medium-0-cpu_act/Y_val.npy\n","data/regression-num-medium-0-cpu_act/X_num_train.npy\n","data/regression-num-medium-0-cpu_act/info.json\n","data/regression-num-medium-0-cpu_act/READY\n","data/regression-num-medium-0-cpu_act/X_num_test.npy\n","data/regression-num-medium-0-cpu_act/Y_test.npy\n","data/regression-num-medium-0-cpu_act/Y_train.npy\n","data/regression-cat-medium-0-Bike_Sharing_Demand/\n","data/regression-cat-medium-0-Bike_Sharing_Demand/X_cat_val.npy\n","data/regression-cat-medium-0-Bike_Sharing_Demand/X_num_val.npy\n","data/regression-cat-medium-0-Bike_Sharing_Demand/Y_val.npy\n","data/regression-cat-medium-0-Bike_Sharing_Demand/X_bin_val.npy\n","data/regression-cat-medium-0-Bike_Sharing_Demand/X_num_train.npy\n","data/regression-cat-medium-0-Bike_Sharing_Demand/X_cat_test.npy\n","data/regression-cat-medium-0-Bike_Sharing_Demand/X_bin_train.npy\n","data/regression-cat-medium-0-Bike_Sharing_Demand/X_cat_train.npy\n","data/regression-cat-medium-0-Bike_Sharing_Demand/info.json\n","data/regression-cat-medium-0-Bike_Sharing_Demand/READY\n","data/regression-cat-medium-0-Bike_Sharing_Demand/X_bin_test.npy\n","data/regression-cat-medium-0-Bike_Sharing_Demand/X_num_test.npy\n","data/regression-cat-medium-0-Bike_Sharing_Demand/Y_test.npy\n","data/regression-cat-medium-0-Bike_Sharing_Demand/Y_train.npy\n","data/regression-cat-medium-1-visualizing_soil/\n","data/regression-cat-medium-1-visualizing_soil/X_num_val.npy\n","data/regression-cat-medium-1-visualizing_soil/Y_val.npy\n","data/regression-cat-medium-1-visualizing_soil/X_bin_val.npy\n","data/regression-cat-medium-1-visualizing_soil/X_num_train.npy\n","data/regression-cat-medium-1-visualizing_soil/X_bin_train.npy\n","data/regression-cat-medium-1-visualizing_soil/info.json\n","data/regression-cat-medium-1-visualizing_soil/READY\n","data/regression-cat-medium-1-visualizing_soil/X_bin_test.npy\n","data/regression-cat-medium-1-visualizing_soil/X_num_test.npy\n","data/regression-cat-medium-1-visualizing_soil/Y_test.npy\n","data/regression-cat-medium-1-visualizing_soil/Y_train.npy\n","data/classif-num-medium-4-phoneme/\n","data/classif-num-medium-4-phoneme/X_num_val.npy\n","data/classif-num-medium-4-phoneme/Y_val.npy\n","data/classif-num-medium-4-phoneme/X_num_train.npy\n","data/classif-num-medium-4-phoneme/info.json\n","data/classif-num-medium-4-phoneme/READY\n","data/classif-num-medium-4-phoneme/X_num_test.npy\n","data/classif-num-medium-4-phoneme/Y_test.npy\n","data/classif-num-medium-4-phoneme/Y_train.npy\n","data/house/\n","data/house/X_num_val.npy\n","data/house/Y_val.npy\n","data/house/X_num_train.npy\n","data/house/info.json\n","data/house/READY\n","data/house/X_num_test.npy\n","data/house/Y_test.npy\n","data/house/Y_train.npy\n","data/regression-cat-medium-2-Brazilian_houses/\n","data/regression-cat-medium-2-Brazilian_houses/X_cat_val.npy\n","data/regression-cat-medium-2-Brazilian_houses/X_num_val.npy\n","data/regression-cat-medium-2-Brazilian_houses/Y_val.npy\n","data/regression-cat-medium-2-Brazilian_houses/X_bin_val.npy\n","data/regression-cat-medium-2-Brazilian_houses/X_num_train.npy\n","data/regression-cat-medium-2-Brazilian_houses/X_cat_test.npy\n","data/regression-cat-medium-2-Brazilian_houses/X_bin_train.npy\n","data/regression-cat-medium-2-Brazilian_houses/X_cat_train.npy\n","data/regression-cat-medium-2-Brazilian_houses/info.json\n","data/regression-cat-medium-2-Brazilian_houses/READY\n","data/regression-cat-medium-2-Brazilian_houses/X_bin_test.npy\n","data/regression-cat-medium-2-Brazilian_houses/X_num_test.npy\n","data/regression-cat-medium-2-Brazilian_houses/Y_test.npy\n","data/regression-cat-medium-2-Brazilian_houses/Y_train.npy\n","data/regression-cat-large-0-particulate-matter-ukair-2017/\n","data/regression-cat-large-0-particulate-matter-ukair-2017/X_cat_val.npy\n","data/regression-cat-large-0-particulate-matter-ukair-2017/X_num_val.npy\n","data/regression-cat-large-0-particulate-matter-ukair-2017/Y_val.npy\n","data/regression-cat-large-0-particulate-matter-ukair-2017/X_num_train.npy\n","data/regression-cat-large-0-particulate-matter-ukair-2017/X_cat_test.npy\n","data/regression-cat-large-0-particulate-matter-ukair-2017/X_cat_train.npy\n","data/regression-cat-large-0-particulate-matter-ukair-2017/info.json\n","data/regression-cat-large-0-particulate-matter-ukair-2017/READY\n","data/regression-cat-large-0-particulate-matter-ukair-2017/X_num_test.npy\n","data/regression-cat-large-0-particulate-matter-ukair-2017/Y_test.npy\n","data/regression-cat-large-0-particulate-matter-ukair-2017/Y_train.npy\n","data/regression-cat-medium-2-Mercedes_Benz_Greener_Manufacturing/\n","data/regression-cat-medium-2-Mercedes_Benz_Greener_Manufacturing/X_cat_val.npy\n","data/regression-cat-medium-2-Mercedes_Benz_Greener_Manufacturing/Y_val.npy\n","data/regression-cat-medium-2-Mercedes_Benz_Greener_Manufacturing/X_bin_val.npy\n","data/regression-cat-medium-2-Mercedes_Benz_Greener_Manufacturing/X_cat_test.npy\n","data/regression-cat-medium-2-Mercedes_Benz_Greener_Manufacturing/X_bin_train.npy\n","data/regression-cat-medium-2-Mercedes_Benz_Greener_Manufacturing/X_cat_train.npy\n","data/regression-cat-medium-2-Mercedes_Benz_Greener_Manufacturing/info.json\n","data/regression-cat-medium-2-Mercedes_Benz_Greener_Manufacturing/READY\n","data/regression-cat-medium-2-Mercedes_Benz_Greener_Manufacturing/X_bin_test.npy\n","data/regression-cat-medium-2-Mercedes_Benz_Greener_Manufacturing/Y_test.npy\n","data/regression-cat-medium-2-Mercedes_Benz_Greener_Manufacturing/Y_train.npy\n","data/black-friday/\n","data/black-friday/X_cat_val.npy\n","data/black-friday/X_num_val.npy\n","data/black-friday/Y_val.npy\n","data/black-friday/X_bin_val.npy\n","data/black-friday/X_num_train.npy\n","data/black-friday/X_cat_test.npy\n","data/black-friday/X_bin_train.npy\n","data/black-friday/X_cat_train.npy\n","data/black-friday/info.json\n","data/black-friday/X_bin_test.npy\n","data/black-friday/X_num_test.npy\n","data/black-friday/Y_test.npy\n","data/black-friday/Y_train.npy\n","data/regression-num-medium-1-sulfur/\n","data/regression-num-medium-1-sulfur/X_num_val.npy\n","data/regression-num-medium-1-sulfur/Y_val.npy\n","data/regression-num-medium-1-sulfur/X_num_train.npy\n","data/regression-num-medium-1-sulfur/info.json\n","data/regression-num-medium-1-sulfur/READY\n","data/regression-num-medium-1-sulfur/X_num_test.npy\n","data/regression-num-medium-1-sulfur/Y_test.npy\n","data/regression-num-medium-1-sulfur/Y_train.npy\n","data/classif-num-medium-0-wine/\n","data/classif-num-medium-0-wine/X_num_val.npy\n","data/classif-num-medium-0-wine/Y_val.npy\n","data/classif-num-medium-0-wine/X_num_train.npy\n","data/classif-num-medium-0-wine/info.json\n","data/classif-num-medium-0-wine/READY\n","data/classif-num-medium-0-wine/X_num_test.npy\n","data/classif-num-medium-0-wine/Y_test.npy\n","data/classif-num-medium-0-wine/Y_train.npy\n","data/covtype/\n","data/covtype/X_num_val.npy\n","data/covtype/Y_val.npy\n","data/covtype/X_bin_val.npy\n","data/covtype/X_num_train.npy\n","data/covtype/X_bin_train.npy\n","data/covtype/info.json\n","data/covtype/READY\n","data/covtype/X_bin_test.npy\n","data/covtype/X_num_test.npy\n","data/covtype/Y_test.npy\n","data/covtype/Y_train.npy\n","data/regression-cat-large-0-nyc-taxi-green-dec-2016/\n","data/regression-cat-large-0-nyc-taxi-green-dec-2016/X_cat_val.npy\n","data/regression-cat-large-0-nyc-taxi-green-dec-2016/X_num_val.npy\n","data/regression-cat-large-0-nyc-taxi-green-dec-2016/Y_val.npy\n","data/regression-cat-large-0-nyc-taxi-green-dec-2016/X_bin_val.npy\n","data/regression-cat-large-0-nyc-taxi-green-dec-2016/X_num_train.npy\n","data/regression-cat-large-0-nyc-taxi-green-dec-2016/X_cat_test.npy\n","data/regression-cat-large-0-nyc-taxi-green-dec-2016/X_bin_train.npy\n","data/regression-cat-large-0-nyc-taxi-green-dec-2016/X_cat_train.npy\n","data/regression-cat-large-0-nyc-taxi-green-dec-2016/info.json\n","data/regression-cat-large-0-nyc-taxi-green-dec-2016/READY\n","data/regression-cat-large-0-nyc-taxi-green-dec-2016/X_bin_test.npy\n","data/regression-cat-large-0-nyc-taxi-green-dec-2016/X_num_test.npy\n","data/regression-cat-large-0-nyc-taxi-green-dec-2016/Y_test.npy\n","data/regression-cat-large-0-nyc-taxi-green-dec-2016/Y_train.npy\n","data/classif-num-medium-0-MagicTelescope/\n","data/classif-num-medium-0-MagicTelescope/X_num_val.npy\n","data/classif-num-medium-0-MagicTelescope/Y_val.npy\n","data/classif-num-medium-0-MagicTelescope/X_num_train.npy\n","data/classif-num-medium-0-MagicTelescope/info.json\n","data/classif-num-medium-0-MagicTelescope/READY\n","data/classif-num-medium-0-MagicTelescope/X_num_test.npy\n","data/classif-num-medium-0-MagicTelescope/Y_test.npy\n","data/classif-num-medium-0-MagicTelescope/Y_train.npy\n","data/regression-cat-medium-3-analcatdata_supreme/\n","data/regression-cat-medium-3-analcatdata_supreme/X_num_val.npy\n","data/regression-cat-medium-3-analcatdata_supreme/Y_val.npy\n","data/regression-cat-medium-3-analcatdata_supreme/X_bin_val.npy\n","data/regression-cat-medium-3-analcatdata_supreme/X_num_train.npy\n","data/regression-cat-medium-3-analcatdata_supreme/X_bin_train.npy\n","data/regression-cat-medium-3-analcatdata_supreme/info.json\n","data/regression-cat-medium-3-analcatdata_supreme/READY\n","data/regression-cat-medium-3-analcatdata_supreme/X_bin_test.npy\n","data/regression-cat-medium-3-analcatdata_supreme/X_num_test.npy\n","data/regression-cat-medium-3-analcatdata_supreme/Y_test.npy\n","data/regression-cat-medium-3-analcatdata_supreme/Y_train.npy\n","data/regression-cat-medium-0-Mercedes_Benz_Greener_Manufacturing/\n","data/regression-cat-medium-0-Mercedes_Benz_Greener_Manufacturing/X_cat_val.npy\n","data/regression-cat-medium-0-Mercedes_Benz_Greener_Manufacturing/Y_val.npy\n","data/regression-cat-medium-0-Mercedes_Benz_Greener_Manufacturing/X_bin_val.npy\n","data/regression-cat-medium-0-Mercedes_Benz_Greener_Manufacturing/X_cat_test.npy\n","data/regression-cat-medium-0-Mercedes_Benz_Greener_Manufacturing/X_bin_train.npy\n","data/regression-cat-medium-0-Mercedes_Benz_Greener_Manufacturing/X_cat_train.npy\n","data/regression-cat-medium-0-Mercedes_Benz_Greener_Manufacturing/info.json\n","data/regression-cat-medium-0-Mercedes_Benz_Greener_Manufacturing/READY\n","data/regression-cat-medium-0-Mercedes_Benz_Greener_Manufacturing/X_bin_test.npy\n","data/regression-cat-medium-0-Mercedes_Benz_Greener_Manufacturing/Y_test.npy\n","data/regression-cat-medium-0-Mercedes_Benz_Greener_Manufacturing/Y_train.npy\n","data/microsoft/\n","data/microsoft/X_num_val.npy\n","data/microsoft/Y_val.npy\n","data/microsoft/X_bin_val.npy\n","data/microsoft/X_num_train.npy\n","data/microsoft/X_bin_train.npy\n","data/microsoft/info.json\n","data/microsoft/READY\n","data/microsoft/X_bin_test.npy\n","data/microsoft/X_num_test.npy\n","data/microsoft/Y_test.npy\n","data/microsoft/Y_train.npy\n","data/regression-cat-medium-4-analcatdata_supreme/\n","data/regression-cat-medium-4-analcatdata_supreme/X_num_val.npy\n","data/regression-cat-medium-4-analcatdata_supreme/Y_val.npy\n","data/regression-cat-medium-4-analcatdata_supreme/X_bin_val.npy\n","data/regression-cat-medium-4-analcatdata_supreme/X_num_train.npy\n","data/regression-cat-medium-4-analcatdata_supreme/X_bin_train.npy\n","data/regression-cat-medium-4-analcatdata_supreme/info.json\n","data/regression-cat-medium-4-analcatdata_supreme/READY\n","data/regression-cat-medium-4-analcatdata_supreme/X_bin_test.npy\n","data/regression-cat-medium-4-analcatdata_supreme/X_num_test.npy\n","data/regression-cat-medium-4-analcatdata_supreme/Y_test.npy\n","data/regression-cat-medium-4-analcatdata_supreme/Y_train.npy\n","data/regression-num-medium-1-fifa/\n","data/regression-num-medium-1-fifa/X_num_val.npy\n","data/regression-num-medium-1-fifa/Y_val.npy\n","data/regression-num-medium-1-fifa/X_num_train.npy\n","data/regression-num-medium-1-fifa/info.json\n","data/regression-num-medium-1-fifa/READY\n","data/regression-num-medium-1-fifa/X_num_test.npy\n","data/regression-num-medium-1-fifa/Y_test.npy\n","data/regression-num-medium-1-fifa/Y_train.npy\n","data/regression-num-medium-0-isolet/\n","data/regression-num-medium-0-isolet/X_num_val.npy\n","data/regression-num-medium-0-isolet/Y_val.npy\n","data/regression-num-medium-0-isolet/X_num_train.npy\n","data/regression-num-medium-0-isolet/info.json\n","data/regression-num-medium-0-isolet/READY\n","data/regression-num-medium-0-isolet/X_num_test.npy\n","data/regression-num-medium-0-isolet/Y_test.npy\n","data/regression-num-medium-0-isolet/Y_train.npy\n","data/classif-num-medium-3-phoneme/\n","data/classif-num-medium-3-phoneme/X_num_val.npy\n","data/classif-num-medium-3-phoneme/Y_val.npy\n","data/classif-num-medium-3-phoneme/X_num_train.npy\n","data/classif-num-medium-3-phoneme/info.json\n","data/classif-num-medium-3-phoneme/READY\n","data/classif-num-medium-3-phoneme/X_num_test.npy\n","data/classif-num-medium-3-phoneme/Y_test.npy\n","data/classif-num-medium-3-phoneme/Y_train.npy\n","data/regression-cat-medium-3-Mercedes_Benz_Greener_Manufacturing/\n","data/regression-cat-medium-3-Mercedes_Benz_Greener_Manufacturing/X_cat_val.npy\n","data/regression-cat-medium-3-Mercedes_Benz_Greener_Manufacturing/Y_val.npy\n","data/regression-cat-medium-3-Mercedes_Benz_Greener_Manufacturing/X_bin_val.npy\n","data/regression-cat-medium-3-Mercedes_Benz_Greener_Manufacturing/X_cat_test.npy\n","data/regression-cat-medium-3-Mercedes_Benz_Greener_Manufacturing/X_bin_train.npy\n","data/regression-cat-medium-3-Mercedes_Benz_Greener_Manufacturing/X_cat_train.npy\n","data/regression-cat-medium-3-Mercedes_Benz_Greener_Manufacturing/info.json\n","data/regression-cat-medium-3-Mercedes_Benz_Greener_Manufacturing/READY\n","data/regression-cat-medium-3-Mercedes_Benz_Greener_Manufacturing/X_bin_test.npy\n","data/regression-cat-medium-3-Mercedes_Benz_Greener_Manufacturing/Y_test.npy\n","data/regression-cat-medium-3-Mercedes_Benz_Greener_Manufacturing/Y_train.npy\n","data/california/\n","data/california/X_num_val.npy\n","data/california/Y_val.npy\n","data/california/X_num_train.npy\n","data/california/info.json\n","data/california/READY\n","data/california/X_num_test.npy\n","data/california/Y_test.npy\n","data/california/Y_train.npy\n","data/classif-cat-medium-2-rl/\n","data/classif-cat-medium-2-rl/X_cat_val.npy\n","data/classif-cat-medium-2-rl/X_num_val.npy\n","data/classif-cat-medium-2-rl/Y_val.npy\n","data/classif-cat-medium-2-rl/X_bin_val.npy\n","data/classif-cat-medium-2-rl/X_num_train.npy\n","data/classif-cat-medium-2-rl/X_cat_test.npy\n","data/classif-cat-medium-2-rl/X_bin_train.npy\n","data/classif-cat-medium-2-rl/X_cat_train.npy\n","data/classif-cat-medium-2-rl/info.json\n","data/classif-cat-medium-2-rl/READY\n","data/classif-cat-medium-2-rl/X_bin_test.npy\n","data/classif-cat-medium-2-rl/X_num_test.npy\n","data/classif-cat-medium-2-rl/Y_test.npy\n","data/classif-cat-medium-2-rl/Y_train.npy\n","data/regression-cat-medium-0-Brazilian_houses/\n","data/regression-cat-medium-0-Brazilian_houses/X_cat_val.npy\n","data/regression-cat-medium-0-Brazilian_houses/X_num_val.npy\n","data/regression-cat-medium-0-Brazilian_houses/Y_val.npy\n","data/regression-cat-medium-0-Brazilian_houses/X_bin_val.npy\n","data/regression-cat-medium-0-Brazilian_houses/X_num_train.npy\n","data/regression-cat-medium-0-Brazilian_houses/X_cat_test.npy\n","data/regression-cat-medium-0-Brazilian_houses/X_bin_train.npy\n","data/regression-cat-medium-0-Brazilian_houses/X_cat_train.npy\n","data/regression-cat-medium-0-Brazilian_houses/info.json\n","data/regression-cat-medium-0-Brazilian_houses/READY\n","data/regression-cat-medium-0-Brazilian_houses/X_bin_test.npy\n","data/regression-cat-medium-0-Brazilian_houses/X_num_test.npy\n","data/regression-cat-medium-0-Brazilian_houses/Y_test.npy\n","data/regression-cat-medium-0-Brazilian_houses/Y_train.npy\n","data/regression-cat-medium-1-analcatdata_supreme/\n","data/regression-cat-medium-1-analcatdata_supreme/X_num_val.npy\n","data/regression-cat-medium-1-analcatdata_supreme/Y_val.npy\n","data/regression-cat-medium-1-analcatdata_supreme/X_bin_val.npy\n","data/regression-cat-medium-1-analcatdata_supreme/X_num_train.npy\n","data/regression-cat-medium-1-analcatdata_supreme/X_bin_train.npy\n","data/regression-cat-medium-1-analcatdata_supreme/info.json\n","data/regression-cat-medium-1-analcatdata_supreme/READY\n","data/regression-cat-medium-1-analcatdata_supreme/X_bin_test.npy\n","data/regression-cat-medium-1-analcatdata_supreme/X_num_test.npy\n","data/regression-cat-medium-1-analcatdata_supreme/Y_test.npy\n","data/regression-cat-medium-1-analcatdata_supreme/Y_train.npy\n","data/classif-num-medium-2-MagicTelescope/\n","data/classif-num-medium-2-MagicTelescope/X_num_val.npy\n","data/classif-num-medium-2-MagicTelescope/Y_val.npy\n","data/classif-num-medium-2-MagicTelescope/X_num_train.npy\n","data/classif-num-medium-2-MagicTelescope/info.json\n","data/classif-num-medium-2-MagicTelescope/READY\n","data/classif-num-medium-2-MagicTelescope/X_num_test.npy\n","data/classif-num-medium-2-MagicTelescope/Y_test.npy\n","data/classif-num-medium-2-MagicTelescope/Y_train.npy\n","data/classif-cat-medium-1-rl/\n","data/classif-cat-medium-1-rl/X_cat_val.npy\n","data/classif-cat-medium-1-rl/X_num_val.npy\n","data/classif-cat-medium-1-rl/Y_val.npy\n","data/classif-cat-medium-1-rl/X_bin_val.npy\n","data/classif-cat-medium-1-rl/X_num_train.npy\n","data/classif-cat-medium-1-rl/X_cat_test.npy\n","data/classif-cat-medium-1-rl/X_bin_train.npy\n","data/classif-cat-medium-1-rl/X_cat_train.npy\n","data/classif-cat-medium-1-rl/info.json\n","data/classif-cat-medium-1-rl/READY\n","data/classif-cat-medium-1-rl/X_bin_test.npy\n","data/classif-cat-medium-1-rl/X_num_test.npy\n","data/classif-cat-medium-1-rl/Y_test.npy\n","data/classif-cat-medium-1-rl/Y_train.npy\n","data/classif-cat-medium-0-compass/\n","data/classif-cat-medium-0-compass/X_cat_val.npy\n","data/classif-cat-medium-0-compass/X_num_val.npy\n","data/classif-cat-medium-0-compass/Y_val.npy\n","data/classif-cat-medium-0-compass/X_bin_val.npy\n","data/classif-cat-medium-0-compass/X_num_train.npy\n","data/classif-cat-medium-0-compass/X_cat_test.npy\n","data/classif-cat-medium-0-compass/X_bin_train.npy\n","data/classif-cat-medium-0-compass/X_cat_train.npy\n","data/classif-cat-medium-0-compass/info.json\n","data/classif-cat-medium-0-compass/READY\n","data/classif-cat-medium-0-compass/X_bin_test.npy\n","data/classif-cat-medium-0-compass/X_num_test.npy\n","data/classif-cat-medium-0-compass/Y_test.npy\n","data/classif-cat-medium-0-compass/Y_train.npy\n","data/regression-cat-medium-2-yprop_4_1/\n","data/regression-cat-medium-2-yprop_4_1/X_num_val.npy\n","data/regression-cat-medium-2-yprop_4_1/Y_val.npy\n","data/regression-cat-medium-2-yprop_4_1/X_bin_val.npy\n","data/regression-cat-medium-2-yprop_4_1/X_num_train.npy\n","data/regression-cat-medium-2-yprop_4_1/X_bin_train.npy\n","data/regression-cat-medium-2-yprop_4_1/info.json\n","data/regression-cat-medium-2-yprop_4_1/READY\n","data/regression-cat-medium-2-yprop_4_1/X_bin_test.npy\n","data/regression-cat-medium-2-yprop_4_1/X_num_test.npy\n","data/regression-cat-medium-2-yprop_4_1/Y_test.npy\n","data/regression-cat-medium-2-yprop_4_1/Y_train.npy\n","data/weather-small/\n","data/weather-small/X_num_val.npy\n","data/weather-small/Y_val.npy\n","data/weather-small/X_bin_val.npy\n","data/weather-small/X_num_train.npy\n","data/weather-small/X_bin_train.npy\n","data/weather-small/info.json\n","data/weather-small/READY\n","data/weather-small/X_bin_test.npy\n","data/weather-small/X_num_test.npy\n","data/weather-small/Y_test.npy\n","data/weather-small/Y_train.npy\n","data/diamond/\n","data/diamond/X_cat_val.npy\n","data/diamond/X_num_val.npy\n","data/diamond/Y_val.npy\n","data/diamond/X_num_train.npy\n","data/diamond/X_cat_test.npy\n","data/diamond/X_cat_train.npy\n","data/diamond/info.json\n","data/diamond/X_num_test.npy\n","data/diamond/Y_test.npy\n","data/diamond/Y_train.npy\n","data/regression-num-medium-0-fifa/\n","data/regression-num-medium-0-fifa/X_num_val.npy\n","data/regression-num-medium-0-fifa/Y_val.npy\n","data/regression-num-medium-0-fifa/X_num_train.npy\n","data/regression-num-medium-0-fifa/info.json\n","data/regression-num-medium-0-fifa/READY\n","data/regression-num-medium-0-fifa/X_num_test.npy\n","data/regression-num-medium-0-fifa/Y_test.npy\n","data/regression-num-medium-0-fifa/Y_train.npy\n","data/regression-num-medium-1-cpu_act/\n","data/regression-num-medium-1-cpu_act/X_num_val.npy\n","data/regression-num-medium-1-cpu_act/Y_val.npy\n","data/regression-num-medium-1-cpu_act/X_num_train.npy\n","data/regression-num-medium-1-cpu_act/info.json\n","data/regression-num-medium-1-cpu_act/READY\n","data/regression-num-medium-1-cpu_act/X_num_test.npy\n","data/regression-num-medium-1-cpu_act/Y_test.npy\n","data/regression-num-medium-1-cpu_act/Y_train.npy\n","data/regression-num-medium-1-pol/\n","data/regression-num-medium-1-pol/X_num_val.npy\n","data/regression-num-medium-1-pol/Y_val.npy\n","data/regression-num-medium-1-pol/X_num_train.npy\n","data/regression-num-medium-1-pol/info.json\n","data/regression-num-medium-1-pol/READY\n","data/regression-num-medium-1-pol/X_num_test.npy\n","data/regression-num-medium-1-pol/Y_test.npy\n","data/regression-num-medium-1-pol/Y_train.npy\n","data/regression-num-medium-0-elevators/\n","data/regression-num-medium-0-elevators/X_num_val.npy\n","data/regression-num-medium-0-elevators/Y_val.npy\n","data/regression-num-medium-0-elevators/X_num_train.npy\n","data/regression-num-medium-0-elevators/info.json\n","data/regression-num-medium-0-elevators/READY\n","data/regression-num-medium-0-elevators/X_num_test.npy\n","data/regression-num-medium-0-elevators/Y_test.npy\n","data/regression-num-medium-0-elevators/Y_train.npy\n","data/regression-cat-medium-4-Mercedes_Benz_Greener_Manufacturing/\n","data/regression-cat-medium-4-Mercedes_Benz_Greener_Manufacturing/X_cat_val.npy\n","data/regression-cat-medium-4-Mercedes_Benz_Greener_Manufacturing/Y_val.npy\n","data/regression-cat-medium-4-Mercedes_Benz_Greener_Manufacturing/X_bin_val.npy\n","data/regression-cat-medium-4-Mercedes_Benz_Greener_Manufacturing/X_cat_test.npy\n","data/regression-cat-medium-4-Mercedes_Benz_Greener_Manufacturing/X_bin_train.npy\n","data/regression-cat-medium-4-Mercedes_Benz_Greener_Manufacturing/X_cat_train.npy\n","data/regression-cat-medium-4-Mercedes_Benz_Greener_Manufacturing/info.json\n","data/regression-cat-medium-4-Mercedes_Benz_Greener_Manufacturing/READY\n","data/regression-cat-medium-4-Mercedes_Benz_Greener_Manufacturing/X_bin_test.npy\n","data/regression-cat-medium-4-Mercedes_Benz_Greener_Manufacturing/Y_test.npy\n","data/regression-cat-medium-4-Mercedes_Benz_Greener_Manufacturing/Y_train.npy\n","data/regression-num-medium-2-MiamiHousing2016/\n","data/regression-num-medium-2-MiamiHousing2016/X_num_val.npy\n","data/regression-num-medium-2-MiamiHousing2016/Y_val.npy\n","data/regression-num-medium-2-MiamiHousing2016/X_num_train.npy\n","data/regression-num-medium-2-MiamiHousing2016/info.json\n","data/regression-num-medium-2-MiamiHousing2016/READY\n","data/regression-num-medium-2-MiamiHousing2016/X_num_test.npy\n","data/regression-num-medium-2-MiamiHousing2016/Y_test.npy\n","data/regression-num-medium-2-MiamiHousing2016/Y_train.npy\n","data/regression-num-medium-1-Ailerons/\n","data/regression-num-medium-1-Ailerons/X_num_val.npy\n","data/regression-num-medium-1-Ailerons/Y_val.npy\n","data/regression-num-medium-1-Ailerons/X_num_train.npy\n","data/regression-num-medium-1-Ailerons/info.json\n","data/regression-num-medium-1-Ailerons/READY\n","data/regression-num-medium-1-Ailerons/X_num_test.npy\n","data/regression-num-medium-1-Ailerons/Y_test.npy\n","data/regression-num-medium-1-Ailerons/Y_train.npy\n","data/regression-num-medium-0-medical_charges/\n","data/regression-num-medium-0-medical_charges/X_num_val.npy\n","data/regression-num-medium-0-medical_charges/Y_val.npy\n","data/regression-num-medium-0-medical_charges/X_num_train.npy\n","data/regression-num-medium-0-medical_charges/info.json\n","data/regression-num-medium-0-medical_charges/READY\n","data/regression-num-medium-0-medical_charges/X_num_test.npy\n","data/regression-num-medium-0-medical_charges/Y_test.npy\n","data/regression-num-medium-0-medical_charges/Y_train.npy\n","data/classif-num-medium-0-bank-marketing/\n","data/classif-num-medium-0-bank-marketing/X_num_val.npy\n","data/classif-num-medium-0-bank-marketing/Y_val.npy\n","data/classif-num-medium-0-bank-marketing/X_num_train.npy\n","data/classif-num-medium-0-bank-marketing/info.json\n","data/classif-num-medium-0-bank-marketing/READY\n","data/classif-num-medium-0-bank-marketing/X_num_test.npy\n","data/classif-num-medium-0-bank-marketing/Y_test.npy\n","data/classif-num-medium-0-bank-marketing/Y_train.npy\n","data/classif-num-medium-3-wine/\n","data/classif-num-medium-3-wine/X_num_val.npy\n","data/classif-num-medium-3-wine/Y_val.npy\n","data/classif-num-medium-3-wine/X_num_train.npy\n","data/classif-num-medium-3-wine/info.json\n","data/classif-num-medium-3-wine/READY\n","data/classif-num-medium-3-wine/X_num_test.npy\n","data/classif-num-medium-3-wine/Y_test.npy\n","data/classif-num-medium-3-wine/Y_train.npy\n","data/classif-num-medium-2-bank-marketing/\n","data/classif-num-medium-2-bank-marketing/X_num_val.npy\n","data/classif-num-medium-2-bank-marketing/Y_val.npy\n","data/classif-num-medium-2-bank-marketing/X_num_train.npy\n","data/classif-num-medium-2-bank-marketing/info.json\n","data/classif-num-medium-2-bank-marketing/READY\n","data/classif-num-medium-2-bank-marketing/X_num_test.npy\n","data/classif-num-medium-2-bank-marketing/Y_test.npy\n","data/classif-num-medium-2-bank-marketing/Y_train.npy\n","data/classif-num-large-0-jannis/\n","data/classif-num-large-0-jannis/X_num_val.npy\n","data/classif-num-large-0-jannis/Y_val.npy\n","data/classif-num-large-0-jannis/X_num_train.npy\n","data/classif-num-large-0-jannis/info.json\n","data/classif-num-large-0-jannis/READY\n","data/classif-num-large-0-jannis/X_num_test.npy\n","data/classif-num-large-0-jannis/Y_test.npy\n","data/classif-num-large-0-jannis/Y_train.npy\n","data/regression-num-medium-0-houses/\n","data/regression-num-medium-0-houses/X_num_val.npy\n","data/regression-num-medium-0-houses/Y_val.npy\n","data/regression-num-medium-0-houses/X_num_train.npy\n","data/regression-num-medium-0-houses/info.json\n","data/regression-num-medium-0-houses/READY\n","data/regression-num-medium-0-houses/X_num_test.npy\n","data/regression-num-medium-0-houses/Y_test.npy\n","data/regression-num-medium-0-houses/Y_train.npy\n","data/regression-num-large-0-year/\n","data/regression-num-large-0-year/X_num_val.npy\n","data/regression-num-large-0-year/Y_val.npy\n","data/regression-num-large-0-year/X_num_train.npy\n","data/regression-num-large-0-year/info.json\n","data/regression-num-large-0-year/READY\n","data/regression-num-large-0-year/X_num_test.npy\n","data/regression-num-large-0-year/Y_test.npy\n","data/regression-num-large-0-year/Y_train.npy\n","data/classif-cat-medium-1-KDDCup09_upselling/\n","data/classif-cat-medium-1-KDDCup09_upselling/X_cat_val.npy\n","data/classif-cat-medium-1-KDDCup09_upselling/X_num_val.npy\n","data/classif-cat-medium-1-KDDCup09_upselling/Y_val.npy\n","data/classif-cat-medium-1-KDDCup09_upselling/X_bin_val.npy\n","data/classif-cat-medium-1-KDDCup09_upselling/X_num_train.npy\n","data/classif-cat-medium-1-KDDCup09_upselling/X_cat_test.npy\n","data/classif-cat-medium-1-KDDCup09_upselling/X_bin_train.npy\n","data/classif-cat-medium-1-KDDCup09_upselling/X_cat_train.npy\n","data/classif-cat-medium-1-KDDCup09_upselling/info.json\n","data/classif-cat-medium-1-KDDCup09_upselling/READY\n","data/classif-cat-medium-1-KDDCup09_upselling/X_bin_test.npy\n","data/classif-cat-medium-1-KDDCup09_upselling/X_num_test.npy\n","data/classif-cat-medium-1-KDDCup09_upselling/Y_test.npy\n","data/classif-cat-medium-1-KDDCup09_upselling/Y_train.npy\n","data/classif-cat-medium-0-KDDCup09_upselling/\n","data/classif-cat-medium-0-KDDCup09_upselling/X_cat_val.npy\n","data/classif-cat-medium-0-KDDCup09_upselling/X_num_val.npy\n","data/classif-cat-medium-0-KDDCup09_upselling/Y_val.npy\n","data/classif-cat-medium-0-KDDCup09_upselling/X_bin_val.npy\n","data/classif-cat-medium-0-KDDCup09_upselling/X_num_train.npy\n","data/classif-cat-medium-0-KDDCup09_upselling/X_cat_test.npy\n","data/classif-cat-medium-0-KDDCup09_upselling/X_bin_train.npy\n","data/classif-cat-medium-0-KDDCup09_upselling/X_cat_train.npy\n","data/classif-cat-medium-0-KDDCup09_upselling/info.json\n","data/classif-cat-medium-0-KDDCup09_upselling/READY\n","data/classif-cat-medium-0-KDDCup09_upselling/X_bin_test.npy\n","data/classif-cat-medium-0-KDDCup09_upselling/X_num_test.npy\n","data/classif-cat-medium-0-KDDCup09_upselling/Y_test.npy\n","data/classif-cat-medium-0-KDDCup09_upselling/Y_train.npy\n","data/classif-num-large-0-MiniBooNE/\n","data/classif-num-large-0-MiniBooNE/X_num_val.npy\n","data/classif-num-large-0-MiniBooNE/Y_val.npy\n","data/classif-num-large-0-MiniBooNE/X_num_train.npy\n","data/classif-num-large-0-MiniBooNE/info.json\n","data/classif-num-large-0-MiniBooNE/READY\n","data/classif-num-large-0-MiniBooNE/X_num_test.npy\n","data/classif-num-large-0-MiniBooNE/Y_test.npy\n","data/classif-num-large-0-MiniBooNE/Y_train.npy\n","data/regression-num-medium-0-MiamiHousing2016/\n","data/regression-num-medium-0-MiamiHousing2016/X_num_val.npy\n","data/regression-num-medium-0-MiamiHousing2016/Y_val.npy\n","data/regression-num-medium-0-MiamiHousing2016/X_num_train.npy\n","data/regression-num-medium-0-MiamiHousing2016/info.json\n","data/regression-num-medium-0-MiamiHousing2016/READY\n","data/regression-num-medium-0-MiamiHousing2016/X_num_test.npy\n","data/regression-num-medium-0-MiamiHousing2016/Y_test.npy\n","data/regression-num-medium-0-MiamiHousing2016/Y_train.npy\n","data/regression-num-medium-2-Ailerons/\n","data/regression-num-medium-2-Ailerons/X_num_val.npy\n","data/regression-num-medium-2-Ailerons/Y_val.npy\n","data/regression-num-medium-2-Ailerons/X_num_train.npy\n","data/regression-num-medium-2-Ailerons/info.json\n","data/regression-num-medium-2-Ailerons/READY\n","data/regression-num-medium-2-Ailerons/X_num_test.npy\n","data/regression-num-medium-2-Ailerons/Y_test.npy\n","data/regression-num-medium-2-Ailerons/Y_train.npy\n","data/classif-num-medium-0-credit/\n","data/classif-num-medium-0-credit/X_num_val.npy\n","data/classif-num-medium-0-credit/Y_val.npy\n","data/classif-num-medium-0-credit/X_num_train.npy\n","data/classif-num-medium-0-credit/info.json\n","data/classif-num-medium-0-credit/READY\n","data/classif-num-medium-0-credit/X_num_test.npy\n","data/classif-num-medium-0-credit/Y_test.npy\n","data/classif-num-medium-0-credit/Y_train.npy\n","data/classif-num-medium-4-wine/\n","data/classif-num-medium-4-wine/X_num_val.npy\n","data/classif-num-medium-4-wine/Y_val.npy\n","data/classif-num-medium-4-wine/X_num_train.npy\n","data/classif-num-medium-4-wine/info.json\n","data/classif-num-medium-4-wine/READY\n","data/classif-num-medium-4-wine/X_num_test.npy\n","data/classif-num-medium-4-wine/Y_test.npy\n","data/classif-num-medium-4-wine/Y_train.npy\n","data/higgs-small/\n","data/higgs-small/X_num_val.npy\n","data/higgs-small/Y_val.npy\n","data/higgs-small/X_num_train.npy\n","data/higgs-small/info.json\n","data/higgs-small/READY\n","data/higgs-small/X_num_test.npy\n","data/higgs-small/Y_test.npy\n","data/higgs-small/Y_train.npy\n","data/classif-cat-medium-1-compass/\n","data/classif-cat-medium-1-compass/X_cat_val.npy\n","data/classif-cat-medium-1-compass/X_num_val.npy\n","data/classif-cat-medium-1-compass/Y_val.npy\n","data/classif-cat-medium-1-compass/X_bin_val.npy\n","data/classif-cat-medium-1-compass/X_num_train.npy\n","data/classif-cat-medium-1-compass/X_cat_test.npy\n","data/classif-cat-medium-1-compass/X_bin_train.npy\n","data/classif-cat-medium-1-compass/X_cat_train.npy\n","data/classif-cat-medium-1-compass/info.json\n","data/classif-cat-medium-1-compass/READY\n","data/classif-cat-medium-1-compass/X_bin_test.npy\n","data/classif-cat-medium-1-compass/X_num_test.npy\n","data/classif-cat-medium-1-compass/Y_test.npy\n","data/classif-cat-medium-1-compass/Y_train.npy\n","data/classif-cat-medium-0-rl/\n","data/classif-cat-medium-0-rl/X_cat_val.npy\n","data/classif-cat-medium-0-rl/X_num_val.npy\n","data/classif-cat-medium-0-rl/Y_val.npy\n","data/classif-cat-medium-0-rl/X_bin_val.npy\n","data/classif-cat-medium-0-rl/X_num_train.npy\n","data/classif-cat-medium-0-rl/X_cat_test.npy\n","data/classif-cat-medium-0-rl/X_bin_train.npy\n","data/classif-cat-medium-0-rl/X_cat_train.npy\n","data/classif-cat-medium-0-rl/info.json\n","data/classif-cat-medium-0-rl/READY\n","data/classif-cat-medium-0-rl/X_bin_test.npy\n","data/classif-cat-medium-0-rl/X_num_test.npy\n","data/classif-cat-medium-0-rl/Y_test.npy\n","data/classif-cat-medium-0-rl/Y_train.npy\n","data/regression-num-medium-2-cpu_act/\n","data/regression-num-medium-2-cpu_act/X_num_val.npy\n","data/regression-num-medium-2-cpu_act/Y_val.npy\n","data/regression-num-medium-2-cpu_act/X_num_train.npy\n","data/regression-num-medium-2-cpu_act/info.json\n","data/regression-num-medium-2-cpu_act/READY\n","data/regression-num-medium-2-cpu_act/X_num_test.npy\n","data/regression-num-medium-2-cpu_act/Y_test.npy\n","data/regression-num-medium-2-cpu_act/Y_train.npy\n","data/otto/\n","data/otto/X_num_val.npy\n","data/otto/Y_val.npy\n","data/otto/X_num_train.npy\n","data/otto/info.json\n","data/otto/READY\n","data/otto/X_num_test.npy\n","data/otto/Y_test.npy\n","data/otto/Y_train.npy\n","data/regression-cat-medium-0-yprop_4_1/\n","data/regression-cat-medium-0-yprop_4_1/X_num_val.npy\n","data/regression-cat-medium-0-yprop_4_1/Y_val.npy\n","data/regression-cat-medium-0-yprop_4_1/X_bin_val.npy\n","data/regression-cat-medium-0-yprop_4_1/X_num_train.npy\n","data/regression-cat-medium-0-yprop_4_1/X_bin_train.npy\n","data/regression-cat-medium-0-yprop_4_1/info.json\n","data/regression-cat-medium-0-yprop_4_1/READY\n","data/regression-cat-medium-0-yprop_4_1/X_bin_test.npy\n","data/regression-cat-medium-0-yprop_4_1/X_num_test.npy\n","data/regression-cat-medium-0-yprop_4_1/Y_test.npy\n","data/regression-cat-medium-0-yprop_4_1/Y_train.npy\n","data/classif-cat-large-0-covertype/\n","data/classif-cat-large-0-covertype/X_num_val.npy\n","data/classif-cat-large-0-covertype/Y_val.npy\n","data/classif-cat-large-0-covertype/X_bin_val.npy\n","data/classif-cat-large-0-covertype/X_num_train.npy\n","data/classif-cat-large-0-covertype/X_bin_train.npy\n","data/classif-cat-large-0-covertype/info.json\n","data/classif-cat-large-0-covertype/READY\n","data/classif-cat-large-0-covertype/X_bin_test.npy\n","data/classif-cat-large-0-covertype/X_num_test.npy\n","data/classif-cat-large-0-covertype/Y_test.npy\n","data/classif-cat-large-0-covertype/Y_train.npy\n","data/regression-cat-medium-1-Bike_Sharing_Demand/\n","data/regression-cat-medium-1-Bike_Sharing_Demand/X_cat_val.npy\n","data/regression-cat-medium-1-Bike_Sharing_Demand/X_num_val.npy\n","data/regression-cat-medium-1-Bike_Sharing_Demand/Y_val.npy\n","data/regression-cat-medium-1-Bike_Sharing_Demand/X_bin_val.npy\n","data/regression-cat-medium-1-Bike_Sharing_Demand/X_num_train.npy\n","data/regression-cat-medium-1-Bike_Sharing_Demand/X_cat_test.npy\n","data/regression-cat-medium-1-Bike_Sharing_Demand/X_bin_train.npy\n","data/regression-cat-medium-1-Bike_Sharing_Demand/X_cat_train.npy\n","data/regression-cat-medium-1-Bike_Sharing_Demand/info.json\n","data/regression-cat-medium-1-Bike_Sharing_Demand/READY\n","data/regression-cat-medium-1-Bike_Sharing_Demand/X_bin_test.npy\n","data/regression-cat-medium-1-Bike_Sharing_Demand/X_num_test.npy\n","data/regression-cat-medium-1-Bike_Sharing_Demand/Y_test.npy\n","data/regression-cat-medium-1-Bike_Sharing_Demand/Y_train.npy\n","data/classif-cat-medium-0-electricity/\n","data/classif-cat-medium-0-electricity/X_cat_val.npy\n","data/classif-cat-medium-0-electricity/X_num_val.npy\n","data/classif-cat-medium-0-electricity/Y_val.npy\n","data/classif-cat-medium-0-electricity/X_num_train.npy\n","data/classif-cat-medium-0-electricity/X_cat_test.npy\n","data/classif-cat-medium-0-electricity/X_cat_train.npy\n","data/classif-cat-medium-0-electricity/info.json\n","data/classif-cat-medium-0-electricity/READY\n","data/classif-cat-medium-0-electricity/X_num_test.npy\n","data/classif-cat-medium-0-electricity/Y_test.npy\n","data/classif-cat-medium-0-electricity/Y_train.npy\n","data/regression-cat-medium-2-visualizing_soil/\n","data/regression-cat-medium-2-visualizing_soil/X_num_val.npy\n","data/regression-cat-medium-2-visualizing_soil/Y_val.npy\n","data/regression-cat-medium-2-visualizing_soil/X_bin_val.npy\n","data/regression-cat-medium-2-visualizing_soil/X_num_train.npy\n","data/regression-cat-medium-2-visualizing_soil/X_bin_train.npy\n","data/regression-cat-medium-2-visualizing_soil/info.json\n","data/regression-cat-medium-2-visualizing_soil/READY\n","data/regression-cat-medium-2-visualizing_soil/X_bin_test.npy\n","data/regression-cat-medium-2-visualizing_soil/X_num_test.npy\n","data/regression-cat-medium-2-visualizing_soil/Y_test.npy\n","data/regression-cat-medium-2-visualizing_soil/Y_train.npy\n","data/regression-cat-medium-1-yprop_4_1/\n","data/regression-cat-medium-1-yprop_4_1/X_num_val.npy\n","data/regression-cat-medium-1-yprop_4_1/Y_val.npy\n","data/regression-cat-medium-1-yprop_4_1/X_bin_val.npy\n","data/regression-cat-medium-1-yprop_4_1/X_num_train.npy\n","data/regression-cat-medium-1-yprop_4_1/X_bin_train.npy\n","data/regression-cat-medium-1-yprop_4_1/info.json\n","data/regression-cat-medium-1-yprop_4_1/READY\n","data/regression-cat-medium-1-yprop_4_1/X_bin_test.npy\n","data/regression-cat-medium-1-yprop_4_1/X_num_test.npy\n","data/regression-cat-medium-1-yprop_4_1/Y_test.npy\n","data/regression-cat-medium-1-yprop_4_1/Y_train.npy\n","data/classif-num-medium-1-bank-marketing/\n","data/classif-num-medium-1-bank-marketing/X_num_val.npy\n","data/classif-num-medium-1-bank-marketing/Y_val.npy\n","data/classif-num-medium-1-bank-marketing/X_num_train.npy\n","data/classif-num-medium-1-bank-marketing/info.json\n","data/classif-num-medium-1-bank-marketing/READY\n","data/classif-num-medium-1-bank-marketing/X_num_test.npy\n","data/classif-num-medium-1-bank-marketing/Y_test.npy\n","data/classif-num-medium-1-bank-marketing/Y_train.npy\n","data/classif-num-medium-1-credit/\n","data/classif-num-medium-1-credit/X_num_val.npy\n","data/classif-num-medium-1-credit/Y_val.npy\n","data/classif-num-medium-1-credit/X_num_train.npy\n","data/classif-num-medium-1-credit/info.json\n","data/classif-num-medium-1-credit/READY\n","data/classif-num-medium-1-credit/X_num_test.npy\n","data/classif-num-medium-1-credit/Y_test.npy\n","data/classif-num-medium-1-credit/Y_train.npy\n"]}]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-glTe-NrxA3S","executionInfo":{"status":"ok","timestamp":1729001026986,"user_tz":-480,"elapsed":4647,"user":{"displayName":"Jonindo Pasaribu","userId":"10958990953097471082"}},"outputId":"2f97c9cd-596e-4a16-9f8e-d8c766e983f1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pytorch-tabnet\n","  Downloading pytorch_tabnet-4.1.0-py3-none-any.whl.metadata (15 kB)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from pytorch-tabnet) (1.26.4)\n","Requirement already satisfied: scikit_learn>0.21 in /usr/local/lib/python3.10/dist-packages (from pytorch-tabnet) (1.5.2)\n","Requirement already satisfied: scipy>1.4 in /usr/local/lib/python3.10/dist-packages (from pytorch-tabnet) (1.13.1)\n","Requirement already satisfied: torch>=1.3 in /usr/local/lib/python3.10/dist-packages (from pytorch-tabnet) (2.4.1+cu121)\n","Requirement already satisfied: tqdm>=4.36 in /usr/local/lib/python3.10/dist-packages (from pytorch-tabnet) (4.66.5)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit_learn>0.21->pytorch-tabnet) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit_learn>0.21->pytorch-tabnet) (3.5.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (3.16.1)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (1.13.3)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (2024.6.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.3->pytorch-tabnet) (2.1.5)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.3->pytorch-tabnet) (1.3.0)\n","Downloading pytorch_tabnet-4.1.0-py3-none-any.whl (44 kB)\n","\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/44.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.5/44.5 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: pytorch-tabnet\n","Successfully installed pytorch-tabnet-4.1.0\n"]}],"source":["!pip install pytorch-tabnet"]},{"cell_type":"code","source":["!pip install optuna"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T3kebgsowkp0","executionInfo":{"status":"ok","timestamp":1729001030257,"user_tz":-480,"elapsed":3275,"user":{"displayName":"Jonindo Pasaribu","userId":"10958990953097471082"}},"outputId":"8ee4cd98-1d9c-4e33-d993-7e742cded5ff"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting optuna\n","  Downloading optuna-4.0.0-py3-none-any.whl.metadata (16 kB)\n","Collecting alembic>=1.5.0 (from optuna)\n","  Downloading alembic-1.13.3-py3-none-any.whl.metadata (7.4 kB)\n","Collecting colorlog (from optuna)\n","  Downloading colorlog-6.8.2-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (24.1)\n","Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.35)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.66.5)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0.2)\n","Collecting Mako (from alembic>=1.5.0->optuna)\n","  Downloading Mako-1.3.5-py3-none-any.whl.metadata (2.9 kB)\n","Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.12.2)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna) (3.1.0)\n","Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.1.5)\n","Downloading optuna-4.0.0-py3-none-any.whl (362 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m362.8/362.8 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading alembic-1.13.3-py3-none-any.whl (233 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.2/233.2 kB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading colorlog-6.8.2-py3-none-any.whl (11 kB)\n","Downloading Mako-1.3.5-py3-none-any.whl (78 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: Mako, colorlog, alembic, optuna\n","Successfully installed Mako-1.3.5 alembic-1.13.3 colorlog-6.8.2 optuna-4.0.0\n"]}]},{"cell_type":"code","source":["!pip install psutil"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1AlZ_9btlf9J","executionInfo":{"status":"ok","timestamp":1729001032440,"user_tz":-480,"elapsed":2190,"user":{"displayName":"Jonindo Pasaribu","userId":"10958990953097471082"}},"outputId":"85d42875-a927-4cc5-f1b4-871aa2a75dba"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (5.9.5)\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import optuna\n","import torch.optim\n","import psutil\n","\n","from pytorch_tabnet.tab_model import TabNetRegressor\n","from sklearn.preprocessing import QuantileTransformer"],"metadata":{"id":"085aiY1dzlHG","executionInfo":{"status":"ok","timestamp":1729001037314,"user_tz":-480,"elapsed":4881,"user":{"displayName":"Jonindo Pasaribu","userId":"10958990953097471082"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["tnr = TabNetRegressor()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pr7k2hel51eb","executionInfo":{"status":"ok","timestamp":1729001037314,"user_tz":-480,"elapsed":5,"user":{"displayName":"Jonindo Pasaribu","userId":"10958990953097471082"}},"outputId":"9f3f2f02-eb24-4956-95a5-7d06a31d6ce2"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]}]},{"cell_type":"code","source":["X_train = np.load('/content/data/regression-num-medium-0-superconduct/X_num_train.npy')\n","y_train = np.load('/content/data/regression-num-medium-0-superconduct/Y_train.npy').reshape(-1, 1)\n","\n","X_valid = np.load('/content/data/regression-num-medium-0-superconduct/X_num_val.npy')\n","y_valid = np.load('/content/data/regression-num-medium-0-superconduct/Y_val.npy').reshape(-1, 1)\n","\n","X_test = np.load('/content/data/regression-num-medium-0-superconduct/X_num_test.npy')\n","y_test = np.load('/content/data/regression-num-medium-0-superconduct/Y_test.npy').reshape(-1, 1)"],"metadata":{"id":"ml0RPc_76dZx","executionInfo":{"status":"ok","timestamp":1729001037314,"user_tz":-480,"elapsed":3,"user":{"displayName":"Jonindo Pasaribu","userId":"10958990953097471082"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["normalizer = QuantileTransformer(\n","            output_distribution='normal',\n","            n_quantiles=max(min(X_train.shape[0] // 30, 1000), 10),\n","            subsample=1_000_000_000,\n","            )\n","normalizer.fit_transform(X_train)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"19PUhYavmHsh","executionInfo":{"status":"ok","timestamp":1729001037314,"user_tz":-480,"elapsed":3,"user":{"displayName":"Jonindo Pasaribu","userId":"10958990953097471082"}},"outputId":"7d01d5de-e464-4483-a01c-688911ed8a15"},"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[-0.34656826, -0.38103637, -0.525267  , ...,  0.079359  ,\n","        -0.8298449 , -0.30274472],\n","       [-0.41147688, -0.7503491 , -0.45711228, ..., -1.0138142 ,\n","        -0.8298449 , -1.1835144 ],\n","       [ 0.17070231, -0.5639779 ,  0.31863937, ..., -0.5226079 ,\n","         0.        , -0.30307585],\n","       ...,\n","       [ 0.41134915, -0.9937043 ,  0.5597231 , ..., -0.3287044 ,\n","         1.1430639 ,  0.6274264 ],\n","       [ 2.1042554 ,  1.6814585 ,  2.115818  , ...,  1.9873234 ,\n","        -5.1993375 , -5.1993375 ],\n","       [-2.0376847 , -1.8410197 , -1.9418334 , ...,  0.4866506 ,\n","         1.3572593 ,  1.7786256 ]], dtype=float32)"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["#Baseline\n","tnr.fit(\n","    X_train=X_train, y_train=y_train,\n","    eval_set=[(X_train, y_train), (X_valid, y_valid)],\n","    eval_name=['train', 'valid'],\n","    eval_metric=['mae', 'rmse'],\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dmadZ12j7CO_","executionInfo":{"status":"ok","timestamp":1729001050908,"user_tz":-480,"elapsed":13596,"user":{"displayName":"Jonindo Pasaribu","userId":"10958990953097471082"}},"outputId":"6ffdaae0-e060-4e1d-8009-51c913cdcb0d"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 2276.83499| train_mae: 25.3787899017334| train_rmse: 36.09175109863281| valid_mae: 25.528860092163086| valid_rmse: 36.10728073120117|  0:00:02s\n","epoch 1  | loss: 1884.15051| train_mae: 35.32780075073242| train_rmse: 47.541439056396484| valid_mae: 35.25843811035156| valid_rmse: 47.465938568115234|  0:00:03s\n","epoch 2  | loss: 1340.63341| train_mae: 23.184179306030273| train_rmse: 34.705108642578125| valid_mae: 23.43716049194336| valid_rmse: 34.443660736083984|  0:00:04s\n","epoch 3  | loss: 784.43372| train_mae: 34.521610260009766| train_rmse: 64.39351654052734| valid_mae: 35.17496109008789| valid_rmse: 65.18331909179688|  0:00:05s\n","epoch 4  | loss: 405.41551| train_mae: 37.86082077026367| train_rmse: 55.63283920288086| valid_mae: 39.23923873901367| valid_rmse: 57.47438049316406|  0:00:05s\n","epoch 5  | loss: 295.96734| train_mae: 64.38655853271484| train_rmse: 86.10163116455078| valid_mae: 64.98332977294922| valid_rmse: 86.55345916748047|  0:00:06s\n","epoch 6  | loss: 284.73232| train_mae: 75.9421615600586| train_rmse: 102.15532684326172| valid_mae: 78.03231811523438| valid_rmse: 104.1515884399414|  0:00:07s\n","epoch 7  | loss: 251.98506| train_mae: 61.9427604675293| train_rmse: 84.94515991210938| valid_mae: 63.69773864746094| valid_rmse: 86.69991302490234|  0:00:08s\n","epoch 8  | loss: 252.92752| train_mae: 65.67018127441406| train_rmse: 90.32525634765625| valid_mae: 67.9503402709961| valid_rmse: 92.5238265991211|  0:00:08s\n","epoch 9  | loss: 248.79252| train_mae: 77.09639739990234| train_rmse: 105.30386352539062| valid_mae: 79.33441925048828| valid_rmse: 107.0101089477539|  0:00:09s\n","epoch 10 | loss: 244.90812| train_mae: 68.22528839111328| train_rmse: 92.75151062011719| valid_mae: 70.25569152832031| valid_rmse: 94.38346099853516|  0:00:10s\n","epoch 11 | loss: 246.738 | train_mae: 66.52580261230469| train_rmse: 90.54769134521484| valid_mae: 68.37300109863281| valid_rmse: 92.16043090820312|  0:00:10s\n","epoch 12 | loss: 245.29294| train_mae: 58.65753173828125| train_rmse: 81.10173034667969| valid_mae: 60.26190185546875| valid_rmse: 82.2197036743164|  0:00:11s\n","\n","Early stopping occurred at epoch 12 with best_epoch = 2 and best_valid_rmse = 34.443660736083984\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n"]}]},{"cell_type":"code","source":["def objective(trial):\n","    params = {\n","        'n_d': trial.suggest_int('n_d', 8, 64),\n","        'n_steps': trial.suggest_int('n_steps', 3, 10),\n","        'gamma': trial.suggest_float('gamma', 1.0, 2.0),\n","        'n_independent': trial.suggest_int('n_independent', 1, 5),\n","        'n_shared': trial.suggest_int('n_shared', 1, 5),\n","        'momentum': trial.suggest_float('momentum', 0.01, 0.4),\n","    }\n","\n","    model = TabNetRegressor(**params, n_a=params['n_d'])\n","    model.fit(X_train, y_train, eval_set=[(X_valid, y_valid)], patience=10)\n","\n","    # Evaluate model performance\n","    score = model.best_cost  # or any other metric\n","\n","    return score\n","\n","study = optuna.create_study(direction='minimize')\n","study.optimize(objective, n_trials=100)\n","\n","best_params = study.best_params"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rKJAw0W-w7sc","executionInfo":{"status":"ok","timestamp":1729006706769,"user_tz":-480,"elapsed":5655870,"user":{"displayName":"Jonindo Pasaribu","userId":"10958990953097471082"}},"outputId":"5d06c76c-adb8-41ff-9533-dc1a8ebf7dd3"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stderr","text":["[I 2024-10-15 14:04:10,382] A new study created in memory with name: no-name-41e80d4f-d928-4328-8447-90069d901cc8\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 1898.05438| val_0_mse: 55153.2890625|  0:00:01s\n","epoch 1  | loss: 1106.23966| val_0_mse: 21754.7578125|  0:00:02s\n","epoch 2  | loss: 728.78733| val_0_mse: 5637.7783203125|  0:00:04s\n","epoch 3  | loss: 569.86243| val_0_mse: 2244.233642578125|  0:00:05s\n","epoch 4  | loss: 533.65029| val_0_mse: 3143.89306640625|  0:00:06s\n","epoch 5  | loss: 545.53985| val_0_mse: 2322.34033203125|  0:00:08s\n","epoch 6  | loss: 495.1388| val_0_mse: 1252.04296875|  0:00:09s\n","epoch 7  | loss: 464.97385| val_0_mse: 1339.28955078125|  0:00:10s\n","epoch 8  | loss: 462.28496| val_0_mse: 1530.982666015625|  0:00:12s\n","epoch 9  | loss: 457.66401| val_0_mse: 1859.3060302734375|  0:00:13s\n","epoch 10 | loss: 440.1539| val_0_mse: 1479.030029296875|  0:00:14s\n","epoch 11 | loss: 437.69959| val_0_mse: 1282.3148193359375|  0:00:16s\n","epoch 12 | loss: 424.30404| val_0_mse: 1072.7437744140625|  0:00:17s\n","epoch 13 | loss: 471.23288| val_0_mse: 993.0364990234375|  0:00:18s\n","epoch 14 | loss: 483.44754| val_0_mse: 934.40576171875|  0:00:20s\n","epoch 15 | loss: 480.44748| val_0_mse: 886.4506225585938|  0:00:21s\n","epoch 16 | loss: 432.41594| val_0_mse: 937.0574951171875|  0:00:22s\n","epoch 17 | loss: 420.16887| val_0_mse: 660.5776977539062|  0:00:24s\n","epoch 18 | loss: 427.93535| val_0_mse: 681.7066650390625|  0:00:25s\n","epoch 19 | loss: 463.11967| val_0_mse: 852.0955200195312|  0:00:27s\n","epoch 20 | loss: 465.44339| val_0_mse: 832.9439697265625|  0:00:28s\n","epoch 21 | loss: 432.74575| val_0_mse: 527.45654296875|  0:00:29s\n","epoch 22 | loss: 432.19525| val_0_mse: 772.1915283203125|  0:00:31s\n","epoch 23 | loss: 430.87857| val_0_mse: 771.767578125|  0:00:32s\n","epoch 24 | loss: 406.83015| val_0_mse: 794.6627197265625|  0:00:33s\n","epoch 25 | loss: 395.76679| val_0_mse: 808.850341796875|  0:00:34s\n","epoch 26 | loss: 389.00842| val_0_mse: 762.4223022460938|  0:00:36s\n","epoch 27 | loss: 373.8811| val_0_mse: 704.8657836914062|  0:00:37s\n","epoch 28 | loss: 391.43523| val_0_mse: 699.5897827148438|  0:00:38s\n","epoch 29 | loss: 359.65155| val_0_mse: 704.0159912109375|  0:00:40s\n","epoch 30 | loss: 339.43337| val_0_mse: 620.1776733398438|  0:00:41s\n","epoch 31 | loss: 339.01149| val_0_mse: 571.1438598632812|  0:00:42s\n","\n","Early stopping occurred at epoch 31 with best_epoch = 21 and best_val_0_mse = 527.45654296875\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 14:04:53,946] Trial 0 finished with value: 527.45654296875 and parameters: {'n_d': 31, 'n_steps': 7, 'gamma': 1.35516410637792, 'n_independent': 4, 'n_shared': 4, 'momentum': 0.2768196243893071}. Best is trial 0 with value: 527.45654296875.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 1616.29003| val_0_mse: 32790.71484375|  0:00:00s\n","epoch 1  | loss: 688.35637| val_0_mse: 4299.87646484375|  0:00:01s\n","epoch 2  | loss: 519.99551| val_0_mse: 1083.519775390625|  0:00:02s\n","epoch 3  | loss: 459.74799| val_0_mse: 1615.077392578125|  0:00:03s\n","epoch 4  | loss: 446.08189| val_0_mse: 823.8484497070312|  0:00:04s\n","epoch 5  | loss: 401.82027| val_0_mse: 1006.6163330078125|  0:00:05s\n","epoch 6  | loss: 377.93265| val_0_mse: 1507.535400390625|  0:00:06s\n","epoch 7  | loss: 356.94058| val_0_mse: 1246.75634765625|  0:00:07s\n","epoch 8  | loss: 364.87153| val_0_mse: 720.806396484375|  0:00:08s\n","epoch 9  | loss: 357.14077| val_0_mse: 843.5452270507812|  0:00:09s\n","epoch 10 | loss: 357.24363| val_0_mse: 608.2981567382812|  0:00:10s\n","epoch 11 | loss: 339.63211| val_0_mse: 673.8869018554688|  0:00:11s\n","epoch 12 | loss: 328.05112| val_0_mse: 651.09716796875|  0:00:12s\n","epoch 13 | loss: 315.18334| val_0_mse: 529.9465942382812|  0:00:13s\n","epoch 14 | loss: 317.63357| val_0_mse: 358.6551513671875|  0:00:14s\n","epoch 15 | loss: 311.47378| val_0_mse: 385.3368835449219|  0:00:15s\n","epoch 16 | loss: 313.93091| val_0_mse: 457.2654113769531|  0:00:16s\n","epoch 17 | loss: 319.46783| val_0_mse: 378.9018249511719|  0:00:16s\n","epoch 18 | loss: 293.58507| val_0_mse: 346.7067565917969|  0:00:17s\n","epoch 19 | loss: 293.64026| val_0_mse: 349.1062927246094|  0:00:18s\n","epoch 20 | loss: 286.75463| val_0_mse: 388.5811462402344|  0:00:19s\n","epoch 21 | loss: 282.24072| val_0_mse: 337.81793212890625|  0:00:20s\n","epoch 22 | loss: 274.22514| val_0_mse: 297.59881591796875|  0:00:21s\n","epoch 23 | loss: 270.12287| val_0_mse: 317.69354248046875|  0:00:22s\n","epoch 24 | loss: 257.68424| val_0_mse: 374.4594421386719|  0:00:23s\n","epoch 25 | loss: 260.25247| val_0_mse: 296.013916015625|  0:00:24s\n","epoch 26 | loss: 258.76253| val_0_mse: 330.4974060058594|  0:00:25s\n","epoch 27 | loss: 255.31881| val_0_mse: 279.10968017578125|  0:00:26s\n","epoch 28 | loss: 261.47827| val_0_mse: 402.80474853515625|  0:00:27s\n","epoch 29 | loss: 330.96898| val_0_mse: 286.2608642578125|  0:00:28s\n","epoch 30 | loss: 280.83032| val_0_mse: 298.3710021972656|  0:00:29s\n","epoch 31 | loss: 295.62607| val_0_mse: 279.0982971191406|  0:00:30s\n","epoch 32 | loss: 244.53631| val_0_mse: 290.68206787109375|  0:00:31s\n","epoch 33 | loss: 259.75974| val_0_mse: 248.39039611816406|  0:00:31s\n","epoch 34 | loss: 243.59768| val_0_mse: 262.2790222167969|  0:00:32s\n","epoch 35 | loss: 237.86693| val_0_mse: 238.39642333984375|  0:00:33s\n","epoch 36 | loss: 239.93617| val_0_mse: 252.49119567871094|  0:00:34s\n","epoch 37 | loss: 250.42107| val_0_mse: 244.21023559570312|  0:00:35s\n","epoch 38 | loss: 225.65262| val_0_mse: 240.92979431152344|  0:00:36s\n","epoch 39 | loss: 227.13464| val_0_mse: 240.6175994873047|  0:00:37s\n","epoch 40 | loss: 229.22613| val_0_mse: 223.86041259765625|  0:00:38s\n","epoch 41 | loss: 224.27425| val_0_mse: 232.4902801513672|  0:00:39s\n","epoch 42 | loss: 229.05595| val_0_mse: 229.42623901367188|  0:00:40s\n","epoch 43 | loss: 222.08564| val_0_mse: 240.1130828857422|  0:00:41s\n","epoch 44 | loss: 227.263 | val_0_mse: 230.49241638183594|  0:00:42s\n","epoch 45 | loss: 225.45656| val_0_mse: 232.19186401367188|  0:00:43s\n","epoch 46 | loss: 228.71048| val_0_mse: 228.94357299804688|  0:00:44s\n","epoch 47 | loss: 220.64219| val_0_mse: 222.59852600097656|  0:00:45s\n","epoch 48 | loss: 217.25178| val_0_mse: 219.5597381591797|  0:00:46s\n","epoch 49 | loss: 214.51737| val_0_mse: 216.5099334716797|  0:00:47s\n","epoch 50 | loss: 214.72548| val_0_mse: 219.45396423339844|  0:00:48s\n","epoch 51 | loss: 218.12502| val_0_mse: 227.89755249023438|  0:00:49s\n","epoch 52 | loss: 219.50074| val_0_mse: 223.03700256347656|  0:00:50s\n","epoch 53 | loss: 210.67821| val_0_mse: 208.4971160888672|  0:00:50s\n","epoch 54 | loss: 220.43772| val_0_mse: 204.75457763671875|  0:00:51s\n","epoch 55 | loss: 219.27432| val_0_mse: 219.77162170410156|  0:00:52s\n","epoch 56 | loss: 205.63485| val_0_mse: 215.3933868408203|  0:00:53s\n","epoch 57 | loss: 211.45428| val_0_mse: 206.4434356689453|  0:00:54s\n","epoch 58 | loss: 207.96208| val_0_mse: 213.45846557617188|  0:00:55s\n","epoch 59 | loss: 199.60912| val_0_mse: 201.36985778808594|  0:00:56s\n","epoch 60 | loss: 194.39745| val_0_mse: 199.69297790527344|  0:00:57s\n","epoch 61 | loss: 198.47199| val_0_mse: 207.19070434570312|  0:00:58s\n","epoch 62 | loss: 208.85338| val_0_mse: 221.09408569335938|  0:00:59s\n","epoch 63 | loss: 205.58988| val_0_mse: 197.62820434570312|  0:01:00s\n","epoch 64 | loss: 202.39189| val_0_mse: 214.88458251953125|  0:01:01s\n","epoch 65 | loss: 199.30736| val_0_mse: 212.67315673828125|  0:01:02s\n","epoch 66 | loss: 195.76606| val_0_mse: 208.51072692871094|  0:01:03s\n","epoch 67 | loss: 193.3034| val_0_mse: 215.5738983154297|  0:01:04s\n","epoch 68 | loss: 201.1739| val_0_mse: 198.7442626953125|  0:01:05s\n","epoch 69 | loss: 186.92171| val_0_mse: 193.3863983154297|  0:01:06s\n","epoch 70 | loss: 184.63215| val_0_mse: 198.01870727539062|  0:01:06s\n","epoch 71 | loss: 187.21378| val_0_mse: 194.39930725097656|  0:01:07s\n","epoch 72 | loss: 184.2636| val_0_mse: 200.8618927001953|  0:01:08s\n","epoch 73 | loss: 185.95654| val_0_mse: 196.6669464111328|  0:01:09s\n","epoch 74 | loss: 198.30939| val_0_mse: 223.73519897460938|  0:01:10s\n","epoch 75 | loss: 199.70491| val_0_mse: 199.4375|  0:01:11s\n","epoch 76 | loss: 183.26163| val_0_mse: 193.8957061767578|  0:01:12s\n","epoch 77 | loss: 186.63272| val_0_mse: 193.98147583007812|  0:01:13s\n","epoch 78 | loss: 190.38724| val_0_mse: 204.2562255859375|  0:01:14s\n","epoch 79 | loss: 191.2739| val_0_mse: 200.99583435058594|  0:01:15s\n","\n","Early stopping occurred at epoch 79 with best_epoch = 69 and best_val_0_mse = 193.3863983154297\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 14:06:09,977] Trial 1 finished with value: 193.3863983154297 and parameters: {'n_d': 60, 'n_steps': 5, 'gamma': 1.5158429596467773, 'n_independent': 5, 'n_shared': 2, 'momentum': 0.20855953208246553}. Best is trial 1 with value: 193.3863983154297.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 1796.65572| val_0_mse: 21778.259765625|  0:00:01s\n","epoch 1  | loss: 842.69839| val_0_mse: 8459.517578125|  0:00:02s\n","epoch 2  | loss: 578.78768| val_0_mse: 1937.1456298828125|  0:00:03s\n","epoch 3  | loss: 572.86454| val_0_mse: 1591.9659423828125|  0:00:04s\n","epoch 4  | loss: 519.65252| val_0_mse: 1394.7890625|  0:00:05s\n","epoch 5  | loss: 475.76213| val_0_mse: 1031.9241943359375|  0:00:06s\n","epoch 6  | loss: 469.13976| val_0_mse: 1798.894775390625|  0:00:07s\n","epoch 7  | loss: 462.44416| val_0_mse: 1307.1583251953125|  0:00:08s\n","epoch 8  | loss: 427.08639| val_0_mse: 861.990966796875|  0:00:09s\n","epoch 9  | loss: 398.12106| val_0_mse: 1545.431884765625|  0:00:10s\n","epoch 10 | loss: 401.75365| val_0_mse: 996.8359985351562|  0:00:11s\n","epoch 11 | loss: 395.42738| val_0_mse: 507.02874755859375|  0:00:12s\n","epoch 12 | loss: 365.81519| val_0_mse: 745.470458984375|  0:00:13s\n","epoch 13 | loss: 327.83744| val_0_mse: 1538.48876953125|  0:00:14s\n","epoch 14 | loss: 300.42021| val_0_mse: 1002.2603759765625|  0:00:15s\n","epoch 15 | loss: 286.65324| val_0_mse: 698.42578125|  0:00:16s\n","epoch 16 | loss: 282.60082| val_0_mse: 810.829833984375|  0:00:17s\n","epoch 17 | loss: 274.08422| val_0_mse: 424.7508850097656|  0:00:18s\n","epoch 18 | loss: 275.05846| val_0_mse: 445.5572509765625|  0:00:19s\n","epoch 19 | loss: 268.36099| val_0_mse: 550.2911987304688|  0:00:20s\n","epoch 20 | loss: 248.48127| val_0_mse: 337.8913269042969|  0:00:21s\n","epoch 21 | loss: 248.75652| val_0_mse: 322.6871032714844|  0:00:22s\n","epoch 22 | loss: 237.35759| val_0_mse: 351.17864990234375|  0:00:23s\n","epoch 23 | loss: 237.27178| val_0_mse: 312.84503173828125|  0:00:25s\n","epoch 24 | loss: 233.41084| val_0_mse: 354.3714904785156|  0:00:26s\n","epoch 25 | loss: 226.55578| val_0_mse: 243.6561737060547|  0:00:27s\n","epoch 26 | loss: 220.7524| val_0_mse: 339.0752258300781|  0:00:28s\n","epoch 27 | loss: 222.07062| val_0_mse: 363.17718505859375|  0:00:29s\n","epoch 28 | loss: 231.9417| val_0_mse: 277.03997802734375|  0:00:30s\n","epoch 29 | loss: 227.74045| val_0_mse: 342.0366516113281|  0:00:31s\n","epoch 30 | loss: 226.55324| val_0_mse: 303.68023681640625|  0:00:32s\n","epoch 31 | loss: 229.55266| val_0_mse: 262.32843017578125|  0:00:33s\n","epoch 32 | loss: 218.5127| val_0_mse: 220.09768676757812|  0:00:34s\n","epoch 33 | loss: 218.75902| val_0_mse: 219.37982177734375|  0:00:35s\n","epoch 34 | loss: 221.40367| val_0_mse: 244.69482421875|  0:00:36s\n","epoch 35 | loss: 224.66247| val_0_mse: 226.23826599121094|  0:00:37s\n","epoch 36 | loss: 218.27867| val_0_mse: 223.2165069580078|  0:00:38s\n","epoch 37 | loss: 212.78898| val_0_mse: 240.91256713867188|  0:00:39s\n","epoch 38 | loss: 205.22182| val_0_mse: 221.88804626464844|  0:00:40s\n","epoch 39 | loss: 222.33512| val_0_mse: 232.3140869140625|  0:00:41s\n","epoch 40 | loss: 220.1968| val_0_mse: 233.8875732421875|  0:00:42s\n","epoch 41 | loss: 217.57275| val_0_mse: 212.6204071044922|  0:00:43s\n","epoch 42 | loss: 215.59974| val_0_mse: 217.3349609375|  0:00:44s\n","epoch 43 | loss: 215.44483| val_0_mse: 218.79893493652344|  0:00:45s\n","epoch 44 | loss: 210.41076| val_0_mse: 216.4056854248047|  0:00:46s\n","epoch 45 | loss: 207.50138| val_0_mse: 206.7023468017578|  0:00:47s\n","epoch 46 | loss: 208.02557| val_0_mse: 216.81910705566406|  0:00:48s\n","epoch 47 | loss: 203.07842| val_0_mse: 210.22500610351562|  0:00:49s\n","epoch 48 | loss: 203.46208| val_0_mse: 206.1119384765625|  0:00:51s\n","epoch 49 | loss: 201.38222| val_0_mse: 207.03419494628906|  0:00:52s\n","epoch 50 | loss: 195.09089| val_0_mse: 199.38003540039062|  0:00:53s\n","epoch 51 | loss: 198.33508| val_0_mse: 211.1806182861328|  0:00:54s\n","epoch 52 | loss: 194.7635| val_0_mse: 210.3268585205078|  0:00:55s\n","epoch 53 | loss: 193.11195| val_0_mse: 204.87013244628906|  0:00:56s\n","epoch 54 | loss: 195.52112| val_0_mse: 200.36915588378906|  0:00:57s\n","epoch 55 | loss: 190.72917| val_0_mse: 200.4133758544922|  0:00:58s\n","epoch 56 | loss: 198.55294| val_0_mse: 199.3631134033203|  0:00:59s\n","epoch 57 | loss: 194.00736| val_0_mse: 196.03147888183594|  0:01:00s\n","epoch 58 | loss: 191.84148| val_0_mse: 189.10699462890625|  0:01:01s\n","epoch 59 | loss: 191.06986| val_0_mse: 199.32879638671875|  0:01:02s\n","epoch 60 | loss: 193.93061| val_0_mse: 185.16171264648438|  0:01:03s\n","epoch 61 | loss: 195.20132| val_0_mse: 200.36944580078125|  0:01:04s\n","epoch 62 | loss: 200.61646| val_0_mse: 189.2300262451172|  0:01:05s\n","epoch 63 | loss: 186.84338| val_0_mse: 205.68301391601562|  0:01:06s\n","epoch 64 | loss: 185.31284| val_0_mse: 189.9152069091797|  0:01:07s\n","epoch 65 | loss: 180.26215| val_0_mse: 189.3829345703125|  0:01:08s\n","epoch 66 | loss: 187.26191| val_0_mse: 202.0855255126953|  0:01:09s\n","epoch 67 | loss: 183.92385| val_0_mse: 185.6267852783203|  0:01:10s\n","epoch 68 | loss: 181.03925| val_0_mse: 216.89199829101562|  0:01:11s\n","epoch 69 | loss: 191.56025| val_0_mse: 205.8671875|  0:01:12s\n","epoch 70 | loss: 187.88362| val_0_mse: 202.97779846191406|  0:01:13s\n","\n","Early stopping occurred at epoch 70 with best_epoch = 60 and best_val_0_mse = 185.16171264648438\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 14:07:24,503] Trial 2 finished with value: 185.16171264648438 and parameters: {'n_d': 42, 'n_steps': 5, 'gamma': 1.7356785738840728, 'n_independent': 5, 'n_shared': 3, 'momentum': 0.18403024175988908}. Best is trial 2 with value: 185.16171264648438.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 1982.67118| val_0_mse: 21138.7421875|  0:00:01s\n","epoch 1  | loss: 1294.15738| val_0_mse: 19042.4921875|  0:00:03s\n","epoch 2  | loss: 799.76202| val_0_mse: 2567.998046875|  0:00:04s\n","epoch 3  | loss: 641.68281| val_0_mse: 2295.46826171875|  0:00:06s\n","epoch 4  | loss: 615.87162| val_0_mse: 1281.5321044921875|  0:00:07s\n","epoch 5  | loss: 599.42588| val_0_mse: 1571.4305419921875|  0:00:09s\n","epoch 6  | loss: 527.90129| val_0_mse: 1588.2974853515625|  0:00:10s\n","epoch 7  | loss: 534.64831| val_0_mse: 956.3195190429688|  0:00:12s\n","epoch 8  | loss: 555.64976| val_0_mse: 1184.07958984375|  0:00:13s\n","epoch 9  | loss: 574.30961| val_0_mse: 1004.9552001953125|  0:00:15s\n","epoch 10 | loss: 577.32713| val_0_mse: 1445.6201171875|  0:00:16s\n","epoch 11 | loss: 538.44512| val_0_mse: 804.08056640625|  0:00:18s\n","epoch 12 | loss: 526.09992| val_0_mse: 846.5637817382812|  0:00:19s\n","epoch 13 | loss: 523.81727| val_0_mse: 628.615478515625|  0:00:21s\n","epoch 14 | loss: 521.78878| val_0_mse: 503.69189453125|  0:00:22s\n","epoch 15 | loss: 499.41762| val_0_mse: 530.5735473632812|  0:00:24s\n","epoch 16 | loss: 475.00051| val_0_mse: 523.7650756835938|  0:00:25s\n","epoch 17 | loss: 470.07252| val_0_mse: 547.3533325195312|  0:00:27s\n","epoch 18 | loss: 465.40176| val_0_mse: 524.6508178710938|  0:00:28s\n","epoch 19 | loss: 457.63081| val_0_mse: 453.24847412109375|  0:00:30s\n","epoch 20 | loss: 423.54536| val_0_mse: 522.863037109375|  0:00:31s\n","epoch 21 | loss: 490.47238| val_0_mse: 506.45245361328125|  0:00:33s\n","epoch 22 | loss: 475.74064| val_0_mse: 529.1395263671875|  0:00:34s\n","epoch 23 | loss: 464.27441| val_0_mse: 463.5188293457031|  0:00:36s\n","epoch 24 | loss: 433.34716| val_0_mse: 471.7952880859375|  0:00:37s\n","epoch 25 | loss: 412.74489| val_0_mse: 565.3573608398438|  0:00:39s\n","epoch 26 | loss: 431.50265| val_0_mse: 507.75579833984375|  0:00:40s\n","epoch 27 | loss: 412.61397| val_0_mse: 463.47442626953125|  0:00:42s\n","epoch 28 | loss: 395.28362| val_0_mse: 413.76312255859375|  0:00:44s\n","epoch 29 | loss: 402.45433| val_0_mse: 426.1964111328125|  0:00:45s\n","epoch 30 | loss: 410.91296| val_0_mse: 499.31317138671875|  0:00:47s\n","epoch 31 | loss: 402.82116| val_0_mse: 423.8525085449219|  0:00:48s\n","epoch 32 | loss: 388.22308| val_0_mse: 426.080810546875|  0:00:49s\n","epoch 33 | loss: 391.98207| val_0_mse: 397.4934387207031|  0:00:51s\n","epoch 34 | loss: 392.87755| val_0_mse: 412.7498474121094|  0:00:52s\n","epoch 35 | loss: 423.8398| val_0_mse: 435.09857177734375|  0:00:54s\n","epoch 36 | loss: 437.25303| val_0_mse: 453.0417175292969|  0:00:56s\n","epoch 37 | loss: 508.68496| val_0_mse: 488.4093322753906|  0:00:57s\n","epoch 38 | loss: 419.01698| val_0_mse: 445.4129638671875|  0:00:59s\n","epoch 39 | loss: 392.10383| val_0_mse: 443.6417236328125|  0:01:00s\n","epoch 40 | loss: 419.88738| val_0_mse: 416.61822509765625|  0:01:02s\n","epoch 41 | loss: 431.75319| val_0_mse: 426.346435546875|  0:01:03s\n","epoch 42 | loss: 415.59953| val_0_mse: 397.60919189453125|  0:01:05s\n","epoch 43 | loss: 387.14631| val_0_mse: 440.531005859375|  0:01:06s\n","\n","Early stopping occurred at epoch 43 with best_epoch = 33 and best_val_0_mse = 397.4934387207031\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 14:08:31,955] Trial 3 finished with value: 397.4934387207031 and parameters: {'n_d': 39, 'n_steps': 8, 'gamma': 1.6396075275833168, 'n_independent': 3, 'n_shared': 5, 'momentum': 0.1248168487694792}. Best is trial 2 with value: 185.16171264648438.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 2104.32978| val_0_mse: 13868.1796875|  0:00:01s\n","epoch 1  | loss: 1578.07267| val_0_mse: 8476.080078125|  0:00:02s\n","epoch 2  | loss: 957.07027| val_0_mse: 5422.26025390625|  0:00:03s\n","epoch 3  | loss: 728.14526| val_0_mse: 5068.171875|  0:00:05s\n","epoch 4  | loss: 618.59423| val_0_mse: 2069.046875|  0:00:06s\n","epoch 5  | loss: 608.78056| val_0_mse: 3604.61962890625|  0:00:07s\n","epoch 6  | loss: 596.64041| val_0_mse: 1468.1767578125|  0:00:09s\n","epoch 7  | loss: 569.02371| val_0_mse: 1289.010009765625|  0:00:10s\n","epoch 8  | loss: 492.07687| val_0_mse: 891.8223876953125|  0:00:11s\n","epoch 9  | loss: 508.02127| val_0_mse: 1639.185302734375|  0:00:13s\n","epoch 10 | loss: 500.96891| val_0_mse: 1933.091064453125|  0:00:14s\n","epoch 11 | loss: 529.62761| val_0_mse: 1415.124755859375|  0:00:15s\n","epoch 12 | loss: 465.41289| val_0_mse: 539.8107299804688|  0:00:17s\n","epoch 13 | loss: 418.23742| val_0_mse: 597.8576049804688|  0:00:18s\n","epoch 14 | loss: 399.98776| val_0_mse: 649.4717407226562|  0:00:19s\n","epoch 15 | loss: 348.52659| val_0_mse: 1005.5784301757812|  0:00:21s\n","epoch 16 | loss: 329.34433| val_0_mse: 984.114990234375|  0:00:22s\n","epoch 17 | loss: 341.10905| val_0_mse: 1717.92626953125|  0:00:23s\n","epoch 18 | loss: 326.33787| val_0_mse: 591.45849609375|  0:00:24s\n","epoch 19 | loss: 315.21565| val_0_mse: 656.1858520507812|  0:00:26s\n","epoch 20 | loss: 309.33909| val_0_mse: 507.9190368652344|  0:00:27s\n","epoch 21 | loss: 306.28873| val_0_mse: 590.2596435546875|  0:00:28s\n","epoch 22 | loss: 299.47408| val_0_mse: 507.8998718261719|  0:00:30s\n","epoch 23 | loss: 292.36565| val_0_mse: 486.8734436035156|  0:00:31s\n","epoch 24 | loss: 296.18448| val_0_mse: 453.3232421875|  0:00:32s\n","epoch 25 | loss: 305.18907| val_0_mse: 412.8581237792969|  0:00:34s\n","epoch 26 | loss: 304.79103| val_0_mse: 422.61383056640625|  0:00:35s\n","epoch 27 | loss: 310.21225| val_0_mse: 427.8827209472656|  0:00:36s\n","epoch 28 | loss: 289.33354| val_0_mse: 394.59161376953125|  0:00:38s\n","epoch 29 | loss: 288.3862| val_0_mse: 385.5539855957031|  0:00:39s\n","epoch 30 | loss: 277.9666| val_0_mse: 386.1168518066406|  0:00:40s\n","epoch 31 | loss: 271.3784| val_0_mse: 324.24951171875|  0:00:42s\n","epoch 32 | loss: 263.22597| val_0_mse: 355.8088684082031|  0:00:43s\n","epoch 33 | loss: 253.22383| val_0_mse: 279.00579833984375|  0:00:44s\n","epoch 34 | loss: 254.75986| val_0_mse: 266.77276611328125|  0:00:46s\n","epoch 35 | loss: 245.32142| val_0_mse: 255.28126525878906|  0:00:47s\n","epoch 36 | loss: 242.34372| val_0_mse: 288.1624450683594|  0:00:48s\n","epoch 37 | loss: 237.23754| val_0_mse: 238.54554748535156|  0:00:49s\n","epoch 38 | loss: 243.91926| val_0_mse: 270.70880126953125|  0:00:51s\n","epoch 39 | loss: 233.67514| val_0_mse: 279.9700622558594|  0:00:52s\n","epoch 40 | loss: 248.67832| val_0_mse: 297.8443603515625|  0:00:53s\n","epoch 41 | loss: 233.79276| val_0_mse: 303.1962890625|  0:00:55s\n","epoch 42 | loss: 225.61672| val_0_mse: 243.2145538330078|  0:00:56s\n","epoch 43 | loss: 221.86028| val_0_mse: 297.4377136230469|  0:00:57s\n","epoch 44 | loss: 216.8452| val_0_mse: 211.0099334716797|  0:00:59s\n","epoch 45 | loss: 221.35426| val_0_mse: 286.2514343261719|  0:01:00s\n","epoch 46 | loss: 228.70638| val_0_mse: 270.27618408203125|  0:01:01s\n","epoch 47 | loss: 217.57808| val_0_mse: 220.1494140625|  0:01:02s\n","epoch 48 | loss: 214.82649| val_0_mse: 219.23953247070312|  0:01:04s\n","epoch 49 | loss: 214.94452| val_0_mse: 214.51632690429688|  0:01:05s\n","epoch 50 | loss: 216.53527| val_0_mse: 228.8411865234375|  0:01:06s\n","epoch 51 | loss: 216.3081| val_0_mse: 202.20281982421875|  0:01:08s\n","epoch 52 | loss: 201.10394| val_0_mse: 353.36041259765625|  0:01:09s\n","epoch 53 | loss: 207.43321| val_0_mse: 213.331298828125|  0:01:10s\n","epoch 54 | loss: 210.47316| val_0_mse: 212.44290161132812|  0:01:12s\n","epoch 55 | loss: 203.96302| val_0_mse: 206.49696350097656|  0:01:13s\n","epoch 56 | loss: 200.97804| val_0_mse: 219.3170928955078|  0:01:14s\n","epoch 57 | loss: 201.85653| val_0_mse: 217.14883422851562|  0:01:16s\n","epoch 58 | loss: 204.99181| val_0_mse: 205.56063842773438|  0:01:17s\n","epoch 59 | loss: 197.4484| val_0_mse: 224.78378295898438|  0:01:18s\n","epoch 60 | loss: 195.06453| val_0_mse: 193.63287353515625|  0:01:20s\n","epoch 61 | loss: 201.75839| val_0_mse: 199.62135314941406|  0:01:21s\n","epoch 62 | loss: 198.90631| val_0_mse: 209.2479248046875|  0:01:22s\n","epoch 63 | loss: 201.57967| val_0_mse: 241.69183349609375|  0:01:23s\n","epoch 64 | loss: 197.14699| val_0_mse: 189.6678009033203|  0:01:25s\n","epoch 65 | loss: 195.95005| val_0_mse: 199.8335723876953|  0:01:26s\n","epoch 66 | loss: 198.35084| val_0_mse: 193.9665069580078|  0:01:27s\n","epoch 67 | loss: 191.32947| val_0_mse: 197.4582977294922|  0:01:29s\n","epoch 68 | loss: 186.75053| val_0_mse: 200.49978637695312|  0:01:30s\n","epoch 69 | loss: 191.51701| val_0_mse: 202.75103759765625|  0:01:31s\n","epoch 70 | loss: 190.79161| val_0_mse: 194.490478515625|  0:01:33s\n","epoch 71 | loss: 192.33472| val_0_mse: 210.0789337158203|  0:01:34s\n","epoch 72 | loss: 210.40257| val_0_mse: 213.1027374267578|  0:01:35s\n","epoch 73 | loss: 207.63083| val_0_mse: 205.1874542236328|  0:01:36s\n","epoch 74 | loss: 191.08792| val_0_mse: 188.23623657226562|  0:01:38s\n","epoch 75 | loss: 181.29851| val_0_mse: 185.20230102539062|  0:01:39s\n","epoch 76 | loss: 183.38334| val_0_mse: 189.85418701171875|  0:01:40s\n","epoch 77 | loss: 186.3918| val_0_mse: 202.09298706054688|  0:01:42s\n","epoch 78 | loss: 179.55352| val_0_mse: 202.4571533203125|  0:01:43s\n","epoch 79 | loss: 182.48785| val_0_mse: 185.76028442382812|  0:01:44s\n","epoch 80 | loss: 184.14613| val_0_mse: 189.5321044921875|  0:01:46s\n","epoch 81 | loss: 168.84667| val_0_mse: 192.61952209472656|  0:01:47s\n","epoch 82 | loss: 179.33466| val_0_mse: 178.1757354736328|  0:01:48s\n","epoch 83 | loss: 175.28501| val_0_mse: 179.49832153320312|  0:01:50s\n","epoch 84 | loss: 177.99842| val_0_mse: 178.7311248779297|  0:01:51s\n","epoch 85 | loss: 172.58053| val_0_mse: 183.0458526611328|  0:01:52s\n","epoch 86 | loss: 171.62992| val_0_mse: 183.0074005126953|  0:01:53s\n","epoch 87 | loss: 168.66277| val_0_mse: 175.80230712890625|  0:01:55s\n","epoch 88 | loss: 166.4904| val_0_mse: 177.48739624023438|  0:01:56s\n","epoch 89 | loss: 164.68184| val_0_mse: 172.87867736816406|  0:01:57s\n","epoch 90 | loss: 170.24579| val_0_mse: 184.26600646972656|  0:01:59s\n","epoch 91 | loss: 176.12601| val_0_mse: 186.27113342285156|  0:02:00s\n","epoch 92 | loss: 184.23029| val_0_mse: 183.73391723632812|  0:02:01s\n","epoch 93 | loss: 166.03014| val_0_mse: 184.73562622070312|  0:02:02s\n","epoch 94 | loss: 161.68958| val_0_mse: 171.56906127929688|  0:02:04s\n","epoch 95 | loss: 167.36149| val_0_mse: 189.58642578125|  0:02:05s\n","epoch 96 | loss: 169.88169| val_0_mse: 172.95822143554688|  0:02:06s\n","epoch 97 | loss: 167.88517| val_0_mse: 187.43357849121094|  0:02:08s\n","epoch 98 | loss: 166.0611| val_0_mse: 181.6881866455078|  0:02:09s\n","epoch 99 | loss: 170.75568| val_0_mse: 173.82818603515625|  0:02:10s\n","Stop training because you reached max_epochs = 100 with best_epoch = 94 and best_val_0_mse = 171.56906127929688\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 14:10:43,446] Trial 4 finished with value: 171.56906127929688 and parameters: {'n_d': 18, 'n_steps': 6, 'gamma': 1.6417537164819322, 'n_independent': 4, 'n_shared': 5, 'momentum': 0.34869228368542915}. Best is trial 4 with value: 171.56906127929688.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 1749.90746| val_0_mse: 54277.8984375|  0:00:01s\n","epoch 1  | loss: 995.853 | val_0_mse: 26170.751953125|  0:00:03s\n","epoch 2  | loss: 651.48737| val_0_mse: 3599.179443359375|  0:00:04s\n","epoch 3  | loss: 568.79144| val_0_mse: 2425.732666015625|  0:00:06s\n","epoch 4  | loss: 538.08117| val_0_mse: 1439.32666015625|  0:00:07s\n","epoch 5  | loss: 527.1749| val_0_mse: 1718.6865234375|  0:00:09s\n","epoch 6  | loss: 550.15642| val_0_mse: 1023.5556030273438|  0:00:10s\n","epoch 7  | loss: 498.73183| val_0_mse: 1005.31298828125|  0:00:12s\n","epoch 8  | loss: 478.88904| val_0_mse: 1017.5911865234375|  0:00:13s\n","epoch 9  | loss: 464.44949| val_0_mse: 793.5846557617188|  0:00:15s\n","epoch 10 | loss: 447.4731| val_0_mse: 1053.827880859375|  0:00:17s\n","epoch 11 | loss: 451.77832| val_0_mse: 729.1276245117188|  0:00:18s\n","epoch 12 | loss: 470.89627| val_0_mse: 715.44287109375|  0:00:20s\n","epoch 13 | loss: 439.45606| val_0_mse: 740.3951416015625|  0:00:21s\n","epoch 14 | loss: 427.49846| val_0_mse: 863.30224609375|  0:00:23s\n","epoch 15 | loss: 421.43785| val_0_mse: 566.1639404296875|  0:00:24s\n","epoch 16 | loss: 399.15802| val_0_mse: 492.9748840332031|  0:00:26s\n","epoch 17 | loss: 396.09274| val_0_mse: 469.0758361816406|  0:00:28s\n","epoch 18 | loss: 383.62116| val_0_mse: 510.50628662109375|  0:00:29s\n","epoch 19 | loss: 362.2883| val_0_mse: 425.4399108886719|  0:00:31s\n","epoch 20 | loss: 348.94783| val_0_mse: 402.3253479003906|  0:00:32s\n","epoch 21 | loss: 352.91212| val_0_mse: 376.62603759765625|  0:00:34s\n","epoch 22 | loss: 336.1775| val_0_mse: 365.11138916015625|  0:00:35s\n","epoch 23 | loss: 332.48047| val_0_mse: 374.70245361328125|  0:00:37s\n","epoch 24 | loss: 351.91247| val_0_mse: 412.7752685546875|  0:00:38s\n","epoch 25 | loss: 341.97863| val_0_mse: 375.99652099609375|  0:00:40s\n","epoch 26 | loss: 326.48823| val_0_mse: 343.4055480957031|  0:00:41s\n","epoch 27 | loss: 334.43945| val_0_mse: 319.8133850097656|  0:00:43s\n","epoch 28 | loss: 300.82166| val_0_mse: 413.1451721191406|  0:00:44s\n","epoch 29 | loss: 296.07337| val_0_mse: 308.5946350097656|  0:00:46s\n","epoch 30 | loss: 299.61178| val_0_mse: 316.36065673828125|  0:00:47s\n","epoch 31 | loss: 277.33599| val_0_mse: 278.361572265625|  0:00:49s\n","epoch 32 | loss: 266.16552| val_0_mse: 273.9683532714844|  0:00:50s\n","epoch 33 | loss: 261.37885| val_0_mse: 262.8684387207031|  0:00:52s\n","epoch 34 | loss: 261.10556| val_0_mse: 264.66046142578125|  0:00:53s\n","epoch 35 | loss: 253.41893| val_0_mse: 295.96868896484375|  0:00:55s\n","epoch 36 | loss: 253.21499| val_0_mse: 264.1923522949219|  0:00:56s\n","epoch 37 | loss: 265.57545| val_0_mse: 253.2255401611328|  0:00:58s\n","epoch 38 | loss: 248.26674| val_0_mse: 335.5286560058594|  0:01:00s\n","epoch 39 | loss: 245.75766| val_0_mse: 240.0821990966797|  0:01:01s\n","epoch 40 | loss: 246.77104| val_0_mse: 251.59609985351562|  0:01:03s\n","epoch 41 | loss: 247.74492| val_0_mse: 237.22601318359375|  0:01:04s\n","epoch 42 | loss: 231.72178| val_0_mse: 232.96646118164062|  0:01:06s\n","epoch 43 | loss: 246.19201| val_0_mse: 276.2571716308594|  0:01:07s\n","epoch 44 | loss: 253.29774| val_0_mse: 248.12066650390625|  0:01:09s\n","epoch 45 | loss: 237.33825| val_0_mse: 248.5605010986328|  0:01:10s\n","epoch 46 | loss: 236.8115| val_0_mse: 244.27716064453125|  0:01:12s\n","epoch 47 | loss: 227.70066| val_0_mse: 229.7464141845703|  0:01:13s\n","epoch 48 | loss: 227.88722| val_0_mse: 227.48287963867188|  0:01:15s\n","epoch 49 | loss: 214.54701| val_0_mse: 241.34622192382812|  0:01:16s\n","epoch 50 | loss: 224.92204| val_0_mse: 223.7192840576172|  0:01:18s\n","epoch 51 | loss: 213.7234| val_0_mse: 226.47134399414062|  0:01:19s\n","epoch 52 | loss: 216.81208| val_0_mse: 223.24298095703125|  0:01:21s\n","epoch 53 | loss: 213.83132| val_0_mse: 212.3236541748047|  0:01:22s\n","epoch 54 | loss: 217.1401| val_0_mse: 220.3654327392578|  0:01:24s\n","epoch 55 | loss: 222.25583| val_0_mse: 218.66380310058594|  0:01:26s\n","epoch 56 | loss: 220.42954| val_0_mse: 222.77508544921875|  0:01:27s\n","epoch 57 | loss: 211.12659| val_0_mse: 227.6171875|  0:01:29s\n","epoch 58 | loss: 210.27256| val_0_mse: 227.18775939941406|  0:01:30s\n","epoch 59 | loss: 208.1549| val_0_mse: 215.92784118652344|  0:01:32s\n","epoch 60 | loss: 209.45864| val_0_mse: 208.0294952392578|  0:01:33s\n","epoch 61 | loss: 212.62799| val_0_mse: 238.648193359375|  0:01:35s\n","epoch 62 | loss: 221.10366| val_0_mse: 216.6124267578125|  0:01:36s\n","epoch 63 | loss: 210.99035| val_0_mse: 218.24896240234375|  0:01:38s\n","epoch 64 | loss: 209.01919| val_0_mse: 204.2371063232422|  0:01:39s\n","epoch 65 | loss: 208.25878| val_0_mse: 223.9906463623047|  0:01:41s\n","epoch 66 | loss: 207.02575| val_0_mse: 218.65928649902344|  0:01:42s\n","epoch 67 | loss: 203.85921| val_0_mse: 214.3766326904297|  0:01:44s\n","epoch 68 | loss: 196.86879| val_0_mse: 214.38609313964844|  0:01:45s\n","epoch 69 | loss: 199.77224| val_0_mse: 210.94662475585938|  0:01:47s\n","epoch 70 | loss: 202.69921| val_0_mse: 217.2105255126953|  0:01:49s\n","epoch 71 | loss: 200.92201| val_0_mse: 230.68505859375|  0:01:50s\n","epoch 72 | loss: 200.65309| val_0_mse: 224.7303009033203|  0:01:52s\n","epoch 73 | loss: 200.98955| val_0_mse: 224.42471313476562|  0:01:53s\n","epoch 74 | loss: 192.97769| val_0_mse: 209.11012268066406|  0:01:55s\n","\n","Early stopping occurred at epoch 74 with best_epoch = 64 and best_val_0_mse = 204.2371063232422\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 14:12:39,430] Trial 5 finished with value: 204.2371063232422 and parameters: {'n_d': 33, 'n_steps': 9, 'gamma': 1.2351573004903798, 'n_independent': 5, 'n_shared': 2, 'momentum': 0.39684146795754516}. Best is trial 4 with value: 171.56906127929688.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 2076.46661| val_0_mse: 36645.53515625|  0:00:01s\n","epoch 1  | loss: 1369.76341| val_0_mse: 35712.80859375|  0:00:03s\n","epoch 2  | loss: 871.87968| val_0_mse: 8846.9609375|  0:00:05s\n","epoch 3  | loss: 632.37198| val_0_mse: 2625.898681640625|  0:00:06s\n","epoch 4  | loss: 594.37609| val_0_mse: 1281.633544921875|  0:00:08s\n","epoch 5  | loss: 513.99402| val_0_mse: 1772.507080078125|  0:00:10s\n","epoch 6  | loss: 603.8472| val_0_mse: 4352.0205078125|  0:00:11s\n","epoch 7  | loss: 600.94705| val_0_mse: 1777.9332275390625|  0:00:13s\n","epoch 8  | loss: 520.28258| val_0_mse: 1314.068359375|  0:00:15s\n","epoch 9  | loss: 535.04902| val_0_mse: 2849.73828125|  0:00:16s\n","epoch 10 | loss: 507.15181| val_0_mse: 984.5350952148438|  0:00:18s\n","epoch 11 | loss: 473.44119| val_0_mse: 685.222900390625|  0:00:20s\n","epoch 12 | loss: 458.148 | val_0_mse: 1571.9766845703125|  0:00:21s\n","epoch 13 | loss: 523.13179| val_0_mse: 645.6668090820312|  0:00:23s\n","epoch 14 | loss: 540.49561| val_0_mse: 1560.875732421875|  0:00:25s\n","epoch 15 | loss: 461.4566| val_0_mse: 606.2041625976562|  0:00:26s\n","epoch 16 | loss: 476.24442| val_0_mse: 559.10009765625|  0:00:28s\n","epoch 17 | loss: 516.68132| val_0_mse: 633.1738891601562|  0:00:30s\n","epoch 18 | loss: 469.90182| val_0_mse: 1034.396728515625|  0:00:31s\n","epoch 19 | loss: 432.13445| val_0_mse: 528.5061645507812|  0:00:33s\n","epoch 20 | loss: 395.88822| val_0_mse: 864.0355224609375|  0:00:35s\n","epoch 21 | loss: 377.3343| val_0_mse: 528.48193359375|  0:00:36s\n","epoch 22 | loss: 368.93866| val_0_mse: 521.9566040039062|  0:00:38s\n","epoch 23 | loss: 355.82188| val_0_mse: 429.7737121582031|  0:00:40s\n","epoch 24 | loss: 339.60578| val_0_mse: 361.1558532714844|  0:00:41s\n","epoch 25 | loss: 334.33734| val_0_mse: 404.4750671386719|  0:00:43s\n","epoch 26 | loss: 312.90277| val_0_mse: 352.62457275390625|  0:00:45s\n","epoch 27 | loss: 324.22386| val_0_mse: 344.6525573730469|  0:00:46s\n","epoch 28 | loss: 306.89382| val_0_mse: 325.0220642089844|  0:00:48s\n","epoch 29 | loss: 330.9317| val_0_mse: 317.9299011230469|  0:00:50s\n","epoch 30 | loss: 323.88495| val_0_mse: 322.7200012207031|  0:00:51s\n","epoch 31 | loss: 327.98133| val_0_mse: 349.3438720703125|  0:00:53s\n","epoch 32 | loss: 297.67229| val_0_mse: 384.3074035644531|  0:00:55s\n","epoch 33 | loss: 299.43506| val_0_mse: 327.4798278808594|  0:00:56s\n","epoch 34 | loss: 300.78296| val_0_mse: 288.0744934082031|  0:00:58s\n","epoch 35 | loss: 308.88313| val_0_mse: 302.87054443359375|  0:01:00s\n","epoch 36 | loss: 308.21415| val_0_mse: 500.38092041015625|  0:01:01s\n","epoch 37 | loss: 288.41317| val_0_mse: 288.4371643066406|  0:01:03s\n","epoch 38 | loss: 290.1205| val_0_mse: 305.6888732910156|  0:01:05s\n","epoch 39 | loss: 309.09476| val_0_mse: 332.7064208984375|  0:01:06s\n","epoch 40 | loss: 288.2894| val_0_mse: 264.12200927734375|  0:01:08s\n","epoch 41 | loss: 281.06227| val_0_mse: 409.9496765136719|  0:01:10s\n","epoch 42 | loss: 280.55631| val_0_mse: 275.587890625|  0:01:11s\n","epoch 43 | loss: 282.1968| val_0_mse: 309.0852355957031|  0:01:13s\n","epoch 44 | loss: 298.37904| val_0_mse: 295.189453125|  0:01:15s\n","epoch 45 | loss: 284.34396| val_0_mse: 329.2514953613281|  0:01:16s\n","epoch 46 | loss: 284.68781| val_0_mse: 251.80593872070312|  0:01:18s\n","epoch 47 | loss: 258.81408| val_0_mse: 266.9024353027344|  0:01:19s\n","epoch 48 | loss: 269.94661| val_0_mse: 250.9829864501953|  0:01:21s\n","epoch 49 | loss: 251.86963| val_0_mse: 247.07301330566406|  0:01:23s\n","epoch 50 | loss: 255.58858| val_0_mse: 253.50772094726562|  0:01:24s\n","epoch 51 | loss: 252.9783| val_0_mse: 264.11279296875|  0:01:26s\n","epoch 52 | loss: 254.26243| val_0_mse: 264.81866455078125|  0:01:28s\n","epoch 53 | loss: 267.13679| val_0_mse: 252.57957458496094|  0:01:29s\n","epoch 54 | loss: 246.26391| val_0_mse: 251.40701293945312|  0:01:31s\n","epoch 55 | loss: 242.3574| val_0_mse: 244.73362731933594|  0:01:33s\n","epoch 56 | loss: 247.82936| val_0_mse: 234.4005126953125|  0:01:34s\n","epoch 57 | loss: 233.18221| val_0_mse: 222.6521453857422|  0:01:36s\n","epoch 58 | loss: 233.95057| val_0_mse: 244.6019744873047|  0:01:38s\n","epoch 59 | loss: 233.69674| val_0_mse: 226.84779357910156|  0:01:39s\n","epoch 60 | loss: 227.63502| val_0_mse: 241.10049438476562|  0:01:41s\n","epoch 61 | loss: 225.86105| val_0_mse: 258.5661315917969|  0:01:43s\n","epoch 62 | loss: 231.01692| val_0_mse: 219.2876739501953|  0:01:44s\n","epoch 63 | loss: 220.78625| val_0_mse: 223.5771026611328|  0:01:46s\n","epoch 64 | loss: 224.44855| val_0_mse: 251.1029815673828|  0:01:48s\n","epoch 65 | loss: 219.96772| val_0_mse: 253.1380615234375|  0:01:50s\n","epoch 66 | loss: 224.44157| val_0_mse: 252.8955535888672|  0:01:51s\n","epoch 67 | loss: 218.10087| val_0_mse: 248.47483825683594|  0:01:53s\n","epoch 68 | loss: 206.43476| val_0_mse: 212.70230102539062|  0:01:55s\n","epoch 69 | loss: 217.47861| val_0_mse: 213.58407592773438|  0:01:56s\n","epoch 70 | loss: 211.20168| val_0_mse: 273.436767578125|  0:01:58s\n","epoch 71 | loss: 221.01671| val_0_mse: 224.65652465820312|  0:02:00s\n","epoch 72 | loss: 218.34453| val_0_mse: 203.00778198242188|  0:02:01s\n","epoch 73 | loss: 208.85513| val_0_mse: 226.79859924316406|  0:02:03s\n","epoch 74 | loss: 212.92246| val_0_mse: 208.4279327392578|  0:02:04s\n","epoch 75 | loss: 207.2277| val_0_mse: 254.353759765625|  0:02:06s\n","epoch 76 | loss: 209.07309| val_0_mse: 253.585205078125|  0:02:08s\n","epoch 77 | loss: 217.83524| val_0_mse: 215.3739471435547|  0:02:09s\n","epoch 78 | loss: 216.92641| val_0_mse: 209.0487060546875|  0:02:11s\n","epoch 79 | loss: 207.26442| val_0_mse: 220.77804565429688|  0:02:13s\n","epoch 80 | loss: 198.22818| val_0_mse: 204.5420379638672|  0:02:14s\n","epoch 81 | loss: 202.9598| val_0_mse: 206.71197509765625|  0:02:16s\n","epoch 82 | loss: 202.72754| val_0_mse: 212.64561462402344|  0:02:18s\n","\n","Early stopping occurred at epoch 82 with best_epoch = 72 and best_val_0_mse = 203.00778198242188\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 14:14:58,533] Trial 6 finished with value: 203.00778198242188 and parameters: {'n_d': 48, 'n_steps': 10, 'gamma': 1.3766101928572305, 'n_independent': 2, 'n_shared': 5, 'momentum': 0.07264297212612916}. Best is trial 4 with value: 171.56906127929688.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 2236.2919| val_0_mse: 2699.042236328125|  0:00:00s\n","epoch 1  | loss: 1646.06699| val_0_mse: 3386.586181640625|  0:00:01s\n","epoch 2  | loss: 790.27274| val_0_mse: 4176.24560546875|  0:00:01s\n","epoch 3  | loss: 386.62981| val_0_mse: 3579.8232421875|  0:00:02s\n","epoch 4  | loss: 364.76625| val_0_mse: 1567.231689453125|  0:00:03s\n","epoch 5  | loss: 290.98851| val_0_mse: 1070.4359130859375|  0:00:03s\n","epoch 6  | loss: 288.85646| val_0_mse: 955.670654296875|  0:00:04s\n","epoch 7  | loss: 272.19283| val_0_mse: 703.9422607421875|  0:00:04s\n","epoch 8  | loss: 263.31088| val_0_mse: 498.5175476074219|  0:00:05s\n","epoch 9  | loss: 259.19256| val_0_mse: 745.3131713867188|  0:00:06s\n","epoch 10 | loss: 263.71858| val_0_mse: 887.5264892578125|  0:00:06s\n","epoch 11 | loss: 252.17746| val_0_mse: 723.4077758789062|  0:00:07s\n","epoch 12 | loss: 245.92313| val_0_mse: 874.690185546875|  0:00:07s\n","epoch 13 | loss: 245.68914| val_0_mse: 629.22314453125|  0:00:08s\n","epoch 14 | loss: 239.1415| val_0_mse: 492.72528076171875|  0:00:09s\n","epoch 15 | loss: 233.68522| val_0_mse: 394.7491455078125|  0:00:09s\n","epoch 16 | loss: 223.69734| val_0_mse: 529.2027587890625|  0:00:10s\n","epoch 17 | loss: 225.0684| val_0_mse: 425.6253662109375|  0:00:10s\n","epoch 18 | loss: 214.45868| val_0_mse: 428.2803955078125|  0:00:11s\n","epoch 19 | loss: 215.61692| val_0_mse: 352.3689880371094|  0:00:12s\n","epoch 20 | loss: 221.16827| val_0_mse: 324.82208251953125|  0:00:12s\n","epoch 21 | loss: 220.96121| val_0_mse: 328.7962951660156|  0:00:13s\n","epoch 22 | loss: 222.93191| val_0_mse: 382.4441223144531|  0:00:14s\n","epoch 23 | loss: 222.92174| val_0_mse: 377.6563720703125|  0:00:14s\n","epoch 24 | loss: 207.6704| val_0_mse: 312.9657287597656|  0:00:15s\n","epoch 25 | loss: 209.58951| val_0_mse: 265.5851745605469|  0:00:15s\n","epoch 26 | loss: 206.09771| val_0_mse: 311.9152526855469|  0:00:16s\n","epoch 27 | loss: 198.86942| val_0_mse: 300.419189453125|  0:00:16s\n","epoch 28 | loss: 203.90638| val_0_mse: 285.0635070800781|  0:00:17s\n","epoch 29 | loss: 206.10551| val_0_mse: 260.1104431152344|  0:00:18s\n","epoch 30 | loss: 200.25343| val_0_mse: 217.9833526611328|  0:00:18s\n","epoch 31 | loss: 197.18799| val_0_mse: 212.1558380126953|  0:00:19s\n","epoch 32 | loss: 192.57378| val_0_mse: 236.40744018554688|  0:00:19s\n","epoch 33 | loss: 193.32009| val_0_mse: 206.7703857421875|  0:00:20s\n","epoch 34 | loss: 192.31052| val_0_mse: 231.1790008544922|  0:00:21s\n","epoch 35 | loss: 196.63903| val_0_mse: 213.3267059326172|  0:00:21s\n","epoch 36 | loss: 192.97643| val_0_mse: 202.38916015625|  0:00:22s\n","epoch 37 | loss: 186.95473| val_0_mse: 198.78541564941406|  0:00:22s\n","epoch 38 | loss: 188.2447| val_0_mse: 194.83363342285156|  0:00:23s\n","epoch 39 | loss: 189.23086| val_0_mse: 219.1033172607422|  0:00:24s\n","epoch 40 | loss: 181.42896| val_0_mse: 190.98179626464844|  0:00:24s\n","epoch 41 | loss: 185.35814| val_0_mse: 205.83741760253906|  0:00:25s\n","epoch 42 | loss: 188.09308| val_0_mse: 205.1546173095703|  0:00:25s\n","epoch 43 | loss: 185.67658| val_0_mse: 184.44395446777344|  0:00:26s\n","epoch 44 | loss: 179.02181| val_0_mse: 190.47622680664062|  0:00:27s\n","epoch 45 | loss: 181.76826| val_0_mse: 181.59347534179688|  0:00:27s\n","epoch 46 | loss: 174.53299| val_0_mse: 181.95550537109375|  0:00:28s\n","epoch 47 | loss: 178.19692| val_0_mse: 189.1072540283203|  0:00:29s\n","epoch 48 | loss: 177.52169| val_0_mse: 178.6641845703125|  0:00:29s\n","epoch 49 | loss: 187.72823| val_0_mse: 187.1504669189453|  0:00:30s\n","epoch 50 | loss: 185.43055| val_0_mse: 180.46517944335938|  0:00:30s\n","epoch 51 | loss: 175.82905| val_0_mse: 180.99234008789062|  0:00:31s\n","epoch 52 | loss: 177.64081| val_0_mse: 185.0467071533203|  0:00:31s\n","epoch 53 | loss: 175.76114| val_0_mse: 179.6551971435547|  0:00:32s\n","epoch 54 | loss: 174.06  | val_0_mse: 180.2420654296875|  0:00:33s\n","epoch 55 | loss: 173.33904| val_0_mse: 177.18820190429688|  0:00:33s\n","epoch 56 | loss: 172.7634| val_0_mse: 171.1980438232422|  0:00:34s\n","epoch 57 | loss: 162.89022| val_0_mse: 174.35794067382812|  0:00:34s\n","epoch 58 | loss: 166.33816| val_0_mse: 176.8053741455078|  0:00:35s\n","epoch 59 | loss: 165.28362| val_0_mse: 169.0008544921875|  0:00:36s\n","epoch 60 | loss: 161.04092| val_0_mse: 163.49757385253906|  0:00:36s\n","epoch 61 | loss: 157.80402| val_0_mse: 166.67384338378906|  0:00:37s\n","epoch 62 | loss: 166.9441| val_0_mse: 175.11373901367188|  0:00:37s\n","epoch 63 | loss: 166.13777| val_0_mse: 167.06309509277344|  0:00:38s\n","epoch 64 | loss: 159.44768| val_0_mse: 171.61480712890625|  0:00:39s\n","epoch 65 | loss: 157.03441| val_0_mse: 175.1055145263672|  0:00:39s\n","epoch 66 | loss: 154.97223| val_0_mse: 176.43603515625|  0:00:40s\n","epoch 67 | loss: 165.60827| val_0_mse: 189.90234375|  0:00:40s\n","epoch 68 | loss: 161.50987| val_0_mse: 181.47056579589844|  0:00:41s\n","epoch 69 | loss: 156.76406| val_0_mse: 154.989013671875|  0:00:42s\n","epoch 70 | loss: 155.48219| val_0_mse: 160.9451904296875|  0:00:42s\n","epoch 71 | loss: 149.49483| val_0_mse: 158.1577911376953|  0:00:43s\n","epoch 72 | loss: 155.86318| val_0_mse: 174.8512725830078|  0:00:43s\n","epoch 73 | loss: 155.24491| val_0_mse: 161.18772888183594|  0:00:44s\n","epoch 74 | loss: 153.67837| val_0_mse: 160.31483459472656|  0:00:44s\n","epoch 75 | loss: 164.43641| val_0_mse: 160.33563232421875|  0:00:45s\n","epoch 76 | loss: 151.87263| val_0_mse: 186.32904052734375|  0:00:46s\n","epoch 77 | loss: 157.63123| val_0_mse: 172.96978759765625|  0:00:46s\n","epoch 78 | loss: 149.6835| val_0_mse: 155.68238830566406|  0:00:47s\n","epoch 79 | loss: 145.76155| val_0_mse: 153.47825622558594|  0:00:47s\n","epoch 80 | loss: 148.91646| val_0_mse: 167.33555603027344|  0:00:48s\n","epoch 81 | loss: 142.90942| val_0_mse: 146.89492797851562|  0:00:49s\n","epoch 82 | loss: 139.35316| val_0_mse: 180.8019256591797|  0:00:49s\n","epoch 83 | loss: 152.45829| val_0_mse: 159.5666046142578|  0:00:50s\n","epoch 84 | loss: 143.45457| val_0_mse: 153.2041778564453|  0:00:51s\n","epoch 85 | loss: 144.18939| val_0_mse: 163.0400390625|  0:00:51s\n","epoch 86 | loss: 143.0565| val_0_mse: 159.98574829101562|  0:00:52s\n","epoch 87 | loss: 140.43199| val_0_mse: 151.87747192382812|  0:00:52s\n","epoch 88 | loss: 135.45185| val_0_mse: 158.4703826904297|  0:00:53s\n","epoch 89 | loss: 141.06885| val_0_mse: 178.2808380126953|  0:00:53s\n","epoch 90 | loss: 144.84138| val_0_mse: 155.06558227539062|  0:00:54s\n","epoch 91 | loss: 144.28871| val_0_mse: 174.12254333496094|  0:00:55s\n","\n","Early stopping occurred at epoch 91 with best_epoch = 81 and best_val_0_mse = 146.89492797851562\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 14:15:53,969] Trial 7 finished with value: 146.89492797851562 and parameters: {'n_d': 17, 'n_steps': 3, 'gamma': 1.7074485043187932, 'n_independent': 3, 'n_shared': 3, 'momentum': 0.23254851116119848}. Best is trial 7 with value: 146.89492797851562.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 2159.54675| val_0_mse: 13280.5234375|  0:00:01s\n","epoch 1  | loss: 1444.84272| val_0_mse: 30433.00390625|  0:00:03s\n","epoch 2  | loss: 860.77121| val_0_mse: 6470.66064453125|  0:00:05s\n","epoch 3  | loss: 702.65705| val_0_mse: 2314.3896484375|  0:00:06s\n","epoch 4  | loss: 611.97916| val_0_mse: 1872.554931640625|  0:00:08s\n","epoch 5  | loss: 571.2897| val_0_mse: 1414.969482421875|  0:00:10s\n","epoch 6  | loss: 504.79892| val_0_mse: 1905.096435546875|  0:00:11s\n","epoch 7  | loss: 546.436 | val_0_mse: 1401.341064453125|  0:00:13s\n","epoch 8  | loss: 526.14157| val_0_mse: 1038.1632080078125|  0:00:15s\n","epoch 9  | loss: 477.94622| val_0_mse: 1506.3369140625|  0:00:16s\n","epoch 10 | loss: 486.96829| val_0_mse: 1162.2178955078125|  0:00:18s\n","epoch 11 | loss: 499.18162| val_0_mse: 964.3050537109375|  0:00:20s\n","epoch 12 | loss: 494.22902| val_0_mse: 997.5993041992188|  0:00:21s\n","epoch 13 | loss: 484.44423| val_0_mse: 791.390625|  0:00:23s\n","epoch 14 | loss: 455.89732| val_0_mse: 613.2465209960938|  0:00:25s\n","epoch 15 | loss: 458.01582| val_0_mse: 776.7391967773438|  0:00:26s\n","epoch 16 | loss: 502.08388| val_0_mse: 591.9181518554688|  0:00:28s\n","epoch 17 | loss: 538.33784| val_0_mse: 600.6264038085938|  0:00:30s\n","epoch 18 | loss: 474.3237| val_0_mse: 588.5052490234375|  0:00:31s\n","epoch 19 | loss: 479.01007| val_0_mse: 524.6447143554688|  0:00:33s\n","epoch 20 | loss: 459.05427| val_0_mse: 556.3422241210938|  0:00:35s\n","epoch 21 | loss: 432.64349| val_0_mse: 487.8648681640625|  0:00:36s\n","epoch 22 | loss: 431.64695| val_0_mse: 526.4055786132812|  0:00:38s\n","epoch 23 | loss: 476.08802| val_0_mse: 561.0036010742188|  0:00:40s\n","epoch 24 | loss: 445.72428| val_0_mse: 488.8562927246094|  0:00:42s\n","epoch 25 | loss: 434.71399| val_0_mse: 509.3464660644531|  0:00:43s\n","epoch 26 | loss: 440.69878| val_0_mse: 480.5376281738281|  0:00:45s\n","epoch 27 | loss: 608.65743| val_0_mse: 918.2785034179688|  0:00:46s\n","epoch 28 | loss: 584.34154| val_0_mse: 516.7609252929688|  0:00:48s\n","epoch 29 | loss: 480.63803| val_0_mse: 471.70404052734375|  0:00:50s\n","epoch 30 | loss: 452.36291| val_0_mse: 436.92010498046875|  0:00:51s\n","epoch 31 | loss: 423.08419| val_0_mse: 488.658447265625|  0:00:53s\n","epoch 32 | loss: 419.18668| val_0_mse: 509.03802490234375|  0:00:55s\n","epoch 33 | loss: 402.93796| val_0_mse: 373.2935485839844|  0:00:56s\n","epoch 34 | loss: 362.5126| val_0_mse: 365.5560302734375|  0:00:58s\n","epoch 35 | loss: 344.90002| val_0_mse: 351.59259033203125|  0:01:00s\n","epoch 36 | loss: 333.53732| val_0_mse: 329.2080383300781|  0:01:02s\n","epoch 37 | loss: 318.08817| val_0_mse: 306.7770080566406|  0:01:03s\n","epoch 38 | loss: 310.47608| val_0_mse: 283.0619201660156|  0:01:05s\n","epoch 39 | loss: 295.97633| val_0_mse: 318.10992431640625|  0:01:07s\n","epoch 40 | loss: 312.00009| val_0_mse: 405.12371826171875|  0:01:08s\n","epoch 41 | loss: 301.70221| val_0_mse: 269.83721923828125|  0:01:10s\n","epoch 42 | loss: 280.50872| val_0_mse: 271.5544738769531|  0:01:12s\n","epoch 43 | loss: 258.14009| val_0_mse: 260.9600830078125|  0:01:13s\n","epoch 44 | loss: 262.5497| val_0_mse: 298.89764404296875|  0:01:15s\n","epoch 45 | loss: 279.17761| val_0_mse: 248.58575439453125|  0:01:17s\n","epoch 46 | loss: 263.03457| val_0_mse: 270.8825378417969|  0:01:18s\n","epoch 47 | loss: 286.47237| val_0_mse: 284.52154541015625|  0:01:20s\n","epoch 48 | loss: 265.65725| val_0_mse: 250.79446411132812|  0:01:21s\n","epoch 49 | loss: 260.28699| val_0_mse: 246.4120330810547|  0:01:23s\n","epoch 50 | loss: 241.95324| val_0_mse: 258.5617980957031|  0:01:25s\n","epoch 51 | loss: 240.74671| val_0_mse: 226.44056701660156|  0:01:26s\n","epoch 52 | loss: 236.70066| val_0_mse: 264.3628845214844|  0:01:28s\n","epoch 53 | loss: 249.36549| val_0_mse: 269.1038818359375|  0:01:30s\n","epoch 54 | loss: 249.85344| val_0_mse: 238.7046661376953|  0:01:31s\n","epoch 55 | loss: 234.19646| val_0_mse: 243.15199279785156|  0:01:33s\n","epoch 56 | loss: 236.68266| val_0_mse: 227.85214233398438|  0:01:35s\n","epoch 57 | loss: 222.55267| val_0_mse: 217.4183349609375|  0:01:36s\n","epoch 58 | loss: 234.38009| val_0_mse: 262.67230224609375|  0:01:38s\n","epoch 59 | loss: 234.00426| val_0_mse: 227.90707397460938|  0:01:40s\n","epoch 60 | loss: 232.30248| val_0_mse: 217.80189514160156|  0:01:42s\n","epoch 61 | loss: 217.51352| val_0_mse: 233.55340576171875|  0:01:43s\n","epoch 62 | loss: 241.61575| val_0_mse: 224.4783935546875|  0:01:45s\n","epoch 63 | loss: 246.53057| val_0_mse: 256.3557434082031|  0:01:46s\n","epoch 64 | loss: 247.10979| val_0_mse: 225.2813262939453|  0:01:48s\n","epoch 65 | loss: 220.62015| val_0_mse: 213.38731384277344|  0:01:50s\n","epoch 66 | loss: 213.82845| val_0_mse: 217.063720703125|  0:01:52s\n","epoch 67 | loss: 210.35026| val_0_mse: 249.91969299316406|  0:01:53s\n","epoch 68 | loss: 219.99398| val_0_mse: 263.9024353027344|  0:01:55s\n","epoch 69 | loss: 236.08322| val_0_mse: 213.92445373535156|  0:01:57s\n","epoch 70 | loss: 229.79368| val_0_mse: 216.07174682617188|  0:01:58s\n","epoch 71 | loss: 216.74313| val_0_mse: 220.657958984375|  0:02:00s\n","epoch 72 | loss: 207.53876| val_0_mse: 211.0890350341797|  0:02:02s\n","epoch 73 | loss: 208.50963| val_0_mse: 223.25100708007812|  0:02:04s\n","epoch 74 | loss: 217.76001| val_0_mse: 199.9167938232422|  0:02:06s\n","epoch 75 | loss: 202.28799| val_0_mse: 202.76718139648438|  0:02:07s\n","epoch 76 | loss: 200.07423| val_0_mse: 211.9173126220703|  0:02:09s\n","epoch 77 | loss: 206.37828| val_0_mse: 199.3627166748047|  0:02:11s\n","epoch 78 | loss: 208.03889| val_0_mse: 192.7722930908203|  0:02:12s\n","epoch 79 | loss: 198.37968| val_0_mse: 196.78677368164062|  0:02:14s\n","epoch 80 | loss: 197.94474| val_0_mse: 195.3995819091797|  0:02:16s\n","epoch 81 | loss: 192.99114| val_0_mse: 217.18057250976562|  0:02:18s\n","epoch 82 | loss: 214.66738| val_0_mse: 215.2952423095703|  0:02:19s\n","epoch 83 | loss: 201.95778| val_0_mse: 194.98377990722656|  0:02:21s\n","epoch 84 | loss: 193.86999| val_0_mse: 204.5199432373047|  0:02:23s\n","epoch 85 | loss: 198.10413| val_0_mse: 219.8776397705078|  0:02:24s\n","epoch 86 | loss: 195.1545| val_0_mse: 197.24566650390625|  0:02:26s\n","epoch 87 | loss: 198.05076| val_0_mse: 214.77606201171875|  0:02:28s\n","epoch 88 | loss: 205.73367| val_0_mse: 215.8305206298828|  0:02:29s\n","\n","Early stopping occurred at epoch 88 with best_epoch = 78 and best_val_0_mse = 192.7722930908203\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 14:18:24,884] Trial 8 finished with value: 192.77230834960938 and parameters: {'n_d': 51, 'n_steps': 8, 'gamma': 1.722329003697801, 'n_independent': 4, 'n_shared': 5, 'momentum': 0.08480736460427099}. Best is trial 7 with value: 146.89492797851562.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 1895.34349| val_0_mse: 12192.3466796875|  0:00:00s\n","epoch 1  | loss: 1469.81112| val_0_mse: 5009.47607421875|  0:00:01s\n","epoch 2  | loss: 1023.60179| val_0_mse: 8890.841796875|  0:00:02s\n","epoch 3  | loss: 794.65826| val_0_mse: 13113.3115234375|  0:00:03s\n","epoch 4  | loss: 649.25248| val_0_mse: 2509.031494140625|  0:00:04s\n","epoch 5  | loss: 542.4942| val_0_mse: 1949.206298828125|  0:00:04s\n","epoch 6  | loss: 501.34344| val_0_mse: 1433.988037109375|  0:00:05s\n","epoch 7  | loss: 488.53146| val_0_mse: 781.0477294921875|  0:00:06s\n","epoch 8  | loss: 506.03429| val_0_mse: 816.4129028320312|  0:00:07s\n","epoch 9  | loss: 513.9685| val_0_mse: 792.3506469726562|  0:00:08s\n","epoch 10 | loss: 531.61785| val_0_mse: 1136.4246826171875|  0:00:08s\n","epoch 11 | loss: 538.25536| val_0_mse: 834.295654296875|  0:00:09s\n","epoch 12 | loss: 497.3587| val_0_mse: 720.7750244140625|  0:00:10s\n","epoch 13 | loss: 475.30536| val_0_mse: 685.8956298828125|  0:00:11s\n","epoch 14 | loss: 578.30641| val_0_mse: 744.5703735351562|  0:00:12s\n","epoch 15 | loss: 496.47953| val_0_mse: 498.5071105957031|  0:00:12s\n","epoch 16 | loss: 466.0849| val_0_mse: 654.3507690429688|  0:00:13s\n","epoch 17 | loss: 520.62799| val_0_mse: 695.932861328125|  0:00:14s\n","epoch 18 | loss: 454.30023| val_0_mse: 602.521728515625|  0:00:15s\n","epoch 19 | loss: 472.83056| val_0_mse: 609.8790893554688|  0:00:16s\n","epoch 20 | loss: 447.70682| val_0_mse: 474.48919677734375|  0:00:16s\n","epoch 21 | loss: 460.93493| val_0_mse: 453.11126708984375|  0:00:17s\n","epoch 22 | loss: 438.53017| val_0_mse: 450.57611083984375|  0:00:18s\n","epoch 23 | loss: 424.80887| val_0_mse: 421.3023986816406|  0:00:19s\n","epoch 24 | loss: 405.48983| val_0_mse: 469.2955322265625|  0:00:20s\n","epoch 25 | loss: 383.39956| val_0_mse: 387.90618896484375|  0:00:20s\n","epoch 26 | loss: 383.61988| val_0_mse: 414.636474609375|  0:00:21s\n","epoch 27 | loss: 356.87801| val_0_mse: 379.7853698730469|  0:00:22s\n","epoch 28 | loss: 340.93816| val_0_mse: 361.239013671875|  0:00:23s\n","epoch 29 | loss: 325.18785| val_0_mse: 390.7328796386719|  0:00:24s\n","epoch 30 | loss: 307.7051| val_0_mse: 389.0663146972656|  0:00:25s\n","epoch 31 | loss: 295.6415| val_0_mse: 317.93731689453125|  0:00:25s\n","epoch 32 | loss: 306.4091| val_0_mse: 309.6591796875|  0:00:26s\n","epoch 33 | loss: 326.76167| val_0_mse: 318.0650939941406|  0:00:27s\n","epoch 34 | loss: 335.54243| val_0_mse: 300.4437561035156|  0:00:28s\n","epoch 35 | loss: 324.44255| val_0_mse: 318.12744140625|  0:00:29s\n","epoch 36 | loss: 295.20713| val_0_mse: 292.00421142578125|  0:00:29s\n","epoch 37 | loss: 290.76614| val_0_mse: 287.9693908691406|  0:00:30s\n","epoch 38 | loss: 296.52079| val_0_mse: 274.49505615234375|  0:00:31s\n","epoch 39 | loss: 288.74069| val_0_mse: 309.1774597167969|  0:00:32s\n","epoch 40 | loss: 292.29318| val_0_mse: 268.4132385253906|  0:00:32s\n","epoch 41 | loss: 275.7503| val_0_mse: 274.53253173828125|  0:00:33s\n","epoch 42 | loss: 302.19936| val_0_mse: 270.67132568359375|  0:00:34s\n","epoch 43 | loss: 272.85067| val_0_mse: 259.7788391113281|  0:00:35s\n","epoch 44 | loss: 265.05992| val_0_mse: 253.42425537109375|  0:00:36s\n","epoch 45 | loss: 253.23495| val_0_mse: 251.71969604492188|  0:00:36s\n","epoch 46 | loss: 254.3257| val_0_mse: 255.9574737548828|  0:00:37s\n","epoch 47 | loss: 270.00537| val_0_mse: 251.72549438476562|  0:00:38s\n","epoch 48 | loss: 245.10232| val_0_mse: 241.41366577148438|  0:00:39s\n","epoch 49 | loss: 240.47871| val_0_mse: 237.63917541503906|  0:00:39s\n","epoch 50 | loss: 241.84122| val_0_mse: 225.83070373535156|  0:00:40s\n","epoch 51 | loss: 240.07325| val_0_mse: 250.2367401123047|  0:00:41s\n","epoch 52 | loss: 240.69349| val_0_mse: 234.09938049316406|  0:00:42s\n","epoch 53 | loss: 246.697 | val_0_mse: 293.0852355957031|  0:00:43s\n","epoch 54 | loss: 245.86571| val_0_mse: 237.4940185546875|  0:00:43s\n","epoch 55 | loss: 241.83452| val_0_mse: 251.01931762695312|  0:00:44s\n","epoch 56 | loss: 255.06519| val_0_mse: 256.1868591308594|  0:00:45s\n","epoch 57 | loss: 246.56001| val_0_mse: 239.2528533935547|  0:00:46s\n","epoch 58 | loss: 246.34766| val_0_mse: 246.18775939941406|  0:00:46s\n","epoch 59 | loss: 238.54712| val_0_mse: 227.8382568359375|  0:00:47s\n","epoch 60 | loss: 241.83693| val_0_mse: 241.126953125|  0:00:48s\n","\n","Early stopping occurred at epoch 60 with best_epoch = 50 and best_val_0_mse = 225.83070373535156\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 14:19:13,977] Trial 9 finished with value: 225.83070373535156 and parameters: {'n_d': 24, 'n_steps': 10, 'gamma': 1.7402791535977702, 'n_independent': 1, 'n_shared': 1, 'momentum': 0.3370811872207294}. Best is trial 7 with value: 146.89492797851562.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 2311.24323| val_0_mse: 2210.616455078125|  0:00:00s\n","epoch 1  | loss: 2093.89004| val_0_mse: 1601.388916015625|  0:00:01s\n","epoch 2  | loss: 1686.16073| val_0_mse: 1457.293701171875|  0:00:01s\n","epoch 3  | loss: 1156.67598| val_0_mse: 1102.68359375|  0:00:02s\n","epoch 4  | loss: 696.02297| val_0_mse: 1196.7926025390625|  0:00:02s\n","epoch 5  | loss: 404.15425| val_0_mse: 2906.784423828125|  0:00:03s\n","epoch 6  | loss: 353.31749| val_0_mse: 3747.508056640625|  0:00:03s\n","epoch 7  | loss: 339.94607| val_0_mse: 2062.271240234375|  0:00:04s\n","epoch 8  | loss: 346.3313| val_0_mse: 1527.3770751953125|  0:00:04s\n","epoch 9  | loss: 332.81306| val_0_mse: 2897.55712890625|  0:00:05s\n","epoch 10 | loss: 339.88097| val_0_mse: 1976.139404296875|  0:00:05s\n","epoch 11 | loss: 307.1374| val_0_mse: 3580.142822265625|  0:00:06s\n","epoch 12 | loss: 284.30835| val_0_mse: 1394.89013671875|  0:00:07s\n","epoch 13 | loss: 280.55242| val_0_mse: 1903.988525390625|  0:00:07s\n","\n","Early stopping occurred at epoch 13 with best_epoch = 3 and best_val_0_mse = 1102.68359375\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 14:19:21,854] Trial 10 finished with value: 1102.68359375 and parameters: {'n_d': 8, 'n_steps': 3, 'gamma': 1.9202252630422714, 'n_independent': 2, 'n_shared': 3, 'momentum': 0.012983543413594062}. Best is trial 7 with value: 146.89492797851562.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 2130.10036| val_0_mse: 3921.281005859375|  0:00:00s\n","epoch 1  | loss: 1487.34547| val_0_mse: 4120.95556640625|  0:00:01s\n","epoch 2  | loss: 718.38435| val_0_mse: 2695.636474609375|  0:00:01s\n","epoch 3  | loss: 434.32751| val_0_mse: 1633.6605224609375|  0:00:02s\n","epoch 4  | loss: 370.04563| val_0_mse: 1555.281494140625|  0:00:03s\n","epoch 5  | loss: 336.51246| val_0_mse: 1300.24462890625|  0:00:04s\n","epoch 6  | loss: 314.91661| val_0_mse: 1011.874267578125|  0:00:04s\n","epoch 7  | loss: 309.66213| val_0_mse: 918.8167724609375|  0:00:05s\n","epoch 8  | loss: 290.51074| val_0_mse: 1008.3076782226562|  0:00:06s\n","epoch 9  | loss: 280.31008| val_0_mse: 877.3753051757812|  0:00:06s\n","epoch 10 | loss: 264.9162| val_0_mse: 596.4706420898438|  0:00:07s\n","epoch 11 | loss: 261.57311| val_0_mse: 428.4277648925781|  0:00:08s\n","epoch 12 | loss: 261.6824| val_0_mse: 396.9563293457031|  0:00:08s\n","epoch 13 | loss: 246.98323| val_0_mse: 375.32110595703125|  0:00:09s\n","epoch 14 | loss: 243.13384| val_0_mse: 356.7487487792969|  0:00:10s\n","epoch 15 | loss: 236.92359| val_0_mse: 311.03173828125|  0:00:10s\n","epoch 16 | loss: 235.18251| val_0_mse: 315.572998046875|  0:00:11s\n","epoch 17 | loss: 241.57922| val_0_mse: 278.9961853027344|  0:00:12s\n","epoch 18 | loss: 228.78473| val_0_mse: 304.2742614746094|  0:00:12s\n","epoch 19 | loss: 227.06837| val_0_mse: 257.5196838378906|  0:00:13s\n","epoch 20 | loss: 220.12008| val_0_mse: 374.9988098144531|  0:00:14s\n","epoch 21 | loss: 224.37674| val_0_mse: 271.1272888183594|  0:00:14s\n","epoch 22 | loss: 214.25113| val_0_mse: 241.3234405517578|  0:00:15s\n","epoch 23 | loss: 220.54773| val_0_mse: 242.66407775878906|  0:00:16s\n","epoch 24 | loss: 218.63768| val_0_mse: 279.8475646972656|  0:00:16s\n","epoch 25 | loss: 222.04885| val_0_mse: 246.74017333984375|  0:00:17s\n","epoch 26 | loss: 207.89327| val_0_mse: 234.16270446777344|  0:00:18s\n","epoch 27 | loss: 207.67637| val_0_mse: 239.50184631347656|  0:00:18s\n","epoch 28 | loss: 205.91203| val_0_mse: 245.72787475585938|  0:00:19s\n","epoch 29 | loss: 208.90702| val_0_mse: 226.6381072998047|  0:00:20s\n","epoch 30 | loss: 201.73712| val_0_mse: 207.66697692871094|  0:00:20s\n","epoch 31 | loss: 197.73718| val_0_mse: 230.9400177001953|  0:00:21s\n","epoch 32 | loss: 202.43638| val_0_mse: 222.95297241210938|  0:00:22s\n","epoch 33 | loss: 198.33278| val_0_mse: 202.66741943359375|  0:00:22s\n","epoch 34 | loss: 192.57428| val_0_mse: 223.6478271484375|  0:00:23s\n","epoch 35 | loss: 192.86919| val_0_mse: 205.37533569335938|  0:00:24s\n","epoch 36 | loss: 193.31459| val_0_mse: 212.09796142578125|  0:00:24s\n","epoch 37 | loss: 191.41485| val_0_mse: 207.50633239746094|  0:00:25s\n","epoch 38 | loss: 197.5533| val_0_mse: 231.3059844970703|  0:00:26s\n","epoch 39 | loss: 198.40212| val_0_mse: 204.54510498046875|  0:00:26s\n","epoch 40 | loss: 198.72611| val_0_mse: 206.2928924560547|  0:00:27s\n","epoch 41 | loss: 193.5943| val_0_mse: 198.36038208007812|  0:00:28s\n","epoch 42 | loss: 194.32911| val_0_mse: 202.01881408691406|  0:00:29s\n","epoch 43 | loss: 189.94983| val_0_mse: 203.8472442626953|  0:00:29s\n","epoch 44 | loss: 191.54737| val_0_mse: 190.88467407226562|  0:00:30s\n","epoch 45 | loss: 183.98531| val_0_mse: 186.51402282714844|  0:00:31s\n","epoch 46 | loss: 187.22995| val_0_mse: 192.10549926757812|  0:00:31s\n","epoch 47 | loss: 180.0244| val_0_mse: 207.50094604492188|  0:00:32s\n","epoch 48 | loss: 186.86184| val_0_mse: 197.73399353027344|  0:00:33s\n","epoch 49 | loss: 188.53954| val_0_mse: 190.5632781982422|  0:00:33s\n","epoch 50 | loss: 186.18554| val_0_mse: 193.3100128173828|  0:00:34s\n","epoch 51 | loss: 183.92054| val_0_mse: 187.9217529296875|  0:00:35s\n","epoch 52 | loss: 182.29458| val_0_mse: 190.0375213623047|  0:00:35s\n","epoch 53 | loss: 176.18411| val_0_mse: 186.8112335205078|  0:00:36s\n","epoch 54 | loss: 188.38242| val_0_mse: 192.5530242919922|  0:00:37s\n","epoch 55 | loss: 183.21827| val_0_mse: 195.0377655029297|  0:00:37s\n","\n","Early stopping occurred at epoch 55 with best_epoch = 45 and best_val_0_mse = 186.51402282714844\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 14:20:00,146] Trial 11 finished with value: 186.51402282714844 and parameters: {'n_d': 14, 'n_steps': 3, 'gamma': 1.9303931741644922, 'n_independent': 3, 'n_shared': 4, 'momentum': 0.2776339181594163}. Best is trial 7 with value: 146.89492797851562.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 2161.22346| val_0_mse: 3280.01513671875|  0:00:01s\n","epoch 1  | loss: 1470.99959| val_0_mse: 6326.3115234375|  0:00:02s\n","epoch 2  | loss: 635.73451| val_0_mse: 4290.05078125|  0:00:03s\n","epoch 3  | loss: 458.62754| val_0_mse: 2262.447509765625|  0:00:04s\n","epoch 4  | loss: 379.54425| val_0_mse: 1606.1209716796875|  0:00:05s\n","epoch 5  | loss: 367.88161| val_0_mse: 2583.4931640625|  0:00:05s\n","epoch 6  | loss: 343.46712| val_0_mse: 1348.650390625|  0:00:06s\n","epoch 7  | loss: 333.04341| val_0_mse: 1042.7823486328125|  0:00:07s\n","epoch 8  | loss: 314.77159| val_0_mse: 826.7935791015625|  0:00:08s\n","epoch 9  | loss: 322.71737| val_0_mse: 802.7987060546875|  0:00:09s\n","epoch 10 | loss: 319.75399| val_0_mse: 909.3377075195312|  0:00:10s\n","epoch 11 | loss: 330.40527| val_0_mse: 794.9794921875|  0:00:11s\n","epoch 12 | loss: 317.24886| val_0_mse: 569.84326171875|  0:00:12s\n","epoch 13 | loss: 316.21323| val_0_mse: 400.08880615234375|  0:00:13s\n","epoch 14 | loss: 303.67281| val_0_mse: 568.0247192382812|  0:00:14s\n","epoch 15 | loss: 280.00933| val_0_mse: 414.4880065917969|  0:00:15s\n","epoch 16 | loss: 283.56042| val_0_mse: 401.3000793457031|  0:00:16s\n","epoch 17 | loss: 275.18745| val_0_mse: 357.4451599121094|  0:00:17s\n","epoch 18 | loss: 290.73815| val_0_mse: 427.7522888183594|  0:00:18s\n","epoch 19 | loss: 274.31429| val_0_mse: 350.06683349609375|  0:00:19s\n","epoch 20 | loss: 267.89208| val_0_mse: 385.9361267089844|  0:00:20s\n","epoch 21 | loss: 261.82968| val_0_mse: 333.53656005859375|  0:00:21s\n","epoch 22 | loss: 274.66033| val_0_mse: 321.6070556640625|  0:00:22s\n","epoch 23 | loss: 263.94081| val_0_mse: 306.49505615234375|  0:00:23s\n","epoch 24 | loss: 256.78925| val_0_mse: 288.2604064941406|  0:00:24s\n","epoch 25 | loss: 248.26332| val_0_mse: 334.5116271972656|  0:00:25s\n","epoch 26 | loss: 255.13507| val_0_mse: 293.9434814453125|  0:00:26s\n","epoch 27 | loss: 252.31126| val_0_mse: 302.2346496582031|  0:00:27s\n","epoch 28 | loss: 239.74225| val_0_mse: 329.69805908203125|  0:00:28s\n","epoch 29 | loss: 242.13707| val_0_mse: 275.80462646484375|  0:00:29s\n","epoch 30 | loss: 237.39977| val_0_mse: 283.1145935058594|  0:00:30s\n","epoch 31 | loss: 246.10231| val_0_mse: 252.07518005371094|  0:00:31s\n","epoch 32 | loss: 245.65176| val_0_mse: 322.1325378417969|  0:00:32s\n","epoch 33 | loss: 234.0005| val_0_mse: 262.649169921875|  0:00:33s\n","epoch 34 | loss: 234.67554| val_0_mse: 291.2662658691406|  0:00:34s\n","epoch 35 | loss: 234.00551| val_0_mse: 248.863525390625|  0:00:35s\n","epoch 36 | loss: 224.93828| val_0_mse: 250.0624237060547|  0:00:35s\n","epoch 37 | loss: 228.74292| val_0_mse: 248.448486328125|  0:00:36s\n","epoch 38 | loss: 226.24819| val_0_mse: 227.16488647460938|  0:00:37s\n","epoch 39 | loss: 224.1183| val_0_mse: 241.475341796875|  0:00:38s\n","epoch 40 | loss: 226.17445| val_0_mse: 229.23501586914062|  0:00:39s\n","epoch 41 | loss: 213.88827| val_0_mse: 234.3820343017578|  0:00:40s\n","epoch 42 | loss: 217.973 | val_0_mse: 216.98193359375|  0:00:41s\n","epoch 43 | loss: 217.35487| val_0_mse: 214.95953369140625|  0:00:42s\n","epoch 44 | loss: 220.8951| val_0_mse: 234.52096557617188|  0:00:43s\n","epoch 45 | loss: 217.32257| val_0_mse: 214.66424560546875|  0:00:44s\n","epoch 46 | loss: 207.27044| val_0_mse: 269.49273681640625|  0:00:45s\n","epoch 47 | loss: 202.71259| val_0_mse: 204.634765625|  0:00:46s\n","epoch 48 | loss: 196.6485| val_0_mse: 212.05282592773438|  0:00:47s\n","epoch 49 | loss: 208.09793| val_0_mse: 219.2183074951172|  0:00:48s\n","epoch 50 | loss: 213.27018| val_0_mse: 219.2805938720703|  0:00:49s\n","epoch 51 | loss: 209.76924| val_0_mse: 223.58050537109375|  0:00:50s\n","epoch 52 | loss: 202.72719| val_0_mse: 257.6239929199219|  0:00:51s\n","epoch 53 | loss: 201.16256| val_0_mse: 196.6788330078125|  0:00:52s\n","epoch 54 | loss: 199.42749| val_0_mse: 198.4121856689453|  0:00:53s\n","epoch 55 | loss: 196.1535| val_0_mse: 205.84165954589844|  0:00:53s\n","epoch 56 | loss: 202.20532| val_0_mse: 200.09251403808594|  0:00:54s\n","epoch 57 | loss: 191.2406| val_0_mse: 197.00083923339844|  0:00:55s\n","epoch 58 | loss: 188.57698| val_0_mse: 214.18226623535156|  0:00:56s\n","epoch 59 | loss: 193.57323| val_0_mse: 192.72250366210938|  0:00:57s\n","epoch 60 | loss: 188.30216| val_0_mse: 201.3799591064453|  0:00:58s\n","epoch 61 | loss: 188.75078| val_0_mse: 224.16351318359375|  0:00:59s\n","epoch 62 | loss: 187.02216| val_0_mse: 188.62828063964844|  0:01:00s\n","epoch 63 | loss: 187.87703| val_0_mse: 199.4185791015625|  0:01:01s\n","epoch 64 | loss: 188.34386| val_0_mse: 181.50961303710938|  0:01:02s\n","epoch 65 | loss: 183.79897| val_0_mse: 186.2835235595703|  0:01:03s\n","epoch 66 | loss: 188.90639| val_0_mse: 199.8600616455078|  0:01:04s\n","epoch 67 | loss: 184.20108| val_0_mse: 195.1916046142578|  0:01:05s\n","epoch 68 | loss: 180.31789| val_0_mse: 200.85064697265625|  0:01:06s\n","epoch 69 | loss: 186.06823| val_0_mse: 193.92018127441406|  0:01:07s\n","epoch 70 | loss: 194.81692| val_0_mse: 186.70985412597656|  0:01:08s\n","epoch 71 | loss: 179.03465| val_0_mse: 183.6940460205078|  0:01:09s\n","epoch 72 | loss: 181.85298| val_0_mse: 194.5472869873047|  0:01:10s\n","epoch 73 | loss: 185.9587| val_0_mse: 184.32908630371094|  0:01:11s\n","epoch 74 | loss: 176.45548| val_0_mse: 208.72450256347656|  0:01:12s\n","\n","Early stopping occurred at epoch 74 with best_epoch = 64 and best_val_0_mse = 181.50961303710938\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 14:21:13,135] Trial 12 finished with value: 181.50962829589844 and parameters: {'n_d': 21, 'n_steps': 5, 'gamma': 1.001105242677882, 'n_independent': 4, 'n_shared': 3, 'momentum': 0.39814222380725584}. Best is trial 7 with value: 146.89492797851562.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 2116.24102| val_0_mse: 4374.9482421875|  0:00:00s\n","epoch 1  | loss: 1469.363| val_0_mse: 2116.90771484375|  0:00:01s\n","epoch 2  | loss: 690.15746| val_0_mse: 7190.18603515625|  0:00:02s\n","epoch 3  | loss: 514.06389| val_0_mse: 2959.898681640625|  0:00:02s\n","epoch 4  | loss: 468.31061| val_0_mse: 1337.32080078125|  0:00:03s\n","epoch 5  | loss: 416.39189| val_0_mse: 2107.674072265625|  0:00:04s\n","epoch 6  | loss: 396.43024| val_0_mse: 881.4342651367188|  0:00:05s\n","epoch 7  | loss: 388.8567| val_0_mse: 1908.88427734375|  0:00:05s\n","epoch 8  | loss: 387.03828| val_0_mse: 2178.63818359375|  0:00:06s\n","epoch 9  | loss: 371.22874| val_0_mse: 755.866943359375|  0:00:07s\n","epoch 10 | loss: 395.25168| val_0_mse: 1176.9490966796875|  0:00:08s\n","epoch 11 | loss: 348.78564| val_0_mse: 1434.4893798828125|  0:00:08s\n","epoch 12 | loss: 359.70342| val_0_mse: 1369.7867431640625|  0:00:09s\n","epoch 13 | loss: 345.99579| val_0_mse: 1095.936767578125|  0:00:10s\n","epoch 14 | loss: 337.25824| val_0_mse: 1160.057861328125|  0:00:11s\n","epoch 15 | loss: 327.2748| val_0_mse: 1035.4232177734375|  0:00:11s\n","epoch 16 | loss: 297.28019| val_0_mse: 755.0487060546875|  0:00:12s\n","epoch 17 | loss: 294.83831| val_0_mse: 749.3839721679688|  0:00:13s\n","epoch 18 | loss: 291.86717| val_0_mse: 768.7005615234375|  0:00:14s\n","epoch 19 | loss: 279.50688| val_0_mse: 648.55419921875|  0:00:14s\n","epoch 20 | loss: 273.61993| val_0_mse: 565.0620727539062|  0:00:15s\n","epoch 21 | loss: 281.19417| val_0_mse: 339.0957336425781|  0:00:16s\n","epoch 22 | loss: 268.93166| val_0_mse: 318.7270812988281|  0:00:17s\n","epoch 23 | loss: 246.77029| val_0_mse: 347.9879455566406|  0:00:17s\n","epoch 24 | loss: 247.50683| val_0_mse: 340.05706787109375|  0:00:18s\n","epoch 25 | loss: 246.53338| val_0_mse: 357.30694580078125|  0:00:19s\n","epoch 26 | loss: 235.88003| val_0_mse: 283.9793701171875|  0:00:20s\n","epoch 27 | loss: 227.36308| val_0_mse: 253.42417907714844|  0:00:20s\n","epoch 28 | loss: 234.36424| val_0_mse: 256.542236328125|  0:00:21s\n","epoch 29 | loss: 232.36859| val_0_mse: 268.220947265625|  0:00:22s\n","epoch 30 | loss: 229.46994| val_0_mse: 260.4586486816406|  0:00:23s\n","epoch 31 | loss: 227.94287| val_0_mse: 231.60714721679688|  0:00:23s\n","epoch 32 | loss: 215.14009| val_0_mse: 235.1290740966797|  0:00:24s\n","epoch 33 | loss: 220.56765| val_0_mse: 244.19952392578125|  0:00:25s\n","epoch 34 | loss: 215.13952| val_0_mse: 230.3282928466797|  0:00:25s\n","epoch 35 | loss: 221.48526| val_0_mse: 230.32301330566406|  0:00:26s\n","epoch 36 | loss: 218.75824| val_0_mse: 239.70541381835938|  0:00:27s\n","epoch 37 | loss: 212.09541| val_0_mse: 253.93844604492188|  0:00:28s\n","epoch 38 | loss: 218.79027| val_0_mse: 249.62916564941406|  0:00:29s\n","epoch 39 | loss: 206.74587| val_0_mse: 218.06138610839844|  0:00:29s\n","epoch 40 | loss: 214.25754| val_0_mse: 222.74041748046875|  0:00:30s\n","epoch 41 | loss: 206.5632| val_0_mse: 253.87939453125|  0:00:31s\n","epoch 42 | loss: 223.03145| val_0_mse: 228.89242553710938|  0:00:32s\n","epoch 43 | loss: 212.22226| val_0_mse: 262.1319885253906|  0:00:32s\n","epoch 44 | loss: 207.38754| val_0_mse: 201.75791931152344|  0:00:33s\n","epoch 45 | loss: 201.21768| val_0_mse: 200.34854125976562|  0:00:34s\n","epoch 46 | loss: 198.10733| val_0_mse: 196.01559448242188|  0:00:35s\n","epoch 47 | loss: 198.35924| val_0_mse: 205.49302673339844|  0:00:35s\n","epoch 48 | loss: 200.49535| val_0_mse: 197.12721252441406|  0:00:36s\n","epoch 49 | loss: 195.9178| val_0_mse: 188.8114776611328|  0:00:37s\n","epoch 50 | loss: 191.41543| val_0_mse: 197.677001953125|  0:00:37s\n","epoch 51 | loss: 191.39591| val_0_mse: 193.4732666015625|  0:00:38s\n","epoch 52 | loss: 194.85887| val_0_mse: 199.10081481933594|  0:00:39s\n","epoch 53 | loss: 198.49402| val_0_mse: 209.86822509765625|  0:00:40s\n","epoch 54 | loss: 193.56509| val_0_mse: 197.08816528320312|  0:00:41s\n","epoch 55 | loss: 199.47529| val_0_mse: 225.30868530273438|  0:00:41s\n","epoch 56 | loss: 197.85943| val_0_mse: 192.04144287109375|  0:00:42s\n","epoch 57 | loss: 187.95657| val_0_mse: 195.53977966308594|  0:00:43s\n","epoch 58 | loss: 179.82457| val_0_mse: 188.66651916503906|  0:00:44s\n","epoch 59 | loss: 186.60374| val_0_mse: 199.65512084960938|  0:00:44s\n","epoch 60 | loss: 191.91379| val_0_mse: 195.196044921875|  0:00:45s\n","epoch 61 | loss: 184.44658| val_0_mse: 188.79544067382812|  0:00:46s\n","epoch 62 | loss: 181.83567| val_0_mse: 188.64939880371094|  0:00:47s\n","epoch 63 | loss: 181.88639| val_0_mse: 195.743896484375|  0:00:47s\n","epoch 64 | loss: 183.36589| val_0_mse: 243.690673828125|  0:00:48s\n","epoch 65 | loss: 180.48065| val_0_mse: 219.4764862060547|  0:00:49s\n","epoch 66 | loss: 182.09423| val_0_mse: 192.56805419921875|  0:00:50s\n","epoch 67 | loss: 175.65903| val_0_mse: 180.87203979492188|  0:00:50s\n","epoch 68 | loss: 175.56595| val_0_mse: 207.51495361328125|  0:00:51s\n","epoch 69 | loss: 173.59344| val_0_mse: 175.496337890625|  0:00:52s\n","epoch 70 | loss: 165.60777| val_0_mse: 191.91285705566406|  0:00:52s\n","epoch 71 | loss: 168.9018| val_0_mse: 181.79786682128906|  0:00:53s\n","epoch 72 | loss: 168.60371| val_0_mse: 177.96702575683594|  0:00:54s\n","epoch 73 | loss: 171.09589| val_0_mse: 180.5235137939453|  0:00:55s\n","epoch 74 | loss: 171.77294| val_0_mse: 173.55780029296875|  0:00:55s\n","epoch 75 | loss: 166.73947| val_0_mse: 202.78648376464844|  0:00:56s\n","epoch 76 | loss: 175.38691| val_0_mse: 185.5948028564453|  0:00:57s\n","epoch 77 | loss: 171.26034| val_0_mse: 182.28317260742188|  0:00:57s\n","epoch 78 | loss: 169.79008| val_0_mse: 182.66505432128906|  0:00:58s\n","epoch 79 | loss: 165.33372| val_0_mse: 195.34512329101562|  0:00:59s\n","epoch 80 | loss: 168.09978| val_0_mse: 172.65345764160156|  0:01:00s\n","epoch 81 | loss: 166.44518| val_0_mse: 178.7393341064453|  0:01:00s\n","epoch 82 | loss: 170.12685| val_0_mse: 171.6103973388672|  0:01:01s\n","epoch 83 | loss: 163.91679| val_0_mse: 183.84254455566406|  0:01:02s\n","epoch 84 | loss: 175.93183| val_0_mse: 177.17196655273438|  0:01:02s\n","epoch 85 | loss: 170.71445| val_0_mse: 171.7519989013672|  0:01:03s\n","epoch 86 | loss: 176.47695| val_0_mse: 175.6479949951172|  0:01:04s\n","epoch 87 | loss: 174.52285| val_0_mse: 209.38087463378906|  0:01:05s\n","epoch 88 | loss: 160.57845| val_0_mse: 187.49688720703125|  0:01:05s\n","epoch 89 | loss: 156.43285| val_0_mse: 170.80099487304688|  0:01:06s\n","epoch 90 | loss: 154.43982| val_0_mse: 164.27935791015625|  0:01:07s\n","epoch 91 | loss: 149.36981| val_0_mse: 174.02684020996094|  0:01:08s\n","epoch 92 | loss: 156.52629| val_0_mse: 175.02272033691406|  0:01:08s\n","epoch 93 | loss: 157.4353| val_0_mse: 169.13467407226562|  0:01:09s\n","epoch 94 | loss: 153.34308| val_0_mse: 162.04969787597656|  0:01:10s\n","epoch 95 | loss: 152.71841| val_0_mse: 161.97750854492188|  0:01:11s\n","epoch 96 | loss: 157.90763| val_0_mse: 169.24227905273438|  0:01:11s\n","epoch 97 | loss: 146.56387| val_0_mse: 175.34556579589844|  0:01:12s\n","epoch 98 | loss: 143.64529| val_0_mse: 171.46957397460938|  0:01:13s\n","epoch 99 | loss: 147.52651| val_0_mse: 180.59693908691406|  0:01:13s\n","Stop training because you reached max_epochs = 100 with best_epoch = 95 and best_val_0_mse = 161.97750854492188\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 14:22:27,424] Trial 13 finished with value: 161.97750854492188 and parameters: {'n_d': 20, 'n_steps': 4, 'gamma': 1.5503866937438027, 'n_independent': 2, 'n_shared': 4, 'momentum': 0.2790146876702459}. Best is trial 7 with value: 146.89492797851562.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 2181.3319| val_0_mse: 3193.697509765625|  0:00:00s\n","epoch 1  | loss: 1771.6127| val_0_mse: 1413.238037109375|  0:00:01s\n","epoch 2  | loss: 1162.14428| val_0_mse: 1350.8314208984375|  0:00:02s\n","epoch 3  | loss: 562.60527| val_0_mse: 1196.566162109375|  0:00:02s\n","epoch 4  | loss: 441.25906| val_0_mse: 972.2363891601562|  0:00:03s\n","epoch 5  | loss: 374.02039| val_0_mse: 1014.3916625976562|  0:00:04s\n","epoch 6  | loss: 339.64054| val_0_mse: 975.6550903320312|  0:00:05s\n","epoch 7  | loss: 312.51423| val_0_mse: 989.3161010742188|  0:00:05s\n","epoch 8  | loss: 296.7839| val_0_mse: 1069.6202392578125|  0:00:06s\n","epoch 9  | loss: 302.76547| val_0_mse: 1594.516845703125|  0:00:07s\n","epoch 10 | loss: 283.23679| val_0_mse: 1338.798583984375|  0:00:07s\n","epoch 11 | loss: 263.97133| val_0_mse: 842.0162963867188|  0:00:08s\n","epoch 12 | loss: 259.41879| val_0_mse: 829.277099609375|  0:00:09s\n","epoch 13 | loss: 254.5601| val_0_mse: 536.937255859375|  0:00:10s\n","epoch 14 | loss: 257.05719| val_0_mse: 471.888427734375|  0:00:10s\n","epoch 15 | loss: 255.22423| val_0_mse: 647.6524047851562|  0:00:11s\n","epoch 16 | loss: 244.96509| val_0_mse: 674.7235717773438|  0:00:12s\n","epoch 17 | loss: 240.2565| val_0_mse: 534.7229614257812|  0:00:13s\n","epoch 18 | loss: 246.61088| val_0_mse: 519.1012573242188|  0:00:13s\n","epoch 19 | loss: 241.62661| val_0_mse: 581.1671142578125|  0:00:14s\n","epoch 20 | loss: 235.7523| val_0_mse: 450.5289611816406|  0:00:15s\n","epoch 21 | loss: 232.3088| val_0_mse: 400.5005187988281|  0:00:15s\n","epoch 22 | loss: 228.24954| val_0_mse: 549.4130859375|  0:00:16s\n","epoch 23 | loss: 228.21133| val_0_mse: 499.92999267578125|  0:00:17s\n","epoch 24 | loss: 218.59301| val_0_mse: 456.628173828125|  0:00:18s\n","epoch 25 | loss: 217.43522| val_0_mse: 455.05609130859375|  0:00:18s\n","epoch 26 | loss: 211.84281| val_0_mse: 418.5079650878906|  0:00:19s\n","epoch 27 | loss: 219.44508| val_0_mse: 382.5167236328125|  0:00:20s\n","epoch 28 | loss: 221.06596| val_0_mse: 276.73785400390625|  0:00:21s\n","epoch 29 | loss: 215.60481| val_0_mse: 332.2706604003906|  0:00:22s\n","epoch 30 | loss: 211.21463| val_0_mse: 423.5877685546875|  0:00:22s\n","epoch 31 | loss: 224.35949| val_0_mse: 240.34805297851562|  0:00:23s\n","epoch 32 | loss: 217.14695| val_0_mse: 233.6658935546875|  0:00:24s\n","epoch 33 | loss: 224.72134| val_0_mse: 271.8158874511719|  0:00:25s\n","epoch 34 | loss: 210.94719| val_0_mse: 324.7817077636719|  0:00:25s\n","epoch 35 | loss: 209.45479| val_0_mse: 298.1187744140625|  0:00:26s\n","epoch 36 | loss: 212.52093| val_0_mse: 289.19921875|  0:00:27s\n","epoch 37 | loss: 201.44366| val_0_mse: 245.50396728515625|  0:00:27s\n","epoch 38 | loss: 204.49521| val_0_mse: 252.0491943359375|  0:00:28s\n","epoch 39 | loss: 202.99334| val_0_mse: 238.38499450683594|  0:00:29s\n","epoch 40 | loss: 200.98083| val_0_mse: 222.09454345703125|  0:00:30s\n","epoch 41 | loss: 198.1413| val_0_mse: 244.1466827392578|  0:00:31s\n","epoch 42 | loss: 202.42845| val_0_mse: 224.87905883789062|  0:00:31s\n","epoch 43 | loss: 192.17681| val_0_mse: 252.0742645263672|  0:00:32s\n","epoch 44 | loss: 192.91007| val_0_mse: 205.25802612304688|  0:00:33s\n","epoch 45 | loss: 195.60472| val_0_mse: 275.40899658203125|  0:00:34s\n","epoch 46 | loss: 200.28308| val_0_mse: 204.3112030029297|  0:00:34s\n","epoch 47 | loss: 191.08473| val_0_mse: 202.78726196289062|  0:00:35s\n","epoch 48 | loss: 191.1599| val_0_mse: 205.87301635742188|  0:00:36s\n","epoch 49 | loss: 197.42635| val_0_mse: 203.88888549804688|  0:00:37s\n","epoch 50 | loss: 199.59052| val_0_mse: 211.43408203125|  0:00:37s\n","epoch 51 | loss: 197.0045| val_0_mse: 224.89576721191406|  0:00:38s\n","epoch 52 | loss: 196.05257| val_0_mse: 222.53515625|  0:00:39s\n","epoch 53 | loss: 199.70348| val_0_mse: 208.56199645996094|  0:00:40s\n","epoch 54 | loss: 193.30267| val_0_mse: 206.84861755371094|  0:00:40s\n","epoch 55 | loss: 188.8538| val_0_mse: 199.07940673828125|  0:00:41s\n","epoch 56 | loss: 190.40875| val_0_mse: 190.24688720703125|  0:00:42s\n","epoch 57 | loss: 183.41778| val_0_mse: 197.38710021972656|  0:00:43s\n","epoch 58 | loss: 184.65327| val_0_mse: 189.84271240234375|  0:00:43s\n","epoch 59 | loss: 178.61758| val_0_mse: 186.37388610839844|  0:00:44s\n","epoch 60 | loss: 180.83985| val_0_mse: 206.26092529296875|  0:00:45s\n","epoch 61 | loss: 181.37744| val_0_mse: 189.9319610595703|  0:00:46s\n","epoch 62 | loss: 176.90541| val_0_mse: 186.37060546875|  0:00:46s\n","epoch 63 | loss: 176.02447| val_0_mse: 189.0062255859375|  0:00:47s\n","epoch 64 | loss: 179.53302| val_0_mse: 182.46343994140625|  0:00:48s\n","epoch 65 | loss: 180.48074| val_0_mse: 183.4326934814453|  0:00:49s\n","epoch 66 | loss: 173.34609| val_0_mse: 181.56675720214844|  0:00:49s\n","epoch 67 | loss: 171.96557| val_0_mse: 181.6151580810547|  0:00:50s\n","epoch 68 | loss: 168.81219| val_0_mse: 178.8338165283203|  0:00:51s\n","epoch 69 | loss: 165.89628| val_0_mse: 191.19151306152344|  0:00:52s\n","epoch 70 | loss: 168.48832| val_0_mse: 180.89602661132812|  0:00:52s\n","epoch 71 | loss: 167.58248| val_0_mse: 179.6974334716797|  0:00:53s\n","epoch 72 | loss: 177.16781| val_0_mse: 183.5055389404297|  0:00:54s\n","epoch 73 | loss: 173.92868| val_0_mse: 182.55206298828125|  0:00:54s\n","epoch 74 | loss: 174.52811| val_0_mse: 179.6480255126953|  0:00:55s\n","epoch 75 | loss: 174.40549| val_0_mse: 191.32408142089844|  0:00:56s\n","epoch 76 | loss: 170.44158| val_0_mse: 191.22572326660156|  0:00:57s\n","epoch 77 | loss: 172.13915| val_0_mse: 178.91407775878906|  0:00:57s\n","epoch 78 | loss: 163.62483| val_0_mse: 190.80050659179688|  0:00:58s\n","\n","Early stopping occurred at epoch 78 with best_epoch = 68 and best_val_0_mse = 178.8338165283203\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 14:23:26,518] Trial 14 finished with value: 178.8338165283203 and parameters: {'n_d': 9, 'n_steps': 4, 'gamma': 1.5218005716969898, 'n_independent': 2, 'n_shared': 4, 'momentum': 0.2276897004338601}. Best is trial 7 with value: 146.89492797851562.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 2092.5651| val_0_mse: 1248.1971435546875|  0:00:00s\n","epoch 1  | loss: 1201.97567| val_0_mse: 1577.6568603515625|  0:00:00s\n","epoch 2  | loss: 505.90071| val_0_mse: 3046.1953125|  0:00:01s\n","epoch 3  | loss: 395.57056| val_0_mse: 1315.8553466796875|  0:00:01s\n","epoch 4  | loss: 349.33601| val_0_mse: 827.3897094726562|  0:00:02s\n","epoch 5  | loss: 328.8976| val_0_mse: 677.4013061523438|  0:00:02s\n","epoch 6  | loss: 299.99194| val_0_mse: 823.515625|  0:00:02s\n","epoch 7  | loss: 286.86741| val_0_mse: 598.4093017578125|  0:00:03s\n","epoch 8  | loss: 274.73853| val_0_mse: 1790.3348388671875|  0:00:03s\n","epoch 9  | loss: 263.91766| val_0_mse: 1912.7354736328125|  0:00:04s\n","epoch 10 | loss: 258.90449| val_0_mse: 1155.1951904296875|  0:00:04s\n","epoch 11 | loss: 253.11314| val_0_mse: 920.6395263671875|  0:00:04s\n","epoch 12 | loss: 257.08685| val_0_mse: 510.0058288574219|  0:00:05s\n","epoch 13 | loss: 247.8282| val_0_mse: 571.0856323242188|  0:00:05s\n","epoch 14 | loss: 245.32988| val_0_mse: 481.9664001464844|  0:00:06s\n","epoch 15 | loss: 231.58795| val_0_mse: 398.6636657714844|  0:00:06s\n","epoch 16 | loss: 232.13444| val_0_mse: 311.8823547363281|  0:00:06s\n","epoch 17 | loss: 221.38604| val_0_mse: 386.7333068847656|  0:00:07s\n","epoch 18 | loss: 219.55551| val_0_mse: 367.7067565917969|  0:00:07s\n","epoch 19 | loss: 224.58601| val_0_mse: 337.271728515625|  0:00:08s\n","epoch 20 | loss: 209.69568| val_0_mse: 294.50555419921875|  0:00:08s\n","epoch 21 | loss: 221.25933| val_0_mse: 356.3019714355469|  0:00:09s\n","epoch 22 | loss: 217.44068| val_0_mse: 286.1805725097656|  0:00:09s\n","epoch 23 | loss: 210.60537| val_0_mse: 282.6418762207031|  0:00:10s\n","epoch 24 | loss: 202.7202| val_0_mse: 261.22540283203125|  0:00:10s\n","epoch 25 | loss: 198.1715| val_0_mse: 258.98052978515625|  0:00:10s\n","epoch 26 | loss: 203.7544| val_0_mse: 235.11691284179688|  0:00:11s\n","epoch 27 | loss: 202.36533| val_0_mse: 293.2760925292969|  0:00:11s\n","epoch 28 | loss: 199.52014| val_0_mse: 252.02874755859375|  0:00:12s\n","epoch 29 | loss: 195.25657| val_0_mse: 218.6078338623047|  0:00:12s\n","epoch 30 | loss: 184.39965| val_0_mse: 245.3336944580078|  0:00:13s\n","epoch 31 | loss: 188.45988| val_0_mse: 222.6701202392578|  0:00:13s\n","epoch 32 | loss: 191.19405| val_0_mse: 207.17518615722656|  0:00:13s\n","epoch 33 | loss: 198.51767| val_0_mse: 227.15928649902344|  0:00:14s\n","epoch 34 | loss: 203.37537| val_0_mse: 212.10487365722656|  0:00:14s\n","epoch 35 | loss: 186.11922| val_0_mse: 202.71273803710938|  0:00:15s\n","epoch 36 | loss: 185.79786| val_0_mse: 218.36044311523438|  0:00:15s\n","epoch 37 | loss: 186.35378| val_0_mse: 197.2677459716797|  0:00:16s\n","epoch 38 | loss: 181.38546| val_0_mse: 208.70640563964844|  0:00:16s\n","epoch 39 | loss: 185.51953| val_0_mse: 201.41018676757812|  0:00:16s\n","epoch 40 | loss: 180.13888| val_0_mse: 192.06117248535156|  0:00:17s\n","epoch 41 | loss: 180.63005| val_0_mse: 238.4795379638672|  0:00:17s\n","epoch 42 | loss: 171.47372| val_0_mse: 186.25965881347656|  0:00:18s\n","epoch 43 | loss: 175.76711| val_0_mse: 210.4854736328125|  0:00:18s\n","epoch 44 | loss: 185.38302| val_0_mse: 198.37738037109375|  0:00:18s\n","epoch 45 | loss: 181.41949| val_0_mse: 197.1929931640625|  0:00:19s\n","epoch 46 | loss: 174.91664| val_0_mse: 188.62498474121094|  0:00:19s\n","epoch 47 | loss: 173.25271| val_0_mse: 189.6576385498047|  0:00:20s\n","epoch 48 | loss: 177.61126| val_0_mse: 191.68679809570312|  0:00:20s\n","epoch 49 | loss: 172.94021| val_0_mse: 183.46185302734375|  0:00:21s\n","epoch 50 | loss: 168.68252| val_0_mse: 194.9079132080078|  0:00:21s\n","epoch 51 | loss: 173.82311| val_0_mse: 181.5837860107422|  0:00:21s\n","epoch 52 | loss: 176.03145| val_0_mse: 188.4429931640625|  0:00:22s\n","epoch 53 | loss: 175.66466| val_0_mse: 189.42645263671875|  0:00:22s\n","epoch 54 | loss: 168.79414| val_0_mse: 190.57391357421875|  0:00:23s\n","epoch 55 | loss: 161.1603| val_0_mse: 171.1567840576172|  0:00:23s\n","epoch 56 | loss: 165.19944| val_0_mse: 181.141845703125|  0:00:24s\n","epoch 57 | loss: 163.78428| val_0_mse: 186.4870147705078|  0:00:24s\n","epoch 58 | loss: 163.78974| val_0_mse: 182.23214721679688|  0:00:24s\n","epoch 59 | loss: 164.56975| val_0_mse: 181.67103576660156|  0:00:25s\n","epoch 60 | loss: 168.19785| val_0_mse: 209.21693420410156|  0:00:25s\n","epoch 61 | loss: 169.04221| val_0_mse: 201.3915252685547|  0:00:26s\n","epoch 62 | loss: 175.09527| val_0_mse: 171.91737365722656|  0:00:26s\n","epoch 63 | loss: 169.334 | val_0_mse: 199.1869659423828|  0:00:27s\n","epoch 64 | loss: 168.96626| val_0_mse: 219.46661376953125|  0:00:27s\n","epoch 65 | loss: 180.91476| val_0_mse: 193.1732177734375|  0:00:27s\n","\n","Early stopping occurred at epoch 65 with best_epoch = 55 and best_val_0_mse = 171.1567840576172\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 14:23:54,726] Trial 15 finished with value: 171.1567840576172 and parameters: {'n_d': 28, 'n_steps': 3, 'gamma': 1.8550514932237148, 'n_independent': 1, 'n_shared': 2, 'momentum': 0.2725386493538941}. Best is trial 7 with value: 146.89492797851562.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 2176.95283| val_0_mse: 2914.0322265625|  0:00:00s\n","epoch 1  | loss: 1762.13717| val_0_mse: 2797.736328125|  0:00:01s\n","epoch 2  | loss: 1132.95606| val_0_mse: 2512.7431640625|  0:00:02s\n","epoch 3  | loss: 537.80733| val_0_mse: 2177.782958984375|  0:00:02s\n","epoch 4  | loss: 423.5661| val_0_mse: 1111.9901123046875|  0:00:03s\n","epoch 5  | loss: 407.39264| val_0_mse: 1385.72314453125|  0:00:04s\n","epoch 6  | loss: 377.26003| val_0_mse: 1439.8016357421875|  0:00:04s\n","epoch 7  | loss: 359.68222| val_0_mse: 721.6915283203125|  0:00:05s\n","epoch 8  | loss: 324.87673| val_0_mse: 858.7977294921875|  0:00:06s\n","epoch 9  | loss: 312.89946| val_0_mse: 540.9371948242188|  0:00:07s\n","epoch 10 | loss: 303.39784| val_0_mse: 578.7651977539062|  0:00:07s\n","epoch 11 | loss: 292.22487| val_0_mse: 958.3322143554688|  0:00:08s\n","epoch 12 | loss: 282.24342| val_0_mse: 692.42138671875|  0:00:09s\n","epoch 13 | loss: 287.42209| val_0_mse: 705.5891723632812|  0:00:10s\n","epoch 14 | loss: 290.73312| val_0_mse: 577.2666625976562|  0:00:10s\n","epoch 15 | loss: 277.8256| val_0_mse: 924.496826171875|  0:00:11s\n","epoch 16 | loss: 257.9765| val_0_mse: 780.8307495117188|  0:00:12s\n","epoch 17 | loss: 273.03217| val_0_mse: 730.04736328125|  0:00:12s\n","epoch 18 | loss: 257.03583| val_0_mse: 554.4655151367188|  0:00:13s\n","epoch 19 | loss: 237.71577| val_0_mse: 697.1405029296875|  0:00:14s\n","\n","Early stopping occurred at epoch 19 with best_epoch = 9 and best_val_0_mse = 540.9371948242188\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 14:24:09,474] Trial 16 finished with value: 540.9371948242188 and parameters: {'n_d': 14, 'n_steps': 4, 'gamma': 1.3607110768956323, 'n_independent': 2, 'n_shared': 4, 'momentum': 0.14831496708308284}. Best is trial 7 with value: 146.89492797851562.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 1950.37831| val_0_mse: 11234.0390625|  0:00:00s\n","epoch 1  | loss: 833.30495| val_0_mse: 3494.193359375|  0:00:01s\n","epoch 2  | loss: 407.6842| val_0_mse: 1251.50048828125|  0:00:01s\n","epoch 3  | loss: 359.97713| val_0_mse: 844.861572265625|  0:00:02s\n","epoch 4  | loss: 349.71231| val_0_mse: 1025.183349609375|  0:00:02s\n","epoch 5  | loss: 323.58368| val_0_mse: 591.7859497070312|  0:00:03s\n","epoch 6  | loss: 313.19718| val_0_mse: 757.009033203125|  0:00:04s\n","epoch 7  | loss: 301.10709| val_0_mse: 544.4185791015625|  0:00:04s\n","epoch 8  | loss: 277.20389| val_0_mse: 561.8578491210938|  0:00:05s\n","epoch 9  | loss: 273.53099| val_0_mse: 458.97705078125|  0:00:05s\n","epoch 10 | loss: 254.03729| val_0_mse: 634.3715209960938|  0:00:06s\n","epoch 11 | loss: 256.21085| val_0_mse: 491.7795715332031|  0:00:07s\n","epoch 12 | loss: 262.70385| val_0_mse: 497.3204040527344|  0:00:07s\n","epoch 13 | loss: 250.14403| val_0_mse: 462.3031311035156|  0:00:08s\n","epoch 14 | loss: 235.41555| val_0_mse: 339.5980529785156|  0:00:08s\n","epoch 15 | loss: 230.00276| val_0_mse: 341.0190124511719|  0:00:09s\n","epoch 16 | loss: 225.89464| val_0_mse: 311.4601745605469|  0:00:09s\n","epoch 17 | loss: 219.2661| val_0_mse: 338.1640930175781|  0:00:10s\n","epoch 18 | loss: 212.0157| val_0_mse: 356.7853698730469|  0:00:10s\n","epoch 19 | loss: 215.96106| val_0_mse: 275.1445617675781|  0:00:11s\n","epoch 20 | loss: 203.6407| val_0_mse: 265.2423095703125|  0:00:12s\n","epoch 21 | loss: 214.6688| val_0_mse: 288.1706237792969|  0:00:12s\n","epoch 22 | loss: 216.93589| val_0_mse: 272.74896240234375|  0:00:13s\n","epoch 23 | loss: 222.13347| val_0_mse: 279.0274353027344|  0:00:13s\n","epoch 24 | loss: 218.51181| val_0_mse: 235.39735412597656|  0:00:14s\n","epoch 25 | loss: 213.887 | val_0_mse: 237.8916473388672|  0:00:14s\n","epoch 26 | loss: 201.76482| val_0_mse: 218.65701293945312|  0:00:15s\n","epoch 27 | loss: 209.08664| val_0_mse: 259.9832458496094|  0:00:16s\n","epoch 28 | loss: 204.79341| val_0_mse: 252.56065368652344|  0:00:16s\n","epoch 29 | loss: 199.69306| val_0_mse: 217.3365936279297|  0:00:17s\n","epoch 30 | loss: 189.62761| val_0_mse: 214.12806701660156|  0:00:17s\n","epoch 31 | loss: 192.83031| val_0_mse: 203.17416381835938|  0:00:18s\n","epoch 32 | loss: 197.73687| val_0_mse: 212.85150146484375|  0:00:18s\n","epoch 33 | loss: 195.94402| val_0_mse: 205.21485900878906|  0:00:19s\n","epoch 34 | loss: 208.99289| val_0_mse: 203.95823669433594|  0:00:19s\n","epoch 35 | loss: 198.72124| val_0_mse: 218.8259735107422|  0:00:20s\n","epoch 36 | loss: 192.74024| val_0_mse: 221.5930633544922|  0:00:21s\n","epoch 37 | loss: 189.88949| val_0_mse: 189.39381408691406|  0:00:21s\n","epoch 38 | loss: 182.10193| val_0_mse: 196.12860107421875|  0:00:22s\n","epoch 39 | loss: 191.43154| val_0_mse: 198.05812072753906|  0:00:22s\n","epoch 40 | loss: 193.42776| val_0_mse: 207.36082458496094|  0:00:23s\n","epoch 41 | loss: 187.89054| val_0_mse: 231.60202026367188|  0:00:23s\n","epoch 42 | loss: 189.63287| val_0_mse: 220.17347717285156|  0:00:24s\n","epoch 43 | loss: 184.36124| val_0_mse: 197.15969848632812|  0:00:25s\n","epoch 44 | loss: 176.29293| val_0_mse: 201.6851348876953|  0:00:25s\n","epoch 45 | loss: 174.9531| val_0_mse: 200.38075256347656|  0:00:26s\n","epoch 46 | loss: 176.87036| val_0_mse: 187.68215942382812|  0:00:26s\n","epoch 47 | loss: 182.9991| val_0_mse: 208.062744140625|  0:00:27s\n","epoch 48 | loss: 196.52918| val_0_mse: 191.15269470214844|  0:00:27s\n","epoch 49 | loss: 186.7244| val_0_mse: 193.56382751464844|  0:00:28s\n","epoch 50 | loss: 182.31647| val_0_mse: 188.35498046875|  0:00:29s\n","epoch 51 | loss: 180.73296| val_0_mse: 177.34243774414062|  0:00:29s\n","epoch 52 | loss: 177.8393| val_0_mse: 183.43765258789062|  0:00:30s\n","epoch 53 | loss: 168.53729| val_0_mse: 188.70968627929688|  0:00:30s\n","epoch 54 | loss: 172.84972| val_0_mse: 181.39364624023438|  0:00:31s\n","epoch 55 | loss: 169.53577| val_0_mse: 199.93511962890625|  0:00:32s\n","epoch 56 | loss: 179.16879| val_0_mse: 187.04733276367188|  0:00:32s\n","epoch 57 | loss: 178.36749| val_0_mse: 183.13551330566406|  0:00:33s\n","epoch 58 | loss: 173.533 | val_0_mse: 172.528564453125|  0:00:33s\n","epoch 59 | loss: 173.59878| val_0_mse: 184.9229736328125|  0:00:34s\n","epoch 60 | loss: 174.29816| val_0_mse: 186.76365661621094|  0:00:34s\n","epoch 61 | loss: 170.81646| val_0_mse: 172.8354034423828|  0:00:35s\n","epoch 62 | loss: 174.23767| val_0_mse: 174.41659545898438|  0:00:35s\n","epoch 63 | loss: 184.70256| val_0_mse: 193.67672729492188|  0:00:36s\n","epoch 64 | loss: 174.89752| val_0_mse: 187.39520263671875|  0:00:37s\n","epoch 65 | loss: 173.34309| val_0_mse: 199.82217407226562|  0:00:37s\n","epoch 66 | loss: 183.63619| val_0_mse: 191.4093780517578|  0:00:38s\n","epoch 67 | loss: 172.56907| val_0_mse: 203.00784301757812|  0:00:38s\n","epoch 68 | loss: 170.35881| val_0_mse: 174.90565490722656|  0:00:39s\n","\n","Early stopping occurred at epoch 68 with best_epoch = 58 and best_val_0_mse = 172.528564453125\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 14:24:49,419] Trial 17 finished with value: 172.528564453125 and parameters: {'n_d': 25, 'n_steps': 4, 'gamma': 1.2003224923454505, 'n_independent': 3, 'n_shared': 1, 'momentum': 0.23981785905237335}. Best is trial 7 with value: 146.89492797851562.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 2002.57997| val_0_mse: 7201.69287109375|  0:00:00s\n","epoch 1  | loss: 1496.18051| val_0_mse: 5447.08740234375|  0:00:01s\n","epoch 2  | loss: 997.94999| val_0_mse: 7765.173828125|  0:00:02s\n","epoch 3  | loss: 723.36322| val_0_mse: 3088.282958984375|  0:00:03s\n","epoch 4  | loss: 601.38827| val_0_mse: 1442.757568359375|  0:00:03s\n","epoch 5  | loss: 541.42249| val_0_mse: 4267.73046875|  0:00:04s\n","epoch 6  | loss: 528.3341| val_0_mse: 2122.565185546875|  0:00:05s\n","epoch 7  | loss: 516.76677| val_0_mse: 976.121826171875|  0:00:06s\n","epoch 8  | loss: 485.34511| val_0_mse: 808.1022338867188|  0:00:06s\n","epoch 9  | loss: 481.71516| val_0_mse: 811.2283935546875|  0:00:07s\n","epoch 10 | loss: 440.15916| val_0_mse: 840.4714965820312|  0:00:08s\n","epoch 11 | loss: 433.64124| val_0_mse: 664.7573852539062|  0:00:09s\n","epoch 12 | loss: 424.98178| val_0_mse: 629.9127197265625|  0:00:10s\n","epoch 13 | loss: 422.33409| val_0_mse: 590.8428955078125|  0:00:10s\n","epoch 14 | loss: 406.29802| val_0_mse: 510.08697509765625|  0:00:11s\n","epoch 15 | loss: 392.74281| val_0_mse: 523.31689453125|  0:00:12s\n","epoch 16 | loss: 389.37925| val_0_mse: 561.6420288085938|  0:00:13s\n","epoch 17 | loss: 390.73237| val_0_mse: 903.2963256835938|  0:00:13s\n","epoch 18 | loss: 393.41047| val_0_mse: 573.2041015625|  0:00:14s\n","epoch 19 | loss: 381.22501| val_0_mse: 676.8968505859375|  0:00:15s\n","epoch 20 | loss: 366.91054| val_0_mse: 573.5859375|  0:00:16s\n","epoch 21 | loss: 354.50864| val_0_mse: 630.4450073242188|  0:00:17s\n","epoch 22 | loss: 367.02844| val_0_mse: 433.2477722167969|  0:00:17s\n","epoch 23 | loss: 347.00902| val_0_mse: 388.0565490722656|  0:00:18s\n","epoch 24 | loss: 359.16018| val_0_mse: 449.633544921875|  0:00:19s\n","epoch 25 | loss: 350.00209| val_0_mse: 400.4095153808594|  0:00:20s\n","epoch 26 | loss: 323.04859| val_0_mse: 332.38922119140625|  0:00:20s\n","epoch 27 | loss: 290.31467| val_0_mse: 312.8453369140625|  0:00:21s\n","epoch 28 | loss: 313.51907| val_0_mse: 417.55291748046875|  0:00:22s\n","epoch 29 | loss: 296.47708| val_0_mse: 329.5729064941406|  0:00:23s\n","epoch 30 | loss: 290.99517| val_0_mse: 369.0257568359375|  0:00:23s\n","epoch 31 | loss: 295.096 | val_0_mse: 278.8983154296875|  0:00:24s\n","epoch 32 | loss: 283.9978| val_0_mse: 279.8147888183594|  0:00:25s\n","epoch 33 | loss: 280.80589| val_0_mse: 276.1795349121094|  0:00:26s\n","epoch 34 | loss: 267.1561| val_0_mse: 265.2673645019531|  0:00:27s\n","epoch 35 | loss: 275.17749| val_0_mse: 311.8507385253906|  0:00:27s\n","epoch 36 | loss: 267.30702| val_0_mse: 256.4497985839844|  0:00:28s\n","epoch 37 | loss: 261.26732| val_0_mse: 263.43450927734375|  0:00:29s\n","epoch 38 | loss: 257.23642| val_0_mse: 242.4431610107422|  0:00:30s\n","epoch 39 | loss: 254.21157| val_0_mse: 251.5111541748047|  0:00:30s\n","epoch 40 | loss: 253.95851| val_0_mse: 245.77842712402344|  0:00:31s\n","epoch 41 | loss: 241.97957| val_0_mse: 244.70376586914062|  0:00:32s\n","epoch 42 | loss: 248.33328| val_0_mse: 242.1703338623047|  0:00:33s\n","epoch 43 | loss: 238.8549| val_0_mse: 246.30215454101562|  0:00:34s\n","epoch 44 | loss: 237.15698| val_0_mse: 235.90841674804688|  0:00:34s\n","epoch 45 | loss: 236.52512| val_0_mse: 229.88595581054688|  0:00:35s\n","epoch 46 | loss: 234.05669| val_0_mse: 228.6846923828125|  0:00:36s\n","epoch 47 | loss: 235.44832| val_0_mse: 227.4203643798828|  0:00:37s\n","epoch 48 | loss: 232.91845| val_0_mse: 240.28489685058594|  0:00:37s\n","epoch 49 | loss: 236.5736| val_0_mse: 268.16680908203125|  0:00:38s\n","epoch 50 | loss: 232.87299| val_0_mse: 227.91903686523438|  0:00:39s\n","epoch 51 | loss: 237.50615| val_0_mse: 228.17965698242188|  0:00:40s\n","epoch 52 | loss: 250.28505| val_0_mse: 226.3047637939453|  0:00:41s\n","epoch 53 | loss: 242.56067| val_0_mse: 235.84071350097656|  0:00:41s\n","epoch 54 | loss: 235.67897| val_0_mse: 261.8338928222656|  0:00:42s\n","epoch 55 | loss: 249.61004| val_0_mse: 236.74693298339844|  0:00:43s\n","epoch 56 | loss: 231.94907| val_0_mse: 223.78431701660156|  0:00:44s\n","epoch 57 | loss: 227.77228| val_0_mse: 226.3875274658203|  0:00:44s\n","epoch 58 | loss: 220.59903| val_0_mse: 213.1809844970703|  0:00:45s\n","epoch 59 | loss: 220.27798| val_0_mse: 223.67593383789062|  0:00:46s\n","epoch 60 | loss: 229.34409| val_0_mse: 225.6396942138672|  0:00:47s\n","epoch 61 | loss: 227.18263| val_0_mse: 228.218505859375|  0:00:47s\n","epoch 62 | loss: 232.06229| val_0_mse: 224.11306762695312|  0:00:48s\n","epoch 63 | loss: 223.75401| val_0_mse: 211.42913818359375|  0:00:49s\n","epoch 64 | loss: 219.07271| val_0_mse: 203.53872680664062|  0:00:50s\n","epoch 65 | loss: 208.12667| val_0_mse: 205.21163940429688|  0:00:50s\n","epoch 66 | loss: 213.44541| val_0_mse: 211.00941467285156|  0:00:51s\n","epoch 67 | loss: 210.6129| val_0_mse: 201.29977416992188|  0:00:52s\n","epoch 68 | loss: 204.4481| val_0_mse: 221.9323272705078|  0:00:53s\n","epoch 69 | loss: 204.64516| val_0_mse: 199.17164611816406|  0:00:54s\n","epoch 70 | loss: 201.20028| val_0_mse: 200.190673828125|  0:00:54s\n","epoch 71 | loss: 206.89661| val_0_mse: 200.9511260986328|  0:00:55s\n","epoch 72 | loss: 195.98079| val_0_mse: 204.5660858154297|  0:00:56s\n","epoch 73 | loss: 194.10399| val_0_mse: 200.5413055419922|  0:00:57s\n","epoch 74 | loss: 191.81163| val_0_mse: 191.7247772216797|  0:00:58s\n","epoch 75 | loss: 189.80896| val_0_mse: 200.2520751953125|  0:00:58s\n","epoch 76 | loss: 196.06474| val_0_mse: 197.96380615234375|  0:00:59s\n","epoch 77 | loss: 195.01493| val_0_mse: 186.57745361328125|  0:01:00s\n","epoch 78 | loss: 186.04872| val_0_mse: 199.77975463867188|  0:01:01s\n","epoch 79 | loss: 186.51066| val_0_mse: 194.61802673339844|  0:01:01s\n","epoch 80 | loss: 188.57475| val_0_mse: 204.95936584472656|  0:01:02s\n","epoch 81 | loss: 193.20797| val_0_mse: 189.95828247070312|  0:01:03s\n","epoch 82 | loss: 186.03767| val_0_mse: 187.55325317382812|  0:01:04s\n","epoch 83 | loss: 184.93759| val_0_mse: 182.36099243164062|  0:01:04s\n","epoch 84 | loss: 175.01768| val_0_mse: 188.29544067382812|  0:01:05s\n","epoch 85 | loss: 177.79521| val_0_mse: 191.76426696777344|  0:01:06s\n","epoch 86 | loss: 184.41816| val_0_mse: 187.5702667236328|  0:01:07s\n","epoch 87 | loss: 182.34363| val_0_mse: 189.86001586914062|  0:01:08s\n","epoch 88 | loss: 181.51309| val_0_mse: 190.3916473388672|  0:01:08s\n","epoch 89 | loss: 180.53059| val_0_mse: 197.56689453125|  0:01:09s\n","epoch 90 | loss: 179.34523| val_0_mse: 187.9330596923828|  0:01:10s\n","epoch 91 | loss: 178.51257| val_0_mse: 184.57345581054688|  0:01:11s\n","epoch 92 | loss: 177.5732| val_0_mse: 206.426513671875|  0:01:12s\n","epoch 93 | loss: 189.76721| val_0_mse: 208.6666259765625|  0:01:12s\n","\n","Early stopping occurred at epoch 93 with best_epoch = 83 and best_val_0_mse = 182.36099243164062\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 14:26:02,794] Trial 18 finished with value: 182.3610076904297 and parameters: {'n_d': 17, 'n_steps': 6, 'gamma': 1.5973266022922363, 'n_independent': 1, 'n_shared': 3, 'momentum': 0.33136498071992454}. Best is trial 7 with value: 146.89492797851562.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 1968.79252| val_0_mse: 8615.904296875|  0:00:00s\n","epoch 1  | loss: 977.49368| val_0_mse: 11157.0478515625|  0:00:01s\n","epoch 2  | loss: 616.19844| val_0_mse: 6807.73974609375|  0:00:02s\n","epoch 3  | loss: 534.91994| val_0_mse: 3073.629150390625|  0:00:02s\n","epoch 4  | loss: 481.06826| val_0_mse: 4728.91455078125|  0:00:03s\n","epoch 5  | loss: 413.32555| val_0_mse: 2728.29931640625|  0:00:04s\n","epoch 6  | loss: 377.04219| val_0_mse: 1424.5284423828125|  0:00:05s\n","epoch 7  | loss: 337.86483| val_0_mse: 3037.76904296875|  0:00:06s\n","epoch 8  | loss: 334.08905| val_0_mse: 977.8590698242188|  0:00:06s\n","epoch 9  | loss: 294.84275| val_0_mse: 3928.304931640625|  0:00:07s\n","epoch 10 | loss: 270.79759| val_0_mse: 2106.381103515625|  0:00:08s\n","epoch 11 | loss: 266.10885| val_0_mse: 1046.7227783203125|  0:00:08s\n","epoch 12 | loss: 271.94855| val_0_mse: 1264.698486328125|  0:00:09s\n","epoch 13 | loss: 252.486 | val_0_mse: 1166.995361328125|  0:00:10s\n","epoch 14 | loss: 236.5961| val_0_mse: 2242.051025390625|  0:00:11s\n","epoch 15 | loss: 235.34273| val_0_mse: 1210.24072265625|  0:00:11s\n","epoch 16 | loss: 244.03476| val_0_mse: 1601.1441650390625|  0:00:12s\n","epoch 17 | loss: 242.1905| val_0_mse: 737.3370971679688|  0:00:13s\n","epoch 18 | loss: 243.08897| val_0_mse: 540.8001708984375|  0:00:14s\n","epoch 19 | loss: 230.36496| val_0_mse: 785.2977294921875|  0:00:14s\n","epoch 20 | loss: 228.22047| val_0_mse: 606.8980712890625|  0:00:15s\n","epoch 21 | loss: 229.51108| val_0_mse: 370.7295227050781|  0:00:16s\n","epoch 22 | loss: 218.7054| val_0_mse: 335.4866638183594|  0:00:17s\n","epoch 23 | loss: 220.70794| val_0_mse: 282.4127502441406|  0:00:17s\n","epoch 24 | loss: 216.73123| val_0_mse: 288.95367431640625|  0:00:18s\n","epoch 25 | loss: 218.71982| val_0_mse: 288.6904602050781|  0:00:19s\n","epoch 26 | loss: 214.1539| val_0_mse: 222.95884704589844|  0:00:20s\n","epoch 27 | loss: 205.69936| val_0_mse: 232.32174682617188|  0:00:20s\n","epoch 28 | loss: 203.26225| val_0_mse: 280.19415283203125|  0:00:21s\n","epoch 29 | loss: 201.03132| val_0_mse: 225.2023468017578|  0:00:22s\n","epoch 30 | loss: 211.25808| val_0_mse: 260.55487060546875|  0:00:23s\n","epoch 31 | loss: 225.81387| val_0_mse: 253.6279754638672|  0:00:23s\n","epoch 32 | loss: 210.45404| val_0_mse: 225.85845947265625|  0:00:24s\n","epoch 33 | loss: 207.76413| val_0_mse: 217.05186462402344|  0:00:25s\n","epoch 34 | loss: 200.67329| val_0_mse: 202.02398681640625|  0:00:26s\n","epoch 35 | loss: 202.27595| val_0_mse: 214.95863342285156|  0:00:27s\n","epoch 36 | loss: 203.81265| val_0_mse: 237.6345672607422|  0:00:27s\n","epoch 37 | loss: 209.24274| val_0_mse: 219.94932556152344|  0:00:28s\n","epoch 38 | loss: 200.85882| val_0_mse: 213.96969604492188|  0:00:29s\n","epoch 39 | loss: 191.80547| val_0_mse: 195.76620483398438|  0:00:30s\n","epoch 40 | loss: 190.39636| val_0_mse: 210.3350067138672|  0:00:30s\n","epoch 41 | loss: 193.21116| val_0_mse: 201.52647399902344|  0:00:31s\n","epoch 42 | loss: 191.27611| val_0_mse: 195.36302185058594|  0:00:32s\n","epoch 43 | loss: 184.85484| val_0_mse: 188.27801513671875|  0:00:33s\n","epoch 44 | loss: 186.94837| val_0_mse: 208.5677947998047|  0:00:33s\n","epoch 45 | loss: 184.11494| val_0_mse: 195.5975341796875|  0:00:34s\n","epoch 46 | loss: 180.88253| val_0_mse: 190.1239471435547|  0:00:35s\n","epoch 47 | loss: 181.26105| val_0_mse: 183.66311645507812|  0:00:35s\n","epoch 48 | loss: 178.14181| val_0_mse: 185.634033203125|  0:00:36s\n","epoch 49 | loss: 178.16027| val_0_mse: 188.58380126953125|  0:00:37s\n","epoch 50 | loss: 182.86685| val_0_mse: 195.9371795654297|  0:00:38s\n","epoch 51 | loss: 169.54068| val_0_mse: 191.76608276367188|  0:00:38s\n","epoch 52 | loss: 171.39485| val_0_mse: 183.54254150390625|  0:00:39s\n","epoch 53 | loss: 168.97375| val_0_mse: 194.79266357421875|  0:00:40s\n","epoch 54 | loss: 180.48456| val_0_mse: 201.3689727783203|  0:00:41s\n","epoch 55 | loss: 176.30778| val_0_mse: 238.35581970214844|  0:00:41s\n","epoch 56 | loss: 172.08024| val_0_mse: 184.65640258789062|  0:00:42s\n","epoch 57 | loss: 168.24931| val_0_mse: 182.45994567871094|  0:00:43s\n","epoch 58 | loss: 173.66083| val_0_mse: 192.49188232421875|  0:00:44s\n","epoch 59 | loss: 171.26028| val_0_mse: 191.0889434814453|  0:00:44s\n","epoch 60 | loss: 166.36032| val_0_mse: 179.73092651367188|  0:00:45s\n","epoch 61 | loss: 165.14194| val_0_mse: 184.00340270996094|  0:00:46s\n","epoch 62 | loss: 159.22647| val_0_mse: 175.1595458984375|  0:00:47s\n","epoch 63 | loss: 161.69013| val_0_mse: 169.4369659423828|  0:00:47s\n","epoch 64 | loss: 165.23807| val_0_mse: 209.83114624023438|  0:00:48s\n","epoch 65 | loss: 166.42305| val_0_mse: 170.33770751953125|  0:00:49s\n","epoch 66 | loss: 161.46189| val_0_mse: 195.23635864257812|  0:00:49s\n","epoch 67 | loss: 162.99181| val_0_mse: 179.8261260986328|  0:00:50s\n","epoch 68 | loss: 161.70649| val_0_mse: 192.00933837890625|  0:00:51s\n","epoch 69 | loss: 158.74229| val_0_mse: 169.0714569091797|  0:00:52s\n","epoch 70 | loss: 164.07025| val_0_mse: 195.34530639648438|  0:00:53s\n","epoch 71 | loss: 163.69181| val_0_mse: 178.2020263671875|  0:00:53s\n","epoch 72 | loss: 162.26122| val_0_mse: 193.55711364746094|  0:00:54s\n","epoch 73 | loss: 162.20386| val_0_mse: 174.8672637939453|  0:00:55s\n","epoch 74 | loss: 159.06643| val_0_mse: 195.2719268798828|  0:00:56s\n","epoch 75 | loss: 155.4464| val_0_mse: 183.37196350097656|  0:00:56s\n","epoch 76 | loss: 160.42285| val_0_mse: 183.32681274414062|  0:00:57s\n","epoch 77 | loss: 157.34457| val_0_mse: 176.8273468017578|  0:00:58s\n","epoch 78 | loss: 153.16081| val_0_mse: 167.3894500732422|  0:00:58s\n","epoch 79 | loss: 152.16753| val_0_mse: 203.6013946533203|  0:00:59s\n","epoch 80 | loss: 149.62206| val_0_mse: 167.53665161132812|  0:01:00s\n","epoch 81 | loss: 146.00985| val_0_mse: 175.93679809570312|  0:01:01s\n","epoch 82 | loss: 155.8797| val_0_mse: 181.29702758789062|  0:01:01s\n","epoch 83 | loss: 155.78677| val_0_mse: 195.25860595703125|  0:01:02s\n","epoch 84 | loss: 163.33029| val_0_mse: 170.96377563476562|  0:01:03s\n","epoch 85 | loss: 154.20138| val_0_mse: 161.3240509033203|  0:01:04s\n","epoch 86 | loss: 153.44359| val_0_mse: 160.609130859375|  0:01:04s\n","epoch 87 | loss: 148.27334| val_0_mse: 164.22557067871094|  0:01:05s\n","epoch 88 | loss: 143.8026| val_0_mse: 172.38926696777344|  0:01:06s\n","epoch 89 | loss: 144.85409| val_0_mse: 171.7405242919922|  0:01:07s\n","epoch 90 | loss: 143.35975| val_0_mse: 154.43093872070312|  0:01:07s\n","epoch 91 | loss: 142.38114| val_0_mse: 160.92935180664062|  0:01:08s\n","epoch 92 | loss: 144.16108| val_0_mse: 171.3360137939453|  0:01:09s\n","epoch 93 | loss: 144.22058| val_0_mse: 169.0391845703125|  0:01:10s\n","epoch 94 | loss: 145.47092| val_0_mse: 179.67518615722656|  0:01:10s\n","epoch 95 | loss: 145.66988| val_0_mse: 157.05909729003906|  0:01:11s\n","epoch 96 | loss: 144.81653| val_0_mse: 187.27987670898438|  0:01:12s\n","epoch 97 | loss: 147.88331| val_0_mse: 154.39736938476562|  0:01:12s\n","epoch 98 | loss: 143.37191| val_0_mse: 160.73048400878906|  0:01:13s\n","epoch 99 | loss: 145.26873| val_0_mse: 164.4258270263672|  0:01:14s\n","Stop training because you reached max_epochs = 100 with best_epoch = 97 and best_val_0_mse = 154.39736938476562\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 14:27:17,821] Trial 19 finished with value: 154.39736938476562 and parameters: {'n_d': 36, 'n_steps': 4, 'gamma': 1.8159456589701288, 'n_independent': 2, 'n_shared': 4, 'momentum': 0.1859425179959578}. Best is trial 7 with value: 146.89492797851562.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 1527.97946| val_0_mse: 11197.05078125|  0:00:00s\n","epoch 1  | loss: 485.05584| val_0_mse: 15134.841796875|  0:00:01s\n","epoch 2  | loss: 370.10708| val_0_mse: 3048.55712890625|  0:00:01s\n","epoch 3  | loss: 333.33554| val_0_mse: 1433.3291015625|  0:00:02s\n","epoch 4  | loss: 331.06743| val_0_mse: 1079.8433837890625|  0:00:02s\n","epoch 5  | loss: 306.19584| val_0_mse: 887.4784545898438|  0:00:03s\n","epoch 6  | loss: 298.57353| val_0_mse: 1580.9412841796875|  0:00:03s\n","epoch 7  | loss: 291.31719| val_0_mse: 1299.3782958984375|  0:00:04s\n","epoch 8  | loss: 274.8936| val_0_mse: 1216.3914794921875|  0:00:05s\n","epoch 9  | loss: 259.87568| val_0_mse: 1245.1080322265625|  0:00:05s\n","epoch 10 | loss: 257.29827| val_0_mse: 1771.572265625|  0:00:06s\n","epoch 11 | loss: 251.82082| val_0_mse: 1536.9022216796875|  0:00:06s\n","epoch 12 | loss: 235.49539| val_0_mse: 1323.08056640625|  0:00:07s\n","epoch 13 | loss: 224.41129| val_0_mse: 1089.0499267578125|  0:00:07s\n","epoch 14 | loss: 220.96381| val_0_mse: 816.4625854492188|  0:00:08s\n","epoch 15 | loss: 211.08634| val_0_mse: 918.9310913085938|  0:00:08s\n","epoch 16 | loss: 233.39872| val_0_mse: 649.322998046875|  0:00:09s\n","epoch 17 | loss: 229.14562| val_0_mse: 561.8635864257812|  0:00:10s\n","epoch 18 | loss: 233.32005| val_0_mse: 475.48150634765625|  0:00:10s\n","epoch 19 | loss: 216.72214| val_0_mse: 457.70068359375|  0:00:11s\n","epoch 20 | loss: 211.3949| val_0_mse: 484.2933654785156|  0:00:11s\n","epoch 21 | loss: 205.59229| val_0_mse: 489.660888671875|  0:00:12s\n","epoch 22 | loss: 208.14345| val_0_mse: 339.6995544433594|  0:00:13s\n","epoch 23 | loss: 204.83402| val_0_mse: 319.32757568359375|  0:00:13s\n","epoch 24 | loss: 197.23635| val_0_mse: 288.6159362792969|  0:00:14s\n","epoch 25 | loss: 197.815 | val_0_mse: 288.5072021484375|  0:00:14s\n","epoch 26 | loss: 201.62263| val_0_mse: 270.12567138671875|  0:00:15s\n","epoch 27 | loss: 196.03485| val_0_mse: 349.5893859863281|  0:00:15s\n","epoch 28 | loss: 191.12983| val_0_mse: 230.2082977294922|  0:00:16s\n","epoch 29 | loss: 196.03845| val_0_mse: 276.23797607421875|  0:00:16s\n","epoch 30 | loss: 198.83456| val_0_mse: 231.52598571777344|  0:00:17s\n","epoch 31 | loss: 186.28758| val_0_mse: 237.77967834472656|  0:00:18s\n","epoch 32 | loss: 179.53015| val_0_mse: 184.84378051757812|  0:00:18s\n","epoch 33 | loss: 182.59426| val_0_mse: 201.34678649902344|  0:00:19s\n","epoch 34 | loss: 184.9879| val_0_mse: 192.63612365722656|  0:00:19s\n","epoch 35 | loss: 181.54421| val_0_mse: 250.42091369628906|  0:00:20s\n","epoch 36 | loss: 178.43756| val_0_mse: 210.26210021972656|  0:00:20s\n","epoch 37 | loss: 171.91077| val_0_mse: 210.02621459960938|  0:00:21s\n","epoch 38 | loss: 176.7582| val_0_mse: 206.18496704101562|  0:00:21s\n","epoch 39 | loss: 178.61585| val_0_mse: 260.3374328613281|  0:00:22s\n","epoch 40 | loss: 172.8702| val_0_mse: 366.0906677246094|  0:00:23s\n","epoch 41 | loss: 175.76103| val_0_mse: 187.006103515625|  0:00:23s\n","epoch 42 | loss: 175.78841| val_0_mse: 171.43812561035156|  0:00:24s\n","epoch 43 | loss: 171.48255| val_0_mse: 178.85708618164062|  0:00:24s\n","epoch 44 | loss: 174.25172| val_0_mse: 176.1225128173828|  0:00:25s\n","epoch 45 | loss: 170.10548| val_0_mse: 169.70559692382812|  0:00:26s\n","epoch 46 | loss: 163.17982| val_0_mse: 166.8142547607422|  0:00:26s\n","epoch 47 | loss: 172.54433| val_0_mse: 200.6609344482422|  0:00:27s\n","epoch 48 | loss: 187.90035| val_0_mse: 178.74588012695312|  0:00:27s\n","epoch 49 | loss: 177.63253| val_0_mse: 180.26776123046875|  0:00:28s\n","epoch 50 | loss: 163.05107| val_0_mse: 212.5220947265625|  0:00:28s\n","epoch 51 | loss: 161.46829| val_0_mse: 167.31875610351562|  0:00:29s\n","epoch 52 | loss: 168.03265| val_0_mse: 172.3829803466797|  0:00:29s\n","epoch 53 | loss: 156.55889| val_0_mse: 158.80809020996094|  0:00:30s\n","epoch 54 | loss: 159.77226| val_0_mse: 181.37229919433594|  0:00:30s\n","epoch 55 | loss: 163.22518| val_0_mse: 179.42559814453125|  0:00:31s\n","epoch 56 | loss: 161.56158| val_0_mse: 173.2534942626953|  0:00:32s\n","epoch 57 | loss: 160.68754| val_0_mse: 173.53855895996094|  0:00:32s\n","epoch 58 | loss: 159.21656| val_0_mse: 220.23965454101562|  0:00:33s\n","epoch 59 | loss: 164.34087| val_0_mse: 161.7955780029297|  0:00:33s\n","epoch 60 | loss: 164.08577| val_0_mse: 233.05734252929688|  0:00:34s\n","epoch 61 | loss: 161.54622| val_0_mse: 242.33148193359375|  0:00:34s\n","epoch 62 | loss: 181.58939| val_0_mse: 198.30850219726562|  0:00:35s\n","epoch 63 | loss: 172.11445| val_0_mse: 208.0401153564453|  0:00:35s\n","\n","Early stopping occurred at epoch 63 with best_epoch = 53 and best_val_0_mse = 158.80809020996094\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 14:27:54,162] Trial 20 finished with value: 158.80809020996094 and parameters: {'n_d': 63, 'n_steps': 3, 'gamma': 1.8295438701151907, 'n_independent': 3, 'n_shared': 2, 'momentum': 0.16870239256259018}. Best is trial 7 with value: 146.89492797851562.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 1668.59936| val_0_mse: 44711.66796875|  0:00:00s\n","epoch 1  | loss: 545.43836| val_0_mse: 21646.193359375|  0:00:01s\n","epoch 2  | loss: 417.7235| val_0_mse: 1849.2825927734375|  0:00:01s\n","epoch 3  | loss: 360.04261| val_0_mse: 1068.6927490234375|  0:00:02s\n","epoch 4  | loss: 320.40094| val_0_mse: 1609.6973876953125|  0:00:02s\n","epoch 5  | loss: 298.99248| val_0_mse: 1087.059326171875|  0:00:03s\n","epoch 6  | loss: 296.56321| val_0_mse: 1101.14697265625|  0:00:03s\n","epoch 7  | loss: 270.84224| val_0_mse: 1078.2415771484375|  0:00:04s\n","epoch 8  | loss: 266.17251| val_0_mse: 1372.4378662109375|  0:00:04s\n","epoch 9  | loss: 263.32632| val_0_mse: 1283.580810546875|  0:00:05s\n","epoch 10 | loss: 257.55002| val_0_mse: 1108.0382080078125|  0:00:05s\n","epoch 11 | loss: 242.47058| val_0_mse: 782.6851806640625|  0:00:06s\n","epoch 12 | loss: 238.65984| val_0_mse: 881.3797607421875|  0:00:07s\n","epoch 13 | loss: 230.45056| val_0_mse: 827.62109375|  0:00:07s\n","epoch 14 | loss: 229.25871| val_0_mse: 548.5497436523438|  0:00:08s\n","epoch 15 | loss: 223.02571| val_0_mse: 556.6641235351562|  0:00:08s\n","epoch 16 | loss: 217.28788| val_0_mse: 651.2600708007812|  0:00:09s\n","epoch 17 | loss: 224.77113| val_0_mse: 640.56396484375|  0:00:10s\n","epoch 18 | loss: 213.5115| val_0_mse: 354.8808288574219|  0:00:10s\n","epoch 19 | loss: 208.05595| val_0_mse: 298.32568359375|  0:00:11s\n","epoch 20 | loss: 211.40442| val_0_mse: 289.7639465332031|  0:00:11s\n","epoch 21 | loss: 201.83556| val_0_mse: 243.49330139160156|  0:00:12s\n","epoch 22 | loss: 198.79339| val_0_mse: 320.6396789550781|  0:00:12s\n","epoch 23 | loss: 187.46348| val_0_mse: 408.4716491699219|  0:00:13s\n","epoch 24 | loss: 194.4351| val_0_mse: 307.3992919921875|  0:00:13s\n","epoch 25 | loss: 180.79647| val_0_mse: 244.6005859375|  0:00:14s\n","epoch 26 | loss: 184.08591| val_0_mse: 244.70359802246094|  0:00:15s\n","epoch 27 | loss: 193.72497| val_0_mse: 225.82736206054688|  0:00:15s\n","epoch 28 | loss: 197.84788| val_0_mse: 206.8186798095703|  0:00:16s\n","epoch 29 | loss: 180.47776| val_0_mse: 196.35768127441406|  0:00:16s\n","epoch 30 | loss: 173.39961| val_0_mse: 247.91574096679688|  0:00:17s\n","epoch 31 | loss: 180.30559| val_0_mse: 176.25860595703125|  0:00:17s\n","epoch 32 | loss: 178.52203| val_0_mse: 207.60305786132812|  0:00:18s\n","epoch 33 | loss: 180.61919| val_0_mse: 188.27113342285156|  0:00:18s\n","epoch 34 | loss: 177.2236| val_0_mse: 186.80831909179688|  0:00:19s\n","epoch 35 | loss: 165.85383| val_0_mse: 236.97998046875|  0:00:20s\n","epoch 36 | loss: 167.43714| val_0_mse: 242.91160583496094|  0:00:20s\n","epoch 37 | loss: 178.70004| val_0_mse: 181.1510467529297|  0:00:21s\n","epoch 38 | loss: 168.68403| val_0_mse: 165.8322296142578|  0:00:21s\n","epoch 39 | loss: 167.91548| val_0_mse: 187.81942749023438|  0:00:22s\n","epoch 40 | loss: 169.01493| val_0_mse: 180.03611755371094|  0:00:22s\n","epoch 41 | loss: 162.52623| val_0_mse: 166.41082763671875|  0:00:23s\n","epoch 42 | loss: 160.5259| val_0_mse: 165.07737731933594|  0:00:23s\n","epoch 43 | loss: 161.07244| val_0_mse: 206.10191345214844|  0:00:24s\n","epoch 44 | loss: 161.84519| val_0_mse: 158.48597717285156|  0:00:24s\n","epoch 45 | loss: 151.60704| val_0_mse: 165.71240234375|  0:00:25s\n","epoch 46 | loss: 164.80988| val_0_mse: 168.69749450683594|  0:00:26s\n","epoch 47 | loss: 154.02947| val_0_mse: 165.1614532470703|  0:00:26s\n","epoch 48 | loss: 151.23323| val_0_mse: 173.27386474609375|  0:00:27s\n","epoch 49 | loss: 158.71257| val_0_mse: 181.3314666748047|  0:00:27s\n","epoch 50 | loss: 158.48246| val_0_mse: 175.55076599121094|  0:00:28s\n","epoch 51 | loss: 150.79776| val_0_mse: 166.0323028564453|  0:00:28s\n","epoch 52 | loss: 158.46903| val_0_mse: 211.2236328125|  0:00:29s\n","epoch 53 | loss: 161.32164| val_0_mse: 234.19520568847656|  0:00:29s\n","epoch 54 | loss: 155.47077| val_0_mse: 181.8248748779297|  0:00:30s\n","\n","Early stopping occurred at epoch 54 with best_epoch = 44 and best_val_0_mse = 158.48597717285156\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 14:28:25,002] Trial 21 finished with value: 158.48597717285156 and parameters: {'n_d': 61, 'n_steps': 3, 'gamma': 1.8318552356641447, 'n_independent': 3, 'n_shared': 2, 'momentum': 0.17252397292249344}. Best is trial 7 with value: 146.89492797851562.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 1678.2834| val_0_mse: 36427.71484375|  0:00:00s\n","epoch 1  | loss: 546.0598| val_0_mse: 8523.4052734375|  0:00:01s\n","epoch 2  | loss: 404.69139| val_0_mse: 1847.147705078125|  0:00:01s\n","epoch 3  | loss: 354.22518| val_0_mse: 2310.713623046875|  0:00:02s\n","epoch 4  | loss: 317.08807| val_0_mse: 7459.5302734375|  0:00:03s\n","epoch 5  | loss: 302.42442| val_0_mse: 4494.0693359375|  0:00:03s\n","epoch 6  | loss: 281.88487| val_0_mse: 1853.08349609375|  0:00:04s\n","epoch 7  | loss: 261.88973| val_0_mse: 1953.4005126953125|  0:00:04s\n","epoch 8  | loss: 270.96701| val_0_mse: 4378.9658203125|  0:00:05s\n","epoch 9  | loss: 271.39902| val_0_mse: 1321.02783203125|  0:00:06s\n","epoch 10 | loss: 261.02151| val_0_mse: 855.4391479492188|  0:00:06s\n","epoch 11 | loss: 251.07482| val_0_mse: 1130.580322265625|  0:00:07s\n","epoch 12 | loss: 237.14097| val_0_mse: 550.6941528320312|  0:00:07s\n","epoch 13 | loss: 233.53746| val_0_mse: 607.60107421875|  0:00:08s\n","epoch 14 | loss: 222.98934| val_0_mse: 627.007568359375|  0:00:09s\n","epoch 15 | loss: 226.29861| val_0_mse: 679.7174682617188|  0:00:09s\n","epoch 16 | loss: 223.4171| val_0_mse: 744.2486572265625|  0:00:10s\n","epoch 17 | loss: 217.75534| val_0_mse: 765.3951416015625|  0:00:11s\n","epoch 18 | loss: 221.78725| val_0_mse: 337.7867736816406|  0:00:11s\n","epoch 19 | loss: 213.55249| val_0_mse: 385.093994140625|  0:00:12s\n","epoch 20 | loss: 218.69762| val_0_mse: 264.9962158203125|  0:00:13s\n","epoch 21 | loss: 205.49717| val_0_mse: 290.9587097167969|  0:00:13s\n","epoch 22 | loss: 204.69262| val_0_mse: 303.64593505859375|  0:00:14s\n","epoch 23 | loss: 199.35563| val_0_mse: 297.51708984375|  0:00:14s\n","epoch 24 | loss: 197.26695| val_0_mse: 292.7973327636719|  0:00:15s\n","epoch 25 | loss: 200.71283| val_0_mse: 309.8818054199219|  0:00:16s\n","epoch 26 | loss: 203.39928| val_0_mse: 221.412353515625|  0:00:16s\n","epoch 27 | loss: 191.84795| val_0_mse: 220.62855529785156|  0:00:17s\n","epoch 28 | loss: 188.26271| val_0_mse: 218.67269897460938|  0:00:17s\n","epoch 29 | loss: 183.20616| val_0_mse: 219.63514709472656|  0:00:18s\n","epoch 30 | loss: 188.70481| val_0_mse: 225.8508758544922|  0:00:19s\n","epoch 31 | loss: 193.72493| val_0_mse: 209.13841247558594|  0:00:19s\n","epoch 32 | loss: 182.02355| val_0_mse: 205.61871337890625|  0:00:20s\n","epoch 33 | loss: 192.59024| val_0_mse: 225.07069396972656|  0:00:21s\n","epoch 34 | loss: 190.86499| val_0_mse: 222.8167724609375|  0:00:21s\n","epoch 35 | loss: 188.25308| val_0_mse: 230.5138397216797|  0:00:22s\n","epoch 36 | loss: 184.091 | val_0_mse: 226.94735717773438|  0:00:22s\n","epoch 37 | loss: 181.61694| val_0_mse: 197.61378479003906|  0:00:23s\n","epoch 38 | loss: 184.19716| val_0_mse: 206.7151336669922|  0:00:24s\n","epoch 39 | loss: 181.59613| val_0_mse: 187.8964385986328|  0:00:24s\n","epoch 40 | loss: 189.70919| val_0_mse: 189.69305419921875|  0:00:25s\n","epoch 41 | loss: 189.4227| val_0_mse: 197.3402557373047|  0:00:26s\n","epoch 42 | loss: 193.42968| val_0_mse: 185.4971466064453|  0:00:26s\n","epoch 43 | loss: 184.70213| val_0_mse: 191.7332000732422|  0:00:27s\n","epoch 44 | loss: 180.85709| val_0_mse: 211.6981658935547|  0:00:27s\n","epoch 45 | loss: 178.6886| val_0_mse: 197.23886108398438|  0:00:28s\n","epoch 46 | loss: 176.34358| val_0_mse: 247.08636474609375|  0:00:29s\n","epoch 47 | loss: 175.95146| val_0_mse: 181.4686737060547|  0:00:29s\n","epoch 48 | loss: 175.11076| val_0_mse: 179.1168212890625|  0:00:30s\n","epoch 49 | loss: 168.58482| val_0_mse: 181.8679656982422|  0:00:30s\n","epoch 50 | loss: 177.69861| val_0_mse: 185.24949645996094|  0:00:31s\n","epoch 51 | loss: 178.194 | val_0_mse: 175.41998291015625|  0:00:32s\n","epoch 52 | loss: 166.2821| val_0_mse: 179.17724609375|  0:00:32s\n","epoch 53 | loss: 169.87401| val_0_mse: 174.0331268310547|  0:00:33s\n","epoch 54 | loss: 166.95058| val_0_mse: 181.87962341308594|  0:00:34s\n","epoch 55 | loss: 166.43134| val_0_mse: 171.7040557861328|  0:00:34s\n","epoch 56 | loss: 161.75574| val_0_mse: 179.26763916015625|  0:00:35s\n","epoch 57 | loss: 155.34782| val_0_mse: 174.4474334716797|  0:00:35s\n","epoch 58 | loss: 151.92146| val_0_mse: 181.76365661621094|  0:00:36s\n","epoch 59 | loss: 156.02421| val_0_mse: 187.50384521484375|  0:00:37s\n","epoch 60 | loss: 161.11545| val_0_mse: 197.52392578125|  0:00:37s\n","epoch 61 | loss: 159.77746| val_0_mse: 201.3298797607422|  0:00:38s\n","epoch 62 | loss: 165.6048| val_0_mse: 171.57093811035156|  0:00:38s\n","epoch 63 | loss: 153.04665| val_0_mse: 172.40371704101562|  0:00:39s\n","epoch 64 | loss: 153.75706| val_0_mse: 177.39100646972656|  0:00:40s\n","epoch 65 | loss: 155.91104| val_0_mse: 176.14146423339844|  0:00:40s\n","epoch 66 | loss: 154.13367| val_0_mse: 181.6678924560547|  0:00:41s\n","epoch 67 | loss: 155.21305| val_0_mse: 171.97865295410156|  0:00:42s\n","epoch 68 | loss: 151.87852| val_0_mse: 176.8502960205078|  0:00:42s\n","epoch 69 | loss: 150.00406| val_0_mse: 165.58311462402344|  0:00:43s\n","epoch 70 | loss: 151.59115| val_0_mse: 183.51210021972656|  0:00:43s\n","epoch 71 | loss: 149.86404| val_0_mse: 171.8970947265625|  0:00:44s\n","epoch 72 | loss: 157.6508| val_0_mse: 171.61534118652344|  0:00:45s\n","epoch 73 | loss: 151.16922| val_0_mse: 174.44790649414062|  0:00:45s\n","epoch 74 | loss: 147.92008| val_0_mse: 163.44100952148438|  0:00:46s\n","epoch 75 | loss: 145.84433| val_0_mse: 175.2744140625|  0:00:47s\n","epoch 76 | loss: 152.53172| val_0_mse: 159.81478881835938|  0:00:47s\n","epoch 77 | loss: 145.64849| val_0_mse: 161.079833984375|  0:00:48s\n","epoch 78 | loss: 145.77315| val_0_mse: 163.98057556152344|  0:00:49s\n","epoch 79 | loss: 149.71293| val_0_mse: 166.46728515625|  0:00:49s\n","epoch 80 | loss: 143.33545| val_0_mse: 169.66329956054688|  0:00:50s\n","epoch 81 | loss: 141.82042| val_0_mse: 169.6715850830078|  0:00:50s\n","epoch 82 | loss: 139.89524| val_0_mse: 171.89596557617188|  0:00:51s\n","epoch 83 | loss: 136.14759| val_0_mse: 161.27880859375|  0:00:52s\n","epoch 84 | loss: 140.92777| val_0_mse: 155.07928466796875|  0:00:52s\n","epoch 85 | loss: 145.20467| val_0_mse: 162.59471130371094|  0:00:53s\n","epoch 86 | loss: 148.2817| val_0_mse: 159.4078826904297|  0:00:53s\n","epoch 87 | loss: 138.53032| val_0_mse: 174.6455535888672|  0:00:54s\n","epoch 88 | loss: 138.85573| val_0_mse: 155.72509765625|  0:00:55s\n","epoch 89 | loss: 136.15198| val_0_mse: 169.47186279296875|  0:00:55s\n","epoch 90 | loss: 142.2234| val_0_mse: 164.00314331054688|  0:00:56s\n","epoch 91 | loss: 136.34501| val_0_mse: 190.48562622070312|  0:00:56s\n","epoch 92 | loss: 135.96729| val_0_mse: 167.80357360839844|  0:00:57s\n","epoch 93 | loss: 133.98676| val_0_mse: 165.3472900390625|  0:00:58s\n","epoch 94 | loss: 135.49385| val_0_mse: 158.39666748046875|  0:00:58s\n","\n","Early stopping occurred at epoch 94 with best_epoch = 84 and best_val_0_mse = 155.07928466796875\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 14:29:24,270] Trial 22 finished with value: 155.07928466796875 and parameters: {'n_d': 54, 'n_steps': 3, 'gamma': 1.8198461416068057, 'n_independent': 3, 'n_shared': 3, 'momentum': 0.11771667358759585}. Best is trial 7 with value: 146.89492797851562.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 1668.39891| val_0_mse: 42285.72265625|  0:00:00s\n","epoch 1  | loss: 708.09928| val_0_mse: 9685.6611328125|  0:00:01s\n","epoch 2  | loss: 562.01657| val_0_mse: 2054.548828125|  0:00:02s\n","epoch 3  | loss: 561.42319| val_0_mse: 2571.131103515625|  0:00:02s\n","epoch 4  | loss: 536.91892| val_0_mse: 3654.51318359375|  0:00:03s\n","epoch 5  | loss: 464.38181| val_0_mse: 3959.70068359375|  0:00:04s\n","epoch 6  | loss: 403.28215| val_0_mse: 853.6065063476562|  0:00:05s\n","epoch 7  | loss: 372.1881| val_0_mse: 1196.3934326171875|  0:00:05s\n","epoch 8  | loss: 361.3554| val_0_mse: 800.81298828125|  0:00:06s\n","epoch 9  | loss: 346.12946| val_0_mse: 1847.4464111328125|  0:00:07s\n","epoch 10 | loss: 342.10092| val_0_mse: 1255.0682373046875|  0:00:08s\n","epoch 11 | loss: 341.27187| val_0_mse: 656.2899169921875|  0:00:08s\n","epoch 12 | loss: 326.49111| val_0_mse: 698.7142944335938|  0:00:09s\n","epoch 13 | loss: 308.38633| val_0_mse: 715.2897338867188|  0:00:10s\n","epoch 14 | loss: 303.84551| val_0_mse: 672.0759887695312|  0:00:11s\n","epoch 15 | loss: 295.3427| val_0_mse: 451.4197692871094|  0:00:12s\n","epoch 16 | loss: 275.88573| val_0_mse: 486.9098815917969|  0:00:12s\n","epoch 17 | loss: 266.17397| val_0_mse: 685.3081665039062|  0:00:13s\n","epoch 18 | loss: 252.27029| val_0_mse: 465.9313049316406|  0:00:14s\n","epoch 19 | loss: 255.79155| val_0_mse: 411.99951171875|  0:00:14s\n","epoch 20 | loss: 243.06852| val_0_mse: 409.0317077636719|  0:00:15s\n","epoch 21 | loss: 239.28855| val_0_mse: 430.48046875|  0:00:16s\n","epoch 22 | loss: 227.20304| val_0_mse: 307.1869812011719|  0:00:17s\n","epoch 23 | loss: 230.45467| val_0_mse: 319.921142578125|  0:00:17s\n","epoch 24 | loss: 226.19429| val_0_mse: 385.5044250488281|  0:00:18s\n","epoch 25 | loss: 220.97701| val_0_mse: 289.936767578125|  0:00:19s\n","epoch 26 | loss: 226.60783| val_0_mse: 274.23974609375|  0:00:20s\n","epoch 27 | loss: 219.75589| val_0_mse: 275.0469665527344|  0:00:20s\n","epoch 28 | loss: 220.69847| val_0_mse: 276.752197265625|  0:00:21s\n","epoch 29 | loss: 222.0751| val_0_mse: 281.9444580078125|  0:00:22s\n","epoch 30 | loss: 212.0608| val_0_mse: 290.7780456542969|  0:00:23s\n","epoch 31 | loss: 203.51797| val_0_mse: 230.081298828125|  0:00:23s\n","epoch 32 | loss: 197.58346| val_0_mse: 218.19683837890625|  0:00:24s\n","epoch 33 | loss: 191.66969| val_0_mse: 208.9195556640625|  0:00:25s\n","epoch 34 | loss: 198.78031| val_0_mse: 207.99757385253906|  0:00:26s\n","epoch 35 | loss: 198.26124| val_0_mse: 200.3816375732422|  0:00:26s\n","epoch 36 | loss: 189.52823| val_0_mse: 208.05029296875|  0:00:27s\n","epoch 37 | loss: 183.43861| val_0_mse: 203.1970672607422|  0:00:28s\n","epoch 38 | loss: 184.26307| val_0_mse: 197.98605346679688|  0:00:29s\n","epoch 39 | loss: 187.70573| val_0_mse: 189.1387939453125|  0:00:29s\n","epoch 40 | loss: 191.89125| val_0_mse: 190.6457977294922|  0:00:30s\n","epoch 41 | loss: 182.80942| val_0_mse: 182.4449005126953|  0:00:31s\n","epoch 42 | loss: 172.6695| val_0_mse: 181.09588623046875|  0:00:32s\n","epoch 43 | loss: 174.35125| val_0_mse: 185.0349578857422|  0:00:32s\n","epoch 44 | loss: 175.1298| val_0_mse: 177.69290161132812|  0:00:33s\n","epoch 45 | loss: 175.72055| val_0_mse: 170.03326416015625|  0:00:34s\n","epoch 46 | loss: 168.1275| val_0_mse: 176.6921844482422|  0:00:35s\n","epoch 47 | loss: 166.79143| val_0_mse: 171.47946166992188|  0:00:36s\n","epoch 48 | loss: 165.65133| val_0_mse: 187.8978271484375|  0:00:36s\n","epoch 49 | loss: 161.63231| val_0_mse: 175.84556579589844|  0:00:37s\n","epoch 50 | loss: 161.05338| val_0_mse: 183.3923797607422|  0:00:38s\n","epoch 51 | loss: 157.52912| val_0_mse: 207.64036560058594|  0:00:39s\n","epoch 52 | loss: 161.99052| val_0_mse: 181.12916564941406|  0:00:39s\n","epoch 53 | loss: 164.46348| val_0_mse: 156.3820343017578|  0:00:40s\n","epoch 54 | loss: 155.34947| val_0_mse: 192.5235137939453|  0:00:41s\n","epoch 55 | loss: 170.62088| val_0_mse: 189.08111572265625|  0:00:42s\n","epoch 56 | loss: 162.72989| val_0_mse: 161.52029418945312|  0:00:42s\n","epoch 57 | loss: 165.31154| val_0_mse: 172.15960693359375|  0:00:43s\n","epoch 58 | loss: 158.34509| val_0_mse: 159.3268585205078|  0:00:44s\n","epoch 59 | loss: 160.60627| val_0_mse: 173.61630249023438|  0:00:45s\n","epoch 60 | loss: 151.87017| val_0_mse: 161.7596893310547|  0:00:45s\n","epoch 61 | loss: 155.31396| val_0_mse: 190.8031463623047|  0:00:46s\n","epoch 62 | loss: 153.36005| val_0_mse: 151.74359130859375|  0:00:47s\n","epoch 63 | loss: 151.73934| val_0_mse: 168.374267578125|  0:00:47s\n","epoch 64 | loss: 154.67253| val_0_mse: 188.01165771484375|  0:00:48s\n","epoch 65 | loss: 158.88547| val_0_mse: 154.89761352539062|  0:00:49s\n","epoch 66 | loss: 153.36847| val_0_mse: 170.43020629882812|  0:00:50s\n","epoch 67 | loss: 158.38019| val_0_mse: 171.01722717285156|  0:00:50s\n","epoch 68 | loss: 153.0123| val_0_mse: 168.64108276367188|  0:00:51s\n","epoch 69 | loss: 152.42026| val_0_mse: 171.37948608398438|  0:00:52s\n","epoch 70 | loss: 154.33094| val_0_mse: 171.84730529785156|  0:00:53s\n","epoch 71 | loss: 155.2363| val_0_mse: 166.30935668945312|  0:00:53s\n","epoch 72 | loss: 154.43567| val_0_mse: 161.9456787109375|  0:00:54s\n","\n","Early stopping occurred at epoch 72 with best_epoch = 62 and best_val_0_mse = 151.74359130859375\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 14:30:19,227] Trial 23 finished with value: 151.74359130859375 and parameters: {'n_d': 52, 'n_steps': 4, 'gamma': 1.9940509123628836, 'n_independent': 3, 'n_shared': 3, 'momentum': 0.11324136119929276}. Best is trial 7 with value: 146.89492797851562.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 1846.04146| val_0_mse: 18273.640625|  0:00:00s\n","epoch 1  | loss: 916.20943| val_0_mse: 16322.3232421875|  0:00:01s\n","epoch 2  | loss: 635.76114| val_0_mse: 4783.21484375|  0:00:02s\n","epoch 3  | loss: 566.30674| val_0_mse: 2934.154296875|  0:00:03s\n","epoch 4  | loss: 533.15877| val_0_mse: 4733.3515625|  0:00:03s\n","epoch 5  | loss: 501.95275| val_0_mse: 3347.260498046875|  0:00:04s\n","epoch 6  | loss: 506.62239| val_0_mse: 761.5289306640625|  0:00:05s\n","epoch 7  | loss: 472.33438| val_0_mse: 1576.6510009765625|  0:00:06s\n","epoch 8  | loss: 496.24276| val_0_mse: 4624.7177734375|  0:00:07s\n","epoch 9  | loss: 453.1148| val_0_mse: 835.7308959960938|  0:00:07s\n","epoch 10 | loss: 438.75094| val_0_mse: 1064.15380859375|  0:00:08s\n","epoch 11 | loss: 404.38756| val_0_mse: 1633.0989990234375|  0:00:09s\n","epoch 12 | loss: 350.59631| val_0_mse: 4411.00390625|  0:00:10s\n","epoch 13 | loss: 326.24034| val_0_mse: 2389.547119140625|  0:00:10s\n","epoch 14 | loss: 300.29777| val_0_mse: 508.95367431640625|  0:00:11s\n","epoch 15 | loss: 289.3692| val_0_mse: 895.2549438476562|  0:00:12s\n","epoch 16 | loss: 262.0043| val_0_mse: 659.4281616210938|  0:00:13s\n","epoch 17 | loss: 261.83579| val_0_mse: 818.2958984375|  0:00:14s\n","epoch 18 | loss: 249.22089| val_0_mse: 591.1434936523438|  0:00:14s\n","epoch 19 | loss: 274.79035| val_0_mse: 400.2341613769531|  0:00:15s\n","epoch 20 | loss: 272.76324| val_0_mse: 417.2803955078125|  0:00:16s\n","epoch 21 | loss: 259.89592| val_0_mse: 552.5296630859375|  0:00:17s\n","epoch 22 | loss: 247.48019| val_0_mse: 369.12921142578125|  0:00:17s\n","epoch 23 | loss: 243.40309| val_0_mse: 348.36383056640625|  0:00:18s\n","epoch 24 | loss: 260.07994| val_0_mse: 297.9682922363281|  0:00:19s\n","epoch 25 | loss: 257.35878| val_0_mse: 362.2753601074219|  0:00:20s\n","epoch 26 | loss: 245.19947| val_0_mse: 270.5013427734375|  0:00:21s\n","epoch 27 | loss: 236.76334| val_0_mse: 302.2884216308594|  0:00:21s\n","epoch 28 | loss: 247.59176| val_0_mse: 329.5439758300781|  0:00:22s\n","epoch 29 | loss: 243.10651| val_0_mse: 374.0851745605469|  0:00:23s\n","epoch 30 | loss: 255.43622| val_0_mse: 245.5460662841797|  0:00:24s\n","epoch 31 | loss: 236.73384| val_0_mse: 290.7909851074219|  0:00:25s\n","epoch 32 | loss: 229.25071| val_0_mse: 244.12583923339844|  0:00:25s\n","epoch 33 | loss: 212.07309| val_0_mse: 289.2703857421875|  0:00:26s\n","epoch 34 | loss: 222.82335| val_0_mse: 257.53216552734375|  0:00:27s\n","epoch 35 | loss: 210.31835| val_0_mse: 256.0898132324219|  0:00:28s\n","epoch 36 | loss: 214.80545| val_0_mse: 221.69534301757812|  0:00:28s\n","epoch 37 | loss: 220.29762| val_0_mse: 254.46188354492188|  0:00:29s\n","epoch 38 | loss: 223.35989| val_0_mse: 229.73309326171875|  0:00:30s\n","epoch 39 | loss: 220.53789| val_0_mse: 250.2760009765625|  0:00:31s\n","epoch 40 | loss: 209.5749| val_0_mse: 300.3390197753906|  0:00:31s\n","epoch 41 | loss: 216.03782| val_0_mse: 209.65234375|  0:00:32s\n","epoch 42 | loss: 199.34795| val_0_mse: 206.5706787109375|  0:00:33s\n","epoch 43 | loss: 205.94196| val_0_mse: 217.6251983642578|  0:00:34s\n","epoch 44 | loss: 206.51566| val_0_mse: 201.5340576171875|  0:00:35s\n","epoch 45 | loss: 200.40737| val_0_mse: 213.80584716796875|  0:00:35s\n","epoch 46 | loss: 197.44119| val_0_mse: 205.7811737060547|  0:00:36s\n","epoch 47 | loss: 200.02413| val_0_mse: 222.2769012451172|  0:00:37s\n","epoch 48 | loss: 193.58376| val_0_mse: 194.13169860839844|  0:00:38s\n","epoch 49 | loss: 192.27554| val_0_mse: 273.0857238769531|  0:00:39s\n","epoch 50 | loss: 202.02436| val_0_mse: 222.5601348876953|  0:00:40s\n","epoch 51 | loss: 202.8107| val_0_mse: 201.65542602539062|  0:00:40s\n","epoch 52 | loss: 194.3096| val_0_mse: 228.85015869140625|  0:00:41s\n","epoch 53 | loss: 197.02355| val_0_mse: 200.2540740966797|  0:00:42s\n","epoch 54 | loss: 195.8178| val_0_mse: 220.345947265625|  0:00:43s\n","epoch 55 | loss: 202.36953| val_0_mse: 209.5582275390625|  0:00:43s\n","epoch 56 | loss: 197.82769| val_0_mse: 199.2967987060547|  0:00:44s\n","epoch 57 | loss: 193.77392| val_0_mse: 211.5897216796875|  0:00:45s\n","epoch 58 | loss: 196.79015| val_0_mse: 206.9903564453125|  0:00:46s\n","\n","Early stopping occurred at epoch 58 with best_epoch = 48 and best_val_0_mse = 194.13169860839844\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 14:31:05,779] Trial 24 finished with value: 194.13169860839844 and parameters: {'n_d': 45, 'n_steps': 5, 'gamma': 1.9895478834395015, 'n_independent': 2, 'n_shared': 3, 'momentum': 0.03157055937224239}. Best is trial 7 with value: 146.89492797851562.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 1999.28156| val_0_mse: 5647.07373046875|  0:00:00s\n","epoch 1  | loss: 1022.75584| val_0_mse: 3631.906005859375|  0:00:01s\n","epoch 2  | loss: 569.28467| val_0_mse: 1881.876220703125|  0:00:02s\n","epoch 3  | loss: 473.30854| val_0_mse: 3067.962158203125|  0:00:03s\n","epoch 4  | loss: 497.34128| val_0_mse: 1649.7633056640625|  0:00:04s\n","epoch 5  | loss: 431.80535| val_0_mse: 1319.6314697265625|  0:00:05s\n","epoch 6  | loss: 401.55932| val_0_mse: 981.5638427734375|  0:00:06s\n","epoch 7  | loss: 379.2847| val_0_mse: 1724.8857421875|  0:00:07s\n","epoch 8  | loss: 380.80045| val_0_mse: 1320.027587890625|  0:00:08s\n","epoch 9  | loss: 377.98763| val_0_mse: 1710.1900634765625|  0:00:09s\n","epoch 10 | loss: 377.47228| val_0_mse: 999.5001831054688|  0:00:10s\n","epoch 11 | loss: 351.4126| val_0_mse: 457.98175048828125|  0:00:11s\n","epoch 12 | loss: 334.84063| val_0_mse: 427.1939697265625|  0:00:11s\n","epoch 13 | loss: 317.71224| val_0_mse: 548.9850463867188|  0:00:12s\n","epoch 14 | loss: 294.47088| val_0_mse: 665.1980590820312|  0:00:13s\n","epoch 15 | loss: 284.70521| val_0_mse: 475.6470947265625|  0:00:14s\n","epoch 16 | loss: 295.30115| val_0_mse: 396.6935729980469|  0:00:15s\n","epoch 17 | loss: 272.89508| val_0_mse: 451.78515625|  0:00:16s\n","epoch 18 | loss: 257.66959| val_0_mse: 431.4267578125|  0:00:17s\n","epoch 19 | loss: 257.6172| val_0_mse: 431.5981750488281|  0:00:18s\n","epoch 20 | loss: 251.63259| val_0_mse: 288.098876953125|  0:00:19s\n","epoch 21 | loss: 245.62403| val_0_mse: 317.8097839355469|  0:00:20s\n","epoch 22 | loss: 237.05701| val_0_mse: 304.2345275878906|  0:00:21s\n","epoch 23 | loss: 241.73804| val_0_mse: 289.4079284667969|  0:00:22s\n","epoch 24 | loss: 230.22931| val_0_mse: 251.520263671875|  0:00:23s\n","epoch 25 | loss: 224.3507| val_0_mse: 262.1270446777344|  0:00:24s\n","epoch 26 | loss: 231.38661| val_0_mse: 254.7878875732422|  0:00:25s\n","epoch 27 | loss: 221.45261| val_0_mse: 284.814208984375|  0:00:26s\n","epoch 28 | loss: 212.45026| val_0_mse: 238.8721160888672|  0:00:27s\n","epoch 29 | loss: 221.81643| val_0_mse: 244.83714294433594|  0:00:28s\n","epoch 30 | loss: 222.02311| val_0_mse: 251.04464721679688|  0:00:28s\n","epoch 31 | loss: 231.06749| val_0_mse: 234.864013671875|  0:00:29s\n","epoch 32 | loss: 218.86323| val_0_mse: 225.0986328125|  0:00:30s\n","epoch 33 | loss: 213.28509| val_0_mse: 261.33856201171875|  0:00:31s\n","epoch 34 | loss: 210.52343| val_0_mse: 217.66087341308594|  0:00:32s\n","epoch 35 | loss: 203.84391| val_0_mse: 241.46290588378906|  0:00:33s\n","epoch 36 | loss: 202.25348| val_0_mse: 219.608154296875|  0:00:34s\n","epoch 37 | loss: 203.06125| val_0_mse: 225.6733856201172|  0:00:35s\n","epoch 38 | loss: 203.05116| val_0_mse: 253.6607666015625|  0:00:36s\n","epoch 39 | loss: 205.06238| val_0_mse: 211.27540588378906|  0:00:37s\n","epoch 40 | loss: 197.30688| val_0_mse: 210.54840087890625|  0:00:38s\n","epoch 41 | loss: 203.57184| val_0_mse: 195.32020568847656|  0:00:39s\n","epoch 42 | loss: 195.09271| val_0_mse: 265.6734924316406|  0:00:40s\n","epoch 43 | loss: 191.49722| val_0_mse: 195.01817321777344|  0:00:41s\n","epoch 44 | loss: 194.59993| val_0_mse: 203.6527862548828|  0:00:41s\n","epoch 45 | loss: 195.91178| val_0_mse: 202.67230224609375|  0:00:42s\n","epoch 46 | loss: 194.62333| val_0_mse: 198.4725799560547|  0:00:43s\n","epoch 47 | loss: 198.59676| val_0_mse: 213.4164276123047|  0:00:44s\n","epoch 48 | loss: 195.92124| val_0_mse: 195.42758178710938|  0:00:45s\n","epoch 49 | loss: 191.19248| val_0_mse: 197.2216339111328|  0:00:46s\n","epoch 50 | loss: 184.94766| val_0_mse: 192.077392578125|  0:00:47s\n","epoch 51 | loss: 193.92579| val_0_mse: 207.82614135742188|  0:00:48s\n","epoch 52 | loss: 189.17916| val_0_mse: 201.75323486328125|  0:00:49s\n","epoch 53 | loss: 192.65936| val_0_mse: 197.00637817382812|  0:00:50s\n","epoch 54 | loss: 192.73532| val_0_mse: 189.38963317871094|  0:00:50s\n","epoch 55 | loss: 182.72983| val_0_mse: 186.8767852783203|  0:00:51s\n","epoch 56 | loss: 188.50133| val_0_mse: 195.47506713867188|  0:00:52s\n","epoch 57 | loss: 191.9865| val_0_mse: 206.32608032226562|  0:00:53s\n","epoch 58 | loss: 201.51829| val_0_mse: 207.90765380859375|  0:00:54s\n","epoch 59 | loss: 190.34345| val_0_mse: 249.56805419921875|  0:00:55s\n","epoch 60 | loss: 198.19231| val_0_mse: 204.49087524414062|  0:00:56s\n","epoch 61 | loss: 190.7621| val_0_mse: 203.216552734375|  0:00:57s\n","epoch 62 | loss: 189.59593| val_0_mse: 184.9068145751953|  0:00:58s\n","epoch 63 | loss: 190.02152| val_0_mse: 197.03347778320312|  0:00:59s\n","epoch 64 | loss: 190.5993| val_0_mse: 236.4279327392578|  0:01:00s\n","epoch 65 | loss: 192.8891| val_0_mse: 201.51678466796875|  0:01:01s\n","epoch 66 | loss: 177.22824| val_0_mse: 182.63221740722656|  0:01:01s\n","epoch 67 | loss: 182.80878| val_0_mse: 203.5609130859375|  0:01:02s\n","epoch 68 | loss: 179.60735| val_0_mse: 183.81434631347656|  0:01:03s\n","epoch 69 | loss: 181.13791| val_0_mse: 214.875244140625|  0:01:04s\n","epoch 70 | loss: 185.27714| val_0_mse: 188.3960418701172|  0:01:05s\n","epoch 71 | loss: 177.68757| val_0_mse: 229.07754516601562|  0:01:06s\n","epoch 72 | loss: 176.35484| val_0_mse: 185.7696075439453|  0:01:07s\n","epoch 73 | loss: 174.72209| val_0_mse: 216.8241424560547|  0:01:08s\n","epoch 74 | loss: 177.61772| val_0_mse: 192.97073364257812|  0:01:09s\n","epoch 75 | loss: 175.59049| val_0_mse: 255.9339141845703|  0:01:10s\n","epoch 76 | loss: 188.75217| val_0_mse: 216.14993286132812|  0:01:11s\n","\n","Early stopping occurred at epoch 76 with best_epoch = 66 and best_val_0_mse = 182.63221740722656\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 14:32:17,448] Trial 25 finished with value: 182.63221740722656 and parameters: {'n_d': 37, 'n_steps': 4, 'gamma': 1.9922927699862432, 'n_independent': 4, 'n_shared': 4, 'momentum': 0.08861964876229253}. Best is trial 7 with value: 146.89492797851562.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 1844.63314| val_0_mse: 49103.22265625|  0:00:00s\n","epoch 1  | loss: 914.77818| val_0_mse: 17916.21484375|  0:00:01s\n","epoch 2  | loss: 621.09241| val_0_mse: 9555.857421875|  0:00:02s\n","epoch 3  | loss: 530.87661| val_0_mse: 5645.16162109375|  0:00:03s\n","epoch 4  | loss: 536.84118| val_0_mse: 1806.668212890625|  0:00:04s\n","epoch 5  | loss: 530.35995| val_0_mse: 3360.80517578125|  0:00:05s\n","epoch 6  | loss: 522.56061| val_0_mse: 2615.63623046875|  0:00:06s\n","epoch 7  | loss: 454.91637| val_0_mse: 3629.228515625|  0:00:07s\n","epoch 8  | loss: 428.07807| val_0_mse: 2133.11376953125|  0:00:08s\n","epoch 9  | loss: 410.9857| val_0_mse: 921.0494995117188|  0:00:08s\n","epoch 10 | loss: 405.05684| val_0_mse: 1716.4996337890625|  0:00:09s\n","epoch 11 | loss: 398.23341| val_0_mse: 1384.83056640625|  0:00:10s\n","epoch 12 | loss: 365.25247| val_0_mse: 610.544921875|  0:00:11s\n","epoch 13 | loss: 358.6753| val_0_mse: 854.2597045898438|  0:00:12s\n","epoch 14 | loss: 337.20733| val_0_mse: 2293.48193359375|  0:00:13s\n","epoch 15 | loss: 318.34285| val_0_mse: 2319.182861328125|  0:00:14s\n","epoch 16 | loss: 317.61946| val_0_mse: 727.1504516601562|  0:00:15s\n","epoch 17 | loss: 312.70744| val_0_mse: 599.8265380859375|  0:00:16s\n","epoch 18 | loss: 301.29856| val_0_mse: 897.4711303710938|  0:00:17s\n","epoch 19 | loss: 292.49221| val_0_mse: 803.6566162109375|  0:00:17s\n","epoch 20 | loss: 285.7284| val_0_mse: 720.078857421875|  0:00:18s\n","epoch 21 | loss: 283.25531| val_0_mse: 649.7134399414062|  0:00:19s\n","epoch 22 | loss: 298.05951| val_0_mse: 782.7134399414062|  0:00:20s\n","epoch 23 | loss: 307.68227| val_0_mse: 346.6561584472656|  0:00:21s\n","epoch 24 | loss: 293.40969| val_0_mse: 622.203369140625|  0:00:22s\n","epoch 25 | loss: 294.70487| val_0_mse: 514.3222045898438|  0:00:23s\n","epoch 26 | loss: 280.58769| val_0_mse: 388.3971862792969|  0:00:24s\n","epoch 27 | loss: 269.76811| val_0_mse: 383.5917663574219|  0:00:25s\n","epoch 28 | loss: 269.93225| val_0_mse: 363.81671142578125|  0:00:25s\n","epoch 29 | loss: 260.14739| val_0_mse: 283.9414367675781|  0:00:26s\n","epoch 30 | loss: 248.92289| val_0_mse: 331.2597961425781|  0:00:27s\n","epoch 31 | loss: 257.51509| val_0_mse: 369.0883483886719|  0:00:28s\n","epoch 32 | loss: 258.02346| val_0_mse: 282.83465576171875|  0:00:29s\n","epoch 33 | loss: 246.237 | val_0_mse: 263.5945129394531|  0:00:30s\n","epoch 34 | loss: 239.21921| val_0_mse: 384.96533203125|  0:00:31s\n","epoch 35 | loss: 247.10751| val_0_mse: 393.7869567871094|  0:00:32s\n","epoch 36 | loss: 252.46852| val_0_mse: 264.7721252441406|  0:00:33s\n","epoch 37 | loss: 247.71699| val_0_mse: 232.73834228515625|  0:00:34s\n","epoch 38 | loss: 231.88579| val_0_mse: 228.41494750976562|  0:00:34s\n","epoch 39 | loss: 230.54502| val_0_mse: 280.04541015625|  0:00:35s\n","epoch 40 | loss: 228.815 | val_0_mse: 260.8482360839844|  0:00:36s\n","epoch 41 | loss: 223.78378| val_0_mse: 214.68260192871094|  0:00:37s\n","epoch 42 | loss: 224.60734| val_0_mse: 220.1717529296875|  0:00:38s\n","epoch 43 | loss: 221.72167| val_0_mse: 218.2314453125|  0:00:39s\n","epoch 44 | loss: 219.11912| val_0_mse: 243.7680206298828|  0:00:40s\n","epoch 45 | loss: 216.32341| val_0_mse: 213.808837890625|  0:00:41s\n","epoch 46 | loss: 217.42053| val_0_mse: 232.2292938232422|  0:00:42s\n","epoch 47 | loss: 218.85826| val_0_mse: 244.29962158203125|  0:00:43s\n","epoch 48 | loss: 220.53497| val_0_mse: 217.3450469970703|  0:00:44s\n","epoch 49 | loss: 212.59427| val_0_mse: 219.81822204589844|  0:00:44s\n","epoch 50 | loss: 213.89653| val_0_mse: 225.8778839111328|  0:00:45s\n","epoch 51 | loss: 210.6873| val_0_mse: 220.0938262939453|  0:00:46s\n","epoch 52 | loss: 202.92059| val_0_mse: 207.72378540039062|  0:00:47s\n","epoch 53 | loss: 204.65924| val_0_mse: 218.42584228515625|  0:00:48s\n","epoch 54 | loss: 205.21111| val_0_mse: 203.08824157714844|  0:00:49s\n","epoch 55 | loss: 202.82121| val_0_mse: 207.38746643066406|  0:00:50s\n","epoch 56 | loss: 226.74125| val_0_mse: 209.44479370117188|  0:00:51s\n","epoch 57 | loss: 211.35733| val_0_mse: 210.7999725341797|  0:00:52s\n","epoch 58 | loss: 215.66206| val_0_mse: 216.16256713867188|  0:00:52s\n","epoch 59 | loss: 205.39014| val_0_mse: 210.16026306152344|  0:00:53s\n","epoch 60 | loss: 203.19499| val_0_mse: 216.4929656982422|  0:00:54s\n","epoch 61 | loss: 200.53525| val_0_mse: 206.6155242919922|  0:00:55s\n","epoch 62 | loss: 195.17538| val_0_mse: 194.85983276367188|  0:00:56s\n","epoch 63 | loss: 185.00797| val_0_mse: 190.03317260742188|  0:00:57s\n","epoch 64 | loss: 187.71717| val_0_mse: 196.68760681152344|  0:00:58s\n","epoch 65 | loss: 185.04405| val_0_mse: 195.07691955566406|  0:00:59s\n","epoch 66 | loss: 185.58926| val_0_mse: 212.02401733398438|  0:01:00s\n","epoch 67 | loss: 189.10679| val_0_mse: 190.07374572753906|  0:01:00s\n","epoch 68 | loss: 186.63713| val_0_mse: 189.9065399169922|  0:01:01s\n","epoch 69 | loss: 184.68461| val_0_mse: 185.11538696289062|  0:01:02s\n","epoch 70 | loss: 177.96799| val_0_mse: 193.19146728515625|  0:01:03s\n","epoch 71 | loss: 175.22991| val_0_mse: 201.77784729003906|  0:01:04s\n","epoch 72 | loss: 193.61717| val_0_mse: 201.50547790527344|  0:01:05s\n","epoch 73 | loss: 184.61833| val_0_mse: 194.22970581054688|  0:01:06s\n","epoch 74 | loss: 180.48193| val_0_mse: 179.21255493164062|  0:01:06s\n","epoch 75 | loss: 176.84784| val_0_mse: 196.76864624023438|  0:01:07s\n","epoch 76 | loss: 176.14546| val_0_mse: 184.6573028564453|  0:01:08s\n","epoch 77 | loss: 177.44261| val_0_mse: 186.93421936035156|  0:01:09s\n","epoch 78 | loss: 175.23517| val_0_mse: 180.0863800048828|  0:01:10s\n","epoch 79 | loss: 171.19224| val_0_mse: 190.71893310546875|  0:01:11s\n","epoch 80 | loss: 171.86673| val_0_mse: 175.1221160888672|  0:01:12s\n","epoch 81 | loss: 174.51498| val_0_mse: 187.87701416015625|  0:01:13s\n","epoch 82 | loss: 163.37427| val_0_mse: 173.0566864013672|  0:01:14s\n","epoch 83 | loss: 167.45771| val_0_mse: 188.23809814453125|  0:01:15s\n","epoch 84 | loss: 167.46147| val_0_mse: 182.92921447753906|  0:01:15s\n","epoch 85 | loss: 168.79858| val_0_mse: 184.2442626953125|  0:01:16s\n","epoch 86 | loss: 170.28121| val_0_mse: 174.2770538330078|  0:01:17s\n","epoch 87 | loss: 168.71961| val_0_mse: 180.82887268066406|  0:01:18s\n","epoch 88 | loss: 161.35899| val_0_mse: 169.591552734375|  0:01:19s\n","epoch 89 | loss: 174.57042| val_0_mse: 168.71127319335938|  0:01:20s\n","epoch 90 | loss: 160.76111| val_0_mse: 181.9497833251953|  0:01:21s\n","epoch 91 | loss: 163.59912| val_0_mse: 170.67262268066406|  0:01:22s\n","epoch 92 | loss: 161.68892| val_0_mse: 172.2636260986328|  0:01:22s\n","epoch 93 | loss: 161.44205| val_0_mse: 175.4505615234375|  0:01:23s\n","epoch 94 | loss: 162.76677| val_0_mse: 161.45193481445312|  0:01:24s\n","epoch 95 | loss: 160.46286| val_0_mse: 162.3661346435547|  0:01:25s\n","epoch 96 | loss: 153.43215| val_0_mse: 163.41209411621094|  0:01:26s\n","epoch 97 | loss: 151.07291| val_0_mse: 173.65121459960938|  0:01:27s\n","epoch 98 | loss: 163.37907| val_0_mse: 189.70957946777344|  0:01:28s\n","epoch 99 | loss: 147.26447| val_0_mse: 163.46128845214844|  0:01:28s\n","Stop training because you reached max_epochs = 100 with best_epoch = 94 and best_val_0_mse = 161.45193481445312\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 14:33:46,959] Trial 26 finished with value: 161.45193481445312 and parameters: {'n_d': 56, 'n_steps': 6, 'gamma': 1.7373763904072979, 'n_independent': 2, 'n_shared': 3, 'momentum': 0.12722156224301187}. Best is trial 7 with value: 146.89492797851562.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 1955.5807| val_0_mse: 8916.990234375|  0:00:00s\n","epoch 1  | loss: 866.62278| val_0_mse: 19501.099609375|  0:00:01s\n","epoch 2  | loss: 552.27149| val_0_mse: 3073.571533203125|  0:00:02s\n","epoch 3  | loss: 488.76845| val_0_mse: 2056.906982421875|  0:00:03s\n","epoch 4  | loss: 452.54655| val_0_mse: 2089.429931640625|  0:00:04s\n","epoch 5  | loss: 444.02713| val_0_mse: 1589.803466796875|  0:00:04s\n","epoch 6  | loss: 411.37595| val_0_mse: 1954.878662109375|  0:00:05s\n","epoch 7  | loss: 422.23933| val_0_mse: 1506.50830078125|  0:00:06s\n","epoch 8  | loss: 383.74649| val_0_mse: 1343.621337890625|  0:00:07s\n","epoch 9  | loss: 397.44469| val_0_mse: 1399.5853271484375|  0:00:08s\n","epoch 10 | loss: 366.92743| val_0_mse: 594.892822265625|  0:00:08s\n","epoch 11 | loss: 349.91447| val_0_mse: 617.67578125|  0:00:09s\n","epoch 12 | loss: 332.23  | val_0_mse: 545.5421752929688|  0:00:10s\n","epoch 13 | loss: 324.49286| val_0_mse: 497.928955078125|  0:00:11s\n","epoch 14 | loss: 288.37142| val_0_mse: 398.4097900390625|  0:00:12s\n","epoch 15 | loss: 296.30672| val_0_mse: 370.4560546875|  0:00:13s\n","epoch 16 | loss: 290.84185| val_0_mse: 322.63995361328125|  0:00:14s\n","epoch 17 | loss: 298.72676| val_0_mse: 325.4029846191406|  0:00:14s\n","epoch 18 | loss: 274.57241| val_0_mse: 310.07421875|  0:00:15s\n","epoch 19 | loss: 274.38057| val_0_mse: 370.6312255859375|  0:00:16s\n","epoch 20 | loss: 276.93303| val_0_mse: 289.53369140625|  0:00:17s\n","epoch 21 | loss: 272.15031| val_0_mse: 290.7586975097656|  0:00:18s\n","epoch 22 | loss: 267.32111| val_0_mse: 350.32159423828125|  0:00:19s\n","epoch 23 | loss: 257.95617| val_0_mse: 265.39605712890625|  0:00:19s\n","epoch 24 | loss: 236.88963| val_0_mse: 274.5887145996094|  0:00:20s\n","epoch 25 | loss: 221.97294| val_0_mse: 263.8394470214844|  0:00:21s\n","epoch 26 | loss: 227.27305| val_0_mse: 256.583984375|  0:00:22s\n","epoch 27 | loss: 219.30879| val_0_mse: 237.64662170410156|  0:00:23s\n","epoch 28 | loss: 232.8968| val_0_mse: 263.81683349609375|  0:00:23s\n","epoch 29 | loss: 237.95859| val_0_mse: 282.2627258300781|  0:00:24s\n","epoch 30 | loss: 233.72872| val_0_mse: 274.92633056640625|  0:00:25s\n","epoch 31 | loss: 222.22194| val_0_mse: 271.0277099609375|  0:00:26s\n","epoch 32 | loss: 216.77574| val_0_mse: 244.86892700195312|  0:00:27s\n","epoch 33 | loss: 212.98999| val_0_mse: 241.83766174316406|  0:00:27s\n","epoch 34 | loss: 209.91726| val_0_mse: 253.91758728027344|  0:00:28s\n","epoch 35 | loss: 210.89603| val_0_mse: 246.26280212402344|  0:00:29s\n","epoch 36 | loss: 208.99961| val_0_mse: 210.7533416748047|  0:00:30s\n","epoch 37 | loss: 209.59243| val_0_mse: 245.39581298828125|  0:00:31s\n","epoch 38 | loss: 218.10665| val_0_mse: 236.2192840576172|  0:00:32s\n","epoch 39 | loss: 211.84153| val_0_mse: 209.68235778808594|  0:00:32s\n","epoch 40 | loss: 212.42505| val_0_mse: 209.7683868408203|  0:00:33s\n","epoch 41 | loss: 195.23445| val_0_mse: 200.04908752441406|  0:00:34s\n","epoch 42 | loss: 197.38942| val_0_mse: 196.64076232910156|  0:00:35s\n","epoch 43 | loss: 215.44086| val_0_mse: 264.5743103027344|  0:00:36s\n","epoch 44 | loss: 220.4728| val_0_mse: 243.92428588867188|  0:00:36s\n","epoch 45 | loss: 209.94493| val_0_mse: 199.81646728515625|  0:00:37s\n","epoch 46 | loss: 186.01319| val_0_mse: 205.47860717773438|  0:00:38s\n","epoch 47 | loss: 194.1152| val_0_mse: 200.7356414794922|  0:00:39s\n","epoch 48 | loss: 187.82179| val_0_mse: 207.28428649902344|  0:00:40s\n","epoch 49 | loss: 182.95591| val_0_mse: 202.55128479003906|  0:00:40s\n","epoch 50 | loss: 187.9222| val_0_mse: 186.55825805664062|  0:00:41s\n","epoch 51 | loss: 181.5155| val_0_mse: 185.57850646972656|  0:00:42s\n","epoch 52 | loss: 178.93169| val_0_mse: 192.88658142089844|  0:00:43s\n","epoch 53 | loss: 179.91354| val_0_mse: 180.11123657226562|  0:00:44s\n","epoch 54 | loss: 181.89185| val_0_mse: 198.02316284179688|  0:00:45s\n","epoch 55 | loss: 179.69926| val_0_mse: 192.4295654296875|  0:00:45s\n","epoch 56 | loss: 178.31413| val_0_mse: 173.3359375|  0:00:46s\n","epoch 57 | loss: 175.83223| val_0_mse: 199.38787841796875|  0:00:47s\n","epoch 58 | loss: 189.68008| val_0_mse: 200.70936584472656|  0:00:48s\n","epoch 59 | loss: 186.11785| val_0_mse: 180.75271606445312|  0:00:49s\n","epoch 60 | loss: 180.75017| val_0_mse: 204.23318481445312|  0:00:49s\n","epoch 61 | loss: 181.24654| val_0_mse: 213.68850708007812|  0:00:50s\n","epoch 62 | loss: 194.79716| val_0_mse: 183.56138610839844|  0:00:51s\n","epoch 63 | loss: 187.6771| val_0_mse: 194.57449340820312|  0:00:52s\n","epoch 64 | loss: 179.04601| val_0_mse: 182.14735412597656|  0:00:53s\n","epoch 65 | loss: 174.93423| val_0_mse: 174.6221466064453|  0:00:53s\n","epoch 66 | loss: 177.22601| val_0_mse: 186.59890747070312|  0:00:54s\n","\n","Early stopping occurred at epoch 66 with best_epoch = 56 and best_val_0_mse = 173.3359375\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 14:34:42,166] Trial 27 finished with value: 173.3359375 and parameters: {'n_d': 43, 'n_steps': 4, 'gamma': 1.9051805919832683, 'n_independent': 3, 'n_shared': 4, 'momentum': 0.21767276164398652}. Best is trial 7 with value: 146.89492797851562.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 1879.4255| val_0_mse: 10239.6943359375|  0:00:00s\n","epoch 1  | loss: 998.95034| val_0_mse: 17621.220703125|  0:00:01s\n","epoch 2  | loss: 591.45455| val_0_mse: 7078.99755859375|  0:00:02s\n","epoch 3  | loss: 509.24851| val_0_mse: 1782.1199951171875|  0:00:03s\n","epoch 4  | loss: 460.10271| val_0_mse: 1425.5732421875|  0:00:04s\n","epoch 5  | loss: 459.96188| val_0_mse: 2027.2501220703125|  0:00:05s\n","epoch 6  | loss: 445.93075| val_0_mse: 1403.1524658203125|  0:00:05s\n","epoch 7  | loss: 404.87957| val_0_mse: 1058.6453857421875|  0:00:06s\n","epoch 8  | loss: 412.9206| val_0_mse: 3444.348388671875|  0:00:07s\n","epoch 9  | loss: 406.30298| val_0_mse: 3380.179443359375|  0:00:08s\n","epoch 10 | loss: 419.5384| val_0_mse: 775.35693359375|  0:00:09s\n","epoch 11 | loss: 363.41579| val_0_mse: 599.4628295898438|  0:00:10s\n","epoch 12 | loss: 332.60677| val_0_mse: 609.1348876953125|  0:00:10s\n","epoch 13 | loss: 322.48267| val_0_mse: 458.1358947753906|  0:00:11s\n","epoch 14 | loss: 358.97252| val_0_mse: 847.3038330078125|  0:00:12s\n","epoch 15 | loss: 343.60718| val_0_mse: 526.7078857421875|  0:00:13s\n","epoch 16 | loss: 319.5219| val_0_mse: 541.2594604492188|  0:00:14s\n","epoch 17 | loss: 307.29166| val_0_mse: 433.0033264160156|  0:00:15s\n","epoch 18 | loss: 327.60407| val_0_mse: 558.8603515625|  0:00:16s\n","epoch 19 | loss: 315.97202| val_0_mse: 433.1234436035156|  0:00:16s\n","epoch 20 | loss: 296.7456| val_0_mse: 442.2676086425781|  0:00:17s\n","epoch 21 | loss: 298.58487| val_0_mse: 439.3396911621094|  0:00:18s\n","epoch 22 | loss: 301.53346| val_0_mse: 449.67303466796875|  0:00:19s\n","epoch 23 | loss: 278.34521| val_0_mse: 377.2206115722656|  0:00:20s\n","epoch 24 | loss: 266.79991| val_0_mse: 437.6673889160156|  0:00:21s\n","epoch 25 | loss: 269.86999| val_0_mse: 448.0484924316406|  0:00:22s\n","epoch 26 | loss: 267.28201| val_0_mse: 356.1368103027344|  0:00:22s\n","epoch 27 | loss: 258.03478| val_0_mse: 382.98553466796875|  0:00:23s\n","epoch 28 | loss: 268.82366| val_0_mse: 354.4228515625|  0:00:24s\n","epoch 29 | loss: 269.47957| val_0_mse: 302.7367858886719|  0:00:25s\n","epoch 30 | loss: 263.24262| val_0_mse: 268.3563537597656|  0:00:26s\n","epoch 31 | loss: 259.42512| val_0_mse: 330.6408386230469|  0:00:27s\n","epoch 32 | loss: 281.52703| val_0_mse: 271.6952209472656|  0:00:28s\n","epoch 33 | loss: 260.79457| val_0_mse: 255.52613830566406|  0:00:28s\n","epoch 34 | loss: 236.41395| val_0_mse: 250.0138397216797|  0:00:29s\n","epoch 35 | loss: 240.01419| val_0_mse: 251.08468627929688|  0:00:30s\n","epoch 36 | loss: 239.8312| val_0_mse: 252.7535858154297|  0:00:31s\n","epoch 37 | loss: 243.3222| val_0_mse: 245.4888458251953|  0:00:32s\n","epoch 38 | loss: 242.73272| val_0_mse: 253.51222229003906|  0:00:33s\n","epoch 39 | loss: 249.49542| val_0_mse: 269.8117370605469|  0:00:33s\n","epoch 40 | loss: 238.69767| val_0_mse: 248.06051635742188|  0:00:34s\n","epoch 41 | loss: 236.44996| val_0_mse: 237.38580322265625|  0:00:35s\n","epoch 42 | loss: 236.74161| val_0_mse: 248.42138671875|  0:00:36s\n","epoch 43 | loss: 249.6058| val_0_mse: 253.74171447753906|  0:00:37s\n","epoch 44 | loss: 244.70344| val_0_mse: 259.40460205078125|  0:00:38s\n","epoch 45 | loss: 232.33184| val_0_mse: 242.8411407470703|  0:00:39s\n","epoch 46 | loss: 242.73353| val_0_mse: 260.81298828125|  0:00:40s\n","epoch 47 | loss: 248.9765| val_0_mse: 234.15020751953125|  0:00:41s\n","epoch 48 | loss: 254.98853| val_0_mse: 246.32286071777344|  0:00:41s\n","epoch 49 | loss: 259.0742| val_0_mse: 244.94378662109375|  0:00:42s\n","epoch 50 | loss: 235.75492| val_0_mse: 278.2450256347656|  0:00:43s\n","epoch 51 | loss: 231.13744| val_0_mse: 234.22802734375|  0:00:44s\n","epoch 52 | loss: 230.49401| val_0_mse: 241.55320739746094|  0:00:45s\n","epoch 53 | loss: 232.76883| val_0_mse: 226.42477416992188|  0:00:46s\n","epoch 54 | loss: 220.49332| val_0_mse: 223.4983673095703|  0:00:47s\n","epoch 55 | loss: 215.623 | val_0_mse: 219.2535858154297|  0:00:48s\n","epoch 56 | loss: 212.73535| val_0_mse: 218.04769897460938|  0:00:49s\n","epoch 57 | loss: 207.01978| val_0_mse: 220.65130615234375|  0:00:50s\n","epoch 58 | loss: 207.12366| val_0_mse: 215.6804656982422|  0:00:51s\n","epoch 59 | loss: 206.26917| val_0_mse: 223.03448486328125|  0:00:52s\n","epoch 60 | loss: 203.593 | val_0_mse: 204.43084716796875|  0:00:52s\n","epoch 61 | loss: 202.23666| val_0_mse: 204.58949279785156|  0:00:53s\n","epoch 62 | loss: 200.696 | val_0_mse: 207.037841796875|  0:00:54s\n","epoch 63 | loss: 193.3309| val_0_mse: 200.69346618652344|  0:00:55s\n","epoch 64 | loss: 191.1424| val_0_mse: 218.11337280273438|  0:00:56s\n","epoch 65 | loss: 194.80486| val_0_mse: 213.4610137939453|  0:00:57s\n","epoch 66 | loss: 199.71519| val_0_mse: 195.26243591308594|  0:00:58s\n","epoch 67 | loss: 192.49067| val_0_mse: 192.84451293945312|  0:00:59s\n","epoch 68 | loss: 179.98578| val_0_mse: 196.603759765625|  0:01:00s\n","epoch 69 | loss: 195.61151| val_0_mse: 189.3219757080078|  0:01:00s\n","epoch 70 | loss: 188.23019| val_0_mse: 199.30857849121094|  0:01:01s\n","epoch 71 | loss: 195.10962| val_0_mse: 247.95205688476562|  0:01:02s\n","epoch 72 | loss: 198.73154| val_0_mse: 205.5024871826172|  0:01:03s\n","epoch 73 | loss: 196.86798| val_0_mse: 202.10914611816406|  0:01:04s\n","epoch 74 | loss: 198.61905| val_0_mse: 199.31797790527344|  0:01:05s\n","epoch 75 | loss: 189.78228| val_0_mse: 204.63583374023438|  0:01:06s\n","epoch 76 | loss: 194.15461| val_0_mse: 184.75180053710938|  0:01:07s\n","epoch 77 | loss: 186.44817| val_0_mse: 199.0689239501953|  0:01:07s\n","epoch 78 | loss: 190.93424| val_0_mse: 218.54649353027344|  0:01:08s\n","epoch 79 | loss: 199.3132| val_0_mse: 215.22935485839844|  0:01:09s\n","epoch 80 | loss: 193.43186| val_0_mse: 185.1818389892578|  0:01:10s\n","epoch 81 | loss: 175.72155| val_0_mse: 177.7334747314453|  0:01:11s\n","epoch 82 | loss: 177.42987| val_0_mse: 204.0470733642578|  0:01:12s\n","epoch 83 | loss: 188.35951| val_0_mse: 201.12611389160156|  0:01:13s\n","epoch 84 | loss: 201.03008| val_0_mse: 249.7859649658203|  0:01:13s\n","epoch 85 | loss: 189.05516| val_0_mse: 225.75559997558594|  0:01:14s\n","epoch 86 | loss: 203.84069| val_0_mse: 202.0659942626953|  0:01:15s\n","epoch 87 | loss: 192.7704| val_0_mse: 197.32110595703125|  0:01:16s\n","epoch 88 | loss: 188.76287| val_0_mse: 228.9493865966797|  0:01:17s\n","epoch 89 | loss: 179.71553| val_0_mse: 190.4709014892578|  0:01:18s\n","epoch 90 | loss: 176.0925| val_0_mse: 214.1267852783203|  0:01:19s\n","epoch 91 | loss: 178.36862| val_0_mse: 191.54849243164062|  0:01:20s\n","\n","Early stopping occurred at epoch 91 with best_epoch = 81 and best_val_0_mse = 177.7334747314453\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 14:36:02,783] Trial 28 finished with value: 177.7334747314453 and parameters: {'n_d': 35, 'n_steps': 5, 'gamma': 1.6733101914582946, 'n_independent': 3, 'n_shared': 3, 'momentum': 0.05149029131147122}. Best is trial 7 with value: 146.89492797851562.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 2120.24901| val_0_mse: 6008.8896484375|  0:00:01s\n","epoch 1  | loss: 1494.92661| val_0_mse: 4909.6630859375|  0:00:02s\n","epoch 2  | loss: 873.33788| val_0_mse: 5394.71533203125|  0:00:03s\n","epoch 3  | loss: 635.50787| val_0_mse: 1676.096923828125|  0:00:05s\n","epoch 4  | loss: 544.33213| val_0_mse: 1846.201171875|  0:00:06s\n","epoch 5  | loss: 541.42023| val_0_mse: 3717.25048828125|  0:00:07s\n","epoch 6  | loss: 522.2814| val_0_mse: 1161.2117919921875|  0:00:09s\n","epoch 7  | loss: 494.59168| val_0_mse: 979.5527954101562|  0:00:10s\n","epoch 8  | loss: 482.01895| val_0_mse: 1308.2579345703125|  0:00:11s\n","epoch 9  | loss: 512.19071| val_0_mse: 848.12353515625|  0:00:12s\n","epoch 10 | loss: 509.93957| val_0_mse: 892.7079467773438|  0:00:14s\n","epoch 11 | loss: 473.86413| val_0_mse: 780.0980224609375|  0:00:15s\n","epoch 12 | loss: 454.14496| val_0_mse: 726.0072631835938|  0:00:16s\n","epoch 13 | loss: 453.16431| val_0_mse: 1008.0518188476562|  0:00:18s\n","epoch 14 | loss: 412.05843| val_0_mse: 2243.905517578125|  0:00:19s\n","epoch 15 | loss: 438.91842| val_0_mse: 1185.8685302734375|  0:00:20s\n","epoch 16 | loss: 418.00242| val_0_mse: 2141.620849609375|  0:00:21s\n","epoch 17 | loss: 385.20827| val_0_mse: 598.1548461914062|  0:00:23s\n","epoch 18 | loss: 380.52534| val_0_mse: 1036.73388671875|  0:00:24s\n","epoch 19 | loss: 366.20047| val_0_mse: 642.897705078125|  0:00:25s\n","epoch 20 | loss: 329.11798| val_0_mse: 606.4196166992188|  0:00:26s\n","epoch 21 | loss: 321.04218| val_0_mse: 545.8150024414062|  0:00:27s\n","epoch 22 | loss: 321.76569| val_0_mse: 339.25274658203125|  0:00:29s\n","epoch 23 | loss: 316.7256| val_0_mse: 387.46429443359375|  0:00:30s\n","epoch 24 | loss: 298.64466| val_0_mse: 382.6744689941406|  0:00:31s\n","epoch 25 | loss: 283.85144| val_0_mse: 350.2877502441406|  0:00:32s\n","epoch 26 | loss: 290.0881| val_0_mse: 309.9374694824219|  0:00:34s\n","epoch 27 | loss: 289.734 | val_0_mse: 334.26397705078125|  0:00:35s\n","epoch 28 | loss: 294.06798| val_0_mse: 293.7790832519531|  0:00:36s\n","epoch 29 | loss: 297.98111| val_0_mse: 419.69775390625|  0:00:37s\n","epoch 30 | loss: 283.61625| val_0_mse: 278.2585144042969|  0:00:39s\n","epoch 31 | loss: 283.42228| val_0_mse: 301.254150390625|  0:00:40s\n","epoch 32 | loss: 278.40375| val_0_mse: 299.3161926269531|  0:00:41s\n","epoch 33 | loss: 272.28564| val_0_mse: 284.553466796875|  0:00:42s\n","epoch 34 | loss: 274.54063| val_0_mse: 267.2360534667969|  0:00:44s\n","epoch 35 | loss: 279.25424| val_0_mse: 292.0301818847656|  0:00:45s\n","epoch 36 | loss: 258.21593| val_0_mse: 272.3911437988281|  0:00:46s\n","epoch 37 | loss: 261.36365| val_0_mse: 262.1882629394531|  0:00:47s\n","epoch 38 | loss: 252.12883| val_0_mse: 240.25961303710938|  0:00:48s\n","epoch 39 | loss: 237.13349| val_0_mse: 230.2579345703125|  0:00:50s\n","epoch 40 | loss: 233.40413| val_0_mse: 331.2458190917969|  0:00:51s\n","epoch 41 | loss: 249.48071| val_0_mse: 280.36053466796875|  0:00:52s\n","epoch 42 | loss: 251.7941| val_0_mse: 288.2900390625|  0:00:53s\n","epoch 43 | loss: 262.06382| val_0_mse: 235.31065368652344|  0:00:55s\n","epoch 44 | loss: 229.42614| val_0_mse: 233.3632354736328|  0:00:56s\n","epoch 45 | loss: 226.35903| val_0_mse: 231.98753356933594|  0:00:57s\n","epoch 46 | loss: 229.96101| val_0_mse: 228.38064575195312|  0:00:58s\n","epoch 47 | loss: 227.23336| val_0_mse: 227.86131286621094|  0:01:00s\n","epoch 48 | loss: 228.08789| val_0_mse: 224.2389373779297|  0:01:01s\n","epoch 49 | loss: 216.77097| val_0_mse: 233.0210723876953|  0:01:02s\n","epoch 50 | loss: 223.83266| val_0_mse: 217.57835388183594|  0:01:03s\n","epoch 51 | loss: 219.22182| val_0_mse: 216.4159393310547|  0:01:05s\n","epoch 52 | loss: 215.4032| val_0_mse: 219.30946350097656|  0:01:06s\n","epoch 53 | loss: 216.51271| val_0_mse: 214.84588623046875|  0:01:07s\n","epoch 54 | loss: 215.42322| val_0_mse: 215.56056213378906|  0:01:08s\n","epoch 55 | loss: 210.13254| val_0_mse: 230.7705535888672|  0:01:10s\n","epoch 56 | loss: 210.20709| val_0_mse: 219.03518676757812|  0:01:11s\n","epoch 57 | loss: 216.08071| val_0_mse: 209.58627319335938|  0:01:12s\n","epoch 58 | loss: 206.95278| val_0_mse: 217.03123474121094|  0:01:13s\n","epoch 59 | loss: 197.85005| val_0_mse: 205.333984375|  0:01:14s\n","epoch 60 | loss: 204.624 | val_0_mse: 215.7158203125|  0:01:16s\n","epoch 61 | loss: 204.03573| val_0_mse: 211.44110107421875|  0:01:17s\n","epoch 62 | loss: 209.73876| val_0_mse: 206.01559448242188|  0:01:18s\n","epoch 63 | loss: 195.61293| val_0_mse: 218.26785278320312|  0:01:19s\n","epoch 64 | loss: 199.69085| val_0_mse: 212.02658081054688|  0:01:20s\n","epoch 65 | loss: 197.02766| val_0_mse: 200.9281005859375|  0:01:22s\n","epoch 66 | loss: 194.84622| val_0_mse: 202.3643341064453|  0:01:23s\n","epoch 67 | loss: 200.59542| val_0_mse: 217.685302734375|  0:01:24s\n","epoch 68 | loss: 196.41684| val_0_mse: 210.20578002929688|  0:01:25s\n","epoch 69 | loss: 199.15127| val_0_mse: 196.99510192871094|  0:01:27s\n","epoch 70 | loss: 193.9351| val_0_mse: 208.14683532714844|  0:01:28s\n","epoch 71 | loss: 199.40759| val_0_mse: 200.60438537597656|  0:01:29s\n","epoch 72 | loss: 196.4687| val_0_mse: 214.57736206054688|  0:01:30s\n","epoch 73 | loss: 193.09149| val_0_mse: 207.60757446289062|  0:01:31s\n","epoch 74 | loss: 195.48856| val_0_mse: 205.28709411621094|  0:01:32s\n","epoch 75 | loss: 191.29743| val_0_mse: 205.63534545898438|  0:01:34s\n","epoch 76 | loss: 188.90675| val_0_mse: 194.84347534179688|  0:01:35s\n","epoch 77 | loss: 193.43316| val_0_mse: 194.71908569335938|  0:01:36s\n","epoch 78 | loss: 185.54533| val_0_mse: 196.11781311035156|  0:01:38s\n","epoch 79 | loss: 188.25164| val_0_mse: 188.16177368164062|  0:01:39s\n","epoch 80 | loss: 199.16969| val_0_mse: 206.34103393554688|  0:01:40s\n","epoch 81 | loss: 186.52368| val_0_mse: 214.27142333984375|  0:01:41s\n","epoch 82 | loss: 199.701 | val_0_mse: 230.6890869140625|  0:01:42s\n","epoch 83 | loss: 195.63017| val_0_mse: 230.79324340820312|  0:01:44s\n","epoch 84 | loss: 189.70516| val_0_mse: 203.75967407226562|  0:01:45s\n","epoch 85 | loss: 190.99034| val_0_mse: 191.16366577148438|  0:01:46s\n","epoch 86 | loss: 191.46607| val_0_mse: 204.5967254638672|  0:01:47s\n","epoch 87 | loss: 189.70044| val_0_mse: 194.09373474121094|  0:01:49s\n","epoch 88 | loss: 180.07163| val_0_mse: 212.09991455078125|  0:01:50s\n","epoch 89 | loss: 186.12533| val_0_mse: 193.46961975097656|  0:01:51s\n","\n","Early stopping occurred at epoch 89 with best_epoch = 79 and best_val_0_mse = 188.16177368164062\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 14:37:54,991] Trial 29 finished with value: 188.1617889404297 and parameters: {'n_d': 29, 'n_steps': 6, 'gamma': 1.7840446343425456, 'n_independent': 4, 'n_shared': 4, 'momentum': 0.19012128680608045}. Best is trial 7 with value: 146.89492797851562.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 2072.64883| val_0_mse: 7561.80810546875|  0:00:00s\n","epoch 1  | loss: 1210.42714| val_0_mse: 12606.48828125|  0:00:01s\n","epoch 2  | loss: 728.33276| val_0_mse: 6445.19189453125|  0:00:02s\n","epoch 3  | loss: 580.03504| val_0_mse: 2663.024169921875|  0:00:02s\n","epoch 4  | loss: 512.63375| val_0_mse: 2567.337890625|  0:00:03s\n","epoch 5  | loss: 579.6538| val_0_mse: 1439.7742919921875|  0:00:04s\n","epoch 6  | loss: 521.61414| val_0_mse: 1062.8511962890625|  0:00:05s\n","epoch 7  | loss: 472.6618| val_0_mse: 1786.9295654296875|  0:00:05s\n","epoch 8  | loss: 463.00523| val_0_mse: 2180.60693359375|  0:00:06s\n","epoch 9  | loss: 474.08191| val_0_mse: 1030.2171630859375|  0:00:07s\n","epoch 10 | loss: 480.24837| val_0_mse: 961.2573852539062|  0:00:08s\n","epoch 11 | loss: 450.10892| val_0_mse: 611.806640625|  0:00:08s\n","epoch 12 | loss: 398.43385| val_0_mse: 607.058837890625|  0:00:09s\n","epoch 13 | loss: 416.10916| val_0_mse: 754.7767944335938|  0:00:10s\n","epoch 14 | loss: 435.09194| val_0_mse: 707.4590454101562|  0:00:11s\n","epoch 15 | loss: 447.92727| val_0_mse: 740.300537109375|  0:00:11s\n","epoch 16 | loss: 472.73912| val_0_mse: 646.012451171875|  0:00:12s\n","epoch 17 | loss: 488.45935| val_0_mse: 796.5143432617188|  0:00:13s\n","epoch 18 | loss: 443.07222| val_0_mse: 708.2476196289062|  0:00:14s\n","epoch 19 | loss: 448.18265| val_0_mse: 993.9649047851562|  0:00:14s\n","epoch 20 | loss: 418.58374| val_0_mse: 435.2635498046875|  0:00:15s\n","epoch 21 | loss: 404.2506| val_0_mse: 422.38726806640625|  0:00:16s\n","epoch 22 | loss: 372.60366| val_0_mse: 526.2228393554688|  0:00:17s\n","epoch 23 | loss: 422.31743| val_0_mse: 390.1969299316406|  0:00:17s\n","epoch 24 | loss: 353.8472| val_0_mse: 381.6834716796875|  0:00:18s\n","epoch 25 | loss: 326.51572| val_0_mse: 381.4486083984375|  0:00:19s\n","epoch 26 | loss: 298.88347| val_0_mse: 343.73626708984375|  0:00:20s\n","epoch 27 | loss: 291.65119| val_0_mse: 315.5115051269531|  0:00:20s\n","epoch 28 | loss: 281.91863| val_0_mse: 337.2682800292969|  0:00:21s\n","epoch 29 | loss: 293.75803| val_0_mse: 338.3922424316406|  0:00:22s\n","epoch 30 | loss: 298.93266| val_0_mse: 317.8108825683594|  0:00:22s\n","epoch 31 | loss: 285.25985| val_0_mse: 287.4271240234375|  0:00:23s\n","epoch 32 | loss: 291.48481| val_0_mse: 300.1705017089844|  0:00:24s\n","epoch 33 | loss: 287.02418| val_0_mse: 358.1915588378906|  0:00:25s\n","epoch 34 | loss: 288.82338| val_0_mse: 288.406494140625|  0:00:25s\n","epoch 35 | loss: 281.94321| val_0_mse: 272.89605712890625|  0:00:26s\n","epoch 36 | loss: 267.34173| val_0_mse: 268.0039367675781|  0:00:27s\n","epoch 37 | loss: 259.20859| val_0_mse: 255.38967895507812|  0:00:28s\n","epoch 38 | loss: 267.77558| val_0_mse: 339.7568054199219|  0:00:28s\n","epoch 39 | loss: 281.57132| val_0_mse: 289.20904541015625|  0:00:29s\n","epoch 40 | loss: 273.6523| val_0_mse: 279.9301452636719|  0:00:30s\n","epoch 41 | loss: 287.24866| val_0_mse: 258.62420654296875|  0:00:31s\n","epoch 42 | loss: 278.36056| val_0_mse: 257.15557861328125|  0:00:31s\n","epoch 43 | loss: 272.0602| val_0_mse: 267.64312744140625|  0:00:32s\n","epoch 44 | loss: 257.36121| val_0_mse: 249.81277465820312|  0:00:33s\n","epoch 45 | loss: 248.45769| val_0_mse: 253.25625610351562|  0:00:33s\n","epoch 46 | loss: 266.89094| val_0_mse: 291.26885986328125|  0:00:34s\n","epoch 47 | loss: 267.18558| val_0_mse: 239.83685302734375|  0:00:35s\n","epoch 48 | loss: 246.81611| val_0_mse: 247.87049865722656|  0:00:36s\n","epoch 49 | loss: 243.56963| val_0_mse: 229.8108673095703|  0:00:36s\n","epoch 50 | loss: 230.55504| val_0_mse: 234.66844177246094|  0:00:37s\n","epoch 51 | loss: 224.79889| val_0_mse: 227.04083251953125|  0:00:38s\n","epoch 52 | loss: 228.66769| val_0_mse: 234.6047821044922|  0:00:39s\n","epoch 53 | loss: 231.36227| val_0_mse: 220.1354217529297|  0:00:39s\n","epoch 54 | loss: 228.00995| val_0_mse: 315.6789855957031|  0:00:40s\n","epoch 55 | loss: 278.62626| val_0_mse: 298.66876220703125|  0:00:41s\n","epoch 56 | loss: 240.30991| val_0_mse: 217.92173767089844|  0:00:42s\n","epoch 57 | loss: 228.39626| val_0_mse: 245.91998291015625|  0:00:42s\n","epoch 58 | loss: 229.72201| val_0_mse: 222.94305419921875|  0:00:43s\n","epoch 59 | loss: 222.52684| val_0_mse: 217.69737243652344|  0:00:44s\n","epoch 60 | loss: 213.62073| val_0_mse: 207.1250762939453|  0:00:45s\n","epoch 61 | loss: 215.99812| val_0_mse: 218.01637268066406|  0:00:45s\n","epoch 62 | loss: 209.85921| val_0_mse: 209.99513244628906|  0:00:46s\n","epoch 63 | loss: 211.84079| val_0_mse: 211.89590454101562|  0:00:47s\n","epoch 64 | loss: 206.41777| val_0_mse: 200.5200958251953|  0:00:47s\n","epoch 65 | loss: 209.34174| val_0_mse: 227.22747802734375|  0:00:48s\n","epoch 66 | loss: 203.48303| val_0_mse: 222.67919921875|  0:00:49s\n","epoch 67 | loss: 206.04922| val_0_mse: 195.1318817138672|  0:00:50s\n","epoch 68 | loss: 201.48824| val_0_mse: 209.38519287109375|  0:00:50s\n","epoch 69 | loss: 207.18431| val_0_mse: 194.5254669189453|  0:00:51s\n","epoch 70 | loss: 203.5408| val_0_mse: 205.31179809570312|  0:00:52s\n","epoch 71 | loss: 202.67299| val_0_mse: 198.50015258789062|  0:00:53s\n","epoch 72 | loss: 206.93042| val_0_mse: 202.11802673339844|  0:00:53s\n","epoch 73 | loss: 202.62199| val_0_mse: 191.392822265625|  0:00:54s\n","epoch 74 | loss: 193.22347| val_0_mse: 191.6689453125|  0:00:55s\n","epoch 75 | loss: 183.99434| val_0_mse: 203.4180145263672|  0:00:56s\n","epoch 76 | loss: 187.28942| val_0_mse: 176.59461975097656|  0:00:56s\n","epoch 77 | loss: 187.49627| val_0_mse: 213.63534545898438|  0:00:57s\n","epoch 78 | loss: 184.25581| val_0_mse: 182.9499053955078|  0:00:58s\n","epoch 79 | loss: 192.37016| val_0_mse: 192.3047332763672|  0:00:58s\n","epoch 80 | loss: 186.0498| val_0_mse: 184.994873046875|  0:00:59s\n","epoch 81 | loss: 184.10849| val_0_mse: 181.58558654785156|  0:01:00s\n","epoch 82 | loss: 181.22836| val_0_mse: 181.8582763671875|  0:01:01s\n","epoch 83 | loss: 183.12681| val_0_mse: 189.6171875|  0:01:01s\n","epoch 84 | loss: 181.16558| val_0_mse: 196.67051696777344|  0:01:02s\n","epoch 85 | loss: 184.20102| val_0_mse: 189.6758270263672|  0:01:03s\n","epoch 86 | loss: 183.45733| val_0_mse: 178.81883239746094|  0:01:03s\n","\n","Early stopping occurred at epoch 86 with best_epoch = 76 and best_val_0_mse = 176.59461975097656\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 14:38:59,512] Trial 30 finished with value: 176.59461975097656 and parameters: {'n_d': 50, 'n_steps': 7, 'gamma': 1.895250798160406, 'n_independent': 1, 'n_shared': 2, 'momentum': 0.2576948808387476}. Best is trial 7 with value: 146.89492797851562.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 1687.48823| val_0_mse: 14411.4658203125|  0:00:00s\n","epoch 1  | loss: 506.0886| val_0_mse: 4525.0009765625|  0:00:01s\n","epoch 2  | loss: 383.27548| val_0_mse: 15936.935546875|  0:00:01s\n","epoch 3  | loss: 338.58613| val_0_mse: 19826.2421875|  0:00:02s\n","epoch 4  | loss: 317.59079| val_0_mse: 4796.7685546875|  0:00:03s\n","epoch 5  | loss: 291.48165| val_0_mse: 6539.77001953125|  0:00:03s\n","epoch 6  | loss: 276.53285| val_0_mse: 7178.7607421875|  0:00:04s\n","epoch 7  | loss: 287.36689| val_0_mse: 4054.287109375|  0:00:04s\n","epoch 8  | loss: 266.58859| val_0_mse: 4417.03955078125|  0:00:05s\n","epoch 9  | loss: 259.77927| val_0_mse: 5412.7666015625|  0:00:06s\n","epoch 10 | loss: 253.63266| val_0_mse: 4375.07470703125|  0:00:06s\n","epoch 11 | loss: 244.49226| val_0_mse: 3065.792236328125|  0:00:07s\n","epoch 12 | loss: 241.67366| val_0_mse: 3014.878662109375|  0:00:07s\n","epoch 13 | loss: 233.7538| val_0_mse: 1101.535400390625|  0:00:08s\n","epoch 14 | loss: 220.59638| val_0_mse: 1023.1207885742188|  0:00:09s\n","epoch 15 | loss: 219.75271| val_0_mse: 649.47900390625|  0:00:09s\n","epoch 16 | loss: 221.41488| val_0_mse: 484.1126403808594|  0:00:10s\n","epoch 17 | loss: 210.03028| val_0_mse: 699.1267700195312|  0:00:11s\n","epoch 18 | loss: 223.48878| val_0_mse: 698.0430908203125|  0:00:11s\n","epoch 19 | loss: 223.67889| val_0_mse: 407.6593322753906|  0:00:12s\n","epoch 20 | loss: 221.03809| val_0_mse: 390.6736145019531|  0:00:12s\n","epoch 21 | loss: 215.11139| val_0_mse: 435.374755859375|  0:00:13s\n","epoch 22 | loss: 209.51033| val_0_mse: 341.70867919921875|  0:00:14s\n","epoch 23 | loss: 205.09998| val_0_mse: 246.5774383544922|  0:00:14s\n","epoch 24 | loss: 206.50835| val_0_mse: 364.25836181640625|  0:00:15s\n","epoch 25 | loss: 203.55966| val_0_mse: 256.37921142578125|  0:00:15s\n","epoch 26 | loss: 195.38804| val_0_mse: 269.7307434082031|  0:00:16s\n","epoch 27 | loss: 203.28795| val_0_mse: 247.99453735351562|  0:00:17s\n","epoch 28 | loss: 204.25087| val_0_mse: 257.4773254394531|  0:00:17s\n","epoch 29 | loss: 196.81175| val_0_mse: 282.44451904296875|  0:00:18s\n","epoch 30 | loss: 189.58254| val_0_mse: 237.9608612060547|  0:00:18s\n","epoch 31 | loss: 193.70635| val_0_mse: 284.7395935058594|  0:00:19s\n","epoch 32 | loss: 196.9246| val_0_mse: 273.7867126464844|  0:00:20s\n","epoch 33 | loss: 188.65051| val_0_mse: 207.0630340576172|  0:00:20s\n","epoch 34 | loss: 190.94613| val_0_mse: 255.9207763671875|  0:00:21s\n","epoch 35 | loss: 185.93539| val_0_mse: 234.2283935546875|  0:00:21s\n","epoch 36 | loss: 186.15052| val_0_mse: 310.2823181152344|  0:00:22s\n","epoch 37 | loss: 190.03158| val_0_mse: 197.5299530029297|  0:00:23s\n","epoch 38 | loss: 183.72597| val_0_mse: 194.329345703125|  0:00:23s\n","epoch 39 | loss: 184.16847| val_0_mse: 199.30267333984375|  0:00:24s\n","epoch 40 | loss: 173.52973| val_0_mse: 189.2946014404297|  0:00:25s\n","epoch 41 | loss: 181.4523| val_0_mse: 192.1514129638672|  0:00:25s\n","epoch 42 | loss: 175.23309| val_0_mse: 208.86961364746094|  0:00:26s\n","epoch 43 | loss: 176.82615| val_0_mse: 190.848876953125|  0:00:27s\n","epoch 44 | loss: 176.16856| val_0_mse: 231.03445434570312|  0:00:27s\n","epoch 45 | loss: 181.14917| val_0_mse: 190.49388122558594|  0:00:28s\n","epoch 46 | loss: 176.8516| val_0_mse: 179.50503540039062|  0:00:28s\n","epoch 47 | loss: 174.69514| val_0_mse: 182.33706665039062|  0:00:29s\n","epoch 48 | loss: 168.40135| val_0_mse: 183.20204162597656|  0:00:30s\n","epoch 49 | loss: 175.03035| val_0_mse: 172.89938354492188|  0:00:30s\n","epoch 50 | loss: 166.24155| val_0_mse: 212.04881286621094|  0:00:31s\n","epoch 51 | loss: 177.44136| val_0_mse: 172.9786376953125|  0:00:31s\n","epoch 52 | loss: 161.97982| val_0_mse: 187.1568145751953|  0:00:32s\n","epoch 53 | loss: 158.36374| val_0_mse: 184.8851776123047|  0:00:33s\n","epoch 54 | loss: 162.89544| val_0_mse: 170.1997528076172|  0:00:33s\n","epoch 55 | loss: 162.21523| val_0_mse: 173.80636596679688|  0:00:34s\n","epoch 56 | loss: 159.94052| val_0_mse: 176.94708251953125|  0:00:35s\n","epoch 57 | loss: 168.36265| val_0_mse: 201.58045959472656|  0:00:35s\n","epoch 58 | loss: 161.03681| val_0_mse: 168.2779541015625|  0:00:36s\n","epoch 59 | loss: 155.10487| val_0_mse: 184.79083251953125|  0:00:36s\n","epoch 60 | loss: 162.71137| val_0_mse: 171.7574005126953|  0:00:37s\n","epoch 61 | loss: 159.42728| val_0_mse: 173.22021484375|  0:00:37s\n","epoch 62 | loss: 159.4587| val_0_mse: 166.2661895751953|  0:00:38s\n","epoch 63 | loss: 156.31313| val_0_mse: 174.56739807128906|  0:00:39s\n","epoch 64 | loss: 159.67556| val_0_mse: 180.6821746826172|  0:00:39s\n","epoch 65 | loss: 153.93498| val_0_mse: 176.76429748535156|  0:00:40s\n","epoch 66 | loss: 150.41448| val_0_mse: 166.7965545654297|  0:00:41s\n","epoch 67 | loss: 157.87187| val_0_mse: 176.82159423828125|  0:00:41s\n","epoch 68 | loss: 152.38472| val_0_mse: 164.63232421875|  0:00:42s\n","epoch 69 | loss: 146.29296| val_0_mse: 155.3724822998047|  0:00:42s\n","epoch 70 | loss: 141.05601| val_0_mse: 154.09544372558594|  0:00:43s\n","epoch 71 | loss: 146.91078| val_0_mse: 154.82186889648438|  0:00:44s\n","epoch 72 | loss: 149.02537| val_0_mse: 174.4228057861328|  0:00:44s\n","epoch 73 | loss: 143.83666| val_0_mse: 167.41293334960938|  0:00:45s\n","epoch 74 | loss: 144.8416| val_0_mse: 166.32815551757812|  0:00:45s\n","epoch 75 | loss: 139.63029| val_0_mse: 150.63784790039062|  0:00:46s\n","epoch 76 | loss: 141.07978| val_0_mse: 162.60475158691406|  0:00:47s\n","epoch 77 | loss: 147.71338| val_0_mse: 168.6588592529297|  0:00:47s\n","epoch 78 | loss: 144.6573| val_0_mse: 172.3953857421875|  0:00:48s\n","epoch 79 | loss: 142.50745| val_0_mse: 162.8633270263672|  0:00:49s\n","epoch 80 | loss: 145.46216| val_0_mse: 145.72171020507812|  0:00:49s\n","epoch 81 | loss: 138.18655| val_0_mse: 148.38027954101562|  0:00:50s\n","epoch 82 | loss: 137.83643| val_0_mse: 148.81109619140625|  0:00:50s\n","epoch 83 | loss: 136.8216| val_0_mse: 164.4376220703125|  0:00:51s\n","epoch 84 | loss: 139.36844| val_0_mse: 177.7699432373047|  0:00:52s\n","epoch 85 | loss: 142.83939| val_0_mse: 163.74766540527344|  0:00:52s\n","epoch 86 | loss: 144.07593| val_0_mse: 165.39849853515625|  0:00:53s\n","epoch 87 | loss: 138.8576| val_0_mse: 169.5430145263672|  0:00:53s\n","epoch 88 | loss: 138.99554| val_0_mse: 151.75621032714844|  0:00:54s\n","epoch 89 | loss: 141.34438| val_0_mse: 146.31068420410156|  0:00:55s\n","epoch 90 | loss: 136.48743| val_0_mse: 164.76499938964844|  0:00:55s\n","\n","Early stopping occurred at epoch 90 with best_epoch = 80 and best_val_0_mse = 145.72171020507812\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 14:39:55,509] Trial 31 finished with value: 145.72171020507812 and parameters: {'n_d': 57, 'n_steps': 3, 'gamma': 1.8012670366552264, 'n_independent': 3, 'n_shared': 3, 'momentum': 0.11451802070679519}. Best is trial 31 with value: 145.72171020507812.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 1667.40019| val_0_mse: 4738.13134765625|  0:00:00s\n","epoch 1  | loss: 504.52908| val_0_mse: 1428.3060302734375|  0:00:01s\n","epoch 2  | loss: 350.04065| val_0_mse: 1915.0537109375|  0:00:01s\n","epoch 3  | loss: 320.74999| val_0_mse: 4910.154296875|  0:00:02s\n","epoch 4  | loss: 304.11924| val_0_mse: 1216.9901123046875|  0:00:03s\n","epoch 5  | loss: 282.21998| val_0_mse: 1567.250244140625|  0:00:03s\n","epoch 6  | loss: 284.07611| val_0_mse: 1554.7833251953125|  0:00:04s\n","epoch 7  | loss: 269.19535| val_0_mse: 2545.9638671875|  0:00:04s\n","epoch 8  | loss: 260.50897| val_0_mse: 6774.6357421875|  0:00:05s\n","epoch 9  | loss: 258.85262| val_0_mse: 5295.87109375|  0:00:06s\n","epoch 10 | loss: 248.78186| val_0_mse: 5870.3232421875|  0:00:06s\n","epoch 11 | loss: 238.13246| val_0_mse: 3383.497802734375|  0:00:07s\n","epoch 12 | loss: 238.30855| val_0_mse: 2820.67138671875|  0:00:07s\n","epoch 13 | loss: 230.72225| val_0_mse: 1199.5443115234375|  0:00:08s\n","epoch 14 | loss: 223.08498| val_0_mse: 581.2164306640625|  0:00:09s\n","epoch 15 | loss: 237.59109| val_0_mse: 1015.2185668945312|  0:00:09s\n","epoch 16 | loss: 220.04849| val_0_mse: 1361.6976318359375|  0:00:10s\n","epoch 17 | loss: 216.57197| val_0_mse: 591.9653930664062|  0:00:10s\n","epoch 18 | loss: 223.12507| val_0_mse: 966.4359130859375|  0:00:11s\n","epoch 19 | loss: 222.52336| val_0_mse: 671.8865356445312|  0:00:12s\n","epoch 20 | loss: 220.55894| val_0_mse: 517.2865600585938|  0:00:12s\n","epoch 21 | loss: 212.71866| val_0_mse: 355.58740234375|  0:00:13s\n","epoch 22 | loss: 219.99594| val_0_mse: 283.9913330078125|  0:00:14s\n","epoch 23 | loss: 220.33906| val_0_mse: 262.7799072265625|  0:00:14s\n","epoch 24 | loss: 207.59085| val_0_mse: 241.74017333984375|  0:00:15s\n","epoch 25 | loss: 200.17097| val_0_mse: 244.52316284179688|  0:00:16s\n","epoch 26 | loss: 194.48907| val_0_mse: 256.0343933105469|  0:00:16s\n","epoch 27 | loss: 202.90636| val_0_mse: 239.85240173339844|  0:00:17s\n","epoch 28 | loss: 204.26449| val_0_mse: 261.592529296875|  0:00:17s\n","epoch 29 | loss: 195.21658| val_0_mse: 247.25799560546875|  0:00:18s\n","epoch 30 | loss: 200.53455| val_0_mse: 242.7571258544922|  0:00:19s\n","epoch 31 | loss: 196.13371| val_0_mse: 246.72854614257812|  0:00:19s\n","epoch 32 | loss: 206.65416| val_0_mse: 227.36279296875|  0:00:20s\n","epoch 33 | loss: 190.80276| val_0_mse: 206.47335815429688|  0:00:20s\n","epoch 34 | loss: 195.03388| val_0_mse: 210.9454803466797|  0:00:21s\n","epoch 35 | loss: 190.31067| val_0_mse: 206.71664428710938|  0:00:22s\n","epoch 36 | loss: 191.61139| val_0_mse: 186.50747680664062|  0:00:22s\n","epoch 37 | loss: 190.77604| val_0_mse: 209.2959747314453|  0:00:23s\n","epoch 38 | loss: 180.93368| val_0_mse: 189.4057159423828|  0:00:23s\n","epoch 39 | loss: 181.40922| val_0_mse: 189.27305603027344|  0:00:24s\n","epoch 40 | loss: 183.79357| val_0_mse: 197.06997680664062|  0:00:25s\n","epoch 41 | loss: 179.06702| val_0_mse: 213.21041870117188|  0:00:25s\n","epoch 42 | loss: 180.28463| val_0_mse: 201.44778442382812|  0:00:26s\n","epoch 43 | loss: 189.76771| val_0_mse: 182.3246612548828|  0:00:26s\n","epoch 44 | loss: 185.57971| val_0_mse: 216.9730987548828|  0:00:27s\n","epoch 45 | loss: 183.65587| val_0_mse: 195.48182678222656|  0:00:28s\n","epoch 46 | loss: 186.4239| val_0_mse: 175.2919464111328|  0:00:28s\n","epoch 47 | loss: 179.17134| val_0_mse: 168.86073303222656|  0:00:29s\n","epoch 48 | loss: 172.015 | val_0_mse: 185.36854553222656|  0:00:29s\n","epoch 49 | loss: 168.56198| val_0_mse: 173.67564392089844|  0:00:30s\n","epoch 50 | loss: 166.6394| val_0_mse: 193.35020446777344|  0:00:31s\n","epoch 51 | loss: 173.85649| val_0_mse: 175.3990936279297|  0:00:31s\n","epoch 52 | loss: 170.62713| val_0_mse: 196.83416748046875|  0:00:32s\n","epoch 53 | loss: 163.60912| val_0_mse: 167.8850860595703|  0:00:32s\n","epoch 54 | loss: 169.9116| val_0_mse: 180.35049438476562|  0:00:33s\n","epoch 55 | loss: 165.78594| val_0_mse: 176.25360107421875|  0:00:34s\n","epoch 56 | loss: 168.53269| val_0_mse: 180.35333251953125|  0:00:34s\n","epoch 57 | loss: 172.05235| val_0_mse: 203.61387634277344|  0:00:35s\n","epoch 58 | loss: 160.6067| val_0_mse: 161.3869171142578|  0:00:35s\n","epoch 59 | loss: 159.39283| val_0_mse: 164.49237060546875|  0:00:36s\n","epoch 60 | loss: 164.6833| val_0_mse: 185.9013214111328|  0:00:37s\n","epoch 61 | loss: 161.06786| val_0_mse: 171.29095458984375|  0:00:37s\n","epoch 62 | loss: 169.14081| val_0_mse: 164.73529052734375|  0:00:38s\n","epoch 63 | loss: 167.86668| val_0_mse: 167.37071228027344|  0:00:39s\n","epoch 64 | loss: 154.94637| val_0_mse: 164.25680541992188|  0:00:39s\n","epoch 65 | loss: 163.2502| val_0_mse: 165.89590454101562|  0:00:40s\n","epoch 66 | loss: 154.36612| val_0_mse: 171.7425994873047|  0:00:40s\n","epoch 67 | loss: 158.18757| val_0_mse: 193.34884643554688|  0:00:41s\n","epoch 68 | loss: 153.52758| val_0_mse: 160.0647430419922|  0:00:42s\n","epoch 69 | loss: 147.49086| val_0_mse: 203.44479370117188|  0:00:42s\n","epoch 70 | loss: 145.30438| val_0_mse: 158.10203552246094|  0:00:43s\n","epoch 71 | loss: 149.11462| val_0_mse: 161.04832458496094|  0:00:43s\n","epoch 72 | loss: 152.56782| val_0_mse: 172.37196350097656|  0:00:44s\n","epoch 73 | loss: 150.09457| val_0_mse: 177.72987365722656|  0:00:45s\n","epoch 74 | loss: 149.68116| val_0_mse: 148.244384765625|  0:00:45s\n","epoch 75 | loss: 136.12897| val_0_mse: 159.390869140625|  0:00:46s\n","epoch 76 | loss: 144.96539| val_0_mse: 156.72219848632812|  0:00:46s\n","epoch 77 | loss: 145.79803| val_0_mse: 177.6278533935547|  0:00:47s\n","epoch 78 | loss: 146.20357| val_0_mse: 148.2992401123047|  0:00:48s\n","epoch 79 | loss: 139.79952| val_0_mse: 167.29962158203125|  0:00:48s\n","epoch 80 | loss: 149.93643| val_0_mse: 171.56153869628906|  0:00:49s\n","epoch 81 | loss: 151.39186| val_0_mse: 182.51524353027344|  0:00:49s\n","epoch 82 | loss: 145.6265| val_0_mse: 148.89381408691406|  0:00:50s\n","epoch 83 | loss: 144.29918| val_0_mse: 162.4522247314453|  0:00:51s\n","epoch 84 | loss: 146.53809| val_0_mse: 174.4438934326172|  0:00:51s\n","\n","Early stopping occurred at epoch 84 with best_epoch = 74 and best_val_0_mse = 148.244384765625\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 14:40:47,580] Trial 32 finished with value: 148.244384765625 and parameters: {'n_d': 57, 'n_steps': 3, 'gamma': 1.4586643496468565, 'n_independent': 3, 'n_shared': 3, 'momentum': 0.11099301560648774}. Best is trial 31 with value: 145.72171020507812.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 1635.88506| val_0_mse: 3515.40234375|  0:00:00s\n","epoch 1  | loss: 473.26632| val_0_mse: 2166.28173828125|  0:00:01s\n","epoch 2  | loss: 352.29855| val_0_mse: 2590.859375|  0:00:01s\n","epoch 3  | loss: 318.34165| val_0_mse: 665.4174194335938|  0:00:02s\n","epoch 4  | loss: 312.97498| val_0_mse: 1019.9885864257812|  0:00:02s\n","epoch 5  | loss: 281.07041| val_0_mse: 910.2095336914062|  0:00:03s\n","epoch 6  | loss: 266.83893| val_0_mse: 624.1610717773438|  0:00:04s\n","epoch 7  | loss: 264.54475| val_0_mse: 425.3011474609375|  0:00:04s\n","epoch 8  | loss: 258.54935| val_0_mse: 408.92877197265625|  0:00:05s\n","epoch 9  | loss: 247.43668| val_0_mse: 486.34246826171875|  0:00:06s\n","epoch 10 | loss: 248.57899| val_0_mse: 376.4223327636719|  0:00:06s\n","epoch 11 | loss: 247.57507| val_0_mse: 368.0894775390625|  0:00:07s\n","epoch 12 | loss: 232.59154| val_0_mse: 435.8020324707031|  0:00:08s\n","epoch 13 | loss: 221.6064| val_0_mse: 465.3260498046875|  0:00:08s\n","epoch 14 | loss: 221.0244| val_0_mse: 423.33306884765625|  0:00:09s\n","epoch 15 | loss: 222.96606| val_0_mse: 512.3915405273438|  0:00:09s\n","epoch 16 | loss: 213.31978| val_0_mse: 559.6223754882812|  0:00:10s\n","epoch 17 | loss: 214.74803| val_0_mse: 458.3041076660156|  0:00:10s\n","epoch 18 | loss: 223.59536| val_0_mse: 467.352294921875|  0:00:11s\n","epoch 19 | loss: 217.6381| val_0_mse: 293.84942626953125|  0:00:12s\n","epoch 20 | loss: 213.28548| val_0_mse: 386.4970397949219|  0:00:12s\n","epoch 21 | loss: 209.46389| val_0_mse: 380.3587951660156|  0:00:13s\n","epoch 22 | loss: 214.72095| val_0_mse: 362.10418701171875|  0:00:13s\n","epoch 23 | loss: 198.86776| val_0_mse: 289.7301025390625|  0:00:14s\n","epoch 24 | loss: 209.24001| val_0_mse: 264.261962890625|  0:00:15s\n","epoch 25 | loss: 199.55281| val_0_mse: 290.1019287109375|  0:00:15s\n","epoch 26 | loss: 196.48973| val_0_mse: 313.7520751953125|  0:00:16s\n","epoch 27 | loss: 200.6831| val_0_mse: 280.7746887207031|  0:00:16s\n","epoch 28 | loss: 194.47504| val_0_mse: 236.20155334472656|  0:00:17s\n","epoch 29 | loss: 187.0413| val_0_mse: 244.91934204101562|  0:00:18s\n","epoch 30 | loss: 182.94286| val_0_mse: 251.2671661376953|  0:00:18s\n","epoch 31 | loss: 188.17158| val_0_mse: 231.01654052734375|  0:00:19s\n","epoch 32 | loss: 189.22686| val_0_mse: 284.1440734863281|  0:00:20s\n","epoch 33 | loss: 183.92476| val_0_mse: 241.9619598388672|  0:00:20s\n","epoch 34 | loss: 184.36395| val_0_mse: 225.71092224121094|  0:00:21s\n","epoch 35 | loss: 177.07242| val_0_mse: 221.33311462402344|  0:00:21s\n","epoch 36 | loss: 178.44344| val_0_mse: 219.45196533203125|  0:00:22s\n","epoch 37 | loss: 178.95615| val_0_mse: 218.80343627929688|  0:00:23s\n","epoch 38 | loss: 174.09319| val_0_mse: 197.27418518066406|  0:00:23s\n","epoch 39 | loss: 172.69391| val_0_mse: 191.99493408203125|  0:00:24s\n","epoch 40 | loss: 166.95468| val_0_mse: 190.27479553222656|  0:00:24s\n","epoch 41 | loss: 173.30168| val_0_mse: 194.90138244628906|  0:00:25s\n","epoch 42 | loss: 169.3339| val_0_mse: 197.98240661621094|  0:00:26s\n","epoch 43 | loss: 182.84544| val_0_mse: 187.78016662597656|  0:00:26s\n","epoch 44 | loss: 174.99948| val_0_mse: 189.6114044189453|  0:00:27s\n","epoch 45 | loss: 173.29055| val_0_mse: 186.42999267578125|  0:00:27s\n","epoch 46 | loss: 166.34816| val_0_mse: 188.07687377929688|  0:00:28s\n","epoch 47 | loss: 173.07263| val_0_mse: 190.57940673828125|  0:00:29s\n","epoch 48 | loss: 163.99264| val_0_mse: 185.47674560546875|  0:00:29s\n","epoch 49 | loss: 164.69054| val_0_mse: 169.06063842773438|  0:00:30s\n","epoch 50 | loss: 160.30241| val_0_mse: 179.4139862060547|  0:00:31s\n","epoch 51 | loss: 170.72379| val_0_mse: 183.22654724121094|  0:00:31s\n","epoch 52 | loss: 160.58968| val_0_mse: 172.49566650390625|  0:00:32s\n","epoch 53 | loss: 162.19777| val_0_mse: 175.83822631835938|  0:00:32s\n","epoch 54 | loss: 162.5807| val_0_mse: 192.89793395996094|  0:00:33s\n","epoch 55 | loss: 164.66148| val_0_mse: 176.28160095214844|  0:00:34s\n","epoch 56 | loss: 155.7895| val_0_mse: 168.2557373046875|  0:00:34s\n","epoch 57 | loss: 158.87282| val_0_mse: 176.0537872314453|  0:00:35s\n","epoch 58 | loss: 151.32839| val_0_mse: 165.4318084716797|  0:00:35s\n","epoch 59 | loss: 150.83289| val_0_mse: 166.0820770263672|  0:00:36s\n","epoch 60 | loss: 156.86015| val_0_mse: 175.5894775390625|  0:00:37s\n","epoch 61 | loss: 158.53336| val_0_mse: 176.57266235351562|  0:00:37s\n","epoch 62 | loss: 160.33907| val_0_mse: 174.28089904785156|  0:00:38s\n","epoch 63 | loss: 154.95221| val_0_mse: 190.954833984375|  0:00:38s\n","epoch 64 | loss: 152.57963| val_0_mse: 171.89381408691406|  0:00:39s\n","epoch 65 | loss: 152.03073| val_0_mse: 190.5635528564453|  0:00:40s\n","epoch 66 | loss: 147.28204| val_0_mse: 165.0143280029297|  0:00:40s\n","epoch 67 | loss: 148.6031| val_0_mse: 170.50042724609375|  0:00:41s\n","epoch 68 | loss: 146.43362| val_0_mse: 180.6100616455078|  0:00:42s\n","epoch 69 | loss: 141.67353| val_0_mse: 154.01219177246094|  0:00:42s\n","epoch 70 | loss: 139.57414| val_0_mse: 182.2289581298828|  0:00:43s\n","epoch 71 | loss: 142.36767| val_0_mse: 160.00225830078125|  0:00:43s\n","epoch 72 | loss: 139.57403| val_0_mse: 163.01988220214844|  0:00:44s\n","epoch 73 | loss: 140.3526| val_0_mse: 164.86497497558594|  0:00:44s\n","epoch 74 | loss: 137.14142| val_0_mse: 168.7593231201172|  0:00:45s\n","epoch 75 | loss: 133.96733| val_0_mse: 157.2263946533203|  0:00:46s\n","epoch 76 | loss: 133.69856| val_0_mse: 153.0662078857422|  0:00:46s\n","epoch 77 | loss: 140.20844| val_0_mse: 155.8556671142578|  0:00:47s\n","epoch 78 | loss: 135.4705| val_0_mse: 154.19613647460938|  0:00:47s\n","epoch 79 | loss: 135.90099| val_0_mse: 181.4839324951172|  0:00:48s\n","epoch 80 | loss: 140.21731| val_0_mse: 155.43565368652344|  0:00:49s\n","epoch 81 | loss: 137.71803| val_0_mse: 149.75355529785156|  0:00:49s\n","epoch 82 | loss: 131.67669| val_0_mse: 143.69085693359375|  0:00:50s\n","epoch 83 | loss: 126.08786| val_0_mse: 163.4355010986328|  0:00:50s\n","epoch 84 | loss: 130.34328| val_0_mse: 165.57937622070312|  0:00:51s\n","epoch 85 | loss: 139.16734| val_0_mse: 147.16835021972656|  0:00:52s\n","epoch 86 | loss: 128.79843| val_0_mse: 143.14608764648438|  0:00:52s\n","epoch 87 | loss: 130.83122| val_0_mse: 166.76382446289062|  0:00:53s\n","epoch 88 | loss: 127.67966| val_0_mse: 144.22657775878906|  0:00:54s\n","epoch 89 | loss: 126.32752| val_0_mse: 135.8055877685547|  0:00:54s\n","epoch 90 | loss: 128.6647| val_0_mse: 144.4778289794922|  0:00:55s\n","epoch 91 | loss: 128.53163| val_0_mse: 141.31011962890625|  0:00:55s\n","epoch 92 | loss: 124.46094| val_0_mse: 145.4884033203125|  0:00:56s\n","epoch 93 | loss: 122.63403| val_0_mse: 161.22076416015625|  0:00:57s\n","epoch 94 | loss: 125.96724| val_0_mse: 146.114501953125|  0:00:57s\n","epoch 95 | loss: 124.16096| val_0_mse: 142.8416290283203|  0:00:58s\n","epoch 96 | loss: 125.58562| val_0_mse: 150.10260009765625|  0:00:58s\n","epoch 97 | loss: 123.05497| val_0_mse: 175.6458740234375|  0:00:59s\n","epoch 98 | loss: 114.07664| val_0_mse: 142.0128173828125|  0:01:00s\n","epoch 99 | loss: 120.68823| val_0_mse: 154.25296020507812|  0:01:00s\n","\n","Early stopping occurred at epoch 99 with best_epoch = 89 and best_val_0_mse = 135.8055877685547\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 14:41:48,741] Trial 33 finished with value: 135.8055877685547 and parameters: {'n_d': 57, 'n_steps': 3, 'gamma': 1.4326005028022137, 'n_independent': 3, 'n_shared': 3, 'momentum': 0.10390725153746129}. Best is trial 33 with value: 135.8055877685547.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 1578.10351| val_0_mse: 23856.3125|  0:00:00s\n","epoch 1  | loss: 507.13617| val_0_mse: 4001.90185546875|  0:00:01s\n","epoch 2  | loss: 366.60278| val_0_mse: 7873.18408203125|  0:00:02s\n","epoch 3  | loss: 312.83515| val_0_mse: 10939.4326171875|  0:00:02s\n","epoch 4  | loss: 297.93008| val_0_mse: 4090.096435546875|  0:00:03s\n","epoch 5  | loss: 282.54509| val_0_mse: 5638.33642578125|  0:00:04s\n","epoch 6  | loss: 270.66745| val_0_mse: 3007.4541015625|  0:00:04s\n","epoch 7  | loss: 259.05586| val_0_mse: 4701.5205078125|  0:00:05s\n","epoch 8  | loss: 265.63457| val_0_mse: 2143.652099609375|  0:00:06s\n","epoch 9  | loss: 260.5737| val_0_mse: 1635.3017578125|  0:00:06s\n","epoch 10 | loss: 244.09852| val_0_mse: 3406.858154296875|  0:00:07s\n","epoch 11 | loss: 224.46322| val_0_mse: 3155.849853515625|  0:00:08s\n","epoch 12 | loss: 220.5752| val_0_mse: 3317.4697265625|  0:00:08s\n","epoch 13 | loss: 220.53189| val_0_mse: 3805.502685546875|  0:00:09s\n","epoch 14 | loss: 223.36186| val_0_mse: 1600.4478759765625|  0:00:10s\n","epoch 15 | loss: 218.69141| val_0_mse: 1305.45263671875|  0:00:10s\n","epoch 16 | loss: 203.59774| val_0_mse: 1662.2662353515625|  0:00:11s\n","epoch 17 | loss: 207.86259| val_0_mse: 942.3793334960938|  0:00:12s\n","epoch 18 | loss: 205.97497| val_0_mse: 1078.5845947265625|  0:00:12s\n","epoch 19 | loss: 215.20245| val_0_mse: 614.6358642578125|  0:00:13s\n","epoch 20 | loss: 209.56712| val_0_mse: 709.2893676757812|  0:00:14s\n","epoch 21 | loss: 199.8201| val_0_mse: 693.1517333984375|  0:00:14s\n","epoch 22 | loss: 199.1104| val_0_mse: 477.5143127441406|  0:00:15s\n","epoch 23 | loss: 192.24061| val_0_mse: 691.5331420898438|  0:00:16s\n","epoch 24 | loss: 193.45989| val_0_mse: 336.54510498046875|  0:00:16s\n","epoch 25 | loss: 190.5581| val_0_mse: 405.54998779296875|  0:00:17s\n","epoch 26 | loss: 201.02961| val_0_mse: 386.6401062011719|  0:00:18s\n","epoch 27 | loss: 202.76249| val_0_mse: 294.9029235839844|  0:00:18s\n","epoch 28 | loss: 199.60828| val_0_mse: 278.6176452636719|  0:00:19s\n","epoch 29 | loss: 204.51024| val_0_mse: 300.343505859375|  0:00:20s\n","epoch 30 | loss: 186.30309| val_0_mse: 227.96624755859375|  0:00:20s\n","epoch 31 | loss: 184.59402| val_0_mse: 220.24493408203125|  0:00:21s\n","epoch 32 | loss: 192.33142| val_0_mse: 212.4895782470703|  0:00:22s\n","epoch 33 | loss: 189.41007| val_0_mse: 225.60914611816406|  0:00:22s\n","epoch 34 | loss: 187.31787| val_0_mse: 222.44842529296875|  0:00:23s\n","epoch 35 | loss: 192.12856| val_0_mse: 263.5899963378906|  0:00:24s\n","epoch 36 | loss: 200.23998| val_0_mse: 223.40774536132812|  0:00:24s\n","epoch 37 | loss: 187.22213| val_0_mse: 228.81642150878906|  0:00:25s\n","epoch 38 | loss: 184.75871| val_0_mse: 207.3147735595703|  0:00:26s\n","epoch 39 | loss: 189.48841| val_0_mse: 210.98330688476562|  0:00:27s\n","epoch 40 | loss: 179.89975| val_0_mse: 208.50497436523438|  0:00:27s\n","epoch 41 | loss: 175.7454| val_0_mse: 198.9685821533203|  0:00:28s\n","epoch 42 | loss: 178.21441| val_0_mse: 194.07814025878906|  0:00:28s\n","epoch 43 | loss: 177.93588| val_0_mse: 189.07882690429688|  0:00:29s\n","epoch 44 | loss: 172.48289| val_0_mse: 193.31756591796875|  0:00:30s\n","epoch 45 | loss: 170.8538| val_0_mse: 198.59629821777344|  0:00:30s\n","epoch 46 | loss: 179.47694| val_0_mse: 200.91981506347656|  0:00:31s\n","epoch 47 | loss: 180.10702| val_0_mse: 189.58880615234375|  0:00:32s\n","epoch 48 | loss: 171.53542| val_0_mse: 202.18084716796875|  0:00:32s\n","epoch 49 | loss: 175.5193| val_0_mse: 201.23260498046875|  0:00:33s\n","epoch 50 | loss: 173.34478| val_0_mse: 191.0637664794922|  0:00:34s\n","epoch 51 | loss: 172.98961| val_0_mse: 202.68655395507812|  0:00:34s\n","epoch 52 | loss: 178.14456| val_0_mse: 184.65780639648438|  0:00:35s\n","epoch 53 | loss: 181.77989| val_0_mse: 186.50784301757812|  0:00:36s\n","epoch 54 | loss: 172.18912| val_0_mse: 188.30020141601562|  0:00:36s\n","epoch 55 | loss: 169.30013| val_0_mse: 179.41342163085938|  0:00:37s\n","epoch 56 | loss: 168.29105| val_0_mse: 178.29847717285156|  0:00:38s\n","epoch 57 | loss: 159.62628| val_0_mse: 176.22421264648438|  0:00:38s\n","epoch 58 | loss: 160.83719| val_0_mse: 186.7238006591797|  0:00:39s\n","epoch 59 | loss: 165.75971| val_0_mse: 183.31512451171875|  0:00:40s\n","epoch 60 | loss: 165.65272| val_0_mse: 190.9629669189453|  0:00:41s\n","epoch 61 | loss: 162.55351| val_0_mse: 181.84388732910156|  0:00:41s\n","epoch 62 | loss: 166.69524| val_0_mse: 206.70245361328125|  0:00:42s\n","epoch 63 | loss: 161.47445| val_0_mse: 176.336181640625|  0:00:43s\n","epoch 64 | loss: 154.85696| val_0_mse: 178.58526611328125|  0:00:43s\n","epoch 65 | loss: 161.73556| val_0_mse: 184.19256591796875|  0:00:44s\n","epoch 66 | loss: 169.0427| val_0_mse: 181.9796142578125|  0:00:45s\n","epoch 67 | loss: 163.70383| val_0_mse: 185.82652282714844|  0:00:45s\n","\n","Early stopping occurred at epoch 67 with best_epoch = 57 and best_val_0_mse = 176.22421264648438\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 14:42:35,014] Trial 34 finished with value: 176.22422790527344 and parameters: {'n_d': 60, 'n_steps': 3, 'gamma': 1.4176017719255927, 'n_independent': 4, 'n_shared': 3, 'momentum': 0.14132785037014625}. Best is trial 33 with value: 135.8055877685547.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 1673.25651| val_0_mse: 6538.07568359375|  0:00:00s\n","epoch 1  | loss: 486.45633| val_0_mse: 7785.33447265625|  0:00:01s\n","epoch 2  | loss: 391.90855| val_0_mse: 2333.332275390625|  0:00:01s\n","epoch 3  | loss: 321.49961| val_0_mse: 1743.03515625|  0:00:02s\n","epoch 4  | loss: 325.29915| val_0_mse: 1922.4306640625|  0:00:02s\n","epoch 5  | loss: 275.54142| val_0_mse: 1435.1865234375|  0:00:03s\n","epoch 6  | loss: 265.68645| val_0_mse: 1211.59375|  0:00:03s\n","epoch 7  | loss: 253.3206| val_0_mse: 1209.614990234375|  0:00:04s\n","epoch 8  | loss: 249.80195| val_0_mse: 916.2307739257812|  0:00:04s\n","epoch 9  | loss: 244.714 | val_0_mse: 947.8592529296875|  0:00:05s\n","epoch 10 | loss: 232.71041| val_0_mse: 871.0557861328125|  0:00:06s\n","epoch 11 | loss: 240.91054| val_0_mse: 623.4906616210938|  0:00:06s\n","epoch 12 | loss: 236.2367| val_0_mse: 586.280517578125|  0:00:07s\n","epoch 13 | loss: 224.55416| val_0_mse: 405.3079528808594|  0:00:07s\n","epoch 14 | loss: 222.74089| val_0_mse: 378.7783508300781|  0:00:08s\n","epoch 15 | loss: 211.62815| val_0_mse: 415.95245361328125|  0:00:08s\n","epoch 16 | loss: 209.85931| val_0_mse: 419.9970703125|  0:00:09s\n","epoch 17 | loss: 208.31516| val_0_mse: 427.2395324707031|  0:00:09s\n","epoch 18 | loss: 210.43562| val_0_mse: 414.6605224609375|  0:00:10s\n","epoch 19 | loss: 208.03825| val_0_mse: 299.7256164550781|  0:00:11s\n","epoch 20 | loss: 218.87931| val_0_mse: 296.43988037109375|  0:00:11s\n","epoch 21 | loss: 220.65248| val_0_mse: 277.1794738769531|  0:00:12s\n","epoch 22 | loss: 208.10309| val_0_mse: 325.9238586425781|  0:00:12s\n","epoch 23 | loss: 199.8511| val_0_mse: 325.8500671386719|  0:00:13s\n","epoch 24 | loss: 205.84732| val_0_mse: 341.8330078125|  0:00:13s\n","epoch 25 | loss: 201.22267| val_0_mse: 446.2419738769531|  0:00:14s\n","epoch 26 | loss: 194.60924| val_0_mse: 233.04730224609375|  0:00:15s\n","epoch 27 | loss: 196.71152| val_0_mse: 282.90435791015625|  0:00:15s\n","epoch 28 | loss: 195.37762| val_0_mse: 388.0851745605469|  0:00:16s\n","epoch 29 | loss: 205.20377| val_0_mse: 215.16409301757812|  0:00:16s\n","epoch 30 | loss: 197.32137| val_0_mse: 216.41482543945312|  0:00:17s\n","epoch 31 | loss: 202.36529| val_0_mse: 240.37266540527344|  0:00:17s\n","epoch 32 | loss: 204.50343| val_0_mse: 211.67076110839844|  0:00:18s\n","epoch 33 | loss: 196.14709| val_0_mse: 203.48345947265625|  0:00:18s\n","epoch 34 | loss: 202.61309| val_0_mse: 199.8767852783203|  0:00:19s\n","epoch 35 | loss: 193.78522| val_0_mse: 203.6260528564453|  0:00:19s\n","epoch 36 | loss: 183.50558| val_0_mse: 264.7057189941406|  0:00:20s\n","epoch 37 | loss: 188.73607| val_0_mse: 199.50534057617188|  0:00:21s\n","epoch 38 | loss: 190.48109| val_0_mse: 190.84547424316406|  0:00:21s\n","epoch 39 | loss: 191.75692| val_0_mse: 219.73092651367188|  0:00:22s\n","epoch 40 | loss: 176.22066| val_0_mse: 212.1604461669922|  0:00:22s\n","epoch 41 | loss: 177.45957| val_0_mse: 186.50729370117188|  0:00:23s\n","epoch 42 | loss: 179.26894| val_0_mse: 197.00401306152344|  0:00:23s\n","epoch 43 | loss: 186.93952| val_0_mse: 275.6213684082031|  0:00:24s\n","epoch 44 | loss: 179.18598| val_0_mse: 183.7807159423828|  0:00:24s\n","epoch 45 | loss: 179.42921| val_0_mse: 192.85801696777344|  0:00:25s\n","epoch 46 | loss: 172.29596| val_0_mse: 175.72650146484375|  0:00:26s\n","epoch 47 | loss: 169.5862| val_0_mse: 178.7409210205078|  0:00:26s\n","epoch 48 | loss: 170.74819| val_0_mse: 181.57034301757812|  0:00:27s\n","epoch 49 | loss: 164.51664| val_0_mse: 227.32252502441406|  0:00:27s\n","epoch 50 | loss: 168.19374| val_0_mse: 185.07041931152344|  0:00:28s\n","epoch 51 | loss: 163.8131| val_0_mse: 174.4554443359375|  0:00:28s\n","epoch 52 | loss: 160.74582| val_0_mse: 175.20187377929688|  0:00:29s\n","epoch 53 | loss: 165.64566| val_0_mse: 175.2014617919922|  0:00:29s\n","epoch 54 | loss: 165.11728| val_0_mse: 181.7559356689453|  0:00:30s\n","epoch 55 | loss: 165.63125| val_0_mse: 178.3815155029297|  0:00:30s\n","epoch 56 | loss: 168.27574| val_0_mse: 165.5084228515625|  0:00:31s\n","epoch 57 | loss: 159.67094| val_0_mse: 171.8505859375|  0:00:31s\n","epoch 58 | loss: 158.14885| val_0_mse: 165.2581024169922|  0:00:32s\n","epoch 59 | loss: 158.54526| val_0_mse: 164.71437072753906|  0:00:33s\n","epoch 60 | loss: 148.75822| val_0_mse: 177.9117431640625|  0:00:33s\n","epoch 61 | loss: 153.82786| val_0_mse: 195.2161407470703|  0:00:34s\n","epoch 62 | loss: 161.22724| val_0_mse: 183.71322631835938|  0:00:34s\n","epoch 63 | loss: 161.52657| val_0_mse: 172.01231384277344|  0:00:35s\n","epoch 64 | loss: 158.36677| val_0_mse: 160.34237670898438|  0:00:35s\n","epoch 65 | loss: 154.17374| val_0_mse: 173.1195831298828|  0:00:36s\n","epoch 66 | loss: 152.24488| val_0_mse: 160.04989624023438|  0:00:36s\n","epoch 67 | loss: 153.72703| val_0_mse: 164.50196838378906|  0:00:37s\n","epoch 68 | loss: 149.7447| val_0_mse: 172.6241455078125|  0:00:38s\n","epoch 69 | loss: 152.23192| val_0_mse: 183.85000610351562|  0:00:38s\n","epoch 70 | loss: 142.64029| val_0_mse: 168.2629852294922|  0:00:39s\n","epoch 71 | loss: 150.82644| val_0_mse: 151.5041046142578|  0:00:39s\n","epoch 72 | loss: 149.93555| val_0_mse: 156.9125213623047|  0:00:40s\n","epoch 73 | loss: 141.08862| val_0_mse: 178.122314453125|  0:00:40s\n","epoch 74 | loss: 145.39536| val_0_mse: 214.51791381835938|  0:00:41s\n","epoch 75 | loss: 147.68819| val_0_mse: 231.91357421875|  0:00:41s\n","epoch 76 | loss: 149.07785| val_0_mse: 160.5906982421875|  0:00:42s\n","epoch 77 | loss: 138.31539| val_0_mse: 183.79827880859375|  0:00:42s\n","epoch 78 | loss: 136.25647| val_0_mse: 178.2464141845703|  0:00:43s\n","epoch 79 | loss: 139.37616| val_0_mse: 145.7207489013672|  0:00:44s\n","epoch 80 | loss: 145.52726| val_0_mse: 155.4190673828125|  0:00:44s\n","epoch 81 | loss: 136.53536| val_0_mse: 150.80999755859375|  0:00:45s\n","epoch 82 | loss: 136.98169| val_0_mse: 166.87847900390625|  0:00:45s\n","epoch 83 | loss: 138.5592| val_0_mse: 158.522705078125|  0:00:46s\n","epoch 84 | loss: 142.9806| val_0_mse: 156.63751220703125|  0:00:46s\n","epoch 85 | loss: 142.40662| val_0_mse: 149.6842803955078|  0:00:47s\n","epoch 86 | loss: 136.78978| val_0_mse: 148.0171661376953|  0:00:47s\n","epoch 87 | loss: 142.13138| val_0_mse: 157.56556701660156|  0:00:48s\n","epoch 88 | loss: 132.98537| val_0_mse: 149.56964111328125|  0:00:49s\n","epoch 89 | loss: 143.21699| val_0_mse: 160.71450805664062|  0:00:49s\n","\n","Early stopping occurred at epoch 89 with best_epoch = 79 and best_val_0_mse = 145.7207489013672\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 14:43:24,990] Trial 35 finished with value: 145.7207489013672 and parameters: {'n_d': 57, 'n_steps': 3, 'gamma': 1.4441528348987127, 'n_independent': 3, 'n_shared': 2, 'momentum': 0.05583911547046002}. Best is trial 33 with value: 135.8055877685547.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 1634.38501| val_0_mse: 101108.4921875|  0:00:00s\n","epoch 1  | loss: 520.25304| val_0_mse: 3191.697509765625|  0:00:01s\n","epoch 2  | loss: 407.3464| val_0_mse: 1158.3077392578125|  0:00:02s\n","epoch 3  | loss: 363.07799| val_0_mse: 5563.8037109375|  0:00:02s\n","epoch 4  | loss: 328.4441| val_0_mse: 3814.082763671875|  0:00:03s\n","epoch 5  | loss: 286.96326| val_0_mse: 864.3060913085938|  0:00:04s\n","epoch 6  | loss: 271.4352| val_0_mse: 5325.380859375|  0:00:04s\n","epoch 7  | loss: 266.42898| val_0_mse: 2384.0869140625|  0:00:05s\n","epoch 8  | loss: 264.25705| val_0_mse: 1099.755126953125|  0:00:06s\n","epoch 9  | loss: 259.02014| val_0_mse: 2158.411865234375|  0:00:06s\n","epoch 10 | loss: 241.94501| val_0_mse: 1182.8260498046875|  0:00:07s\n","epoch 11 | loss: 246.06061| val_0_mse: 1567.426025390625|  0:00:08s\n","epoch 12 | loss: 237.13362| val_0_mse: 1217.3912353515625|  0:00:08s\n","epoch 13 | loss: 226.35749| val_0_mse: 628.5452880859375|  0:00:09s\n","epoch 14 | loss: 217.13323| val_0_mse: 480.3621520996094|  0:00:10s\n","epoch 15 | loss: 212.9019| val_0_mse: 503.3664855957031|  0:00:11s\n","epoch 16 | loss: 207.42778| val_0_mse: 347.43072509765625|  0:00:11s\n","epoch 17 | loss: 208.25979| val_0_mse: 291.8316345214844|  0:00:12s\n","epoch 18 | loss: 201.4551| val_0_mse: 373.2024841308594|  0:00:13s\n","epoch 19 | loss: 207.70141| val_0_mse: 288.06719970703125|  0:00:13s\n","epoch 20 | loss: 209.79319| val_0_mse: 381.9603576660156|  0:00:14s\n","epoch 21 | loss: 203.60312| val_0_mse: 355.54058837890625|  0:00:15s\n","epoch 22 | loss: 199.49996| val_0_mse: 341.9228820800781|  0:00:16s\n","epoch 23 | loss: 197.82258| val_0_mse: 304.7986145019531|  0:00:16s\n","epoch 24 | loss: 192.23368| val_0_mse: 228.7191925048828|  0:00:17s\n","epoch 25 | loss: 205.73925| val_0_mse: 233.05526733398438|  0:00:18s\n","epoch 26 | loss: 211.04567| val_0_mse: 224.30589294433594|  0:00:18s\n","epoch 27 | loss: 197.77282| val_0_mse: 217.74876403808594|  0:00:19s\n","epoch 28 | loss: 193.10891| val_0_mse: 338.31732177734375|  0:00:20s\n","epoch 29 | loss: 191.36203| val_0_mse: 212.605712890625|  0:00:20s\n","epoch 30 | loss: 186.67085| val_0_mse: 215.67503356933594|  0:00:21s\n","epoch 31 | loss: 188.80161| val_0_mse: 213.3633575439453|  0:00:22s\n","epoch 32 | loss: 188.9821| val_0_mse: 301.3041687011719|  0:00:22s\n","epoch 33 | loss: 194.2673| val_0_mse: 249.53952026367188|  0:00:23s\n","epoch 34 | loss: 186.87276| val_0_mse: 208.7246856689453|  0:00:24s\n","epoch 35 | loss: 196.72658| val_0_mse: 207.4845733642578|  0:00:24s\n","epoch 36 | loss: 184.77751| val_0_mse: 206.5772247314453|  0:00:25s\n","epoch 37 | loss: 185.2195| val_0_mse: 190.36459350585938|  0:00:26s\n","epoch 38 | loss: 183.66504| val_0_mse: 202.97354125976562|  0:00:26s\n","epoch 39 | loss: 185.08474| val_0_mse: 230.43057250976562|  0:00:27s\n","epoch 40 | loss: 180.90728| val_0_mse: 219.13720703125|  0:00:28s\n","epoch 41 | loss: 174.35797| val_0_mse: 194.85238647460938|  0:00:28s\n","epoch 42 | loss: 177.27603| val_0_mse: 242.5220947265625|  0:00:29s\n","epoch 43 | loss: 178.03653| val_0_mse: 268.8468322753906|  0:00:30s\n","epoch 44 | loss: 192.97526| val_0_mse: 214.28733825683594|  0:00:30s\n","epoch 45 | loss: 213.39085| val_0_mse: 229.9571075439453|  0:00:31s\n","epoch 46 | loss: 199.02997| val_0_mse: 246.66293334960938|  0:00:32s\n","epoch 47 | loss: 192.56179| val_0_mse: 203.48789978027344|  0:00:32s\n","\n","Early stopping occurred at epoch 47 with best_epoch = 37 and best_val_0_mse = 190.36459350585938\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 14:43:58,266] Trial 36 finished with value: 190.36460876464844 and parameters: {'n_d': 57, 'n_steps': 3, 'gamma': 1.2892481135846576, 'n_independent': 5, 'n_shared': 2, 'momentum': 0.06336588442970055}. Best is trial 33 with value: 135.8055877685547.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 1649.51103| val_0_mse: 75235.109375|  0:00:00s\n","epoch 1  | loss: 609.54206| val_0_mse: 6830.6875|  0:00:01s\n","epoch 2  | loss: 453.86812| val_0_mse: 1750.4212646484375|  0:00:02s\n","epoch 3  | loss: 419.12351| val_0_mse: 8172.162109375|  0:00:02s\n","epoch 4  | loss: 410.96621| val_0_mse: 1618.88720703125|  0:00:03s\n","epoch 5  | loss: 391.77596| val_0_mse: 1320.99609375|  0:00:04s\n","epoch 6  | loss: 398.13869| val_0_mse: 14113.0458984375|  0:00:04s\n","epoch 7  | loss: 394.86697| val_0_mse: 4208.42529296875|  0:00:05s\n","epoch 8  | loss: 365.24163| val_0_mse: 2047.3372802734375|  0:00:06s\n","epoch 9  | loss: 315.08985| val_0_mse: 883.2842407226562|  0:00:06s\n","epoch 10 | loss: 300.64589| val_0_mse: 887.7208251953125|  0:00:07s\n","epoch 11 | loss: 281.85046| val_0_mse: 1105.967529296875|  0:00:07s\n","epoch 12 | loss: 274.25177| val_0_mse: 1215.183349609375|  0:00:08s\n","epoch 13 | loss: 271.12875| val_0_mse: 873.3663940429688|  0:00:09s\n","epoch 14 | loss: 265.8546| val_0_mse: 1035.0684814453125|  0:00:09s\n","epoch 15 | loss: 252.55924| val_0_mse: 1075.479248046875|  0:00:10s\n","epoch 16 | loss: 258.36255| val_0_mse: 600.8667602539062|  0:00:11s\n","epoch 17 | loss: 244.77915| val_0_mse: 360.5367126464844|  0:00:12s\n","epoch 18 | loss: 235.7311| val_0_mse: 419.929931640625|  0:00:12s\n","epoch 19 | loss: 225.19628| val_0_mse: 381.6517333984375|  0:00:13s\n","epoch 20 | loss: 218.91077| val_0_mse: 382.689453125|  0:00:14s\n","epoch 21 | loss: 219.29048| val_0_mse: 367.1405334472656|  0:00:14s\n","epoch 22 | loss: 216.10127| val_0_mse: 322.0238952636719|  0:00:15s\n","epoch 23 | loss: 203.03488| val_0_mse: 272.1848449707031|  0:00:15s\n","epoch 24 | loss: 211.5568| val_0_mse: 401.6165466308594|  0:00:16s\n","epoch 25 | loss: 209.36233| val_0_mse: 313.66015625|  0:00:17s\n","epoch 26 | loss: 198.92332| val_0_mse: 289.8651123046875|  0:00:17s\n","epoch 27 | loss: 201.76926| val_0_mse: 226.3025665283203|  0:00:18s\n","epoch 28 | loss: 200.35887| val_0_mse: 476.69189453125|  0:00:19s\n","epoch 29 | loss: 191.39376| val_0_mse: 215.48611450195312|  0:00:19s\n","epoch 30 | loss: 193.26629| val_0_mse: 303.07672119140625|  0:00:20s\n","epoch 31 | loss: 191.80229| val_0_mse: 203.95445251464844|  0:00:21s\n","epoch 32 | loss: 183.00512| val_0_mse: 289.90142822265625|  0:00:21s\n","epoch 33 | loss: 184.84615| val_0_mse: 200.28128051757812|  0:00:22s\n","epoch 34 | loss: 186.50088| val_0_mse: 265.9515075683594|  0:00:23s\n","epoch 35 | loss: 184.60231| val_0_mse: 202.5596466064453|  0:00:24s\n","epoch 36 | loss: 174.95625| val_0_mse: 214.5825958251953|  0:00:24s\n","epoch 37 | loss: 180.61645| val_0_mse: 213.08522033691406|  0:00:25s\n","epoch 38 | loss: 186.90734| val_0_mse: 281.7249450683594|  0:00:26s\n","epoch 39 | loss: 175.43209| val_0_mse: 187.24171447753906|  0:00:26s\n","epoch 40 | loss: 172.35953| val_0_mse: 193.56971740722656|  0:00:27s\n","epoch 41 | loss: 182.31187| val_0_mse: 190.1688995361328|  0:00:28s\n","epoch 42 | loss: 181.32579| val_0_mse: 214.18011474609375|  0:00:28s\n","epoch 43 | loss: 177.26152| val_0_mse: 213.56370544433594|  0:00:29s\n","epoch 44 | loss: 168.80867| val_0_mse: 181.90379333496094|  0:00:30s\n","epoch 45 | loss: 170.86672| val_0_mse: 242.1968231201172|  0:00:30s\n","epoch 46 | loss: 171.08153| val_0_mse: 200.21336364746094|  0:00:31s\n","epoch 47 | loss: 172.03142| val_0_mse: 184.0059356689453|  0:00:32s\n","epoch 48 | loss: 179.23037| val_0_mse: 194.24008178710938|  0:00:32s\n","epoch 49 | loss: 179.01071| val_0_mse: 196.7011260986328|  0:00:33s\n","epoch 50 | loss: 175.52329| val_0_mse: 267.62738037109375|  0:00:34s\n","epoch 51 | loss: 172.05353| val_0_mse: 193.4285430908203|  0:00:34s\n","epoch 52 | loss: 171.15116| val_0_mse: 212.7131805419922|  0:00:35s\n","epoch 53 | loss: 167.82829| val_0_mse: 192.30990600585938|  0:00:36s\n","epoch 54 | loss: 171.72896| val_0_mse: 187.73382568359375|  0:00:36s\n","\n","Early stopping occurred at epoch 54 with best_epoch = 44 and best_val_0_mse = 181.90379333496094\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 14:44:35,410] Trial 37 finished with value: 181.90380859375 and parameters: {'n_d': 64, 'n_steps': 5, 'gamma': 1.4562218320329778, 'n_independent': 3, 'n_shared': 1, 'momentum': 0.03213854878101695}. Best is trial 33 with value: 135.8055877685547.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 2233.74931| val_0_mse: 6728.27587890625|  0:00:01s\n","epoch 1  | loss: 1154.12297| val_0_mse: 13598.685546875|  0:00:02s\n","epoch 2  | loss: 721.86829| val_0_mse: 2578.1787109375|  0:00:03s\n","epoch 3  | loss: 629.14886| val_0_mse: 3803.88671875|  0:00:04s\n","epoch 4  | loss: 534.41087| val_0_mse: 1051.83349609375|  0:00:06s\n","epoch 5  | loss: 504.27454| val_0_mse: 2915.998779296875|  0:00:07s\n","epoch 6  | loss: 505.77993| val_0_mse: 2424.12548828125|  0:00:08s\n","epoch 7  | loss: 490.17302| val_0_mse: 1197.6982421875|  0:00:10s\n","epoch 8  | loss: 477.87047| val_0_mse: 1398.360107421875|  0:00:11s\n","epoch 9  | loss: 496.66254| val_0_mse: 808.685546875|  0:00:12s\n","epoch 10 | loss: 439.5583| val_0_mse: 1245.072509765625|  0:00:13s\n","epoch 11 | loss: 446.34214| val_0_mse: 969.5166625976562|  0:00:15s\n","epoch 12 | loss: 449.46531| val_0_mse: 1844.7447509765625|  0:00:16s\n","epoch 13 | loss: 417.75171| val_0_mse: 845.8831787109375|  0:00:17s\n","epoch 14 | loss: 451.24731| val_0_mse: 541.7088623046875|  0:00:18s\n","epoch 15 | loss: 475.41504| val_0_mse: 481.0129089355469|  0:00:20s\n","epoch 16 | loss: 435.23182| val_0_mse: 647.9815063476562|  0:00:21s\n","epoch 17 | loss: 395.00277| val_0_mse: 900.9017333984375|  0:00:22s\n","epoch 18 | loss: 399.91777| val_0_mse: 636.7255249023438|  0:00:23s\n","epoch 19 | loss: 420.48492| val_0_mse: 542.6046752929688|  0:00:25s\n","epoch 20 | loss: 425.68393| val_0_mse: 503.0633544921875|  0:00:26s\n","epoch 21 | loss: 405.73013| val_0_mse: 529.7816162109375|  0:00:27s\n","epoch 22 | loss: 428.41486| val_0_mse: 462.50146484375|  0:00:28s\n","epoch 23 | loss: 426.3057| val_0_mse: 446.3503112792969|  0:00:30s\n","epoch 24 | loss: 406.10281| val_0_mse: 461.7454528808594|  0:00:31s\n","epoch 25 | loss: 395.32034| val_0_mse: 523.2978515625|  0:00:32s\n","epoch 26 | loss: 389.07424| val_0_mse: 391.3775634765625|  0:00:33s\n","epoch 27 | loss: 354.46741| val_0_mse: 407.63995361328125|  0:00:35s\n","epoch 28 | loss: 342.58987| val_0_mse: 365.7331848144531|  0:00:36s\n","epoch 29 | loss: 352.10596| val_0_mse: 388.9364318847656|  0:00:37s\n","epoch 30 | loss: 332.71303| val_0_mse: 365.2268371582031|  0:00:38s\n","epoch 31 | loss: 329.70664| val_0_mse: 402.5386657714844|  0:00:40s\n","epoch 32 | loss: 345.01638| val_0_mse: 364.51763916015625|  0:00:41s\n","epoch 33 | loss: 333.99929| val_0_mse: 332.6195983886719|  0:00:42s\n","epoch 34 | loss: 332.1884| val_0_mse: 418.0224914550781|  0:00:44s\n","epoch 35 | loss: 366.21156| val_0_mse: 402.0708923339844|  0:00:45s\n","epoch 36 | loss: 340.54084| val_0_mse: 320.02813720703125|  0:00:46s\n","epoch 37 | loss: 299.67806| val_0_mse: 304.85723876953125|  0:00:47s\n","epoch 38 | loss: 299.79527| val_0_mse: 324.029296875|  0:00:49s\n","epoch 39 | loss: 299.27679| val_0_mse: 280.9521789550781|  0:00:50s\n","epoch 40 | loss: 278.22769| val_0_mse: 281.3785095214844|  0:00:51s\n","epoch 41 | loss: 281.086 | val_0_mse: 305.25518798828125|  0:00:52s\n","epoch 42 | loss: 267.22361| val_0_mse: 264.76318359375|  0:00:54s\n","epoch 43 | loss: 267.52203| val_0_mse: 252.93267822265625|  0:00:55s\n","epoch 44 | loss: 265.60112| val_0_mse: 292.74725341796875|  0:00:56s\n","epoch 45 | loss: 278.10619| val_0_mse: 275.836181640625|  0:00:57s\n","epoch 46 | loss: 271.18553| val_0_mse: 267.153564453125|  0:00:59s\n","epoch 47 | loss: 254.96304| val_0_mse: 257.89447021484375|  0:01:00s\n","epoch 48 | loss: 255.16104| val_0_mse: 241.6013946533203|  0:01:01s\n","epoch 49 | loss: 255.54879| val_0_mse: 252.84573364257812|  0:01:03s\n","epoch 50 | loss: 256.4081| val_0_mse: 245.1387939453125|  0:01:04s\n","epoch 51 | loss: 253.24503| val_0_mse: 250.2944793701172|  0:01:05s\n","epoch 52 | loss: 249.55097| val_0_mse: 255.18923950195312|  0:01:06s\n","epoch 53 | loss: 261.28372| val_0_mse: 241.4259033203125|  0:01:08s\n","epoch 54 | loss: 238.66691| val_0_mse: 253.767333984375|  0:01:09s\n","epoch 55 | loss: 245.45658| val_0_mse: 235.9717254638672|  0:01:10s\n","epoch 56 | loss: 232.09586| val_0_mse: 224.73843383789062|  0:01:11s\n","epoch 57 | loss: 228.7372| val_0_mse: 228.26150512695312|  0:01:13s\n","epoch 58 | loss: 221.10154| val_0_mse: 220.00381469726562|  0:01:14s\n","epoch 59 | loss: 223.68203| val_0_mse: 222.66610717773438|  0:01:15s\n","epoch 60 | loss: 225.6743| val_0_mse: 215.79632568359375|  0:01:17s\n","epoch 61 | loss: 220.99411| val_0_mse: 235.07766723632812|  0:01:18s\n","epoch 62 | loss: 226.8621| val_0_mse: 223.58981323242188|  0:01:19s\n","epoch 63 | loss: 218.68222| val_0_mse: 208.8183135986328|  0:01:21s\n","epoch 64 | loss: 210.34865| val_0_mse: 224.18380737304688|  0:01:22s\n","epoch 65 | loss: 212.48993| val_0_mse: 215.73631286621094|  0:01:23s\n","epoch 66 | loss: 218.98718| val_0_mse: 240.88504028320312|  0:01:25s\n","epoch 67 | loss: 225.43521| val_0_mse: 230.40237426757812|  0:01:26s\n","epoch 68 | loss: 218.81348| val_0_mse: 213.47511291503906|  0:01:27s\n","epoch 69 | loss: 225.58739| val_0_mse: 224.01014709472656|  0:01:28s\n","epoch 70 | loss: 216.29376| val_0_mse: 199.31919860839844|  0:01:30s\n","epoch 71 | loss: 198.70812| val_0_mse: 225.34219360351562|  0:01:31s\n","epoch 72 | loss: 219.09498| val_0_mse: 218.64862060546875|  0:01:32s\n","epoch 73 | loss: 201.59579| val_0_mse: 204.99339294433594|  0:01:34s\n","epoch 74 | loss: 202.44465| val_0_mse: 204.24334716796875|  0:01:35s\n","epoch 75 | loss: 195.28747| val_0_mse: 199.34144592285156|  0:01:36s\n","epoch 76 | loss: 196.20345| val_0_mse: 205.39141845703125|  0:01:37s\n","epoch 77 | loss: 196.34384| val_0_mse: 197.53245544433594|  0:01:39s\n","epoch 78 | loss: 195.2165| val_0_mse: 191.17706298828125|  0:01:40s\n","epoch 79 | loss: 191.58424| val_0_mse: 204.19679260253906|  0:01:41s\n","epoch 80 | loss: 196.03256| val_0_mse: 223.37896728515625|  0:01:42s\n","epoch 81 | loss: 210.52985| val_0_mse: 212.72372436523438|  0:01:44s\n","epoch 82 | loss: 192.70743| val_0_mse: 247.23797607421875|  0:01:45s\n","epoch 83 | loss: 202.69851| val_0_mse: 216.25840759277344|  0:01:46s\n","epoch 84 | loss: 204.33241| val_0_mse: 213.95852661132812|  0:01:48s\n","epoch 85 | loss: 219.30061| val_0_mse: 231.31216430664062|  0:01:49s\n","epoch 86 | loss: 220.09256| val_0_mse: 219.6817626953125|  0:01:50s\n","epoch 87 | loss: 217.79449| val_0_mse: 217.523193359375|  0:01:51s\n","epoch 88 | loss: 206.30354| val_0_mse: 211.2440643310547|  0:01:53s\n","\n","Early stopping occurred at epoch 88 with best_epoch = 78 and best_val_0_mse = 191.17706298828125\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 14:46:29,359] Trial 38 finished with value: 191.17706298828125 and parameters: {'n_d': 46, 'n_steps': 8, 'gamma': 1.5820012979727316, 'n_independent': 4, 'n_shared': 2, 'momentum': 0.09233590882242063}. Best is trial 33 with value: 135.8055877685547.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 1838.91985| val_0_mse: 19554.509765625|  0:00:00s\n","epoch 1  | loss: 633.29645| val_0_mse: 16247.5810546875|  0:00:01s\n","epoch 2  | loss: 404.99037| val_0_mse: 7101.37548828125|  0:00:01s\n","epoch 3  | loss: 359.9199| val_0_mse: 2252.496337890625|  0:00:02s\n","epoch 4  | loss: 318.19545| val_0_mse: 2146.773193359375|  0:00:02s\n","epoch 5  | loss: 302.11048| val_0_mse: 1533.942138671875|  0:00:03s\n","epoch 6  | loss: 288.5845| val_0_mse: 1123.630126953125|  0:00:04s\n","epoch 7  | loss: 289.19833| val_0_mse: 1404.3575439453125|  0:00:04s\n","epoch 8  | loss: 276.51395| val_0_mse: 540.6616821289062|  0:00:05s\n","epoch 9  | loss: 246.20896| val_0_mse: 458.56695556640625|  0:00:05s\n","epoch 10 | loss: 239.34582| val_0_mse: 442.2584533691406|  0:00:06s\n","epoch 11 | loss: 230.0509| val_0_mse: 365.48553466796875|  0:00:06s\n","epoch 12 | loss: 236.04421| val_0_mse: 452.74713134765625|  0:00:07s\n","epoch 13 | loss: 232.97217| val_0_mse: 405.2152404785156|  0:00:07s\n","epoch 14 | loss: 242.01185| val_0_mse: 392.74566650390625|  0:00:08s\n","epoch 15 | loss: 234.03242| val_0_mse: 393.3057556152344|  0:00:09s\n","epoch 16 | loss: 216.2962| val_0_mse: 433.1370544433594|  0:00:09s\n","epoch 17 | loss: 212.1659| val_0_mse: 359.6072082519531|  0:00:10s\n","epoch 18 | loss: 198.06739| val_0_mse: 316.0983581542969|  0:00:10s\n","epoch 19 | loss: 204.56495| val_0_mse: 290.23260498046875|  0:00:11s\n","epoch 20 | loss: 206.58985| val_0_mse: 329.6384582519531|  0:00:11s\n","epoch 21 | loss: 204.07133| val_0_mse: 305.6654052734375|  0:00:12s\n","epoch 22 | loss: 183.91947| val_0_mse: 268.2848815917969|  0:00:12s\n","epoch 23 | loss: 193.66587| val_0_mse: 226.1611328125|  0:00:13s\n","epoch 24 | loss: 186.79934| val_0_mse: 250.43528747558594|  0:00:13s\n","epoch 25 | loss: 196.8991| val_0_mse: 280.85992431640625|  0:00:14s\n","epoch 26 | loss: 187.33455| val_0_mse: 255.38876342773438|  0:00:15s\n","epoch 27 | loss: 181.66812| val_0_mse: 260.1667175292969|  0:00:15s\n","epoch 28 | loss: 182.73161| val_0_mse: 205.76986694335938|  0:00:16s\n","epoch 29 | loss: 182.80654| val_0_mse: 208.30816650390625|  0:00:16s\n","epoch 30 | loss: 177.68867| val_0_mse: 292.8373107910156|  0:00:17s\n","epoch 31 | loss: 179.76362| val_0_mse: 195.81251525878906|  0:00:17s\n","epoch 32 | loss: 185.48712| val_0_mse: 220.45065307617188|  0:00:18s\n","epoch 33 | loss: 169.68371| val_0_mse: 196.15956115722656|  0:00:18s\n","epoch 34 | loss: 170.64295| val_0_mse: 205.16156005859375|  0:00:19s\n","epoch 35 | loss: 173.38646| val_0_mse: 186.26898193359375|  0:00:19s\n","epoch 36 | loss: 172.44457| val_0_mse: 223.96888732910156|  0:00:20s\n","epoch 37 | loss: 170.21238| val_0_mse: 187.63180541992188|  0:00:21s\n","epoch 38 | loss: 170.47672| val_0_mse: 207.67898559570312|  0:00:21s\n","epoch 39 | loss: 169.70108| val_0_mse: 187.78480529785156|  0:00:22s\n","epoch 40 | loss: 166.59104| val_0_mse: 175.65374755859375|  0:00:22s\n","epoch 41 | loss: 162.7286| val_0_mse: 167.3778839111328|  0:00:23s\n","epoch 42 | loss: 160.17098| val_0_mse: 209.7314453125|  0:00:23s\n","epoch 43 | loss: 167.05829| val_0_mse: 227.36752319335938|  0:00:24s\n","epoch 44 | loss: 162.17149| val_0_mse: 181.54095458984375|  0:00:25s\n","epoch 45 | loss: 166.84759| val_0_mse: 171.45762634277344|  0:00:25s\n","epoch 46 | loss: 165.11561| val_0_mse: 174.416259765625|  0:00:26s\n","epoch 47 | loss: 163.20136| val_0_mse: 161.82008361816406|  0:00:26s\n","epoch 48 | loss: 164.51876| val_0_mse: 179.66885375976562|  0:00:27s\n","epoch 49 | loss: 157.67506| val_0_mse: 199.05685424804688|  0:00:27s\n","epoch 50 | loss: 162.87588| val_0_mse: 185.31387329101562|  0:00:28s\n","epoch 51 | loss: 154.72062| val_0_mse: 175.24188232421875|  0:00:28s\n","epoch 52 | loss: 155.13135| val_0_mse: 168.40521240234375|  0:00:29s\n","epoch 53 | loss: 158.54667| val_0_mse: 167.62911987304688|  0:00:29s\n","epoch 54 | loss: 154.58515| val_0_mse: 156.05587768554688|  0:00:30s\n","epoch 55 | loss: 153.6213| val_0_mse: 164.3140869140625|  0:00:30s\n","epoch 56 | loss: 154.2029| val_0_mse: 162.61941528320312|  0:00:31s\n","epoch 57 | loss: 150.24886| val_0_mse: 157.64266967773438|  0:00:32s\n","epoch 58 | loss: 148.43225| val_0_mse: 175.7804412841797|  0:00:32s\n","epoch 59 | loss: 152.487 | val_0_mse: 214.188720703125|  0:00:33s\n","epoch 60 | loss: 147.72423| val_0_mse: 156.2969512939453|  0:00:33s\n","epoch 61 | loss: 145.53731| val_0_mse: 156.51332092285156|  0:00:34s\n","epoch 62 | loss: 145.82388| val_0_mse: 159.4718017578125|  0:00:34s\n","epoch 63 | loss: 146.40752| val_0_mse: 173.0301971435547|  0:00:35s\n","epoch 64 | loss: 139.76396| val_0_mse: 159.17454528808594|  0:00:35s\n","\n","Early stopping occurred at epoch 64 with best_epoch = 54 and best_val_0_mse = 156.05587768554688\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 14:47:05,558] Trial 39 finished with value: 156.05587768554688 and parameters: {'n_d': 42, 'n_steps': 3, 'gamma': 1.2792979826815345, 'n_independent': 3, 'n_shared': 2, 'momentum': 0.3062787379285919}. Best is trial 33 with value: 135.8055877685547.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 1619.21665| val_0_mse: 106118.8984375|  0:00:00s\n","epoch 1  | loss: 744.88119| val_0_mse: 19728.62109375|  0:00:01s\n","epoch 2  | loss: 609.49538| val_0_mse: 7134.6572265625|  0:00:02s\n","epoch 3  | loss: 532.19574| val_0_mse: 1895.7535400390625|  0:00:03s\n","epoch 4  | loss: 516.42255| val_0_mse: 1969.0506591796875|  0:00:04s\n","epoch 5  | loss: 518.58854| val_0_mse: 1188.6495361328125|  0:00:06s\n","epoch 6  | loss: 485.4018| val_0_mse: 1167.0528564453125|  0:00:07s\n","epoch 7  | loss: 488.42431| val_0_mse: 908.196533203125|  0:00:08s\n","epoch 8  | loss: 473.2852| val_0_mse: 1012.0548706054688|  0:00:09s\n","epoch 9  | loss: 439.38882| val_0_mse: 941.0562133789062|  0:00:10s\n","epoch 10 | loss: 462.5495| val_0_mse: 700.8115844726562|  0:00:11s\n","epoch 11 | loss: 473.12361| val_0_mse: 671.1068115234375|  0:00:12s\n","epoch 12 | loss: 476.65058| val_0_mse: 889.7819213867188|  0:00:13s\n","epoch 13 | loss: 445.26933| val_0_mse: 1160.0552978515625|  0:00:14s\n","epoch 14 | loss: 452.10191| val_0_mse: 519.0524291992188|  0:00:15s\n","epoch 15 | loss: 468.11285| val_0_mse: 735.5940551757812|  0:00:15s\n","epoch 16 | loss: 428.0618| val_0_mse: 591.6837768554688|  0:00:16s\n","epoch 17 | loss: 380.128 | val_0_mse: 478.0751953125|  0:00:17s\n","epoch 18 | loss: 336.41674| val_0_mse: 425.96136474609375|  0:00:18s\n","epoch 19 | loss: 349.98311| val_0_mse: 446.22747802734375|  0:00:20s\n","epoch 20 | loss: 344.97145| val_0_mse: 512.1392211914062|  0:00:21s\n","epoch 21 | loss: 322.92823| val_0_mse: 420.9822692871094|  0:00:21s\n","epoch 22 | loss: 325.89986| val_0_mse: 424.13372802734375|  0:00:22s\n","epoch 23 | loss: 340.35263| val_0_mse: 398.60028076171875|  0:00:24s\n","epoch 24 | loss: 344.02862| val_0_mse: 370.3799743652344|  0:00:25s\n","epoch 25 | loss: 336.61576| val_0_mse: 346.22906494140625|  0:00:26s\n","epoch 26 | loss: 340.01683| val_0_mse: 403.43597412109375|  0:00:27s\n","epoch 27 | loss: 330.18565| val_0_mse: 341.2891540527344|  0:00:27s\n","epoch 28 | loss: 304.33601| val_0_mse: 297.1713562011719|  0:00:29s\n","epoch 29 | loss: 283.75497| val_0_mse: 313.9963073730469|  0:00:30s\n","epoch 30 | loss: 278.69489| val_0_mse: 337.6407165527344|  0:00:31s\n","epoch 31 | loss: 292.82746| val_0_mse: 262.3223571777344|  0:00:32s\n","epoch 32 | loss: 268.41545| val_0_mse: 276.5146484375|  0:00:33s\n","epoch 33 | loss: 280.32329| val_0_mse: 294.75067138671875|  0:00:34s\n","epoch 34 | loss: 277.09695| val_0_mse: 277.5075988769531|  0:00:35s\n","epoch 35 | loss: 283.05506| val_0_mse: 260.9606628417969|  0:00:36s\n","epoch 36 | loss: 260.36897| val_0_mse: 275.93414306640625|  0:00:37s\n","epoch 37 | loss: 261.58915| val_0_mse: 333.0212097167969|  0:00:38s\n","epoch 38 | loss: 254.66256| val_0_mse: 252.82565307617188|  0:00:39s\n","epoch 39 | loss: 248.99612| val_0_mse: 246.68275451660156|  0:00:40s\n","epoch 40 | loss: 238.70204| val_0_mse: 242.9033966064453|  0:00:41s\n","epoch 41 | loss: 249.48314| val_0_mse: 284.92169189453125|  0:00:42s\n","epoch 42 | loss: 252.74134| val_0_mse: 243.7843780517578|  0:00:43s\n","epoch 43 | loss: 231.73345| val_0_mse: 230.7006378173828|  0:00:44s\n","epoch 44 | loss: 225.78419| val_0_mse: 221.58355712890625|  0:00:45s\n","epoch 45 | loss: 219.53502| val_0_mse: 241.79580688476562|  0:00:46s\n","epoch 46 | loss: 219.35122| val_0_mse: 222.32275390625|  0:00:47s\n","epoch 47 | loss: 215.70747| val_0_mse: 217.29591369628906|  0:00:48s\n","epoch 48 | loss: 207.99571| val_0_mse: 231.6988983154297|  0:00:49s\n","epoch 49 | loss: 214.85966| val_0_mse: 211.27145385742188|  0:00:50s\n","epoch 50 | loss: 207.3951| val_0_mse: 217.8978729248047|  0:00:51s\n","epoch 51 | loss: 214.62559| val_0_mse: 216.81796264648438|  0:00:52s\n","epoch 52 | loss: 215.61997| val_0_mse: 216.23068237304688|  0:00:53s\n","epoch 53 | loss: 217.12189| val_0_mse: 226.86422729492188|  0:00:54s\n","epoch 54 | loss: 219.54389| val_0_mse: 236.3257598876953|  0:00:55s\n","epoch 55 | loss: 235.02079| val_0_mse: 220.7578125|  0:00:56s\n","epoch 56 | loss: 207.26479| val_0_mse: 205.9046173095703|  0:00:57s\n","epoch 57 | loss: 201.94388| val_0_mse: 215.10723876953125|  0:00:58s\n","epoch 58 | loss: 203.11875| val_0_mse: 214.24667358398438|  0:00:59s\n","epoch 59 | loss: 206.96659| val_0_mse: 212.63465881347656|  0:01:00s\n","epoch 60 | loss: 200.22431| val_0_mse: 198.6212615966797|  0:01:01s\n","epoch 61 | loss: 199.61662| val_0_mse: 199.0032958984375|  0:01:02s\n","epoch 62 | loss: 205.41888| val_0_mse: 205.413818359375|  0:01:03s\n","epoch 63 | loss: 197.26225| val_0_mse: 193.96612548828125|  0:01:04s\n","epoch 64 | loss: 196.19915| val_0_mse: 194.06224060058594|  0:01:05s\n","epoch 65 | loss: 197.8703| val_0_mse: 196.30393981933594|  0:01:06s\n","epoch 66 | loss: 189.5987| val_0_mse: 193.5413055419922|  0:01:07s\n","epoch 67 | loss: 195.64454| val_0_mse: 210.585693359375|  0:01:08s\n","epoch 68 | loss: 190.6641| val_0_mse: 206.0738525390625|  0:01:09s\n","epoch 69 | loss: 191.23645| val_0_mse: 189.3502655029297|  0:01:10s\n","epoch 70 | loss: 191.56797| val_0_mse: 196.56622314453125|  0:01:11s\n","epoch 71 | loss: 194.44894| val_0_mse: 202.56460571289062|  0:01:12s\n","epoch 72 | loss: 189.68031| val_0_mse: 199.09132385253906|  0:01:13s\n","epoch 73 | loss: 189.74744| val_0_mse: 226.9281005859375|  0:01:14s\n","epoch 74 | loss: 188.88446| val_0_mse: 202.18760681152344|  0:01:15s\n","epoch 75 | loss: 183.18102| val_0_mse: 201.1065216064453|  0:01:16s\n","epoch 76 | loss: 190.10969| val_0_mse: 194.2439727783203|  0:01:17s\n","epoch 77 | loss: 185.29036| val_0_mse: 189.22787475585938|  0:01:18s\n","epoch 78 | loss: 180.20871| val_0_mse: 193.70208740234375|  0:01:19s\n","epoch 79 | loss: 183.15056| val_0_mse: 197.9075469970703|  0:01:20s\n","epoch 80 | loss: 202.26218| val_0_mse: 199.96170043945312|  0:01:21s\n","epoch 81 | loss: 190.82485| val_0_mse: 200.6864013671875|  0:01:22s\n","epoch 82 | loss: 189.62212| val_0_mse: 187.14340209960938|  0:01:23s\n","epoch 83 | loss: 181.80702| val_0_mse: 190.83172607421875|  0:01:24s\n","epoch 84 | loss: 183.30165| val_0_mse: 227.70411682128906|  0:01:25s\n","epoch 85 | loss: 181.90828| val_0_mse: 187.72772216796875|  0:01:26s\n","epoch 86 | loss: 176.42323| val_0_mse: 187.6235809326172|  0:01:27s\n","epoch 87 | loss: 175.74654| val_0_mse: 184.69656372070312|  0:01:28s\n","epoch 88 | loss: 176.71508| val_0_mse: 191.17831420898438|  0:01:29s\n","epoch 89 | loss: 180.95356| val_0_mse: 195.12115478515625|  0:01:30s\n","epoch 90 | loss: 177.54756| val_0_mse: 183.5943603515625|  0:01:31s\n","epoch 91 | loss: 173.45726| val_0_mse: 189.08151245117188|  0:01:32s\n","epoch 92 | loss: 171.64823| val_0_mse: 203.6381072998047|  0:01:33s\n","epoch 93 | loss: 183.8637| val_0_mse: 199.68661499023438|  0:01:34s\n","epoch 94 | loss: 174.38061| val_0_mse: 183.6212615966797|  0:01:35s\n","epoch 95 | loss: 169.02778| val_0_mse: 195.66253662109375|  0:01:36s\n","epoch 96 | loss: 174.8269| val_0_mse: 183.9874267578125|  0:01:37s\n","epoch 97 | loss: 165.99503| val_0_mse: 189.85137939453125|  0:01:38s\n","epoch 98 | loss: 166.19157| val_0_mse: 180.56155395507812|  0:01:39s\n","epoch 99 | loss: 160.76808| val_0_mse: 185.9840850830078|  0:01:40s\n","Stop training because you reached max_epochs = 100 with best_epoch = 98 and best_val_0_mse = 180.56155395507812\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 14:48:46,432] Trial 40 finished with value: 180.5615692138672 and parameters: {'n_d': 59, 'n_steps': 7, 'gamma': 1.6603598359619822, 'n_independent': 4, 'n_shared': 1, 'momentum': 0.15450570493731308}. Best is trial 33 with value: 135.8055877685547.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 1675.1328| val_0_mse: 4429.57763671875|  0:00:00s\n","epoch 1  | loss: 471.88242| val_0_mse: 4396.39794921875|  0:00:01s\n","epoch 2  | loss: 347.19798| val_0_mse: 2443.22265625|  0:00:01s\n","epoch 3  | loss: 302.75359| val_0_mse: 2276.775146484375|  0:00:02s\n","epoch 4  | loss: 292.32254| val_0_mse: 1209.201171875|  0:00:03s\n","epoch 5  | loss: 275.84929| val_0_mse: 2113.11279296875|  0:00:03s\n","epoch 6  | loss: 265.06871| val_0_mse: 1868.485107421875|  0:00:04s\n","epoch 7  | loss: 235.1504| val_0_mse: 1707.1697998046875|  0:00:04s\n","epoch 8  | loss: 247.00975| val_0_mse: 1408.3343505859375|  0:00:05s\n","epoch 9  | loss: 233.5577| val_0_mse: 1322.9912109375|  0:00:06s\n","epoch 10 | loss: 238.18604| val_0_mse: 761.3556518554688|  0:00:06s\n","epoch 11 | loss: 239.18234| val_0_mse: 1009.3244018554688|  0:00:07s\n","epoch 12 | loss: 228.58512| val_0_mse: 1218.5135498046875|  0:00:07s\n","epoch 13 | loss: 222.71862| val_0_mse: 763.3871459960938|  0:00:08s\n","epoch 14 | loss: 209.00649| val_0_mse: 806.7025756835938|  0:00:09s\n","epoch 15 | loss: 212.98228| val_0_mse: 618.1029663085938|  0:00:09s\n","epoch 16 | loss: 208.67884| val_0_mse: 599.1121826171875|  0:00:10s\n","epoch 17 | loss: 207.95302| val_0_mse: 557.7288818359375|  0:00:11s\n","epoch 18 | loss: 208.13367| val_0_mse: 643.6218872070312|  0:00:11s\n","epoch 19 | loss: 203.78964| val_0_mse: 541.161376953125|  0:00:12s\n","epoch 20 | loss: 199.00175| val_0_mse: 457.7057189941406|  0:00:13s\n","epoch 21 | loss: 213.92089| val_0_mse: 589.5296020507812|  0:00:13s\n","epoch 22 | loss: 211.64361| val_0_mse: 442.1573486328125|  0:00:14s\n","epoch 23 | loss: 214.0978| val_0_mse: 407.72210693359375|  0:00:14s\n","epoch 24 | loss: 207.77737| val_0_mse: 352.2557067871094|  0:00:15s\n","epoch 25 | loss: 193.39731| val_0_mse: 337.2977294921875|  0:00:16s\n","epoch 26 | loss: 190.34947| val_0_mse: 298.24847412109375|  0:00:16s\n","epoch 27 | loss: 187.90092| val_0_mse: 309.6593933105469|  0:00:17s\n","epoch 28 | loss: 189.83868| val_0_mse: 282.58551025390625|  0:00:17s\n","epoch 29 | loss: 188.71364| val_0_mse: 239.52099609375|  0:00:18s\n","epoch 30 | loss: 179.89202| val_0_mse: 226.74920654296875|  0:00:18s\n","epoch 31 | loss: 184.76807| val_0_mse: 262.1394958496094|  0:00:19s\n","epoch 32 | loss: 183.9638| val_0_mse: 211.97901916503906|  0:00:20s\n","epoch 33 | loss: 178.95626| val_0_mse: 196.88998413085938|  0:00:20s\n","epoch 34 | loss: 177.45326| val_0_mse: 212.92486572265625|  0:00:21s\n","epoch 35 | loss: 176.76408| val_0_mse: 217.68243408203125|  0:00:22s\n","epoch 36 | loss: 179.79305| val_0_mse: 196.54750061035156|  0:00:22s\n","epoch 37 | loss: 173.24329| val_0_mse: 195.40126037597656|  0:00:23s\n","epoch 38 | loss: 170.82708| val_0_mse: 192.40939331054688|  0:00:23s\n","epoch 39 | loss: 169.78094| val_0_mse: 240.6907196044922|  0:00:24s\n","epoch 40 | loss: 179.45384| val_0_mse: 210.3290557861328|  0:00:25s\n","epoch 41 | loss: 185.48235| val_0_mse: 192.15518188476562|  0:00:25s\n","epoch 42 | loss: 171.998 | val_0_mse: 182.99493408203125|  0:00:26s\n","epoch 43 | loss: 167.77795| val_0_mse: 195.35775756835938|  0:00:26s\n","epoch 44 | loss: 163.0379| val_0_mse: 179.4329071044922|  0:00:27s\n","epoch 45 | loss: 163.08222| val_0_mse: 194.52804565429688|  0:00:28s\n","epoch 46 | loss: 156.12854| val_0_mse: 182.6311798095703|  0:00:28s\n","epoch 47 | loss: 155.09531| val_0_mse: 185.16104125976562|  0:00:29s\n","epoch 48 | loss: 161.33002| val_0_mse: 187.72561645507812|  0:00:29s\n","epoch 49 | loss: 163.08105| val_0_mse: 187.9886016845703|  0:00:30s\n","epoch 50 | loss: 171.90237| val_0_mse: 185.169921875|  0:00:31s\n","epoch 51 | loss: 159.33787| val_0_mse: 174.06919860839844|  0:00:31s\n","epoch 52 | loss: 153.79571| val_0_mse: 177.23191833496094|  0:00:32s\n","epoch 53 | loss: 157.8741| val_0_mse: 180.48939514160156|  0:00:33s\n","epoch 54 | loss: 156.06133| val_0_mse: 181.7185821533203|  0:00:33s\n","epoch 55 | loss: 160.37676| val_0_mse: 193.4333953857422|  0:00:34s\n","epoch 56 | loss: 156.14738| val_0_mse: 166.8935089111328|  0:00:34s\n","epoch 57 | loss: 147.41044| val_0_mse: 177.0694580078125|  0:00:35s\n","epoch 58 | loss: 152.1938| val_0_mse: 175.06546020507812|  0:00:36s\n","epoch 59 | loss: 149.38482| val_0_mse: 173.9497528076172|  0:00:36s\n","epoch 60 | loss: 150.43404| val_0_mse: 199.7567138671875|  0:00:37s\n","epoch 61 | loss: 149.04769| val_0_mse: 189.78428649902344|  0:00:37s\n","epoch 62 | loss: 157.79884| val_0_mse: 165.54815673828125|  0:00:38s\n","epoch 63 | loss: 154.18241| val_0_mse: 173.25486755371094|  0:00:39s\n","epoch 64 | loss: 152.02029| val_0_mse: 168.2136993408203|  0:00:39s\n","epoch 65 | loss: 148.29553| val_0_mse: 176.7593536376953|  0:00:40s\n","epoch 66 | loss: 156.79695| val_0_mse: 179.7377166748047|  0:00:40s\n","epoch 67 | loss: 143.24406| val_0_mse: 171.2677459716797|  0:00:41s\n","epoch 68 | loss: 144.02427| val_0_mse: 178.9485626220703|  0:00:42s\n","epoch 69 | loss: 141.78056| val_0_mse: 162.33236694335938|  0:00:42s\n","epoch 70 | loss: 143.51164| val_0_mse: 164.54486083984375|  0:00:43s\n","epoch 71 | loss: 142.06901| val_0_mse: 158.26095581054688|  0:00:43s\n","epoch 72 | loss: 149.45788| val_0_mse: 165.3383331298828|  0:00:44s\n","epoch 73 | loss: 142.77462| val_0_mse: 165.69744873046875|  0:00:45s\n","epoch 74 | loss: 139.51619| val_0_mse: 178.4783172607422|  0:00:45s\n","epoch 75 | loss: 141.10207| val_0_mse: 158.83425903320312|  0:00:46s\n","epoch 76 | loss: 138.69507| val_0_mse: 160.12376403808594|  0:00:47s\n","epoch 77 | loss: 133.62792| val_0_mse: 150.5251007080078|  0:00:47s\n","epoch 78 | loss: 138.98873| val_0_mse: 161.78302001953125|  0:00:48s\n","epoch 79 | loss: 135.23275| val_0_mse: 156.8003692626953|  0:00:48s\n","epoch 80 | loss: 140.00276| val_0_mse: 170.62274169921875|  0:00:49s\n","epoch 81 | loss: 140.39508| val_0_mse: 174.08921813964844|  0:00:50s\n","epoch 82 | loss: 131.97005| val_0_mse: 154.4047393798828|  0:00:50s\n","epoch 83 | loss: 132.17574| val_0_mse: 157.7419891357422|  0:00:51s\n","epoch 84 | loss: 125.12954| val_0_mse: 172.04791259765625|  0:00:51s\n","epoch 85 | loss: 129.17614| val_0_mse: 149.9314727783203|  0:00:52s\n","epoch 86 | loss: 135.40411| val_0_mse: 153.9484405517578|  0:00:52s\n","epoch 87 | loss: 134.22146| val_0_mse: 158.447998046875|  0:00:53s\n","epoch 88 | loss: 132.10353| val_0_mse: 157.19305419921875|  0:00:54s\n","epoch 89 | loss: 129.03182| val_0_mse: 156.16244506835938|  0:00:54s\n","epoch 90 | loss: 129.4383| val_0_mse: 140.2835693359375|  0:00:55s\n","epoch 91 | loss: 121.34036| val_0_mse: 153.12367248535156|  0:00:56s\n","epoch 92 | loss: 127.19446| val_0_mse: 144.65782165527344|  0:00:56s\n","epoch 93 | loss: 133.82573| val_0_mse: 180.1806182861328|  0:00:57s\n","epoch 94 | loss: 128.40147| val_0_mse: 152.26646423339844|  0:00:58s\n","epoch 95 | loss: 129.18131| val_0_mse: 157.30213928222656|  0:00:58s\n","epoch 96 | loss: 131.78072| val_0_mse: 158.10643005371094|  0:00:59s\n","epoch 97 | loss: 128.49003| val_0_mse: 182.98391723632812|  0:00:59s\n","epoch 98 | loss: 124.61289| val_0_mse: 151.55267333984375|  0:01:00s\n","epoch 99 | loss: 117.19791| val_0_mse: 141.22994995117188|  0:01:01s\n","Stop training because you reached max_epochs = 100 with best_epoch = 90 and best_val_0_mse = 140.2835693359375\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 14:49:47,942] Trial 41 finished with value: 140.2835693359375 and parameters: {'n_d': 55, 'n_steps': 3, 'gamma': 1.4613959050135252, 'n_independent': 3, 'n_shared': 3, 'momentum': 0.10651988138879682}. Best is trial 33 with value: 135.8055877685547.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 1644.08754| val_0_mse: 10144.92578125|  0:00:00s\n","epoch 1  | loss: 519.56503| val_0_mse: 15574.96875|  0:00:01s\n","epoch 2  | loss: 369.97888| val_0_mse: 34409.02734375|  0:00:01s\n","epoch 3  | loss: 322.77404| val_0_mse: 5652.58837890625|  0:00:02s\n","epoch 4  | loss: 294.90513| val_0_mse: 2440.413818359375|  0:00:02s\n","epoch 5  | loss: 292.49861| val_0_mse: 1291.334228515625|  0:00:03s\n","epoch 6  | loss: 284.02348| val_0_mse: 953.7413330078125|  0:00:04s\n","epoch 7  | loss: 269.14763| val_0_mse: 1412.8406982421875|  0:00:04s\n","epoch 8  | loss: 263.24077| val_0_mse: 12735.9541015625|  0:00:05s\n","epoch 9  | loss: 248.11959| val_0_mse: 1293.3863525390625|  0:00:06s\n","epoch 10 | loss: 252.62262| val_0_mse: 940.2449340820312|  0:00:06s\n","epoch 11 | loss: 226.47718| val_0_mse: 3327.1748046875|  0:00:07s\n","epoch 12 | loss: 226.80095| val_0_mse: 1719.913818359375|  0:00:07s\n","epoch 13 | loss: 219.98958| val_0_mse: 1092.976318359375|  0:00:08s\n","epoch 14 | loss: 211.7904| val_0_mse: 3015.595947265625|  0:00:09s\n","epoch 15 | loss: 218.49457| val_0_mse: 939.4921875|  0:00:09s\n","epoch 16 | loss: 209.54627| val_0_mse: 803.248291015625|  0:00:10s\n","epoch 17 | loss: 205.83729| val_0_mse: 662.06884765625|  0:00:10s\n","epoch 18 | loss: 208.87634| val_0_mse: 591.3492431640625|  0:00:11s\n","epoch 19 | loss: 198.84106| val_0_mse: 467.6610412597656|  0:00:12s\n","epoch 20 | loss: 200.49405| val_0_mse: 500.55072021484375|  0:00:12s\n","epoch 21 | loss: 193.69544| val_0_mse: 353.8106689453125|  0:00:13s\n","epoch 22 | loss: 196.30484| val_0_mse: 327.69012451171875|  0:00:13s\n","epoch 23 | loss: 187.95732| val_0_mse: 360.08770751953125|  0:00:14s\n","epoch 24 | loss: 190.41828| val_0_mse: 436.0770263671875|  0:00:15s\n","epoch 25 | loss: 200.28912| val_0_mse: 293.46417236328125|  0:00:15s\n","epoch 26 | loss: 198.51146| val_0_mse: 249.12396240234375|  0:00:16s\n","epoch 27 | loss: 191.70893| val_0_mse: 252.01675415039062|  0:00:16s\n","epoch 28 | loss: 180.89526| val_0_mse: 250.1920928955078|  0:00:17s\n","epoch 29 | loss: 179.69166| val_0_mse: 199.517822265625|  0:00:18s\n","epoch 30 | loss: 180.26764| val_0_mse: 259.63397216796875|  0:00:18s\n","epoch 31 | loss: 181.79302| val_0_mse: 218.06224060058594|  0:00:19s\n","epoch 32 | loss: 176.26657| val_0_mse: 213.11697387695312|  0:00:20s\n","epoch 33 | loss: 177.35994| val_0_mse: 228.65675354003906|  0:00:20s\n","epoch 34 | loss: 171.96835| val_0_mse: 218.91000366210938|  0:00:21s\n","epoch 35 | loss: 175.05716| val_0_mse: 200.40194702148438|  0:00:21s\n","epoch 36 | loss: 174.14859| val_0_mse: 186.7124786376953|  0:00:22s\n","epoch 37 | loss: 180.60881| val_0_mse: 208.86465454101562|  0:00:23s\n","epoch 38 | loss: 174.88061| val_0_mse: 241.48135375976562|  0:00:23s\n","epoch 39 | loss: 169.75099| val_0_mse: 188.38319396972656|  0:00:24s\n","epoch 40 | loss: 175.31212| val_0_mse: 189.94021606445312|  0:00:24s\n","epoch 41 | loss: 169.12666| val_0_mse: 185.3329620361328|  0:00:25s\n","epoch 42 | loss: 166.33967| val_0_mse: 175.92617797851562|  0:00:26s\n","epoch 43 | loss: 166.28001| val_0_mse: 173.8701934814453|  0:00:26s\n","epoch 44 | loss: 173.66127| val_0_mse: 187.8411865234375|  0:00:27s\n","epoch 45 | loss: 165.62461| val_0_mse: 192.85586547851562|  0:00:27s\n","epoch 46 | loss: 162.94308| val_0_mse: 180.24856567382812|  0:00:28s\n","epoch 47 | loss: 164.0615| val_0_mse: 172.684814453125|  0:00:29s\n","epoch 48 | loss: 168.66262| val_0_mse: 178.35011291503906|  0:00:29s\n","epoch 49 | loss: 159.93585| val_0_mse: 204.07730102539062|  0:00:30s\n","epoch 50 | loss: 160.62139| val_0_mse: 171.99778747558594|  0:00:30s\n","epoch 51 | loss: 160.79055| val_0_mse: 188.25094604492188|  0:00:31s\n","epoch 52 | loss: 155.33977| val_0_mse: 175.2506866455078|  0:00:32s\n","epoch 53 | loss: 158.70744| val_0_mse: 177.04693603515625|  0:00:32s\n","epoch 54 | loss: 160.611 | val_0_mse: 179.45578002929688|  0:00:33s\n","epoch 55 | loss: 162.80523| val_0_mse: 165.345947265625|  0:00:33s\n","epoch 56 | loss: 148.84493| val_0_mse: 164.33013916015625|  0:00:34s\n","epoch 57 | loss: 154.81248| val_0_mse: 209.51539611816406|  0:00:35s\n","epoch 58 | loss: 154.11109| val_0_mse: 168.26712036132812|  0:00:35s\n","epoch 59 | loss: 149.33787| val_0_mse: 169.68724060058594|  0:00:36s\n","epoch 60 | loss: 155.35954| val_0_mse: 163.15338134765625|  0:00:36s\n","epoch 61 | loss: 138.9669| val_0_mse: 161.6153564453125|  0:00:37s\n","epoch 62 | loss: 148.06808| val_0_mse: 164.91799926757812|  0:00:38s\n","epoch 63 | loss: 143.18437| val_0_mse: 149.1667938232422|  0:00:38s\n","epoch 64 | loss: 141.75286| val_0_mse: 162.9542999267578|  0:00:39s\n","epoch 65 | loss: 146.49145| val_0_mse: 190.61062622070312|  0:00:39s\n","epoch 66 | loss: 146.32203| val_0_mse: 159.16732788085938|  0:00:40s\n","epoch 67 | loss: 140.5443| val_0_mse: 227.2140655517578|  0:00:41s\n","epoch 68 | loss: 140.47442| val_0_mse: 195.63583374023438|  0:00:41s\n","epoch 69 | loss: 144.10862| val_0_mse: 165.6112518310547|  0:00:42s\n","epoch 70 | loss: 149.81794| val_0_mse: 191.4352264404297|  0:00:43s\n","epoch 71 | loss: 151.29756| val_0_mse: 171.8350372314453|  0:00:43s\n","epoch 72 | loss: 157.4018| val_0_mse: 193.17698669433594|  0:00:44s\n","epoch 73 | loss: 145.01728| val_0_mse: 156.74481201171875|  0:00:44s\n","\n","Early stopping occurred at epoch 73 with best_epoch = 63 and best_val_0_mse = 149.1667938232422\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 14:50:33,206] Trial 42 finished with value: 149.1667938232422 and parameters: {'n_d': 54, 'n_steps': 3, 'gamma': 1.478244079111108, 'n_independent': 3, 'n_shared': 3, 'momentum': 0.050026781517614305}. Best is trial 33 with value: 135.8055877685547.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 1901.85981| val_0_mse: 7612.52587890625|  0:00:00s\n","epoch 1  | loss: 724.67194| val_0_mse: 5204.896484375|  0:00:01s\n","epoch 2  | loss: 545.16262| val_0_mse: 1618.9305419921875|  0:00:02s\n","epoch 3  | loss: 468.67585| val_0_mse: 2945.8486328125|  0:00:02s\n","epoch 4  | loss: 407.1947| val_0_mse: 1232.2537841796875|  0:00:03s\n","epoch 5  | loss: 434.84491| val_0_mse: 1412.322998046875|  0:00:04s\n","epoch 6  | loss: 368.55714| val_0_mse: 1868.4708251953125|  0:00:05s\n","epoch 7  | loss: 373.67131| val_0_mse: 2181.15283203125|  0:00:05s\n","epoch 8  | loss: 367.18087| val_0_mse: 1456.9962158203125|  0:00:06s\n","epoch 9  | loss: 336.23014| val_0_mse: 2278.456787109375|  0:00:07s\n","epoch 10 | loss: 351.24699| val_0_mse: 1327.9249267578125|  0:00:08s\n","epoch 11 | loss: 323.55621| val_0_mse: 703.16162109375|  0:00:08s\n","epoch 12 | loss: 325.70327| val_0_mse: 647.6270141601562|  0:00:09s\n","epoch 13 | loss: 324.26571| val_0_mse: 830.9376220703125|  0:00:10s\n","epoch 14 | loss: 324.52628| val_0_mse: 1014.270263671875|  0:00:10s\n","epoch 15 | loss: 314.1896| val_0_mse: 1261.40673828125|  0:00:11s\n","epoch 16 | loss: 304.78986| val_0_mse: 1102.7518310546875|  0:00:12s\n","epoch 17 | loss: 303.53598| val_0_mse: 896.2670288085938|  0:00:13s\n","epoch 18 | loss: 290.60837| val_0_mse: 599.81884765625|  0:00:13s\n","epoch 19 | loss: 317.23199| val_0_mse: 1266.4671630859375|  0:00:14s\n","epoch 20 | loss: 298.41563| val_0_mse: 1403.79541015625|  0:00:15s\n","epoch 21 | loss: 295.69916| val_0_mse: 1216.679931640625|  0:00:15s\n","epoch 22 | loss: 288.51685| val_0_mse: 1033.112548828125|  0:00:16s\n","epoch 23 | loss: 279.48712| val_0_mse: 790.6911010742188|  0:00:17s\n","epoch 24 | loss: 291.95251| val_0_mse: 823.9852294921875|  0:00:18s\n","epoch 25 | loss: 289.13521| val_0_mse: 954.0926513671875|  0:00:18s\n","epoch 26 | loss: 284.02548| val_0_mse: 994.381591796875|  0:00:19s\n","epoch 27 | loss: 286.38752| val_0_mse: 1010.3694458007812|  0:00:20s\n","epoch 28 | loss: 281.23567| val_0_mse: 1019.5496826171875|  0:00:21s\n","\n","Early stopping occurred at epoch 28 with best_epoch = 18 and best_val_0_mse = 599.81884765625\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 14:50:54,906] Trial 43 finished with value: 599.81884765625 and parameters: {'n_d': 50, 'n_steps': 4, 'gamma': 1.4056846392398021, 'n_independent': 3, 'n_shared': 3, 'momentum': 0.10005581156900444}. Best is trial 33 with value: 135.8055877685547.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 1679.08872| val_0_mse: 14322.0224609375|  0:00:00s\n","epoch 1  | loss: 510.76131| val_0_mse: 10248.330078125|  0:00:01s\n","epoch 2  | loss: 372.40331| val_0_mse: 1854.3377685546875|  0:00:01s\n","epoch 3  | loss: 310.18254| val_0_mse: 4368.29736328125|  0:00:02s\n","epoch 4  | loss: 301.89905| val_0_mse: 1310.2073974609375|  0:00:03s\n","epoch 5  | loss: 296.66193| val_0_mse: 2009.67138671875|  0:00:03s\n","epoch 6  | loss: 265.70074| val_0_mse: 1174.135009765625|  0:00:04s\n","epoch 7  | loss: 277.25562| val_0_mse: 2027.2205810546875|  0:00:05s\n","epoch 8  | loss: 253.91544| val_0_mse: 2943.56103515625|  0:00:05s\n","epoch 9  | loss: 239.64832| val_0_mse: 3355.38037109375|  0:00:06s\n","epoch 10 | loss: 238.81209| val_0_mse: 2534.90771484375|  0:00:07s\n","epoch 11 | loss: 240.13516| val_0_mse: 2158.700927734375|  0:00:08s\n","epoch 12 | loss: 228.67629| val_0_mse: 1546.190673828125|  0:00:08s\n","epoch 13 | loss: 230.6075| val_0_mse: 979.8516235351562|  0:00:09s\n","epoch 14 | loss: 229.77015| val_0_mse: 1099.3045654296875|  0:00:10s\n","epoch 15 | loss: 223.8737| val_0_mse: 921.218017578125|  0:00:10s\n","epoch 16 | loss: 217.28042| val_0_mse: 716.35302734375|  0:00:11s\n","epoch 17 | loss: 209.26131| val_0_mse: 881.690185546875|  0:00:12s\n","epoch 18 | loss: 203.8445| val_0_mse: 485.8807067871094|  0:00:12s\n","epoch 19 | loss: 207.40793| val_0_mse: 429.1963195800781|  0:00:13s\n","epoch 20 | loss: 209.60101| val_0_mse: 469.19390869140625|  0:00:14s\n","epoch 21 | loss: 203.97846| val_0_mse: 369.25628662109375|  0:00:14s\n","epoch 22 | loss: 214.98721| val_0_mse: 527.0446166992188|  0:00:15s\n","epoch 23 | loss: 204.99163| val_0_mse: 376.2249450683594|  0:00:16s\n","epoch 24 | loss: 196.43392| val_0_mse: 336.4449462890625|  0:00:16s\n","epoch 25 | loss: 199.78789| val_0_mse: 313.1824645996094|  0:00:17s\n","epoch 26 | loss: 197.21733| val_0_mse: 388.2466735839844|  0:00:18s\n","epoch 27 | loss: 207.48569| val_0_mse: 313.5751037597656|  0:00:18s\n","epoch 28 | loss: 204.14869| val_0_mse: 301.0527648925781|  0:00:19s\n","epoch 29 | loss: 202.08031| val_0_mse: 257.93316650390625|  0:00:20s\n","epoch 30 | loss: 207.32563| val_0_mse: 276.8887023925781|  0:00:20s\n","epoch 31 | loss: 209.52143| val_0_mse: 324.23675537109375|  0:00:21s\n","epoch 32 | loss: 206.12656| val_0_mse: 221.49026489257812|  0:00:22s\n","epoch 33 | loss: 198.99701| val_0_mse: 262.3719787597656|  0:00:22s\n","epoch 34 | loss: 202.66614| val_0_mse: 208.0575408935547|  0:00:23s\n","epoch 35 | loss: 196.73934| val_0_mse: 286.8447570800781|  0:00:24s\n","epoch 36 | loss: 208.41104| val_0_mse: 219.72535705566406|  0:00:24s\n","epoch 37 | loss: 196.63198| val_0_mse: 201.73594665527344|  0:00:25s\n","epoch 38 | loss: 193.80107| val_0_mse: 195.86578369140625|  0:00:26s\n","epoch 39 | loss: 204.85538| val_0_mse: 204.40423583984375|  0:00:26s\n","epoch 40 | loss: 197.12116| val_0_mse: 199.09365844726562|  0:00:27s\n","epoch 41 | loss: 195.47865| val_0_mse: 196.21047973632812|  0:00:28s\n","epoch 42 | loss: 185.20257| val_0_mse: 184.07586669921875|  0:00:28s\n","epoch 43 | loss: 184.49828| val_0_mse: 193.51046752929688|  0:00:29s\n","epoch 44 | loss: 182.63781| val_0_mse: 201.06309509277344|  0:00:30s\n","epoch 45 | loss: 187.19899| val_0_mse: 192.87899780273438|  0:00:30s\n","epoch 46 | loss: 185.97716| val_0_mse: 245.02383422851562|  0:00:31s\n","epoch 47 | loss: 187.85494| val_0_mse: 186.50877380371094|  0:00:32s\n","epoch 48 | loss: 181.56856| val_0_mse: 198.62991333007812|  0:00:33s\n","epoch 49 | loss: 196.32115| val_0_mse: 190.85693359375|  0:00:33s\n","epoch 50 | loss: 192.44806| val_0_mse: 226.15365600585938|  0:00:34s\n","epoch 51 | loss: 184.09178| val_0_mse: 244.84292602539062|  0:00:34s\n","epoch 52 | loss: 180.13739| val_0_mse: 203.0609130859375|  0:00:35s\n","\n","Early stopping occurred at epoch 52 with best_epoch = 42 and best_val_0_mse = 184.07586669921875\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 14:51:30,946] Trial 44 finished with value: 184.0758514404297 and parameters: {'n_d': 48, 'n_steps': 3, 'gamma': 1.5180616757226844, 'n_independent': 4, 'n_shared': 3, 'momentum': 0.0741276657969055}. Best is trial 33 with value: 135.8055877685547.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 1559.69222| val_0_mse: 37256.6484375|  0:00:00s\n","epoch 1  | loss: 504.3357| val_0_mse: 11465.7001953125|  0:00:01s\n","epoch 2  | loss: 385.15544| val_0_mse: 8917.9267578125|  0:00:01s\n","epoch 3  | loss: 349.62109| val_0_mse: 5683.88330078125|  0:00:02s\n","epoch 4  | loss: 309.25707| val_0_mse: 3738.72314453125|  0:00:03s\n","epoch 5  | loss: 311.64414| val_0_mse: 3052.291259765625|  0:00:03s\n","epoch 6  | loss: 312.46802| val_0_mse: 1758.4188232421875|  0:00:04s\n","epoch 7  | loss: 306.96482| val_0_mse: 3802.099609375|  0:00:05s\n","epoch 8  | loss: 286.88907| val_0_mse: 3829.558837890625|  0:00:05s\n","epoch 9  | loss: 275.61877| val_0_mse: 3128.010009765625|  0:00:06s\n","epoch 10 | loss: 294.46781| val_0_mse: 1529.845947265625|  0:00:07s\n","epoch 11 | loss: 274.19328| val_0_mse: 1427.1390380859375|  0:00:07s\n","epoch 12 | loss: 280.74623| val_0_mse: 1908.190185546875|  0:00:08s\n","epoch 13 | loss: 279.98725| val_0_mse: 1560.0474853515625|  0:00:09s\n","epoch 14 | loss: 257.99035| val_0_mse: 1473.12890625|  0:00:09s\n","epoch 15 | loss: 261.35795| val_0_mse: 1247.259521484375|  0:00:10s\n","epoch 16 | loss: 242.6845| val_0_mse: 1483.9014892578125|  0:00:11s\n","epoch 17 | loss: 236.92578| val_0_mse: 1028.0841064453125|  0:00:11s\n","epoch 18 | loss: 234.00224| val_0_mse: 759.3473510742188|  0:00:12s\n","epoch 19 | loss: 230.14115| val_0_mse: 440.3907165527344|  0:00:13s\n","epoch 20 | loss: 230.7755| val_0_mse: 513.8585205078125|  0:00:13s\n","epoch 21 | loss: 247.42701| val_0_mse: 722.0673828125|  0:00:14s\n","epoch 22 | loss: 239.89612| val_0_mse: 792.09814453125|  0:00:15s\n","epoch 23 | loss: 214.00212| val_0_mse: 787.9125366210938|  0:00:15s\n","epoch 24 | loss: 228.62586| val_0_mse: 773.3164672851562|  0:00:16s\n","epoch 25 | loss: 225.37745| val_0_mse: 298.20147705078125|  0:00:16s\n","epoch 26 | loss: 214.05296| val_0_mse: 309.9831237792969|  0:00:17s\n","epoch 27 | loss: 214.05021| val_0_mse: 280.90814208984375|  0:00:18s\n","epoch 28 | loss: 217.52583| val_0_mse: 275.5277099609375|  0:00:19s\n","epoch 29 | loss: 209.83684| val_0_mse: 275.39129638671875|  0:00:19s\n","epoch 30 | loss: 203.3769| val_0_mse: 261.40386962890625|  0:00:20s\n","epoch 31 | loss: 202.37981| val_0_mse: 235.6903076171875|  0:00:20s\n","epoch 32 | loss: 197.68767| val_0_mse: 303.7832946777344|  0:00:21s\n","epoch 33 | loss: 206.50988| val_0_mse: 270.39959716796875|  0:00:22s\n","epoch 34 | loss: 200.21893| val_0_mse: 236.96983337402344|  0:00:22s\n","epoch 35 | loss: 202.97449| val_0_mse: 278.2073669433594|  0:00:23s\n","epoch 36 | loss: 199.66711| val_0_mse: 207.9138946533203|  0:00:24s\n","epoch 37 | loss: 196.1862| val_0_mse: 201.05137634277344|  0:00:24s\n","epoch 38 | loss: 197.03524| val_0_mse: 201.9915771484375|  0:00:25s\n","epoch 39 | loss: 192.36087| val_0_mse: 228.52325439453125|  0:00:26s\n","epoch 40 | loss: 187.13787| val_0_mse: 225.90106201171875|  0:00:26s\n","epoch 41 | loss: 184.98164| val_0_mse: 228.62893676757812|  0:00:27s\n","epoch 42 | loss: 185.6202| val_0_mse: 222.94189453125|  0:00:28s\n","epoch 43 | loss: 188.37012| val_0_mse: 194.92933654785156|  0:00:28s\n","epoch 44 | loss: 177.09391| val_0_mse: 216.2806854248047|  0:00:29s\n","epoch 45 | loss: 177.36102| val_0_mse: 198.72116088867188|  0:00:30s\n","epoch 46 | loss: 171.58535| val_0_mse: 184.857666015625|  0:00:30s\n","epoch 47 | loss: 175.20902| val_0_mse: 205.42164611816406|  0:00:31s\n","epoch 48 | loss: 178.32948| val_0_mse: 230.7696075439453|  0:00:32s\n","epoch 49 | loss: 175.11619| val_0_mse: 222.66844177246094|  0:00:32s\n","epoch 50 | loss: 180.47186| val_0_mse: 243.17019653320312|  0:00:33s\n","epoch 51 | loss: 176.05146| val_0_mse: 180.53370666503906|  0:00:34s\n","epoch 52 | loss: 174.32309| val_0_mse: 183.70840454101562|  0:00:34s\n","epoch 53 | loss: 177.83584| val_0_mse: 194.6891326904297|  0:00:35s\n","epoch 54 | loss: 169.91372| val_0_mse: 170.7560272216797|  0:00:36s\n","epoch 55 | loss: 164.10733| val_0_mse: 186.20779418945312|  0:00:36s\n","epoch 56 | loss: 162.57859| val_0_mse: 161.71743774414062|  0:00:37s\n","epoch 57 | loss: 161.20794| val_0_mse: 183.4628143310547|  0:00:38s\n","epoch 58 | loss: 165.8024| val_0_mse: 194.87428283691406|  0:00:38s\n","epoch 59 | loss: 167.30319| val_0_mse: 199.19793701171875|  0:00:39s\n","epoch 60 | loss: 156.81023| val_0_mse: 172.32237243652344|  0:00:40s\n","epoch 61 | loss: 163.67825| val_0_mse: 168.2410430908203|  0:00:40s\n","epoch 62 | loss: 158.32029| val_0_mse: 222.3009796142578|  0:00:41s\n","epoch 63 | loss: 161.56506| val_0_mse: 163.2572479248047|  0:00:41s\n","epoch 64 | loss: 161.76514| val_0_mse: 222.90460205078125|  0:00:42s\n","epoch 65 | loss: 176.56425| val_0_mse: 193.91357421875|  0:00:43s\n","epoch 66 | loss: 164.46571| val_0_mse: 198.7795867919922|  0:00:43s\n","\n","Early stopping occurred at epoch 66 with best_epoch = 56 and best_val_0_mse = 161.71743774414062\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 14:52:15,295] Trial 45 finished with value: 161.71743774414062 and parameters: {'n_d': 59, 'n_steps': 4, 'gamma': 1.1643275517011191, 'n_independent': 3, 'n_shared': 2, 'momentum': 0.011442625991610361}. Best is trial 33 with value: 135.8055877685547.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 1750.56868| val_0_mse: 98852.9453125|  0:00:01s\n","epoch 1  | loss: 876.26248| val_0_mse: 12445.3876953125|  0:00:02s\n","epoch 2  | loss: 607.46817| val_0_mse: 14143.529296875|  0:00:03s\n","epoch 3  | loss: 543.06539| val_0_mse: 3432.62939453125|  0:00:04s\n","epoch 4  | loss: 512.83228| val_0_mse: 3218.484130859375|  0:00:06s\n","epoch 5  | loss: 474.01036| val_0_mse: 2082.88623046875|  0:00:07s\n","epoch 6  | loss: 476.41875| val_0_mse: 1119.3857421875|  0:00:08s\n","epoch 7  | loss: 459.64175| val_0_mse: 1142.257568359375|  0:00:09s\n","epoch 8  | loss: 462.23746| val_0_mse: 1897.2486572265625|  0:00:10s\n","epoch 9  | loss: 458.65307| val_0_mse: 1287.725830078125|  0:00:12s\n","epoch 10 | loss: 454.74265| val_0_mse: 998.9285888671875|  0:00:13s\n","epoch 11 | loss: 480.82073| val_0_mse: 1153.6895751953125|  0:00:14s\n","epoch 12 | loss: 469.11515| val_0_mse: 707.9946899414062|  0:00:15s\n","epoch 13 | loss: 432.0387| val_0_mse: 589.85791015625|  0:00:16s\n","epoch 14 | loss: 379.18153| val_0_mse: 677.9632568359375|  0:00:18s\n","epoch 15 | loss: 380.261 | val_0_mse: 689.11181640625|  0:00:19s\n","epoch 16 | loss: 401.972 | val_0_mse: 483.0270690917969|  0:00:20s\n","epoch 17 | loss: 404.96854| val_0_mse: 554.4285888671875|  0:00:21s\n","epoch 18 | loss: 406.47861| val_0_mse: 498.1429138183594|  0:00:23s\n","epoch 19 | loss: 378.29066| val_0_mse: 541.6097412109375|  0:00:24s\n","epoch 20 | loss: 395.16177| val_0_mse: 641.5763549804688|  0:00:25s\n","epoch 21 | loss: 396.47907| val_0_mse: 416.305908203125|  0:00:26s\n","epoch 22 | loss: 404.44494| val_0_mse: 820.2981567382812|  0:00:27s\n","epoch 23 | loss: 374.17928| val_0_mse: 524.2813720703125|  0:00:29s\n","epoch 24 | loss: 342.23206| val_0_mse: 516.05615234375|  0:00:30s\n","epoch 25 | loss: 322.71921| val_0_mse: 475.14447021484375|  0:00:31s\n","epoch 26 | loss: 341.03111| val_0_mse: 516.00732421875|  0:00:32s\n","epoch 27 | loss: 361.50091| val_0_mse: 574.8267211914062|  0:00:33s\n","epoch 28 | loss: 334.25714| val_0_mse: 373.5242919921875|  0:00:35s\n","epoch 29 | loss: 307.06043| val_0_mse: 485.2901611328125|  0:00:36s\n","epoch 30 | loss: 300.55629| val_0_mse: 343.5480651855469|  0:00:37s\n","epoch 31 | loss: 295.26773| val_0_mse: 341.769287109375|  0:00:38s\n","epoch 32 | loss: 292.15095| val_0_mse: 426.63616943359375|  0:00:39s\n","epoch 33 | loss: 307.52263| val_0_mse: 306.072021484375|  0:00:41s\n","epoch 34 | loss: 290.01994| val_0_mse: 290.7926940917969|  0:00:42s\n","epoch 35 | loss: 277.75761| val_0_mse: 305.90057373046875|  0:00:43s\n","epoch 36 | loss: 272.90431| val_0_mse: 280.5538024902344|  0:00:44s\n","epoch 37 | loss: 285.59072| val_0_mse: 273.51251220703125|  0:00:46s\n","epoch 38 | loss: 285.68763| val_0_mse: 283.3622131347656|  0:00:47s\n","epoch 39 | loss: 273.61061| val_0_mse: 291.2145080566406|  0:00:48s\n","epoch 40 | loss: 280.21477| val_0_mse: 315.40704345703125|  0:00:49s\n","epoch 41 | loss: 272.85936| val_0_mse: 277.36248779296875|  0:00:51s\n","epoch 42 | loss: 265.251 | val_0_mse: 251.1938934326172|  0:00:52s\n","epoch 43 | loss: 264.84034| val_0_mse: 266.0330505371094|  0:00:53s\n","epoch 44 | loss: 270.10248| val_0_mse: 277.8600158691406|  0:00:54s\n","epoch 45 | loss: 265.64206| val_0_mse: 279.056396484375|  0:00:55s\n","epoch 46 | loss: 266.35652| val_0_mse: 254.30624389648438|  0:00:57s\n","epoch 47 | loss: 270.41628| val_0_mse: 246.51754760742188|  0:00:58s\n","epoch 48 | loss: 263.69961| val_0_mse: 252.9897003173828|  0:00:59s\n","epoch 49 | loss: 264.6916| val_0_mse: 244.4296875|  0:01:00s\n","epoch 50 | loss: 259.43263| val_0_mse: 245.39437866210938|  0:01:01s\n","epoch 51 | loss: 257.43849| val_0_mse: 249.43417358398438|  0:01:03s\n","epoch 52 | loss: 253.6836| val_0_mse: 260.6999816894531|  0:01:04s\n","epoch 53 | loss: 257.6781| val_0_mse: 253.9812774658203|  0:01:05s\n","epoch 54 | loss: 250.6871| val_0_mse: 252.66531372070312|  0:01:06s\n","epoch 55 | loss: 256.6908| val_0_mse: 245.0977020263672|  0:01:07s\n","epoch 56 | loss: 288.35308| val_0_mse: 268.2342224121094|  0:01:09s\n","epoch 57 | loss: 273.34742| val_0_mse: 263.82000732421875|  0:01:10s\n","epoch 58 | loss: 243.57694| val_0_mse: 240.42481994628906|  0:01:11s\n","epoch 59 | loss: 241.33212| val_0_mse: 239.30459594726562|  0:01:12s\n","epoch 60 | loss: 240.14611| val_0_mse: 237.42080688476562|  0:01:13s\n","epoch 61 | loss: 236.78974| val_0_mse: 239.3354949951172|  0:01:15s\n","epoch 62 | loss: 237.08904| val_0_mse: 239.25643920898438|  0:01:16s\n","epoch 63 | loss: 233.85481| val_0_mse: 235.76626586914062|  0:01:17s\n","epoch 64 | loss: 229.44407| val_0_mse: 227.6282958984375|  0:01:18s\n","epoch 65 | loss: 230.13702| val_0_mse: 233.5305633544922|  0:01:20s\n","epoch 66 | loss: 235.06948| val_0_mse: 228.64596557617188|  0:01:21s\n","epoch 67 | loss: 231.63873| val_0_mse: 235.69891357421875|  0:01:22s\n","epoch 68 | loss: 233.44905| val_0_mse: 231.01429748535156|  0:01:23s\n","epoch 69 | loss: 230.84217| val_0_mse: 240.43687438964844|  0:01:25s\n","epoch 70 | loss: 228.46925| val_0_mse: 232.2734832763672|  0:01:26s\n","epoch 71 | loss: 225.75932| val_0_mse: 221.47265625|  0:01:27s\n","epoch 72 | loss: 212.68885| val_0_mse: 222.16653442382812|  0:01:28s\n","epoch 73 | loss: 217.35761| val_0_mse: 224.266357421875|  0:01:29s\n","epoch 74 | loss: 208.20612| val_0_mse: 216.28724670410156|  0:01:31s\n","epoch 75 | loss: 220.61096| val_0_mse: 208.48739624023438|  0:01:32s\n","epoch 76 | loss: 217.27396| val_0_mse: 217.92735290527344|  0:01:33s\n","epoch 77 | loss: 203.38107| val_0_mse: 200.79649353027344|  0:01:34s\n","epoch 78 | loss: 203.58423| val_0_mse: 208.03778076171875|  0:01:36s\n","epoch 79 | loss: 202.0333| val_0_mse: 198.7258758544922|  0:01:37s\n","epoch 80 | loss: 195.6794| val_0_mse: 221.5150604248047|  0:01:38s\n","epoch 81 | loss: 199.00541| val_0_mse: 205.9759063720703|  0:01:39s\n","epoch 82 | loss: 196.46242| val_0_mse: 201.6320343017578|  0:01:41s\n","epoch 83 | loss: 200.68184| val_0_mse: 202.50497436523438|  0:01:42s\n","epoch 84 | loss: 196.59479| val_0_mse: 203.94993591308594|  0:01:43s\n","epoch 85 | loss: 199.84522| val_0_mse: 200.44284057617188|  0:01:44s\n","epoch 86 | loss: 192.09381| val_0_mse: 194.95816040039062|  0:01:45s\n","epoch 87 | loss: 186.76712| val_0_mse: 192.9620361328125|  0:01:47s\n","epoch 88 | loss: 184.15306| val_0_mse: 193.71652221679688|  0:01:48s\n","epoch 89 | loss: 182.37535| val_0_mse: 193.728515625|  0:01:49s\n","epoch 90 | loss: 187.86424| val_0_mse: 198.91871643066406|  0:01:50s\n","epoch 91 | loss: 186.74563| val_0_mse: 189.52621459960938|  0:01:52s\n","epoch 92 | loss: 186.94122| val_0_mse: 183.40220642089844|  0:01:53s\n","epoch 93 | loss: 181.09645| val_0_mse: 187.13795471191406|  0:01:54s\n","epoch 94 | loss: 182.12227| val_0_mse: 186.50991821289062|  0:01:55s\n","epoch 95 | loss: 177.61019| val_0_mse: 180.7483367919922|  0:01:57s\n","epoch 96 | loss: 179.30941| val_0_mse: 203.0471954345703|  0:01:58s\n","epoch 97 | loss: 183.46944| val_0_mse: 187.93325805664062|  0:01:59s\n","epoch 98 | loss: 175.44574| val_0_mse: 186.96217346191406|  0:02:00s\n","epoch 99 | loss: 171.02638| val_0_mse: 184.5292205810547|  0:02:02s\n","Stop training because you reached max_epochs = 100 with best_epoch = 95 and best_val_0_mse = 180.7483367919922\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 14:54:18,091] Trial 46 finished with value: 180.7483367919922 and parameters: {'n_d': 54, 'n_steps': 9, 'gamma': 1.303033430497671, 'n_independent': 2, 'n_shared': 3, 'momentum': 0.13643293992591504}. Best is trial 33 with value: 135.8055877685547.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 1586.8928| val_0_mse: 59106.26953125|  0:00:00s\n","epoch 1  | loss: 460.88254| val_0_mse: 7663.30322265625|  0:00:01s\n","epoch 2  | loss: 356.50525| val_0_mse: 18207.703125|  0:00:01s\n","epoch 3  | loss: 335.45615| val_0_mse: 7965.05322265625|  0:00:02s\n","epoch 4  | loss: 298.70828| val_0_mse: 6673.00439453125|  0:00:02s\n","epoch 5  | loss: 269.6604| val_0_mse: 9863.185546875|  0:00:03s\n","epoch 6  | loss: 268.51431| val_0_mse: 7968.68115234375|  0:00:03s\n","epoch 7  | loss: 262.64274| val_0_mse: 3061.228515625|  0:00:04s\n","epoch 8  | loss: 251.9013| val_0_mse: 2312.500244140625|  0:00:05s\n","epoch 9  | loss: 256.24  | val_0_mse: 1933.734619140625|  0:00:05s\n","epoch 10 | loss: 258.02576| val_0_mse: 1162.03515625|  0:00:06s\n","epoch 11 | loss: 242.54013| val_0_mse: 1211.6839599609375|  0:00:06s\n","epoch 12 | loss: 243.42477| val_0_mse: 1196.5345458984375|  0:00:07s\n","epoch 13 | loss: 237.97066| val_0_mse: 600.3508911132812|  0:00:07s\n","epoch 14 | loss: 241.06035| val_0_mse: 766.949462890625|  0:00:08s\n","epoch 15 | loss: 226.83943| val_0_mse: 757.5734252929688|  0:00:08s\n","epoch 16 | loss: 225.67929| val_0_mse: 712.5447998046875|  0:00:09s\n","epoch 17 | loss: 226.12427| val_0_mse: 570.1334838867188|  0:00:10s\n","epoch 18 | loss: 219.93641| val_0_mse: 640.7269897460938|  0:00:10s\n","epoch 19 | loss: 229.45345| val_0_mse: 409.28167724609375|  0:00:11s\n","epoch 20 | loss: 213.4707| val_0_mse: 359.60247802734375|  0:00:11s\n","epoch 21 | loss: 210.93879| val_0_mse: 352.0814514160156|  0:00:12s\n","epoch 22 | loss: 205.54148| val_0_mse: 523.4177856445312|  0:00:12s\n","epoch 23 | loss: 199.78951| val_0_mse: 353.7925720214844|  0:00:13s\n","epoch 24 | loss: 213.08849| val_0_mse: 238.88819885253906|  0:00:14s\n","epoch 25 | loss: 207.56837| val_0_mse: 270.91943359375|  0:00:14s\n","epoch 26 | loss: 207.27316| val_0_mse: 314.12042236328125|  0:00:15s\n","epoch 27 | loss: 201.26031| val_0_mse: 252.98699951171875|  0:00:15s\n","epoch 28 | loss: 197.51648| val_0_mse: 263.2117004394531|  0:00:16s\n","epoch 29 | loss: 200.6627| val_0_mse: 232.40582275390625|  0:00:17s\n","epoch 30 | loss: 197.39453| val_0_mse: 257.1919860839844|  0:00:17s\n","epoch 31 | loss: 193.56202| val_0_mse: 207.47642517089844|  0:00:18s\n","epoch 32 | loss: 188.31723| val_0_mse: 207.19288635253906|  0:00:18s\n","epoch 33 | loss: 183.16607| val_0_mse: 211.1144256591797|  0:00:19s\n","epoch 34 | loss: 192.16898| val_0_mse: 203.2323455810547|  0:00:19s\n","epoch 35 | loss: 181.12254| val_0_mse: 224.75714111328125|  0:00:20s\n","epoch 36 | loss: 183.12604| val_0_mse: 223.27188110351562|  0:00:20s\n","epoch 37 | loss: 184.69338| val_0_mse: 204.42532348632812|  0:00:21s\n","epoch 38 | loss: 179.77811| val_0_mse: 210.9706268310547|  0:00:21s\n","epoch 39 | loss: 184.89086| val_0_mse: 194.3092803955078|  0:00:22s\n","epoch 40 | loss: 183.80131| val_0_mse: 209.59469604492188|  0:00:23s\n","epoch 41 | loss: 179.53357| val_0_mse: 194.23890686035156|  0:00:23s\n","epoch 42 | loss: 175.5889| val_0_mse: 207.5131378173828|  0:00:24s\n","epoch 43 | loss: 177.45917| val_0_mse: 218.79603576660156|  0:00:24s\n","epoch 44 | loss: 193.29747| val_0_mse: 198.54364013671875|  0:00:25s\n","epoch 45 | loss: 180.01912| val_0_mse: 281.30413818359375|  0:00:25s\n","epoch 46 | loss: 201.63863| val_0_mse: 198.0316925048828|  0:00:26s\n","epoch 47 | loss: 181.49669| val_0_mse: 185.85838317871094|  0:00:26s\n","epoch 48 | loss: 171.43823| val_0_mse: 200.5625|  0:00:27s\n","epoch 49 | loss: 180.57346| val_0_mse: 181.52516174316406|  0:00:27s\n","epoch 50 | loss: 172.25992| val_0_mse: 198.6064453125|  0:00:28s\n","epoch 51 | loss: 179.72594| val_0_mse: 203.9808349609375|  0:00:29s\n","epoch 52 | loss: 178.39305| val_0_mse: 205.53256225585938|  0:00:29s\n","epoch 53 | loss: 175.98559| val_0_mse: 181.86953735351562|  0:00:30s\n","epoch 54 | loss: 174.35726| val_0_mse: 210.85601806640625|  0:00:30s\n","epoch 55 | loss: 183.85639| val_0_mse: 188.3069610595703|  0:00:31s\n","epoch 56 | loss: 184.02153| val_0_mse: 203.1592254638672|  0:00:31s\n","epoch 57 | loss: 186.6126| val_0_mse: 185.91311645507812|  0:00:32s\n","epoch 58 | loss: 186.97927| val_0_mse: 183.7517547607422|  0:00:32s\n","epoch 59 | loss: 170.30831| val_0_mse: 178.83700561523438|  0:00:33s\n","epoch 60 | loss: 172.63699| val_0_mse: 182.89544677734375|  0:00:33s\n","epoch 61 | loss: 178.00436| val_0_mse: 188.7541046142578|  0:00:34s\n","epoch 62 | loss: 172.99097| val_0_mse: 176.446044921875|  0:00:34s\n","epoch 63 | loss: 165.086 | val_0_mse: 185.09193420410156|  0:00:35s\n","epoch 64 | loss: 166.22658| val_0_mse: 176.5063934326172|  0:00:36s\n","epoch 65 | loss: 173.40656| val_0_mse: 185.0157012939453|  0:00:36s\n","epoch 66 | loss: 170.07666| val_0_mse: 177.7868194580078|  0:00:37s\n","epoch 67 | loss: 163.93582| val_0_mse: 180.5067138671875|  0:00:37s\n","epoch 68 | loss: 161.21257| val_0_mse: 169.03799438476562|  0:00:38s\n","epoch 69 | loss: 159.29727| val_0_mse: 182.8450469970703|  0:00:38s\n","epoch 70 | loss: 164.971 | val_0_mse: 184.9312744140625|  0:00:39s\n","epoch 71 | loss: 158.35297| val_0_mse: 169.77383422851562|  0:00:39s\n","epoch 72 | loss: 154.91253| val_0_mse: 175.20132446289062|  0:00:40s\n","epoch 73 | loss: 157.64618| val_0_mse: 180.64111328125|  0:00:40s\n","epoch 74 | loss: 158.07786| val_0_mse: 175.35899353027344|  0:00:41s\n","epoch 75 | loss: 165.22722| val_0_mse: 179.28907775878906|  0:00:42s\n","epoch 76 | loss: 157.7621| val_0_mse: 164.83547973632812|  0:00:42s\n","epoch 77 | loss: 157.09696| val_0_mse: 179.04986572265625|  0:00:43s\n","epoch 78 | loss: 151.51199| val_0_mse: 162.95993041992188|  0:00:43s\n","epoch 79 | loss: 156.19031| val_0_mse: 164.77552795410156|  0:00:44s\n","epoch 80 | loss: 148.82086| val_0_mse: 166.044189453125|  0:00:44s\n","epoch 81 | loss: 152.5154| val_0_mse: 162.60487365722656|  0:00:45s\n","epoch 82 | loss: 149.85475| val_0_mse: 159.65025329589844|  0:00:45s\n","epoch 83 | loss: 146.89587| val_0_mse: 162.72398376464844|  0:00:46s\n","epoch 84 | loss: 150.37433| val_0_mse: 181.89476013183594|  0:00:47s\n","epoch 85 | loss: 149.61761| val_0_mse: 156.9171142578125|  0:00:47s\n","epoch 86 | loss: 145.80178| val_0_mse: 183.44984436035156|  0:00:48s\n","epoch 87 | loss: 146.29014| val_0_mse: 173.39805603027344|  0:00:48s\n","epoch 88 | loss: 147.88409| val_0_mse: 161.02394104003906|  0:00:49s\n","epoch 89 | loss: 144.72378| val_0_mse: 158.38912963867188|  0:00:49s\n","epoch 90 | loss: 148.82231| val_0_mse: 164.8954315185547|  0:00:50s\n","epoch 91 | loss: 157.83564| val_0_mse: 180.9770965576172|  0:00:50s\n","epoch 92 | loss: 153.26221| val_0_mse: 185.71484375|  0:00:51s\n","epoch 93 | loss: 168.87195| val_0_mse: 193.8105926513672|  0:00:51s\n","epoch 94 | loss: 161.07908| val_0_mse: 166.26365661621094|  0:00:52s\n","epoch 95 | loss: 147.01014| val_0_mse: 161.41770935058594|  0:00:52s\n","\n","Early stopping occurred at epoch 95 with best_epoch = 85 and best_val_0_mse = 156.9171142578125\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 14:55:11,298] Trial 47 finished with value: 156.9171142578125 and parameters: {'n_d': 61, 'n_steps': 3, 'gamma': 1.5954590958533392, 'n_independent': 3, 'n_shared': 2, 'momentum': 0.20122281865932007}. Best is trial 33 with value: 135.8055877685547.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 1809.92244| val_0_mse: 9625.294921875|  0:00:00s\n","epoch 1  | loss: 619.6384| val_0_mse: 33103.3046875|  0:00:01s\n","epoch 2  | loss: 404.75035| val_0_mse: 2812.546142578125|  0:00:02s\n","epoch 3  | loss: 332.02206| val_0_mse: 2530.836669921875|  0:00:03s\n","epoch 4  | loss: 294.41813| val_0_mse: 2696.42041015625|  0:00:04s\n","epoch 5  | loss: 288.38038| val_0_mse: 1299.7347412109375|  0:00:05s\n","epoch 6  | loss: 287.32902| val_0_mse: 815.8911743164062|  0:00:06s\n","epoch 7  | loss: 277.4588| val_0_mse: 1104.1243896484375|  0:00:07s\n","epoch 8  | loss: 285.08552| val_0_mse: 1866.510986328125|  0:00:08s\n","epoch 9  | loss: 273.63861| val_0_mse: 644.4031982421875|  0:00:09s\n","epoch 10 | loss: 260.10104| val_0_mse: 802.2633056640625|  0:00:09s\n","epoch 11 | loss: 269.88487| val_0_mse: 524.208251953125|  0:00:10s\n","epoch 12 | loss: 262.34454| val_0_mse: 538.630126953125|  0:00:11s\n","epoch 13 | loss: 273.35867| val_0_mse: 502.4646301269531|  0:00:12s\n","epoch 14 | loss: 253.39889| val_0_mse: 424.968994140625|  0:00:13s\n","epoch 15 | loss: 244.33711| val_0_mse: 430.15631103515625|  0:00:14s\n","epoch 16 | loss: 240.36699| val_0_mse: 368.07415771484375|  0:00:15s\n","epoch 17 | loss: 242.69739| val_0_mse: 448.1743469238281|  0:00:16s\n","epoch 18 | loss: 235.17065| val_0_mse: 480.3353576660156|  0:00:17s\n","epoch 19 | loss: 227.86855| val_0_mse: 418.95611572265625|  0:00:17s\n","epoch 20 | loss: 216.17494| val_0_mse: 416.044189453125|  0:00:18s\n","epoch 21 | loss: 220.74027| val_0_mse: 422.8951721191406|  0:00:19s\n","epoch 22 | loss: 213.93366| val_0_mse: 344.7512512207031|  0:00:20s\n","epoch 23 | loss: 218.84952| val_0_mse: 373.3757629394531|  0:00:21s\n","epoch 24 | loss: 220.30431| val_0_mse: 306.6607971191406|  0:00:22s\n","epoch 25 | loss: 221.95186| val_0_mse: 309.4198913574219|  0:00:23s\n","epoch 26 | loss: 222.7254| val_0_mse: 304.566162109375|  0:00:24s\n","epoch 27 | loss: 206.45801| val_0_mse: 251.14697265625|  0:00:25s\n","epoch 28 | loss: 212.30095| val_0_mse: 253.83999633789062|  0:00:25s\n","epoch 29 | loss: 205.28821| val_0_mse: 270.29296875|  0:00:26s\n","epoch 30 | loss: 206.3906| val_0_mse: 264.4076232910156|  0:00:27s\n","epoch 31 | loss: 206.83872| val_0_mse: 264.6492004394531|  0:00:28s\n","epoch 32 | loss: 202.45282| val_0_mse: 224.76138305664062|  0:00:29s\n","epoch 33 | loss: 199.67206| val_0_mse: 221.76806640625|  0:00:30s\n","epoch 34 | loss: 202.34769| val_0_mse: 223.3954620361328|  0:00:31s\n","epoch 35 | loss: 198.222 | val_0_mse: 222.11854553222656|  0:00:32s\n","epoch 36 | loss: 193.7837| val_0_mse: 212.20895385742188|  0:00:33s\n","epoch 37 | loss: 189.89835| val_0_mse: 224.95448303222656|  0:00:33s\n","epoch 38 | loss: 196.00285| val_0_mse: 198.7206268310547|  0:00:34s\n","epoch 39 | loss: 198.64501| val_0_mse: 216.7008056640625|  0:00:35s\n","epoch 40 | loss: 197.61536| val_0_mse: 197.38926696777344|  0:00:36s\n","epoch 41 | loss: 190.09135| val_0_mse: 183.466552734375|  0:00:37s\n","epoch 42 | loss: 195.62241| val_0_mse: 256.8757019042969|  0:00:38s\n","epoch 43 | loss: 188.5948| val_0_mse: 195.17454528808594|  0:00:39s\n","epoch 44 | loss: 190.11682| val_0_mse: 195.98875427246094|  0:00:40s\n","epoch 45 | loss: 185.3372| val_0_mse: 189.47427368164062|  0:00:41s\n","epoch 46 | loss: 184.36477| val_0_mse: 201.63156127929688|  0:00:42s\n","epoch 47 | loss: 192.08016| val_0_mse: 190.01036071777344|  0:00:43s\n","epoch 48 | loss: 179.97414| val_0_mse: 181.04136657714844|  0:00:43s\n","epoch 49 | loss: 183.52576| val_0_mse: 212.52035522460938|  0:00:44s\n","epoch 50 | loss: 191.38755| val_0_mse: 177.17233276367188|  0:00:45s\n","epoch 51 | loss: 172.48963| val_0_mse: 173.1923065185547|  0:00:46s\n","epoch 52 | loss: 174.64067| val_0_mse: 199.366455078125|  0:00:47s\n","epoch 53 | loss: 179.56387| val_0_mse: 186.01681518554688|  0:00:48s\n","epoch 54 | loss: 178.22386| val_0_mse: 204.55844116210938|  0:00:49s\n","epoch 55 | loss: 172.0751| val_0_mse: 175.51646423339844|  0:00:50s\n","epoch 56 | loss: 171.59585| val_0_mse: 166.57675170898438|  0:00:51s\n","epoch 57 | loss: 169.29741| val_0_mse: 169.17031860351562|  0:00:51s\n","epoch 58 | loss: 168.61925| val_0_mse: 183.74330139160156|  0:00:52s\n","epoch 59 | loss: 178.39234| val_0_mse: 172.60595703125|  0:00:53s\n","epoch 60 | loss: 175.24241| val_0_mse: 190.0636444091797|  0:00:54s\n","epoch 61 | loss: 171.94912| val_0_mse: 213.3456573486328|  0:00:55s\n","epoch 62 | loss: 190.64411| val_0_mse: 200.48789978027344|  0:00:56s\n","epoch 63 | loss: 180.20712| val_0_mse: 191.54336547851562|  0:00:57s\n","epoch 64 | loss: 175.3992| val_0_mse: 182.87130737304688|  0:00:58s\n","epoch 65 | loss: 173.72026| val_0_mse: 185.74371337890625|  0:00:58s\n","epoch 66 | loss: 181.30017| val_0_mse: 177.74435424804688|  0:00:59s\n","\n","Early stopping occurred at epoch 66 with best_epoch = 56 and best_val_0_mse = 166.57675170898438\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 14:56:11,707] Trial 48 finished with value: 166.57675170898438 and parameters: {'n_d': 52, 'n_steps': 4, 'gamma': 1.3278120916783624, 'n_independent': 3, 'n_shared': 5, 'momentum': 0.06318688959301197}. Best is trial 33 with value: 135.8055877685547.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 1613.96261| val_0_mse: 20817.548828125|  0:00:00s\n","epoch 1  | loss: 515.95567| val_0_mse: 29125.650390625|  0:00:01s\n","epoch 2  | loss: 381.75717| val_0_mse: 8033.1142578125|  0:00:01s\n","epoch 3  | loss: 341.11358| val_0_mse: 17340.259765625|  0:00:02s\n","epoch 4  | loss: 353.35301| val_0_mse: 9499.171875|  0:00:02s\n","epoch 5  | loss: 316.94872| val_0_mse: 12982.8515625|  0:00:03s\n","epoch 6  | loss: 297.67082| val_0_mse: 6170.78271484375|  0:00:03s\n","epoch 7  | loss: 282.02622| val_0_mse: 12679.7314453125|  0:00:04s\n","epoch 8  | loss: 274.9453| val_0_mse: 8648.3046875|  0:00:05s\n","epoch 9  | loss: 271.51343| val_0_mse: 4205.27197265625|  0:00:05s\n","epoch 10 | loss: 262.02968| val_0_mse: 2654.336669921875|  0:00:06s\n","epoch 11 | loss: 250.7215| val_0_mse: 2350.92626953125|  0:00:06s\n","epoch 12 | loss: 245.43077| val_0_mse: 1558.3016357421875|  0:00:07s\n","epoch 13 | loss: 238.08045| val_0_mse: 1705.0823974609375|  0:00:07s\n","epoch 14 | loss: 225.39782| val_0_mse: 1231.4063720703125|  0:00:08s\n","epoch 15 | loss: 230.24574| val_0_mse: 685.4286499023438|  0:00:08s\n","epoch 16 | loss: 216.07208| val_0_mse: 626.1129150390625|  0:00:09s\n","epoch 17 | loss: 223.7052| val_0_mse: 608.07568359375|  0:00:09s\n","epoch 18 | loss: 212.83479| val_0_mse: 765.649658203125|  0:00:10s\n","epoch 19 | loss: 216.61178| val_0_mse: 465.57586669921875|  0:00:11s\n","epoch 20 | loss: 215.40167| val_0_mse: 366.7249450683594|  0:00:11s\n","epoch 21 | loss: 206.12172| val_0_mse: 449.8631591796875|  0:00:12s\n","epoch 22 | loss: 200.39269| val_0_mse: 488.8946838378906|  0:00:12s\n","epoch 23 | loss: 194.88454| val_0_mse: 358.7945861816406|  0:00:13s\n","epoch 24 | loss: 189.95223| val_0_mse: 317.2271728515625|  0:00:13s\n","epoch 25 | loss: 188.2199| val_0_mse: 238.793701171875|  0:00:14s\n","epoch 26 | loss: 184.59408| val_0_mse: 247.1853790283203|  0:00:14s\n","epoch 27 | loss: 198.30435| val_0_mse: 243.40171813964844|  0:00:15s\n","epoch 28 | loss: 194.51658| val_0_mse: 419.5869140625|  0:00:15s\n","epoch 29 | loss: 195.68399| val_0_mse: 228.40957641601562|  0:00:16s\n","epoch 30 | loss: 194.85961| val_0_mse: 207.8486328125|  0:00:16s\n","epoch 31 | loss: 192.98243| val_0_mse: 221.8566436767578|  0:00:17s\n","epoch 32 | loss: 190.13247| val_0_mse: 224.54295349121094|  0:00:18s\n","epoch 33 | loss: 184.85921| val_0_mse: 210.5448455810547|  0:00:18s\n","epoch 34 | loss: 182.76147| val_0_mse: 213.5770263671875|  0:00:19s\n","epoch 35 | loss: 186.87531| val_0_mse: 212.0808868408203|  0:00:19s\n","epoch 36 | loss: 189.99044| val_0_mse: 223.94183349609375|  0:00:20s\n","epoch 37 | loss: 191.29964| val_0_mse: 198.2259063720703|  0:00:20s\n","epoch 38 | loss: 174.50705| val_0_mse: 230.5467987060547|  0:00:21s\n","epoch 39 | loss: 182.04388| val_0_mse: 194.59324645996094|  0:00:21s\n","epoch 40 | loss: 177.61836| val_0_mse: 182.2581787109375|  0:00:22s\n","epoch 41 | loss: 178.86958| val_0_mse: 196.3339385986328|  0:00:22s\n","epoch 42 | loss: 177.11326| val_0_mse: 180.3998260498047|  0:00:23s\n","epoch 43 | loss: 180.91676| val_0_mse: 196.1806182861328|  0:00:24s\n","epoch 44 | loss: 182.6306| val_0_mse: 182.3876953125|  0:00:24s\n","epoch 45 | loss: 182.1141| val_0_mse: 194.03759765625|  0:00:25s\n","epoch 46 | loss: 182.67479| val_0_mse: 183.84373474121094|  0:00:25s\n","epoch 47 | loss: 169.2438| val_0_mse: 195.42306518554688|  0:00:26s\n","epoch 48 | loss: 179.6517| val_0_mse: 185.32940673828125|  0:00:26s\n","epoch 49 | loss: 176.50337| val_0_mse: 223.0445556640625|  0:00:27s\n","epoch 50 | loss: 175.71553| val_0_mse: 179.6403350830078|  0:00:27s\n","epoch 51 | loss: 175.76885| val_0_mse: 198.76231384277344|  0:00:28s\n","epoch 52 | loss: 180.14778| val_0_mse: 177.16233825683594|  0:00:28s\n","epoch 53 | loss: 167.19253| val_0_mse: 193.62399291992188|  0:00:29s\n","epoch 54 | loss: 174.98692| val_0_mse: 216.607666015625|  0:00:30s\n","epoch 55 | loss: 185.60227| val_0_mse: 203.50799560546875|  0:00:30s\n","epoch 56 | loss: 171.2317| val_0_mse: 183.1296844482422|  0:00:31s\n","epoch 57 | loss: 175.34671| val_0_mse: 176.7766876220703|  0:00:31s\n","epoch 58 | loss: 174.34688| val_0_mse: 199.2984161376953|  0:00:32s\n","epoch 59 | loss: 166.1189| val_0_mse: 209.15823364257812|  0:00:32s\n","epoch 60 | loss: 174.56703| val_0_mse: 186.85072326660156|  0:00:33s\n","epoch 61 | loss: 169.17369| val_0_mse: 192.3714141845703|  0:00:33s\n","epoch 62 | loss: 179.01389| val_0_mse: 185.78915405273438|  0:00:34s\n","epoch 63 | loss: 175.37938| val_0_mse: 194.4483642578125|  0:00:34s\n","epoch 64 | loss: 166.71038| val_0_mse: 173.91758728027344|  0:00:35s\n","epoch 65 | loss: 164.409 | val_0_mse: 192.6675567626953|  0:00:36s\n","epoch 66 | loss: 161.97107| val_0_mse: 184.79551696777344|  0:00:36s\n","epoch 67 | loss: 159.33765| val_0_mse: 220.7040557861328|  0:00:37s\n","epoch 68 | loss: 161.57679| val_0_mse: 200.33181762695312|  0:00:37s\n","epoch 69 | loss: 154.8541| val_0_mse: 172.6664276123047|  0:00:38s\n","epoch 70 | loss: 159.13133| val_0_mse: 197.4566650390625|  0:00:38s\n","epoch 71 | loss: 160.53593| val_0_mse: 178.73153686523438|  0:00:39s\n","epoch 72 | loss: 163.48052| val_0_mse: 177.89047241210938|  0:00:39s\n","epoch 73 | loss: 163.62536| val_0_mse: 186.67347717285156|  0:00:40s\n","epoch 74 | loss: 165.22505| val_0_mse: 175.1019744873047|  0:00:40s\n","epoch 75 | loss: 162.34978| val_0_mse: 176.0183868408203|  0:00:41s\n","epoch 76 | loss: 162.24198| val_0_mse: 178.78855895996094|  0:00:41s\n","epoch 77 | loss: 158.95349| val_0_mse: 203.83103942871094|  0:00:42s\n","epoch 78 | loss: 160.70846| val_0_mse: 173.19456481933594|  0:00:42s\n","epoch 79 | loss: 152.36345| val_0_mse: 212.36578369140625|  0:00:43s\n","\n","Early stopping occurred at epoch 79 with best_epoch = 69 and best_val_0_mse = 172.6664276123047\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 14:56:55,511] Trial 49 finished with value: 172.66641235351562 and parameters: {'n_d': 56, 'n_steps': 3, 'gamma': 1.698930655846666, 'n_independent': 2, 'n_shared': 3, 'momentum': 0.03386026955353666}. Best is trial 33 with value: 135.8055877685547.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 1977.44653| val_0_mse: 8841.2900390625|  0:00:01s\n","epoch 1  | loss: 1059.96376| val_0_mse: 8586.6357421875|  0:00:02s\n","epoch 2  | loss: 537.19831| val_0_mse: 4909.16357421875|  0:00:03s\n","epoch 3  | loss: 471.70496| val_0_mse: 2335.063720703125|  0:00:04s\n","epoch 4  | loss: 415.03357| val_0_mse: 14168.666015625|  0:00:05s\n","epoch 5  | loss: 415.59818| val_0_mse: 1097.80517578125|  0:00:06s\n","epoch 6  | loss: 410.66493| val_0_mse: 1509.2183837890625|  0:00:06s\n","epoch 7  | loss: 370.23364| val_0_mse: 2483.992919921875|  0:00:07s\n","epoch 8  | loss: 336.95389| val_0_mse: 3114.27880859375|  0:00:08s\n","epoch 9  | loss: 355.50719| val_0_mse: 2053.12841796875|  0:00:09s\n","epoch 10 | loss: 380.41458| val_0_mse: 979.6229858398438|  0:00:10s\n","epoch 11 | loss: 342.2838| val_0_mse: 1201.162353515625|  0:00:11s\n","epoch 12 | loss: 325.67056| val_0_mse: 984.3248901367188|  0:00:12s\n","epoch 13 | loss: 314.83581| val_0_mse: 1424.277099609375|  0:00:13s\n","epoch 14 | loss: 296.47973| val_0_mse: 993.498291015625|  0:00:14s\n","epoch 15 | loss: 316.65306| val_0_mse: 1070.0758056640625|  0:00:15s\n","epoch 16 | loss: 290.44339| val_0_mse: 972.8408813476562|  0:00:16s\n","epoch 17 | loss: 281.97712| val_0_mse: 883.0037841796875|  0:00:17s\n","epoch 18 | loss: 275.20582| val_0_mse: 1229.6702880859375|  0:00:18s\n","epoch 19 | loss: 284.1808| val_0_mse: 464.1590270996094|  0:00:19s\n","epoch 20 | loss: 273.08466| val_0_mse: 590.0580444335938|  0:00:20s\n","epoch 21 | loss: 271.10175| val_0_mse: 403.3694763183594|  0:00:21s\n","epoch 22 | loss: 265.12772| val_0_mse: 398.36029052734375|  0:00:22s\n","epoch 23 | loss: 257.91994| val_0_mse: 714.6821899414062|  0:00:23s\n","epoch 24 | loss: 265.64051| val_0_mse: 462.5621643066406|  0:00:24s\n","epoch 25 | loss: 270.08621| val_0_mse: 386.7294921875|  0:00:25s\n","epoch 26 | loss: 279.7623| val_0_mse: 340.23553466796875|  0:00:26s\n","epoch 27 | loss: 243.03503| val_0_mse: 293.326416015625|  0:00:27s\n","epoch 28 | loss: 260.23391| val_0_mse: 351.76739501953125|  0:00:28s\n","epoch 29 | loss: 248.82625| val_0_mse: 326.5936279296875|  0:00:29s\n","epoch 30 | loss: 246.90421| val_0_mse: 293.69232177734375|  0:00:29s\n","epoch 31 | loss: 238.56447| val_0_mse: 257.96270751953125|  0:00:31s\n","epoch 32 | loss: 243.92765| val_0_mse: 307.8941345214844|  0:00:32s\n","epoch 33 | loss: 241.04018| val_0_mse: 278.222412109375|  0:00:33s\n","epoch 34 | loss: 231.52147| val_0_mse: 271.4517517089844|  0:00:34s\n","epoch 35 | loss: 234.16159| val_0_mse: 249.52081298828125|  0:00:35s\n","epoch 36 | loss: 226.07152| val_0_mse: 231.10345458984375|  0:00:36s\n","epoch 37 | loss: 257.86735| val_0_mse: 315.37432861328125|  0:00:37s\n","epoch 38 | loss: 253.23496| val_0_mse: 237.55880737304688|  0:00:38s\n","epoch 39 | loss: 225.71175| val_0_mse: 224.75515747070312|  0:00:39s\n","epoch 40 | loss: 222.71627| val_0_mse: 244.11697387695312|  0:00:40s\n","epoch 41 | loss: 217.92242| val_0_mse: 221.0599822998047|  0:00:41s\n","epoch 42 | loss: 212.18747| val_0_mse: 229.04544067382812|  0:00:42s\n","epoch 43 | loss: 215.24895| val_0_mse: 223.26454162597656|  0:00:43s\n","epoch 44 | loss: 209.34909| val_0_mse: 229.80050659179688|  0:00:44s\n","epoch 45 | loss: 217.08759| val_0_mse: 229.26077270507812|  0:00:45s\n","epoch 46 | loss: 207.88257| val_0_mse: 240.7876739501953|  0:00:46s\n","epoch 47 | loss: 218.61378| val_0_mse: 274.24554443359375|  0:00:47s\n","epoch 48 | loss: 215.6422| val_0_mse: 213.48216247558594|  0:00:48s\n","epoch 49 | loss: 205.17242| val_0_mse: 227.6797332763672|  0:00:49s\n","epoch 50 | loss: 203.98639| val_0_mse: 214.10328674316406|  0:00:50s\n","epoch 51 | loss: 204.21008| val_0_mse: 213.6053924560547|  0:00:51s\n","epoch 52 | loss: 199.70749| val_0_mse: 212.2587127685547|  0:00:52s\n","epoch 53 | loss: 206.38638| val_0_mse: 216.44412231445312|  0:00:53s\n","epoch 54 | loss: 205.85799| val_0_mse: 216.99847412109375|  0:00:54s\n","epoch 55 | loss: 204.14001| val_0_mse: 199.56475830078125|  0:00:55s\n","epoch 56 | loss: 207.48779| val_0_mse: 200.58175659179688|  0:00:56s\n","epoch 57 | loss: 199.82188| val_0_mse: 209.5582275390625|  0:00:57s\n","epoch 58 | loss: 206.50271| val_0_mse: 250.46864318847656|  0:00:58s\n","epoch 59 | loss: 214.97152| val_0_mse: 217.83837890625|  0:00:59s\n","epoch 60 | loss: 208.66183| val_0_mse: 207.2726593017578|  0:01:00s\n","epoch 61 | loss: 197.29912| val_0_mse: 208.21966552734375|  0:01:01s\n","epoch 62 | loss: 196.86972| val_0_mse: 201.14010620117188|  0:01:02s\n","epoch 63 | loss: 190.4473| val_0_mse: 192.66831970214844|  0:01:03s\n","epoch 64 | loss: 188.23484| val_0_mse: 221.35015869140625|  0:01:04s\n","epoch 65 | loss: 193.57725| val_0_mse: 238.79449462890625|  0:01:05s\n","epoch 66 | loss: 199.20123| val_0_mse: 318.0238952636719|  0:01:06s\n","epoch 67 | loss: 205.35406| val_0_mse: 196.2937469482422|  0:01:07s\n","epoch 68 | loss: 198.20036| val_0_mse: 195.8203125|  0:01:08s\n","epoch 69 | loss: 196.26081| val_0_mse: 200.4068145751953|  0:01:09s\n","epoch 70 | loss: 197.5145| val_0_mse: 198.85191345214844|  0:01:10s\n","epoch 71 | loss: 195.86717| val_0_mse: 240.4915771484375|  0:01:11s\n","epoch 72 | loss: 203.29712| val_0_mse: 231.48365783691406|  0:01:12s\n","epoch 73 | loss: 198.69976| val_0_mse: 196.3470458984375|  0:01:13s\n","\n","Early stopping occurred at epoch 73 with best_epoch = 63 and best_val_0_mse = 192.66831970214844\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 14:58:10,106] Trial 50 finished with value: 192.66831970214844 and parameters: {'n_d': 32, 'n_steps': 5, 'gamma': 1.4088684139917047, 'n_independent': 4, 'n_shared': 3, 'momentum': 0.07682059510946293}. Best is trial 33 with value: 135.8055877685547.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 1686.20828| val_0_mse: 26601.236328125|  0:00:00s\n","epoch 1  | loss: 515.15656| val_0_mse: 3661.735107421875|  0:00:01s\n","epoch 2  | loss: 349.22768| val_0_mse: 3239.991455078125|  0:00:01s\n","epoch 3  | loss: 309.47753| val_0_mse: 2164.0107421875|  0:00:02s\n","epoch 4  | loss: 289.37683| val_0_mse: 2301.143798828125|  0:00:03s\n","epoch 5  | loss: 279.11743| val_0_mse: 1147.7362060546875|  0:00:03s\n","epoch 6  | loss: 272.34468| val_0_mse: 926.934814453125|  0:00:04s\n","epoch 7  | loss: 261.84495| val_0_mse: 1400.1895751953125|  0:00:05s\n","epoch 8  | loss: 261.70489| val_0_mse: 1138.1041259765625|  0:00:05s\n","epoch 9  | loss: 267.01585| val_0_mse: 610.1919555664062|  0:00:06s\n","epoch 10 | loss: 246.21857| val_0_mse: 844.8324584960938|  0:00:07s\n","epoch 11 | loss: 224.89519| val_0_mse: 1341.45263671875|  0:00:07s\n","epoch 12 | loss: 226.78631| val_0_mse: 687.6046142578125|  0:00:08s\n","epoch 13 | loss: 219.7147| val_0_mse: 695.1514282226562|  0:00:09s\n","epoch 14 | loss: 204.81434| val_0_mse: 463.1927490234375|  0:00:09s\n","epoch 15 | loss: 199.92225| val_0_mse: 610.65625|  0:00:10s\n","epoch 16 | loss: 196.16503| val_0_mse: 641.745849609375|  0:00:11s\n","epoch 17 | loss: 193.86591| val_0_mse: 598.3704223632812|  0:00:11s\n","epoch 18 | loss: 221.58284| val_0_mse: 558.2864990234375|  0:00:12s\n","epoch 19 | loss: 206.19572| val_0_mse: 579.474853515625|  0:00:13s\n","epoch 20 | loss: 204.99979| val_0_mse: 554.6966552734375|  0:00:13s\n","epoch 21 | loss: 203.46446| val_0_mse: 523.7548217773438|  0:00:14s\n","epoch 22 | loss: 204.95659| val_0_mse: 469.2430419921875|  0:00:15s\n","epoch 23 | loss: 216.24922| val_0_mse: 303.64837646484375|  0:00:15s\n","epoch 24 | loss: 200.13047| val_0_mse: 270.500732421875|  0:00:16s\n","epoch 25 | loss: 187.50987| val_0_mse: 355.373291015625|  0:00:17s\n","epoch 26 | loss: 180.18062| val_0_mse: 263.433349609375|  0:00:17s\n","epoch 27 | loss: 187.07016| val_0_mse: 285.8190612792969|  0:00:18s\n","epoch 28 | loss: 184.50879| val_0_mse: 230.92628479003906|  0:00:18s\n","epoch 29 | loss: 175.1616| val_0_mse: 264.40765380859375|  0:00:19s\n","epoch 30 | loss: 173.96174| val_0_mse: 215.04705810546875|  0:00:20s\n","epoch 31 | loss: 177.93242| val_0_mse: 262.2041320800781|  0:00:20s\n","epoch 32 | loss: 183.90485| val_0_mse: 297.082763671875|  0:00:21s\n","epoch 33 | loss: 171.53236| val_0_mse: 236.37124633789062|  0:00:22s\n","epoch 34 | loss: 179.18611| val_0_mse: 243.40428161621094|  0:00:22s\n","epoch 35 | loss: 184.10444| val_0_mse: 190.4103240966797|  0:00:23s\n","epoch 36 | loss: 176.00544| val_0_mse: 208.08026123046875|  0:00:24s\n","epoch 37 | loss: 178.44739| val_0_mse: 214.9564208984375|  0:00:24s\n","epoch 38 | loss: 167.33526| val_0_mse: 202.15460205078125|  0:00:25s\n","epoch 39 | loss: 175.44058| val_0_mse: 202.20736694335938|  0:00:25s\n","epoch 40 | loss: 170.71954| val_0_mse: 181.8514862060547|  0:00:26s\n","epoch 41 | loss: 166.21372| val_0_mse: 178.5935821533203|  0:00:27s\n","epoch 42 | loss: 163.137 | val_0_mse: 216.3345184326172|  0:00:27s\n","epoch 43 | loss: 168.56325| val_0_mse: 175.7501220703125|  0:00:28s\n","epoch 44 | loss: 162.58849| val_0_mse: 177.30584716796875|  0:00:28s\n","epoch 45 | loss: 161.18036| val_0_mse: 182.5669403076172|  0:00:29s\n","epoch 46 | loss: 158.80661| val_0_mse: 170.4562530517578|  0:00:30s\n","epoch 47 | loss: 166.02397| val_0_mse: 168.74957275390625|  0:00:30s\n","epoch 48 | loss: 154.05422| val_0_mse: 172.13967895507812|  0:00:31s\n","epoch 49 | loss: 160.50061| val_0_mse: 158.66990661621094|  0:00:32s\n","epoch 50 | loss: 159.09946| val_0_mse: 174.43350219726562|  0:00:32s\n","epoch 51 | loss: 160.14617| val_0_mse: 176.8071746826172|  0:00:33s\n","epoch 52 | loss: 151.95447| val_0_mse: 166.97808837890625|  0:00:34s\n","epoch 53 | loss: 152.73857| val_0_mse: 168.92636108398438|  0:00:34s\n","epoch 54 | loss: 149.17403| val_0_mse: 165.53517150878906|  0:00:35s\n","epoch 55 | loss: 157.0365| val_0_mse: 196.99742126464844|  0:00:36s\n","epoch 56 | loss: 161.23946| val_0_mse: 165.1303253173828|  0:00:36s\n","epoch 57 | loss: 166.63153| val_0_mse: 170.50314331054688|  0:00:37s\n","epoch 58 | loss: 154.42403| val_0_mse: 197.6366729736328|  0:00:38s\n","epoch 59 | loss: 154.06661| val_0_mse: 157.13934326171875|  0:00:38s\n","epoch 60 | loss: 152.9932| val_0_mse: 177.139892578125|  0:00:39s\n","epoch 61 | loss: 156.83147| val_0_mse: 167.94822692871094|  0:00:39s\n","epoch 62 | loss: 150.47673| val_0_mse: 188.1663055419922|  0:00:40s\n","epoch 63 | loss: 159.42391| val_0_mse: 166.6541290283203|  0:00:41s\n","epoch 64 | loss: 148.08822| val_0_mse: 180.77630615234375|  0:00:42s\n","epoch 65 | loss: 143.84899| val_0_mse: 163.59547424316406|  0:00:42s\n","epoch 66 | loss: 136.95418| val_0_mse: 153.20802307128906|  0:00:43s\n","epoch 67 | loss: 136.60149| val_0_mse: 163.32382202148438|  0:00:44s\n","epoch 68 | loss: 144.83044| val_0_mse: 161.0701446533203|  0:00:44s\n","epoch 69 | loss: 140.88601| val_0_mse: 158.06407165527344|  0:00:45s\n","epoch 70 | loss: 140.24737| val_0_mse: 150.50245666503906|  0:00:46s\n","epoch 71 | loss: 140.40671| val_0_mse: 160.70652770996094|  0:00:46s\n","epoch 72 | loss: 136.70741| val_0_mse: 169.9744873046875|  0:00:47s\n","epoch 73 | loss: 144.20795| val_0_mse: 164.40296936035156|  0:00:47s\n","epoch 74 | loss: 139.46481| val_0_mse: 156.63365173339844|  0:00:48s\n","epoch 75 | loss: 135.86002| val_0_mse: 158.944091796875|  0:00:49s\n","epoch 76 | loss: 133.70825| val_0_mse: 163.33990478515625|  0:00:49s\n","epoch 77 | loss: 137.90823| val_0_mse: 156.10708618164062|  0:00:50s\n","epoch 78 | loss: 139.2521| val_0_mse: 156.67808532714844|  0:00:51s\n","epoch 79 | loss: 137.66688| val_0_mse: 169.7746124267578|  0:00:51s\n","epoch 80 | loss: 146.66981| val_0_mse: 170.02993774414062|  0:00:52s\n","\n","Early stopping occurred at epoch 80 with best_epoch = 70 and best_val_0_mse = 150.50245666503906\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 14:59:03,110] Trial 51 finished with value: 150.50245666503906 and parameters: {'n_d': 57, 'n_steps': 3, 'gamma': 1.4816152520508805, 'n_independent': 3, 'n_shared': 3, 'momentum': 0.10566068626935098}. Best is trial 33 with value: 135.8055877685547.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 1382.0411| val_0_mse: 60381.0390625|  0:00:00s\n","epoch 1  | loss: 449.54593| val_0_mse: 36004.42578125|  0:00:01s\n","epoch 2  | loss: 371.19013| val_0_mse: 72625.1015625|  0:00:01s\n","epoch 3  | loss: 368.773 | val_0_mse: 8854.90625|  0:00:02s\n","epoch 4  | loss: 340.12688| val_0_mse: 3707.931884765625|  0:00:03s\n","epoch 5  | loss: 324.81483| val_0_mse: 10481.9423828125|  0:00:03s\n","epoch 6  | loss: 309.03796| val_0_mse: 5555.2744140625|  0:00:04s\n","epoch 7  | loss: 302.84924| val_0_mse: 7397.9521484375|  0:00:05s\n","epoch 8  | loss: 293.76405| val_0_mse: 11209.322265625|  0:00:05s\n","epoch 9  | loss: 283.07107| val_0_mse: 7596.21484375|  0:00:06s\n","epoch 10 | loss: 267.33985| val_0_mse: 5068.39111328125|  0:00:07s\n","epoch 11 | loss: 259.18152| val_0_mse: 1565.17333984375|  0:00:07s\n","epoch 12 | loss: 261.69083| val_0_mse: 1777.6309814453125|  0:00:08s\n","epoch 13 | loss: 258.39213| val_0_mse: 2788.433349609375|  0:00:09s\n","epoch 14 | loss: 242.09001| val_0_mse: 1589.3448486328125|  0:00:09s\n","epoch 15 | loss: 235.46683| val_0_mse: 3604.7607421875|  0:00:10s\n","epoch 16 | loss: 230.42784| val_0_mse: 1780.8475341796875|  0:00:11s\n","epoch 17 | loss: 227.99591| val_0_mse: 3037.935791015625|  0:00:11s\n","epoch 18 | loss: 224.72557| val_0_mse: 1003.927490234375|  0:00:12s\n","epoch 19 | loss: 225.78783| val_0_mse: 802.3421630859375|  0:00:13s\n","epoch 20 | loss: 223.00208| val_0_mse: 834.4425048828125|  0:00:13s\n","epoch 21 | loss: 214.74819| val_0_mse: 761.0838623046875|  0:00:14s\n","epoch 22 | loss: 218.83831| val_0_mse: 542.85986328125|  0:00:15s\n","epoch 23 | loss: 209.90954| val_0_mse: 409.4415283203125|  0:00:15s\n","epoch 24 | loss: 202.57347| val_0_mse: 510.6439514160156|  0:00:16s\n","epoch 25 | loss: 205.14752| val_0_mse: 427.51080322265625|  0:00:17s\n","epoch 26 | loss: 200.49886| val_0_mse: 406.12359619140625|  0:00:17s\n","epoch 27 | loss: 201.58554| val_0_mse: 295.9595642089844|  0:00:18s\n","epoch 28 | loss: 194.00789| val_0_mse: 331.4020080566406|  0:00:18s\n","epoch 29 | loss: 192.08864| val_0_mse: 276.91107177734375|  0:00:19s\n","epoch 30 | loss: 197.21265| val_0_mse: 233.4595947265625|  0:00:20s\n","epoch 31 | loss: 187.91503| val_0_mse: 272.3600769042969|  0:00:20s\n","epoch 32 | loss: 184.8801| val_0_mse: 238.51611328125|  0:00:21s\n","epoch 33 | loss: 191.72448| val_0_mse: 247.29029846191406|  0:00:22s\n","epoch 34 | loss: 186.00201| val_0_mse: 186.5742645263672|  0:00:22s\n","epoch 35 | loss: 185.30705| val_0_mse: 194.42031860351562|  0:00:23s\n","epoch 36 | loss: 177.36584| val_0_mse: 202.62832641601562|  0:00:24s\n","epoch 37 | loss: 171.6631| val_0_mse: 187.396240234375|  0:00:24s\n","epoch 38 | loss: 173.8642| val_0_mse: 180.9676055908203|  0:00:25s\n","epoch 39 | loss: 168.99327| val_0_mse: 198.33566284179688|  0:00:26s\n","epoch 40 | loss: 169.45673| val_0_mse: 177.0003662109375|  0:00:26s\n","epoch 41 | loss: 169.11209| val_0_mse: 177.77308654785156|  0:00:27s\n","epoch 42 | loss: 174.51575| val_0_mse: 193.98983764648438|  0:00:28s\n","epoch 43 | loss: 168.04469| val_0_mse: 177.1069793701172|  0:00:28s\n","epoch 44 | loss: 166.71537| val_0_mse: 200.4521942138672|  0:00:29s\n","epoch 45 | loss: 165.8249| val_0_mse: 182.876220703125|  0:00:30s\n","epoch 46 | loss: 159.52774| val_0_mse: 197.51255798339844|  0:00:30s\n","epoch 47 | loss: 161.99164| val_0_mse: 179.36886596679688|  0:00:31s\n","epoch 48 | loss: 171.86102| val_0_mse: 186.27398681640625|  0:00:31s\n","epoch 49 | loss: 160.53021| val_0_mse: 173.77975463867188|  0:00:32s\n","epoch 50 | loss: 161.09123| val_0_mse: 203.5373992919922|  0:00:33s\n","epoch 51 | loss: 162.1813| val_0_mse: 174.51600646972656|  0:00:33s\n","epoch 52 | loss: 167.83335| val_0_mse: 182.67698669433594|  0:00:34s\n","epoch 53 | loss: 164.39266| val_0_mse: 171.23182678222656|  0:00:35s\n","epoch 54 | loss: 156.53421| val_0_mse: 168.81619262695312|  0:00:35s\n","epoch 55 | loss: 153.80253| val_0_mse: 183.72799682617188|  0:00:36s\n","epoch 56 | loss: 151.90543| val_0_mse: 164.4820556640625|  0:00:37s\n","epoch 57 | loss: 144.36108| val_0_mse: 173.49815368652344|  0:00:37s\n","epoch 58 | loss: 146.63442| val_0_mse: 188.03115844726562|  0:00:38s\n","epoch 59 | loss: 153.17165| val_0_mse: 164.78382873535156|  0:00:38s\n","epoch 60 | loss: 152.62551| val_0_mse: 171.0088653564453|  0:00:39s\n","epoch 61 | loss: 150.2597| val_0_mse: 167.93557739257812|  0:00:40s\n","epoch 62 | loss: 146.06792| val_0_mse: 165.2188720703125|  0:00:40s\n","epoch 63 | loss: 145.20088| val_0_mse: 167.8302459716797|  0:00:41s\n","epoch 64 | loss: 148.08478| val_0_mse: 165.58697509765625|  0:00:42s\n","epoch 65 | loss: 144.7626| val_0_mse: 165.89744567871094|  0:00:42s\n","epoch 66 | loss: 140.7368| val_0_mse: 160.3126220703125|  0:00:43s\n","epoch 67 | loss: 139.78871| val_0_mse: 164.87393188476562|  0:00:43s\n","epoch 68 | loss: 145.60837| val_0_mse: 177.26400756835938|  0:00:44s\n","epoch 69 | loss: 143.92354| val_0_mse: 173.5871124267578|  0:00:45s\n","epoch 70 | loss: 144.83572| val_0_mse: 187.03306579589844|  0:00:45s\n","epoch 71 | loss: 145.90595| val_0_mse: 158.4368896484375|  0:00:46s\n","epoch 72 | loss: 138.29784| val_0_mse: 150.79568481445312|  0:00:47s\n","epoch 73 | loss: 139.69263| val_0_mse: 167.7218017578125|  0:00:47s\n","epoch 74 | loss: 139.90528| val_0_mse: 155.4281005859375|  0:00:48s\n","epoch 75 | loss: 131.65653| val_0_mse: 162.58436584472656|  0:00:49s\n","epoch 76 | loss: 130.71557| val_0_mse: 165.8153533935547|  0:00:49s\n","epoch 77 | loss: 132.77585| val_0_mse: 173.46890258789062|  0:00:50s\n","epoch 78 | loss: 137.46961| val_0_mse: 155.6457977294922|  0:00:51s\n","epoch 79 | loss: 134.49272| val_0_mse: 152.6143798828125|  0:00:51s\n","epoch 80 | loss: 130.86138| val_0_mse: 146.16937255859375|  0:00:52s\n","epoch 81 | loss: 129.05316| val_0_mse: 155.073974609375|  0:00:53s\n","epoch 82 | loss: 130.09319| val_0_mse: 145.3269805908203|  0:00:53s\n","epoch 83 | loss: 122.28073| val_0_mse: 145.90066528320312|  0:00:54s\n","epoch 84 | loss: 126.22571| val_0_mse: 180.88955688476562|  0:00:54s\n","epoch 85 | loss: 123.02813| val_0_mse: 152.2991180419922|  0:00:55s\n","epoch 86 | loss: 124.74478| val_0_mse: 166.2139434814453|  0:00:56s\n","epoch 87 | loss: 121.50687| val_0_mse: 144.247802734375|  0:00:56s\n","epoch 88 | loss: 123.9634| val_0_mse: 154.8487091064453|  0:00:57s\n","epoch 89 | loss: 119.02004| val_0_mse: 143.73190307617188|  0:00:58s\n","epoch 90 | loss: 115.93322| val_0_mse: 136.5078582763672|  0:00:58s\n","epoch 91 | loss: 115.8178| val_0_mse: 151.35935974121094|  0:00:59s\n","epoch 92 | loss: 114.5476| val_0_mse: 137.38291931152344|  0:01:00s\n","epoch 93 | loss: 116.02169| val_0_mse: 136.95509338378906|  0:01:01s\n","epoch 94 | loss: 115.56693| val_0_mse: 144.61099243164062|  0:01:01s\n","epoch 95 | loss: 118.257 | val_0_mse: 176.59872436523438|  0:01:02s\n","epoch 96 | loss: 119.82673| val_0_mse: 136.6498260498047|  0:01:03s\n","epoch 97 | loss: 119.14695| val_0_mse: 177.83590698242188|  0:01:03s\n","epoch 98 | loss: 117.38634| val_0_mse: 157.97198486328125|  0:01:04s\n","epoch 99 | loss: 110.28293| val_0_mse: 166.83636474609375|  0:01:05s\n","Stop training because you reached max_epochs = 100 with best_epoch = 90 and best_val_0_mse = 136.5078582763672\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 15:00:08,526] Trial 52 finished with value: 136.5078582763672 and parameters: {'n_d': 63, 'n_steps': 3, 'gamma': 1.4616081744520757, 'n_independent': 3, 'n_shared': 3, 'momentum': 0.15838839296696103}. Best is trial 33 with value: 135.8055877685547.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 1626.77254| val_0_mse: 63130.5234375|  0:00:00s\n","epoch 1  | loss: 473.02522| val_0_mse: 4921.06201171875|  0:00:01s\n","epoch 2  | loss: 377.5277| val_0_mse: 7024.3720703125|  0:00:02s\n","epoch 3  | loss: 334.39274| val_0_mse: 2336.14892578125|  0:00:02s\n","epoch 4  | loss: 297.87839| val_0_mse: 8553.4267578125|  0:00:03s\n","epoch 5  | loss: 286.09457| val_0_mse: 3600.2138671875|  0:00:04s\n","epoch 6  | loss: 256.45723| val_0_mse: 1201.8284912109375|  0:00:05s\n","epoch 7  | loss: 259.7001| val_0_mse: 970.7888793945312|  0:00:05s\n","epoch 8  | loss: 248.91282| val_0_mse: 1037.8756103515625|  0:00:06s\n","epoch 9  | loss: 235.04026| val_0_mse: 1088.533203125|  0:00:07s\n","epoch 10 | loss: 233.71683| val_0_mse: 909.9613037109375|  0:00:07s\n","epoch 11 | loss: 218.3766| val_0_mse: 762.9300537109375|  0:00:08s\n","epoch 12 | loss: 216.03005| val_0_mse: 898.4791259765625|  0:00:09s\n","epoch 13 | loss: 208.08339| val_0_mse: 686.7728271484375|  0:00:10s\n","epoch 14 | loss: 209.55509| val_0_mse: 535.3955688476562|  0:00:10s\n","epoch 15 | loss: 214.8748| val_0_mse: 574.7741088867188|  0:00:11s\n","epoch 16 | loss: 203.90295| val_0_mse: 368.60247802734375|  0:00:12s\n","epoch 17 | loss: 208.66824| val_0_mse: 298.81231689453125|  0:00:12s\n","epoch 18 | loss: 200.96269| val_0_mse: 368.772705078125|  0:00:13s\n","epoch 19 | loss: 197.88987| val_0_mse: 430.82489013671875|  0:00:14s\n","epoch 20 | loss: 201.04929| val_0_mse: 316.5109558105469|  0:00:15s\n","epoch 21 | loss: 198.19001| val_0_mse: 415.1069641113281|  0:00:15s\n","epoch 22 | loss: 191.63929| val_0_mse: 342.63494873046875|  0:00:16s\n","epoch 23 | loss: 191.64517| val_0_mse: 340.17791748046875|  0:00:17s\n","epoch 24 | loss: 189.3891| val_0_mse: 281.20684814453125|  0:00:17s\n","epoch 25 | loss: 191.55996| val_0_mse: 338.8782043457031|  0:00:18s\n","epoch 26 | loss: 189.4667| val_0_mse: 362.396728515625|  0:00:19s\n","epoch 27 | loss: 193.9248| val_0_mse: 343.4016418457031|  0:00:20s\n","epoch 28 | loss: 190.53461| val_0_mse: 258.15899658203125|  0:00:20s\n","epoch 29 | loss: 184.5577| val_0_mse: 320.89178466796875|  0:00:21s\n","epoch 30 | loss: 186.63701| val_0_mse: 237.45509338378906|  0:00:22s\n","epoch 31 | loss: 195.0264| val_0_mse: 200.565185546875|  0:00:23s\n","epoch 32 | loss: 180.46056| val_0_mse: 200.09107971191406|  0:00:23s\n","epoch 33 | loss: 193.57035| val_0_mse: 206.65025329589844|  0:00:24s\n","epoch 34 | loss: 180.43714| val_0_mse: 239.878173828125|  0:00:25s\n","epoch 35 | loss: 179.39027| val_0_mse: 196.9694061279297|  0:00:26s\n","epoch 36 | loss: 179.64457| val_0_mse: 189.2577362060547|  0:00:26s\n","epoch 37 | loss: 176.4457| val_0_mse: 235.05003356933594|  0:00:27s\n","epoch 38 | loss: 183.37462| val_0_mse: 192.59402465820312|  0:00:28s\n","epoch 39 | loss: 180.53397| val_0_mse: 210.90716552734375|  0:00:29s\n","epoch 40 | loss: 171.1629| val_0_mse: 181.51437377929688|  0:00:29s\n","epoch 41 | loss: 175.52342| val_0_mse: 198.08213806152344|  0:00:30s\n","epoch 42 | loss: 181.66267| val_0_mse: 239.6214141845703|  0:00:31s\n","epoch 43 | loss: 178.21548| val_0_mse: 198.69204711914062|  0:00:32s\n","epoch 44 | loss: 174.73066| val_0_mse: 187.46910095214844|  0:00:32s\n","epoch 45 | loss: 177.31641| val_0_mse: 180.13937377929688|  0:00:33s\n","epoch 46 | loss: 175.71436| val_0_mse: 187.7705535888672|  0:00:34s\n","epoch 47 | loss: 172.7065| val_0_mse: 184.78175354003906|  0:00:34s\n","epoch 48 | loss: 176.3252| val_0_mse: 197.9889373779297|  0:00:35s\n","epoch 49 | loss: 164.70837| val_0_mse: 199.55018615722656|  0:00:36s\n","epoch 50 | loss: 171.20686| val_0_mse: 178.07591247558594|  0:00:37s\n","epoch 51 | loss: 169.1353| val_0_mse: 174.17703247070312|  0:00:37s\n","epoch 52 | loss: 159.35864| val_0_mse: 181.59661865234375|  0:00:38s\n","epoch 53 | loss: 163.41994| val_0_mse: 177.49339294433594|  0:00:39s\n","epoch 54 | loss: 176.44082| val_0_mse: 191.28309631347656|  0:00:40s\n","epoch 55 | loss: 166.30809| val_0_mse: 188.69859313964844|  0:00:40s\n","epoch 56 | loss: 160.93048| val_0_mse: 196.045654296875|  0:00:41s\n","epoch 57 | loss: 171.79219| val_0_mse: 200.89242553710938|  0:00:42s\n","epoch 58 | loss: 163.32824| val_0_mse: 182.29794311523438|  0:00:42s\n","epoch 59 | loss: 160.37313| val_0_mse: 184.24989318847656|  0:00:43s\n","epoch 60 | loss: 160.00323| val_0_mse: 197.26495361328125|  0:00:44s\n","epoch 61 | loss: 166.50056| val_0_mse: 171.09817504882812|  0:00:45s\n","epoch 62 | loss: 162.48127| val_0_mse: 178.20217895507812|  0:00:45s\n","epoch 63 | loss: 179.54093| val_0_mse: 178.39547729492188|  0:00:46s\n","epoch 64 | loss: 160.72508| val_0_mse: 174.51742553710938|  0:00:47s\n","epoch 65 | loss: 161.90903| val_0_mse: 176.00579833984375|  0:00:47s\n","epoch 66 | loss: 155.1627| val_0_mse: 169.20811462402344|  0:00:48s\n","epoch 67 | loss: 155.0209| val_0_mse: 163.29444885253906|  0:00:49s\n","epoch 68 | loss: 150.15463| val_0_mse: 159.18824768066406|  0:00:50s\n","epoch 69 | loss: 148.98178| val_0_mse: 169.35581970214844|  0:00:50s\n","epoch 70 | loss: 152.81701| val_0_mse: 184.4595947265625|  0:00:51s\n","epoch 71 | loss: 147.46283| val_0_mse: 168.88714599609375|  0:00:52s\n","epoch 72 | loss: 142.76394| val_0_mse: 157.36439514160156|  0:00:53s\n","epoch 73 | loss: 145.55475| val_0_mse: 184.51611328125|  0:00:53s\n","epoch 74 | loss: 146.01347| val_0_mse: 163.04054260253906|  0:00:54s\n","epoch 75 | loss: 137.83586| val_0_mse: 146.55978393554688|  0:00:55s\n","epoch 76 | loss: 140.44802| val_0_mse: 163.99163818359375|  0:00:56s\n","epoch 77 | loss: 148.02353| val_0_mse: 159.65196228027344|  0:00:56s\n","epoch 78 | loss: 138.50175| val_0_mse: 158.3055877685547|  0:00:57s\n","epoch 79 | loss: 136.88374| val_0_mse: 146.79608154296875|  0:00:58s\n","epoch 80 | loss: 136.55533| val_0_mse: 153.250732421875|  0:00:58s\n","epoch 81 | loss: 136.80727| val_0_mse: 149.01730346679688|  0:00:59s\n","epoch 82 | loss: 136.28236| val_0_mse: 150.54383850097656|  0:01:00s\n","epoch 83 | loss: 141.80275| val_0_mse: 157.09359741210938|  0:01:01s\n","epoch 84 | loss: 141.52938| val_0_mse: 153.69427490234375|  0:01:01s\n","epoch 85 | loss: 141.43542| val_0_mse: 157.8895263671875|  0:01:02s\n","\n","Early stopping occurred at epoch 85 with best_epoch = 75 and best_val_0_mse = 146.55978393554688\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 15:01:11,583] Trial 53 finished with value: 146.55978393554688 and parameters: {'n_d': 62, 'n_steps': 3, 'gamma': 1.5441419351177217, 'n_independent': 3, 'n_shared': 4, 'momentum': 0.1275717794836053}. Best is trial 33 with value: 135.8055877685547.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 1671.72937| val_0_mse: 31128.796875|  0:00:00s\n","epoch 1  | loss: 614.35394| val_0_mse: 24701.6953125|  0:00:01s\n","epoch 2  | loss: 506.75132| val_0_mse: 5168.69921875|  0:00:02s\n","epoch 3  | loss: 450.33571| val_0_mse: 11548.0 |  0:00:03s\n","epoch 4  | loss: 386.12894| val_0_mse: 30575.611328125|  0:00:04s\n","epoch 5  | loss: 383.81767| val_0_mse: 6231.5029296875|  0:00:05s\n","epoch 6  | loss: 377.50065| val_0_mse: 5938.0888671875|  0:00:06s\n","epoch 7  | loss: 373.68661| val_0_mse: 11206.6376953125|  0:00:07s\n","epoch 8  | loss: 369.84092| val_0_mse: 5626.14892578125|  0:00:07s\n","epoch 9  | loss: 357.81631| val_0_mse: 4311.33251953125|  0:00:08s\n","epoch 10 | loss: 369.78625| val_0_mse: 9904.939453125|  0:00:09s\n","epoch 11 | loss: 366.459 | val_0_mse: 5350.05322265625|  0:00:10s\n","epoch 12 | loss: 411.35403| val_0_mse: 2617.49853515625|  0:00:11s\n","epoch 13 | loss: 363.45654| val_0_mse: 1619.5257568359375|  0:00:12s\n","epoch 14 | loss: 385.70353| val_0_mse: 1336.161376953125|  0:00:13s\n","epoch 15 | loss: 362.14869| val_0_mse: 1644.1329345703125|  0:00:13s\n","epoch 16 | loss: 334.27159| val_0_mse: 1480.7667236328125|  0:00:14s\n","epoch 17 | loss: 331.29417| val_0_mse: 1435.490234375|  0:00:15s\n","epoch 18 | loss: 314.73204| val_0_mse: 914.410888671875|  0:00:16s\n","epoch 19 | loss: 313.7879| val_0_mse: 869.3507080078125|  0:00:17s\n","epoch 20 | loss: 320.16515| val_0_mse: 1081.05078125|  0:00:18s\n","epoch 21 | loss: 335.44418| val_0_mse: 1053.48486328125|  0:00:19s\n","epoch 22 | loss: 322.4283| val_0_mse: 803.6141357421875|  0:00:19s\n","epoch 23 | loss: 355.20974| val_0_mse: 653.7307739257812|  0:00:20s\n","epoch 24 | loss: 354.7812| val_0_mse: 489.77459716796875|  0:00:21s\n","epoch 25 | loss: 357.95117| val_0_mse: 497.5752258300781|  0:00:22s\n","epoch 26 | loss: 321.66522| val_0_mse: 547.4829711914062|  0:00:23s\n","epoch 27 | loss: 301.47195| val_0_mse: 448.78369140625|  0:00:24s\n","epoch 28 | loss: 291.67116| val_0_mse: 291.74090576171875|  0:00:25s\n","epoch 29 | loss: 289.96004| val_0_mse: 333.5435791015625|  0:00:26s\n","epoch 30 | loss: 272.44336| val_0_mse: 339.4134826660156|  0:00:26s\n","epoch 31 | loss: 275.81744| val_0_mse: 294.5068054199219|  0:00:27s\n","epoch 32 | loss: 266.71891| val_0_mse: 297.7350158691406|  0:00:28s\n","epoch 33 | loss: 262.25732| val_0_mse: 244.0364532470703|  0:00:29s\n","epoch 34 | loss: 242.26412| val_0_mse: 252.4610595703125|  0:00:30s\n","epoch 35 | loss: 240.65969| val_0_mse: 270.76300048828125|  0:00:30s\n","epoch 36 | loss: 237.07072| val_0_mse: 255.05361938476562|  0:00:31s\n","epoch 37 | loss: 232.16579| val_0_mse: 240.811767578125|  0:00:32s\n","epoch 38 | loss: 229.06963| val_0_mse: 236.2613525390625|  0:00:33s\n","epoch 39 | loss: 226.39699| val_0_mse: 237.56028747558594|  0:00:34s\n","epoch 40 | loss: 228.7859| val_0_mse: 239.533935546875|  0:00:35s\n","epoch 41 | loss: 223.80059| val_0_mse: 231.16140747070312|  0:00:35s\n","epoch 42 | loss: 232.23267| val_0_mse: 233.59678649902344|  0:00:36s\n","epoch 43 | loss: 223.6934| val_0_mse: 230.71556091308594|  0:00:37s\n","epoch 44 | loss: 213.90719| val_0_mse: 224.39349365234375|  0:00:38s\n","epoch 45 | loss: 219.14141| val_0_mse: 216.63467407226562|  0:00:39s\n","epoch 46 | loss: 216.00502| val_0_mse: 213.09335327148438|  0:00:40s\n","epoch 47 | loss: 213.12463| val_0_mse: 203.85028076171875|  0:00:40s\n","epoch 48 | loss: 202.8055| val_0_mse: 217.81065368652344|  0:00:41s\n","epoch 49 | loss: 211.85799| val_0_mse: 221.36512756347656|  0:00:42s\n","epoch 50 | loss: 218.42604| val_0_mse: 230.10598754882812|  0:00:43s\n","epoch 51 | loss: 218.02505| val_0_mse: 216.91445922851562|  0:00:44s\n","epoch 52 | loss: 211.9289| val_0_mse: 222.41009521484375|  0:00:45s\n","epoch 53 | loss: 201.26579| val_0_mse: 228.3560791015625|  0:00:46s\n","epoch 54 | loss: 199.41472| val_0_mse: 200.87991333007812|  0:00:47s\n","epoch 55 | loss: 201.4448| val_0_mse: 205.7358856201172|  0:00:47s\n","epoch 56 | loss: 203.38368| val_0_mse: 206.96624755859375|  0:00:48s\n","epoch 57 | loss: 206.58877| val_0_mse: 200.01458740234375|  0:00:49s\n","epoch 58 | loss: 200.98124| val_0_mse: 199.81724548339844|  0:00:50s\n","epoch 59 | loss: 202.51016| val_0_mse: 222.19674682617188|  0:00:51s\n","epoch 60 | loss: 206.13412| val_0_mse: 192.19212341308594|  0:00:52s\n","epoch 61 | loss: 204.79236| val_0_mse: 213.2545928955078|  0:00:52s\n","epoch 62 | loss: 206.36158| val_0_mse: 214.47775268554688|  0:00:53s\n","epoch 63 | loss: 189.56531| val_0_mse: 204.8005828857422|  0:00:54s\n","epoch 64 | loss: 198.96018| val_0_mse: 202.46255493164062|  0:00:55s\n","epoch 65 | loss: 184.54917| val_0_mse: 200.55209350585938|  0:00:56s\n","epoch 66 | loss: 188.29013| val_0_mse: 193.77456665039062|  0:00:56s\n","epoch 67 | loss: 193.42242| val_0_mse: 195.8108367919922|  0:00:57s\n","epoch 68 | loss: 194.34775| val_0_mse: 206.39561462402344|  0:00:58s\n","epoch 69 | loss: 191.14649| val_0_mse: 196.3907928466797|  0:00:59s\n","epoch 70 | loss: 182.11831| val_0_mse: 193.2942657470703|  0:01:00s\n","\n","Early stopping occurred at epoch 70 with best_epoch = 60 and best_val_0_mse = 192.19212341308594\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 15:02:12,485] Trial 54 finished with value: 192.19212341308594 and parameters: {'n_d': 63, 'n_steps': 4, 'gamma': 1.5361008723206908, 'n_independent': 3, 'n_shared': 4, 'momentum': 0.1617597364544843}. Best is trial 33 with value: 135.8055877685547.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 1612.66602| val_0_mse: 142021.015625|  0:00:00s\n","epoch 1  | loss: 428.84847| val_0_mse: 30052.869140625|  0:00:01s\n","epoch 2  | loss: 328.06711| val_0_mse: 13752.8828125|  0:00:02s\n","epoch 3  | loss: 303.30724| val_0_mse: 3727.171142578125|  0:00:02s\n","epoch 4  | loss: 290.26609| val_0_mse: 1085.2711181640625|  0:00:03s\n","epoch 5  | loss: 288.56899| val_0_mse: 1126.3880615234375|  0:00:04s\n","epoch 6  | loss: 265.22365| val_0_mse: 1376.0299072265625|  0:00:04s\n","epoch 7  | loss: 260.45905| val_0_mse: 1040.862548828125|  0:00:05s\n","epoch 8  | loss: 258.97016| val_0_mse: 879.8626098632812|  0:00:06s\n","epoch 9  | loss: 241.25063| val_0_mse: 1623.2041015625|  0:00:07s\n","epoch 10 | loss: 234.28243| val_0_mse: 708.1797485351562|  0:00:07s\n","epoch 11 | loss: 223.65935| val_0_mse: 2201.48876953125|  0:00:08s\n","epoch 12 | loss: 218.67188| val_0_mse: 1227.519775390625|  0:00:09s\n","epoch 13 | loss: 219.45044| val_0_mse: 1234.8013916015625|  0:00:10s\n","epoch 14 | loss: 219.77177| val_0_mse: 976.6669311523438|  0:00:10s\n","epoch 15 | loss: 219.97463| val_0_mse: 746.273193359375|  0:00:11s\n","epoch 16 | loss: 202.54267| val_0_mse: 902.6265869140625|  0:00:12s\n","epoch 17 | loss: 205.26938| val_0_mse: 952.29248046875|  0:00:12s\n","epoch 18 | loss: 210.87591| val_0_mse: 840.6864013671875|  0:00:13s\n","epoch 19 | loss: 204.57969| val_0_mse: 315.072998046875|  0:00:14s\n","epoch 20 | loss: 202.71187| val_0_mse: 262.0357360839844|  0:00:15s\n","epoch 21 | loss: 193.73765| val_0_mse: 300.8813171386719|  0:00:15s\n","epoch 22 | loss: 197.49808| val_0_mse: 392.0960693359375|  0:00:16s\n","epoch 23 | loss: 196.67327| val_0_mse: 284.4260559082031|  0:00:17s\n","epoch 24 | loss: 197.07279| val_0_mse: 292.34857177734375|  0:00:17s\n","epoch 25 | loss: 189.1488| val_0_mse: 269.8699645996094|  0:00:18s\n","epoch 26 | loss: 192.57232| val_0_mse: 247.27757263183594|  0:00:19s\n","epoch 27 | loss: 174.49275| val_0_mse: 245.8443603515625|  0:00:19s\n","epoch 28 | loss: 178.45561| val_0_mse: 214.7217254638672|  0:00:20s\n","epoch 29 | loss: 182.29839| val_0_mse: 224.93490600585938|  0:00:21s\n","epoch 30 | loss: 177.74933| val_0_mse: 278.6297607421875|  0:00:22s\n","epoch 31 | loss: 186.91775| val_0_mse: 203.1536865234375|  0:00:22s\n","epoch 32 | loss: 174.27818| val_0_mse: 236.6308135986328|  0:00:23s\n","epoch 33 | loss: 190.55862| val_0_mse: 189.87965393066406|  0:00:24s\n","epoch 34 | loss: 175.18338| val_0_mse: 185.05172729492188|  0:00:25s\n","epoch 35 | loss: 173.46565| val_0_mse: 186.14190673828125|  0:00:25s\n","epoch 36 | loss: 168.08103| val_0_mse: 173.39915466308594|  0:00:26s\n","epoch 37 | loss: 165.96751| val_0_mse: 191.53439331054688|  0:00:27s\n","epoch 38 | loss: 163.20886| val_0_mse: 166.6968231201172|  0:00:27s\n","epoch 39 | loss: 168.06549| val_0_mse: 223.6891326904297|  0:00:28s\n","epoch 40 | loss: 160.71427| val_0_mse: 165.26136779785156|  0:00:29s\n","epoch 41 | loss: 168.40873| val_0_mse: 178.23721313476562|  0:00:30s\n","epoch 42 | loss: 158.54372| val_0_mse: 229.85423278808594|  0:00:30s\n","epoch 43 | loss: 161.51502| val_0_mse: 164.66893005371094|  0:00:31s\n","epoch 44 | loss: 159.58087| val_0_mse: 188.2523651123047|  0:00:32s\n","epoch 45 | loss: 158.30802| val_0_mse: 175.43067932128906|  0:00:33s\n","epoch 46 | loss: 164.99816| val_0_mse: 217.60560607910156|  0:00:33s\n","epoch 47 | loss: 159.7754| val_0_mse: 218.14364624023438|  0:00:34s\n","epoch 48 | loss: 154.66965| val_0_mse: 169.33009338378906|  0:00:35s\n","epoch 49 | loss: 158.04933| val_0_mse: 183.0272674560547|  0:00:35s\n","epoch 50 | loss: 156.10367| val_0_mse: 165.77468872070312|  0:00:36s\n","epoch 51 | loss: 153.1284| val_0_mse: 182.66102600097656|  0:00:37s\n","epoch 52 | loss: 148.00541| val_0_mse: 153.08816528320312|  0:00:38s\n","epoch 53 | loss: 149.65246| val_0_mse: 166.368408203125|  0:00:38s\n","epoch 54 | loss: 149.14755| val_0_mse: 163.80250549316406|  0:00:39s\n","epoch 55 | loss: 144.07627| val_0_mse: 161.4010467529297|  0:00:40s\n","epoch 56 | loss: 137.76744| val_0_mse: 153.9447021484375|  0:00:40s\n","epoch 57 | loss: 145.59648| val_0_mse: 165.95632934570312|  0:00:41s\n","epoch 58 | loss: 142.705 | val_0_mse: 164.45339965820312|  0:00:42s\n","epoch 59 | loss: 136.59924| val_0_mse: 178.3917236328125|  0:00:43s\n","epoch 60 | loss: 140.06306| val_0_mse: 157.63319396972656|  0:00:43s\n","epoch 61 | loss: 139.86671| val_0_mse: 148.57852172851562|  0:00:44s\n","epoch 62 | loss: 141.77275| val_0_mse: 171.4157257080078|  0:00:45s\n","epoch 63 | loss: 138.30704| val_0_mse: 171.43923950195312|  0:00:45s\n","epoch 64 | loss: 142.89172| val_0_mse: 168.8959197998047|  0:00:46s\n","epoch 65 | loss: 141.70969| val_0_mse: 153.32220458984375|  0:00:47s\n","epoch 66 | loss: 145.35462| val_0_mse: 177.44871520996094|  0:00:47s\n","epoch 67 | loss: 144.86891| val_0_mse: 166.43421936035156|  0:00:48s\n","epoch 68 | loss: 142.22498| val_0_mse: 150.3198699951172|  0:00:49s\n","epoch 69 | loss: 133.35987| val_0_mse: 158.7528533935547|  0:00:49s\n","epoch 70 | loss: 134.75455| val_0_mse: 142.6813507080078|  0:00:50s\n","epoch 71 | loss: 134.24947| val_0_mse: 165.52577209472656|  0:00:51s\n","epoch 72 | loss: 137.04757| val_0_mse: 158.5890350341797|  0:00:52s\n","epoch 73 | loss: 134.3412| val_0_mse: 168.3995361328125|  0:00:52s\n","epoch 74 | loss: 132.58047| val_0_mse: 288.0721435546875|  0:00:53s\n","epoch 75 | loss: 131.03092| val_0_mse: 169.8613739013672|  0:00:54s\n","epoch 76 | loss: 128.23771| val_0_mse: 148.19125366210938|  0:00:54s\n","epoch 77 | loss: 137.93948| val_0_mse: 147.76889038085938|  0:00:55s\n","epoch 78 | loss: 130.45088| val_0_mse: 155.12844848632812|  0:00:56s\n","epoch 79 | loss: 130.18408| val_0_mse: 153.60105895996094|  0:00:56s\n","epoch 80 | loss: 130.42899| val_0_mse: 153.46795654296875|  0:00:57s\n","\n","Early stopping occurred at epoch 80 with best_epoch = 70 and best_val_0_mse = 142.6813507080078\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 15:03:10,530] Trial 55 finished with value: 142.6813507080078 and parameters: {'n_d': 64, 'n_steps': 3, 'gamma': 1.3791409760385551, 'n_independent': 3, 'n_shared': 4, 'momentum': 0.13149900015711885}. Best is trial 33 with value: 135.8055877685547.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 1576.84577| val_0_mse: 9785.97265625|  0:00:00s\n","epoch 1  | loss: 432.60357| val_0_mse: 10622.1904296875|  0:00:01s\n","epoch 2  | loss: 336.88571| val_0_mse: 18204.775390625|  0:00:02s\n","epoch 3  | loss: 306.4827| val_0_mse: 2906.650146484375|  0:00:02s\n","epoch 4  | loss: 275.82896| val_0_mse: 1091.886474609375|  0:00:03s\n","epoch 5  | loss: 277.11798| val_0_mse: 1200.0872802734375|  0:00:04s\n","epoch 6  | loss: 273.9679| val_0_mse: 686.4083862304688|  0:00:04s\n","epoch 7  | loss: 254.73582| val_0_mse: 668.8917846679688|  0:00:05s\n","epoch 8  | loss: 248.31798| val_0_mse: 1021.83837890625|  0:00:06s\n","epoch 9  | loss: 240.77615| val_0_mse: 764.9950561523438|  0:00:07s\n","epoch 10 | loss: 243.25913| val_0_mse: 879.0367431640625|  0:00:07s\n","epoch 11 | loss: 236.39855| val_0_mse: 688.2513427734375|  0:00:08s\n","epoch 12 | loss: 236.44245| val_0_mse: 620.7763671875|  0:00:09s\n","epoch 13 | loss: 236.87964| val_0_mse: 546.3390502929688|  0:00:09s\n","epoch 14 | loss: 237.99537| val_0_mse: 488.0997314453125|  0:00:10s\n","epoch 15 | loss: 230.81195| val_0_mse: 424.96514892578125|  0:00:11s\n","epoch 16 | loss: 212.09652| val_0_mse: 417.4131164550781|  0:00:12s\n","epoch 17 | loss: 216.928 | val_0_mse: 325.8172607421875|  0:00:12s\n","epoch 18 | loss: 214.36838| val_0_mse: 392.5172424316406|  0:00:13s\n","epoch 19 | loss: 217.75093| val_0_mse: 344.5087890625|  0:00:14s\n","epoch 20 | loss: 224.79805| val_0_mse: 323.5118408203125|  0:00:14s\n","epoch 21 | loss: 218.26531| val_0_mse: 342.8066101074219|  0:00:15s\n","epoch 22 | loss: 225.30728| val_0_mse: 364.42584228515625|  0:00:16s\n","epoch 23 | loss: 211.29649| val_0_mse: 268.363525390625|  0:00:16s\n","epoch 24 | loss: 205.49619| val_0_mse: 253.41937255859375|  0:00:17s\n","epoch 25 | loss: 202.33842| val_0_mse: 271.8278503417969|  0:00:18s\n","epoch 26 | loss: 205.36616| val_0_mse: 242.34002685546875|  0:00:18s\n","epoch 27 | loss: 192.78157| val_0_mse: 253.69412231445312|  0:00:19s\n","epoch 28 | loss: 192.90908| val_0_mse: 257.8719787597656|  0:00:20s\n","epoch 29 | loss: 193.90369| val_0_mse: 237.9032745361328|  0:00:21s\n","epoch 30 | loss: 194.31945| val_0_mse: 245.13551330566406|  0:00:21s\n","epoch 31 | loss: 197.24247| val_0_mse: 216.25694274902344|  0:00:22s\n","epoch 32 | loss: 186.97136| val_0_mse: 220.00718688964844|  0:00:23s\n","epoch 33 | loss: 191.01477| val_0_mse: 199.45846557617188|  0:00:23s\n","epoch 34 | loss: 182.51  | val_0_mse: 198.14248657226562|  0:00:24s\n","epoch 35 | loss: 187.00872| val_0_mse: 206.30441284179688|  0:00:25s\n","epoch 36 | loss: 181.38604| val_0_mse: 200.4504852294922|  0:00:25s\n","epoch 37 | loss: 174.05506| val_0_mse: 198.01898193359375|  0:00:26s\n","epoch 38 | loss: 172.40249| val_0_mse: 198.47410583496094|  0:00:27s\n","epoch 39 | loss: 175.47716| val_0_mse: 200.9197540283203|  0:00:27s\n","epoch 40 | loss: 170.63516| val_0_mse: 181.17784118652344|  0:00:28s\n","epoch 41 | loss: 173.15184| val_0_mse: 194.5770263671875|  0:00:29s\n","epoch 42 | loss: 171.94696| val_0_mse: 186.40623474121094|  0:00:30s\n","epoch 43 | loss: 166.78532| val_0_mse: 192.45895385742188|  0:00:30s\n","epoch 44 | loss: 165.64222| val_0_mse: 169.48414611816406|  0:00:31s\n","epoch 45 | loss: 164.68119| val_0_mse: 187.94883728027344|  0:00:32s\n","epoch 46 | loss: 172.63524| val_0_mse: 198.26686096191406|  0:00:33s\n","epoch 47 | loss: 172.36164| val_0_mse: 173.18734741210938|  0:00:33s\n","epoch 48 | loss: 163.35239| val_0_mse: 174.2582550048828|  0:00:34s\n","epoch 49 | loss: 162.66117| val_0_mse: 191.71910095214844|  0:00:35s\n","epoch 50 | loss: 165.34967| val_0_mse: 178.35072326660156|  0:00:35s\n","epoch 51 | loss: 160.60238| val_0_mse: 184.95994567871094|  0:00:36s\n","epoch 52 | loss: 158.47865| val_0_mse: 173.4457550048828|  0:00:37s\n","epoch 53 | loss: 162.03298| val_0_mse: 191.39993286132812|  0:00:37s\n","epoch 54 | loss: 162.09157| val_0_mse: 180.28207397460938|  0:00:38s\n","\n","Early stopping occurred at epoch 54 with best_epoch = 44 and best_val_0_mse = 169.48414611816406\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 15:03:49,515] Trial 56 finished with value: 169.484130859375 and parameters: {'n_d': 64, 'n_steps': 3, 'gamma': 1.3694954001894495, 'n_independent': 3, 'n_shared': 4, 'momentum': 0.1459834611681688}. Best is trial 33 with value: 135.8055877685547.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 1833.63231| val_0_mse: 25609.44921875|  0:00:00s\n","epoch 1  | loss: 634.01401| val_0_mse: 10532.0400390625|  0:00:01s\n","epoch 2  | loss: 463.79249| val_0_mse: 2583.73095703125|  0:00:02s\n","epoch 3  | loss: 382.45237| val_0_mse: 5265.87548828125|  0:00:03s\n","epoch 4  | loss: 376.3615| val_0_mse: 3478.7724609375|  0:00:04s\n","epoch 5  | loss: 346.75077| val_0_mse: 1442.5989990234375|  0:00:05s\n","epoch 6  | loss: 339.34099| val_0_mse: 2474.631103515625|  0:00:06s\n","epoch 7  | loss: 314.29468| val_0_mse: 761.0126953125|  0:00:06s\n","epoch 8  | loss: 312.6426| val_0_mse: 586.8489990234375|  0:00:07s\n","epoch 9  | loss: 301.22268| val_0_mse: 630.7649536132812|  0:00:08s\n","epoch 10 | loss: 282.56933| val_0_mse: 1212.413818359375|  0:00:09s\n","epoch 11 | loss: 284.64486| val_0_mse: 739.1819458007812|  0:00:10s\n","epoch 12 | loss: 265.58204| val_0_mse: 825.9955444335938|  0:00:11s\n","epoch 13 | loss: 256.90524| val_0_mse: 551.6355590820312|  0:00:12s\n","epoch 14 | loss: 261.04677| val_0_mse: 512.327880859375|  0:00:12s\n","epoch 15 | loss: 257.15808| val_0_mse: 479.14288330078125|  0:00:13s\n","epoch 16 | loss: 254.36954| val_0_mse: 567.68603515625|  0:00:14s\n","epoch 17 | loss: 240.88053| val_0_mse: 561.6041870117188|  0:00:15s\n","epoch 18 | loss: 225.43116| val_0_mse: 774.0734252929688|  0:00:16s\n","epoch 19 | loss: 215.50435| val_0_mse: 560.8812866210938|  0:00:17s\n","epoch 20 | loss: 224.20992| val_0_mse: 482.28692626953125|  0:00:17s\n","epoch 21 | loss: 228.71911| val_0_mse: 595.8526000976562|  0:00:18s\n","epoch 22 | loss: 223.67047| val_0_mse: 887.80810546875|  0:00:19s\n","epoch 23 | loss: 215.68387| val_0_mse: 447.45562744140625|  0:00:20s\n","epoch 24 | loss: 213.3182| val_0_mse: 469.3951721191406|  0:00:21s\n","epoch 25 | loss: 215.54345| val_0_mse: 342.7501220703125|  0:00:22s\n","epoch 26 | loss: 212.43325| val_0_mse: 265.6599426269531|  0:00:23s\n","epoch 27 | loss: 215.17087| val_0_mse: 371.49249267578125|  0:00:23s\n","epoch 28 | loss: 204.51355| val_0_mse: 353.5743103027344|  0:00:24s\n","epoch 29 | loss: 195.22094| val_0_mse: 374.6122741699219|  0:00:25s\n","epoch 30 | loss: 195.24632| val_0_mse: 364.6474304199219|  0:00:26s\n","epoch 31 | loss: 199.72824| val_0_mse: 256.9444580078125|  0:00:27s\n","epoch 32 | loss: 201.93807| val_0_mse: 199.22311401367188|  0:00:28s\n","epoch 33 | loss: 196.90287| val_0_mse: 322.4654846191406|  0:00:29s\n","epoch 34 | loss: 195.36597| val_0_mse: 227.77630615234375|  0:00:30s\n","epoch 35 | loss: 189.3464| val_0_mse: 222.31451416015625|  0:00:30s\n","epoch 36 | loss: 190.24586| val_0_mse: 231.3705596923828|  0:00:31s\n","epoch 37 | loss: 188.85093| val_0_mse: 225.9588623046875|  0:00:32s\n","epoch 38 | loss: 189.47429| val_0_mse: 206.10069274902344|  0:00:33s\n","epoch 39 | loss: 191.83048| val_0_mse: 220.84356689453125|  0:00:34s\n","epoch 40 | loss: 192.25416| val_0_mse: 196.1920928955078|  0:00:35s\n","epoch 41 | loss: 182.53173| val_0_mse: 184.0502471923828|  0:00:35s\n","epoch 42 | loss: 183.56928| val_0_mse: 220.6860809326172|  0:00:36s\n","epoch 43 | loss: 185.20635| val_0_mse: 221.4904022216797|  0:00:37s\n","epoch 44 | loss: 192.81632| val_0_mse: 190.16958618164062|  0:00:38s\n","epoch 45 | loss: 185.92606| val_0_mse: 200.4137725830078|  0:00:39s\n","epoch 46 | loss: 184.1392| val_0_mse: 195.07003784179688|  0:00:40s\n","epoch 47 | loss: 183.06016| val_0_mse: 198.49093627929688|  0:00:40s\n","epoch 48 | loss: 189.89853| val_0_mse: 219.50396728515625|  0:00:41s\n","epoch 49 | loss: 184.42367| val_0_mse: 181.59820556640625|  0:00:42s\n","epoch 50 | loss: 178.41552| val_0_mse: 220.0453338623047|  0:00:43s\n","epoch 51 | loss: 175.12694| val_0_mse: 249.04937744140625|  0:00:44s\n","epoch 52 | loss: 172.71072| val_0_mse: 180.9886932373047|  0:00:45s\n","epoch 53 | loss: 179.52682| val_0_mse: 184.66937255859375|  0:00:46s\n","epoch 54 | loss: 179.19633| val_0_mse: 180.4150390625|  0:00:46s\n","epoch 55 | loss: 174.01977| val_0_mse: 178.39285278320312|  0:00:47s\n","epoch 56 | loss: 171.08255| val_0_mse: 189.89450073242188|  0:00:48s\n","epoch 57 | loss: 175.85521| val_0_mse: 239.98849487304688|  0:00:49s\n","epoch 58 | loss: 177.00306| val_0_mse: 206.25250244140625|  0:00:50s\n","epoch 59 | loss: 172.20285| val_0_mse: 191.12840270996094|  0:00:51s\n","epoch 60 | loss: 162.08508| val_0_mse: 182.77999877929688|  0:00:52s\n","epoch 61 | loss: 160.56491| val_0_mse: 165.62181091308594|  0:00:52s\n","epoch 62 | loss: 161.27357| val_0_mse: 191.58547973632812|  0:00:53s\n","epoch 63 | loss: 159.71989| val_0_mse: 208.63807678222656|  0:00:54s\n","epoch 64 | loss: 162.09116| val_0_mse: 180.25534057617188|  0:00:55s\n","epoch 65 | loss: 155.44159| val_0_mse: 167.41452026367188|  0:00:56s\n","epoch 66 | loss: 158.2605| val_0_mse: 177.62278747558594|  0:00:57s\n","epoch 67 | loss: 161.03609| val_0_mse: 171.02291870117188|  0:00:57s\n","epoch 68 | loss: 165.58887| val_0_mse: 171.5165252685547|  0:00:58s\n","epoch 69 | loss: 160.10156| val_0_mse: 166.78509521484375|  0:00:59s\n","epoch 70 | loss: 158.4736| val_0_mse: 197.9139862060547|  0:01:00s\n","epoch 71 | loss: 165.38343| val_0_mse: 171.86314392089844|  0:01:01s\n","\n","Early stopping occurred at epoch 71 with best_epoch = 61 and best_val_0_mse = 165.62181091308594\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 15:04:51,185] Trial 57 finished with value: 165.62181091308594 and parameters: {'n_d': 59, 'n_steps': 4, 'gamma': 1.4446733424949505, 'n_independent': 2, 'n_shared': 5, 'momentum': 0.0963289287852857}. Best is trial 33 with value: 135.8055877685547.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 1553.46175| val_0_mse: 20332.2578125|  0:00:00s\n","epoch 1  | loss: 457.88555| val_0_mse: 3050.443115234375|  0:00:01s\n","epoch 2  | loss: 388.86427| val_0_mse: 1874.775146484375|  0:00:02s\n","epoch 3  | loss: 326.1803| val_0_mse: 3602.054443359375|  0:00:02s\n","epoch 4  | loss: 292.82743| val_0_mse: 7784.482421875|  0:00:03s\n","epoch 5  | loss: 291.88027| val_0_mse: 3555.989013671875|  0:00:04s\n","epoch 6  | loss: 275.80379| val_0_mse: 2458.23486328125|  0:00:04s\n","epoch 7  | loss: 267.2039| val_0_mse: 1583.445556640625|  0:00:05s\n","epoch 8  | loss: 255.37116| val_0_mse: 1044.513427734375|  0:00:06s\n","epoch 9  | loss: 244.95342| val_0_mse: 830.7669677734375|  0:00:06s\n","epoch 10 | loss: 239.59493| val_0_mse: 1022.4214477539062|  0:00:07s\n","epoch 11 | loss: 235.82575| val_0_mse: 520.8998413085938|  0:00:08s\n","epoch 12 | loss: 238.92371| val_0_mse: 532.16943359375|  0:00:08s\n","epoch 13 | loss: 225.85844| val_0_mse: 638.3136596679688|  0:00:09s\n","epoch 14 | loss: 213.1585| val_0_mse: 548.3019409179688|  0:00:10s\n","epoch 15 | loss: 222.21042| val_0_mse: 539.8866577148438|  0:00:10s\n","epoch 16 | loss: 211.17045| val_0_mse: 418.8280334472656|  0:00:11s\n","epoch 17 | loss: 202.0932| val_0_mse: 401.8428039550781|  0:00:12s\n","epoch 18 | loss: 204.24947| val_0_mse: 363.0179138183594|  0:00:12s\n","epoch 19 | loss: 200.03784| val_0_mse: 405.86627197265625|  0:00:13s\n","epoch 20 | loss: 205.2347| val_0_mse: 284.4366455078125|  0:00:14s\n","epoch 21 | loss: 196.11443| val_0_mse: 281.5567321777344|  0:00:15s\n","epoch 22 | loss: 188.97434| val_0_mse: 307.8316650390625|  0:00:15s\n","epoch 23 | loss: 187.57476| val_0_mse: 256.0980224609375|  0:00:16s\n","epoch 24 | loss: 197.10282| val_0_mse: 252.067626953125|  0:00:17s\n","epoch 25 | loss: 187.53633| val_0_mse: 263.25506591796875|  0:00:17s\n","epoch 26 | loss: 185.50801| val_0_mse: 226.49215698242188|  0:00:18s\n","epoch 27 | loss: 188.17107| val_0_mse: 244.3829345703125|  0:00:19s\n","epoch 28 | loss: 184.68434| val_0_mse: 254.79025268554688|  0:00:19s\n","epoch 29 | loss: 186.9156| val_0_mse: 238.43222045898438|  0:00:20s\n","epoch 30 | loss: 179.35411| val_0_mse: 206.28671264648438|  0:00:21s\n","epoch 31 | loss: 173.21142| val_0_mse: 247.75656127929688|  0:00:21s\n","epoch 32 | loss: 173.97562| val_0_mse: 221.08505249023438|  0:00:22s\n","epoch 33 | loss: 179.73279| val_0_mse: 218.02076721191406|  0:00:23s\n","epoch 34 | loss: 180.0157| val_0_mse: 226.58816528320312|  0:00:24s\n","epoch 35 | loss: 174.13774| val_0_mse: 189.5491943359375|  0:00:24s\n","epoch 36 | loss: 171.03605| val_0_mse: 196.31170654296875|  0:00:25s\n","epoch 37 | loss: 169.44077| val_0_mse: 188.99905395507812|  0:00:26s\n","epoch 38 | loss: 170.43126| val_0_mse: 197.72787475585938|  0:00:26s\n","epoch 39 | loss: 164.88715| val_0_mse: 191.74130249023438|  0:00:27s\n","epoch 40 | loss: 161.81447| val_0_mse: 174.6536865234375|  0:00:28s\n","epoch 41 | loss: 169.04399| val_0_mse: 203.7982177734375|  0:00:28s\n","epoch 42 | loss: 161.89868| val_0_mse: 176.8185272216797|  0:00:29s\n","epoch 43 | loss: 169.9223| val_0_mse: 181.7430419921875|  0:00:30s\n","epoch 44 | loss: 175.11581| val_0_mse: 182.53729248046875|  0:00:31s\n","epoch 45 | loss: 165.3177| val_0_mse: 175.1620330810547|  0:00:31s\n","epoch 46 | loss: 168.79332| val_0_mse: 185.00062561035156|  0:00:32s\n","epoch 47 | loss: 167.18053| val_0_mse: 172.44830322265625|  0:00:33s\n","epoch 48 | loss: 164.99385| val_0_mse: 179.02427673339844|  0:00:33s\n","epoch 49 | loss: 161.21753| val_0_mse: 191.4984130859375|  0:00:34s\n","epoch 50 | loss: 159.30937| val_0_mse: 179.18243408203125|  0:00:35s\n","epoch 51 | loss: 155.18276| val_0_mse: 162.30239868164062|  0:00:35s\n","epoch 52 | loss: 157.25102| val_0_mse: 169.48431396484375|  0:00:36s\n","epoch 53 | loss: 161.38214| val_0_mse: 172.9271240234375|  0:00:37s\n","epoch 54 | loss: 157.88382| val_0_mse: 172.7377166748047|  0:00:37s\n","epoch 55 | loss: 154.883 | val_0_mse: 163.96624755859375|  0:00:38s\n","epoch 56 | loss: 148.34291| val_0_mse: 176.976318359375|  0:00:39s\n","epoch 57 | loss: 152.49148| val_0_mse: 165.93482971191406|  0:00:40s\n","epoch 58 | loss: 146.84919| val_0_mse: 154.8992919921875|  0:00:40s\n","epoch 59 | loss: 144.80108| val_0_mse: 161.4542999267578|  0:00:41s\n","epoch 60 | loss: 150.38469| val_0_mse: 199.00909423828125|  0:00:42s\n","epoch 61 | loss: 151.85385| val_0_mse: 166.42771911621094|  0:00:42s\n","epoch 62 | loss: 140.76649| val_0_mse: 193.1269989013672|  0:00:43s\n","epoch 63 | loss: 142.93641| val_0_mse: 155.9684600830078|  0:00:44s\n","epoch 64 | loss: 143.33198| val_0_mse: 159.50103759765625|  0:00:44s\n","epoch 65 | loss: 141.43577| val_0_mse: 178.48919677734375|  0:00:45s\n","epoch 66 | loss: 148.46235| val_0_mse: 162.46864318847656|  0:00:46s\n","epoch 67 | loss: 142.16511| val_0_mse: 159.17385864257812|  0:00:47s\n","epoch 68 | loss: 138.34876| val_0_mse: 155.30433654785156|  0:00:47s\n","\n","Early stopping occurred at epoch 68 with best_epoch = 58 and best_val_0_mse = 154.8992919921875\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 15:05:39,462] Trial 58 finished with value: 154.8992919921875 and parameters: {'n_d': 61, 'n_steps': 3, 'gamma': 1.2437356269989879, 'n_independent': 3, 'n_shared': 4, 'momentum': 0.1755408133154462}. Best is trial 33 with value: 135.8055877685547.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 1625.67042| val_0_mse: 10308.23046875|  0:00:00s\n","epoch 1  | loss: 613.07718| val_0_mse: 4077.824951171875|  0:00:01s\n","epoch 2  | loss: 504.8271| val_0_mse: 1756.4100341796875|  0:00:02s\n","epoch 3  | loss: 434.32369| val_0_mse: 1455.59326171875|  0:00:03s\n","epoch 4  | loss: 382.44157| val_0_mse: 5340.94140625|  0:00:03s\n","epoch 5  | loss: 371.43571| val_0_mse: 2510.347900390625|  0:00:04s\n","epoch 6  | loss: 343.42264| val_0_mse: 2692.016845703125|  0:00:05s\n","epoch 7  | loss: 309.61912| val_0_mse: 3772.846923828125|  0:00:05s\n","epoch 8  | loss: 295.69595| val_0_mse: 3961.901123046875|  0:00:06s\n","epoch 9  | loss: 272.38107| val_0_mse: 6473.21875|  0:00:07s\n","epoch 10 | loss: 272.34522| val_0_mse: 8283.1015625|  0:00:08s\n","epoch 11 | loss: 275.59318| val_0_mse: 3551.74072265625|  0:00:08s\n","epoch 12 | loss: 273.57974| val_0_mse: 2482.403564453125|  0:00:09s\n","epoch 13 | loss: 254.78307| val_0_mse: 1338.8804931640625|  0:00:10s\n","epoch 14 | loss: 246.76192| val_0_mse: 1214.032958984375|  0:00:11s\n","epoch 15 | loss: 240.56206| val_0_mse: 775.3395385742188|  0:00:11s\n","epoch 16 | loss: 237.9876| val_0_mse: 595.2037963867188|  0:00:12s\n","epoch 17 | loss: 242.52059| val_0_mse: 619.3558959960938|  0:00:13s\n","epoch 18 | loss: 230.9082| val_0_mse: 427.709228515625|  0:00:14s\n","epoch 19 | loss: 243.56866| val_0_mse: 526.552978515625|  0:00:15s\n","epoch 20 | loss: 242.82752| val_0_mse: 573.7557983398438|  0:00:15s\n","epoch 21 | loss: 243.4564| val_0_mse: 411.779052734375|  0:00:16s\n","epoch 22 | loss: 233.38872| val_0_mse: 429.9228515625|  0:00:17s\n","epoch 23 | loss: 223.0529| val_0_mse: 411.8411560058594|  0:00:17s\n","epoch 24 | loss: 219.28725| val_0_mse: 394.24371337890625|  0:00:18s\n","epoch 25 | loss: 217.67988| val_0_mse: 294.2357177734375|  0:00:19s\n","epoch 26 | loss: 206.67208| val_0_mse: 393.26312255859375|  0:00:20s\n","epoch 27 | loss: 215.28458| val_0_mse: 307.2115783691406|  0:00:21s\n","epoch 28 | loss: 214.62193| val_0_mse: 250.9893035888672|  0:00:21s\n","epoch 29 | loss: 204.13212| val_0_mse: 243.78756713867188|  0:00:22s\n","epoch 30 | loss: 205.49195| val_0_mse: 269.4294128417969|  0:00:23s\n","epoch 31 | loss: 209.39898| val_0_mse: 242.11575317382812|  0:00:24s\n","epoch 32 | loss: 222.10991| val_0_mse: 207.2022247314453|  0:00:24s\n","epoch 33 | loss: 203.92826| val_0_mse: 221.96270751953125|  0:00:25s\n","epoch 34 | loss: 205.0677| val_0_mse: 211.43130493164062|  0:00:26s\n","epoch 35 | loss: 200.35313| val_0_mse: 219.43402099609375|  0:00:27s\n","epoch 36 | loss: 197.31655| val_0_mse: 231.06655883789062|  0:00:27s\n","epoch 37 | loss: 192.80834| val_0_mse: 210.05665588378906|  0:00:28s\n","epoch 38 | loss: 190.56345| val_0_mse: 195.68739318847656|  0:00:29s\n","epoch 39 | loss: 196.14448| val_0_mse: 195.59165954589844|  0:00:30s\n","epoch 40 | loss: 186.05792| val_0_mse: 186.4346466064453|  0:00:30s\n","epoch 41 | loss: 183.8046| val_0_mse: 209.84463500976562|  0:00:31s\n","epoch 42 | loss: 192.07709| val_0_mse: 195.96629333496094|  0:00:32s\n","epoch 43 | loss: 194.24607| val_0_mse: 203.6002197265625|  0:00:33s\n","epoch 44 | loss: 194.45061| val_0_mse: 196.56222534179688|  0:00:34s\n","epoch 45 | loss: 183.69224| val_0_mse: 185.79063415527344|  0:00:34s\n","epoch 46 | loss: 183.20307| val_0_mse: 202.50326538085938|  0:00:35s\n","epoch 47 | loss: 187.33809| val_0_mse: 198.1343536376953|  0:00:36s\n","epoch 48 | loss: 179.02488| val_0_mse: 198.4905242919922|  0:00:36s\n","epoch 49 | loss: 175.03174| val_0_mse: 191.73997497558594|  0:00:37s\n","epoch 50 | loss: 183.75384| val_0_mse: 187.202392578125|  0:00:38s\n","epoch 51 | loss: 183.07512| val_0_mse: 182.30447387695312|  0:00:39s\n","epoch 52 | loss: 181.2993| val_0_mse: 181.0821533203125|  0:00:39s\n","epoch 53 | loss: 174.43623| val_0_mse: 210.46792602539062|  0:00:40s\n","epoch 54 | loss: 175.37133| val_0_mse: 195.76150512695312|  0:00:41s\n","epoch 55 | loss: 172.25663| val_0_mse: 195.2220001220703|  0:00:42s\n","epoch 56 | loss: 184.7745| val_0_mse: 194.13223266601562|  0:00:42s\n","epoch 57 | loss: 169.14742| val_0_mse: 197.4597930908203|  0:00:43s\n","epoch 58 | loss: 178.51165| val_0_mse: 193.06321716308594|  0:00:44s\n","epoch 59 | loss: 184.67503| val_0_mse: 192.17913818359375|  0:00:45s\n","epoch 60 | loss: 181.87298| val_0_mse: 196.51626586914062|  0:00:45s\n","epoch 61 | loss: 180.6501| val_0_mse: 202.4680633544922|  0:00:46s\n","epoch 62 | loss: 173.35239| val_0_mse: 186.3326416015625|  0:00:47s\n","\n","Early stopping occurred at epoch 62 with best_epoch = 52 and best_val_0_mse = 181.0821533203125\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 15:06:27,399] Trial 59 finished with value: 181.0821533203125 and parameters: {'n_d': 53, 'n_steps': 4, 'gamma': 1.3887676394587425, 'n_independent': 4, 'n_shared': 2, 'momentum': 0.12609376692483887}. Best is trial 33 with value: 135.8055877685547.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 1568.27304| val_0_mse: 9442.890625|  0:00:00s\n","epoch 1  | loss: 499.13181| val_0_mse: 8870.8857421875|  0:00:01s\n","epoch 2  | loss: 383.65609| val_0_mse: 2377.89501953125|  0:00:01s\n","epoch 3  | loss: 334.36022| val_0_mse: 9188.439453125|  0:00:02s\n","epoch 4  | loss: 302.71855| val_0_mse: 8135.8271484375|  0:00:03s\n","epoch 5  | loss: 288.8379| val_0_mse: 16576.5703125|  0:00:03s\n","epoch 6  | loss: 279.3534| val_0_mse: 3934.29931640625|  0:00:04s\n","epoch 7  | loss: 268.96617| val_0_mse: 4736.46435546875|  0:00:05s\n","epoch 8  | loss: 261.84173| val_0_mse: 5710.0322265625|  0:00:05s\n","epoch 9  | loss: 245.74633| val_0_mse: 4976.77197265625|  0:00:06s\n","epoch 10 | loss: 242.77356| val_0_mse: 5245.55224609375|  0:00:06s\n","epoch 11 | loss: 247.50428| val_0_mse: 3045.6630859375|  0:00:07s\n","epoch 12 | loss: 232.94488| val_0_mse: 3070.888427734375|  0:00:08s\n","\n","Early stopping occurred at epoch 12 with best_epoch = 2 and best_val_0_mse = 2377.89501953125\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 15:06:35,980] Trial 60 finished with value: 2377.89501953125 and parameters: {'n_d': 58, 'n_steps': 3, 'gamma': 1.3284650908910662, 'n_independent': 3, 'n_shared': 3, 'momentum': 0.05006619801291756}. Best is trial 33 with value: 135.8055877685547.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 1608.32697| val_0_mse: 100269.5078125|  0:00:00s\n","epoch 1  | loss: 452.86616| val_0_mse: 2769.040283203125|  0:00:01s\n","epoch 2  | loss: 358.98971| val_0_mse: 1262.7021484375|  0:00:02s\n","epoch 3  | loss: 312.80874| val_0_mse: 626.0208740234375|  0:00:02s\n","epoch 4  | loss: 286.48652| val_0_mse: 556.66015625|  0:00:03s\n","epoch 5  | loss: 263.23415| val_0_mse: 608.8114013671875|  0:00:04s\n","epoch 6  | loss: 252.95444| val_0_mse: 597.0153198242188|  0:00:04s\n","epoch 7  | loss: 256.37091| val_0_mse: 498.7049560546875|  0:00:05s\n","epoch 8  | loss: 250.02257| val_0_mse: 793.3619995117188|  0:00:06s\n","epoch 9  | loss: 247.78243| val_0_mse: 988.5371704101562|  0:00:06s\n","epoch 10 | loss: 244.29765| val_0_mse: 889.877685546875|  0:00:07s\n","epoch 11 | loss: 232.4945| val_0_mse: 796.1521606445312|  0:00:08s\n","epoch 12 | loss: 230.24488| val_0_mse: 1090.382568359375|  0:00:08s\n","epoch 13 | loss: 212.56553| val_0_mse: 815.0331420898438|  0:00:09s\n","epoch 14 | loss: 213.65804| val_0_mse: 1026.3765869140625|  0:00:10s\n","epoch 15 | loss: 216.11535| val_0_mse: 444.7633972167969|  0:00:11s\n","epoch 16 | loss: 208.30203| val_0_mse: 402.2378845214844|  0:00:11s\n","epoch 17 | loss: 216.83009| val_0_mse: 503.445068359375|  0:00:12s\n","epoch 18 | loss: 209.40045| val_0_mse: 478.1815490722656|  0:00:13s\n","epoch 19 | loss: 207.08875| val_0_mse: 550.101806640625|  0:00:13s\n","epoch 20 | loss: 206.60601| val_0_mse: 366.213134765625|  0:00:14s\n","epoch 21 | loss: 201.79028| val_0_mse: 321.99688720703125|  0:00:15s\n","epoch 22 | loss: 201.57012| val_0_mse: 344.78485107421875|  0:00:16s\n","epoch 23 | loss: 195.89474| val_0_mse: 275.81268310546875|  0:00:16s\n","epoch 24 | loss: 194.75191| val_0_mse: 310.8182067871094|  0:00:17s\n","epoch 25 | loss: 194.37329| val_0_mse: 265.6820373535156|  0:00:18s\n","epoch 26 | loss: 206.28326| val_0_mse: 218.06216430664062|  0:00:18s\n","epoch 27 | loss: 203.13752| val_0_mse: 239.52613830566406|  0:00:19s\n","epoch 28 | loss: 208.87094| val_0_mse: 272.215576171875|  0:00:20s\n","epoch 29 | loss: 203.12501| val_0_mse: 263.3784484863281|  0:00:20s\n","epoch 30 | loss: 209.02975| val_0_mse: 220.91720581054688|  0:00:21s\n","epoch 31 | loss: 198.88766| val_0_mse: 239.98577880859375|  0:00:22s\n","epoch 32 | loss: 189.35598| val_0_mse: 206.311279296875|  0:00:22s\n","epoch 33 | loss: 193.97595| val_0_mse: 238.36279296875|  0:00:23s\n","epoch 34 | loss: 185.37661| val_0_mse: 211.4132843017578|  0:00:24s\n","epoch 35 | loss: 188.70194| val_0_mse: 220.33447265625|  0:00:24s\n","epoch 36 | loss: 184.69353| val_0_mse: 187.9647979736328|  0:00:25s\n","epoch 37 | loss: 182.64357| val_0_mse: 204.33949279785156|  0:00:26s\n","epoch 38 | loss: 185.15212| val_0_mse: 208.90924072265625|  0:00:27s\n","epoch 39 | loss: 185.9252| val_0_mse: 205.2416534423828|  0:00:27s\n","epoch 40 | loss: 179.44376| val_0_mse: 186.7675018310547|  0:00:28s\n","epoch 41 | loss: 177.66845| val_0_mse: 198.02488708496094|  0:00:29s\n","epoch 42 | loss: 175.64828| val_0_mse: 200.24830627441406|  0:00:29s\n","epoch 43 | loss: 179.34519| val_0_mse: 185.2055206298828|  0:00:30s\n","epoch 44 | loss: 173.86292| val_0_mse: 182.82591247558594|  0:00:31s\n","epoch 45 | loss: 177.21972| val_0_mse: 188.7922821044922|  0:00:31s\n","epoch 46 | loss: 175.44568| val_0_mse: 176.51954650878906|  0:00:32s\n","epoch 47 | loss: 171.06845| val_0_mse: 169.41998291015625|  0:00:33s\n","epoch 48 | loss: 178.40838| val_0_mse: 176.910400390625|  0:00:33s\n","epoch 49 | loss: 169.75641| val_0_mse: 207.43649291992188|  0:00:34s\n","epoch 50 | loss: 173.30389| val_0_mse: 181.80662536621094|  0:00:35s\n","epoch 51 | loss: 175.5381| val_0_mse: 192.6179656982422|  0:00:35s\n","epoch 52 | loss: 170.89497| val_0_mse: 170.7790069580078|  0:00:36s\n","epoch 53 | loss: 166.50478| val_0_mse: 199.1704559326172|  0:00:37s\n","epoch 54 | loss: 168.57018| val_0_mse: 178.1645965576172|  0:00:37s\n","epoch 55 | loss: 156.02829| val_0_mse: 174.5067138671875|  0:00:38s\n","epoch 56 | loss: 158.97983| val_0_mse: 195.42889404296875|  0:00:39s\n","epoch 57 | loss: 159.40146| val_0_mse: 165.6446533203125|  0:00:39s\n","epoch 58 | loss: 163.6231| val_0_mse: 185.99844360351562|  0:00:40s\n","epoch 59 | loss: 167.48746| val_0_mse: 169.2183074951172|  0:00:41s\n","epoch 60 | loss: 155.06848| val_0_mse: 165.70896911621094|  0:00:42s\n","epoch 61 | loss: 163.27016| val_0_mse: 172.374267578125|  0:00:42s\n","epoch 62 | loss: 156.52331| val_0_mse: 162.87599182128906|  0:00:43s\n","epoch 63 | loss: 159.19835| val_0_mse: 175.0651397705078|  0:00:44s\n","epoch 64 | loss: 166.69214| val_0_mse: 206.7241668701172|  0:00:44s\n","epoch 65 | loss: 166.57292| val_0_mse: 162.96047973632812|  0:00:45s\n","epoch 66 | loss: 151.42216| val_0_mse: 198.76461791992188|  0:00:46s\n","epoch 67 | loss: 153.39469| val_0_mse: 160.47055053710938|  0:00:47s\n","epoch 68 | loss: 155.59082| val_0_mse: 168.94854736328125|  0:00:47s\n","epoch 69 | loss: 146.57311| val_0_mse: 187.3309326171875|  0:00:48s\n","epoch 70 | loss: 157.31927| val_0_mse: 173.79498291015625|  0:00:49s\n","epoch 71 | loss: 152.28919| val_0_mse: 163.7564697265625|  0:00:49s\n","epoch 72 | loss: 151.0563| val_0_mse: 159.233642578125|  0:00:50s\n","epoch 73 | loss: 150.93207| val_0_mse: 176.0796356201172|  0:00:51s\n","epoch 74 | loss: 156.31232| val_0_mse: 155.67828369140625|  0:00:51s\n","epoch 75 | loss: 147.64462| val_0_mse: 160.90260314941406|  0:00:52s\n","epoch 76 | loss: 141.48398| val_0_mse: 175.51400756835938|  0:00:53s\n","epoch 77 | loss: 153.70702| val_0_mse: 170.62860107421875|  0:00:53s\n","epoch 78 | loss: 143.62863| val_0_mse: 157.00155639648438|  0:00:54s\n","epoch 79 | loss: 146.68995| val_0_mse: 159.04055786132812|  0:00:55s\n","epoch 80 | loss: 145.20881| val_0_mse: 159.6639404296875|  0:00:55s\n","epoch 81 | loss: 150.64695| val_0_mse: 152.84298706054688|  0:00:56s\n","epoch 82 | loss: 145.16922| val_0_mse: 173.40875244140625|  0:00:57s\n","epoch 83 | loss: 134.8174| val_0_mse: 155.82826232910156|  0:00:57s\n","epoch 84 | loss: 140.66504| val_0_mse: 154.6173553466797|  0:00:58s\n","epoch 85 | loss: 143.3271| val_0_mse: 155.76329040527344|  0:00:59s\n","epoch 86 | loss: 138.96163| val_0_mse: 169.94125366210938|  0:01:00s\n","epoch 87 | loss: 142.61202| val_0_mse: 160.70339965820312|  0:01:00s\n","epoch 88 | loss: 136.43728| val_0_mse: 148.87294006347656|  0:01:01s\n","epoch 89 | loss: 144.82219| val_0_mse: 159.35971069335938|  0:01:02s\n","epoch 90 | loss: 145.68986| val_0_mse: 162.97657775878906|  0:01:02s\n","epoch 91 | loss: 138.30981| val_0_mse: 157.81138610839844|  0:01:03s\n","epoch 92 | loss: 131.56651| val_0_mse: 144.34263610839844|  0:01:04s\n","epoch 93 | loss: 129.42515| val_0_mse: 160.6127166748047|  0:01:04s\n","epoch 94 | loss: 131.13037| val_0_mse: 142.6671600341797|  0:01:05s\n","epoch 95 | loss: 130.11889| val_0_mse: 157.7886199951172|  0:01:06s\n","epoch 96 | loss: 134.36943| val_0_mse: 156.19345092773438|  0:01:06s\n","epoch 97 | loss: 131.16203| val_0_mse: 158.06517028808594|  0:01:07s\n","epoch 98 | loss: 127.96513| val_0_mse: 167.1825714111328|  0:01:08s\n","epoch 99 | loss: 134.4712| val_0_mse: 150.53659057617188|  0:01:09s\n","Stop training because you reached max_epochs = 100 with best_epoch = 94 and best_val_0_mse = 142.6671600341797\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 15:07:45,620] Trial 61 finished with value: 142.6671600341797 and parameters: {'n_d': 62, 'n_steps': 3, 'gamma': 1.5030760077851426, 'n_independent': 3, 'n_shared': 4, 'momentum': 0.13407738495307286}. Best is trial 33 with value: 135.8055877685547.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 1558.63101| val_0_mse: 20645.92578125|  0:00:00s\n","epoch 1  | loss: 457.19651| val_0_mse: 3403.53955078125|  0:00:01s\n","epoch 2  | loss: 363.64363| val_0_mse: 4226.318359375|  0:00:02s\n","epoch 3  | loss: 339.85535| val_0_mse: 3333.837646484375|  0:00:02s\n","epoch 4  | loss: 317.99176| val_0_mse: 924.9110107421875|  0:00:03s\n","epoch 5  | loss: 297.44024| val_0_mse: 1404.875732421875|  0:00:04s\n","epoch 6  | loss: 276.99642| val_0_mse: 1866.883056640625|  0:00:04s\n","epoch 7  | loss: 275.64886| val_0_mse: 2066.865234375|  0:00:05s\n","epoch 8  | loss: 272.59251| val_0_mse: 1252.719970703125|  0:00:06s\n","epoch 9  | loss: 262.79007| val_0_mse: 1707.577880859375|  0:00:06s\n","epoch 10 | loss: 261.82668| val_0_mse: 1246.0926513671875|  0:00:07s\n","epoch 11 | loss: 240.67799| val_0_mse: 993.4283447265625|  0:00:08s\n","epoch 12 | loss: 240.52777| val_0_mse: 1073.9903564453125|  0:00:08s\n","epoch 13 | loss: 227.78432| val_0_mse: 884.237060546875|  0:00:09s\n","epoch 14 | loss: 234.26188| val_0_mse: 977.934814453125|  0:00:10s\n","epoch 15 | loss: 219.69397| val_0_mse: 530.2490844726562|  0:00:11s\n","epoch 16 | loss: 215.15303| val_0_mse: 353.0435485839844|  0:00:11s\n","epoch 17 | loss: 215.07273| val_0_mse: 433.8699951171875|  0:00:12s\n","epoch 18 | loss: 206.74027| val_0_mse: 389.0097961425781|  0:00:13s\n","epoch 19 | loss: 200.44363| val_0_mse: 261.2170715332031|  0:00:13s\n","epoch 20 | loss: 201.8744| val_0_mse: 266.7362976074219|  0:00:14s\n","epoch 21 | loss: 194.57017| val_0_mse: 395.9576110839844|  0:00:15s\n","epoch 22 | loss: 197.0724| val_0_mse: 276.17724609375|  0:00:15s\n","epoch 23 | loss: 190.58062| val_0_mse: 259.59259033203125|  0:00:16s\n","epoch 24 | loss: 187.88254| val_0_mse: 275.53314208984375|  0:00:17s\n","epoch 25 | loss: 180.73873| val_0_mse: 209.17373657226562|  0:00:17s\n","epoch 26 | loss: 179.79131| val_0_mse: 228.9436798095703|  0:00:18s\n","epoch 27 | loss: 177.98171| val_0_mse: 234.6866455078125|  0:00:19s\n","epoch 28 | loss: 180.1173| val_0_mse: 283.52081298828125|  0:00:20s\n","epoch 29 | loss: 178.89221| val_0_mse: 204.73983764648438|  0:00:20s\n","epoch 30 | loss: 173.4025| val_0_mse: 190.828857421875|  0:00:21s\n","epoch 31 | loss: 181.91467| val_0_mse: 200.35165405273438|  0:00:22s\n","epoch 32 | loss: 175.54717| val_0_mse: 307.9904479980469|  0:00:22s\n","epoch 33 | loss: 184.41246| val_0_mse: 172.23214721679688|  0:00:23s\n","epoch 34 | loss: 181.55541| val_0_mse: 176.2947540283203|  0:00:24s\n","epoch 35 | loss: 176.72236| val_0_mse: 209.3898468017578|  0:00:25s\n","epoch 36 | loss: 182.59925| val_0_mse: 210.95144653320312|  0:00:25s\n","epoch 37 | loss: 177.84712| val_0_mse: 203.16525268554688|  0:00:26s\n","epoch 38 | loss: 179.3979| val_0_mse: 203.90162658691406|  0:00:27s\n","epoch 39 | loss: 174.15619| val_0_mse: 175.0388946533203|  0:00:27s\n","epoch 40 | loss: 171.36512| val_0_mse: 174.5540771484375|  0:00:28s\n","epoch 41 | loss: 175.60411| val_0_mse: 189.8975372314453|  0:00:29s\n","epoch 42 | loss: 163.27917| val_0_mse: 173.40203857421875|  0:00:29s\n","epoch 43 | loss: 163.8975| val_0_mse: 166.40652465820312|  0:00:30s\n","epoch 44 | loss: 160.88159| val_0_mse: 159.2541961669922|  0:00:31s\n","epoch 45 | loss: 162.75727| val_0_mse: 179.57655334472656|  0:00:31s\n","epoch 46 | loss: 160.64519| val_0_mse: 174.0521240234375|  0:00:32s\n","epoch 47 | loss: 162.9253| val_0_mse: 196.84335327148438|  0:00:33s\n","epoch 48 | loss: 163.94546| val_0_mse: 182.80145263671875|  0:00:33s\n","epoch 49 | loss: 158.79452| val_0_mse: 164.60491943359375|  0:00:34s\n","epoch 50 | loss: 166.05231| val_0_mse: 166.56866455078125|  0:00:35s\n","epoch 51 | loss: 162.92348| val_0_mse: 165.37197875976562|  0:00:36s\n","epoch 52 | loss: 161.38105| val_0_mse: 164.4125213623047|  0:00:36s\n","epoch 53 | loss: 171.36548| val_0_mse: 170.3855743408203|  0:00:37s\n","epoch 54 | loss: 163.18306| val_0_mse: 185.48081970214844|  0:00:38s\n","\n","Early stopping occurred at epoch 54 with best_epoch = 44 and best_val_0_mse = 159.2541961669922\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 15:08:24,126] Trial 62 finished with value: 159.2541961669922 and parameters: {'n_d': 62, 'n_steps': 3, 'gamma': 1.0786924037715249, 'n_independent': 3, 'n_shared': 4, 'momentum': 0.13601806698159713}. Best is trial 33 with value: 135.8055877685547.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 1590.99677| val_0_mse: 9424.17578125|  0:00:00s\n","epoch 1  | loss: 441.14805| val_0_mse: 2461.146484375|  0:00:01s\n","epoch 2  | loss: 326.31845| val_0_mse: 1586.3876953125|  0:00:02s\n","epoch 3  | loss: 297.23056| val_0_mse: 1627.51806640625|  0:00:02s\n","epoch 4  | loss: 271.77943| val_0_mse: 2168.81787109375|  0:00:03s\n","epoch 5  | loss: 268.72291| val_0_mse: 1850.8330078125|  0:00:04s\n","epoch 6  | loss: 260.83221| val_0_mse: 1621.42138671875|  0:00:04s\n","epoch 7  | loss: 262.84602| val_0_mse: 1277.777099609375|  0:00:05s\n","epoch 8  | loss: 255.60575| val_0_mse: 785.0640869140625|  0:00:06s\n","epoch 9  | loss: 244.64047| val_0_mse: 840.4696655273438|  0:00:06s\n","epoch 10 | loss: 239.28276| val_0_mse: 967.130615234375|  0:00:07s\n","epoch 11 | loss: 230.55367| val_0_mse: 722.1642456054688|  0:00:08s\n","epoch 12 | loss: 225.50774| val_0_mse: 776.5755004882812|  0:00:08s\n","epoch 13 | loss: 221.34402| val_0_mse: 555.1853637695312|  0:00:09s\n","epoch 14 | loss: 220.11004| val_0_mse: 588.3937377929688|  0:00:10s\n","epoch 15 | loss: 224.3354| val_0_mse: 568.4991455078125|  0:00:11s\n","epoch 16 | loss: 206.44707| val_0_mse: 555.8702392578125|  0:00:11s\n","epoch 17 | loss: 198.79037| val_0_mse: 479.4346923828125|  0:00:12s\n","epoch 18 | loss: 216.13909| val_0_mse: 453.0094909667969|  0:00:13s\n","epoch 19 | loss: 211.59248| val_0_mse: 439.2748107910156|  0:00:13s\n","epoch 20 | loss: 203.3022| val_0_mse: 359.07354736328125|  0:00:14s\n","epoch 21 | loss: 204.10035| val_0_mse: 298.82916259765625|  0:00:15s\n","epoch 22 | loss: 205.4705| val_0_mse: 290.2610168457031|  0:00:15s\n","epoch 23 | loss: 195.23787| val_0_mse: 276.17822265625|  0:00:16s\n","epoch 24 | loss: 195.398 | val_0_mse: 287.9542541503906|  0:00:17s\n","epoch 25 | loss: 195.78066| val_0_mse: 271.29168701171875|  0:00:18s\n","epoch 26 | loss: 196.2478| val_0_mse: 239.39059448242188|  0:00:18s\n","epoch 27 | loss: 190.28555| val_0_mse: 232.97067260742188|  0:00:19s\n","epoch 28 | loss: 192.89764| val_0_mse: 221.6774139404297|  0:00:20s\n","epoch 29 | loss: 192.24059| val_0_mse: 230.35357666015625|  0:00:20s\n","epoch 30 | loss: 192.50821| val_0_mse: 237.8714141845703|  0:00:21s\n","epoch 31 | loss: 201.14887| val_0_mse: 207.42018127441406|  0:00:22s\n","epoch 32 | loss: 194.98075| val_0_mse: 219.7843475341797|  0:00:22s\n","epoch 33 | loss: 196.74243| val_0_mse: 215.4980926513672|  0:00:23s\n","epoch 34 | loss: 186.57697| val_0_mse: 220.73875427246094|  0:00:24s\n","epoch 35 | loss: 191.93576| val_0_mse: 214.7133331298828|  0:00:25s\n","epoch 36 | loss: 187.2068| val_0_mse: 204.69479370117188|  0:00:25s\n","epoch 37 | loss: 184.05435| val_0_mse: 201.7625732421875|  0:00:26s\n","epoch 38 | loss: 187.39253| val_0_mse: 189.677734375|  0:00:27s\n","epoch 39 | loss: 179.09822| val_0_mse: 209.4391326904297|  0:00:27s\n","epoch 40 | loss: 181.20694| val_0_mse: 208.29769897460938|  0:00:28s\n","epoch 41 | loss: 182.88813| val_0_mse: 255.24598693847656|  0:00:29s\n","epoch 42 | loss: 175.50056| val_0_mse: 197.86309814453125|  0:00:29s\n","epoch 43 | loss: 175.67242| val_0_mse: 208.7047576904297|  0:00:30s\n","epoch 44 | loss: 171.14692| val_0_mse: 183.58433532714844|  0:00:31s\n","epoch 45 | loss: 171.9392| val_0_mse: 218.06370544433594|  0:00:32s\n","epoch 46 | loss: 176.02071| val_0_mse: 193.5077362060547|  0:00:32s\n","epoch 47 | loss: 169.54293| val_0_mse: 171.32998657226562|  0:00:33s\n","epoch 48 | loss: 161.72373| val_0_mse: 184.98558044433594|  0:00:34s\n","epoch 49 | loss: 160.84102| val_0_mse: 233.70274353027344|  0:00:34s\n","epoch 50 | loss: 171.24039| val_0_mse: 225.55409240722656|  0:00:35s\n","epoch 51 | loss: 168.91401| val_0_mse: 203.3951873779297|  0:00:36s\n","epoch 52 | loss: 180.96988| val_0_mse: 185.75958251953125|  0:00:36s\n","epoch 53 | loss: 169.41705| val_0_mse: 183.24266052246094|  0:00:37s\n","epoch 54 | loss: 165.04067| val_0_mse: 180.0590057373047|  0:00:38s\n","epoch 55 | loss: 158.30667| val_0_mse: 167.50233459472656|  0:00:38s\n","epoch 56 | loss: 160.13078| val_0_mse: 188.3151397705078|  0:00:39s\n","epoch 57 | loss: 155.56891| val_0_mse: 171.2322998046875|  0:00:40s\n","epoch 58 | loss: 152.08365| val_0_mse: 175.72030639648438|  0:00:41s\n","epoch 59 | loss: 152.05664| val_0_mse: 171.311767578125|  0:00:41s\n","epoch 60 | loss: 162.9195| val_0_mse: 182.579833984375|  0:00:42s\n","epoch 61 | loss: 157.86661| val_0_mse: 189.1768798828125|  0:00:43s\n","epoch 62 | loss: 152.75448| val_0_mse: 168.6324462890625|  0:00:43s\n","epoch 63 | loss: 147.03697| val_0_mse: 157.81329345703125|  0:00:44s\n","epoch 64 | loss: 146.29721| val_0_mse: 160.81385803222656|  0:00:45s\n","epoch 65 | loss: 157.8461| val_0_mse: 172.05877685546875|  0:00:45s\n","epoch 66 | loss: 148.84824| val_0_mse: 173.031005859375|  0:00:46s\n","epoch 67 | loss: 159.06377| val_0_mse: 168.6818389892578|  0:00:47s\n","epoch 68 | loss: 155.17702| val_0_mse: 170.60000610351562|  0:00:47s\n","epoch 69 | loss: 150.45278| val_0_mse: 168.18295288085938|  0:00:48s\n","epoch 70 | loss: 149.20223| val_0_mse: 172.2004852294922|  0:00:49s\n","epoch 71 | loss: 145.25951| val_0_mse: 184.05130004882812|  0:00:49s\n","epoch 72 | loss: 149.53087| val_0_mse: 162.43252563476562|  0:00:50s\n","epoch 73 | loss: 147.13753| val_0_mse: 156.63565063476562|  0:00:51s\n","epoch 74 | loss: 146.51589| val_0_mse: 196.29209899902344|  0:00:52s\n","epoch 75 | loss: 142.17025| val_0_mse: 167.6289825439453|  0:00:52s\n","epoch 76 | loss: 154.82131| val_0_mse: 187.50347900390625|  0:00:53s\n","epoch 77 | loss: 154.98023| val_0_mse: 152.44427490234375|  0:00:54s\n","epoch 78 | loss: 143.79094| val_0_mse: 163.08148193359375|  0:00:54s\n","epoch 79 | loss: 142.54916| val_0_mse: 160.38021850585938|  0:00:55s\n","epoch 80 | loss: 149.35637| val_0_mse: 170.267822265625|  0:00:56s\n","epoch 81 | loss: 149.71154| val_0_mse: 161.23171997070312|  0:00:56s\n","epoch 82 | loss: 141.83414| val_0_mse: 159.90841674804688|  0:00:57s\n","epoch 83 | loss: 139.19384| val_0_mse: 171.9109649658203|  0:00:58s\n","epoch 84 | loss: 144.79566| val_0_mse: 154.0943145751953|  0:00:58s\n","epoch 85 | loss: 147.5967| val_0_mse: 168.50360107421875|  0:00:59s\n","epoch 86 | loss: 141.60213| val_0_mse: 159.642578125|  0:01:00s\n","epoch 87 | loss: 141.40276| val_0_mse: 177.12379455566406|  0:01:00s\n","\n","Early stopping occurred at epoch 87 with best_epoch = 77 and best_val_0_mse = 152.44427490234375\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 15:09:25,374] Trial 63 finished with value: 152.44427490234375 and parameters: {'n_d': 64, 'n_steps': 3, 'gamma': 1.4964817620235642, 'n_independent': 3, 'n_shared': 4, 'momentum': 0.07998520153412905}. Best is trial 33 with value: 135.8055877685547.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 1708.9566| val_0_mse: 53191.68359375|  0:00:00s\n","epoch 1  | loss: 607.91197| val_0_mse: 13945.07421875|  0:00:01s\n","epoch 2  | loss: 455.13347| val_0_mse: 5036.0712890625|  0:00:02s\n","epoch 3  | loss: 397.51497| val_0_mse: 2463.6025390625|  0:00:03s\n","epoch 4  | loss: 392.09528| val_0_mse: 1499.9114990234375|  0:00:04s\n","epoch 5  | loss: 386.26345| val_0_mse: 1903.24169921875|  0:00:04s\n","epoch 6  | loss: 342.68054| val_0_mse: 1897.5389404296875|  0:00:05s\n","epoch 7  | loss: 333.11201| val_0_mse: 1143.6724853515625|  0:00:06s\n","epoch 8  | loss: 302.41644| val_0_mse: 1296.2987060546875|  0:00:06s\n","epoch 9  | loss: 294.60918| val_0_mse: 1343.7012939453125|  0:00:07s\n","epoch 10 | loss: 298.54284| val_0_mse: 1079.9212646484375|  0:00:08s\n","epoch 11 | loss: 280.98748| val_0_mse: 1211.514404296875|  0:00:09s\n","epoch 12 | loss: 279.49436| val_0_mse: 1015.7633666992188|  0:00:09s\n","epoch 13 | loss: 268.48375| val_0_mse: 610.6021118164062|  0:00:10s\n","epoch 14 | loss: 270.279 | val_0_mse: 737.098876953125|  0:00:11s\n","epoch 15 | loss: 258.41518| val_0_mse: 448.71630859375|  0:00:12s\n","epoch 16 | loss: 255.55218| val_0_mse: 764.96240234375|  0:00:12s\n","epoch 17 | loss: 253.25208| val_0_mse: 775.7221069335938|  0:00:13s\n","epoch 18 | loss: 249.28089| val_0_mse: 702.9334106445312|  0:00:14s\n","epoch 19 | loss: 241.34104| val_0_mse: 554.988037109375|  0:00:15s\n","epoch 20 | loss: 245.20099| val_0_mse: 414.46173095703125|  0:00:15s\n","epoch 21 | loss: 252.49072| val_0_mse: 351.1178894042969|  0:00:16s\n","epoch 22 | loss: 245.20217| val_0_mse: 329.39166259765625|  0:00:17s\n","epoch 23 | loss: 244.53457| val_0_mse: 343.5799865722656|  0:00:18s\n","epoch 24 | loss: 237.63869| val_0_mse: 311.466064453125|  0:00:18s\n","epoch 25 | loss: 230.53332| val_0_mse: 285.65289306640625|  0:00:19s\n","epoch 26 | loss: 219.25611| val_0_mse: 325.6816101074219|  0:00:20s\n","epoch 27 | loss: 225.04075| val_0_mse: 288.81756591796875|  0:00:21s\n","epoch 28 | loss: 222.88252| val_0_mse: 264.8185119628906|  0:00:21s\n","epoch 29 | loss: 206.55447| val_0_mse: 239.88868713378906|  0:00:22s\n","epoch 30 | loss: 209.73067| val_0_mse: 236.80335998535156|  0:00:23s\n","epoch 31 | loss: 203.91913| val_0_mse: 223.42904663085938|  0:00:24s\n","epoch 32 | loss: 206.94606| val_0_mse: 235.13525390625|  0:00:25s\n","epoch 33 | loss: 201.33349| val_0_mse: 235.47439575195312|  0:00:25s\n","epoch 34 | loss: 198.09937| val_0_mse: 204.12498474121094|  0:00:26s\n","epoch 35 | loss: 190.42439| val_0_mse: 217.5967254638672|  0:00:27s\n","epoch 36 | loss: 200.05466| val_0_mse: 194.41958618164062|  0:00:28s\n","epoch 37 | loss: 195.77869| val_0_mse: 214.48553466796875|  0:00:28s\n","epoch 38 | loss: 196.08729| val_0_mse: 195.16131591796875|  0:00:29s\n","epoch 39 | loss: 190.26541| val_0_mse: 191.9380340576172|  0:00:30s\n","epoch 40 | loss: 185.88831| val_0_mse: 214.83163452148438|  0:00:31s\n","epoch 41 | loss: 192.5788| val_0_mse: 206.82861328125|  0:00:31s\n","epoch 42 | loss: 194.46762| val_0_mse: 240.5487823486328|  0:00:32s\n","epoch 43 | loss: 187.70264| val_0_mse: 177.51669311523438|  0:00:33s\n","epoch 44 | loss: 189.27866| val_0_mse: 192.09461975097656|  0:00:34s\n","epoch 45 | loss: 187.05242| val_0_mse: 201.2736053466797|  0:00:34s\n","epoch 46 | loss: 185.13443| val_0_mse: 254.46751403808594|  0:00:35s\n","epoch 47 | loss: 184.3616| val_0_mse: 182.0499267578125|  0:00:36s\n","epoch 48 | loss: 187.74556| val_0_mse: 174.8190460205078|  0:00:37s\n","epoch 49 | loss: 172.18223| val_0_mse: 170.1919403076172|  0:00:37s\n","epoch 50 | loss: 173.40689| val_0_mse: 175.9642333984375|  0:00:38s\n","epoch 51 | loss: 175.70466| val_0_mse: 183.3748016357422|  0:00:39s\n","epoch 52 | loss: 173.45089| val_0_mse: 201.64808654785156|  0:00:40s\n","epoch 53 | loss: 170.19288| val_0_mse: 171.61343383789062|  0:00:40s\n","epoch 54 | loss: 170.68798| val_0_mse: 165.9838104248047|  0:00:41s\n","epoch 55 | loss: 165.26599| val_0_mse: 166.16615295410156|  0:00:42s\n","epoch 56 | loss: 169.30588| val_0_mse: 167.0979461669922|  0:00:43s\n","epoch 57 | loss: 167.26  | val_0_mse: 220.50201416015625|  0:00:43s\n","epoch 58 | loss: 176.04346| val_0_mse: 198.0489044189453|  0:00:44s\n","epoch 59 | loss: 172.42405| val_0_mse: 170.2574462890625|  0:00:45s\n","epoch 60 | loss: 179.63742| val_0_mse: 168.39439392089844|  0:00:46s\n","epoch 61 | loss: 164.90264| val_0_mse: 183.8739776611328|  0:00:46s\n","epoch 62 | loss: 168.16546| val_0_mse: 171.09556579589844|  0:00:47s\n","epoch 63 | loss: 166.13977| val_0_mse: 177.15597534179688|  0:00:48s\n","epoch 64 | loss: 171.65076| val_0_mse: 184.91058349609375|  0:00:49s\n","\n","Early stopping occurred at epoch 64 with best_epoch = 54 and best_val_0_mse = 165.9838104248047\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 15:10:14,912] Trial 64 finished with value: 165.9838104248047 and parameters: {'n_d': 55, 'n_steps': 4, 'gamma': 1.43725788791886, 'n_independent': 3, 'n_shared': 3, 'momentum': 0.15641978279035584}. Best is trial 33 with value: 135.8055877685547.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 1796.00458| val_0_mse: 4880.53125|  0:00:00s\n","epoch 1  | loss: 536.51913| val_0_mse: 4996.72900390625|  0:00:01s\n","epoch 2  | loss: 363.01228| val_0_mse: 14011.48828125|  0:00:02s\n","epoch 3  | loss: 337.96182| val_0_mse: 1352.4620361328125|  0:00:02s\n","epoch 4  | loss: 338.56276| val_0_mse: 1567.667236328125|  0:00:03s\n","epoch 5  | loss: 307.8882| val_0_mse: 705.4663696289062|  0:00:04s\n","epoch 6  | loss: 277.18853| val_0_mse: 2607.06103515625|  0:00:04s\n","epoch 7  | loss: 272.14503| val_0_mse: 2166.223388671875|  0:00:05s\n","epoch 8  | loss: 256.48699| val_0_mse: 1524.772216796875|  0:00:06s\n","epoch 9  | loss: 245.68433| val_0_mse: 4090.141845703125|  0:00:06s\n","epoch 10 | loss: 241.04111| val_0_mse: 4270.10498046875|  0:00:07s\n","epoch 11 | loss: 232.54592| val_0_mse: 1752.5621337890625|  0:00:08s\n","epoch 12 | loss: 227.30699| val_0_mse: 590.0361328125|  0:00:08s\n","epoch 13 | loss: 224.22189| val_0_mse: 781.2705688476562|  0:00:09s\n","epoch 14 | loss: 221.93677| val_0_mse: 542.2971801757812|  0:00:10s\n","epoch 15 | loss: 214.11114| val_0_mse: 648.9393310546875|  0:00:11s\n","epoch 16 | loss: 204.74156| val_0_mse: 497.1919860839844|  0:00:11s\n","epoch 17 | loss: 198.24836| val_0_mse: 633.2208251953125|  0:00:12s\n","epoch 18 | loss: 195.80983| val_0_mse: 474.9857482910156|  0:00:13s\n","epoch 19 | loss: 193.13988| val_0_mse: 292.17877197265625|  0:00:13s\n","epoch 20 | loss: 187.45402| val_0_mse: 334.4595947265625|  0:00:14s\n","epoch 21 | loss: 192.07741| val_0_mse: 373.50335693359375|  0:00:15s\n","epoch 22 | loss: 189.37976| val_0_mse: 292.58966064453125|  0:00:15s\n","epoch 23 | loss: 189.35795| val_0_mse: 308.99786376953125|  0:00:16s\n","epoch 24 | loss: 192.51217| val_0_mse: 226.5696563720703|  0:00:17s\n","epoch 25 | loss: 181.65252| val_0_mse: 282.4985656738281|  0:00:17s\n","epoch 26 | loss: 192.16927| val_0_mse: 220.28280639648438|  0:00:18s\n","epoch 27 | loss: 179.39114| val_0_mse: 237.48536682128906|  0:00:19s\n","epoch 28 | loss: 175.64988| val_0_mse: 195.99905395507812|  0:00:19s\n","epoch 29 | loss: 175.49897| val_0_mse: 284.4337158203125|  0:00:20s\n","epoch 30 | loss: 179.32432| val_0_mse: 217.303466796875|  0:00:21s\n","epoch 31 | loss: 175.55082| val_0_mse: 192.50819396972656|  0:00:22s\n","epoch 32 | loss: 172.25258| val_0_mse: 193.253662109375|  0:00:22s\n","epoch 33 | loss: 174.72522| val_0_mse: 195.85073852539062|  0:00:23s\n","epoch 34 | loss: 175.48443| val_0_mse: 204.92906188964844|  0:00:24s\n","epoch 35 | loss: 175.77156| val_0_mse: 201.056396484375|  0:00:24s\n","epoch 36 | loss: 176.07853| val_0_mse: 197.7257537841797|  0:00:25s\n","epoch 37 | loss: 167.98981| val_0_mse: 176.85394287109375|  0:00:26s\n","epoch 38 | loss: 164.42233| val_0_mse: 210.80007934570312|  0:00:26s\n","epoch 39 | loss: 166.75032| val_0_mse: 178.23475646972656|  0:00:27s\n","epoch 40 | loss: 165.85739| val_0_mse: 191.1184844970703|  0:00:28s\n","epoch 41 | loss: 165.17957| val_0_mse: 162.50765991210938|  0:00:28s\n","epoch 42 | loss: 160.98784| val_0_mse: 166.9757080078125|  0:00:29s\n","epoch 43 | loss: 155.72182| val_0_mse: 174.6722869873047|  0:00:30s\n","epoch 44 | loss: 158.81731| val_0_mse: 191.39956665039062|  0:00:30s\n","epoch 45 | loss: 158.84721| val_0_mse: 176.12660217285156|  0:00:31s\n","epoch 46 | loss: 156.79979| val_0_mse: 167.1483917236328|  0:00:32s\n","epoch 47 | loss: 161.26025| val_0_mse: 170.66409301757812|  0:00:33s\n","epoch 48 | loss: 159.05296| val_0_mse: 170.6683349609375|  0:00:33s\n","epoch 49 | loss: 151.08128| val_0_mse: 153.3811492919922|  0:00:34s\n","epoch 50 | loss: 151.78446| val_0_mse: 169.95770263671875|  0:00:35s\n","epoch 51 | loss: 147.88176| val_0_mse: 166.26406860351562|  0:00:35s\n","epoch 52 | loss: 153.02704| val_0_mse: 159.86279296875|  0:00:36s\n","epoch 53 | loss: 144.46089| val_0_mse: 177.96290588378906|  0:00:37s\n","epoch 54 | loss: 144.6019| val_0_mse: 164.79501342773438|  0:00:37s\n","epoch 55 | loss: 147.96429| val_0_mse: 166.4603729248047|  0:00:38s\n","epoch 56 | loss: 151.05893| val_0_mse: 165.24008178710938|  0:00:39s\n","epoch 57 | loss: 143.82465| val_0_mse: 180.44912719726562|  0:00:39s\n","epoch 58 | loss: 140.26352| val_0_mse: 164.73155212402344|  0:00:40s\n","epoch 59 | loss: 141.98451| val_0_mse: 171.48513793945312|  0:00:41s\n","\n","Early stopping occurred at epoch 59 with best_epoch = 49 and best_val_0_mse = 153.3811492919922\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 15:10:56,401] Trial 65 finished with value: 153.3811492919922 and parameters: {'n_d': 59, 'n_steps': 3, 'gamma': 1.3572159144490552, 'n_independent': 2, 'n_shared': 5, 'momentum': 0.11645633636514312}. Best is trial 33 with value: 135.8055877685547.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 2116.68083| val_0_mse: 57331.4296875|  0:00:01s\n","epoch 1  | loss: 1227.2933| val_0_mse: 23817.416015625|  0:00:03s\n","epoch 2  | loss: 759.16928| val_0_mse: 4046.8369140625|  0:00:04s\n","epoch 3  | loss: 600.44708| val_0_mse: 2726.672119140625|  0:00:06s\n","epoch 4  | loss: 540.88958| val_0_mse: 2492.726806640625|  0:00:07s\n","epoch 5  | loss: 591.68674| val_0_mse: 1575.6795654296875|  0:00:09s\n","epoch 6  | loss: 570.00601| val_0_mse: 1594.43701171875|  0:00:10s\n","epoch 7  | loss: 535.84421| val_0_mse: 1913.34814453125|  0:00:12s\n","epoch 8  | loss: 498.38105| val_0_mse: 1110.391357421875|  0:00:13s\n","epoch 9  | loss: 535.28445| val_0_mse: 1932.5009765625|  0:00:15s\n","epoch 10 | loss: 584.78367| val_0_mse: 622.5861206054688|  0:00:17s\n","epoch 11 | loss: 546.89114| val_0_mse: 964.3614501953125|  0:00:18s\n","epoch 12 | loss: 546.94238| val_0_mse: 1023.1522216796875|  0:00:20s\n","epoch 13 | loss: 570.83269| val_0_mse: 552.9588623046875|  0:00:21s\n","epoch 14 | loss: 542.41604| val_0_mse: 559.0180053710938|  0:00:23s\n","epoch 15 | loss: 450.65026| val_0_mse: 705.4710693359375|  0:00:24s\n","epoch 16 | loss: 441.34342| val_0_mse: 596.0589599609375|  0:00:26s\n","epoch 17 | loss: 465.63386| val_0_mse: 473.477294921875|  0:00:28s\n","epoch 18 | loss: 449.34829| val_0_mse: 502.724609375|  0:00:29s\n","epoch 19 | loss: 441.23315| val_0_mse: 476.6751708984375|  0:00:31s\n","epoch 20 | loss: 437.26141| val_0_mse: 445.24444580078125|  0:00:32s\n","epoch 21 | loss: 442.50512| val_0_mse: 481.98724365234375|  0:00:34s\n","epoch 22 | loss: 448.63132| val_0_mse: 507.8783264160156|  0:00:35s\n","epoch 23 | loss: 437.05866| val_0_mse: 456.35479736328125|  0:00:37s\n","epoch 24 | loss: 426.02411| val_0_mse: 436.7066650390625|  0:00:38s\n","epoch 25 | loss: 406.36806| val_0_mse: 483.32171630859375|  0:00:40s\n","epoch 26 | loss: 377.56746| val_0_mse: 429.8280029296875|  0:00:41s\n","epoch 27 | loss: 361.81524| val_0_mse: 484.0654296875|  0:00:43s\n","epoch 28 | loss: 369.87214| val_0_mse: 474.90838623046875|  0:00:45s\n","epoch 29 | loss: 360.6934| val_0_mse: 515.0392456054688|  0:00:46s\n","epoch 30 | loss: 383.69327| val_0_mse: 375.764404296875|  0:00:48s\n","epoch 31 | loss: 402.17103| val_0_mse: 438.9535217285156|  0:00:49s\n","epoch 32 | loss: 376.92518| val_0_mse: 333.9378356933594|  0:00:51s\n","epoch 33 | loss: 363.20045| val_0_mse: 335.8935852050781|  0:00:52s\n","epoch 34 | loss: 376.28309| val_0_mse: 385.2511901855469|  0:00:54s\n","epoch 35 | loss: 365.87444| val_0_mse: 326.5614013671875|  0:00:56s\n","epoch 36 | loss: 322.19942| val_0_mse: 310.1897888183594|  0:00:57s\n","epoch 37 | loss: 310.91147| val_0_mse: 312.9364929199219|  0:00:59s\n","epoch 38 | loss: 310.06965| val_0_mse: 355.70635986328125|  0:01:01s\n","epoch 39 | loss: 332.06588| val_0_mse: 297.4510498046875|  0:01:02s\n","epoch 40 | loss: 303.3922| val_0_mse: 301.49908447265625|  0:01:04s\n","epoch 41 | loss: 317.19407| val_0_mse: 345.0025329589844|  0:01:05s\n","epoch 42 | loss: 300.43406| val_0_mse: 289.15374755859375|  0:01:07s\n","epoch 43 | loss: 299.00078| val_0_mse: 280.3849182128906|  0:01:08s\n","epoch 44 | loss: 287.16912| val_0_mse: 277.32012939453125|  0:01:10s\n","epoch 45 | loss: 283.16667| val_0_mse: 318.3786315917969|  0:01:11s\n","epoch 46 | loss: 286.13514| val_0_mse: 271.2481994628906|  0:01:13s\n","epoch 47 | loss: 274.98182| val_0_mse: 261.9903869628906|  0:01:15s\n","epoch 48 | loss: 263.96501| val_0_mse: 261.2427062988281|  0:01:16s\n","epoch 49 | loss: 262.30172| val_0_mse: 255.22607421875|  0:01:18s\n","epoch 50 | loss: 288.21652| val_0_mse: 317.25018310546875|  0:01:19s\n","epoch 51 | loss: 271.88393| val_0_mse: 269.49432373046875|  0:01:21s\n","epoch 52 | loss: 258.00367| val_0_mse: 267.9243469238281|  0:01:22s\n","epoch 53 | loss: 270.36257| val_0_mse: 263.4737854003906|  0:01:24s\n","epoch 54 | loss: 263.2429| val_0_mse: 282.5699768066406|  0:01:26s\n","epoch 55 | loss: 253.2809| val_0_mse: 276.39605712890625|  0:01:27s\n","epoch 56 | loss: 257.84569| val_0_mse: 271.6760559082031|  0:01:29s\n","epoch 57 | loss: 258.70072| val_0_mse: 237.19337463378906|  0:01:30s\n","epoch 58 | loss: 257.76784| val_0_mse: 240.88754272460938|  0:01:32s\n","epoch 59 | loss: 245.91986| val_0_mse: 253.0288543701172|  0:01:33s\n","epoch 60 | loss: 241.83806| val_0_mse: 264.5819396972656|  0:01:35s\n","epoch 61 | loss: 242.75971| val_0_mse: 302.04736328125|  0:01:36s\n","epoch 62 | loss: 231.62987| val_0_mse: 226.75765991210938|  0:01:38s\n","epoch 63 | loss: 228.56711| val_0_mse: 232.41102600097656|  0:01:39s\n","epoch 64 | loss: 231.18808| val_0_mse: 225.96702575683594|  0:01:41s\n","epoch 65 | loss: 229.17964| val_0_mse: 223.55589294433594|  0:01:43s\n","epoch 66 | loss: 236.73714| val_0_mse: 228.44775390625|  0:01:44s\n","epoch 67 | loss: 223.0662| val_0_mse: 212.29495239257812|  0:01:46s\n","epoch 68 | loss: 219.19388| val_0_mse: 225.87596130371094|  0:01:47s\n","epoch 69 | loss: 220.9422| val_0_mse: 201.54928588867188|  0:01:49s\n","epoch 70 | loss: 217.7282| val_0_mse: 226.98167419433594|  0:01:51s\n","epoch 71 | loss: 210.24572| val_0_mse: 207.56117248535156|  0:01:52s\n","epoch 72 | loss: 198.65969| val_0_mse: 200.1728057861328|  0:01:54s\n","epoch 73 | loss: 202.74909| val_0_mse: 199.07327270507812|  0:01:55s\n","epoch 74 | loss: 199.29056| val_0_mse: 196.897216796875|  0:01:57s\n","epoch 75 | loss: 202.774 | val_0_mse: 205.92254638671875|  0:01:58s\n","epoch 76 | loss: 197.52173| val_0_mse: 197.28463745117188|  0:02:00s\n","epoch 77 | loss: 198.03891| val_0_mse: 195.18734741210938|  0:02:01s\n","epoch 78 | loss: 193.26661| val_0_mse: 191.72390747070312|  0:02:03s\n","epoch 79 | loss: 192.79622| val_0_mse: 186.99783325195312|  0:02:05s\n","epoch 80 | loss: 185.74585| val_0_mse: 188.23736572265625|  0:02:06s\n","epoch 81 | loss: 192.25616| val_0_mse: 201.5555419921875|  0:02:08s\n","epoch 82 | loss: 187.75009| val_0_mse: 185.9346923828125|  0:02:09s\n","epoch 83 | loss: 189.67317| val_0_mse: 196.3436737060547|  0:02:11s\n","epoch 84 | loss: 186.09622| val_0_mse: 188.10955810546875|  0:02:12s\n","epoch 85 | loss: 184.63114| val_0_mse: 189.0829620361328|  0:02:14s\n","epoch 86 | loss: 189.55092| val_0_mse: 187.76199340820312|  0:02:16s\n","epoch 87 | loss: 182.84546| val_0_mse: 181.86221313476562|  0:02:17s\n","epoch 88 | loss: 180.70896| val_0_mse: 189.559326171875|  0:02:19s\n","epoch 89 | loss: 185.67824| val_0_mse: 195.68614196777344|  0:02:20s\n","epoch 90 | loss: 181.30392| val_0_mse: 177.54588317871094|  0:02:22s\n","epoch 91 | loss: 177.73681| val_0_mse: 185.58592224121094|  0:02:23s\n","epoch 92 | loss: 173.15566| val_0_mse: 180.12063598632812|  0:02:25s\n","epoch 93 | loss: 175.09114| val_0_mse: 182.48658752441406|  0:02:26s\n","epoch 94 | loss: 170.17462| val_0_mse: 171.4398651123047|  0:02:28s\n","epoch 95 | loss: 169.37307| val_0_mse: 202.9794464111328|  0:02:29s\n","epoch 96 | loss: 176.69169| val_0_mse: 176.1728057861328|  0:02:31s\n","epoch 97 | loss: 170.20968| val_0_mse: 183.66183471679688|  0:02:32s\n","epoch 98 | loss: 174.08502| val_0_mse: 182.35650634765625|  0:02:34s\n","epoch 99 | loss: 165.84099| val_0_mse: 199.6575927734375|  0:02:35s\n","Stop training because you reached max_epochs = 100 with best_epoch = 94 and best_val_0_mse = 171.4398651123047\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 15:13:33,259] Trial 66 finished with value: 171.4398651123047 and parameters: {'n_d': 61, 'n_steps': 9, 'gamma': 1.6297572128619593, 'n_independent': 3, 'n_shared': 4, 'momentum': 0.19698536878711206}. Best is trial 33 with value: 135.8055877685547.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 1748.17887| val_0_mse: 38145.7109375|  0:00:00s\n","epoch 1  | loss: 570.58702| val_0_mse: 4394.609375|  0:00:01s\n","epoch 2  | loss: 393.92654| val_0_mse: 3408.61279296875|  0:00:02s\n","epoch 3  | loss: 338.99708| val_0_mse: 934.2162475585938|  0:00:02s\n","epoch 4  | loss: 360.11073| val_0_mse: 1220.4150390625|  0:00:03s\n","epoch 5  | loss: 363.1486| val_0_mse: 875.5076293945312|  0:00:04s\n","epoch 6  | loss: 370.50826| val_0_mse: 1631.798828125|  0:00:05s\n","epoch 7  | loss: 351.69569| val_0_mse: 844.7590942382812|  0:00:05s\n","epoch 8  | loss: 333.06941| val_0_mse: 706.647705078125|  0:00:06s\n","epoch 9  | loss: 324.46339| val_0_mse: 583.6140747070312|  0:00:07s\n","epoch 10 | loss: 315.05013| val_0_mse: 449.8808288574219|  0:00:08s\n","epoch 11 | loss: 314.48294| val_0_mse: 612.592529296875|  0:00:09s\n","epoch 12 | loss: 306.81758| val_0_mse: 471.2455139160156|  0:00:09s\n","epoch 13 | loss: 294.91092| val_0_mse: 398.53021240234375|  0:00:10s\n","epoch 14 | loss: 282.08173| val_0_mse: 381.0633850097656|  0:00:11s\n","epoch 15 | loss: 276.22444| val_0_mse: 394.1049499511719|  0:00:12s\n","epoch 16 | loss: 286.00956| val_0_mse: 407.1114807128906|  0:00:12s\n","epoch 17 | loss: 274.82216| val_0_mse: 378.57763671875|  0:00:13s\n","epoch 18 | loss: 267.03042| val_0_mse: 487.7176513671875|  0:00:14s\n","epoch 19 | loss: 257.51764| val_0_mse: 953.722900390625|  0:00:15s\n","epoch 20 | loss: 259.83777| val_0_mse: 370.3017272949219|  0:00:15s\n","epoch 21 | loss: 249.08595| val_0_mse: 326.64898681640625|  0:00:16s\n","epoch 22 | loss: 259.87624| val_0_mse: 306.5899353027344|  0:00:17s\n","epoch 23 | loss: 255.64931| val_0_mse: 316.8912048339844|  0:00:18s\n","epoch 24 | loss: 251.39183| val_0_mse: 321.8999328613281|  0:00:18s\n","epoch 25 | loss: 238.06491| val_0_mse: 260.1950988769531|  0:00:19s\n","epoch 26 | loss: 242.00833| val_0_mse: 273.3333435058594|  0:00:20s\n","epoch 27 | loss: 234.59371| val_0_mse: 273.6835632324219|  0:00:21s\n","epoch 28 | loss: 239.86953| val_0_mse: 257.5243835449219|  0:00:21s\n","epoch 29 | loss: 233.95304| val_0_mse: 254.0531463623047|  0:00:22s\n","epoch 30 | loss: 235.46956| val_0_mse: 243.71788024902344|  0:00:23s\n","epoch 31 | loss: 233.3047| val_0_mse: 260.7568664550781|  0:00:23s\n","epoch 32 | loss: 229.26906| val_0_mse: 255.20455932617188|  0:00:24s\n","epoch 33 | loss: 240.97501| val_0_mse: 248.39735412597656|  0:00:25s\n","epoch 34 | loss: 232.37291| val_0_mse: 290.0152587890625|  0:00:26s\n","epoch 35 | loss: 236.65859| val_0_mse: 230.55145263671875|  0:00:26s\n","epoch 36 | loss: 238.00936| val_0_mse: 245.88514709472656|  0:00:27s\n","epoch 37 | loss: 226.67417| val_0_mse: 235.03216552734375|  0:00:28s\n","epoch 38 | loss: 226.27801| val_0_mse: 224.76611328125|  0:00:29s\n","epoch 39 | loss: 233.69459| val_0_mse: 235.36094665527344|  0:00:29s\n","epoch 40 | loss: 239.28409| val_0_mse: 257.3179016113281|  0:00:30s\n","epoch 41 | loss: 224.81745| val_0_mse: 227.17628479003906|  0:00:31s\n","epoch 42 | loss: 215.23603| val_0_mse: 228.38284301757812|  0:00:32s\n","epoch 43 | loss: 218.03007| val_0_mse: 213.559326171875|  0:00:32s\n","epoch 44 | loss: 213.45972| val_0_mse: 226.25343322753906|  0:00:33s\n","epoch 45 | loss: 221.02516| val_0_mse: 218.65292358398438|  0:00:34s\n","epoch 46 | loss: 209.3878| val_0_mse: 211.3683624267578|  0:00:35s\n","epoch 47 | loss: 203.33892| val_0_mse: 228.3096466064453|  0:00:35s\n","epoch 48 | loss: 204.73292| val_0_mse: 219.9800262451172|  0:00:36s\n","epoch 49 | loss: 210.88985| val_0_mse: 230.40550231933594|  0:00:37s\n","epoch 50 | loss: 212.33031| val_0_mse: 217.7422637939453|  0:00:38s\n","epoch 51 | loss: 209.97499| val_0_mse: 208.51707458496094|  0:00:38s\n","epoch 52 | loss: 213.71043| val_0_mse: 223.8211669921875|  0:00:39s\n","epoch 53 | loss: 213.75141| val_0_mse: 240.73536682128906|  0:00:40s\n","epoch 54 | loss: 223.06048| val_0_mse: 231.6805419921875|  0:00:41s\n","epoch 55 | loss: 204.01978| val_0_mse: 207.34054565429688|  0:00:41s\n","epoch 56 | loss: 204.04197| val_0_mse: 204.0425567626953|  0:00:42s\n","epoch 57 | loss: 207.02246| val_0_mse: 202.48956298828125|  0:00:43s\n","epoch 58 | loss: 198.01565| val_0_mse: 215.54733276367188|  0:00:44s\n","epoch 59 | loss: 195.95204| val_0_mse: 196.80374145507812|  0:00:44s\n","epoch 60 | loss: 193.86924| val_0_mse: 198.01565551757812|  0:00:45s\n","epoch 61 | loss: 191.01648| val_0_mse: 204.18795776367188|  0:00:46s\n","epoch 62 | loss: 194.72861| val_0_mse: 200.0762176513672|  0:00:47s\n","epoch 63 | loss: 191.30367| val_0_mse: 206.5908966064453|  0:00:47s\n","epoch 64 | loss: 195.19198| val_0_mse: 194.21253967285156|  0:00:48s\n","epoch 65 | loss: 187.64248| val_0_mse: 195.3804473876953|  0:00:49s\n","epoch 66 | loss: 194.52573| val_0_mse: 223.77047729492188|  0:00:50s\n","epoch 67 | loss: 192.1717| val_0_mse: 210.40428161621094|  0:00:50s\n","epoch 68 | loss: 207.03584| val_0_mse: 219.45640563964844|  0:00:51s\n","epoch 69 | loss: 194.19436| val_0_mse: 210.23251342773438|  0:00:52s\n","epoch 70 | loss: 197.17959| val_0_mse: 202.62744140625|  0:00:52s\n","epoch 71 | loss: 192.0644| val_0_mse: 204.0941925048828|  0:00:53s\n","epoch 72 | loss: 199.61444| val_0_mse: 197.54739379882812|  0:00:54s\n","epoch 73 | loss: 186.25257| val_0_mse: 199.49798583984375|  0:00:55s\n","epoch 74 | loss: 188.94535| val_0_mse: 208.22886657714844|  0:00:55s\n","\n","Early stopping occurred at epoch 74 with best_epoch = 64 and best_val_0_mse = 194.21253967285156\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 15:14:29,695] Trial 67 finished with value: 194.21253967285156 and parameters: {'n_d': 56, 'n_steps': 4, 'gamma': 1.5717598114924451, 'n_independent': 3, 'n_shared': 3, 'momentum': 0.1054729988519418}. Best is trial 33 with value: 135.8055877685547.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 1752.52437| val_0_mse: 23894.201171875|  0:00:00s\n","epoch 1  | loss: 544.29244| val_0_mse: 5645.9052734375|  0:00:01s\n","epoch 2  | loss: 384.7236| val_0_mse: 2415.90771484375|  0:00:01s\n","epoch 3  | loss: 350.02034| val_0_mse: 2154.45263671875|  0:00:02s\n","epoch 4  | loss: 317.6284| val_0_mse: 1079.9971923828125|  0:00:03s\n","epoch 5  | loss: 324.97529| val_0_mse: 1198.1097412109375|  0:00:03s\n","epoch 6  | loss: 303.36894| val_0_mse: 678.5482177734375|  0:00:04s\n","epoch 7  | loss: 300.64441| val_0_mse: 858.4955444335938|  0:00:05s\n","epoch 8  | loss: 295.03461| val_0_mse: 1037.9881591796875|  0:00:05s\n","epoch 9  | loss: 283.5917| val_0_mse: 2050.258544921875|  0:00:06s\n","epoch 10 | loss: 285.41998| val_0_mse: 990.0174560546875|  0:00:06s\n","epoch 11 | loss: 274.35922| val_0_mse: 809.6271362304688|  0:00:07s\n","epoch 12 | loss: 268.95704| val_0_mse: 1075.030029296875|  0:00:08s\n","epoch 13 | loss: 260.48835| val_0_mse: 1025.0391845703125|  0:00:08s\n","epoch 14 | loss: 260.06718| val_0_mse: 718.9404907226562|  0:00:09s\n","epoch 15 | loss: 237.88266| val_0_mse: 1089.6124267578125|  0:00:09s\n","epoch 16 | loss: 239.3583| val_0_mse: 862.6678466796875|  0:00:10s\n","\n","Early stopping occurred at epoch 16 with best_epoch = 6 and best_val_0_mse = 678.5482177734375\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 15:14:40,641] Trial 68 finished with value: 678.5482788085938 and parameters: {'n_d': 49, 'n_steps': 3, 'gamma': 1.4937831965201633, 'n_independent': 3, 'n_shared': 3, 'momentum': 0.17511837601405897}. Best is trial 33 with value: 135.8055877685547.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 2034.61915| val_0_mse: 2814.527587890625|  0:00:00s\n","epoch 1  | loss: 860.08851| val_0_mse: 1090.898681640625|  0:00:00s\n","epoch 2  | loss: 426.92753| val_0_mse: 1409.3865966796875|  0:00:01s\n","epoch 3  | loss: 377.77115| val_0_mse: 1147.5777587890625|  0:00:01s\n","epoch 4  | loss: 322.94449| val_0_mse: 1943.337890625|  0:00:02s\n","epoch 5  | loss: 305.58834| val_0_mse: 4523.97802734375|  0:00:02s\n","epoch 6  | loss: 305.9816| val_0_mse: 4204.89697265625|  0:00:02s\n","epoch 7  | loss: 279.00789| val_0_mse: 3615.123291015625|  0:00:03s\n","epoch 8  | loss: 261.61791| val_0_mse: 5703.58740234375|  0:00:03s\n","epoch 9  | loss: 268.80601| val_0_mse: 4497.87109375|  0:00:04s\n","epoch 10 | loss: 254.61651| val_0_mse: 5914.8603515625|  0:00:04s\n","epoch 11 | loss: 267.19874| val_0_mse: 5034.1201171875|  0:00:04s\n","\n","Early stopping occurred at epoch 11 with best_epoch = 1 and best_val_0_mse = 1090.898681640625\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 15:14:45,852] Trial 69 finished with value: 1090.898681640625 and parameters: {'n_d': 52, 'n_steps': 3, 'gamma': 1.7780454570664892, 'n_independent': 2, 'n_shared': 1, 'momentum': 0.08791636833932301}. Best is trial 33 with value: 135.8055877685547.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 1652.39084| val_0_mse: 35770.09765625|  0:00:00s\n","epoch 1  | loss: 487.03051| val_0_mse: 3974.5908203125|  0:00:01s\n","epoch 2  | loss: 371.1793| val_0_mse: 1998.034912109375|  0:00:02s\n","epoch 3  | loss: 366.87814| val_0_mse: 3689.6015625|  0:00:03s\n","epoch 4  | loss: 356.41403| val_0_mse: 1276.46240234375|  0:00:04s\n","epoch 5  | loss: 318.87948| val_0_mse: 811.2047119140625|  0:00:05s\n","epoch 6  | loss: 326.31622| val_0_mse: 1804.3433837890625|  0:00:05s\n","epoch 7  | loss: 309.93694| val_0_mse: 2483.608642578125|  0:00:06s\n","epoch 8  | loss: 295.86057| val_0_mse: 974.0712280273438|  0:00:07s\n","epoch 9  | loss: 275.46222| val_0_mse: 797.4683837890625|  0:00:08s\n","epoch 10 | loss: 285.80106| val_0_mse: 709.29345703125|  0:00:09s\n","epoch 11 | loss: 278.12898| val_0_mse: 708.6768188476562|  0:00:09s\n","epoch 12 | loss: 271.23253| val_0_mse: 747.4570922851562|  0:00:10s\n","epoch 13 | loss: 282.86925| val_0_mse: 814.6885375976562|  0:00:11s\n","epoch 14 | loss: 273.78899| val_0_mse: 520.7897338867188|  0:00:12s\n","epoch 15 | loss: 256.04703| val_0_mse: 677.7227783203125|  0:00:13s\n","epoch 16 | loss: 260.06259| val_0_mse: 722.2294921875|  0:00:14s\n","epoch 17 | loss: 278.29215| val_0_mse: 384.5076904296875|  0:00:14s\n","epoch 18 | loss: 245.60034| val_0_mse: 505.07208251953125|  0:00:15s\n","epoch 19 | loss: 242.27911| val_0_mse: 383.38885498046875|  0:00:16s\n","epoch 20 | loss: 238.4054| val_0_mse: 370.0046691894531|  0:00:17s\n","epoch 21 | loss: 238.9039| val_0_mse: 296.509521484375|  0:00:18s\n","epoch 22 | loss: 232.47439| val_0_mse: 300.45672607421875|  0:00:19s\n","epoch 23 | loss: 239.25115| val_0_mse: 309.6543884277344|  0:00:19s\n","epoch 24 | loss: 219.5063| val_0_mse: 330.1033020019531|  0:00:20s\n","epoch 25 | loss: 217.95998| val_0_mse: 289.90435791015625|  0:00:21s\n","epoch 26 | loss: 228.93348| val_0_mse: 264.18292236328125|  0:00:22s\n","epoch 27 | loss: 233.2038| val_0_mse: 265.6096496582031|  0:00:23s\n","epoch 28 | loss: 217.22991| val_0_mse: 244.53565979003906|  0:00:23s\n","epoch 29 | loss: 227.82818| val_0_mse: 271.7877502441406|  0:00:24s\n","epoch 30 | loss: 228.12284| val_0_mse: 239.48646545410156|  0:00:25s\n","epoch 31 | loss: 224.79809| val_0_mse: 248.77023315429688|  0:00:26s\n","epoch 32 | loss: 230.12596| val_0_mse: 218.07066345214844|  0:00:27s\n","epoch 33 | loss: 209.1883| val_0_mse: 259.8103942871094|  0:00:28s\n","epoch 34 | loss: 212.74058| val_0_mse: 227.259033203125|  0:00:28s\n","epoch 35 | loss: 216.18785| val_0_mse: 225.95144653320312|  0:00:29s\n","epoch 36 | loss: 219.84814| val_0_mse: 220.2080535888672|  0:00:30s\n","epoch 37 | loss: 216.60011| val_0_mse: 218.89901733398438|  0:00:31s\n","epoch 38 | loss: 203.79085| val_0_mse: 208.0649871826172|  0:00:31s\n","epoch 39 | loss: 206.7473| val_0_mse: 226.19033813476562|  0:00:32s\n","epoch 40 | loss: 204.79927| val_0_mse: 206.07269287109375|  0:00:33s\n","epoch 41 | loss: 202.02578| val_0_mse: 216.32623291015625|  0:00:34s\n","epoch 42 | loss: 202.29113| val_0_mse: 220.6494140625|  0:00:35s\n","epoch 43 | loss: 206.95227| val_0_mse: 205.15965270996094|  0:00:36s\n","epoch 44 | loss: 198.93649| val_0_mse: 217.732666015625|  0:00:36s\n","epoch 45 | loss: 198.03641| val_0_mse: 247.47901916503906|  0:00:37s\n","epoch 46 | loss: 199.73337| val_0_mse: 206.16555786132812|  0:00:38s\n","epoch 47 | loss: 198.06229| val_0_mse: 208.44671630859375|  0:00:39s\n","epoch 48 | loss: 203.94853| val_0_mse: 199.573486328125|  0:00:40s\n","epoch 49 | loss: 198.11361| val_0_mse: 233.4480438232422|  0:00:41s\n","epoch 50 | loss: 200.61243| val_0_mse: 279.3752136230469|  0:00:42s\n","epoch 51 | loss: 199.99765| val_0_mse: 197.2716827392578|  0:00:42s\n","epoch 52 | loss: 187.82007| val_0_mse: 203.8424530029297|  0:00:43s\n","epoch 53 | loss: 198.96571| val_0_mse: 214.65426635742188|  0:00:44s\n","epoch 54 | loss: 188.75391| val_0_mse: 206.6245574951172|  0:00:45s\n","epoch 55 | loss: 197.50282| val_0_mse: 193.97242736816406|  0:00:46s\n","epoch 56 | loss: 185.13504| val_0_mse: 197.50845336914062|  0:00:47s\n","epoch 57 | loss: 188.31344| val_0_mse: 200.9834747314453|  0:00:48s\n","epoch 58 | loss: 194.14198| val_0_mse: 197.84339904785156|  0:00:49s\n","epoch 59 | loss: 189.5038| val_0_mse: 199.48634338378906|  0:00:49s\n","epoch 60 | loss: 193.75303| val_0_mse: 216.36587524414062|  0:00:50s\n","epoch 61 | loss: 206.22641| val_0_mse: 196.96214294433594|  0:00:51s\n","epoch 62 | loss: 188.68964| val_0_mse: 193.3253631591797|  0:00:52s\n","epoch 63 | loss: 177.5746| val_0_mse: 186.55996704101562|  0:00:53s\n","epoch 64 | loss: 184.61787| val_0_mse: 194.1039276123047|  0:00:54s\n","epoch 65 | loss: 184.07939| val_0_mse: 215.8585662841797|  0:00:55s\n","epoch 66 | loss: 183.90134| val_0_mse: 199.36834716796875|  0:00:55s\n","epoch 67 | loss: 188.17036| val_0_mse: 198.8183135986328|  0:00:56s\n","epoch 68 | loss: 186.24957| val_0_mse: 220.30413818359375|  0:00:57s\n","epoch 69 | loss: 188.99533| val_0_mse: 224.1860809326172|  0:00:58s\n","epoch 70 | loss: 185.78746| val_0_mse: 199.0336456298828|  0:00:59s\n","epoch 71 | loss: 187.89227| val_0_mse: 185.032958984375|  0:01:00s\n","epoch 72 | loss: 178.59433| val_0_mse: 205.94627380371094|  0:01:00s\n","epoch 73 | loss: 171.42099| val_0_mse: 175.14581298828125|  0:01:01s\n","epoch 74 | loss: 171.25323| val_0_mse: 192.4640655517578|  0:01:02s\n","epoch 75 | loss: 171.01389| val_0_mse: 190.4109344482422|  0:01:03s\n","epoch 76 | loss: 170.65355| val_0_mse: 187.77340698242188|  0:01:04s\n","epoch 77 | loss: 167.64713| val_0_mse: 174.7178192138672|  0:01:05s\n","epoch 78 | loss: 170.26205| val_0_mse: 180.3011932373047|  0:01:06s\n","epoch 79 | loss: 175.9428| val_0_mse: 231.87777709960938|  0:01:06s\n","epoch 80 | loss: 172.06799| val_0_mse: 189.08392333984375|  0:01:07s\n","epoch 81 | loss: 186.46225| val_0_mse: 182.28866577148438|  0:01:08s\n","epoch 82 | loss: 170.20014| val_0_mse: 181.16659545898438|  0:01:09s\n","epoch 83 | loss: 170.2864| val_0_mse: 177.80548095703125|  0:01:10s\n","epoch 84 | loss: 169.8648| val_0_mse: 187.7079620361328|  0:01:11s\n","epoch 85 | loss: 183.47108| val_0_mse: 186.16561889648438|  0:01:11s\n","epoch 86 | loss: 164.49516| val_0_mse: 181.4015350341797|  0:01:12s\n","epoch 87 | loss: 173.48549| val_0_mse: 187.68104553222656|  0:01:13s\n","\n","Early stopping occurred at epoch 87 with best_epoch = 77 and best_val_0_mse = 174.7178192138672\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 15:16:00,021] Trial 70 finished with value: 174.7178192138672 and parameters: {'n_d': 62, 'n_steps': 4, 'gamma': 1.3382499029808328, 'n_independent': 3, 'n_shared': 4, 'momentum': 0.11642613355004149}. Best is trial 33 with value: 135.8055877685547.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 1586.25278| val_0_mse: 6679.16943359375|  0:00:00s\n","epoch 1  | loss: 497.73016| val_0_mse: 1566.564697265625|  0:00:01s\n","epoch 2  | loss: 383.29728| val_0_mse: 1786.1719970703125|  0:00:02s\n","epoch 3  | loss: 346.95643| val_0_mse: 2265.331787109375|  0:00:02s\n","epoch 4  | loss: 342.91855| val_0_mse: 2659.1201171875|  0:00:03s\n","epoch 5  | loss: 321.2939| val_0_mse: 2266.723876953125|  0:00:04s\n","epoch 6  | loss: 306.07973| val_0_mse: 1845.1390380859375|  0:00:04s\n","epoch 7  | loss: 299.88048| val_0_mse: 698.3060302734375|  0:00:05s\n","epoch 8  | loss: 282.32211| val_0_mse: 562.4744873046875|  0:00:06s\n","epoch 9  | loss: 308.09197| val_0_mse: 1089.8033447265625|  0:00:06s\n","epoch 10 | loss: 291.43241| val_0_mse: 762.2039184570312|  0:00:07s\n","epoch 11 | loss: 253.91968| val_0_mse: 506.188720703125|  0:00:08s\n","epoch 12 | loss: 246.55077| val_0_mse: 916.0568237304688|  0:00:08s\n","epoch 13 | loss: 237.25759| val_0_mse: 789.9888916015625|  0:00:09s\n","epoch 14 | loss: 251.44937| val_0_mse: 1217.5247802734375|  0:00:10s\n","epoch 15 | loss: 237.5672| val_0_mse: 782.3798217773438|  0:00:11s\n","epoch 16 | loss: 238.54659| val_0_mse: 388.37353515625|  0:00:11s\n","epoch 17 | loss: 232.38014| val_0_mse: 792.5944213867188|  0:00:12s\n","epoch 18 | loss: 216.568 | val_0_mse: 657.4808959960938|  0:00:13s\n","epoch 19 | loss: 207.77016| val_0_mse: 474.4739074707031|  0:00:13s\n","epoch 20 | loss: 211.2831| val_0_mse: 891.864990234375|  0:00:14s\n","epoch 21 | loss: 214.72147| val_0_mse: 492.8103332519531|  0:00:15s\n","epoch 22 | loss: 207.5728| val_0_mse: 469.76458740234375|  0:00:15s\n","epoch 23 | loss: 202.77121| val_0_mse: 568.8668823242188|  0:00:16s\n","epoch 24 | loss: 213.98522| val_0_mse: 268.36260986328125|  0:00:17s\n","epoch 25 | loss: 209.26288| val_0_mse: 309.9391174316406|  0:00:17s\n","epoch 26 | loss: 199.74528| val_0_mse: 240.8353271484375|  0:00:18s\n","epoch 27 | loss: 205.54038| val_0_mse: 240.2648468017578|  0:00:19s\n","epoch 28 | loss: 208.59401| val_0_mse: 269.9440002441406|  0:00:19s\n","epoch 29 | loss: 201.09134| val_0_mse: 224.01339721679688|  0:00:20s\n","epoch 30 | loss: 199.47786| val_0_mse: 242.4178924560547|  0:00:21s\n","epoch 31 | loss: 209.69462| val_0_mse: 289.2875671386719|  0:00:22s\n","epoch 32 | loss: 194.16175| val_0_mse: 231.5651397705078|  0:00:22s\n","epoch 33 | loss: 204.57081| val_0_mse: 223.4506072998047|  0:00:23s\n","epoch 34 | loss: 191.98341| val_0_mse: 217.57615661621094|  0:00:24s\n","epoch 35 | loss: 193.98814| val_0_mse: 203.09957885742188|  0:00:24s\n","epoch 36 | loss: 187.60703| val_0_mse: 226.01437377929688|  0:00:25s\n","epoch 37 | loss: 188.62365| val_0_mse: 199.48489379882812|  0:00:26s\n","epoch 38 | loss: 186.20497| val_0_mse: 214.02540588378906|  0:00:27s\n","epoch 39 | loss: 186.02686| val_0_mse: 200.18106079101562|  0:00:27s\n","epoch 40 | loss: 172.7875| val_0_mse: 217.26133728027344|  0:00:28s\n","epoch 41 | loss: 173.08044| val_0_mse: 196.7032928466797|  0:00:29s\n","epoch 42 | loss: 168.98428| val_0_mse: 187.97897338867188|  0:00:29s\n","epoch 43 | loss: 176.86538| val_0_mse: 191.15823364257812|  0:00:30s\n","epoch 44 | loss: 173.76352| val_0_mse: 188.1184844970703|  0:00:31s\n","epoch 45 | loss: 173.1112| val_0_mse: 181.26834106445312|  0:00:31s\n","epoch 46 | loss: 176.81429| val_0_mse: 197.1092529296875|  0:00:32s\n","epoch 47 | loss: 170.02482| val_0_mse: 173.51480102539062|  0:00:33s\n","epoch 48 | loss: 171.35466| val_0_mse: 173.6621856689453|  0:00:33s\n","epoch 49 | loss: 175.1648| val_0_mse: 190.62107849121094|  0:00:34s\n","epoch 50 | loss: 177.54079| val_0_mse: 191.89845275878906|  0:00:35s\n","epoch 51 | loss: 170.66496| val_0_mse: 185.45184326171875|  0:00:35s\n","epoch 52 | loss: 166.38254| val_0_mse: 177.57200622558594|  0:00:36s\n","epoch 53 | loss: 169.43697| val_0_mse: 210.41696166992188|  0:00:37s\n","epoch 54 | loss: 164.99825| val_0_mse: 170.2206268310547|  0:00:37s\n","epoch 55 | loss: 155.31355| val_0_mse: 178.58236694335938|  0:00:38s\n","epoch 56 | loss: 154.17238| val_0_mse: 170.00758361816406|  0:00:39s\n","epoch 57 | loss: 168.75037| val_0_mse: 184.06912231445312|  0:00:40s\n","epoch 58 | loss: 163.15562| val_0_mse: 172.8667449951172|  0:00:40s\n","epoch 59 | loss: 155.78899| val_0_mse: 167.35816955566406|  0:00:41s\n","epoch 60 | loss: 154.97457| val_0_mse: 162.31207275390625|  0:00:42s\n","epoch 61 | loss: 154.18227| val_0_mse: 163.63323974609375|  0:00:42s\n","epoch 62 | loss: 152.83669| val_0_mse: 171.90411376953125|  0:00:43s\n","epoch 63 | loss: 155.90973| val_0_mse: 177.84869384765625|  0:00:44s\n","epoch 64 | loss: 152.42641| val_0_mse: 181.8850860595703|  0:00:44s\n","epoch 65 | loss: 166.81023| val_0_mse: 187.0404815673828|  0:00:45s\n","epoch 66 | loss: 158.75144| val_0_mse: 170.10757446289062|  0:00:46s\n","epoch 67 | loss: 154.87694| val_0_mse: 174.22305297851562|  0:00:47s\n","epoch 68 | loss: 152.98236| val_0_mse: 162.0591278076172|  0:00:47s\n","epoch 69 | loss: 147.80908| val_0_mse: 166.91964721679688|  0:00:48s\n","epoch 70 | loss: 151.95534| val_0_mse: 168.2797393798828|  0:00:49s\n","epoch 71 | loss: 150.25019| val_0_mse: 178.15057373046875|  0:00:49s\n","epoch 72 | loss: 147.15434| val_0_mse: 167.02268981933594|  0:00:50s\n","epoch 73 | loss: 148.70765| val_0_mse: 164.8586883544922|  0:00:51s\n","epoch 74 | loss: 145.61043| val_0_mse: 164.67552185058594|  0:00:52s\n","epoch 75 | loss: 139.81494| val_0_mse: 151.6079559326172|  0:00:52s\n","epoch 76 | loss: 139.50299| val_0_mse: 160.40774536132812|  0:00:53s\n","epoch 77 | loss: 157.62005| val_0_mse: 166.3116455078125|  0:00:54s\n","epoch 78 | loss: 146.85605| val_0_mse: 169.96273803710938|  0:00:54s\n","epoch 79 | loss: 146.3358| val_0_mse: 169.3556671142578|  0:00:55s\n","epoch 80 | loss: 153.22901| val_0_mse: 155.6499786376953|  0:00:56s\n","epoch 81 | loss: 147.02821| val_0_mse: 166.8134307861328|  0:00:57s\n","epoch 82 | loss: 147.76979| val_0_mse: 162.95166015625|  0:00:57s\n","epoch 83 | loss: 140.2186| val_0_mse: 152.89064025878906|  0:00:58s\n","epoch 84 | loss: 146.07064| val_0_mse: 152.8164520263672|  0:00:59s\n","epoch 85 | loss: 143.52896| val_0_mse: 153.45932006835938|  0:01:00s\n","\n","Early stopping occurred at epoch 85 with best_epoch = 75 and best_val_0_mse = 151.6079559326172\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 15:17:00,466] Trial 71 finished with value: 151.6079559326172 and parameters: {'n_d': 62, 'n_steps': 3, 'gamma': 1.55013080872944, 'n_independent': 3, 'n_shared': 4, 'momentum': 0.1294239301003613}. Best is trial 33 with value: 135.8055877685547.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 1729.60334| val_0_mse: 12473.12109375|  0:00:00s\n","epoch 1  | loss: 502.42161| val_0_mse: 2126.79541015625|  0:00:01s\n","epoch 2  | loss: 354.9087| val_0_mse: 3644.5791015625|  0:00:02s\n","epoch 3  | loss: 331.62544| val_0_mse: 2516.275390625|  0:00:03s\n","epoch 4  | loss: 304.79101| val_0_mse: 1287.4771728515625|  0:00:03s\n","epoch 5  | loss: 291.25185| val_0_mse: 1363.671630859375|  0:00:04s\n","epoch 6  | loss: 277.45365| val_0_mse: 1965.1453857421875|  0:00:05s\n","epoch 7  | loss: 267.47165| val_0_mse: 2833.63818359375|  0:00:06s\n","epoch 8  | loss: 263.91594| val_0_mse: 1965.16162109375|  0:00:06s\n","epoch 9  | loss: 259.54208| val_0_mse: 943.0352172851562|  0:00:07s\n","epoch 10 | loss: 282.59876| val_0_mse: 846.9501342773438|  0:00:08s\n","epoch 11 | loss: 257.70919| val_0_mse: 1203.8260498046875|  0:00:09s\n","epoch 12 | loss: 255.6064| val_0_mse: 1058.108642578125|  0:00:10s\n","epoch 13 | loss: 248.68436| val_0_mse: 1094.5147705078125|  0:00:10s\n","epoch 14 | loss: 242.58022| val_0_mse: 392.1564025878906|  0:00:11s\n","epoch 15 | loss: 240.16902| val_0_mse: 447.9035339355469|  0:00:12s\n","epoch 16 | loss: 230.6956| val_0_mse: 528.6602783203125|  0:00:13s\n","epoch 17 | loss: 237.5113| val_0_mse: 572.0115356445312|  0:00:13s\n","epoch 18 | loss: 234.39657| val_0_mse: 666.0598754882812|  0:00:14s\n","epoch 19 | loss: 226.86964| val_0_mse: 449.0353088378906|  0:00:15s\n","epoch 20 | loss: 237.94583| val_0_mse: 418.8135070800781|  0:00:16s\n","epoch 21 | loss: 239.18496| val_0_mse: 352.9267883300781|  0:00:17s\n","epoch 22 | loss: 248.25909| val_0_mse: 355.1439208984375|  0:00:17s\n","epoch 23 | loss: 224.51573| val_0_mse: 336.6518249511719|  0:00:18s\n","epoch 24 | loss: 229.4561| val_0_mse: 319.8591003417969|  0:00:19s\n","epoch 25 | loss: 226.93096| val_0_mse: 288.4474182128906|  0:00:20s\n","epoch 26 | loss: 221.15654| val_0_mse: 325.9999694824219|  0:00:20s\n","epoch 27 | loss: 222.73723| val_0_mse: 284.9266357421875|  0:00:21s\n","epoch 28 | loss: 215.67321| val_0_mse: 254.36517333984375|  0:00:22s\n","epoch 29 | loss: 209.45627| val_0_mse: 234.4285125732422|  0:00:23s\n","epoch 30 | loss: 218.24897| val_0_mse: 244.5545654296875|  0:00:23s\n","epoch 31 | loss: 220.00365| val_0_mse: 291.14459228515625|  0:00:24s\n","epoch 32 | loss: 220.46741| val_0_mse: 269.78369140625|  0:00:25s\n","epoch 33 | loss: 220.04162| val_0_mse: 260.7113342285156|  0:00:26s\n","epoch 34 | loss: 221.60124| val_0_mse: 236.0585174560547|  0:00:26s\n","epoch 35 | loss: 214.64247| val_0_mse: 226.88546752929688|  0:00:27s\n","epoch 36 | loss: 211.9601| val_0_mse: 228.52975463867188|  0:00:28s\n","epoch 37 | loss: 208.7714| val_0_mse: 245.50802612304688|  0:00:29s\n","epoch 38 | loss: 214.84771| val_0_mse: 235.77882385253906|  0:00:30s\n","epoch 39 | loss: 217.85826| val_0_mse: 217.38937377929688|  0:00:30s\n","epoch 40 | loss: 204.50891| val_0_mse: 199.9056854248047|  0:00:31s\n","epoch 41 | loss: 206.28174| val_0_mse: 200.01246643066406|  0:00:32s\n","epoch 42 | loss: 205.53638| val_0_mse: 195.46803283691406|  0:00:33s\n","epoch 43 | loss: 198.42835| val_0_mse: 199.75706481933594|  0:00:33s\n","epoch 44 | loss: 193.21306| val_0_mse: 194.22317504882812|  0:00:34s\n","epoch 45 | loss: 189.39872| val_0_mse: 235.71188354492188|  0:00:35s\n","epoch 46 | loss: 193.93642| val_0_mse: 200.03611755371094|  0:00:36s\n","epoch 47 | loss: 195.98973| val_0_mse: 188.99920654296875|  0:00:37s\n","epoch 48 | loss: 201.0106| val_0_mse: 194.50965881347656|  0:00:37s\n","epoch 49 | loss: 190.23042| val_0_mse: 181.823974609375|  0:00:38s\n","epoch 50 | loss: 187.00588| val_0_mse: 194.1388397216797|  0:00:39s\n","epoch 51 | loss: 188.85519| val_0_mse: 192.8804473876953|  0:00:40s\n","epoch 52 | loss: 183.73965| val_0_mse: 175.7153778076172|  0:00:41s\n","epoch 53 | loss: 183.91263| val_0_mse: 183.08738708496094|  0:00:41s\n","epoch 54 | loss: 172.73761| val_0_mse: 188.3769989013672|  0:00:42s\n","epoch 55 | loss: 181.21903| val_0_mse: 180.12472534179688|  0:00:43s\n","epoch 56 | loss: 179.90641| val_0_mse: 193.8900604248047|  0:00:44s\n","epoch 57 | loss: 178.10775| val_0_mse: 233.8137969970703|  0:00:45s\n","epoch 58 | loss: 180.93875| val_0_mse: 193.2218017578125|  0:00:45s\n","epoch 59 | loss: 182.18705| val_0_mse: 181.4373779296875|  0:00:46s\n","epoch 60 | loss: 180.16791| val_0_mse: 250.06509399414062|  0:00:47s\n","epoch 61 | loss: 174.7802| val_0_mse: 186.68661499023438|  0:00:48s\n","epoch 62 | loss: 176.28639| val_0_mse: 203.93594360351562|  0:00:48s\n","\n","Early stopping occurred at epoch 62 with best_epoch = 52 and best_val_0_mse = 175.7153778076172\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 15:17:49,922] Trial 72 finished with value: 175.7153778076172 and parameters: {'n_d': 60, 'n_steps': 3, 'gamma': 1.4300687250568767, 'n_independent': 3, 'n_shared': 5, 'momentum': 0.1450434595432174}. Best is trial 33 with value: 135.8055877685547.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 1619.43589| val_0_mse: 55647.28125|  0:00:00s\n","epoch 1  | loss: 479.77101| val_0_mse: 7949.6904296875|  0:00:01s\n","epoch 2  | loss: 370.10131| val_0_mse: 1075.1878662109375|  0:00:02s\n","epoch 3  | loss: 336.01675| val_0_mse: 2167.215576171875|  0:00:02s\n","epoch 4  | loss: 297.14171| val_0_mse: 5029.38671875|  0:00:03s\n","epoch 5  | loss: 271.82084| val_0_mse: 2186.865478515625|  0:00:04s\n","epoch 6  | loss: 275.16863| val_0_mse: 3223.89404296875|  0:00:05s\n","epoch 7  | loss: 263.29283| val_0_mse: 1872.5015869140625|  0:00:05s\n","epoch 8  | loss: 246.46952| val_0_mse: 4056.552734375|  0:00:06s\n","epoch 9  | loss: 233.0047| val_0_mse: 7322.5546875|  0:00:07s\n","epoch 10 | loss: 221.25433| val_0_mse: 1744.281494140625|  0:00:07s\n","epoch 11 | loss: 218.95494| val_0_mse: 1828.171142578125|  0:00:08s\n","epoch 12 | loss: 216.36834| val_0_mse: 2698.849365234375|  0:00:09s\n","\n","Early stopping occurred at epoch 12 with best_epoch = 2 and best_val_0_mse = 1075.1878662109375\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 15:17:59,445] Trial 73 finished with value: 1075.1878662109375 and parameters: {'n_d': 58, 'n_steps': 3, 'gamma': 1.3955844752663944, 'n_independent': 3, 'n_shared': 4, 'momentum': 0.12404942262887979}. Best is trial 33 with value: 135.8055877685547.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 1609.27961| val_0_mse: 24236.1875|  0:00:00s\n","epoch 1  | loss: 441.96606| val_0_mse: 7292.111328125|  0:00:01s\n","epoch 2  | loss: 363.68686| val_0_mse: 11039.1953125|  0:00:02s\n","epoch 3  | loss: 329.68699| val_0_mse: 10963.109375|  0:00:02s\n","epoch 4  | loss: 298.88975| val_0_mse: 6119.55029296875|  0:00:03s\n","epoch 5  | loss: 289.53833| val_0_mse: 4489.4482421875|  0:00:04s\n","epoch 6  | loss: 276.4381| val_0_mse: 2344.004150390625|  0:00:04s\n","epoch 7  | loss: 261.07603| val_0_mse: 1801.11474609375|  0:00:05s\n","epoch 8  | loss: 260.58485| val_0_mse: 2591.4677734375|  0:00:06s\n","epoch 9  | loss: 239.61154| val_0_mse: 2523.037109375|  0:00:06s\n","epoch 10 | loss: 237.2575| val_0_mse: 1634.9205322265625|  0:00:07s\n","epoch 11 | loss: 227.98719| val_0_mse: 2269.8115234375|  0:00:08s\n","epoch 12 | loss: 231.0689| val_0_mse: 796.94921875|  0:00:09s\n","epoch 13 | loss: 221.64348| val_0_mse: 573.0447387695312|  0:00:09s\n","epoch 14 | loss: 214.79363| val_0_mse: 423.7571716308594|  0:00:10s\n","epoch 15 | loss: 221.00604| val_0_mse: 429.3503112792969|  0:00:11s\n","epoch 16 | loss: 208.44408| val_0_mse: 432.6944274902344|  0:00:11s\n","epoch 17 | loss: 204.86959| val_0_mse: 333.7013854980469|  0:00:12s\n","epoch 18 | loss: 209.77491| val_0_mse: 383.4433898925781|  0:00:13s\n","epoch 19 | loss: 207.82057| val_0_mse: 302.244140625|  0:00:14s\n","epoch 20 | loss: 203.52904| val_0_mse: 323.7282409667969|  0:00:14s\n","epoch 21 | loss: 201.01713| val_0_mse: 315.5053405761719|  0:00:15s\n","epoch 22 | loss: 198.55082| val_0_mse: 332.05865478515625|  0:00:16s\n","epoch 23 | loss: 195.55896| val_0_mse: 301.6679382324219|  0:00:16s\n","epoch 24 | loss: 190.59238| val_0_mse: 329.2291564941406|  0:00:17s\n","epoch 25 | loss: 187.78203| val_0_mse: 270.0572509765625|  0:00:18s\n","epoch 26 | loss: 191.79879| val_0_mse: 256.2626647949219|  0:00:19s\n","epoch 27 | loss: 176.57396| val_0_mse: 272.233154296875|  0:00:19s\n","epoch 28 | loss: 175.37605| val_0_mse: 251.43246459960938|  0:00:20s\n","epoch 29 | loss: 184.79032| val_0_mse: 261.984130859375|  0:00:21s\n","epoch 30 | loss: 189.14806| val_0_mse: 277.9519958496094|  0:00:21s\n","epoch 31 | loss: 195.21449| val_0_mse: 245.8701934814453|  0:00:22s\n","epoch 32 | loss: 172.96604| val_0_mse: 223.71893310546875|  0:00:23s\n","epoch 33 | loss: 185.73152| val_0_mse: 211.45933532714844|  0:00:23s\n","epoch 34 | loss: 170.18755| val_0_mse: 190.41546630859375|  0:00:24s\n","epoch 35 | loss: 176.15565| val_0_mse: 252.07374572753906|  0:00:25s\n","epoch 36 | loss: 160.39183| val_0_mse: 252.677734375|  0:00:25s\n","epoch 37 | loss: 162.8178| val_0_mse: 187.77645874023438|  0:00:26s\n","epoch 38 | loss: 157.49954| val_0_mse: 240.3150177001953|  0:00:27s\n","epoch 39 | loss: 163.0829| val_0_mse: 237.0471649169922|  0:00:28s\n","epoch 40 | loss: 161.80012| val_0_mse: 198.4390411376953|  0:00:28s\n","epoch 41 | loss: 161.99364| val_0_mse: 177.63963317871094|  0:00:29s\n","epoch 42 | loss: 164.63716| val_0_mse: 179.54307556152344|  0:00:30s\n","epoch 43 | loss: 160.70533| val_0_mse: 163.63624572753906|  0:00:30s\n","epoch 44 | loss: 154.70074| val_0_mse: 158.83148193359375|  0:00:31s\n","epoch 45 | loss: 160.98003| val_0_mse: 174.87564086914062|  0:00:32s\n","epoch 46 | loss: 161.97433| val_0_mse: 168.61167907714844|  0:00:32s\n","epoch 47 | loss: 157.93152| val_0_mse: 202.77090454101562|  0:00:33s\n","epoch 48 | loss: 152.48576| val_0_mse: 173.75616455078125|  0:00:34s\n","epoch 49 | loss: 147.35796| val_0_mse: 173.90415954589844|  0:00:35s\n","epoch 50 | loss: 154.88053| val_0_mse: 177.0741729736328|  0:00:35s\n","epoch 51 | loss: 147.33477| val_0_mse: 175.2528076171875|  0:00:36s\n","epoch 52 | loss: 142.52363| val_0_mse: 150.86729431152344|  0:00:37s\n","epoch 53 | loss: 145.85759| val_0_mse: 155.6437225341797|  0:00:37s\n","epoch 54 | loss: 140.40282| val_0_mse: 153.98497009277344|  0:00:38s\n","epoch 55 | loss: 135.97575| val_0_mse: 156.97117614746094|  0:00:39s\n","epoch 56 | loss: 139.76223| val_0_mse: 167.77696228027344|  0:00:39s\n","epoch 57 | loss: 139.94649| val_0_mse: 258.46435546875|  0:00:40s\n","epoch 58 | loss: 153.33675| val_0_mse: 158.99252319335938|  0:00:41s\n","epoch 59 | loss: 145.74871| val_0_mse: 215.23326110839844|  0:00:42s\n","epoch 60 | loss: 142.86486| val_0_mse: 152.46434020996094|  0:00:42s\n","epoch 61 | loss: 141.8287| val_0_mse: 154.47975158691406|  0:00:43s\n","epoch 62 | loss: 141.02132| val_0_mse: 151.2086639404297|  0:00:44s\n","\n","Early stopping occurred at epoch 62 with best_epoch = 52 and best_val_0_mse = 150.86729431152344\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 15:18:44,068] Trial 74 finished with value: 150.86729431152344 and parameters: {'n_d': 64, 'n_steps': 3, 'gamma': 1.5132893621123567, 'n_independent': 3, 'n_shared': 4, 'momentum': 0.13463437390646832}. Best is trial 33 with value: 135.8055877685547.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 1784.74424| val_0_mse: 7792.05126953125|  0:00:00s\n","epoch 1  | loss: 544.813 | val_0_mse: 3056.52587890625|  0:00:01s\n","epoch 2  | loss: 419.35136| val_0_mse: 2715.54296875|  0:00:01s\n","epoch 3  | loss: 346.79967| val_0_mse: 3523.3623046875|  0:00:02s\n","epoch 4  | loss: 318.89536| val_0_mse: 1890.587646484375|  0:00:03s\n","epoch 5  | loss: 284.81855| val_0_mse: 850.463134765625|  0:00:03s\n","epoch 6  | loss: 285.57242| val_0_mse: 669.801513671875|  0:00:04s\n","epoch 7  | loss: 262.54027| val_0_mse: 1092.619873046875|  0:00:05s\n","epoch 8  | loss: 269.95042| val_0_mse: 719.7893676757812|  0:00:05s\n","epoch 9  | loss: 251.06168| val_0_mse: 622.6824951171875|  0:00:06s\n","epoch 10 | loss: 248.70692| val_0_mse: 837.7687377929688|  0:00:07s\n","epoch 11 | loss: 257.33122| val_0_mse: 595.78173828125|  0:00:07s\n","epoch 12 | loss: 244.92709| val_0_mse: 615.60302734375|  0:00:08s\n","epoch 13 | loss: 234.95533| val_0_mse: 582.5065307617188|  0:00:09s\n","epoch 14 | loss: 235.78044| val_0_mse: 498.5572814941406|  0:00:09s\n","epoch 15 | loss: 238.45521| val_0_mse: 644.2426147460938|  0:00:10s\n","epoch 16 | loss: 237.03948| val_0_mse: 527.4496459960938|  0:00:11s\n","epoch 17 | loss: 232.44119| val_0_mse: 430.6853942871094|  0:00:11s\n","epoch 18 | loss: 229.87025| val_0_mse: 282.1813659667969|  0:00:12s\n","epoch 19 | loss: 218.84849| val_0_mse: 277.6737060546875|  0:00:13s\n","epoch 20 | loss: 226.22926| val_0_mse: 282.1188659667969|  0:00:13s\n","epoch 21 | loss: 222.91674| val_0_mse: 267.4190979003906|  0:00:14s\n","epoch 22 | loss: 204.8174| val_0_mse: 260.2103271484375|  0:00:15s\n","epoch 23 | loss: 202.30738| val_0_mse: 233.0924072265625|  0:00:15s\n","epoch 24 | loss: 199.26587| val_0_mse: 267.0762023925781|  0:00:16s\n","epoch 25 | loss: 201.45019| val_0_mse: 268.0404357910156|  0:00:17s\n","epoch 26 | loss: 206.49982| val_0_mse: 226.76272583007812|  0:00:17s\n","epoch 27 | loss: 208.24568| val_0_mse: 283.2825012207031|  0:00:18s\n","epoch 28 | loss: 204.06612| val_0_mse: 213.58822631835938|  0:00:19s\n","epoch 29 | loss: 195.26329| val_0_mse: 203.65858459472656|  0:00:19s\n","epoch 30 | loss: 192.4317| val_0_mse: 201.74920654296875|  0:00:20s\n","epoch 31 | loss: 188.96941| val_0_mse: 200.96771240234375|  0:00:21s\n","epoch 32 | loss: 193.62923| val_0_mse: 207.7789764404297|  0:00:21s\n","epoch 33 | loss: 192.24908| val_0_mse: 201.21873474121094|  0:00:22s\n","epoch 34 | loss: 186.95866| val_0_mse: 229.6215057373047|  0:00:23s\n","epoch 35 | loss: 192.42811| val_0_mse: 196.10792541503906|  0:00:23s\n","epoch 36 | loss: 181.60797| val_0_mse: 191.89418029785156|  0:00:24s\n","epoch 37 | loss: 187.90648| val_0_mse: 196.8188934326172|  0:00:25s\n","epoch 38 | loss: 185.9497| val_0_mse: 200.23390197753906|  0:00:25s\n","epoch 39 | loss: 180.45189| val_0_mse: 211.5266571044922|  0:00:26s\n","epoch 40 | loss: 190.80074| val_0_mse: 195.16293334960938|  0:00:26s\n","epoch 41 | loss: 185.36223| val_0_mse: 184.97607421875|  0:00:27s\n","epoch 42 | loss: 177.41666| val_0_mse: 190.38389587402344|  0:00:28s\n","epoch 43 | loss: 185.61721| val_0_mse: 193.48049926757812|  0:00:28s\n","epoch 44 | loss: 172.60185| val_0_mse: 183.55677795410156|  0:00:29s\n","epoch 45 | loss: 175.37526| val_0_mse: 182.62884521484375|  0:00:30s\n","epoch 46 | loss: 164.29728| val_0_mse: 187.97796630859375|  0:00:30s\n","epoch 47 | loss: 168.66235| val_0_mse: 176.30685424804688|  0:00:31s\n","epoch 48 | loss: 173.42351| val_0_mse: 185.57650756835938|  0:00:32s\n","epoch 49 | loss: 170.40777| val_0_mse: 186.0759735107422|  0:00:32s\n","epoch 50 | loss: 175.70517| val_0_mse: 197.345947265625|  0:00:33s\n","epoch 51 | loss: 172.61952| val_0_mse: 177.2256622314453|  0:00:33s\n","epoch 52 | loss: 166.26562| val_0_mse: 189.63343811035156|  0:00:34s\n","epoch 53 | loss: 167.744 | val_0_mse: 187.12135314941406|  0:00:35s\n","epoch 54 | loss: 169.22636| val_0_mse: 194.4456024169922|  0:00:35s\n","epoch 55 | loss: 168.44649| val_0_mse: 191.91439819335938|  0:00:36s\n","epoch 56 | loss: 166.31012| val_0_mse: 171.84652709960938|  0:00:37s\n","epoch 57 | loss: 159.62761| val_0_mse: 174.5261993408203|  0:00:37s\n","epoch 58 | loss: 163.65977| val_0_mse: 173.99615478515625|  0:00:38s\n","epoch 59 | loss: 159.66678| val_0_mse: 168.89198303222656|  0:00:39s\n","epoch 60 | loss: 159.67623| val_0_mse: 175.35714721679688|  0:00:39s\n","epoch 61 | loss: 161.67388| val_0_mse: 206.8521728515625|  0:00:40s\n","epoch 62 | loss: 170.44338| val_0_mse: 199.72630310058594|  0:00:40s\n","epoch 63 | loss: 181.67909| val_0_mse: 172.93533325195312|  0:00:41s\n","epoch 64 | loss: 173.3966| val_0_mse: 176.04876708984375|  0:00:42s\n","epoch 65 | loss: 163.1245| val_0_mse: 177.1201934814453|  0:00:42s\n","epoch 66 | loss: 162.88698| val_0_mse: 181.32518005371094|  0:00:43s\n","epoch 67 | loss: 156.46337| val_0_mse: 178.28465270996094|  0:00:44s\n","epoch 68 | loss: 152.93626| val_0_mse: 184.24130249023438|  0:00:44s\n","epoch 69 | loss: 156.1669| val_0_mse: 177.990234375|  0:00:45s\n","\n","Early stopping occurred at epoch 69 with best_epoch = 59 and best_val_0_mse = 168.89198303222656\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 15:19:29,758] Trial 75 finished with value: 168.89198303222656 and parameters: {'n_d': 55, 'n_steps': 3, 'gamma': 1.6246280903720791, 'n_independent': 3, 'n_shared': 3, 'momentum': 0.3680733492299278}. Best is trial 33 with value: 135.8055877685547.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 1443.4523| val_0_mse: 583546.5|  0:00:00s\n","epoch 1  | loss: 507.97237| val_0_mse: 3671.90966796875|  0:00:01s\n","epoch 2  | loss: 405.42795| val_0_mse: 1256.2386474609375|  0:00:02s\n","epoch 3  | loss: 390.62485| val_0_mse: 1665.1015625|  0:00:02s\n","epoch 4  | loss: 354.69805| val_0_mse: 1076.862060546875|  0:00:03s\n","epoch 5  | loss: 318.12008| val_0_mse: 646.1403198242188|  0:00:04s\n","epoch 6  | loss: 302.37083| val_0_mse: 591.6994018554688|  0:00:05s\n","epoch 7  | loss: 288.91309| val_0_mse: 582.7766723632812|  0:00:05s\n","epoch 8  | loss: 279.91496| val_0_mse: 833.1264038085938|  0:00:06s\n","epoch 9  | loss: 263.79768| val_0_mse: 721.1223754882812|  0:00:07s\n","epoch 10 | loss: 268.16056| val_0_mse: 533.9508056640625|  0:00:08s\n","epoch 11 | loss: 276.01075| val_0_mse: 670.7896728515625|  0:00:09s\n","epoch 12 | loss: 269.01879| val_0_mse: 621.4728393554688|  0:00:09s\n","epoch 13 | loss: 245.8139| val_0_mse: 561.5918579101562|  0:00:10s\n","epoch 14 | loss: 238.89345| val_0_mse: 631.2529907226562|  0:00:11s\n","epoch 15 | loss: 225.3955| val_0_mse: 676.60693359375|  0:00:12s\n","epoch 16 | loss: 223.09399| val_0_mse: 668.9474487304688|  0:00:12s\n","epoch 17 | loss: 217.11615| val_0_mse: 454.7733459472656|  0:00:13s\n","epoch 18 | loss: 225.69274| val_0_mse: 508.23223876953125|  0:00:14s\n","epoch 19 | loss: 219.18244| val_0_mse: 497.689453125|  0:00:15s\n","epoch 20 | loss: 210.56486| val_0_mse: 473.3065490722656|  0:00:15s\n","epoch 21 | loss: 207.75626| val_0_mse: 492.6405334472656|  0:00:16s\n","epoch 22 | loss: 221.37579| val_0_mse: 449.0345458984375|  0:00:17s\n","epoch 23 | loss: 203.27434| val_0_mse: 396.9590148925781|  0:00:18s\n","epoch 24 | loss: 211.22402| val_0_mse: 345.0304870605469|  0:00:19s\n","epoch 25 | loss: 194.93441| val_0_mse: 452.79351806640625|  0:00:19s\n","epoch 26 | loss: 196.47074| val_0_mse: 403.0681457519531|  0:00:20s\n","epoch 27 | loss: 192.86843| val_0_mse: 353.75054931640625|  0:00:21s\n","epoch 28 | loss: 191.79979| val_0_mse: 304.78375244140625|  0:00:22s\n","epoch 29 | loss: 191.23345| val_0_mse: 307.32513427734375|  0:00:22s\n","epoch 30 | loss: 198.72055| val_0_mse: 277.09930419921875|  0:00:23s\n","epoch 31 | loss: 188.77808| val_0_mse: 386.71551513671875|  0:00:24s\n","epoch 32 | loss: 189.53935| val_0_mse: 359.74261474609375|  0:00:25s\n","epoch 33 | loss: 194.06417| val_0_mse: 285.53472900390625|  0:00:25s\n","epoch 34 | loss: 190.62529| val_0_mse: 254.34605407714844|  0:00:26s\n","epoch 35 | loss: 192.69281| val_0_mse: 244.52914428710938|  0:00:27s\n","epoch 36 | loss: 191.68462| val_0_mse: 217.66334533691406|  0:00:28s\n","epoch 37 | loss: 191.31508| val_0_mse: 231.00135803222656|  0:00:28s\n","epoch 38 | loss: 188.19284| val_0_mse: 235.11676025390625|  0:00:29s\n","epoch 39 | loss: 186.16026| val_0_mse: 190.03724670410156|  0:00:30s\n","epoch 40 | loss: 191.08659| val_0_mse: 198.9539337158203|  0:00:31s\n","epoch 41 | loss: 176.39506| val_0_mse: 190.5176544189453|  0:00:31s\n","epoch 42 | loss: 178.60465| val_0_mse: 193.78216552734375|  0:00:32s\n","epoch 43 | loss: 171.99091| val_0_mse: 192.4340057373047|  0:00:33s\n","epoch 44 | loss: 178.86985| val_0_mse: 181.84933471679688|  0:00:34s\n","epoch 45 | loss: 183.99074| val_0_mse: 188.0313262939453|  0:00:35s\n","epoch 46 | loss: 171.35167| val_0_mse: 230.97239685058594|  0:00:35s\n","epoch 47 | loss: 179.15757| val_0_mse: 220.66128540039062|  0:00:36s\n","epoch 48 | loss: 180.13908| val_0_mse: 226.0323944091797|  0:00:37s\n","epoch 49 | loss: 182.45657| val_0_mse: 221.22946166992188|  0:00:37s\n","epoch 50 | loss: 172.61817| val_0_mse: 243.69674682617188|  0:00:38s\n","epoch 51 | loss: 172.81322| val_0_mse: 177.52760314941406|  0:00:39s\n","epoch 52 | loss: 166.20031| val_0_mse: 184.20150756835938|  0:00:40s\n","epoch 53 | loss: 166.76275| val_0_mse: 187.9432373046875|  0:00:40s\n","epoch 54 | loss: 170.79384| val_0_mse: 192.33529663085938|  0:00:41s\n","epoch 55 | loss: 170.04905| val_0_mse: 182.1741943359375|  0:00:42s\n","epoch 56 | loss: 166.64916| val_0_mse: 186.3326873779297|  0:00:43s\n","epoch 57 | loss: 166.24194| val_0_mse: 179.03143310546875|  0:00:44s\n","epoch 58 | loss: 164.13966| val_0_mse: 175.1360626220703|  0:00:44s\n","epoch 59 | loss: 162.70784| val_0_mse: 175.08775329589844|  0:00:45s\n","epoch 60 | loss: 160.13992| val_0_mse: 183.01365661621094|  0:00:46s\n","epoch 61 | loss: 164.59371| val_0_mse: 188.9157257080078|  0:00:47s\n","epoch 62 | loss: 165.1916| val_0_mse: 201.11453247070312|  0:00:47s\n","epoch 63 | loss: 165.12532| val_0_mse: 197.93104553222656|  0:00:48s\n","epoch 64 | loss: 168.01709| val_0_mse: 176.2430419921875|  0:00:49s\n","epoch 65 | loss: 161.866 | val_0_mse: 194.30027770996094|  0:00:50s\n","epoch 66 | loss: 167.14362| val_0_mse: 173.62794494628906|  0:00:50s\n","epoch 67 | loss: 162.02471| val_0_mse: 169.2630615234375|  0:00:51s\n","epoch 68 | loss: 160.2486| val_0_mse: 191.47792053222656|  0:00:52s\n","epoch 69 | loss: 161.23069| val_0_mse: 205.4346466064453|  0:00:53s\n","epoch 70 | loss: 157.60407| val_0_mse: 162.5841827392578|  0:00:54s\n","epoch 71 | loss: 156.23607| val_0_mse: 168.88038635253906|  0:00:54s\n","epoch 72 | loss: 159.06011| val_0_mse: 180.62472534179688|  0:00:55s\n","epoch 73 | loss: 151.09899| val_0_mse: 186.73272705078125|  0:00:56s\n","epoch 74 | loss: 162.05135| val_0_mse: 180.86021423339844|  0:00:57s\n","epoch 75 | loss: 160.25526| val_0_mse: 171.9013214111328|  0:00:57s\n","epoch 76 | loss: 158.71371| val_0_mse: 178.77589416503906|  0:00:58s\n","epoch 77 | loss: 151.38697| val_0_mse: 176.3243865966797|  0:00:59s\n","epoch 78 | loss: 149.15758| val_0_mse: 180.90049743652344|  0:01:00s\n","epoch 79 | loss: 148.47766| val_0_mse: 165.60208129882812|  0:01:00s\n","epoch 80 | loss: 152.81959| val_0_mse: 171.4378662109375|  0:01:01s\n","\n","Early stopping occurred at epoch 80 with best_epoch = 70 and best_val_0_mse = 162.5841827392578\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 15:20:31,986] Trial 76 finished with value: 162.5841827392578 and parameters: {'n_d': 62, 'n_steps': 4, 'gamma': 1.4632272882080142, 'n_independent': 3, 'n_shared': 3, 'momentum': 0.10011254095008207}. Best is trial 33 with value: 135.8055877685547.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 1614.47487| val_0_mse: 38598.62109375|  0:00:00s\n","epoch 1  | loss: 459.29279| val_0_mse: 61675.48046875|  0:00:01s\n","epoch 2  | loss: 346.76803| val_0_mse: 13275.703125|  0:00:02s\n","epoch 3  | loss: 325.60454| val_0_mse: 3721.80517578125|  0:00:02s\n","epoch 4  | loss: 297.02717| val_0_mse: 1654.7703857421875|  0:00:03s\n","epoch 5  | loss: 270.41658| val_0_mse: 1215.4227294921875|  0:00:04s\n","epoch 6  | loss: 272.52138| val_0_mse: 2057.98876953125|  0:00:04s\n","epoch 7  | loss: 261.20664| val_0_mse: 2973.497802734375|  0:00:05s\n","epoch 8  | loss: 251.12499| val_0_mse: 2041.525390625|  0:00:06s\n","epoch 9  | loss: 240.54574| val_0_mse: 3460.98828125|  0:00:07s\n","epoch 10 | loss: 238.69196| val_0_mse: 2006.262939453125|  0:00:07s\n","epoch 11 | loss: 236.96387| val_0_mse: 4273.63720703125|  0:00:08s\n","epoch 12 | loss: 231.28176| val_0_mse: 2677.56494140625|  0:00:09s\n","epoch 13 | loss: 229.59294| val_0_mse: 2377.79541015625|  0:00:09s\n","epoch 14 | loss: 223.51798| val_0_mse: 1401.3291015625|  0:00:10s\n","epoch 15 | loss: 219.93696| val_0_mse: 1006.4215698242188|  0:00:11s\n","epoch 16 | loss: 228.34899| val_0_mse: 519.1807861328125|  0:00:11s\n","epoch 17 | loss: 214.85879| val_0_mse: 839.5665893554688|  0:00:12s\n","epoch 18 | loss: 210.46264| val_0_mse: 790.748291015625|  0:00:13s\n","epoch 19 | loss: 204.53498| val_0_mse: 382.3528137207031|  0:00:13s\n","epoch 20 | loss: 202.38472| val_0_mse: 394.9410095214844|  0:00:14s\n","epoch 21 | loss: 215.70201| val_0_mse: 556.560791015625|  0:00:15s\n","epoch 22 | loss: 204.13863| val_0_mse: 539.8135986328125|  0:00:16s\n","epoch 23 | loss: 203.73185| val_0_mse: 323.4122009277344|  0:00:16s\n","epoch 24 | loss: 208.1032| val_0_mse: 350.6737976074219|  0:00:17s\n","epoch 25 | loss: 195.56218| val_0_mse: 333.8382263183594|  0:00:18s\n","epoch 26 | loss: 193.82648| val_0_mse: 295.8102111816406|  0:00:18s\n","epoch 27 | loss: 208.25531| val_0_mse: 264.1251525878906|  0:00:19s\n","epoch 28 | loss: 210.84514| val_0_mse: 274.42724609375|  0:00:20s\n","epoch 29 | loss: 199.42415| val_0_mse: 277.3780212402344|  0:00:20s\n","epoch 30 | loss: 194.17003| val_0_mse: 274.04278564453125|  0:00:21s\n","epoch 31 | loss: 189.26714| val_0_mse: 216.72508239746094|  0:00:22s\n","epoch 32 | loss: 187.0796| val_0_mse: 243.95553588867188|  0:00:22s\n","epoch 33 | loss: 198.17627| val_0_mse: 238.26576232910156|  0:00:23s\n","epoch 34 | loss: 196.13866| val_0_mse: 223.22206115722656|  0:00:24s\n","epoch 35 | loss: 193.81763| val_0_mse: 213.08375549316406|  0:00:24s\n","epoch 36 | loss: 188.69855| val_0_mse: 221.73423767089844|  0:00:25s\n","epoch 37 | loss: 186.74966| val_0_mse: 207.1317138671875|  0:00:26s\n","epoch 38 | loss: 187.75719| val_0_mse: 207.4024200439453|  0:00:27s\n","epoch 39 | loss: 183.11833| val_0_mse: 208.72691345214844|  0:00:27s\n","epoch 40 | loss: 188.01186| val_0_mse: 209.92649841308594|  0:00:28s\n","epoch 41 | loss: 192.8738| val_0_mse: 266.59893798828125|  0:00:29s\n","epoch 42 | loss: 187.53005| val_0_mse: 203.93170166015625|  0:00:29s\n","epoch 43 | loss: 192.18237| val_0_mse: 198.99998474121094|  0:00:30s\n","epoch 44 | loss: 184.01216| val_0_mse: 196.28335571289062|  0:00:31s\n","epoch 45 | loss: 191.56308| val_0_mse: 190.37156677246094|  0:00:31s\n","epoch 46 | loss: 179.38763| val_0_mse: 200.7802734375|  0:00:32s\n","epoch 47 | loss: 179.36656| val_0_mse: 183.74420166015625|  0:00:33s\n","epoch 48 | loss: 181.81844| val_0_mse: 196.30763244628906|  0:00:33s\n","epoch 49 | loss: 187.27766| val_0_mse: 188.89544677734375|  0:00:34s\n","epoch 50 | loss: 179.91668| val_0_mse: 179.5821990966797|  0:00:35s\n","epoch 51 | loss: 177.57124| val_0_mse: 189.6774139404297|  0:00:35s\n","epoch 52 | loss: 179.72531| val_0_mse: 194.365478515625|  0:00:36s\n","epoch 53 | loss: 177.88185| val_0_mse: 198.0288543701172|  0:00:37s\n","epoch 54 | loss: 181.28179| val_0_mse: 194.25592041015625|  0:00:38s\n","epoch 55 | loss: 189.44054| val_0_mse: 202.6619873046875|  0:00:38s\n","epoch 56 | loss: 182.42748| val_0_mse: 184.753662109375|  0:00:39s\n","epoch 57 | loss: 183.23726| val_0_mse: 179.17417907714844|  0:00:40s\n","epoch 58 | loss: 176.873 | val_0_mse: 198.63092041015625|  0:00:41s\n","epoch 59 | loss: 176.87472| val_0_mse: 188.01463317871094|  0:00:41s\n","epoch 60 | loss: 183.80401| val_0_mse: 183.26783752441406|  0:00:42s\n","epoch 61 | loss: 175.44946| val_0_mse: 194.82672119140625|  0:00:43s\n","epoch 62 | loss: 178.39536| val_0_mse: 192.60960388183594|  0:00:43s\n","epoch 63 | loss: 176.70188| val_0_mse: 184.72933959960938|  0:00:44s\n","epoch 64 | loss: 180.69527| val_0_mse: 192.8714141845703|  0:00:45s\n","epoch 65 | loss: 182.79429| val_0_mse: 177.57415771484375|  0:00:45s\n","epoch 66 | loss: 185.33483| val_0_mse: 196.11915588378906|  0:00:46s\n","epoch 67 | loss: 181.26562| val_0_mse: 181.03411865234375|  0:00:47s\n","epoch 68 | loss: 173.84023| val_0_mse: 222.79443359375|  0:00:47s\n","epoch 69 | loss: 175.08843| val_0_mse: 181.34890747070312|  0:00:48s\n","epoch 70 | loss: 168.01055| val_0_mse: 172.45101928710938|  0:00:49s\n","epoch 71 | loss: 166.32187| val_0_mse: 198.10061645507812|  0:00:50s\n","epoch 72 | loss: 169.90889| val_0_mse: 180.88467407226562|  0:00:50s\n","epoch 73 | loss: 169.78742| val_0_mse: 222.04527282714844|  0:00:51s\n","epoch 74 | loss: 170.70723| val_0_mse: 194.41183471679688|  0:00:52s\n","epoch 75 | loss: 155.55421| val_0_mse: 176.7685546875|  0:00:52s\n","epoch 76 | loss: 166.5592| val_0_mse: 195.3241729736328|  0:00:53s\n","epoch 77 | loss: 173.71341| val_0_mse: 193.2804412841797|  0:00:54s\n","epoch 78 | loss: 169.29355| val_0_mse: 192.14688110351562|  0:00:54s\n","epoch 79 | loss: 164.15175| val_0_mse: 185.92709350585938|  0:00:55s\n","epoch 80 | loss: 162.04437| val_0_mse: 171.4246063232422|  0:00:56s\n","epoch 81 | loss: 159.96239| val_0_mse: 180.88632202148438|  0:00:56s\n","epoch 82 | loss: 161.65185| val_0_mse: 182.63888549804688|  0:00:57s\n","epoch 83 | loss: 159.34758| val_0_mse: 166.05743408203125|  0:00:58s\n","epoch 84 | loss: 154.07959| val_0_mse: 179.4630126953125|  0:00:58s\n","epoch 85 | loss: 153.39307| val_0_mse: 204.39927673339844|  0:00:59s\n","epoch 86 | loss: 161.92084| val_0_mse: 188.9330596923828|  0:01:00s\n","epoch 87 | loss: 172.77675| val_0_mse: 174.9385528564453|  0:01:00s\n","epoch 88 | loss: 158.28252| val_0_mse: 173.60020446777344|  0:01:01s\n","epoch 89 | loss: 159.82516| val_0_mse: 175.2251739501953|  0:01:02s\n","epoch 90 | loss: 157.74077| val_0_mse: 172.6377410888672|  0:01:03s\n","epoch 91 | loss: 160.02356| val_0_mse: 169.33401489257812|  0:01:03s\n","epoch 92 | loss: 155.10031| val_0_mse: 169.8831024169922|  0:01:04s\n","epoch 93 | loss: 155.45555| val_0_mse: 167.24932861328125|  0:01:05s\n","\n","Early stopping occurred at epoch 93 with best_epoch = 83 and best_val_0_mse = 166.05743408203125\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 15:21:37,609] Trial 77 finished with value: 166.05743408203125 and parameters: {'n_d': 58, 'n_steps': 3, 'gamma': 1.5529629159405713, 'n_independent': 3, 'n_shared': 4, 'momentum': 0.06322695241835061}. Best is trial 33 with value: 135.8055877685547.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 1621.70266| val_0_mse: 17426.494140625|  0:00:00s\n","epoch 1  | loss: 538.64326| val_0_mse: 4540.47900390625|  0:00:01s\n","epoch 2  | loss: 422.0158| val_0_mse: 4475.1171875|  0:00:02s\n","epoch 3  | loss: 377.94215| val_0_mse: 5446.880859375|  0:00:03s\n","epoch 4  | loss: 352.26916| val_0_mse: 968.8053588867188|  0:00:04s\n","epoch 5  | loss: 328.96469| val_0_mse: 1283.4739990234375|  0:00:05s\n","epoch 6  | loss: 299.15246| val_0_mse: 906.130615234375|  0:00:06s\n","epoch 7  | loss: 299.20719| val_0_mse: 1128.5933837890625|  0:00:06s\n","epoch 8  | loss: 278.54196| val_0_mse: 1171.5328369140625|  0:00:07s\n","epoch 9  | loss: 268.68501| val_0_mse: 679.9995727539062|  0:00:08s\n","epoch 10 | loss: 258.98402| val_0_mse: 710.527099609375|  0:00:09s\n","epoch 11 | loss: 250.6607| val_0_mse: 695.4406127929688|  0:00:10s\n","epoch 12 | loss: 244.07019| val_0_mse: 521.2946166992188|  0:00:11s\n","epoch 13 | loss: 236.33164| val_0_mse: 571.750732421875|  0:00:11s\n","epoch 14 | loss: 229.97142| val_0_mse: 398.6927490234375|  0:00:12s\n","epoch 15 | loss: 233.97868| val_0_mse: 517.6148681640625|  0:00:13s\n","epoch 16 | loss: 234.5574| val_0_mse: 533.5611572265625|  0:00:14s\n","epoch 17 | loss: 226.16428| val_0_mse: 448.5444030761719|  0:00:15s\n","epoch 18 | loss: 214.7254| val_0_mse: 374.2383728027344|  0:00:16s\n","epoch 19 | loss: 218.23528| val_0_mse: 356.1070251464844|  0:00:17s\n","epoch 20 | loss: 211.27101| val_0_mse: 327.863525390625|  0:00:17s\n","epoch 21 | loss: 210.13401| val_0_mse: 287.6254577636719|  0:00:18s\n","epoch 22 | loss: 205.3347| val_0_mse: 290.2054138183594|  0:00:19s\n","epoch 23 | loss: 207.15571| val_0_mse: 343.81805419921875|  0:00:20s\n","epoch 24 | loss: 202.76089| val_0_mse: 275.11053466796875|  0:00:21s\n","epoch 25 | loss: 201.11206| val_0_mse: 265.8584899902344|  0:00:22s\n","epoch 26 | loss: 209.26177| val_0_mse: 264.48651123046875|  0:00:22s\n","epoch 27 | loss: 206.8848| val_0_mse: 225.4423065185547|  0:00:23s\n","epoch 28 | loss: 200.07476| val_0_mse: 227.9434051513672|  0:00:24s\n","epoch 29 | loss: 202.99387| val_0_mse: 232.6536407470703|  0:00:25s\n","epoch 30 | loss: 201.79052| val_0_mse: 220.51832580566406|  0:00:26s\n","epoch 31 | loss: 199.45715| val_0_mse: 203.2001190185547|  0:00:27s\n","epoch 32 | loss: 195.74876| val_0_mse: 225.27027893066406|  0:00:28s\n","epoch 33 | loss: 193.79283| val_0_mse: 202.27134704589844|  0:00:29s\n","epoch 34 | loss: 189.53042| val_0_mse: 194.46835327148438|  0:00:29s\n","epoch 35 | loss: 189.25365| val_0_mse: 203.51010131835938|  0:00:30s\n","epoch 36 | loss: 184.00823| val_0_mse: 209.93472290039062|  0:00:31s\n","epoch 37 | loss: 178.57127| val_0_mse: 189.8795928955078|  0:00:32s\n","epoch 38 | loss: 177.38093| val_0_mse: 186.9431610107422|  0:00:33s\n","epoch 39 | loss: 176.30338| val_0_mse: 198.09567260742188|  0:00:34s\n","epoch 40 | loss: 174.78127| val_0_mse: 212.61900329589844|  0:00:34s\n","epoch 41 | loss: 175.66808| val_0_mse: 186.2624053955078|  0:00:35s\n","epoch 42 | loss: 172.83287| val_0_mse: 190.8933868408203|  0:00:36s\n","epoch 43 | loss: 174.96332| val_0_mse: 174.86819458007812|  0:00:37s\n","epoch 44 | loss: 172.65422| val_0_mse: 186.35899353027344|  0:00:38s\n","epoch 45 | loss: 172.77458| val_0_mse: 205.00173950195312|  0:00:39s\n","epoch 46 | loss: 173.14827| val_0_mse: 177.7279052734375|  0:00:39s\n","epoch 47 | loss: 176.41899| val_0_mse: 194.99392700195312|  0:00:40s\n","epoch 48 | loss: 176.22866| val_0_mse: 211.1999053955078|  0:00:41s\n","epoch 49 | loss: 172.89008| val_0_mse: 218.309814453125|  0:00:42s\n","epoch 50 | loss: 174.45138| val_0_mse: 185.2974853515625|  0:00:43s\n","epoch 51 | loss: 169.97181| val_0_mse: 174.2958526611328|  0:00:44s\n","epoch 52 | loss: 173.68878| val_0_mse: 181.33912658691406|  0:00:45s\n","epoch 53 | loss: 170.74978| val_0_mse: 246.62274169921875|  0:00:45s\n","epoch 54 | loss: 183.22516| val_0_mse: 222.63424682617188|  0:00:46s\n","epoch 55 | loss: 170.76556| val_0_mse: 176.21124267578125|  0:00:47s\n","epoch 56 | loss: 172.76315| val_0_mse: 207.58067321777344|  0:00:48s\n","epoch 57 | loss: 170.76901| val_0_mse: 168.2054443359375|  0:00:49s\n","epoch 58 | loss: 168.40859| val_0_mse: 192.09356689453125|  0:00:49s\n","epoch 59 | loss: 167.37106| val_0_mse: 167.34239196777344|  0:00:50s\n","epoch 60 | loss: 164.55103| val_0_mse: 182.09942626953125|  0:00:51s\n","epoch 61 | loss: 170.2026| val_0_mse: 178.01002502441406|  0:00:52s\n","epoch 62 | loss: 172.18855| val_0_mse: 169.4396209716797|  0:00:53s\n","epoch 63 | loss: 170.98119| val_0_mse: 169.01278686523438|  0:00:54s\n","epoch 64 | loss: 169.31477| val_0_mse: 166.64060974121094|  0:00:54s\n","epoch 65 | loss: 167.58536| val_0_mse: 167.25936889648438|  0:00:55s\n","epoch 66 | loss: 162.97985| val_0_mse: 172.71331787109375|  0:00:56s\n","epoch 67 | loss: 163.7548| val_0_mse: 179.68466186523438|  0:00:57s\n","epoch 68 | loss: 162.47327| val_0_mse: 234.3921661376953|  0:00:58s\n","epoch 69 | loss: 165.39824| val_0_mse: 170.178466796875|  0:00:59s\n","epoch 70 | loss: 159.54268| val_0_mse: 167.81344604492188|  0:01:00s\n","epoch 71 | loss: 152.20885| val_0_mse: 168.4558868408203|  0:01:00s\n","epoch 72 | loss: 153.80599| val_0_mse: 168.5550994873047|  0:01:01s\n","epoch 73 | loss: 153.93557| val_0_mse: 171.1272430419922|  0:01:02s\n","epoch 74 | loss: 155.48  | val_0_mse: 156.38702392578125|  0:01:03s\n","epoch 75 | loss: 152.36105| val_0_mse: 169.64990234375|  0:01:04s\n","epoch 76 | loss: 151.62194| val_0_mse: 168.3203125|  0:01:05s\n","epoch 77 | loss: 154.95957| val_0_mse: 159.3052978515625|  0:01:05s\n","epoch 78 | loss: 152.01987| val_0_mse: 164.8278350830078|  0:01:06s\n","epoch 79 | loss: 162.9223| val_0_mse: 164.6671905517578|  0:01:07s\n","epoch 80 | loss: 156.6039| val_0_mse: 164.68565368652344|  0:01:08s\n","epoch 81 | loss: 153.8195| val_0_mse: 167.50863647460938|  0:01:09s\n","epoch 82 | loss: 149.98671| val_0_mse: 162.1343231201172|  0:01:09s\n","epoch 83 | loss: 149.77081| val_0_mse: 220.16990661621094|  0:01:10s\n","epoch 84 | loss: 149.23616| val_0_mse: 160.42807006835938|  0:01:11s\n","\n","Early stopping occurred at epoch 84 with best_epoch = 74 and best_val_0_mse = 156.38702392578125\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 15:22:49,686] Trial 78 finished with value: 156.38702392578125 and parameters: {'n_d': 60, 'n_steps': 4, 'gamma': 1.3735546623175565, 'n_independent': 4, 'n_shared': 3, 'momentum': 0.16454595965010346}. Best is trial 33 with value: 135.8055877685547.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 1729.86444| val_0_mse: 7297.005859375|  0:00:00s\n","epoch 1  | loss: 533.70939| val_0_mse: 3728.88232421875|  0:00:01s\n","epoch 2  | loss: 385.17836| val_0_mse: 1039.385986328125|  0:00:02s\n","epoch 3  | loss: 384.28744| val_0_mse: 834.2354125976562|  0:00:02s\n","epoch 4  | loss: 369.69943| val_0_mse: 1489.8310546875|  0:00:03s\n","epoch 5  | loss: 332.28388| val_0_mse: 1013.136474609375|  0:00:04s\n","epoch 6  | loss: 284.28619| val_0_mse: 1076.63427734375|  0:00:04s\n","epoch 7  | loss: 281.83846| val_0_mse: 725.9784545898438|  0:00:05s\n","epoch 8  | loss: 268.24979| val_0_mse: 642.4022827148438|  0:00:06s\n","epoch 9  | loss: 258.79436| val_0_mse: 620.4291381835938|  0:00:06s\n","epoch 10 | loss: 254.6296| val_0_mse: 423.4749450683594|  0:00:07s\n","epoch 11 | loss: 249.32469| val_0_mse: 390.63311767578125|  0:00:08s\n","epoch 12 | loss: 248.81408| val_0_mse: 505.322265625|  0:00:09s\n","epoch 13 | loss: 248.41285| val_0_mse: 341.9020690917969|  0:00:09s\n","epoch 14 | loss: 248.13185| val_0_mse: 356.0451965332031|  0:00:10s\n","epoch 15 | loss: 231.97432| val_0_mse: 331.0995178222656|  0:00:11s\n","epoch 16 | loss: 227.6738| val_0_mse: 333.4932556152344|  0:00:11s\n","epoch 17 | loss: 220.11365| val_0_mse: 314.9820861816406|  0:00:12s\n","epoch 18 | loss: 215.22655| val_0_mse: 286.4956359863281|  0:00:13s\n","epoch 19 | loss: 212.10177| val_0_mse: 261.7667541503906|  0:00:14s\n","epoch 20 | loss: 217.26179| val_0_mse: 299.4188232421875|  0:00:14s\n","epoch 21 | loss: 217.58162| val_0_mse: 340.40374755859375|  0:00:15s\n","epoch 22 | loss: 209.43747| val_0_mse: 317.9216003417969|  0:00:16s\n","epoch 23 | loss: 204.7823| val_0_mse: 264.9167785644531|  0:00:16s\n","epoch 24 | loss: 205.17987| val_0_mse: 296.5544738769531|  0:00:17s\n","epoch 25 | loss: 207.59859| val_0_mse: 245.0891876220703|  0:00:18s\n","epoch 26 | loss: 203.28324| val_0_mse: 261.8342590332031|  0:00:18s\n","epoch 27 | loss: 200.21361| val_0_mse: 234.4057159423828|  0:00:19s\n","epoch 28 | loss: 202.68842| val_0_mse: 214.60281372070312|  0:00:20s\n","epoch 29 | loss: 196.15294| val_0_mse: 230.2285614013672|  0:00:20s\n","epoch 30 | loss: 196.79359| val_0_mse: 224.46499633789062|  0:00:21s\n","epoch 31 | loss: 197.93471| val_0_mse: 224.25933837890625|  0:00:22s\n","epoch 32 | loss: 191.29036| val_0_mse: 241.32850646972656|  0:00:22s\n","epoch 33 | loss: 188.9991| val_0_mse: 207.06271362304688|  0:00:23s\n","epoch 34 | loss: 190.79896| val_0_mse: 201.13491821289062|  0:00:24s\n","epoch 35 | loss: 198.84853| val_0_mse: 204.4381866455078|  0:00:25s\n","epoch 36 | loss: 189.8747| val_0_mse: 191.73330688476562|  0:00:25s\n","epoch 37 | loss: 186.81899| val_0_mse: 199.6687469482422|  0:00:26s\n","epoch 38 | loss: 188.99428| val_0_mse: 204.5128936767578|  0:00:27s\n","epoch 39 | loss: 195.14163| val_0_mse: 232.6284942626953|  0:00:27s\n","epoch 40 | loss: 200.57662| val_0_mse: 210.35011291503906|  0:00:28s\n","epoch 41 | loss: 192.00982| val_0_mse: 199.90126037597656|  0:00:29s\n","epoch 42 | loss: 194.81847| val_0_mse: 208.98345947265625|  0:00:29s\n","epoch 43 | loss: 184.39989| val_0_mse: 188.61000061035156|  0:00:30s\n","epoch 44 | loss: 189.39873| val_0_mse: 201.95010375976562|  0:00:31s\n","epoch 45 | loss: 185.17171| val_0_mse: 188.0263671875|  0:00:32s\n","epoch 46 | loss: 177.45708| val_0_mse: 190.89793395996094|  0:00:32s\n","epoch 47 | loss: 179.87708| val_0_mse: 189.0818328857422|  0:00:33s\n","epoch 48 | loss: 176.29315| val_0_mse: 184.1140594482422|  0:00:34s\n","epoch 49 | loss: 175.3688| val_0_mse: 216.7381134033203|  0:00:34s\n","epoch 50 | loss: 174.99753| val_0_mse: 183.9243621826172|  0:00:35s\n","epoch 51 | loss: 168.55676| val_0_mse: 184.24435424804688|  0:00:36s\n","epoch 52 | loss: 169.7977| val_0_mse: 189.22657775878906|  0:00:36s\n","epoch 53 | loss: 168.8857| val_0_mse: 189.77008056640625|  0:00:37s\n","epoch 54 | loss: 174.00568| val_0_mse: 189.6292724609375|  0:00:38s\n","epoch 55 | loss: 175.68746| val_0_mse: 184.97938537597656|  0:00:39s\n","epoch 56 | loss: 172.4804| val_0_mse: 185.2925567626953|  0:00:39s\n","epoch 57 | loss: 171.17364| val_0_mse: 185.84051513671875|  0:00:40s\n","epoch 58 | loss: 169.90059| val_0_mse: 188.15182495117188|  0:00:41s\n","epoch 59 | loss: 167.57893| val_0_mse: 178.20803833007812|  0:00:41s\n","epoch 60 | loss: 163.35493| val_0_mse: 190.17550659179688|  0:00:42s\n","epoch 61 | loss: 168.85934| val_0_mse: 171.8273468017578|  0:00:43s\n","epoch 62 | loss: 165.71588| val_0_mse: 174.74920654296875|  0:00:43s\n","epoch 63 | loss: 162.35464| val_0_mse: 180.45335388183594|  0:00:44s\n","epoch 64 | loss: 155.257 | val_0_mse: 180.39862060546875|  0:00:45s\n","epoch 65 | loss: 164.02606| val_0_mse: 167.11622619628906|  0:00:45s\n","epoch 66 | loss: 174.78698| val_0_mse: 186.4246368408203|  0:00:46s\n","epoch 67 | loss: 173.2951| val_0_mse: 179.42398071289062|  0:00:47s\n","epoch 68 | loss: 153.92372| val_0_mse: 218.03492736816406|  0:00:48s\n","epoch 69 | loss: 157.36341| val_0_mse: 198.2712860107422|  0:00:48s\n","epoch 70 | loss: 157.48685| val_0_mse: 172.90939331054688|  0:00:49s\n","epoch 71 | loss: 158.10442| val_0_mse: 197.22247314453125|  0:00:50s\n","epoch 72 | loss: 162.10219| val_0_mse: 183.31576538085938|  0:00:50s\n","epoch 73 | loss: 160.23111| val_0_mse: 190.87298583984375|  0:00:51s\n","epoch 74 | loss: 155.31716| val_0_mse: 184.67462158203125|  0:00:52s\n","epoch 75 | loss: 148.86817| val_0_mse: 169.7511444091797|  0:00:52s\n","\n","Early stopping occurred at epoch 75 with best_epoch = 65 and best_val_0_mse = 167.11622619628906\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 15:23:43,065] Trial 79 finished with value: 167.11622619628906 and parameters: {'n_d': 63, 'n_steps': 3, 'gamma': 1.424861250704028, 'n_independent': 3, 'n_shared': 4, 'momentum': 0.21351382951653444}. Best is trial 33 with value: 135.8055877685547.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 1860.15811| val_0_mse: 19589.818359375|  0:00:00s\n","epoch 1  | loss: 619.61775| val_0_mse: 1692.769287109375|  0:00:01s\n","epoch 2  | loss: 400.54737| val_0_mse: 4110.03857421875|  0:00:01s\n","epoch 3  | loss: 327.02946| val_0_mse: 2675.851806640625|  0:00:02s\n","epoch 4  | loss: 309.96316| val_0_mse: 1865.7249755859375|  0:00:03s\n","epoch 5  | loss: 293.90927| val_0_mse: 2928.609375|  0:00:03s\n","epoch 6  | loss: 275.97017| val_0_mse: 2227.39453125|  0:00:04s\n","epoch 7  | loss: 265.93615| val_0_mse: 2269.532470703125|  0:00:04s\n","epoch 8  | loss: 247.43689| val_0_mse: 2824.6376953125|  0:00:05s\n","epoch 9  | loss: 235.91916| val_0_mse: 2835.161376953125|  0:00:06s\n","epoch 10 | loss: 237.91333| val_0_mse: 1230.2894287109375|  0:00:06s\n","epoch 11 | loss: 238.9734| val_0_mse: 1400.8258056640625|  0:00:07s\n","epoch 12 | loss: 226.18042| val_0_mse: 1203.1878662109375|  0:00:07s\n","epoch 13 | loss: 227.12182| val_0_mse: 1467.49072265625|  0:00:08s\n","epoch 14 | loss: 235.06835| val_0_mse: 1191.7921142578125|  0:00:09s\n","epoch 15 | loss: 220.14048| val_0_mse: 1175.4627685546875|  0:00:10s\n","epoch 16 | loss: 214.10157| val_0_mse: 696.9852294921875|  0:00:10s\n","epoch 17 | loss: 209.61927| val_0_mse: 741.1326293945312|  0:00:11s\n","epoch 18 | loss: 210.23653| val_0_mse: 610.3131103515625|  0:00:11s\n","epoch 19 | loss: 209.62528| val_0_mse: 408.4921569824219|  0:00:12s\n","epoch 20 | loss: 208.21731| val_0_mse: 420.33251953125|  0:00:13s\n","epoch 21 | loss: 210.68614| val_0_mse: 467.5827331542969|  0:00:13s\n","epoch 22 | loss: 210.11443| val_0_mse: 341.7844543457031|  0:00:14s\n","epoch 23 | loss: 198.57549| val_0_mse: 368.5848083496094|  0:00:14s\n","epoch 24 | loss: 197.14579| val_0_mse: 341.5889892578125|  0:00:15s\n","epoch 25 | loss: 191.76322| val_0_mse: 381.136962890625|  0:00:16s\n","epoch 26 | loss: 193.0932| val_0_mse: 307.19183349609375|  0:00:16s\n","epoch 27 | loss: 198.59937| val_0_mse: 267.6596374511719|  0:00:17s\n","epoch 28 | loss: 198.27084| val_0_mse: 237.2747039794922|  0:00:18s\n","epoch 29 | loss: 192.96904| val_0_mse: 278.3981628417969|  0:00:18s\n","epoch 30 | loss: 186.77333| val_0_mse: 213.4921875|  0:00:19s\n","epoch 31 | loss: 184.52999| val_0_mse: 203.50828552246094|  0:00:20s\n","epoch 32 | loss: 182.92926| val_0_mse: 194.37860107421875|  0:00:20s\n","epoch 33 | loss: 172.62497| val_0_mse: 221.36032104492188|  0:00:21s\n","epoch 34 | loss: 175.28784| val_0_mse: 206.23324584960938|  0:00:21s\n","epoch 35 | loss: 174.54574| val_0_mse: 192.58485412597656|  0:00:22s\n","epoch 36 | loss: 173.95701| val_0_mse: 194.63002014160156|  0:00:23s\n","epoch 37 | loss: 171.3154| val_0_mse: 191.1241455078125|  0:00:23s\n","epoch 38 | loss: 172.94172| val_0_mse: 191.24952697753906|  0:00:24s\n","epoch 39 | loss: 173.03918| val_0_mse: 199.51658630371094|  0:00:24s\n","epoch 40 | loss: 172.26307| val_0_mse: 188.06861877441406|  0:00:25s\n","epoch 41 | loss: 174.57178| val_0_mse: 199.56202697753906|  0:00:26s\n","epoch 42 | loss: 180.65493| val_0_mse: 197.64649963378906|  0:00:26s\n","epoch 43 | loss: 174.00729| val_0_mse: 186.6557159423828|  0:00:27s\n","epoch 44 | loss: 174.54403| val_0_mse: 183.92919921875|  0:00:28s\n","epoch 45 | loss: 168.96769| val_0_mse: 186.91293334960938|  0:00:28s\n","epoch 46 | loss: 162.55607| val_0_mse: 179.8194580078125|  0:00:29s\n","epoch 47 | loss: 158.84731| val_0_mse: 175.89996337890625|  0:00:29s\n","epoch 48 | loss: 160.47805| val_0_mse: 179.4297332763672|  0:00:30s\n","epoch 49 | loss: 169.14704| val_0_mse: 171.05250549316406|  0:00:31s\n","epoch 50 | loss: 169.58793| val_0_mse: 177.2991180419922|  0:00:32s\n","epoch 51 | loss: 173.68491| val_0_mse: 179.7222442626953|  0:00:32s\n","epoch 52 | loss: 163.48623| val_0_mse: 187.6851348876953|  0:00:33s\n","epoch 53 | loss: 158.93468| val_0_mse: 195.57919311523438|  0:00:33s\n","epoch 54 | loss: 169.77149| val_0_mse: 164.17984008789062|  0:00:34s\n","epoch 55 | loss: 164.99846| val_0_mse: 192.65379333496094|  0:00:35s\n","epoch 56 | loss: 165.3677| val_0_mse: 170.73031616210938|  0:00:35s\n","epoch 57 | loss: 160.11866| val_0_mse: 176.31698608398438|  0:00:36s\n","epoch 58 | loss: 160.80013| val_0_mse: 172.23268127441406|  0:00:36s\n","epoch 59 | loss: 160.20614| val_0_mse: 182.55419921875|  0:00:37s\n","epoch 60 | loss: 158.77839| val_0_mse: 168.96112060546875|  0:00:38s\n","epoch 61 | loss: 158.3591| val_0_mse: 165.33389282226562|  0:00:38s\n","epoch 62 | loss: 158.12632| val_0_mse: 186.7354736328125|  0:00:39s\n","epoch 63 | loss: 155.78435| val_0_mse: 169.13473510742188|  0:00:39s\n","epoch 64 | loss: 154.90598| val_0_mse: 157.2830810546875|  0:00:40s\n","epoch 65 | loss: 151.91211| val_0_mse: 181.96673583984375|  0:00:41s\n","epoch 66 | loss: 148.84647| val_0_mse: 185.26193237304688|  0:00:41s\n","epoch 67 | loss: 148.76164| val_0_mse: 176.19349670410156|  0:00:42s\n","epoch 68 | loss: 150.04436| val_0_mse: 165.11199951171875|  0:00:43s\n","epoch 69 | loss: 151.75359| val_0_mse: 169.43661499023438|  0:00:43s\n","epoch 70 | loss: 147.59388| val_0_mse: 191.8627471923828|  0:00:44s\n","epoch 71 | loss: 152.9031| val_0_mse: 164.006103515625|  0:00:44s\n","epoch 72 | loss: 152.72086| val_0_mse: 156.98353576660156|  0:00:45s\n","epoch 73 | loss: 146.41638| val_0_mse: 173.46043395996094|  0:00:46s\n","epoch 74 | loss: 142.45788| val_0_mse: 155.87750244140625|  0:00:46s\n","epoch 75 | loss: 143.8477| val_0_mse: 149.30345153808594|  0:00:47s\n","epoch 76 | loss: 147.3716| val_0_mse: 160.77867126464844|  0:00:47s\n","epoch 77 | loss: 143.27651| val_0_mse: 204.32020568847656|  0:00:48s\n","epoch 78 | loss: 145.8118| val_0_mse: 155.8684844970703|  0:00:49s\n","epoch 79 | loss: 150.12903| val_0_mse: 153.02940368652344|  0:00:49s\n","epoch 80 | loss: 138.15477| val_0_mse: 149.85560607910156|  0:00:50s\n","epoch 81 | loss: 133.12475| val_0_mse: 205.2544403076172|  0:00:50s\n","epoch 82 | loss: 141.44728| val_0_mse: 158.18812561035156|  0:00:51s\n","epoch 83 | loss: 135.34643| val_0_mse: 160.44992065429688|  0:00:52s\n","epoch 84 | loss: 129.15213| val_0_mse: 154.10430908203125|  0:00:52s\n","epoch 85 | loss: 132.81797| val_0_mse: 147.98654174804688|  0:00:53s\n","epoch 86 | loss: 139.99459| val_0_mse: 163.74488830566406|  0:00:54s\n","epoch 87 | loss: 148.81105| val_0_mse: 173.9982452392578|  0:00:54s\n","epoch 88 | loss: 131.57338| val_0_mse: 157.74288940429688|  0:00:55s\n","epoch 89 | loss: 133.18403| val_0_mse: 159.2265625|  0:00:56s\n","epoch 90 | loss: 134.13676| val_0_mse: 155.21316528320312|  0:00:56s\n","epoch 91 | loss: 137.17977| val_0_mse: 168.786376953125|  0:00:57s\n","epoch 92 | loss: 133.40591| val_0_mse: 198.10244750976562|  0:00:57s\n","epoch 93 | loss: 132.58982| val_0_mse: 146.81663513183594|  0:00:58s\n","epoch 94 | loss: 135.10835| val_0_mse: 146.18431091308594|  0:00:59s\n","epoch 95 | loss: 128.596 | val_0_mse: 148.06947326660156|  0:00:59s\n","epoch 96 | loss: 124.0654| val_0_mse: 153.2451934814453|  0:01:00s\n","epoch 97 | loss: 127.66392| val_0_mse: 150.075927734375|  0:01:01s\n","epoch 98 | loss: 128.58966| val_0_mse: 149.5317840576172|  0:01:01s\n","epoch 99 | loss: 127.31769| val_0_mse: 153.94760131835938|  0:01:02s\n","Stop training because you reached max_epochs = 100 with best_epoch = 94 and best_val_0_mse = 146.18431091308594\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 15:24:45,676] Trial 80 finished with value: 146.18431091308594 and parameters: {'n_d': 39, 'n_steps': 3, 'gamma': 1.4678739002294285, 'n_independent': 3, 'n_shared': 3, 'momentum': 0.1538528383835002}. Best is trial 33 with value: 135.8055877685547.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 1952.49394| val_0_mse: 7123.57421875|  0:00:00s\n","epoch 1  | loss: 763.68333| val_0_mse: 5800.67626953125|  0:00:01s\n","epoch 2  | loss: 440.68899| val_0_mse: 1763.2109375|  0:00:01s\n","epoch 3  | loss: 367.09323| val_0_mse: 1329.970947265625|  0:00:02s\n","epoch 4  | loss: 327.92756| val_0_mse: 1175.2384033203125|  0:00:03s\n","epoch 5  | loss: 297.78833| val_0_mse: 1944.062744140625|  0:00:03s\n","epoch 6  | loss: 293.17241| val_0_mse: 1141.012451171875|  0:00:04s\n","epoch 7  | loss: 322.64795| val_0_mse: 2025.8670654296875|  0:00:05s\n","epoch 8  | loss: 277.37014| val_0_mse: 790.0418701171875|  0:00:05s\n","epoch 9  | loss: 272.38014| val_0_mse: 867.294189453125|  0:00:06s\n","epoch 10 | loss: 260.79274| val_0_mse: 1284.6099853515625|  0:00:06s\n","epoch 11 | loss: 259.10412| val_0_mse: 877.5445556640625|  0:00:07s\n","epoch 12 | loss: 252.88724| val_0_mse: 2417.280517578125|  0:00:08s\n","epoch 13 | loss: 249.90692| val_0_mse: 970.9739379882812|  0:00:08s\n","epoch 14 | loss: 249.33934| val_0_mse: 486.3591613769531|  0:00:09s\n","epoch 15 | loss: 237.9013| val_0_mse: 699.5053100585938|  0:00:09s\n","epoch 16 | loss: 230.45324| val_0_mse: 579.16650390625|  0:00:10s\n","epoch 17 | loss: 232.64225| val_0_mse: 342.0295715332031|  0:00:11s\n","epoch 18 | loss: 225.12288| val_0_mse: 298.5474548339844|  0:00:11s\n","epoch 19 | loss: 215.83741| val_0_mse: 373.49481201171875|  0:00:12s\n","epoch 20 | loss: 217.82847| val_0_mse: 270.23968505859375|  0:00:13s\n","epoch 21 | loss: 220.82771| val_0_mse: 313.6628112792969|  0:00:13s\n","epoch 22 | loss: 208.2831| val_0_mse: 346.7237243652344|  0:00:14s\n","epoch 23 | loss: 206.8649| val_0_mse: 275.588134765625|  0:00:15s\n","epoch 24 | loss: 202.68709| val_0_mse: 242.9270782470703|  0:00:15s\n","epoch 25 | loss: 205.30809| val_0_mse: 281.3222351074219|  0:00:16s\n","epoch 26 | loss: 202.01723| val_0_mse: 279.2813415527344|  0:00:16s\n","epoch 27 | loss: 201.44628| val_0_mse: 260.4513854980469|  0:00:17s\n","epoch 28 | loss: 194.58044| val_0_mse: 232.70211791992188|  0:00:18s\n","epoch 29 | loss: 189.2061| val_0_mse: 222.9464569091797|  0:00:18s\n","epoch 30 | loss: 196.22272| val_0_mse: 235.28317260742188|  0:00:19s\n","epoch 31 | loss: 186.50386| val_0_mse: 290.7479248046875|  0:00:20s\n","epoch 32 | loss: 187.72576| val_0_mse: 248.89990234375|  0:00:20s\n","epoch 33 | loss: 186.76812| val_0_mse: 198.6485137939453|  0:00:21s\n","epoch 34 | loss: 182.72833| val_0_mse: 226.72239685058594|  0:00:21s\n","epoch 35 | loss: 187.73542| val_0_mse: 192.20065307617188|  0:00:22s\n","epoch 36 | loss: 185.40694| val_0_mse: 208.98536682128906|  0:00:23s\n","epoch 37 | loss: 185.17958| val_0_mse: 213.9987335205078|  0:00:23s\n","epoch 38 | loss: 186.82495| val_0_mse: 189.8933563232422|  0:00:24s\n","epoch 39 | loss: 180.1101| val_0_mse: 229.058837890625|  0:00:24s\n","epoch 40 | loss: 189.09698| val_0_mse: 214.67881774902344|  0:00:25s\n","epoch 41 | loss: 180.07283| val_0_mse: 196.922607421875|  0:00:26s\n","epoch 42 | loss: 177.76123| val_0_mse: 199.16078186035156|  0:00:26s\n","epoch 43 | loss: 169.1857| val_0_mse: 187.86575317382812|  0:00:27s\n","epoch 44 | loss: 175.47101| val_0_mse: 185.08331298828125|  0:00:28s\n","epoch 45 | loss: 174.29353| val_0_mse: 179.755126953125|  0:00:28s\n","epoch 46 | loss: 172.04223| val_0_mse: 182.27035522460938|  0:00:29s\n","epoch 47 | loss: 173.30237| val_0_mse: 193.52175903320312|  0:00:29s\n","epoch 48 | loss: 172.36745| val_0_mse: 179.86843872070312|  0:00:30s\n","epoch 49 | loss: 165.24971| val_0_mse: 179.17166137695312|  0:00:31s\n","epoch 50 | loss: 163.10614| val_0_mse: 177.45423889160156|  0:00:31s\n","epoch 51 | loss: 169.23745| val_0_mse: 171.45648193359375|  0:00:32s\n","epoch 52 | loss: 166.98841| val_0_mse: 170.47219848632812|  0:00:33s\n","epoch 53 | loss: 160.5964| val_0_mse: 172.2241668701172|  0:00:33s\n","epoch 54 | loss: 163.28279| val_0_mse: 200.07972717285156|  0:00:34s\n","epoch 55 | loss: 164.86863| val_0_mse: 182.3296356201172|  0:00:34s\n","epoch 56 | loss: 164.05312| val_0_mse: 175.1189727783203|  0:00:35s\n","epoch 57 | loss: 155.60016| val_0_mse: 167.75880432128906|  0:00:36s\n","epoch 58 | loss: 166.24131| val_0_mse: 176.29791259765625|  0:00:36s\n","epoch 59 | loss: 164.75213| val_0_mse: 161.1912384033203|  0:00:37s\n","epoch 60 | loss: 161.63719| val_0_mse: 161.70204162597656|  0:00:38s\n","epoch 61 | loss: 159.40916| val_0_mse: 175.5179443359375|  0:00:38s\n","epoch 62 | loss: 157.05251| val_0_mse: 170.88221740722656|  0:00:39s\n","epoch 63 | loss: 147.59328| val_0_mse: 182.76072692871094|  0:00:39s\n","epoch 64 | loss: 152.38882| val_0_mse: 164.52830505371094|  0:00:40s\n","epoch 65 | loss: 153.09689| val_0_mse: 171.33944702148438|  0:00:41s\n","epoch 66 | loss: 152.31915| val_0_mse: 170.69070434570312|  0:00:41s\n","epoch 67 | loss: 152.03208| val_0_mse: 180.1175537109375|  0:00:42s\n","epoch 68 | loss: 157.41115| val_0_mse: 168.88592529296875|  0:00:43s\n","epoch 69 | loss: 145.35609| val_0_mse: 164.19993591308594|  0:00:43s\n","\n","Early stopping occurred at epoch 69 with best_epoch = 59 and best_val_0_mse = 161.1912384033203\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 15:25:29,705] Trial 81 finished with value: 161.1912384033203 and parameters: {'n_d': 41, 'n_steps': 3, 'gamma': 1.473497405084002, 'n_independent': 3, 'n_shared': 3, 'momentum': 0.1530802800845885}. Best is trial 33 with value: 135.8055877685547.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 1639.7934| val_0_mse: 4827.17236328125|  0:00:00s\n","epoch 1  | loss: 597.8248| val_0_mse: 17279.505859375|  0:00:01s\n","epoch 2  | loss: 418.3964| val_0_mse: 1113.8221435546875|  0:00:01s\n","epoch 3  | loss: 339.7844| val_0_mse: 5016.181640625|  0:00:02s\n","epoch 4  | loss: 312.92971| val_0_mse: 5799.90380859375|  0:00:02s\n","epoch 5  | loss: 294.92281| val_0_mse: 2516.650390625|  0:00:03s\n","epoch 6  | loss: 287.03871| val_0_mse: 861.39013671875|  0:00:04s\n","epoch 7  | loss: 271.79529| val_0_mse: 2593.4072265625|  0:00:04s\n","epoch 8  | loss: 251.93043| val_0_mse: 895.8798217773438|  0:00:05s\n","epoch 9  | loss: 250.45931| val_0_mse: 1668.9547119140625|  0:00:06s\n","epoch 10 | loss: 240.54531| val_0_mse: 2735.33447265625|  0:00:06s\n","epoch 11 | loss: 237.09007| val_0_mse: 2834.70166015625|  0:00:07s\n","epoch 12 | loss: 232.11273| val_0_mse: 1435.1929931640625|  0:00:07s\n","epoch 13 | loss: 224.18173| val_0_mse: 1517.3427734375|  0:00:08s\n","epoch 14 | loss: 224.69362| val_0_mse: 1049.943115234375|  0:00:09s\n","epoch 15 | loss: 222.70139| val_0_mse: 546.2747802734375|  0:00:09s\n","epoch 16 | loss: 222.23321| val_0_mse: 468.2637634277344|  0:00:10s\n","epoch 17 | loss: 219.68531| val_0_mse: 365.692626953125|  0:00:10s\n","epoch 18 | loss: 215.34814| val_0_mse: 509.3052673339844|  0:00:11s\n","epoch 19 | loss: 204.61604| val_0_mse: 320.4893493652344|  0:00:12s\n","epoch 20 | loss: 206.13574| val_0_mse: 294.7313537597656|  0:00:12s\n","epoch 21 | loss: 208.93436| val_0_mse: 311.9707946777344|  0:00:13s\n","epoch 22 | loss: 207.09413| val_0_mse: 347.6129455566406|  0:00:14s\n","epoch 23 | loss: 195.84682| val_0_mse: 284.6761169433594|  0:00:14s\n","epoch 24 | loss: 208.73905| val_0_mse: 261.2176818847656|  0:00:15s\n","epoch 25 | loss: 196.22207| val_0_mse: 381.9152526855469|  0:00:15s\n","epoch 26 | loss: 198.02771| val_0_mse: 248.92112731933594|  0:00:16s\n","epoch 27 | loss: 199.58782| val_0_mse: 241.71185302734375|  0:00:17s\n","epoch 28 | loss: 192.68285| val_0_mse: 233.40220642089844|  0:00:17s\n","epoch 29 | loss: 193.89156| val_0_mse: 223.79098510742188|  0:00:18s\n","epoch 30 | loss: 196.32905| val_0_mse: 229.56353759765625|  0:00:19s\n","epoch 31 | loss: 195.51175| val_0_mse: 212.27134704589844|  0:00:19s\n","epoch 32 | loss: 188.85921| val_0_mse: 243.13894653320312|  0:00:20s\n","epoch 33 | loss: 188.74926| val_0_mse: 260.8139343261719|  0:00:21s\n","epoch 34 | loss: 191.62121| val_0_mse: 216.70339965820312|  0:00:21s\n","epoch 35 | loss: 195.44572| val_0_mse: 207.1007843017578|  0:00:22s\n","epoch 36 | loss: 189.33989| val_0_mse: 244.05516052246094|  0:00:22s\n","epoch 37 | loss: 187.94909| val_0_mse: 265.7174072265625|  0:00:23s\n","epoch 38 | loss: 186.96896| val_0_mse: 199.08425903320312|  0:00:24s\n","epoch 39 | loss: 188.17145| val_0_mse: 200.25733947753906|  0:00:24s\n","epoch 40 | loss: 173.67712| val_0_mse: 170.20309448242188|  0:00:25s\n","epoch 41 | loss: 177.22294| val_0_mse: 203.74375915527344|  0:00:25s\n","epoch 42 | loss: 181.03266| val_0_mse: 197.87081909179688|  0:00:26s\n","epoch 43 | loss: 175.35911| val_0_mse: 197.80076599121094|  0:00:27s\n","epoch 44 | loss: 169.9044| val_0_mse: 187.9387664794922|  0:00:27s\n","epoch 45 | loss: 171.66154| val_0_mse: 189.47491455078125|  0:00:28s\n","epoch 46 | loss: 171.17121| val_0_mse: 177.8875732421875|  0:00:29s\n","epoch 47 | loss: 173.42538| val_0_mse: 208.87986755371094|  0:00:29s\n","epoch 48 | loss: 182.57011| val_0_mse: 184.7130126953125|  0:00:30s\n","epoch 49 | loss: 176.27071| val_0_mse: 184.41810607910156|  0:00:30s\n","epoch 50 | loss: 171.21493| val_0_mse: 167.74644470214844|  0:00:31s\n","epoch 51 | loss: 162.99927| val_0_mse: 162.45523071289062|  0:00:32s\n","epoch 52 | loss: 162.02592| val_0_mse: 230.84506225585938|  0:00:32s\n","epoch 53 | loss: 167.06816| val_0_mse: 189.2866668701172|  0:00:33s\n","epoch 54 | loss: 162.59892| val_0_mse: 277.2200012207031|  0:00:33s\n","epoch 55 | loss: 160.98884| val_0_mse: 160.20994567871094|  0:00:34s\n","epoch 56 | loss: 162.87286| val_0_mse: 175.5554656982422|  0:00:35s\n","epoch 57 | loss: 160.86275| val_0_mse: 219.33624267578125|  0:00:35s\n","epoch 58 | loss: 156.89394| val_0_mse: 161.33753967285156|  0:00:36s\n","epoch 59 | loss: 154.22905| val_0_mse: 169.96798706054688|  0:00:36s\n","epoch 60 | loss: 158.45538| val_0_mse: 185.7035675048828|  0:00:37s\n","epoch 61 | loss: 171.33466| val_0_mse: 179.45359802246094|  0:00:38s\n","epoch 62 | loss: 157.56957| val_0_mse: 184.22230529785156|  0:00:38s\n","epoch 63 | loss: 165.62555| val_0_mse: 181.31492614746094|  0:00:39s\n","epoch 64 | loss: 163.47417| val_0_mse: 165.27105712890625|  0:00:40s\n","epoch 65 | loss: 159.50631| val_0_mse: 218.08721923828125|  0:00:40s\n","\n","Early stopping occurred at epoch 65 with best_epoch = 55 and best_val_0_mse = 160.20994567871094\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 15:26:10,740] Trial 82 finished with value: 160.20994567871094 and parameters: {'n_d': 45, 'n_steps': 3, 'gamma': 1.5200552344555958, 'n_independent': 3, 'n_shared': 3, 'momentum': 0.1826859501857489}. Best is trial 33 with value: 135.8055877685547.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 2048.31432| val_0_mse: 5564.83203125|  0:00:00s\n","epoch 1  | loss: 1086.27686| val_0_mse: 5683.69580078125|  0:00:01s\n","epoch 2  | loss: 484.91261| val_0_mse: 4292.0283203125|  0:00:01s\n","epoch 3  | loss: 438.18312| val_0_mse: 1320.192138671875|  0:00:02s\n","epoch 4  | loss: 359.03277| val_0_mse: 862.985107421875|  0:00:03s\n","epoch 5  | loss: 319.73634| val_0_mse: 1543.514892578125|  0:00:03s\n","epoch 6  | loss: 314.16071| val_0_mse: 1134.56982421875|  0:00:04s\n","epoch 7  | loss: 296.13082| val_0_mse: 892.4373779296875|  0:00:05s\n","epoch 8  | loss: 295.59268| val_0_mse: 583.8140869140625|  0:00:05s\n","epoch 9  | loss: 293.68347| val_0_mse: 640.221435546875|  0:00:06s\n","epoch 10 | loss: 274.12491| val_0_mse: 606.2587280273438|  0:00:06s\n","epoch 11 | loss: 265.23638| val_0_mse: 860.7816772460938|  0:00:07s\n","epoch 12 | loss: 261.90375| val_0_mse: 751.841064453125|  0:00:08s\n","epoch 13 | loss: 255.43808| val_0_mse: 745.7471923828125|  0:00:08s\n","epoch 14 | loss: 245.79381| val_0_mse: 518.6162109375|  0:00:09s\n","epoch 15 | loss: 246.14435| val_0_mse: 584.0474243164062|  0:00:09s\n","epoch 16 | loss: 238.33019| val_0_mse: 526.4441528320312|  0:00:10s\n","epoch 17 | loss: 240.44775| val_0_mse: 507.6049499511719|  0:00:11s\n","epoch 18 | loss: 237.27953| val_0_mse: 480.0544738769531|  0:00:11s\n","epoch 19 | loss: 243.21093| val_0_mse: 378.0284118652344|  0:00:12s\n","epoch 20 | loss: 242.33173| val_0_mse: 404.765625|  0:00:12s\n","epoch 21 | loss: 232.8654| val_0_mse: 433.2978515625|  0:00:13s\n","epoch 22 | loss: 221.33325| val_0_mse: 385.6594543457031|  0:00:14s\n","epoch 23 | loss: 224.22736| val_0_mse: 351.4832763671875|  0:00:14s\n","epoch 24 | loss: 222.98742| val_0_mse: 324.339111328125|  0:00:15s\n","epoch 25 | loss: 229.8889| val_0_mse: 292.56927490234375|  0:00:16s\n","epoch 26 | loss: 222.52192| val_0_mse: 252.56649780273438|  0:00:16s\n","epoch 27 | loss: 215.99419| val_0_mse: 232.56668090820312|  0:00:17s\n","epoch 28 | loss: 216.85164| val_0_mse: 270.73443603515625|  0:00:18s\n","epoch 29 | loss: 212.40479| val_0_mse: 246.0379638671875|  0:00:18s\n","epoch 30 | loss: 214.98807| val_0_mse: 225.68460083007812|  0:00:19s\n","epoch 31 | loss: 208.61003| val_0_mse: 233.91250610351562|  0:00:19s\n","epoch 32 | loss: 199.51719| val_0_mse: 213.58575439453125|  0:00:20s\n","epoch 33 | loss: 201.61552| val_0_mse: 209.72616577148438|  0:00:21s\n","epoch 34 | loss: 207.85987| val_0_mse: 213.53733825683594|  0:00:21s\n","epoch 35 | loss: 198.64586| val_0_mse: 193.43882751464844|  0:00:22s\n","epoch 36 | loss: 193.19252| val_0_mse: 195.25607299804688|  0:00:23s\n","epoch 37 | loss: 190.62641| val_0_mse: 209.9110565185547|  0:00:23s\n","epoch 38 | loss: 193.27508| val_0_mse: 198.79722595214844|  0:00:24s\n","epoch 39 | loss: 190.62699| val_0_mse: 199.4800567626953|  0:00:24s\n","epoch 40 | loss: 180.00642| val_0_mse: 189.3671875|  0:00:25s\n","epoch 41 | loss: 176.37899| val_0_mse: 191.4873046875|  0:00:26s\n","epoch 42 | loss: 178.62106| val_0_mse: 187.59515380859375|  0:00:26s\n","epoch 43 | loss: 178.86028| val_0_mse: 196.52073669433594|  0:00:27s\n","epoch 44 | loss: 175.16902| val_0_mse: 216.50845336914062|  0:00:28s\n","epoch 45 | loss: 186.58393| val_0_mse: 200.1616668701172|  0:00:28s\n","epoch 46 | loss: 182.19843| val_0_mse: 200.32200622558594|  0:00:29s\n","epoch 47 | loss: 185.54225| val_0_mse: 184.9945068359375|  0:00:29s\n","epoch 48 | loss: 180.01903| val_0_mse: 182.27149963378906|  0:00:30s\n","epoch 49 | loss: 178.15369| val_0_mse: 187.19830322265625|  0:00:31s\n","epoch 50 | loss: 170.91281| val_0_mse: 199.62901306152344|  0:00:31s\n","epoch 51 | loss: 171.96755| val_0_mse: 188.45803833007812|  0:00:32s\n","epoch 52 | loss: 163.05896| val_0_mse: 185.4642333984375|  0:00:32s\n","epoch 53 | loss: 168.18304| val_0_mse: 205.7919464111328|  0:00:33s\n","epoch 54 | loss: 171.28721| val_0_mse: 201.68923950195312|  0:00:34s\n","epoch 55 | loss: 167.75842| val_0_mse: 183.7075653076172|  0:00:34s\n","epoch 56 | loss: 168.04906| val_0_mse: 183.07095336914062|  0:00:35s\n","epoch 57 | loss: 164.4511| val_0_mse: 196.3721923828125|  0:00:36s\n","epoch 58 | loss: 171.33624| val_0_mse: 182.82786560058594|  0:00:36s\n","\n","Early stopping occurred at epoch 58 with best_epoch = 48 and best_val_0_mse = 182.27149963378906\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 15:26:47,716] Trial 83 finished with value: 182.27149963378906 and parameters: {'n_d': 24, 'n_steps': 3, 'gamma': 1.4490421351458058, 'n_independent': 3, 'n_shared': 3, 'momentum': 0.12459014937131085}. Best is trial 33 with value: 135.8055877685547.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 1968.87709| val_0_mse: 14324.3291015625|  0:00:00s\n","epoch 1  | loss: 860.85124| val_0_mse: 2528.374755859375|  0:00:01s\n","epoch 2  | loss: 437.89837| val_0_mse: 3786.949462890625|  0:00:01s\n","epoch 3  | loss: 378.95902| val_0_mse: 2098.245361328125|  0:00:02s\n","epoch 4  | loss: 323.50125| val_0_mse: 5523.79833984375|  0:00:03s\n","epoch 5  | loss: 303.79746| val_0_mse: 2041.2410888671875|  0:00:03s\n","epoch 6  | loss: 290.47757| val_0_mse: 2210.607421875|  0:00:04s\n","epoch 7  | loss: 278.42482| val_0_mse: 717.5811157226562|  0:00:04s\n","epoch 8  | loss: 259.79505| val_0_mse: 762.5429077148438|  0:00:05s\n","epoch 9  | loss: 238.66514| val_0_mse: 701.4546508789062|  0:00:06s\n","epoch 10 | loss: 238.96392| val_0_mse: 641.3330078125|  0:00:06s\n","epoch 11 | loss: 238.04503| val_0_mse: 653.0042724609375|  0:00:07s\n","epoch 12 | loss: 227.83252| val_0_mse: 568.6273803710938|  0:00:07s\n","epoch 13 | loss: 230.25695| val_0_mse: 449.948974609375|  0:00:08s\n","epoch 14 | loss: 221.72794| val_0_mse: 565.5744018554688|  0:00:09s\n","epoch 15 | loss: 212.91482| val_0_mse: 486.5296325683594|  0:00:09s\n","epoch 16 | loss: 208.27886| val_0_mse: 462.4750671386719|  0:00:10s\n","epoch 17 | loss: 214.66711| val_0_mse: 364.5054931640625|  0:00:11s\n","epoch 18 | loss: 211.72288| val_0_mse: 577.3282470703125|  0:00:11s\n","epoch 19 | loss: 205.9634| val_0_mse: 635.4845581054688|  0:00:12s\n","epoch 20 | loss: 208.00594| val_0_mse: 259.671875|  0:00:12s\n","epoch 21 | loss: 204.37701| val_0_mse: 239.34765625|  0:00:13s\n","epoch 22 | loss: 195.85853| val_0_mse: 239.07484436035156|  0:00:14s\n","epoch 23 | loss: 188.22012| val_0_mse: 251.71029663085938|  0:00:14s\n","epoch 24 | loss: 196.60961| val_0_mse: 214.2822265625|  0:00:15s\n","epoch 25 | loss: 190.08608| val_0_mse: 210.71438598632812|  0:00:16s\n","epoch 26 | loss: 185.84955| val_0_mse: 216.2064666748047|  0:00:16s\n","epoch 27 | loss: 190.02039| val_0_mse: 214.52342224121094|  0:00:17s\n","epoch 28 | loss: 178.75524| val_0_mse: 225.02049255371094|  0:00:17s\n","epoch 29 | loss: 179.80101| val_0_mse: 281.27294921875|  0:00:18s\n","epoch 30 | loss: 178.16761| val_0_mse: 206.55020141601562|  0:00:19s\n","epoch 31 | loss: 178.98989| val_0_mse: 166.19940185546875|  0:00:19s\n","epoch 32 | loss: 170.171 | val_0_mse: 214.62094116210938|  0:00:20s\n","epoch 33 | loss: 177.84765| val_0_mse: 282.7835693359375|  0:00:21s\n","epoch 34 | loss: 187.08605| val_0_mse: 208.3457794189453|  0:00:21s\n","epoch 35 | loss: 178.83498| val_0_mse: 194.66050720214844|  0:00:22s\n","epoch 36 | loss: 177.30473| val_0_mse: 175.3844757080078|  0:00:22s\n","epoch 37 | loss: 172.32012| val_0_mse: 177.9320526123047|  0:00:23s\n","epoch 38 | loss: 168.55081| val_0_mse: 178.71597290039062|  0:00:24s\n","epoch 39 | loss: 169.98678| val_0_mse: 281.8017272949219|  0:00:24s\n","epoch 40 | loss: 171.18482| val_0_mse: 192.705322265625|  0:00:25s\n","epoch 41 | loss: 159.93412| val_0_mse: 178.64418029785156|  0:00:26s\n","\n","Early stopping occurred at epoch 41 with best_epoch = 31 and best_val_0_mse = 166.19940185546875\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 15:27:14,121] Trial 84 finished with value: 166.19940185546875 and parameters: {'n_d': 29, 'n_steps': 3, 'gamma': 1.5019345914076856, 'n_independent': 3, 'n_shared': 3, 'momentum': 0.11209331353475968}. Best is trial 33 with value: 135.8055877685547.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 1646.11777| val_0_mse: 12394.126953125|  0:00:00s\n","epoch 1  | loss: 520.61567| val_0_mse: 6690.32373046875|  0:00:01s\n","epoch 2  | loss: 397.93046| val_0_mse: 1886.4820556640625|  0:00:01s\n","epoch 3  | loss: 335.50882| val_0_mse: 20625.283203125|  0:00:02s\n","epoch 4  | loss: 309.97466| val_0_mse: 16660.212890625|  0:00:02s\n","epoch 5  | loss: 293.49368| val_0_mse: 11789.2763671875|  0:00:03s\n","epoch 6  | loss: 290.16331| val_0_mse: 12092.6396484375|  0:00:03s\n","epoch 7  | loss: 266.18095| val_0_mse: 9211.9443359375|  0:00:04s\n","epoch 8  | loss: 269.44938| val_0_mse: 7009.12255859375|  0:00:05s\n","epoch 9  | loss: 262.50947| val_0_mse: 4349.4130859375|  0:00:05s\n","epoch 10 | loss: 250.32256| val_0_mse: 1648.879150390625|  0:00:06s\n","epoch 11 | loss: 250.52023| val_0_mse: 911.9422607421875|  0:00:06s\n","epoch 12 | loss: 253.39277| val_0_mse: 1196.94970703125|  0:00:07s\n","epoch 13 | loss: 249.83003| val_0_mse: 1116.4732666015625|  0:00:08s\n","epoch 14 | loss: 233.44496| val_0_mse: 879.339111328125|  0:00:08s\n","epoch 15 | loss: 234.43298| val_0_mse: 1741.713134765625|  0:00:09s\n","epoch 16 | loss: 249.20217| val_0_mse: 1097.7916259765625|  0:00:09s\n","epoch 17 | loss: 236.25899| val_0_mse: 1641.954833984375|  0:00:10s\n","epoch 18 | loss: 235.51381| val_0_mse: 1257.898193359375|  0:00:10s\n","epoch 19 | loss: 224.68531| val_0_mse: 650.0703125|  0:00:11s\n","epoch 20 | loss: 221.26611| val_0_mse: 513.3060302734375|  0:00:11s\n","epoch 21 | loss: 226.50525| val_0_mse: 512.7916870117188|  0:00:12s\n","epoch 22 | loss: 212.8483| val_0_mse: 369.3414306640625|  0:00:13s\n","epoch 23 | loss: 210.27047| val_0_mse: 486.8759460449219|  0:00:13s\n","epoch 24 | loss: 211.48392| val_0_mse: 346.7940368652344|  0:00:14s\n","epoch 25 | loss: 197.81616| val_0_mse: 339.2597351074219|  0:00:14s\n","epoch 26 | loss: 199.48444| val_0_mse: 340.4517517089844|  0:00:15s\n","epoch 27 | loss: 193.2077| val_0_mse: 298.3258056640625|  0:00:15s\n","epoch 28 | loss: 202.49767| val_0_mse: 284.3069152832031|  0:00:16s\n","epoch 29 | loss: 191.63134| val_0_mse: 265.59033203125|  0:00:17s\n","epoch 30 | loss: 188.86604| val_0_mse: 226.53854370117188|  0:00:17s\n","epoch 31 | loss: 184.52143| val_0_mse: 237.6569061279297|  0:00:18s\n","epoch 32 | loss: 190.34554| val_0_mse: 252.35324096679688|  0:00:18s\n","epoch 33 | loss: 186.22195| val_0_mse: 209.5295867919922|  0:00:19s\n","epoch 34 | loss: 179.70443| val_0_mse: 206.52748107910156|  0:00:19s\n","epoch 35 | loss: 176.78678| val_0_mse: 257.31744384765625|  0:00:20s\n","epoch 36 | loss: 183.50541| val_0_mse: 251.04710388183594|  0:00:20s\n","epoch 37 | loss: 177.83659| val_0_mse: 210.93385314941406|  0:00:21s\n","epoch 38 | loss: 179.72523| val_0_mse: 201.7057647705078|  0:00:22s\n","epoch 39 | loss: 189.83929| val_0_mse: 209.1433563232422|  0:00:22s\n","epoch 40 | loss: 188.07441| val_0_mse: 247.41664123535156|  0:00:23s\n","epoch 41 | loss: 191.9001| val_0_mse: 203.1497802734375|  0:00:23s\n","epoch 42 | loss: 177.14483| val_0_mse: 196.21328735351562|  0:00:24s\n","epoch 43 | loss: 173.06011| val_0_mse: 206.80979919433594|  0:00:24s\n","epoch 44 | loss: 164.69825| val_0_mse: 199.81564331054688|  0:00:25s\n","epoch 45 | loss: 172.6443| val_0_mse: 208.493896484375|  0:00:25s\n","epoch 46 | loss: 163.41786| val_0_mse: 214.96670532226562|  0:00:26s\n","epoch 47 | loss: 162.67462| val_0_mse: 204.12075805664062|  0:00:27s\n","epoch 48 | loss: 170.11736| val_0_mse: 238.66278076171875|  0:00:27s\n","epoch 49 | loss: 168.51249| val_0_mse: 179.4435272216797|  0:00:28s\n","epoch 50 | loss: 155.79639| val_0_mse: 186.16937255859375|  0:00:28s\n","epoch 51 | loss: 162.09752| val_0_mse: 194.9996337890625|  0:00:29s\n","epoch 52 | loss: 157.47893| val_0_mse: 195.35104370117188|  0:00:29s\n","epoch 53 | loss: 162.84311| val_0_mse: 213.49400329589844|  0:00:30s\n","epoch 54 | loss: 157.79372| val_0_mse: 206.21624755859375|  0:00:31s\n","epoch 55 | loss: 154.10153| val_0_mse: 194.8794403076172|  0:00:31s\n","epoch 56 | loss: 156.30589| val_0_mse: 171.60447692871094|  0:00:32s\n","epoch 57 | loss: 153.87936| val_0_mse: 173.98997497558594|  0:00:32s\n","epoch 58 | loss: 154.44241| val_0_mse: 197.3183135986328|  0:00:33s\n","epoch 59 | loss: 150.41257| val_0_mse: 178.60888671875|  0:00:33s\n","epoch 60 | loss: 151.33886| val_0_mse: 182.38650512695312|  0:00:34s\n","epoch 61 | loss: 152.666 | val_0_mse: 172.773193359375|  0:00:34s\n","epoch 62 | loss: 147.5606| val_0_mse: 184.46029663085938|  0:00:35s\n","epoch 63 | loss: 149.92799| val_0_mse: 176.93394470214844|  0:00:35s\n","epoch 64 | loss: 150.05965| val_0_mse: 172.3673858642578|  0:00:36s\n","epoch 65 | loss: 147.16738| val_0_mse: 191.28341674804688|  0:00:37s\n","epoch 66 | loss: 148.30057| val_0_mse: 184.551025390625|  0:00:37s\n","\n","Early stopping occurred at epoch 66 with best_epoch = 56 and best_val_0_mse = 171.60447692871094\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 15:27:52,113] Trial 85 finished with value: 171.60447692871094 and parameters: {'n_d': 39, 'n_steps': 3, 'gamma': 1.567239492026526, 'n_independent': 3, 'n_shared': 2, 'momentum': 0.14047704916007148}. Best is trial 33 with value: 135.8055877685547.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 1717.0827| val_0_mse: 13393.3916015625|  0:00:00s\n","epoch 1  | loss: 625.57703| val_0_mse: 11291.9287109375|  0:00:01s\n","epoch 2  | loss: 494.372 | val_0_mse: 3720.770263671875|  0:00:02s\n","epoch 3  | loss: 420.35473| val_0_mse: 1428.8165283203125|  0:00:03s\n","epoch 4  | loss: 387.25534| val_0_mse: 6168.841796875|  0:00:03s\n","epoch 5  | loss: 357.5239| val_0_mse: 6014.39697265625|  0:00:04s\n","epoch 6  | loss: 381.06457| val_0_mse: 3490.154541015625|  0:00:05s\n","epoch 7  | loss: 343.34032| val_0_mse: 2685.16455078125|  0:00:06s\n","epoch 8  | loss: 329.08379| val_0_mse: 3898.228515625|  0:00:06s\n","epoch 9  | loss: 301.03592| val_0_mse: 2201.531494140625|  0:00:07s\n","epoch 10 | loss: 315.72033| val_0_mse: 1239.245361328125|  0:00:08s\n","epoch 11 | loss: 285.97175| val_0_mse: 592.2718505859375|  0:00:08s\n","epoch 12 | loss: 271.27898| val_0_mse: 690.177490234375|  0:00:09s\n","epoch 13 | loss: 260.35895| val_0_mse: 577.73681640625|  0:00:10s\n","epoch 14 | loss: 259.7693| val_0_mse: 422.34869384765625|  0:00:11s\n","epoch 15 | loss: 249.54375| val_0_mse: 589.6812133789062|  0:00:11s\n","epoch 16 | loss: 244.86171| val_0_mse: 586.9599609375|  0:00:12s\n","epoch 17 | loss: 243.0377| val_0_mse: 486.9906311035156|  0:00:13s\n","epoch 18 | loss: 238.86651| val_0_mse: 395.44158935546875|  0:00:14s\n","epoch 19 | loss: 224.39519| val_0_mse: 325.11773681640625|  0:00:15s\n","epoch 20 | loss: 226.76246| val_0_mse: 324.1636962890625|  0:00:15s\n","epoch 21 | loss: 233.29844| val_0_mse: 434.7441711425781|  0:00:16s\n","epoch 22 | loss: 245.2805| val_0_mse: 314.4979248046875|  0:00:17s\n","epoch 23 | loss: 244.30506| val_0_mse: 264.1571044921875|  0:00:18s\n","epoch 24 | loss: 226.61348| val_0_mse: 262.3121643066406|  0:00:18s\n","epoch 25 | loss: 229.46437| val_0_mse: 269.9342346191406|  0:00:19s\n","epoch 26 | loss: 223.81122| val_0_mse: 252.36236572265625|  0:00:20s\n","epoch 27 | loss: 213.62182| val_0_mse: 252.9681396484375|  0:00:20s\n","epoch 28 | loss: 224.18868| val_0_mse: 235.317626953125|  0:00:21s\n","epoch 29 | loss: 212.24291| val_0_mse: 233.73826599121094|  0:00:22s\n","epoch 30 | loss: 208.34622| val_0_mse: 214.0908203125|  0:00:23s\n","epoch 31 | loss: 228.23888| val_0_mse: 219.7683868408203|  0:00:24s\n","epoch 32 | loss: 221.42659| val_0_mse: 268.074462890625|  0:00:24s\n","epoch 33 | loss: 211.03277| val_0_mse: 247.37974548339844|  0:00:25s\n","epoch 34 | loss: 212.87636| val_0_mse: 217.57510375976562|  0:00:26s\n","epoch 35 | loss: 206.0594| val_0_mse: 216.26112365722656|  0:00:27s\n","epoch 36 | loss: 208.54179| val_0_mse: 205.99603271484375|  0:00:27s\n","epoch 37 | loss: 194.14097| val_0_mse: 200.73243713378906|  0:00:28s\n","epoch 38 | loss: 202.6749| val_0_mse: 219.5750732421875|  0:00:29s\n","epoch 39 | loss: 202.90021| val_0_mse: 211.10513305664062|  0:00:29s\n","epoch 40 | loss: 200.51991| val_0_mse: 190.7826385498047|  0:00:30s\n","epoch 41 | loss: 199.9273| val_0_mse: 231.06741333007812|  0:00:31s\n","epoch 42 | loss: 204.74834| val_0_mse: 190.97337341308594|  0:00:32s\n","epoch 43 | loss: 196.10613| val_0_mse: 201.42669677734375|  0:00:32s\n","epoch 44 | loss: 191.36081| val_0_mse: 193.61561584472656|  0:00:33s\n","epoch 45 | loss: 187.67763| val_0_mse: 199.87506103515625|  0:00:34s\n","epoch 46 | loss: 178.26146| val_0_mse: 184.67576599121094|  0:00:35s\n","epoch 47 | loss: 183.21773| val_0_mse: 219.06005859375|  0:00:35s\n","epoch 48 | loss: 193.18523| val_0_mse: 193.1898651123047|  0:00:36s\n","epoch 49 | loss: 188.99268| val_0_mse: 179.52464294433594|  0:00:37s\n","epoch 50 | loss: 180.20666| val_0_mse: 185.86500549316406|  0:00:38s\n","epoch 51 | loss: 185.31822| val_0_mse: 185.4606475830078|  0:00:38s\n","epoch 52 | loss: 179.03072| val_0_mse: 177.77932739257812|  0:00:39s\n","epoch 53 | loss: 192.46571| val_0_mse: 192.2246856689453|  0:00:40s\n","epoch 54 | loss: 194.12708| val_0_mse: 222.6880340576172|  0:00:41s\n","epoch 55 | loss: 184.84802| val_0_mse: 185.16061401367188|  0:00:42s\n","epoch 56 | loss: 182.78042| val_0_mse: 191.7234344482422|  0:00:42s\n","epoch 57 | loss: 177.77172| val_0_mse: 185.35316467285156|  0:00:43s\n","epoch 58 | loss: 175.63962| val_0_mse: 176.39793395996094|  0:00:44s\n","epoch 59 | loss: 166.67808| val_0_mse: 182.93020629882812|  0:00:44s\n","epoch 60 | loss: 175.09364| val_0_mse: 177.1551971435547|  0:00:45s\n","epoch 61 | loss: 176.88534| val_0_mse: 184.9551544189453|  0:00:46s\n","epoch 62 | loss: 173.30755| val_0_mse: 192.05752563476562|  0:00:47s\n","epoch 63 | loss: 166.87879| val_0_mse: 179.32994079589844|  0:00:47s\n","epoch 64 | loss: 165.80463| val_0_mse: 187.87635803222656|  0:00:48s\n","epoch 65 | loss: 160.16859| val_0_mse: 172.30787658691406|  0:00:49s\n","epoch 66 | loss: 167.87864| val_0_mse: 166.69216918945312|  0:00:50s\n","epoch 67 | loss: 168.52577| val_0_mse: 184.1779022216797|  0:00:50s\n","epoch 68 | loss: 172.10892| val_0_mse: 185.2050018310547|  0:00:51s\n","epoch 69 | loss: 163.57544| val_0_mse: 171.24972534179688|  0:00:52s\n","epoch 70 | loss: 171.14757| val_0_mse: 211.09034729003906|  0:00:52s\n","epoch 71 | loss: 172.01741| val_0_mse: 178.82215881347656|  0:00:53s\n","epoch 72 | loss: 179.76991| val_0_mse: 190.35072326660156|  0:00:54s\n","epoch 73 | loss: 174.55888| val_0_mse: 170.63856506347656|  0:00:55s\n","epoch 74 | loss: 161.29032| val_0_mse: 179.09669494628906|  0:00:55s\n","epoch 75 | loss: 157.38358| val_0_mse: 165.8631591796875|  0:00:56s\n","epoch 76 | loss: 162.6183| val_0_mse: 197.64120483398438|  0:00:57s\n","epoch 77 | loss: 162.91365| val_0_mse: 171.89703369140625|  0:00:58s\n","epoch 78 | loss: 163.31586| val_0_mse: 163.73544311523438|  0:00:58s\n","epoch 79 | loss: 160.67183| val_0_mse: 190.44252014160156|  0:00:59s\n","epoch 80 | loss: 170.61245| val_0_mse: 185.7798614501953|  0:01:00s\n","epoch 81 | loss: 155.02629| val_0_mse: 159.9085235595703|  0:01:01s\n","epoch 82 | loss: 153.83042| val_0_mse: 177.50643920898438|  0:01:01s\n","epoch 83 | loss: 170.78475| val_0_mse: 179.58526611328125|  0:01:02s\n","epoch 84 | loss: 160.98089| val_0_mse: 166.37071228027344|  0:01:03s\n","epoch 85 | loss: 155.9543| val_0_mse: 189.33099365234375|  0:01:03s\n","epoch 86 | loss: 155.86515| val_0_mse: 173.89154052734375|  0:01:04s\n","epoch 87 | loss: 151.39852| val_0_mse: 216.40081787109375|  0:01:05s\n","epoch 88 | loss: 154.69652| val_0_mse: 183.37315368652344|  0:01:06s\n","epoch 89 | loss: 156.19399| val_0_mse: 177.356201171875|  0:01:06s\n","epoch 90 | loss: 163.27468| val_0_mse: 192.7059326171875|  0:01:07s\n","epoch 91 | loss: 172.90557| val_0_mse: 175.5906219482422|  0:01:08s\n","\n","Early stopping occurred at epoch 91 with best_epoch = 81 and best_val_0_mse = 159.9085235595703\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 15:29:01,076] Trial 86 finished with value: 159.9085235595703 and parameters: {'n_d': 57, 'n_steps': 4, 'gamma': 1.6080041473438171, 'n_independent': 3, 'n_shared': 3, 'momentum': 0.1508167878319576}. Best is trial 33 with value: 135.8055877685547.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 1680.64083| val_0_mse: 82175.4921875|  0:00:00s\n","epoch 1  | loss: 488.80549| val_0_mse: 21068.8125|  0:00:01s\n","epoch 2  | loss: 371.08597| val_0_mse: 3962.76025390625|  0:00:01s\n","epoch 3  | loss: 330.29266| val_0_mse: 13328.134765625|  0:00:02s\n","epoch 4  | loss: 307.18449| val_0_mse: 4070.910400390625|  0:00:03s\n","epoch 5  | loss: 297.72578| val_0_mse: 2181.192626953125|  0:00:03s\n","epoch 6  | loss: 280.1944| val_0_mse: 1630.3944091796875|  0:00:04s\n","epoch 7  | loss: 250.32642| val_0_mse: 1565.1595458984375|  0:00:04s\n","epoch 8  | loss: 252.20277| val_0_mse: 730.9839477539062|  0:00:05s\n","epoch 9  | loss: 233.6944| val_0_mse: 485.6582946777344|  0:00:06s\n","epoch 10 | loss: 244.48715| val_0_mse: 562.8402709960938|  0:00:06s\n","epoch 11 | loss: 233.61592| val_0_mse: 528.8280029296875|  0:00:07s\n","epoch 12 | loss: 223.71887| val_0_mse: 503.9717712402344|  0:00:07s\n","epoch 13 | loss: 211.10625| val_0_mse: 959.3309326171875|  0:00:08s\n","epoch 14 | loss: 207.28493| val_0_mse: 504.2167663574219|  0:00:09s\n","epoch 15 | loss: 211.22932| val_0_mse: 623.7365112304688|  0:00:09s\n","epoch 16 | loss: 211.95957| val_0_mse: 413.19189453125|  0:00:10s\n","epoch 17 | loss: 205.73663| val_0_mse: 788.3942260742188|  0:00:10s\n","epoch 18 | loss: 201.07145| val_0_mse: 408.62689208984375|  0:00:11s\n","epoch 19 | loss: 189.30551| val_0_mse: 386.42340087890625|  0:00:12s\n","epoch 20 | loss: 193.44548| val_0_mse: 481.7582092285156|  0:00:12s\n","epoch 21 | loss: 203.66686| val_0_mse: 479.0412902832031|  0:00:13s\n","epoch 22 | loss: 193.17338| val_0_mse: 386.59088134765625|  0:00:14s\n","epoch 23 | loss: 188.1125| val_0_mse: 311.6715087890625|  0:00:14s\n","epoch 24 | loss: 195.68846| val_0_mse: 271.61279296875|  0:00:15s\n","epoch 25 | loss: 185.40853| val_0_mse: 269.17352294921875|  0:00:15s\n","epoch 26 | loss: 190.3478| val_0_mse: 263.15667724609375|  0:00:16s\n","epoch 27 | loss: 182.81549| val_0_mse: 334.1125793457031|  0:00:17s\n","epoch 28 | loss: 179.35373| val_0_mse: 341.0010070800781|  0:00:17s\n","epoch 29 | loss: 178.37369| val_0_mse: 341.8379211425781|  0:00:18s\n","epoch 30 | loss: 174.7164| val_0_mse: 340.9195556640625|  0:00:18s\n","epoch 31 | loss: 171.15247| val_0_mse: 205.85897827148438|  0:00:19s\n","epoch 32 | loss: 174.70238| val_0_mse: 229.58285522460938|  0:00:20s\n","epoch 33 | loss: 174.95362| val_0_mse: 213.0288543701172|  0:00:20s\n","epoch 34 | loss: 169.37043| val_0_mse: 239.29518127441406|  0:00:21s\n","epoch 35 | loss: 173.12491| val_0_mse: 237.44383239746094|  0:00:22s\n","epoch 36 | loss: 169.18379| val_0_mse: 219.794677734375|  0:00:22s\n","epoch 37 | loss: 173.90057| val_0_mse: 211.10638427734375|  0:00:23s\n","epoch 38 | loss: 179.19904| val_0_mse: 229.505859375|  0:00:24s\n","epoch 39 | loss: 169.42475| val_0_mse: 207.1749725341797|  0:00:24s\n","epoch 40 | loss: 165.36327| val_0_mse: 240.16737365722656|  0:00:25s\n","epoch 41 | loss: 166.71823| val_0_mse: 193.28990173339844|  0:00:25s\n","epoch 42 | loss: 159.43817| val_0_mse: 220.71084594726562|  0:00:26s\n","epoch 43 | loss: 169.25439| val_0_mse: 195.77525329589844|  0:00:27s\n","epoch 44 | loss: 169.1816| val_0_mse: 174.6916046142578|  0:00:27s\n","epoch 45 | loss: 167.49287| val_0_mse: 200.46043395996094|  0:00:28s\n","epoch 46 | loss: 161.05268| val_0_mse: 177.97247314453125|  0:00:28s\n","epoch 47 | loss: 156.28577| val_0_mse: 181.97569274902344|  0:00:29s\n","epoch 48 | loss: 155.67822| val_0_mse: 191.38665771484375|  0:00:30s\n","epoch 49 | loss: 157.13846| val_0_mse: 180.8893585205078|  0:00:30s\n","epoch 50 | loss: 167.09781| val_0_mse: 177.43357849121094|  0:00:31s\n","epoch 51 | loss: 150.89532| val_0_mse: 169.1800537109375|  0:00:31s\n","epoch 52 | loss: 158.36069| val_0_mse: 173.8431396484375|  0:00:32s\n","epoch 53 | loss: 151.83862| val_0_mse: 195.9355926513672|  0:00:33s\n","epoch 54 | loss: 152.52756| val_0_mse: 174.48008728027344|  0:00:33s\n","epoch 55 | loss: 152.48111| val_0_mse: 163.13963317871094|  0:00:34s\n","epoch 56 | loss: 149.38517| val_0_mse: 170.4079132080078|  0:00:35s\n","epoch 57 | loss: 142.46477| val_0_mse: 162.4313201904297|  0:00:35s\n","epoch 58 | loss: 143.22745| val_0_mse: 163.29721069335938|  0:00:36s\n","epoch 59 | loss: 142.61915| val_0_mse: 174.4945068359375|  0:00:36s\n","epoch 60 | loss: 140.3319| val_0_mse: 177.89991760253906|  0:00:37s\n","epoch 61 | loss: 147.75761| val_0_mse: 184.56919860839844|  0:00:38s\n","epoch 62 | loss: 147.08575| val_0_mse: 164.59280395507812|  0:00:38s\n","epoch 63 | loss: 149.12753| val_0_mse: 168.0951385498047|  0:00:39s\n","epoch 64 | loss: 143.0419| val_0_mse: 170.7492218017578|  0:00:39s\n","epoch 65 | loss: 145.63009| val_0_mse: 167.0248260498047|  0:00:40s\n","epoch 66 | loss: 142.28841| val_0_mse: 167.31475830078125|  0:00:41s\n","epoch 67 | loss: 134.75564| val_0_mse: 164.5079803466797|  0:00:41s\n","\n","Early stopping occurred at epoch 67 with best_epoch = 57 and best_val_0_mse = 162.4313201904297\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 15:29:43,223] Trial 87 finished with value: 162.4313201904297 and parameters: {'n_d': 55, 'n_steps': 3, 'gamma': 1.4170070026238428, 'n_independent': 3, 'n_shared': 3, 'momentum': 0.0863598346196018}. Best is trial 33 with value: 135.8055877685547.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 1762.55743| val_0_mse: 35057.875|  0:00:00s\n","epoch 1  | loss: 535.19488| val_0_mse: 10738.2783203125|  0:00:01s\n","epoch 2  | loss: 394.66019| val_0_mse: 9241.6845703125|  0:00:02s\n","epoch 3  | loss: 372.67979| val_0_mse: 1884.08203125|  0:00:03s\n","epoch 4  | loss: 334.43468| val_0_mse: 3736.9052734375|  0:00:04s\n","epoch 5  | loss: 324.79339| val_0_mse: 1188.2335205078125|  0:00:05s\n","epoch 6  | loss: 336.72261| val_0_mse: 11749.369140625|  0:00:05s\n","epoch 7  | loss: 333.13286| val_0_mse: 2440.796142578125|  0:00:06s\n","epoch 8  | loss: 324.16163| val_0_mse: 2221.4765625|  0:00:07s\n","epoch 9  | loss: 300.08879| val_0_mse: 3901.742431640625|  0:00:08s\n","epoch 10 | loss: 292.31636| val_0_mse: 5898.6875|  0:00:09s\n","epoch 11 | loss: 285.67955| val_0_mse: 3523.14794921875|  0:00:09s\n","epoch 12 | loss: 276.00071| val_0_mse: 1155.1705322265625|  0:00:10s\n","epoch 13 | loss: 265.04026| val_0_mse: 1042.8367919921875|  0:00:11s\n","epoch 14 | loss: 261.57295| val_0_mse: 493.3276672363281|  0:00:12s\n","epoch 15 | loss: 291.24858| val_0_mse: 951.531494140625|  0:00:13s\n","epoch 16 | loss: 288.67293| val_0_mse: 615.5762939453125|  0:00:14s\n","epoch 17 | loss: 266.08785| val_0_mse: 631.078125|  0:00:14s\n","epoch 18 | loss: 253.3899| val_0_mse: 447.88494873046875|  0:00:15s\n","epoch 19 | loss: 258.72423| val_0_mse: 548.4668579101562|  0:00:16s\n","epoch 20 | loss: 236.89188| val_0_mse: 481.9377746582031|  0:00:17s\n","epoch 21 | loss: 248.42722| val_0_mse: 423.759033203125|  0:00:18s\n","epoch 22 | loss: 236.46671| val_0_mse: 318.59185791015625|  0:00:19s\n","epoch 23 | loss: 234.0138| val_0_mse: 263.0379333496094|  0:00:19s\n","epoch 24 | loss: 227.07201| val_0_mse: 364.6671447753906|  0:00:20s\n","epoch 25 | loss: 220.45123| val_0_mse: 382.31787109375|  0:00:21s\n","epoch 26 | loss: 214.10369| val_0_mse: 308.9042663574219|  0:00:22s\n","epoch 27 | loss: 231.85969| val_0_mse: 301.1546325683594|  0:00:23s\n","epoch 28 | loss: 218.1368| val_0_mse: 271.7904357910156|  0:00:23s\n","epoch 29 | loss: 216.64232| val_0_mse: 267.7927551269531|  0:00:24s\n","epoch 30 | loss: 205.9601| val_0_mse: 374.0689697265625|  0:00:25s\n","epoch 31 | loss: 211.50254| val_0_mse: 268.9274597167969|  0:00:26s\n","epoch 32 | loss: 202.2003| val_0_mse: 251.75123596191406|  0:00:27s\n","epoch 33 | loss: 208.57316| val_0_mse: 288.9532775878906|  0:00:27s\n","epoch 34 | loss: 203.01775| val_0_mse: 273.53973388671875|  0:00:28s\n","epoch 35 | loss: 197.27932| val_0_mse: 217.1448211669922|  0:00:29s\n","epoch 36 | loss: 199.46295| val_0_mse: 214.02357482910156|  0:00:30s\n","epoch 37 | loss: 197.44527| val_0_mse: 223.86349487304688|  0:00:31s\n","epoch 38 | loss: 203.66356| val_0_mse: 252.44256591796875|  0:00:31s\n","epoch 39 | loss: 213.79283| val_0_mse: 205.49615478515625|  0:00:32s\n","epoch 40 | loss: 220.87912| val_0_mse: 215.33631896972656|  0:00:33s\n","epoch 41 | loss: 201.70315| val_0_mse: 193.71127319335938|  0:00:34s\n","epoch 42 | loss: 189.48939| val_0_mse: 205.05459594726562|  0:00:35s\n","epoch 43 | loss: 200.10873| val_0_mse: 201.45968627929688|  0:00:36s\n","epoch 44 | loss: 199.36425| val_0_mse: 214.85061645507812|  0:00:36s\n","epoch 45 | loss: 192.17996| val_0_mse: 203.7393341064453|  0:00:37s\n","epoch 46 | loss: 187.60368| val_0_mse: 212.9058837890625|  0:00:38s\n","epoch 47 | loss: 190.08698| val_0_mse: 194.90748596191406|  0:00:39s\n","epoch 48 | loss: 194.88249| val_0_mse: 225.00221252441406|  0:00:40s\n","epoch 49 | loss: 190.16797| val_0_mse: 213.58514404296875|  0:00:41s\n","epoch 50 | loss: 182.5499| val_0_mse: 183.0650177001953|  0:00:41s\n","epoch 51 | loss: 181.33017| val_0_mse: 205.6750946044922|  0:00:42s\n","epoch 52 | loss: 188.36769| val_0_mse: 231.1037139892578|  0:00:43s\n","epoch 53 | loss: 186.59731| val_0_mse: 204.57191467285156|  0:00:44s\n","epoch 54 | loss: 188.26862| val_0_mse: 188.36932373046875|  0:00:45s\n","epoch 55 | loss: 189.91036| val_0_mse: 188.4189453125|  0:00:45s\n","epoch 56 | loss: 173.97381| val_0_mse: 190.54049682617188|  0:00:46s\n","epoch 57 | loss: 187.35453| val_0_mse: 229.71820068359375|  0:00:47s\n","epoch 58 | loss: 181.87338| val_0_mse: 220.50205993652344|  0:00:48s\n","epoch 59 | loss: 179.71095| val_0_mse: 196.01211547851562|  0:00:49s\n","epoch 60 | loss: 189.33347| val_0_mse: 191.06619262695312|  0:00:50s\n","\n","Early stopping occurred at epoch 60 with best_epoch = 50 and best_val_0_mse = 183.0650177001953\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 15:30:33,852] Trial 88 finished with value: 183.0650177001953 and parameters: {'n_d': 61, 'n_steps': 4, 'gamma': 1.537169337613544, 'n_independent': 3, 'n_shared': 4, 'momentum': 0.10476554702432075}. Best is trial 33 with value: 135.8055877685547.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 1608.67823| val_0_mse: 6745.97998046875|  0:00:00s\n","epoch 1  | loss: 480.41679| val_0_mse: 1800.4970703125|  0:00:01s\n","epoch 2  | loss: 339.28997| val_0_mse: 15640.998046875|  0:00:01s\n","epoch 3  | loss: 290.9236| val_0_mse: 17937.548828125|  0:00:02s\n","epoch 4  | loss: 283.16853| val_0_mse: 7597.7275390625|  0:00:02s\n","epoch 5  | loss: 270.91597| val_0_mse: 6415.0361328125|  0:00:03s\n","epoch 6  | loss: 258.43708| val_0_mse: 3705.841064453125|  0:00:04s\n","epoch 7  | loss: 245.5779| val_0_mse: 4072.238037109375|  0:00:04s\n","epoch 8  | loss: 250.42744| val_0_mse: 656.7462158203125|  0:00:05s\n","epoch 9  | loss: 254.38431| val_0_mse: 1386.3424072265625|  0:00:05s\n","epoch 10 | loss: 235.06648| val_0_mse: 2464.471923828125|  0:00:06s\n","epoch 11 | loss: 219.99362| val_0_mse: 2254.8193359375|  0:00:06s\n","epoch 12 | loss: 220.47562| val_0_mse: 1724.6590576171875|  0:00:07s\n","epoch 13 | loss: 215.45642| val_0_mse: 1922.073974609375|  0:00:07s\n","epoch 14 | loss: 212.02057| val_0_mse: 1881.857177734375|  0:00:08s\n","epoch 15 | loss: 206.0261| val_0_mse: 979.8663330078125|  0:00:09s\n","epoch 16 | loss: 204.71261| val_0_mse: 1522.686767578125|  0:00:09s\n","epoch 17 | loss: 204.11034| val_0_mse: 1433.8148193359375|  0:00:10s\n","epoch 18 | loss: 203.91137| val_0_mse: 899.9586181640625|  0:00:10s\n","\n","Early stopping occurred at epoch 18 with best_epoch = 8 and best_val_0_mse = 656.7462158203125\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 15:30:45,203] Trial 89 finished with value: 656.7462158203125 and parameters: {'n_d': 47, 'n_steps': 3, 'gamma': 1.391441564484769, 'n_independent': 3, 'n_shared': 2, 'momentum': 0.163488860908185}. Best is trial 33 with value: 135.8055877685547.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 1727.73439| val_0_mse: 18617.8203125|  0:00:00s\n","epoch 1  | loss: 603.41442| val_0_mse: 4146.2841796875|  0:00:01s\n","epoch 2  | loss: 398.28407| val_0_mse: 33692.83984375|  0:00:02s\n","epoch 3  | loss: 342.82475| val_0_mse: 27567.564453125|  0:00:03s\n","epoch 4  | loss: 324.16619| val_0_mse: 12827.1767578125|  0:00:03s\n","epoch 5  | loss: 292.80624| val_0_mse: 41049.484375|  0:00:04s\n","epoch 6  | loss: 266.10112| val_0_mse: 14933.115234375|  0:00:05s\n","epoch 7  | loss: 257.48811| val_0_mse: 11812.078125|  0:00:05s\n","epoch 8  | loss: 247.23998| val_0_mse: 12645.677734375|  0:00:06s\n","epoch 9  | loss: 240.80315| val_0_mse: 4620.3603515625|  0:00:07s\n","epoch 10 | loss: 243.86943| val_0_mse: 2382.5673828125|  0:00:08s\n","epoch 11 | loss: 243.43727| val_0_mse: 3195.44970703125|  0:00:08s\n","epoch 12 | loss: 237.61519| val_0_mse: 2239.049072265625|  0:00:09s\n","epoch 13 | loss: 224.99195| val_0_mse: 1570.5621337890625|  0:00:10s\n","epoch 14 | loss: 219.06932| val_0_mse: 1192.3699951171875|  0:00:11s\n","epoch 15 | loss: 220.78826| val_0_mse: 976.572265625|  0:00:12s\n","epoch 16 | loss: 227.30979| val_0_mse: 812.0008544921875|  0:00:12s\n","epoch 17 | loss: 215.97683| val_0_mse: 653.7339477539062|  0:00:13s\n","epoch 18 | loss: 212.43863| val_0_mse: 484.786865234375|  0:00:14s\n","epoch 19 | loss: 210.39694| val_0_mse: 385.44879150390625|  0:00:15s\n","epoch 20 | loss: 208.70964| val_0_mse: 371.3929748535156|  0:00:15s\n","epoch 21 | loss: 211.66908| val_0_mse: 352.84100341796875|  0:00:16s\n","epoch 22 | loss: 205.88797| val_0_mse: 344.0069580078125|  0:00:17s\n","epoch 23 | loss: 208.15628| val_0_mse: 366.44049072265625|  0:00:18s\n","epoch 24 | loss: 197.28367| val_0_mse: 363.0699462890625|  0:00:18s\n","epoch 25 | loss: 200.95108| val_0_mse: 352.6905212402344|  0:00:19s\n","epoch 26 | loss: 216.83473| val_0_mse: 304.8470764160156|  0:00:20s\n","epoch 27 | loss: 198.34536| val_0_mse: 329.9878845214844|  0:00:21s\n","epoch 28 | loss: 209.56994| val_0_mse: 290.1807861328125|  0:00:21s\n","epoch 29 | loss: 200.44695| val_0_mse: 291.75762939453125|  0:00:22s\n","epoch 30 | loss: 194.45335| val_0_mse: 217.13551330566406|  0:00:23s\n","epoch 31 | loss: 199.92827| val_0_mse: 252.1588134765625|  0:00:24s\n","epoch 32 | loss: 193.49075| val_0_mse: 202.47071838378906|  0:00:25s\n","epoch 33 | loss: 194.80711| val_0_mse: 232.09617614746094|  0:00:25s\n","epoch 34 | loss: 194.47127| val_0_mse: 203.67567443847656|  0:00:26s\n","epoch 35 | loss: 196.35214| val_0_mse: 224.89605712890625|  0:00:27s\n","epoch 36 | loss: 197.8568| val_0_mse: 199.8670654296875|  0:00:28s\n","epoch 37 | loss: 201.31068| val_0_mse: 198.07449340820312|  0:00:28s\n","epoch 38 | loss: 192.48913| val_0_mse: 187.6262969970703|  0:00:29s\n","epoch 39 | loss: 189.68742| val_0_mse: 206.56207275390625|  0:00:30s\n","epoch 40 | loss: 188.7517| val_0_mse: 197.38580322265625|  0:00:30s\n","epoch 41 | loss: 194.63875| val_0_mse: 185.25881958007812|  0:00:31s\n","epoch 42 | loss: 187.09544| val_0_mse: 212.15289306640625|  0:00:32s\n","epoch 43 | loss: 185.14421| val_0_mse: 221.8538360595703|  0:00:33s\n","epoch 44 | loss: 185.67106| val_0_mse: 191.8996124267578|  0:00:34s\n","epoch 45 | loss: 186.56186| val_0_mse: 192.54995727539062|  0:00:34s\n","epoch 46 | loss: 182.79636| val_0_mse: 185.91151428222656|  0:00:35s\n","epoch 47 | loss: 179.325 | val_0_mse: 193.46998596191406|  0:00:36s\n","epoch 48 | loss: 180.86307| val_0_mse: 181.74354553222656|  0:00:37s\n","epoch 49 | loss: 181.08267| val_0_mse: 195.80679321289062|  0:00:37s\n","epoch 50 | loss: 175.47383| val_0_mse: 198.7003631591797|  0:00:38s\n","epoch 51 | loss: 179.98877| val_0_mse: 186.96661376953125|  0:00:39s\n","epoch 52 | loss: 177.1777| val_0_mse: 181.98045349121094|  0:00:40s\n","epoch 53 | loss: 173.32068| val_0_mse: 178.65997314453125|  0:00:40s\n","epoch 54 | loss: 169.95378| val_0_mse: 176.6173858642578|  0:00:41s\n","epoch 55 | loss: 176.38572| val_0_mse: 190.7606201171875|  0:00:42s\n","epoch 56 | loss: 174.80586| val_0_mse: 213.9546356201172|  0:00:43s\n","epoch 57 | loss: 181.87722| val_0_mse: 200.50987243652344|  0:00:43s\n","epoch 58 | loss: 182.35371| val_0_mse: 201.278564453125|  0:00:44s\n","epoch 59 | loss: 178.83032| val_0_mse: 191.12916564941406|  0:00:45s\n","epoch 60 | loss: 179.32146| val_0_mse: 192.68069458007812|  0:00:46s\n","epoch 61 | loss: 180.25168| val_0_mse: 192.22215270996094|  0:00:47s\n","epoch 62 | loss: 182.45817| val_0_mse: 186.7266845703125|  0:00:47s\n","epoch 63 | loss: 180.44413| val_0_mse: 186.3478546142578|  0:00:48s\n","epoch 64 | loss: 174.4942| val_0_mse: 184.20814514160156|  0:00:49s\n","\n","Early stopping occurred at epoch 64 with best_epoch = 54 and best_val_0_mse = 176.6173858642578\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 15:31:35,065] Trial 90 finished with value: 176.61737060546875 and parameters: {'n_d': 51, 'n_steps': 3, 'gamma': 1.9442711802903383, 'n_independent': 4, 'n_shared': 4, 'momentum': 0.1216025756228842}. Best is trial 33 with value: 135.8055877685547.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 2196.87189| val_0_mse: 2256.74951171875|  0:00:00s\n","epoch 1  | loss: 1667.1575| val_0_mse: 1448.92333984375|  0:00:01s\n","epoch 2  | loss: 898.39413| val_0_mse: 1517.035888671875|  0:00:02s\n","epoch 3  | loss: 434.53434| val_0_mse: 1369.8817138671875|  0:00:02s\n","epoch 4  | loss: 369.73099| val_0_mse: 1346.3662109375|  0:00:03s\n","epoch 5  | loss: 335.35241| val_0_mse: 2331.455810546875|  0:00:03s\n","epoch 6  | loss: 306.43361| val_0_mse: 6602.24169921875|  0:00:04s\n","epoch 7  | loss: 283.51996| val_0_mse: 7182.35986328125|  0:00:05s\n","epoch 8  | loss: 270.35579| val_0_mse: 2694.915283203125|  0:00:05s\n","epoch 9  | loss: 257.05278| val_0_mse: 3247.48095703125|  0:00:06s\n","epoch 10 | loss: 254.58587| val_0_mse: 4916.46875|  0:00:06s\n","epoch 11 | loss: 261.70455| val_0_mse: 2658.361572265625|  0:00:07s\n","epoch 12 | loss: 250.45384| val_0_mse: 3719.4580078125|  0:00:08s\n","epoch 13 | loss: 247.19649| val_0_mse: 3139.783935546875|  0:00:08s\n","epoch 14 | loss: 246.72286| val_0_mse: 2386.83935546875|  0:00:09s\n","\n","Early stopping occurred at epoch 14 with best_epoch = 4 and best_val_0_mse = 1346.3662109375\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 15:31:44,851] Trial 91 finished with value: 1346.3662109375 and parameters: {'n_d': 10, 'n_steps': 3, 'gamma': 1.7454912098967001, 'n_independent': 3, 'n_shared': 3, 'momentum': 0.24082477291277796}. Best is trial 33 with value: 135.8055877685547.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 2090.966| val_0_mse: 9298.6181640625|  0:00:00s\n","epoch 1  | loss: 1415.56565| val_0_mse: 2500.961181640625|  0:00:01s\n","epoch 2  | loss: 653.119 | val_0_mse: 1973.6500244140625|  0:00:01s\n","epoch 3  | loss: 419.52067| val_0_mse: 1428.624755859375|  0:00:02s\n","epoch 4  | loss: 385.01978| val_0_mse: 1482.4107666015625|  0:00:03s\n","epoch 5  | loss: 341.19062| val_0_mse: 706.0487060546875|  0:00:03s\n","epoch 6  | loss: 367.41372| val_0_mse: 1798.070556640625|  0:00:04s\n","epoch 7  | loss: 316.20641| val_0_mse: 1002.84326171875|  0:00:04s\n","epoch 8  | loss: 293.04526| val_0_mse: 1151.505126953125|  0:00:05s\n","epoch 9  | loss: 296.40976| val_0_mse: 1376.221435546875|  0:00:06s\n","epoch 10 | loss: 302.3074| val_0_mse: 1275.9078369140625|  0:00:06s\n","epoch 11 | loss: 304.63896| val_0_mse: 979.7476196289062|  0:00:07s\n","epoch 12 | loss: 300.51134| val_0_mse: 750.8565673828125|  0:00:07s\n","epoch 13 | loss: 283.77309| val_0_mse: 766.8677368164062|  0:00:08s\n","epoch 14 | loss: 276.96354| val_0_mse: 663.9776000976562|  0:00:09s\n","epoch 15 | loss: 278.72463| val_0_mse: 578.0519409179688|  0:00:09s\n","epoch 16 | loss: 264.06259| val_0_mse: 655.0275268554688|  0:00:10s\n","epoch 17 | loss: 255.62678| val_0_mse: 452.2523193359375|  0:00:11s\n","epoch 18 | loss: 249.06777| val_0_mse: 402.9646911621094|  0:00:11s\n","epoch 19 | loss: 239.2069| val_0_mse: 367.90277099609375|  0:00:12s\n","epoch 20 | loss: 239.18235| val_0_mse: 377.5670471191406|  0:00:13s\n","epoch 21 | loss: 231.34716| val_0_mse: 359.08056640625|  0:00:13s\n","epoch 22 | loss: 237.88199| val_0_mse: 337.6594543457031|  0:00:14s\n","epoch 23 | loss: 231.83386| val_0_mse: 320.6093444824219|  0:00:15s\n","epoch 24 | loss: 223.42658| val_0_mse: 272.6024475097656|  0:00:15s\n","epoch 25 | loss: 223.05181| val_0_mse: 269.98846435546875|  0:00:16s\n","epoch 26 | loss: 212.81011| val_0_mse: 237.6682586669922|  0:00:17s\n","epoch 27 | loss: 219.00165| val_0_mse: 267.05291748046875|  0:00:17s\n","epoch 28 | loss: 210.99842| val_0_mse: 237.71775817871094|  0:00:18s\n","epoch 29 | loss: 216.06721| val_0_mse: 251.67788696289062|  0:00:18s\n","epoch 30 | loss: 206.62012| val_0_mse: 227.3244171142578|  0:00:19s\n","epoch 31 | loss: 197.9978| val_0_mse: 247.10525512695312|  0:00:20s\n","epoch 32 | loss: 199.36629| val_0_mse: 232.55221557617188|  0:00:20s\n","epoch 33 | loss: 203.93548| val_0_mse: 250.6964874267578|  0:00:21s\n","epoch 34 | loss: 201.2074| val_0_mse: 233.41932678222656|  0:00:22s\n","epoch 35 | loss: 191.61613| val_0_mse: 224.423583984375|  0:00:22s\n","epoch 36 | loss: 192.45617| val_0_mse: 219.7371368408203|  0:00:23s\n","epoch 37 | loss: 190.37968| val_0_mse: 195.97006225585938|  0:00:23s\n","epoch 38 | loss: 190.6623| val_0_mse: 229.0879669189453|  0:00:24s\n","epoch 39 | loss: 193.08713| val_0_mse: 214.97311401367188|  0:00:25s\n","epoch 40 | loss: 188.19865| val_0_mse: 215.87710571289062|  0:00:25s\n","epoch 41 | loss: 186.32242| val_0_mse: 193.95994567871094|  0:00:26s\n","epoch 42 | loss: 183.3188| val_0_mse: 189.88536071777344|  0:00:27s\n","epoch 43 | loss: 183.81528| val_0_mse: 191.46734619140625|  0:00:27s\n","epoch 44 | loss: 188.5262| val_0_mse: 195.458740234375|  0:00:28s\n","epoch 45 | loss: 185.47215| val_0_mse: 198.36749267578125|  0:00:28s\n","epoch 46 | loss: 184.28211| val_0_mse: 191.58096313476562|  0:00:29s\n","epoch 47 | loss: 177.62128| val_0_mse: 182.20379638671875|  0:00:30s\n","epoch 48 | loss: 175.06445| val_0_mse: 192.50401306152344|  0:00:30s\n","epoch 49 | loss: 172.72722| val_0_mse: 180.9597930908203|  0:00:31s\n","epoch 50 | loss: 168.72572| val_0_mse: 193.29681396484375|  0:00:32s\n","epoch 51 | loss: 175.27088| val_0_mse: 182.28404235839844|  0:00:32s\n","epoch 52 | loss: 168.65605| val_0_mse: 181.5286865234375|  0:00:33s\n","epoch 53 | loss: 168.19871| val_0_mse: 171.70205688476562|  0:00:33s\n","epoch 54 | loss: 166.29107| val_0_mse: 180.46388244628906|  0:00:34s\n","epoch 55 | loss: 164.95231| val_0_mse: 168.1708526611328|  0:00:35s\n","epoch 56 | loss: 160.66473| val_0_mse: 182.4491729736328|  0:00:35s\n","epoch 57 | loss: 171.97173| val_0_mse: 172.57505798339844|  0:00:36s\n","epoch 58 | loss: 167.43098| val_0_mse: 181.27244567871094|  0:00:37s\n","epoch 59 | loss: 166.34774| val_0_mse: 167.22190856933594|  0:00:37s\n","epoch 60 | loss: 163.05639| val_0_mse: 176.64796447753906|  0:00:38s\n","epoch 61 | loss: 164.5072| val_0_mse: 172.8448028564453|  0:00:39s\n","epoch 62 | loss: 166.27673| val_0_mse: 175.18446350097656|  0:00:39s\n","epoch 63 | loss: 168.57192| val_0_mse: 182.36448669433594|  0:00:40s\n","epoch 64 | loss: 165.3384| val_0_mse: 162.1590118408203|  0:00:41s\n","epoch 65 | loss: 158.57847| val_0_mse: 190.096435546875|  0:00:41s\n","epoch 66 | loss: 160.78297| val_0_mse: 186.6170196533203|  0:00:42s\n","epoch 67 | loss: 164.37481| val_0_mse: 165.16551208496094|  0:00:43s\n","epoch 68 | loss: 157.43973| val_0_mse: 168.70657348632812|  0:00:43s\n","epoch 69 | loss: 158.90257| val_0_mse: 166.39364624023438|  0:00:44s\n","epoch 70 | loss: 162.16304| val_0_mse: 183.74598693847656|  0:00:45s\n","epoch 71 | loss: 164.70047| val_0_mse: 172.74725341796875|  0:00:45s\n","epoch 72 | loss: 161.39382| val_0_mse: 168.2632598876953|  0:00:46s\n","epoch 73 | loss: 158.85241| val_0_mse: 164.52468872070312|  0:00:47s\n","epoch 74 | loss: 154.54821| val_0_mse: 170.8319854736328|  0:00:47s\n","\n","Early stopping occurred at epoch 74 with best_epoch = 64 and best_val_0_mse = 162.1590118408203\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 15:32:32,932] Trial 92 finished with value: 162.1590118408203 and parameters: {'n_d': 16, 'n_steps': 3, 'gamma': 1.7026830937767274, 'n_independent': 3, 'n_shared': 3, 'momentum': 0.2480525455107775}. Best is trial 33 with value: 135.8055877685547.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 2264.57845| val_0_mse: 1916.87744140625|  0:00:00s\n","epoch 1  | loss: 1841.75431| val_0_mse: 1940.148193359375|  0:00:01s\n","epoch 2  | loss: 1217.94881| val_0_mse: 1343.3759765625|  0:00:01s\n","epoch 3  | loss: 617.7581| val_0_mse: 1452.527099609375|  0:00:02s\n","epoch 4  | loss: 389.55562| val_0_mse: 1387.2257080078125|  0:00:02s\n","epoch 5  | loss: 330.45209| val_0_mse: 1447.549072265625|  0:00:03s\n","epoch 6  | loss: 299.1355| val_0_mse: 875.9744262695312|  0:00:04s\n","epoch 7  | loss: 300.54796| val_0_mse: 1839.326416015625|  0:00:04s\n","epoch 8  | loss: 295.70093| val_0_mse: 881.6737670898438|  0:00:05s\n","epoch 9  | loss: 264.86463| val_0_mse: 924.8276977539062|  0:00:05s\n","epoch 10 | loss: 257.53834| val_0_mse: 1853.3385009765625|  0:00:06s\n","epoch 11 | loss: 240.1621| val_0_mse: 1795.615478515625|  0:00:06s\n","epoch 12 | loss: 246.30043| val_0_mse: 1266.9825439453125|  0:00:07s\n","epoch 13 | loss: 227.37762| val_0_mse: 1186.492431640625|  0:00:08s\n","epoch 14 | loss: 226.00942| val_0_mse: 1217.5308837890625|  0:00:08s\n","epoch 15 | loss: 224.58247| val_0_mse: 945.51123046875|  0:00:09s\n","epoch 16 | loss: 224.43204| val_0_mse: 539.6489868164062|  0:00:09s\n","epoch 17 | loss: 223.88912| val_0_mse: 672.5667724609375|  0:00:10s\n","epoch 18 | loss: 215.37167| val_0_mse: 635.4095458984375|  0:00:11s\n","epoch 19 | loss: 219.6521| val_0_mse: 427.455810546875|  0:00:11s\n","epoch 20 | loss: 214.63105| val_0_mse: 399.9427490234375|  0:00:12s\n","epoch 21 | loss: 206.26034| val_0_mse: 392.8612365722656|  0:00:12s\n","epoch 22 | loss: 206.21139| val_0_mse: 275.59625244140625|  0:00:13s\n","epoch 23 | loss: 205.65606| val_0_mse: 282.7934875488281|  0:00:14s\n","epoch 24 | loss: 198.0651| val_0_mse: 303.1806945800781|  0:00:14s\n","epoch 25 | loss: 196.37611| val_0_mse: 279.4321594238281|  0:00:15s\n","epoch 26 | loss: 198.19452| val_0_mse: 241.57078552246094|  0:00:15s\n","epoch 27 | loss: 196.77751| val_0_mse: 272.9425964355469|  0:00:16s\n","epoch 28 | loss: 207.93117| val_0_mse: 258.3296813964844|  0:00:16s\n","epoch 29 | loss: 189.45144| val_0_mse: 231.1407928466797|  0:00:17s\n","epoch 30 | loss: 196.91993| val_0_mse: 242.7986602783203|  0:00:18s\n","epoch 31 | loss: 197.01403| val_0_mse: 237.8443145751953|  0:00:18s\n","epoch 32 | loss: 191.65102| val_0_mse: 205.14561462402344|  0:00:19s\n","epoch 33 | loss: 187.07928| val_0_mse: 216.0644073486328|  0:00:19s\n","epoch 34 | loss: 188.46654| val_0_mse: 205.5264129638672|  0:00:20s\n","epoch 35 | loss: 184.83007| val_0_mse: 188.47265625|  0:00:21s\n","epoch 36 | loss: 185.13055| val_0_mse: 193.4868621826172|  0:00:21s\n","epoch 37 | loss: 187.82851| val_0_mse: 202.68333435058594|  0:00:22s\n","epoch 38 | loss: 187.44527| val_0_mse: 204.44166564941406|  0:00:22s\n","epoch 39 | loss: 187.03391| val_0_mse: 198.22320556640625|  0:00:23s\n","epoch 40 | loss: 185.81413| val_0_mse: 191.4076385498047|  0:00:23s\n","epoch 41 | loss: 183.20469| val_0_mse: 205.38221740722656|  0:00:24s\n","epoch 42 | loss: 184.79476| val_0_mse: 192.6737060546875|  0:00:24s\n","epoch 43 | loss: 176.78401| val_0_mse: 190.09657287597656|  0:00:25s\n","epoch 44 | loss: 177.03186| val_0_mse: 180.7884979248047|  0:00:26s\n","epoch 45 | loss: 176.58101| val_0_mse: 185.58627319335938|  0:00:26s\n","epoch 46 | loss: 176.33913| val_0_mse: 177.28492736816406|  0:00:27s\n","epoch 47 | loss: 172.04815| val_0_mse: 213.29319763183594|  0:00:27s\n","epoch 48 | loss: 170.59474| val_0_mse: 176.1651611328125|  0:00:28s\n","epoch 49 | loss: 166.52999| val_0_mse: 177.6062469482422|  0:00:28s\n","epoch 50 | loss: 171.65563| val_0_mse: 174.58758544921875|  0:00:29s\n","epoch 51 | loss: 168.7355| val_0_mse: 174.67044067382812|  0:00:29s\n","epoch 52 | loss: 166.83881| val_0_mse: 170.82301330566406|  0:00:30s\n","epoch 53 | loss: 163.60958| val_0_mse: 174.83633422851562|  0:00:31s\n","epoch 54 | loss: 165.12574| val_0_mse: 171.44146728515625|  0:00:31s\n","epoch 55 | loss: 160.64862| val_0_mse: 166.7545166015625|  0:00:32s\n","epoch 56 | loss: 155.52209| val_0_mse: 160.81179809570312|  0:00:32s\n","epoch 57 | loss: 158.5003| val_0_mse: 186.22157287597656|  0:00:33s\n","epoch 58 | loss: 152.31849| val_0_mse: 165.38018798828125|  0:00:33s\n","epoch 59 | loss: 149.9253| val_0_mse: 166.48475646972656|  0:00:34s\n","epoch 60 | loss: 153.22589| val_0_mse: 163.30299377441406|  0:00:34s\n","epoch 61 | loss: 148.47486| val_0_mse: 170.3746337890625|  0:00:35s\n","epoch 62 | loss: 150.87525| val_0_mse: 151.0104217529297|  0:00:36s\n","epoch 63 | loss: 150.78674| val_0_mse: 157.97750854492188|  0:00:36s\n","epoch 64 | loss: 151.20836| val_0_mse: 158.24818420410156|  0:00:37s\n","epoch 65 | loss: 152.28187| val_0_mse: 209.02658081054688|  0:00:37s\n","epoch 66 | loss: 154.20702| val_0_mse: 158.775146484375|  0:00:38s\n","epoch 67 | loss: 146.62658| val_0_mse: 154.79092407226562|  0:00:38s\n","epoch 68 | loss: 148.03902| val_0_mse: 159.57696533203125|  0:00:39s\n","epoch 69 | loss: 149.93782| val_0_mse: 172.025146484375|  0:00:40s\n","epoch 70 | loss: 149.83148| val_0_mse: 186.18211364746094|  0:00:40s\n","epoch 71 | loss: 151.02716| val_0_mse: 154.6536407470703|  0:00:41s\n","epoch 72 | loss: 149.17624| val_0_mse: 203.85626220703125|  0:00:41s\n","\n","Early stopping occurred at epoch 72 with best_epoch = 62 and best_val_0_mse = 151.0104217529297\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 15:33:14,969] Trial 93 finished with value: 151.0104217529297 and parameters: {'n_d': 11, 'n_steps': 3, 'gamma': 1.7950419289175814, 'n_independent': 3, 'n_shared': 2, 'momentum': 0.26433411826357345}. Best is trial 33 with value: 135.8055877685547.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 2196.83268| val_0_mse: 1934.4053955078125|  0:00:00s\n","epoch 1  | loss: 1583.09725| val_0_mse: 2250.70263671875|  0:00:01s\n","epoch 2  | loss: 721.2619| val_0_mse: 4536.2041015625|  0:00:02s\n","epoch 3  | loss: 470.25185| val_0_mse: 2121.93798828125|  0:00:02s\n","epoch 4  | loss: 444.58135| val_0_mse: 844.7545776367188|  0:00:03s\n","epoch 5  | loss: 391.43782| val_0_mse: 1462.841064453125|  0:00:04s\n","epoch 6  | loss: 376.52329| val_0_mse: 816.4154663085938|  0:00:05s\n","epoch 7  | loss: 385.15297| val_0_mse: 691.9588623046875|  0:00:05s\n","epoch 8  | loss: 354.62782| val_0_mse: 1727.6005859375|  0:00:06s\n","epoch 9  | loss: 343.76727| val_0_mse: 944.7024536132812|  0:00:07s\n","epoch 10 | loss: 316.64305| val_0_mse: 1211.2261962890625|  0:00:08s\n","epoch 11 | loss: 325.53254| val_0_mse: 856.209228515625|  0:00:08s\n","epoch 12 | loss: 319.85154| val_0_mse: 881.53857421875|  0:00:09s\n","epoch 13 | loss: 294.41383| val_0_mse: 985.046875|  0:00:10s\n","epoch 14 | loss: 276.94075| val_0_mse: 752.7692260742188|  0:00:11s\n","epoch 15 | loss: 261.18351| val_0_mse: 713.6065673828125|  0:00:11s\n","epoch 16 | loss: 268.17534| val_0_mse: 676.037353515625|  0:00:12s\n","epoch 17 | loss: 286.95152| val_0_mse: 776.6793823242188|  0:00:13s\n","epoch 18 | loss: 271.59933| val_0_mse: 1061.9322509765625|  0:00:14s\n","epoch 19 | loss: 258.24995| val_0_mse: 527.9297485351562|  0:00:14s\n","epoch 20 | loss: 260.21076| val_0_mse: 444.65997314453125|  0:00:15s\n","epoch 21 | loss: 265.00588| val_0_mse: 403.97601318359375|  0:00:16s\n","epoch 22 | loss: 276.08356| val_0_mse: 450.0158386230469|  0:00:17s\n","epoch 23 | loss: 244.06759| val_0_mse: 395.3645324707031|  0:00:18s\n","epoch 24 | loss: 245.75581| val_0_mse: 311.3821105957031|  0:00:18s\n","epoch 25 | loss: 240.81272| val_0_mse: 307.288330078125|  0:00:19s\n","epoch 26 | loss: 241.62179| val_0_mse: 331.99078369140625|  0:00:20s\n","epoch 27 | loss: 237.89675| val_0_mse: 341.8880920410156|  0:00:21s\n","epoch 28 | loss: 249.48796| val_0_mse: 273.1468200683594|  0:00:21s\n","epoch 29 | loss: 243.82688| val_0_mse: 340.4313049316406|  0:00:22s\n","epoch 30 | loss: 228.5989| val_0_mse: 293.1632385253906|  0:00:23s\n","epoch 31 | loss: 228.99213| val_0_mse: 362.3252258300781|  0:00:24s\n","epoch 32 | loss: 230.07428| val_0_mse: 285.32244873046875|  0:00:25s\n","epoch 33 | loss: 226.46977| val_0_mse: 311.1618957519531|  0:00:25s\n","epoch 34 | loss: 221.91232| val_0_mse: 298.5277404785156|  0:00:26s\n","epoch 35 | loss: 209.68698| val_0_mse: 262.3168029785156|  0:00:27s\n","epoch 36 | loss: 205.98658| val_0_mse: 302.7462158203125|  0:00:28s\n","epoch 37 | loss: 196.8192| val_0_mse: 304.1087951660156|  0:00:28s\n","epoch 38 | loss: 201.87614| val_0_mse: 283.54730224609375|  0:00:29s\n","epoch 39 | loss: 201.10304| val_0_mse: 225.13592529296875|  0:00:30s\n","epoch 40 | loss: 196.61777| val_0_mse: 229.80760192871094|  0:00:31s\n","epoch 41 | loss: 195.34013| val_0_mse: 331.5830383300781|  0:00:31s\n","epoch 42 | loss: 186.00513| val_0_mse: 201.7270050048828|  0:00:32s\n","epoch 43 | loss: 194.64845| val_0_mse: 225.77735900878906|  0:00:33s\n","epoch 44 | loss: 190.57338| val_0_mse: 203.182373046875|  0:00:34s\n","epoch 45 | loss: 189.8429| val_0_mse: 186.88418579101562|  0:00:34s\n","epoch 46 | loss: 192.90501| val_0_mse: 198.2646942138672|  0:00:35s\n","epoch 47 | loss: 187.62428| val_0_mse: 248.3323211669922|  0:00:36s\n","epoch 48 | loss: 185.70254| val_0_mse: 282.3582458496094|  0:00:37s\n","epoch 49 | loss: 177.86027| val_0_mse: 192.2859649658203|  0:00:37s\n","epoch 50 | loss: 181.15534| val_0_mse: 187.5481414794922|  0:00:38s\n","epoch 51 | loss: 174.37279| val_0_mse: 210.62484741210938|  0:00:39s\n","epoch 52 | loss: 174.64351| val_0_mse: 193.91845703125|  0:00:40s\n","epoch 53 | loss: 173.38905| val_0_mse: 188.17381286621094|  0:00:40s\n","epoch 54 | loss: 163.54859| val_0_mse: 199.76513671875|  0:00:41s\n","epoch 55 | loss: 170.89357| val_0_mse: 182.30117797851562|  0:00:42s\n","epoch 56 | loss: 172.94715| val_0_mse: 191.17532348632812|  0:00:43s\n","epoch 57 | loss: 168.62538| val_0_mse: 174.0780792236328|  0:00:43s\n","epoch 58 | loss: 166.03049| val_0_mse: 165.02273559570312|  0:00:44s\n","epoch 59 | loss: 161.94179| val_0_mse: 193.2976837158203|  0:00:45s\n","epoch 60 | loss: 165.43778| val_0_mse: 175.40223693847656|  0:00:46s\n","epoch 61 | loss: 161.00055| val_0_mse: 202.4137420654297|  0:00:47s\n","epoch 62 | loss: 158.3662| val_0_mse: 177.9532012939453|  0:00:47s\n","epoch 63 | loss: 163.4331| val_0_mse: 174.88308715820312|  0:00:48s\n","epoch 64 | loss: 161.63063| val_0_mse: 174.4702606201172|  0:00:49s\n","epoch 65 | loss: 168.42705| val_0_mse: 177.69561767578125|  0:00:50s\n","epoch 66 | loss: 163.4001| val_0_mse: 194.4693603515625|  0:00:50s\n","epoch 67 | loss: 164.25592| val_0_mse: 168.68287658691406|  0:00:51s\n","epoch 68 | loss: 159.92238| val_0_mse: 179.04342651367188|  0:00:52s\n","\n","Early stopping occurred at epoch 68 with best_epoch = 58 and best_val_0_mse = 165.02273559570312\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 15:34:07,674] Trial 94 finished with value: 165.02273559570312 and parameters: {'n_d': 21, 'n_steps': 4, 'gamma': 1.4733304902060744, 'n_independent': 3, 'n_shared': 3, 'momentum': 0.022598728929621836}. Best is trial 33 with value: 135.8055877685547.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 2221.92171| val_0_mse: 5324.39892578125|  0:00:00s\n","epoch 1  | loss: 1483.92021| val_0_mse: 2231.8134765625|  0:00:01s\n","epoch 2  | loss: 634.51899| val_0_mse: 1143.6033935546875|  0:00:02s\n","epoch 3  | loss: 446.38363| val_0_mse: 1178.07958984375|  0:00:02s\n","epoch 4  | loss: 370.44871| val_0_mse: 2451.17822265625|  0:00:03s\n","epoch 5  | loss: 327.10143| val_0_mse: 5358.75537109375|  0:00:04s\n","epoch 6  | loss: 290.27294| val_0_mse: 12554.5966796875|  0:00:04s\n","epoch 7  | loss: 275.90529| val_0_mse: 14425.8037109375|  0:00:05s\n","epoch 8  | loss: 267.95172| val_0_mse: 9185.8447265625|  0:00:06s\n","epoch 9  | loss: 271.94999| val_0_mse: 14043.6943359375|  0:00:06s\n","epoch 10 | loss: 255.44975| val_0_mse: 7572.47314453125|  0:00:07s\n","epoch 11 | loss: 278.87096| val_0_mse: 8528.9140625|  0:00:08s\n","epoch 12 | loss: 266.17856| val_0_mse: 3338.987548828125|  0:00:08s\n","\n","Early stopping occurred at epoch 12 with best_epoch = 2 and best_val_0_mse = 1143.6033935546875\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 15:34:16,843] Trial 95 finished with value: 1143.6033935546875 and parameters: {'n_d': 25, 'n_steps': 3, 'gamma': 1.8458422952586937, 'n_independent': 3, 'n_shared': 4, 'momentum': 0.22480091012214298}. Best is trial 33 with value: 135.8055877685547.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 1672.94198| val_0_mse: 8085.49560546875|  0:00:00s\n","epoch 1  | loss: 484.70386| val_0_mse: 15380.462890625|  0:00:01s\n","epoch 2  | loss: 375.22641| val_0_mse: 1120.42919921875|  0:00:01s\n","epoch 3  | loss: 345.33227| val_0_mse: 2293.686279296875|  0:00:02s\n","epoch 4  | loss: 288.84733| val_0_mse: 7684.62646484375|  0:00:02s\n","epoch 5  | loss: 302.89894| val_0_mse: 8960.8017578125|  0:00:03s\n","epoch 6  | loss: 293.57407| val_0_mse: 7001.2529296875|  0:00:03s\n","epoch 7  | loss: 301.53743| val_0_mse: 6121.94677734375|  0:00:04s\n","epoch 8  | loss: 283.82177| val_0_mse: 5561.900390625|  0:00:04s\n","epoch 9  | loss: 268.36935| val_0_mse: 5253.9326171875|  0:00:05s\n","epoch 10 | loss: 275.49551| val_0_mse: 3072.680908203125|  0:00:06s\n","epoch 11 | loss: 264.10342| val_0_mse: 3510.602783203125|  0:00:06s\n","epoch 12 | loss: 263.93021| val_0_mse: 2816.35498046875|  0:00:07s\n","\n","Early stopping occurred at epoch 12 with best_epoch = 2 and best_val_0_mse = 1120.42919921875\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 15:34:24,383] Trial 96 finished with value: 1120.42919921875 and parameters: {'n_d': 60, 'n_steps': 3, 'gamma': 1.89113909557199, 'n_independent': 2, 'n_shared': 3, 'momentum': 0.1925082498854178}. Best is trial 33 with value: 135.8055877685547.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 2114.53018| val_0_mse: 9756.5126953125|  0:00:01s\n","epoch 1  | loss: 1299.58942| val_0_mse: 8746.6064453125|  0:00:01s\n","epoch 2  | loss: 614.82702| val_0_mse: 4561.671875|  0:00:02s\n","epoch 3  | loss: 461.94745| val_0_mse: 1967.208984375|  0:00:03s\n","epoch 4  | loss: 404.73813| val_0_mse: 1988.2523193359375|  0:00:04s\n","epoch 5  | loss: 439.21393| val_0_mse: 793.6154174804688|  0:00:05s\n","epoch 6  | loss: 388.04459| val_0_mse: 1573.002197265625|  0:00:06s\n","epoch 7  | loss: 367.47911| val_0_mse: 1552.02099609375|  0:00:07s\n","epoch 8  | loss: 335.74054| val_0_mse: 1159.447998046875|  0:00:08s\n","epoch 9  | loss: 324.05032| val_0_mse: 1055.8658447265625|  0:00:09s\n","epoch 10 | loss: 318.26018| val_0_mse: 639.9071655273438|  0:00:10s\n","epoch 11 | loss: 291.21852| val_0_mse: 558.5377807617188|  0:00:11s\n","epoch 12 | loss: 300.10045| val_0_mse: 671.8938598632812|  0:00:11s\n","epoch 13 | loss: 282.98296| val_0_mse: 553.5354614257812|  0:00:12s\n","epoch 14 | loss: 270.88062| val_0_mse: 579.923828125|  0:00:13s\n","epoch 15 | loss: 273.56721| val_0_mse: 442.2647705078125|  0:00:14s\n","epoch 16 | loss: 269.81182| val_0_mse: 365.79669189453125|  0:00:15s\n","epoch 17 | loss: 259.60738| val_0_mse: 431.1446533203125|  0:00:16s\n","epoch 18 | loss: 254.70037| val_0_mse: 402.3241271972656|  0:00:17s\n","epoch 19 | loss: 243.70152| val_0_mse: 343.2602844238281|  0:00:18s\n","epoch 20 | loss: 247.54967| val_0_mse: 357.0400695800781|  0:00:19s\n","epoch 21 | loss: 238.8927| val_0_mse: 340.2978515625|  0:00:20s\n","epoch 22 | loss: 230.80073| val_0_mse: 393.5370788574219|  0:00:21s\n","epoch 23 | loss: 239.85237| val_0_mse: 342.408203125|  0:00:21s\n","epoch 24 | loss: 251.08983| val_0_mse: 270.5122985839844|  0:00:22s\n","epoch 25 | loss: 240.01384| val_0_mse: 284.9136047363281|  0:00:23s\n","epoch 26 | loss: 246.9263| val_0_mse: 289.2219543457031|  0:00:24s\n","epoch 27 | loss: 243.3267| val_0_mse: 277.088623046875|  0:00:25s\n","epoch 28 | loss: 236.38436| val_0_mse: 248.90293884277344|  0:00:26s\n","epoch 29 | loss: 231.85164| val_0_mse: 250.57608032226562|  0:00:27s\n","epoch 30 | loss: 215.98309| val_0_mse: 259.7247314453125|  0:00:28s\n","epoch 31 | loss: 224.96182| val_0_mse: 419.00390625|  0:00:29s\n","epoch 32 | loss: 224.08004| val_0_mse: 314.1756591796875|  0:00:30s\n","epoch 33 | loss: 210.62991| val_0_mse: 245.2726593017578|  0:00:31s\n","epoch 34 | loss: 216.13778| val_0_mse: 239.07171630859375|  0:00:32s\n","epoch 35 | loss: 227.48464| val_0_mse: 240.1054229736328|  0:00:33s\n","epoch 36 | loss: 220.55059| val_0_mse: 251.2957000732422|  0:00:33s\n","epoch 37 | loss: 218.93574| val_0_mse: 270.1039733886719|  0:00:34s\n","epoch 38 | loss: 223.01348| val_0_mse: 265.0437316894531|  0:00:35s\n","epoch 39 | loss: 224.08036| val_0_mse: 228.63754272460938|  0:00:36s\n","epoch 40 | loss: 224.5189| val_0_mse: 304.56768798828125|  0:00:37s\n","epoch 41 | loss: 221.26349| val_0_mse: 225.7243194580078|  0:00:38s\n","epoch 42 | loss: 215.23024| val_0_mse: 217.9243621826172|  0:00:39s\n","epoch 43 | loss: 221.18222| val_0_mse: 209.46014404296875|  0:00:40s\n","epoch 44 | loss: 212.7287| val_0_mse: 209.88693237304688|  0:00:41s\n","epoch 45 | loss: 201.12855| val_0_mse: 210.7964630126953|  0:00:42s\n","epoch 46 | loss: 210.08543| val_0_mse: 229.93116760253906|  0:00:43s\n","epoch 47 | loss: 216.48377| val_0_mse: 219.8689727783203|  0:00:43s\n","epoch 48 | loss: 206.37278| val_0_mse: 217.97923278808594|  0:00:44s\n","epoch 49 | loss: 201.91144| val_0_mse: 200.9927215576172|  0:00:45s\n","epoch 50 | loss: 208.60314| val_0_mse: 235.05520629882812|  0:00:46s\n","epoch 51 | loss: 198.53115| val_0_mse: 195.18728637695312|  0:00:47s\n","epoch 52 | loss: 189.88512| val_0_mse: 203.04733276367188|  0:00:48s\n","epoch 53 | loss: 189.02558| val_0_mse: 189.537841796875|  0:00:49s\n","epoch 54 | loss: 189.52606| val_0_mse: 185.5942840576172|  0:00:50s\n","epoch 55 | loss: 189.49068| val_0_mse: 184.82998657226562|  0:00:51s\n","epoch 56 | loss: 177.07396| val_0_mse: 207.99594116210938|  0:00:52s\n","epoch 57 | loss: 180.66152| val_0_mse: 182.17662048339844|  0:00:53s\n","epoch 58 | loss: 181.42715| val_0_mse: 186.22845458984375|  0:00:53s\n","epoch 59 | loss: 185.21974| val_0_mse: 187.1503143310547|  0:00:54s\n","epoch 60 | loss: 187.54336| val_0_mse: 193.62229919433594|  0:00:55s\n","epoch 61 | loss: 180.54659| val_0_mse: 176.03106689453125|  0:00:56s\n","epoch 62 | loss: 174.61718| val_0_mse: 175.46664428710938|  0:00:57s\n","epoch 63 | loss: 167.46025| val_0_mse: 184.11785888671875|  0:00:58s\n","epoch 64 | loss: 167.47264| val_0_mse: 173.91763305664062|  0:00:59s\n","epoch 65 | loss: 168.97184| val_0_mse: 181.70509338378906|  0:01:00s\n","epoch 66 | loss: 176.51152| val_0_mse: 196.14630126953125|  0:01:01s\n","epoch 67 | loss: 174.3131| val_0_mse: 174.75819396972656|  0:01:02s\n","epoch 68 | loss: 169.14131| val_0_mse: 199.0785675048828|  0:01:03s\n","epoch 69 | loss: 168.9408| val_0_mse: 189.33250427246094|  0:01:03s\n","epoch 70 | loss: 172.26561| val_0_mse: 191.30125427246094|  0:01:04s\n","epoch 71 | loss: 167.28678| val_0_mse: 167.24148559570312|  0:01:05s\n","epoch 72 | loss: 164.826 | val_0_mse: 192.9371337890625|  0:01:06s\n","epoch 73 | loss: 172.55202| val_0_mse: 168.45599365234375|  0:01:07s\n","epoch 74 | loss: 158.59162| val_0_mse: 171.9629669189453|  0:01:08s\n","epoch 75 | loss: 158.14913| val_0_mse: 183.98890686035156|  0:01:09s\n","epoch 76 | loss: 170.47935| val_0_mse: 171.42213439941406|  0:01:10s\n","epoch 77 | loss: 161.68622| val_0_mse: 169.51815795898438|  0:01:11s\n","epoch 78 | loss: 161.68691| val_0_mse: 188.84957885742188|  0:01:12s\n","epoch 79 | loss: 153.80578| val_0_mse: 165.49981689453125|  0:01:13s\n","epoch 80 | loss: 152.63183| val_0_mse: 157.90225219726562|  0:01:13s\n","epoch 81 | loss: 157.85183| val_0_mse: 161.2052001953125|  0:01:14s\n","epoch 82 | loss: 150.97398| val_0_mse: 162.58493041992188|  0:01:15s\n","epoch 83 | loss: 149.24043| val_0_mse: 169.16598510742188|  0:01:16s\n","epoch 84 | loss: 152.5267| val_0_mse: 165.1634521484375|  0:01:17s\n","epoch 85 | loss: 160.01363| val_0_mse: 180.26426696777344|  0:01:18s\n","epoch 86 | loss: 156.07705| val_0_mse: 155.43202209472656|  0:01:19s\n","epoch 87 | loss: 150.98307| val_0_mse: 169.99652099609375|  0:01:20s\n","epoch 88 | loss: 155.2268| val_0_mse: 167.12252807617188|  0:01:21s\n","epoch 89 | loss: 149.61577| val_0_mse: 168.56895446777344|  0:01:22s\n","epoch 90 | loss: 143.20277| val_0_mse: 153.22933959960938|  0:01:22s\n","epoch 91 | loss: 138.02563| val_0_mse: 192.5623779296875|  0:01:23s\n","epoch 92 | loss: 146.02384| val_0_mse: 159.25050354003906|  0:01:24s\n","epoch 93 | loss: 139.57243| val_0_mse: 159.1235809326172|  0:01:25s\n","epoch 94 | loss: 140.04718| val_0_mse: 159.1363983154297|  0:01:26s\n","epoch 95 | loss: 147.94839| val_0_mse: 171.52183532714844|  0:01:27s\n","epoch 96 | loss: 152.67224| val_0_mse: 161.96502685546875|  0:01:28s\n","epoch 97 | loss: 145.14614| val_0_mse: 175.97642517089844|  0:01:29s\n","epoch 98 | loss: 137.83047| val_0_mse: 166.27867126464844|  0:01:30s\n","epoch 99 | loss: 133.45542| val_0_mse: 155.93316650390625|  0:01:31s\n","Stop training because you reached max_epochs = 100 with best_epoch = 90 and best_val_0_mse = 153.22933959960938\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 15:35:55,976] Trial 97 finished with value: 153.22933959960938 and parameters: {'n_d': 35, 'n_steps': 4, 'gamma': 1.6693459581717853, 'n_independent': 3, 'n_shared': 5, 'momentum': 0.13219105241800796}. Best is trial 33 with value: 135.8055877685547.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 1489.28921| val_0_mse: 108163.5703125|  0:00:01s\n","epoch 1  | loss: 731.62916| val_0_mse: 8711.30859375|  0:00:02s\n","epoch 2  | loss: 588.30362| val_0_mse: 2113.103515625|  0:00:03s\n","epoch 3  | loss: 537.63578| val_0_mse: 6676.744140625|  0:00:04s\n","epoch 4  | loss: 520.23142| val_0_mse: 1248.8671875|  0:00:05s\n","epoch 5  | loss: 452.03021| val_0_mse: 1413.9654541015625|  0:00:07s\n","epoch 6  | loss: 443.46328| val_0_mse: 2315.471435546875|  0:00:08s\n","epoch 7  | loss: 452.6895| val_0_mse: 705.3342895507812|  0:00:09s\n","epoch 8  | loss: 498.82333| val_0_mse: 2439.140625|  0:00:10s\n","epoch 9  | loss: 449.07606| val_0_mse: 1374.469482421875|  0:00:11s\n","epoch 10 | loss: 433.79872| val_0_mse: 2202.276123046875|  0:00:12s\n","epoch 11 | loss: 429.75564| val_0_mse: 1080.1796875|  0:00:13s\n","epoch 12 | loss: 391.3453| val_0_mse: 1038.591064453125|  0:00:14s\n","epoch 13 | loss: 393.93135| val_0_mse: 1012.6807250976562|  0:00:16s\n","epoch 14 | loss: 366.07558| val_0_mse: 1156.622802734375|  0:00:17s\n","epoch 15 | loss: 366.67417| val_0_mse: 671.2396240234375|  0:00:18s\n","epoch 16 | loss: 336.14375| val_0_mse: 1537.9014892578125|  0:00:19s\n","epoch 17 | loss: 315.55741| val_0_mse: 1183.339111328125|  0:00:20s\n","epoch 18 | loss: 328.82672| val_0_mse: 696.9150390625|  0:00:21s\n","epoch 19 | loss: 312.06143| val_0_mse: 752.4854125976562|  0:00:22s\n","epoch 20 | loss: 317.26104| val_0_mse: 903.1553344726562|  0:00:23s\n","epoch 21 | loss: 286.81371| val_0_mse: 654.1013793945312|  0:00:25s\n","epoch 22 | loss: 277.82975| val_0_mse: 628.1633911132812|  0:00:26s\n","epoch 23 | loss: 284.83848| val_0_mse: 506.960693359375|  0:00:27s\n","epoch 24 | loss: 271.20348| val_0_mse: 493.9519348144531|  0:00:28s\n","epoch 25 | loss: 252.44037| val_0_mse: 434.23162841796875|  0:00:29s\n","epoch 26 | loss: 252.28026| val_0_mse: 381.4302673339844|  0:00:30s\n","epoch 27 | loss: 249.19635| val_0_mse: 403.63824462890625|  0:00:32s\n","epoch 28 | loss: 239.25717| val_0_mse: 253.2004852294922|  0:00:33s\n","epoch 29 | loss: 250.82955| val_0_mse: 300.7237548828125|  0:00:34s\n","epoch 30 | loss: 251.28784| val_0_mse: 287.6922302246094|  0:00:35s\n","epoch 31 | loss: 239.91377| val_0_mse: 233.56065368652344|  0:00:36s\n","epoch 32 | loss: 239.69206| val_0_mse: 228.84519958496094|  0:00:37s\n","epoch 33 | loss: 275.84325| val_0_mse: 293.60955810546875|  0:00:38s\n","epoch 34 | loss: 258.52902| val_0_mse: 285.618408203125|  0:00:39s\n","epoch 35 | loss: 245.35179| val_0_mse: 225.08580017089844|  0:00:41s\n","epoch 36 | loss: 229.93043| val_0_mse: 230.65611267089844|  0:00:42s\n","epoch 37 | loss: 227.81299| val_0_mse: 241.26124572753906|  0:00:43s\n","epoch 38 | loss: 222.40702| val_0_mse: 219.130126953125|  0:00:44s\n","epoch 39 | loss: 225.85109| val_0_mse: 241.1250762939453|  0:00:45s\n","epoch 40 | loss: 221.55617| val_0_mse: 221.9640350341797|  0:00:46s\n","epoch 41 | loss: 208.28736| val_0_mse: 212.4358673095703|  0:00:47s\n","epoch 42 | loss: 208.12886| val_0_mse: 212.25567626953125|  0:00:49s\n","epoch 43 | loss: 202.05059| val_0_mse: 208.1208953857422|  0:00:50s\n","epoch 44 | loss: 210.83073| val_0_mse: 219.22781372070312|  0:00:51s\n","epoch 45 | loss: 204.29473| val_0_mse: 214.99774169921875|  0:00:52s\n","epoch 46 | loss: 201.98371| val_0_mse: 211.80746459960938|  0:00:53s\n","epoch 47 | loss: 214.87171| val_0_mse: 207.04501342773438|  0:00:54s\n","epoch 48 | loss: 200.44014| val_0_mse: 194.12721252441406|  0:00:55s\n","epoch 49 | loss: 199.0033| val_0_mse: 219.86221313476562|  0:00:56s\n","epoch 50 | loss: 205.81316| val_0_mse: 207.47506713867188|  0:00:58s\n","epoch 51 | loss: 200.23107| val_0_mse: 211.1320343017578|  0:00:59s\n","epoch 52 | loss: 206.20941| val_0_mse: 209.8356475830078|  0:01:00s\n","epoch 53 | loss: 198.7666| val_0_mse: 198.13180541992188|  0:01:01s\n","epoch 54 | loss: 192.63002| val_0_mse: 193.3869171142578|  0:01:02s\n","epoch 55 | loss: 188.52739| val_0_mse: 200.7559051513672|  0:01:03s\n","epoch 56 | loss: 191.86504| val_0_mse: 205.36541748046875|  0:01:04s\n","epoch 57 | loss: 191.88889| val_0_mse: 245.79010009765625|  0:01:05s\n","epoch 58 | loss: 196.78576| val_0_mse: 210.87478637695312|  0:01:07s\n","epoch 59 | loss: 182.92098| val_0_mse: 206.4580535888672|  0:01:08s\n","epoch 60 | loss: 186.10989| val_0_mse: 200.2512664794922|  0:01:09s\n","epoch 61 | loss: 188.22075| val_0_mse: 225.07980346679688|  0:01:10s\n","epoch 62 | loss: 198.39619| val_0_mse: 204.79281616210938|  0:01:11s\n","epoch 63 | loss: 189.26868| val_0_mse: 209.116455078125|  0:01:12s\n","epoch 64 | loss: 189.1457| val_0_mse: 192.20346069335938|  0:01:13s\n","epoch 65 | loss: 179.61153| val_0_mse: 192.64915466308594|  0:01:14s\n","epoch 66 | loss: 177.1661| val_0_mse: 188.1931610107422|  0:01:16s\n","epoch 67 | loss: 175.84353| val_0_mse: 190.07005310058594|  0:01:17s\n","epoch 68 | loss: 179.33538| val_0_mse: 195.23423767089844|  0:01:18s\n","epoch 69 | loss: 174.4396| val_0_mse: 195.9853057861328|  0:01:19s\n","epoch 70 | loss: 177.84231| val_0_mse: 183.9056854248047|  0:01:20s\n","epoch 71 | loss: 175.81455| val_0_mse: 189.75489807128906|  0:01:21s\n","epoch 72 | loss: 177.37116| val_0_mse: 190.57322692871094|  0:01:22s\n","epoch 73 | loss: 181.54721| val_0_mse: 219.366455078125|  0:01:23s\n","epoch 74 | loss: 181.17896| val_0_mse: 184.63534545898438|  0:01:25s\n","epoch 75 | loss: 171.44977| val_0_mse: 196.9900665283203|  0:01:26s\n","epoch 76 | loss: 180.95219| val_0_mse: 191.31344604492188|  0:01:27s\n","epoch 77 | loss: 181.25928| val_0_mse: 191.15570068359375|  0:01:28s\n","epoch 78 | loss: 172.65599| val_0_mse: 196.06275939941406|  0:01:29s\n","epoch 79 | loss: 175.31845| val_0_mse: 200.34938049316406|  0:01:30s\n","epoch 80 | loss: 172.46351| val_0_mse: 177.60496520996094|  0:01:31s\n","epoch 81 | loss: 183.24709| val_0_mse: 183.56028747558594|  0:01:33s\n","epoch 82 | loss: 174.19276| val_0_mse: 184.35009765625|  0:01:34s\n","epoch 83 | loss: 169.37497| val_0_mse: 179.97230529785156|  0:01:35s\n","epoch 84 | loss: 170.74583| val_0_mse: 182.1691131591797|  0:01:36s\n","epoch 85 | loss: 171.75511| val_0_mse: 174.16136169433594|  0:01:37s\n","epoch 86 | loss: 168.03678| val_0_mse: 168.798583984375|  0:01:38s\n","epoch 87 | loss: 166.44909| val_0_mse: 178.9399871826172|  0:01:40s\n","epoch 88 | loss: 164.8012| val_0_mse: 176.95701599121094|  0:01:41s\n","epoch 89 | loss: 164.4953| val_0_mse: 187.45916748046875|  0:01:42s\n","epoch 90 | loss: 164.36169| val_0_mse: 186.31112670898438|  0:01:43s\n","epoch 91 | loss: 166.20692| val_0_mse: 181.9894561767578|  0:01:44s\n","epoch 92 | loss: 163.3937| val_0_mse: 191.70135498046875|  0:01:45s\n","epoch 93 | loss: 179.05626| val_0_mse: 185.30616760253906|  0:01:46s\n","epoch 94 | loss: 172.94445| val_0_mse: 189.93539428710938|  0:01:47s\n","epoch 95 | loss: 166.65148| val_0_mse: 190.5428009033203|  0:01:49s\n","epoch 96 | loss: 159.66497| val_0_mse: 167.71417236328125|  0:01:50s\n","epoch 97 | loss: 163.38642| val_0_mse: 173.45318603515625|  0:01:51s\n","epoch 98 | loss: 163.2952| val_0_mse: 171.73486328125|  0:01:52s\n","epoch 99 | loss: 156.73006| val_0_mse: 164.82093811035156|  0:01:53s\n","Stop training because you reached max_epochs = 100 with best_epoch = 99 and best_val_0_mse = 164.82093811035156\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 15:37:50,131] Trial 98 finished with value: 164.82093811035156 and parameters: {'n_d': 64, 'n_steps': 7, 'gamma': 1.4439139415056461, 'n_independent': 4, 'n_shared': 2, 'momentum': 0.2906631523981622}. Best is trial 33 with value: 135.8055877685547.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 1585.84587| val_0_mse: 34502.75390625|  0:00:00s\n","epoch 1  | loss: 460.3007| val_0_mse: 11995.7734375|  0:00:01s\n","epoch 2  | loss: 373.14782| val_0_mse: 7181.12060546875|  0:00:01s\n","epoch 3  | loss: 294.2411| val_0_mse: 1925.7633056640625|  0:00:02s\n","epoch 4  | loss: 300.53768| val_0_mse: 3048.811767578125|  0:00:03s\n","epoch 5  | loss: 283.88398| val_0_mse: 1949.3536376953125|  0:00:03s\n","epoch 6  | loss: 272.06189| val_0_mse: 2351.68408203125|  0:00:04s\n","epoch 7  | loss: 267.90889| val_0_mse: 3910.25048828125|  0:00:05s\n","epoch 8  | loss: 261.89424| val_0_mse: 1557.8394775390625|  0:00:05s\n","epoch 9  | loss: 244.94405| val_0_mse: 1480.325439453125|  0:00:06s\n","epoch 10 | loss: 252.45689| val_0_mse: 2222.34765625|  0:00:07s\n","epoch 11 | loss: 239.12446| val_0_mse: 2450.130859375|  0:00:07s\n","epoch 12 | loss: 230.81992| val_0_mse: 2278.248046875|  0:00:08s\n","epoch 13 | loss: 227.07229| val_0_mse: 2699.365966796875|  0:00:08s\n","epoch 14 | loss: 241.43877| val_0_mse: 2133.947998046875|  0:00:09s\n","epoch 15 | loss: 224.61465| val_0_mse: 1259.5286865234375|  0:00:10s\n","epoch 16 | loss: 225.65077| val_0_mse: 1480.3782958984375|  0:00:10s\n","epoch 17 | loss: 214.8933| val_0_mse: 1556.7747802734375|  0:00:11s\n","epoch 18 | loss: 228.10505| val_0_mse: 1212.641845703125|  0:00:12s\n","epoch 19 | loss: 214.7878| val_0_mse: 892.062744140625|  0:00:12s\n","epoch 20 | loss: 214.9695| val_0_mse: 785.4368286132812|  0:00:13s\n","epoch 21 | loss: 214.30632| val_0_mse: 633.5510864257812|  0:00:14s\n","epoch 22 | loss: 201.76323| val_0_mse: 509.8132019042969|  0:00:14s\n","epoch 23 | loss: 211.61502| val_0_mse: 568.8787841796875|  0:00:15s\n","epoch 24 | loss: 196.59954| val_0_mse: 457.85894775390625|  0:00:15s\n","epoch 25 | loss: 204.56309| val_0_mse: 402.9302673339844|  0:00:16s\n","epoch 26 | loss: 195.47952| val_0_mse: 268.44219970703125|  0:00:17s\n","epoch 27 | loss: 212.43421| val_0_mse: 278.4087219238281|  0:00:17s\n","epoch 28 | loss: 209.6902| val_0_mse: 253.5721435546875|  0:00:18s\n","epoch 29 | loss: 204.55854| val_0_mse: 246.31857299804688|  0:00:18s\n","epoch 30 | loss: 196.84234| val_0_mse: 224.29762268066406|  0:00:19s\n","epoch 31 | loss: 196.18851| val_0_mse: 239.2562255859375|  0:00:20s\n","epoch 32 | loss: 192.73662| val_0_mse: 256.1838684082031|  0:00:20s\n","epoch 33 | loss: 190.63618| val_0_mse: 255.33792114257812|  0:00:21s\n","epoch 34 | loss: 189.52321| val_0_mse: 197.80824279785156|  0:00:22s\n","epoch 35 | loss: 181.7569| val_0_mse: 222.01890563964844|  0:00:22s\n","epoch 36 | loss: 192.62571| val_0_mse: 226.55535888671875|  0:00:23s\n","epoch 37 | loss: 181.3327| val_0_mse: 223.22744750976562|  0:00:23s\n","epoch 38 | loss: 173.6053| val_0_mse: 207.37962341308594|  0:00:24s\n","epoch 39 | loss: 169.78983| val_0_mse: 177.95779418945312|  0:00:25s\n","epoch 40 | loss: 178.3298| val_0_mse: 217.08090209960938|  0:00:25s\n","epoch 41 | loss: 166.47948| val_0_mse: 170.88894653320312|  0:00:26s\n","epoch 42 | loss: 167.55243| val_0_mse: 257.1434326171875|  0:00:27s\n","epoch 43 | loss: 174.54279| val_0_mse: 202.18157958984375|  0:00:27s\n","epoch 44 | loss: 161.08826| val_0_mse: 172.33642578125|  0:00:28s\n","epoch 45 | loss: 164.14852| val_0_mse: 237.75677490234375|  0:00:28s\n","epoch 46 | loss: 161.35273| val_0_mse: 166.77169799804688|  0:00:29s\n","epoch 47 | loss: 167.02998| val_0_mse: 178.1045379638672|  0:00:30s\n","epoch 48 | loss: 160.54762| val_0_mse: 185.2054443359375|  0:00:30s\n","epoch 49 | loss: 157.38836| val_0_mse: 180.66488647460938|  0:00:31s\n","epoch 50 | loss: 156.15774| val_0_mse: 222.7240753173828|  0:00:32s\n","epoch 51 | loss: 157.69708| val_0_mse: 172.7913055419922|  0:00:32s\n","epoch 52 | loss: 154.00916| val_0_mse: 260.4972229003906|  0:00:33s\n","epoch 53 | loss: 159.75231| val_0_mse: 194.3456573486328|  0:00:33s\n","epoch 54 | loss: 158.59227| val_0_mse: 172.74830627441406|  0:00:34s\n","epoch 55 | loss: 156.12178| val_0_mse: 170.7146453857422|  0:00:35s\n","epoch 56 | loss: 150.4544| val_0_mse: 208.7801971435547|  0:00:35s\n","\n","Early stopping occurred at epoch 56 with best_epoch = 46 and best_val_0_mse = 166.77169799804688\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 15:38:26,243] Trial 99 finished with value: 166.77169799804688 and parameters: {'n_d': 58, 'n_steps': 3, 'gamma': 1.4935322964190052, 'n_independent': 2, 'n_shared': 4, 'momentum': 0.20474979051373327}. Best is trial 33 with value: 135.8055877685547.\n"]}]},{"cell_type":"code","source":["best_params"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sg7oYTivFBGe","executionInfo":{"status":"ok","timestamp":1729006706770,"user_tz":-480,"elapsed":81,"user":{"displayName":"Jonindo Pasaribu","userId":"10958990953097471082"}},"outputId":"9e10589e-950d-4f2f-bb05-6f8c2c4564c0"},"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'n_d': 57,\n"," 'n_steps': 3,\n"," 'gamma': 1.4326005028022137,\n"," 'n_independent': 3,\n"," 'n_shared': 3,\n"," 'momentum': 0.10390725153746129}"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["from pytorch_tabnet.callbacks import Callback\n","\n","def print_memory_usage():\n","    process = psutil.Process()\n","    mem_info = process.memory_info()\n","    print(f\"Memory Usage: {mem_info.rss / (1024 ** 2):.2f} MB\")\n","\n","class MemoryUsageCallback(Callback):\n","    def on_epoch_end(self, epoch, logs=None):\n","        print_memory_usage()"],"metadata":{"id":"Tc2ueju9nSae","executionInfo":{"status":"ok","timestamp":1729006706770,"user_tz":-480,"elapsed":3,"user":{"displayName":"Jonindo Pasaribu","userId":"10958990953097471082"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["# Train final model using best hyperparameters\n","best_model = TabNetRegressor(**best_params,\n","                             n_a=best_params['n_d'],\n","                             optimizer_fn=torch.optim.Adam,\n","                             optimizer_params=dict(lr=2e-2)\n","                             )\n","best_model.fit(\n","    X_train, y_train,\n","    eval_set=[(X_train, y_train), (X_valid, y_valid)],\n","    eval_name=['train', 'valid'],\n","    eval_metric=['mae', 'rmse'],\n","    callbacks=[MemoryUsageCallback()]\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rLdfMkJXw_Xl","executionInfo":{"status":"ok","timestamp":1729006785594,"user_tz":-480,"elapsed":78827,"user":{"displayName":"Jonindo Pasaribu","userId":"10958990953097471082"}},"outputId":"9a083cb5-60e9-4b95-8c58-68f9963450c3"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 1635.88506| train_mae: 40.05009841918945| train_rmse: 63.12295913696289| valid_mae: 37.89181900024414| valid_rmse: 59.29082107543945|  0:00:00s\n","Memory Usage: 1223.48 MB\n","epoch 1  | loss: 451.87158| train_mae: 35.08042907714844| train_rmse: 45.933998107910156| valid_mae: 35.7258186340332| valid_rmse: 47.01129913330078|  0:00:01s\n","Memory Usage: 1223.48 MB\n","epoch 2  | loss: 344.96931| train_mae: 58.52035903930664| train_rmse: 77.70072174072266| valid_mae: 60.758018493652344| valid_rmse: 79.64662170410156|  0:00:02s\n","Memory Usage: 1223.48 MB\n","epoch 3  | loss: 299.25001| train_mae: 22.249000549316406| train_rmse: 31.95471954345703| valid_mae: 22.811370849609375| valid_rmse: 32.34431076049805|  0:00:03s\n","Memory Usage: 1223.48 MB\n","epoch 4  | loss: 293.87474| train_mae: 43.87417984008789| train_rmse: 64.5948486328125| valid_mae: 46.00606155395508| valid_rmse: 66.53350067138672|  0:00:04s\n","Memory Usage: 1223.48 MB\n","epoch 5  | loss: 296.14812| train_mae: 19.75589942932129| train_rmse: 29.146320343017578| valid_mae: 20.384580612182617| valid_rmse: 29.811370849609375|  0:00:05s\n","Memory Usage: 1223.48 MB\n","epoch 6  | loss: 283.04573| train_mae: 26.262439727783203| train_rmse: 38.87575912475586| valid_mae: 27.43791961669922| valid_rmse: 39.892578125|  0:00:06s\n","Memory Usage: 1223.48 MB\n","epoch 7  | loss: 270.37233| train_mae: 19.545560836791992| train_rmse: 30.182039260864258| valid_mae: 20.351699829101562| valid_rmse: 31.238849639892578|  0:00:07s\n","Memory Usage: 1223.48 MB\n","epoch 8  | loss: 267.65484| train_mae: 20.439279556274414| train_rmse: 30.790599822998047| valid_mae: 21.47711944580078| valid_rmse: 32.143638610839844|  0:00:08s\n","Memory Usage: 1223.48 MB\n","epoch 9  | loss: 265.79415| train_mae: 38.54962158203125| train_rmse: 57.82307815551758| valid_mae: 40.622779846191406| valid_rmse: 60.29909896850586|  0:00:09s\n","Memory Usage: 1223.48 MB\n","epoch 10 | loss: 250.644 | train_mae: 36.507938385009766| train_rmse: 54.440059661865234| valid_mae: 38.147830963134766| valid_rmse: 56.23004150390625|  0:00:09s\n","Memory Usage: 1223.48 MB\n","epoch 11 | loss: 241.21028| train_mae: 21.94978904724121| train_rmse: 31.757200241088867| valid_mae: 22.568470001220703| valid_rmse: 32.29431915283203|  0:00:10s\n","Memory Usage: 1223.48 MB\n","epoch 12 | loss: 232.37621| train_mae: 24.425939559936523| train_rmse: 37.30931854248047| valid_mae: 25.616439819335938| valid_rmse: 39.123470306396484|  0:00:11s\n","Memory Usage: 1223.48 MB\n","epoch 13 | loss: 237.0801| train_mae: 22.834680557250977| train_rmse: 35.98228073120117| valid_mae: 24.256059646606445| valid_rmse: 38.095638275146484|  0:00:12s\n","Memory Usage: 1223.48 MB\n","epoch 14 | loss: 235.0746| train_mae: 14.897029876708984| train_rmse: 23.180030822753906| valid_mae: 15.370209693908691| valid_rmse: 24.03516960144043|  0:00:13s\n","Memory Usage: 1223.48 MB\n","epoch 15 | loss: 225.46273| train_mae: 15.699689865112305| train_rmse: 24.286439895629883| valid_mae: 16.285709381103516| valid_rmse: 25.352699279785156|  0:00:14s\n","Memory Usage: 1223.48 MB\n","epoch 16 | loss: 228.17899| train_mae: 18.32090950012207| train_rmse: 28.024179458618164| valid_mae: 19.223779678344727| valid_rmse: 29.256139755249023|  0:00:15s\n","Memory Usage: 1223.48 MB\n","epoch 17 | loss: 228.5251| train_mae: 12.535750389099121| train_rmse: 18.797529220581055| valid_mae: 12.781780242919922| valid_rmse: 19.035839080810547|  0:00:16s\n","Memory Usage: 1223.48 MB\n","epoch 18 | loss: 223.52459| train_mae: 11.477459907531738| train_rmse: 17.008140563964844| valid_mae: 11.539870262145996| valid_rmse: 17.173280715942383|  0:00:17s\n","Memory Usage: 1223.48 MB\n","epoch 19 | loss: 219.85875| train_mae: 12.919139862060547| train_rmse: 20.360599517822266| valid_mae: 13.379690170288086| valid_rmse: 20.93001937866211|  0:00:18s\n","Memory Usage: 1223.48 MB\n","epoch 20 | loss: 224.59751| train_mae: 12.077690124511719| train_rmse: 19.041969299316406| valid_mae: 12.610679626464844| valid_rmse: 19.747329711914062|  0:00:19s\n","Memory Usage: 1223.48 MB\n","epoch 21 | loss: 220.76618| train_mae: 10.979940414428711| train_rmse: 16.507280349731445| valid_mae: 11.290160179138184| valid_rmse: 16.966819763183594|  0:00:20s\n","Memory Usage: 1223.48 MB\n","epoch 22 | loss: 213.61193| train_mae: 11.440509796142578| train_rmse: 17.59324073791504| valid_mae: 11.915329933166504| valid_rmse: 18.159740447998047|  0:00:20s\n","Memory Usage: 1223.48 MB\n","epoch 23 | loss: 210.21937| train_mae: 11.079330444335938| train_rmse: 16.59514045715332| valid_mae: 11.298529624938965| valid_rmse: 16.806570053100586|  0:00:21s\n","Memory Usage: 1223.48 MB\n","epoch 24 | loss: 206.22287| train_mae: 11.248950004577637| train_rmse: 17.5805606842041| valid_mae: 11.820839881896973| valid_rmse: 18.270280838012695|  0:00:22s\n","Memory Usage: 1223.48 MB\n","epoch 25 | loss: 201.37615| train_mae: 10.733110427856445| train_rmse: 16.43954086303711| valid_mae: 11.133769989013672| valid_rmse: 16.90666961669922|  0:00:23s\n","Memory Usage: 1223.48 MB\n","epoch 26 | loss: 194.84723| train_mae: 9.53538990020752| train_rmse: 14.84076976776123| valid_mae: 9.998820304870605| valid_rmse: 15.488019943237305|  0:00:24s\n","Memory Usage: 1223.48 MB\n","epoch 27 | loss: 194.4141| train_mae: 9.74705982208252| train_rmse: 14.839070320129395| valid_mae: 10.144180297851562| valid_rmse: 15.481969833374023|  0:00:25s\n","Memory Usage: 1223.48 MB\n","epoch 28 | loss: 202.31261| train_mae: 10.621649742126465| train_rmse: 15.936820030212402| valid_mae: 10.955109596252441| valid_rmse: 16.407569885253906|  0:00:26s\n","Memory Usage: 1223.48 MB\n","epoch 29 | loss: 214.37866| train_mae: 9.562589645385742| train_rmse: 14.090479850769043| valid_mae: 10.037969589233398| valid_rmse: 14.695690155029297|  0:00:27s\n","Memory Usage: 1223.48 MB\n","epoch 30 | loss: 190.50572| train_mae: 9.526430130004883| train_rmse: 14.22426986694336| valid_mae: 10.055899620056152| valid_rmse: 14.964839935302734|  0:00:28s\n","Memory Usage: 1223.48 MB\n","epoch 31 | loss: 194.70678| train_mae: 10.007559776306152| train_rmse: 14.784890174865723| valid_mae: 10.280799865722656| valid_rmse: 15.11950969696045|  0:00:29s\n","Memory Usage: 1223.48 MB\n","epoch 32 | loss: 194.92534| train_mae: 9.013580322265625| train_rmse: 13.660360336303711| valid_mae: 9.375269889831543| valid_rmse: 14.215530395507812|  0:00:30s\n","Memory Usage: 1223.48 MB\n","epoch 33 | loss: 209.00819| train_mae: 9.604009628295898| train_rmse: 14.411210060119629| valid_mae: 10.044960021972656| valid_rmse: 15.00767993927002|  0:00:31s\n","Memory Usage: 1223.48 MB\n","epoch 34 | loss: 195.56485| train_mae: 9.467249870300293| train_rmse: 15.006540298461914| valid_mae: 9.95149040222168| valid_rmse: 15.726460456848145|  0:00:32s\n","Memory Usage: 1223.48 MB\n","epoch 35 | loss: 187.59302| train_mae: 8.804889678955078| train_rmse: 13.290969848632812| valid_mae: 9.283309936523438| valid_rmse: 13.902299880981445|  0:00:32s\n","Memory Usage: 1223.48 MB\n","epoch 36 | loss: 195.34046| train_mae: 8.911629676818848| train_rmse: 13.30482006072998| valid_mae: 9.462200164794922| valid_rmse: 14.08428955078125|  0:00:33s\n","Memory Usage: 1223.48 MB\n","epoch 37 | loss: 194.34168| train_mae: 9.128910064697266| train_rmse: 13.796850204467773| valid_mae: 9.48069953918457| valid_rmse: 14.277990341186523|  0:00:34s\n","Memory Usage: 1223.48 MB\n","epoch 38 | loss: 196.98549| train_mae: 8.975799560546875| train_rmse: 13.852009773254395| valid_mae: 9.451800346374512| valid_rmse: 14.483590126037598|  0:00:35s\n","Memory Usage: 1223.48 MB\n","epoch 39 | loss: 190.20896| train_mae: 9.051750183105469| train_rmse: 14.615130424499512| valid_mae: 9.60200023651123| valid_rmse: 15.512299537658691|  0:00:36s\n","Memory Usage: 1223.48 MB\n","epoch 40 | loss: 188.83439| train_mae: 9.30562973022461| train_rmse: 13.822059631347656| valid_mae: 9.832369804382324| valid_rmse: 14.508830070495605|  0:00:37s\n","Memory Usage: 1223.48 MB\n","epoch 41 | loss: 185.82973| train_mae: 8.529879570007324| train_rmse: 12.822310447692871| valid_mae: 9.159390449523926| valid_rmse: 13.748709678649902|  0:00:38s\n","Memory Usage: 1223.48 MB\n","epoch 42 | loss: 179.82041| train_mae: 8.658849716186523| train_rmse: 12.872570037841797| valid_mae: 9.21483039855957| valid_rmse: 13.584890365600586|  0:00:39s\n","Memory Usage: 1223.48 MB\n","epoch 43 | loss: 180.19554| train_mae: 8.519570350646973| train_rmse: 13.023099899291992| valid_mae: 9.149200439453125| valid_rmse: 13.83683967590332|  0:00:40s\n","Memory Usage: 1223.48 MB\n","epoch 44 | loss: 184.32644| train_mae: 8.625410079956055| train_rmse: 13.402259826660156| valid_mae: 9.12244987487793| valid_rmse: 13.977629661560059|  0:00:41s\n","Memory Usage: 1223.48 MB\n","epoch 45 | loss: 181.85656| train_mae: 8.555999755859375| train_rmse: 12.973170280456543| valid_mae: 9.182499885559082| valid_rmse: 13.893210411071777|  0:00:42s\n","Memory Usage: 1223.48 MB\n","epoch 46 | loss: 177.37124| train_mae: 8.269729614257812| train_rmse: 13.08213996887207| valid_mae: 8.98313045501709| valid_rmse: 14.195670127868652|  0:00:43s\n","Memory Usage: 1223.48 MB\n","epoch 47 | loss: 177.11766| train_mae: 9.02892017364502| train_rmse: 13.353750228881836| valid_mae: 9.58180046081543| valid_rmse: 14.032999992370605|  0:00:43s\n","Memory Usage: 1223.48 MB\n","epoch 48 | loss: 185.5507| train_mae: 8.750020027160645| train_rmse: 12.901809692382812| valid_mae: 9.218449592590332| valid_rmse: 13.550339698791504|  0:00:44s\n","Memory Usage: 1223.48 MB\n","epoch 49 | loss: 177.48296| train_mae: 8.606610298156738| train_rmse: 12.953760147094727| valid_mae: 9.236220359802246| valid_rmse: 13.834500312805176|  0:00:45s\n","Memory Usage: 1223.48 MB\n","epoch 50 | loss: 189.1199| train_mae: 8.607000350952148| train_rmse: 13.520319938659668| valid_mae: 9.30243968963623| valid_rmse: 14.606630325317383|  0:00:46s\n","Memory Usage: 1223.48 MB\n","epoch 51 | loss: 180.30634| train_mae: 8.362939834594727| train_rmse: 13.188190460205078| valid_mae: 8.945730209350586| valid_rmse: 14.044919967651367|  0:00:47s\n","Memory Usage: 1223.48 MB\n","epoch 52 | loss: 171.18474| train_mae: 8.723360061645508| train_rmse: 12.884289741516113| valid_mae: 9.281490325927734| valid_rmse: 13.683639526367188|  0:00:48s\n","Memory Usage: 1223.48 MB\n","epoch 53 | loss: 169.8718| train_mae: 8.368670463562012| train_rmse: 12.83318042755127| valid_mae: 9.116800308227539| valid_rmse: 14.043720245361328|  0:00:49s\n","Memory Usage: 1223.48 MB\n","epoch 54 | loss: 168.16243| train_mae: 8.070090293884277| train_rmse: 12.347809791564941| valid_mae: 8.778450012207031| valid_rmse: 13.533340454101562|  0:00:50s\n","Memory Usage: 1223.48 MB\n","epoch 55 | loss: 169.43289| train_mae: 8.085840225219727| train_rmse: 12.594369888305664| valid_mae: 8.697310447692871| valid_rmse: 13.544099807739258|  0:00:51s\n","Memory Usage: 1223.48 MB\n","epoch 56 | loss: 173.56932| train_mae: 8.298600196838379| train_rmse: 12.53042984008789| valid_mae: 8.934470176696777| valid_rmse: 13.504130363464355|  0:00:52s\n","Memory Usage: 1223.48 MB\n","epoch 57 | loss: 169.98001| train_mae: 8.087989807128906| train_rmse: 12.875869750976562| valid_mae: 8.768110275268555| valid_rmse: 14.063170433044434|  0:00:52s\n","Memory Usage: 1223.48 MB\n","epoch 58 | loss: 177.93389| train_mae: 8.766980171203613| train_rmse: 12.958080291748047| valid_mae: 9.243840217590332| valid_rmse: 13.653759956359863|  0:00:53s\n","Memory Usage: 1223.48 MB\n","epoch 59 | loss: 177.67412| train_mae: 8.578980445861816| train_rmse: 12.582189559936523| valid_mae: 9.191189765930176| valid_rmse: 13.49586009979248|  0:00:54s\n","Memory Usage: 1223.48 MB\n","epoch 60 | loss: 177.82319| train_mae: 8.298199653625488| train_rmse: 12.684370040893555| valid_mae: 8.934789657592773| valid_rmse: 13.76636028289795|  0:00:55s\n","Memory Usage: 1223.48 MB\n","epoch 61 | loss: 169.19099| train_mae: 8.421649932861328| train_rmse: 12.457610130310059| valid_mae: 9.0029296875| valid_rmse: 13.35338020324707|  0:00:56s\n","Memory Usage: 1223.48 MB\n","epoch 62 | loss: 168.47872| train_mae: 8.225020408630371| train_rmse: 12.861889839172363| valid_mae: 8.942359924316406| valid_rmse: 13.981340408325195|  0:00:57s\n","Memory Usage: 1223.48 MB\n","epoch 63 | loss: 168.67548| train_mae: 8.350870132446289| train_rmse: 12.624489784240723| valid_mae: 9.089010238647461| valid_rmse: 13.700039863586426|  0:00:58s\n","Memory Usage: 1223.48 MB\n","epoch 64 | loss: 167.01818| train_mae: 7.97613000869751| train_rmse: 12.370550155639648| valid_mae: 8.597180366516113| valid_rmse: 13.258600234985352|  0:00:59s\n","Memory Usage: 1223.48 MB\n","epoch 65 | loss: 165.21982| train_mae: 8.672430038452148| train_rmse: 12.71718978881836| valid_mae: 9.27495002746582| valid_rmse: 13.630620002746582|  0:01:00s\n","Memory Usage: 1223.48 MB\n","epoch 66 | loss: 161.19209| train_mae: 8.599149703979492| train_rmse: 12.765589714050293| valid_mae: 9.228429794311523| valid_rmse: 13.633959770202637|  0:01:01s\n","Memory Usage: 1223.48 MB\n","epoch 67 | loss: 155.7244| train_mae: 8.189780235290527| train_rmse: 12.434430122375488| valid_mae: 8.912409782409668| valid_rmse: 13.645159721374512|  0:01:02s\n","Memory Usage: 1223.48 MB\n","epoch 68 | loss: 161.50502| train_mae: 8.022299766540527| train_rmse: 12.167980194091797| valid_mae: 8.757410049438477| valid_rmse: 13.285759925842285|  0:01:03s\n","Memory Usage: 1223.48 MB\n","epoch 69 | loss: 158.82958| train_mae: 8.171130180358887| train_rmse: 12.10241985321045| valid_mae: 8.860930442810059| valid_rmse: 13.106590270996094|  0:01:03s\n","Memory Usage: 1223.48 MB\n","epoch 70 | loss: 164.21739| train_mae: 8.287859916687012| train_rmse: 12.387370109558105| valid_mae: 8.914130210876465| valid_rmse: 13.270039558410645|  0:01:04s\n","Memory Usage: 1223.48 MB\n","epoch 71 | loss: 166.45143| train_mae: 8.37477970123291| train_rmse: 12.551830291748047| valid_mae: 8.95343017578125| valid_rmse: 13.193429946899414|  0:01:05s\n","Memory Usage: 1223.48 MB\n","epoch 72 | loss: 170.63692| train_mae: 7.94605016708374| train_rmse: 12.557700157165527| valid_mae: 8.665390014648438| valid_rmse: 13.728930473327637|  0:01:06s\n","Memory Usage: 1223.48 MB\n","epoch 73 | loss: 157.63681| train_mae: 7.699679851531982| train_rmse: 11.895870208740234| valid_mae: 8.35966968536377| valid_rmse: 12.962960243225098|  0:01:07s\n","Memory Usage: 1223.48 MB\n","epoch 74 | loss: 153.77986| train_mae: 8.15641975402832| train_rmse: 12.254670143127441| valid_mae: 8.698989868164062| valid_rmse: 12.868080139160156|  0:01:08s\n","Memory Usage: 1223.48 MB\n","epoch 75 | loss: 161.82636| train_mae: 8.141119956970215| train_rmse: 12.111300468444824| valid_mae: 8.67553997039795| valid_rmse: 12.82526969909668|  0:01:09s\n","Memory Usage: 1223.48 MB\n","epoch 76 | loss: 153.2004| train_mae: 8.040610313415527| train_rmse: 12.210820198059082| valid_mae: 8.887089729309082| valid_rmse: 13.529159545898438|  0:01:10s\n","Memory Usage: 1223.48 MB\n","epoch 77 | loss: 148.44845| train_mae: 7.586919784545898| train_rmse: 11.993180274963379| valid_mae: 8.311619758605957| valid_rmse: 13.131429672241211|  0:01:11s\n","Memory Usage: 1223.48 MB\n","epoch 78 | loss: 154.44487| train_mae: 7.785419940948486| train_rmse: 11.91234016418457| valid_mae: 8.546910285949707| valid_rmse: 13.121740341186523|  0:01:12s\n","Memory Usage: 1223.48 MB\n","epoch 79 | loss: 155.17632| train_mae: 7.993760108947754| train_rmse: 12.21288013458252| valid_mae: 8.624329566955566| valid_rmse: 13.143409729003906|  0:01:13s\n","Memory Usage: 1223.48 MB\n","epoch 80 | loss: 160.98165| train_mae: 8.396690368652344| train_rmse: 12.941010475158691| valid_mae: 8.951889991760254| valid_rmse: 13.588370323181152|  0:01:13s\n","Memory Usage: 1223.48 MB\n","epoch 81 | loss: 164.03299| train_mae: 8.164079666137695| train_rmse: 12.470549583435059| valid_mae: 8.922380447387695| valid_rmse: 13.492630004882812|  0:01:14s\n","Memory Usage: 1223.48 MB\n","epoch 82 | loss: 159.10639| train_mae: 7.657370090484619| train_rmse: 11.770440101623535| valid_mae: 8.327659606933594| valid_rmse: 12.908069610595703|  0:01:15s\n","Memory Usage: 1223.48 MB\n","epoch 83 | loss: 157.28585| train_mae: 7.916029930114746| train_rmse: 12.019450187683105| valid_mae: 8.583009719848633| valid_rmse: 13.121749877929688|  0:01:16s\n","Memory Usage: 1223.48 MB\n","epoch 84 | loss: 151.71785| train_mae: 7.897830009460449| train_rmse: 12.058930397033691| valid_mae: 8.491379737854004| valid_rmse: 13.12738037109375|  0:01:17s\n","Memory Usage: 1223.48 MB\n","epoch 85 | loss: 155.25512| train_mae: 7.751870155334473| train_rmse: 11.747420310974121| valid_mae: 8.532930374145508| valid_rmse: 13.121129989624023|  0:01:18s\n","Memory Usage: 1223.48 MB\n","\n","Early stopping occurred at epoch 85 with best_epoch = 75 and best_valid_rmse = 12.82526969909668\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n"]}]},{"cell_type":"code","source":["from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, classification_report\n","\n","preds = best_model.predict(X_test)\n","y_true = y_test\n","\n","mae_test = mean_absolute_error(y_pred=preds, y_true=y_true)\n","mse = mean_squared_error(y_pred=preds, y_true=y_true)\n","rmse_test = np.sqrt(mean_squared_error(y_true, y_pred=preds))\n","r2_test = r2_score(y_true=y_true, y_pred=preds)\n","\n","print(\"Best Valid RMSE:\", best_model.best_cost)\n","print(\"Test MAE:\", mae_test)\n","print(\"Test RMSE:\", rmse_test)\n","print(\"R-squared:\", r2_test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"o3TYXT_o_6oS","executionInfo":{"status":"ok","timestamp":1729006785594,"user_tz":-480,"elapsed":11,"user":{"displayName":"Jonindo Pasaribu","userId":"10958990953097471082"}},"outputId":"f436b493-8103-40a6-8d3c-1cc32dd40888"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Best Valid RMSE: 12.825269\n","Test MAE: 8.69767\n","Test RMSE: 13.161221\n","R-squared: 0.8514436483383179\n"]}]},{"cell_type":"code","source":["base_preds = tnr.predict(X_test)\n","\n","base_mae_test = mean_absolute_error(y_pred=base_preds, y_true=y_true)\n","base_mse = mean_squared_error(y_pred=base_preds, y_true=y_true)\n","base_rmse_test = np.sqrt(mean_squared_error(y_true, y_pred=base_preds))\n","\n","print(\"Best Valid Score:\", tnr.best_cost)\n","print(\"Test MAE:\", base_mae_test)\n","print(\"Test RMSE:\", base_rmse_test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8nW4N4ls2O6R","executionInfo":{"status":"ok","timestamp":1719678487046,"user_tz":-420,"elapsed":573,"user":{"displayName":"Jonindo Pasaribu","userId":"10958990953097471082"}},"outputId":"7ef5eb55-479d-419c-8ac6-6531e841e0f5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Best Valid Score: 34.443657\n","Test MAE: 23.186302\n","Test RMSE: 34.57977\n"]}]}]}