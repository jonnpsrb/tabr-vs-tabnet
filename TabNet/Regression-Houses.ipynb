{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","machine_shape":"hm","authorship_tag":"ABX9TyMIEateto2O+sqgyhAifbxe"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["!wget https://huggingface.co/datasets/puhsu/tabular-benchmarks/resolve/main/data.tar -O tabular-dl-tabr.tar.gz\n","!tar -xvf tabular-dl-tabr.tar.gz"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pulqlCAgJDEt","executionInfo":{"status":"ok","timestamp":1728990733141,"user_tz":-480,"elapsed":18601,"user":{"displayName":"Jonindo Pasaribu","userId":"10958990953097471082"}},"outputId":"27bec57d-3f77-470e-f175-d14819219cab"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["--2024-10-15 11:11:54--  https://huggingface.co/datasets/puhsu/tabular-benchmarks/resolve/main/data.tar\n","Resolving huggingface.co (huggingface.co)... 18.244.202.60, 18.244.202.118, 18.244.202.68, ...\n","Connecting to huggingface.co (huggingface.co)|18.244.202.60|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://cdn-lfs.hf.co/repos/1b/25/1b25d6e2556c827abfaf6ba9da6021338691cafc39fe9d77986955ae0a69243d/0d74e4b96febb48fbe4dd2d851f8638b5738354f82c3183f92adbd2abf2f256b?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27data.tar%3B+filename%3D%22data.tar%22%3B&response-content-type=application%2Fx-tar&Expires=1729249914&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcyOTI0OTkxNH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5oZi5jby9yZXBvcy8xYi8yNS8xYjI1ZDZlMjU1NmM4MjdhYmZhZjZiYTlkYTYwMjEzMzg2OTFjYWZjMzlmZTlkNzc5ODY5NTVhZTBhNjkyNDNkLzBkNzRlNGI5NmZlYmI0OGZiZTRkZDJkODUxZjg2MzhiNTczODM1NGY4MmMzMTgzZjkyYWRiZDJhYmYyZjI1NmI%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qJnJlc3BvbnNlLWNvbnRlbnQtdHlwZT0qIn1dfQ__&Signature=O5I8DYG9ZZfFRuguVZMS98d83soc9ed23CRw4Wd0DEibQcpvttN%7EeCquF3xX70p9YKhY6AzQwDvGx%7E8qBrwKnJ46ycfaNq7jIH-bRD4Ou-u5Gub9QkCHcP0nQNcXzGvtOvREVhdJ-Acc6Lg2B16Xq9EBrEQyUGjYcWE-HzJXzd1205IdUHzsMy2QMKQ3HS%7EiqCtCCnXch8tSxEOUUMJUrAxGBYSY-thsOALCBKinfMi2UyarFmlUZfVto%7E5ZXgFCorgE-XnZFizKsT8kZ%7EU7QB%7EEK6Jjg8BgHHCbxZx9wlqy5OzdKaUo4K5fb83tI0E-HgAL7VcNBqBuY19BuzNuIA__&Key-Pair-Id=K3RPWS32NSSJCE [following]\n","--2024-10-15 11:11:54--  https://cdn-lfs.hf.co/repos/1b/25/1b25d6e2556c827abfaf6ba9da6021338691cafc39fe9d77986955ae0a69243d/0d74e4b96febb48fbe4dd2d851f8638b5738354f82c3183f92adbd2abf2f256b?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27data.tar%3B+filename%3D%22data.tar%22%3B&response-content-type=application%2Fx-tar&Expires=1729249914&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcyOTI0OTkxNH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5oZi5jby9yZXBvcy8xYi8yNS8xYjI1ZDZlMjU1NmM4MjdhYmZhZjZiYTlkYTYwMjEzMzg2OTFjYWZjMzlmZTlkNzc5ODY5NTVhZTBhNjkyNDNkLzBkNzRlNGI5NmZlYmI0OGZiZTRkZDJkODUxZjg2MzhiNTczODM1NGY4MmMzMTgzZjkyYWRiZDJhYmYyZjI1NmI%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qJnJlc3BvbnNlLWNvbnRlbnQtdHlwZT0qIn1dfQ__&Signature=O5I8DYG9ZZfFRuguVZMS98d83soc9ed23CRw4Wd0DEibQcpvttN%7EeCquF3xX70p9YKhY6AzQwDvGx%7E8qBrwKnJ46ycfaNq7jIH-bRD4Ou-u5Gub9QkCHcP0nQNcXzGvtOvREVhdJ-Acc6Lg2B16Xq9EBrEQyUGjYcWE-HzJXzd1205IdUHzsMy2QMKQ3HS%7EiqCtCCnXch8tSxEOUUMJUrAxGBYSY-thsOALCBKinfMi2UyarFmlUZfVto%7E5ZXgFCorgE-XnZFizKsT8kZ%7EU7QB%7EEK6Jjg8BgHHCbxZx9wlqy5OzdKaUo4K5fb83tI0E-HgAL7VcNBqBuY19BuzNuIA__&Key-Pair-Id=K3RPWS32NSSJCE\n","Resolving cdn-lfs.hf.co (cdn-lfs.hf.co)... 18.160.78.76, 18.160.78.87, 18.160.78.43, ...\n","Connecting to cdn-lfs.hf.co (cdn-lfs.hf.co)|18.160.78.76|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 3094384640 (2.9G) [application/x-tar]\n","Saving to: ‘tabular-dl-tabr.tar.gz’\n","\n","tabular-dl-tabr.tar 100%[===================>]   2.88G   326MB/s    in 9.1s    \n","\n","2024-10-15 11:12:03 (324 MB/s) - ‘tabular-dl-tabr.tar.gz’ saved [3094384640/3094384640]\n","\n","data/\n","data/regression-num-medium-0-Ailerons/\n","data/regression-num-medium-0-Ailerons/X_num_val.npy\n","data/regression-num-medium-0-Ailerons/Y_val.npy\n","data/regression-num-medium-0-Ailerons/X_num_train.npy\n","data/regression-num-medium-0-Ailerons/info.json\n","data/regression-num-medium-0-Ailerons/READY\n","data/regression-num-medium-0-Ailerons/X_num_test.npy\n","data/regression-num-medium-0-Ailerons/Y_test.npy\n","data/regression-num-medium-0-Ailerons/Y_train.npy\n","data/regression-cat-medium-0-house_sales/\n","data/regression-cat-medium-0-house_sales/X_num_val.npy\n","data/regression-cat-medium-0-house_sales/Y_val.npy\n","data/regression-cat-medium-0-house_sales/X_bin_val.npy\n","data/regression-cat-medium-0-house_sales/X_num_train.npy\n","data/regression-cat-medium-0-house_sales/X_bin_train.npy\n","data/regression-cat-medium-0-house_sales/info.json\n","data/regression-cat-medium-0-house_sales/READY\n","data/regression-cat-medium-0-house_sales/X_bin_test.npy\n","data/regression-cat-medium-0-house_sales/X_num_test.npy\n","data/regression-cat-medium-0-house_sales/Y_test.npy\n","data/regression-cat-medium-0-house_sales/Y_train.npy\n","data/classif-cat-medium-2-KDDCup09_upselling/\n","data/classif-cat-medium-2-KDDCup09_upselling/X_cat_val.npy\n","data/classif-cat-medium-2-KDDCup09_upselling/X_num_val.npy\n","data/classif-cat-medium-2-KDDCup09_upselling/Y_val.npy\n","data/classif-cat-medium-2-KDDCup09_upselling/X_bin_val.npy\n","data/classif-cat-medium-2-KDDCup09_upselling/X_num_train.npy\n","data/classif-cat-medium-2-KDDCup09_upselling/X_cat_test.npy\n","data/classif-cat-medium-2-KDDCup09_upselling/X_bin_train.npy\n","data/classif-cat-medium-2-KDDCup09_upselling/X_cat_train.npy\n","data/classif-cat-medium-2-KDDCup09_upselling/info.json\n","data/classif-cat-medium-2-KDDCup09_upselling/READY\n","data/classif-cat-medium-2-KDDCup09_upselling/X_bin_test.npy\n","data/classif-cat-medium-2-KDDCup09_upselling/X_num_test.npy\n","data/classif-cat-medium-2-KDDCup09_upselling/Y_test.npy\n","data/classif-cat-medium-2-KDDCup09_upselling/Y_train.npy\n","data/regression-num-medium-2-isolet/\n","data/regression-num-medium-2-isolet/X_num_val.npy\n","data/regression-num-medium-2-isolet/Y_val.npy\n","data/regression-num-medium-2-isolet/X_num_train.npy\n","data/regression-num-medium-2-isolet/info.json\n","data/regression-num-medium-2-isolet/READY\n","data/regression-num-medium-2-isolet/X_num_test.npy\n","data/regression-num-medium-2-isolet/Y_test.npy\n","data/regression-num-medium-2-isolet/Y_train.npy\n","data/regression-cat-medium-1-Brazilian_houses/\n","data/regression-cat-medium-1-Brazilian_houses/X_cat_val.npy\n","data/regression-cat-medium-1-Brazilian_houses/X_num_val.npy\n","data/regression-cat-medium-1-Brazilian_houses/Y_val.npy\n","data/regression-cat-medium-1-Brazilian_houses/X_bin_val.npy\n","data/regression-cat-medium-1-Brazilian_houses/X_num_train.npy\n","data/regression-cat-medium-1-Brazilian_houses/X_cat_test.npy\n","data/regression-cat-medium-1-Brazilian_houses/X_bin_train.npy\n","data/regression-cat-medium-1-Brazilian_houses/X_cat_train.npy\n","data/regression-cat-medium-1-Brazilian_houses/info.json\n","data/regression-cat-medium-1-Brazilian_houses/READY\n","data/regression-cat-medium-1-Brazilian_houses/X_bin_test.npy\n","data/regression-cat-medium-1-Brazilian_houses/X_num_test.npy\n","data/regression-cat-medium-1-Brazilian_houses/Y_test.npy\n","data/regression-cat-medium-1-Brazilian_houses/Y_train.npy\n","data/regression-num-medium-2-wine_quality/\n","data/regression-num-medium-2-wine_quality/X_num_val.npy\n","data/regression-num-medium-2-wine_quality/Y_val.npy\n","data/regression-num-medium-2-wine_quality/X_num_train.npy\n","data/regression-num-medium-2-wine_quality/info.json\n","data/regression-num-medium-2-wine_quality/READY\n","data/regression-num-medium-2-wine_quality/X_num_test.npy\n","data/regression-num-medium-2-wine_quality/Y_test.npy\n","data/regression-num-medium-2-wine_quality/Y_train.npy\n","data/regression-num-medium-0-california/\n","data/regression-num-medium-0-california/X_num_val.npy\n","data/regression-num-medium-0-california/Y_val.npy\n","data/regression-num-medium-0-california/X_num_train.npy\n","data/regression-num-medium-0-california/info.json\n","data/regression-num-medium-0-california/READY\n","data/regression-num-medium-0-california/X_num_test.npy\n","data/regression-num-medium-0-california/Y_test.npy\n","data/regression-num-medium-0-california/Y_train.npy\n","data/classif-num-medium-2-wine/\n","data/classif-num-medium-2-wine/X_num_val.npy\n","data/classif-num-medium-2-wine/Y_val.npy\n","data/classif-num-medium-2-wine/X_num_train.npy\n","data/classif-num-medium-2-wine/info.json\n","data/classif-num-medium-2-wine/READY\n","data/classif-num-medium-2-wine/X_num_test.npy\n","data/classif-num-medium-2-wine/Y_test.npy\n","data/classif-num-medium-2-wine/Y_train.npy\n","data/classif-num-medium-1-phoneme/\n","data/classif-num-medium-1-phoneme/X_num_val.npy\n","data/classif-num-medium-1-phoneme/Y_val.npy\n","data/classif-num-medium-1-phoneme/X_num_train.npy\n","data/classif-num-medium-1-phoneme/info.json\n","data/classif-num-medium-1-phoneme/READY\n","data/classif-num-medium-1-phoneme/X_num_test.npy\n","data/classif-num-medium-1-phoneme/Y_test.npy\n","data/classif-num-medium-1-phoneme/Y_train.npy\n","data/regression-num-medium-1-isolet/\n","data/regression-num-medium-1-isolet/X_num_val.npy\n","data/regression-num-medium-1-isolet/Y_val.npy\n","data/regression-num-medium-1-isolet/X_num_train.npy\n","data/regression-num-medium-1-isolet/info.json\n","data/regression-num-medium-1-isolet/READY\n","data/regression-num-medium-1-isolet/X_num_test.npy\n","data/regression-num-medium-1-isolet/Y_test.npy\n","data/regression-num-medium-1-isolet/Y_train.npy\n","data/churn/\n","data/churn/X_cat_val.npy\n","data/churn/X_num_val.npy\n","data/churn/Y_val.npy\n","data/churn/X_bin_val.npy\n","data/churn/X_num_train.npy\n","data/churn/X_cat_test.npy\n","data/churn/X_bin_train.npy\n","data/churn/X_cat_train.npy\n","data/churn/info.json\n","data/churn/READY\n","data/churn/X_bin_test.npy\n","data/churn/X_num_test.npy\n","data/churn/Y_test.npy\n","data/churn/Y_train.npy\n","data/regression-num-medium-2-sulfur/\n","data/regression-num-medium-2-sulfur/X_num_val.npy\n","data/regression-num-medium-2-sulfur/Y_val.npy\n","data/regression-num-medium-2-sulfur/X_num_train.npy\n","data/regression-num-medium-2-sulfur/info.json\n","data/regression-num-medium-2-sulfur/READY\n","data/regression-num-medium-2-sulfur/X_num_test.npy\n","data/regression-num-medium-2-sulfur/Y_test.npy\n","data/regression-num-medium-2-sulfur/Y_train.npy\n","data/regression-cat-large-0-diamonds/\n","data/regression-cat-large-0-diamonds/X_cat_val.npy\n","data/regression-cat-large-0-diamonds/X_num_val.npy\n","data/regression-cat-large-0-diamonds/Y_val.npy\n","data/regression-cat-large-0-diamonds/X_num_train.npy\n","data/regression-cat-large-0-diamonds/X_cat_test.npy\n","data/regression-cat-large-0-diamonds/X_cat_train.npy\n","data/regression-cat-large-0-diamonds/info.json\n","data/regression-cat-large-0-diamonds/READY\n","data/regression-cat-large-0-diamonds/X_num_test.npy\n","data/regression-cat-large-0-diamonds/Y_test.npy\n","data/regression-cat-large-0-diamonds/Y_train.npy\n","data/classif-cat-large-0-road-safety/\n","data/classif-cat-large-0-road-safety/X_cat_val.npy\n","data/classif-cat-large-0-road-safety/X_num_val.npy\n","data/classif-cat-large-0-road-safety/Y_val.npy\n","data/classif-cat-large-0-road-safety/X_num_train.npy\n","data/classif-cat-large-0-road-safety/X_cat_test.npy\n","data/classif-cat-large-0-road-safety/X_cat_train.npy\n","data/classif-cat-large-0-road-safety/info.json\n","data/classif-cat-large-0-road-safety/READY\n","data/classif-cat-large-0-road-safety/X_num_test.npy\n","data/classif-cat-large-0-road-safety/Y_test.npy\n","data/classif-cat-large-0-road-safety/Y_train.npy\n","data/classif-num-medium-1-MagicTelescope/\n","data/classif-num-medium-1-MagicTelescope/X_num_val.npy\n","data/classif-num-medium-1-MagicTelescope/Y_val.npy\n","data/classif-num-medium-1-MagicTelescope/X_num_train.npy\n","data/classif-num-medium-1-MagicTelescope/info.json\n","data/classif-num-medium-1-MagicTelescope/READY\n","data/classif-num-medium-1-MagicTelescope/X_num_test.npy\n","data/classif-num-medium-1-MagicTelescope/Y_test.npy\n","data/classif-num-medium-1-MagicTelescope/Y_train.npy\n","data/regression-num-medium-0-wine_quality/\n","data/regression-num-medium-0-wine_quality/X_num_val.npy\n","data/regression-num-medium-0-wine_quality/Y_val.npy\n","data/regression-num-medium-0-wine_quality/X_num_train.npy\n","data/regression-num-medium-0-wine_quality/info.json\n","data/regression-num-medium-0-wine_quality/READY\n","data/regression-num-medium-0-wine_quality/X_num_test.npy\n","data/regression-num-medium-0-wine_quality/Y_test.npy\n","data/regression-num-medium-0-wine_quality/Y_train.npy\n","data/adult/\n","data/adult/X_cat_val.npy\n","data/adult/X_num_val.npy\n","data/adult/Y_val.npy\n","data/adult/X_bin_val.npy\n","data/adult/X_num_train.npy\n","data/adult/X_cat_test.npy\n","data/adult/X_bin_train.npy\n","data/adult/X_cat_train.npy\n","data/adult/info.json\n","data/adult/READY\n","data/adult/X_bin_test.npy\n","data/adult/X_num_test.npy\n","data/adult/Y_test.npy\n","data/adult/Y_train.npy\n","data/classif-num-medium-1-kdd_ipums_la_97-small/\n","data/classif-num-medium-1-kdd_ipums_la_97-small/X_num_val.npy\n","data/classif-num-medium-1-kdd_ipums_la_97-small/Y_val.npy\n","data/classif-num-medium-1-kdd_ipums_la_97-small/X_num_train.npy\n","data/classif-num-medium-1-kdd_ipums_la_97-small/info.json\n","data/classif-num-medium-1-kdd_ipums_la_97-small/READY\n","data/classif-num-medium-1-kdd_ipums_la_97-small/X_num_test.npy\n","data/classif-num-medium-1-kdd_ipums_la_97-small/Y_test.npy\n","data/classif-num-medium-1-kdd_ipums_la_97-small/Y_train.npy\n","data/regression-num-medium-0-superconduct/\n","data/regression-num-medium-0-superconduct/X_num_val.npy\n","data/regression-num-medium-0-superconduct/Y_val.npy\n","data/regression-num-medium-0-superconduct/X_num_train.npy\n","data/regression-num-medium-0-superconduct/info.json\n","data/regression-num-medium-0-superconduct/READY\n","data/regression-num-medium-0-superconduct/X_num_test.npy\n","data/regression-num-medium-0-superconduct/Y_test.npy\n","data/regression-num-medium-0-superconduct/Y_train.npy\n","data/regression-num-medium-0-house_16H/\n","data/regression-num-medium-0-house_16H/X_num_val.npy\n","data/regression-num-medium-0-house_16H/Y_val.npy\n","data/regression-num-medium-0-house_16H/X_num_train.npy\n","data/regression-num-medium-0-house_16H/info.json\n","data/regression-num-medium-0-house_16H/READY\n","data/regression-num-medium-0-house_16H/X_num_test.npy\n","data/regression-num-medium-0-house_16H/Y_test.npy\n","data/regression-num-medium-0-house_16H/Y_train.npy\n","data/weather-big/\n","data/weather-big/X_num_val.npy\n","data/weather-big/Y_val.npy\n","data/weather-big/X_bin_val.npy\n","data/weather-big/X_num_train.npy\n","data/weather-big/X_bin_train.npy\n","data/weather-big/LICENSE.md\n","data/weather-big/info.json\n","data/weather-big/READY\n","data/weather-big/X_bin_test.npy\n","data/weather-big/X_num_test.npy\n","data/weather-big/Y_test.npy\n","data/weather-big/Y_train.npy\n","data/classif-num-large-0-Higgs/\n","data/classif-num-large-0-Higgs/X_num_val.npy\n","data/classif-num-large-0-Higgs/Y_val.npy\n","data/classif-num-large-0-Higgs/X_num_train.npy\n","data/classif-num-large-0-Higgs/info.json\n","data/classif-num-large-0-Higgs/READY\n","data/classif-num-large-0-Higgs/X_num_test.npy\n","data/classif-num-large-0-Higgs/Y_test.npy\n","data/classif-num-large-0-Higgs/Y_train.npy\n","data/regression-cat-medium-2-analcatdata_supreme/\n","data/regression-cat-medium-2-analcatdata_supreme/X_num_val.npy\n","data/regression-cat-medium-2-analcatdata_supreme/Y_val.npy\n","data/regression-cat-medium-2-analcatdata_supreme/X_bin_val.npy\n","data/regression-cat-medium-2-analcatdata_supreme/X_num_train.npy\n","data/regression-cat-medium-2-analcatdata_supreme/X_bin_train.npy\n","data/regression-cat-medium-2-analcatdata_supreme/info.json\n","data/regression-cat-medium-2-analcatdata_supreme/READY\n","data/regression-cat-medium-2-analcatdata_supreme/X_bin_test.npy\n","data/regression-cat-medium-2-analcatdata_supreme/X_num_test.npy\n","data/regression-cat-medium-2-analcatdata_supreme/Y_test.npy\n","data/regression-cat-medium-2-analcatdata_supreme/Y_train.npy\n","data/regression-cat-large-0-black_friday/\n","data/regression-cat-large-0-black_friday/X_cat_val.npy\n","data/regression-cat-large-0-black_friday/X_num_val.npy\n","data/regression-cat-large-0-black_friday/Y_val.npy\n","data/regression-cat-large-0-black_friday/X_bin_val.npy\n","data/regression-cat-large-0-black_friday/X_num_train.npy\n","data/regression-cat-large-0-black_friday/X_cat_test.npy\n","data/regression-cat-large-0-black_friday/X_bin_train.npy\n","data/regression-cat-large-0-black_friday/X_cat_train.npy\n","data/regression-cat-large-0-black_friday/info.json\n","data/regression-cat-large-0-black_friday/READY\n","data/regression-cat-large-0-black_friday/X_bin_test.npy\n","data/regression-cat-large-0-black_friday/X_num_test.npy\n","data/regression-cat-large-0-black_friday/Y_test.npy\n","data/regression-cat-large-0-black_friday/Y_train.npy\n","data/classif-num-medium-1-wine/\n","data/classif-num-medium-1-wine/X_num_val.npy\n","data/classif-num-medium-1-wine/Y_val.npy\n","data/classif-num-medium-1-wine/X_num_train.npy\n","data/classif-num-medium-1-wine/info.json\n","data/classif-num-medium-1-wine/READY\n","data/classif-num-medium-1-wine/X_num_test.npy\n","data/classif-num-medium-1-wine/Y_test.npy\n","data/classif-num-medium-1-wine/Y_train.npy\n","data/regression-cat-medium-0-visualizing_soil/\n","data/regression-cat-medium-0-visualizing_soil/X_num_val.npy\n","data/regression-cat-medium-0-visualizing_soil/Y_val.npy\n","data/regression-cat-medium-0-visualizing_soil/X_bin_val.npy\n","data/regression-cat-medium-0-visualizing_soil/X_num_train.npy\n","data/regression-cat-medium-0-visualizing_soil/X_bin_train.npy\n","data/regression-cat-medium-0-visualizing_soil/info.json\n","data/regression-cat-medium-0-visualizing_soil/READY\n","data/regression-cat-medium-0-visualizing_soil/X_bin_test.npy\n","data/regression-cat-medium-0-visualizing_soil/X_num_test.npy\n","data/regression-cat-medium-0-visualizing_soil/Y_test.npy\n","data/regression-cat-medium-0-visualizing_soil/Y_train.npy\n","data/regression-cat-medium-1-Mercedes_Benz_Greener_Manufacturing/\n","data/regression-cat-medium-1-Mercedes_Benz_Greener_Manufacturing/X_cat_val.npy\n","data/regression-cat-medium-1-Mercedes_Benz_Greener_Manufacturing/Y_val.npy\n","data/regression-cat-medium-1-Mercedes_Benz_Greener_Manufacturing/X_bin_val.npy\n","data/regression-cat-medium-1-Mercedes_Benz_Greener_Manufacturing/X_cat_test.npy\n","data/regression-cat-medium-1-Mercedes_Benz_Greener_Manufacturing/X_bin_train.npy\n","data/regression-cat-medium-1-Mercedes_Benz_Greener_Manufacturing/X_cat_train.npy\n","data/regression-cat-medium-1-Mercedes_Benz_Greener_Manufacturing/info.json\n","data/regression-cat-medium-1-Mercedes_Benz_Greener_Manufacturing/READY\n","data/regression-cat-medium-1-Mercedes_Benz_Greener_Manufacturing/X_bin_test.npy\n","data/regression-cat-medium-1-Mercedes_Benz_Greener_Manufacturing/Y_test.npy\n","data/regression-cat-medium-1-Mercedes_Benz_Greener_Manufacturing/Y_train.npy\n","data/classif-num-medium-0-kdd_ipums_la_97-small/\n","data/classif-num-medium-0-kdd_ipums_la_97-small/X_num_val.npy\n","data/classif-num-medium-0-kdd_ipums_la_97-small/Y_val.npy\n","data/classif-num-medium-0-kdd_ipums_la_97-small/X_num_train.npy\n","data/classif-num-medium-0-kdd_ipums_la_97-small/info.json\n","data/classif-num-medium-0-kdd_ipums_la_97-small/READY\n","data/classif-num-medium-0-kdd_ipums_la_97-small/X_num_test.npy\n","data/classif-num-medium-0-kdd_ipums_la_97-small/Y_test.npy\n","data/classif-num-medium-0-kdd_ipums_la_97-small/Y_train.npy\n","data/regression-num-medium-1-MiamiHousing2016/\n","data/regression-num-medium-1-MiamiHousing2016/X_num_val.npy\n","data/regression-num-medium-1-MiamiHousing2016/Y_val.npy\n","data/regression-num-medium-1-MiamiHousing2016/X_num_train.npy\n","data/regression-num-medium-1-MiamiHousing2016/info.json\n","data/regression-num-medium-1-MiamiHousing2016/READY\n","data/regression-num-medium-1-MiamiHousing2016/X_num_test.npy\n","data/regression-num-medium-1-MiamiHousing2016/Y_test.npy\n","data/regression-num-medium-1-MiamiHousing2016/Y_train.npy\n","data/regression-cat-medium-0-OnlineNewsPopularity/\n","data/regression-cat-medium-0-OnlineNewsPopularity/X_num_val.npy\n","data/regression-cat-medium-0-OnlineNewsPopularity/Y_val.npy\n","data/regression-cat-medium-0-OnlineNewsPopularity/X_bin_val.npy\n","data/regression-cat-medium-0-OnlineNewsPopularity/X_num_train.npy\n","data/regression-cat-medium-0-OnlineNewsPopularity/X_bin_train.npy\n","data/regression-cat-medium-0-OnlineNewsPopularity/info.json\n","data/regression-cat-medium-0-OnlineNewsPopularity/READY\n","data/regression-cat-medium-0-OnlineNewsPopularity/X_bin_test.npy\n","data/regression-cat-medium-0-OnlineNewsPopularity/X_num_test.npy\n","data/regression-cat-medium-0-OnlineNewsPopularity/Y_test.npy\n","data/regression-cat-medium-0-OnlineNewsPopularity/Y_train.npy\n","data/regression-num-medium-1-elevators/\n","data/regression-num-medium-1-elevators/X_num_val.npy\n","data/regression-num-medium-1-elevators/Y_val.npy\n","data/regression-num-medium-1-elevators/X_num_train.npy\n","data/regression-num-medium-1-elevators/info.json\n","data/regression-num-medium-1-elevators/READY\n","data/regression-num-medium-1-elevators/X_num_test.npy\n","data/regression-num-medium-1-elevators/Y_test.npy\n","data/regression-num-medium-1-elevators/Y_train.npy\n","data/regression-num-medium-0-pol/\n","data/regression-num-medium-0-pol/X_num_val.npy\n","data/regression-num-medium-0-pol/Y_val.npy\n","data/regression-num-medium-0-pol/X_num_train.npy\n","data/regression-num-medium-0-pol/info.json\n","data/regression-num-medium-0-pol/READY\n","data/regression-num-medium-0-pol/X_num_test.npy\n","data/regression-num-medium-0-pol/Y_test.npy\n","data/regression-num-medium-0-pol/Y_train.npy\n","data/classif-num-medium-2-kdd_ipums_la_97-small/\n","data/classif-num-medium-2-kdd_ipums_la_97-small/X_num_val.npy\n","data/classif-num-medium-2-kdd_ipums_la_97-small/Y_val.npy\n","data/classif-num-medium-2-kdd_ipums_la_97-small/X_num_train.npy\n","data/classif-num-medium-2-kdd_ipums_la_97-small/info.json\n","data/classif-num-medium-2-kdd_ipums_la_97-small/READY\n","data/classif-num-medium-2-kdd_ipums_la_97-small/X_num_test.npy\n","data/classif-num-medium-2-kdd_ipums_la_97-small/Y_test.npy\n","data/classif-num-medium-2-kdd_ipums_la_97-small/Y_train.npy\n","data/classif-num-medium-0-phoneme/\n","data/classif-num-medium-0-phoneme/X_num_val.npy\n","data/classif-num-medium-0-phoneme/Y_val.npy\n","data/classif-num-medium-0-phoneme/X_num_train.npy\n","data/classif-num-medium-0-phoneme/info.json\n","data/classif-num-medium-0-phoneme/READY\n","data/classif-num-medium-0-phoneme/X_num_test.npy\n","data/classif-num-medium-0-phoneme/Y_test.npy\n","data/classif-num-medium-0-phoneme/Y_train.npy\n","data/regression-num-medium-0-sulfur/\n","data/regression-num-medium-0-sulfur/X_num_val.npy\n","data/regression-num-medium-0-sulfur/Y_val.npy\n","data/regression-num-medium-0-sulfur/X_num_train.npy\n","data/regression-num-medium-0-sulfur/info.json\n","data/regression-num-medium-0-sulfur/READY\n","data/regression-num-medium-0-sulfur/X_num_test.npy\n","data/regression-num-medium-0-sulfur/Y_test.npy\n","data/regression-num-medium-0-sulfur/Y_train.npy\n","data/regression-cat-medium-0-analcatdata_supreme/\n","data/regression-cat-medium-0-analcatdata_supreme/X_num_val.npy\n","data/regression-cat-medium-0-analcatdata_supreme/Y_val.npy\n","data/regression-cat-medium-0-analcatdata_supreme/X_bin_val.npy\n","data/regression-cat-medium-0-analcatdata_supreme/X_num_train.npy\n","data/regression-cat-medium-0-analcatdata_supreme/X_bin_train.npy\n","data/regression-cat-medium-0-analcatdata_supreme/info.json\n","data/regression-cat-medium-0-analcatdata_supreme/READY\n","data/regression-cat-medium-0-analcatdata_supreme/X_bin_test.npy\n","data/regression-cat-medium-0-analcatdata_supreme/X_num_test.npy\n","data/regression-cat-medium-0-analcatdata_supreme/Y_test.npy\n","data/regression-cat-medium-0-analcatdata_supreme/Y_train.npy\n","data/classif-num-medium-2-phoneme/\n","data/classif-num-medium-2-phoneme/X_num_val.npy\n","data/classif-num-medium-2-phoneme/Y_val.npy\n","data/classif-num-medium-2-phoneme/X_num_train.npy\n","data/classif-num-medium-2-phoneme/info.json\n","data/classif-num-medium-2-phoneme/READY\n","data/classif-num-medium-2-phoneme/X_num_test.npy\n","data/classif-num-medium-2-phoneme/Y_test.npy\n","data/classif-num-medium-2-phoneme/Y_train.npy\n","data/regression-cat-large-0-SGEMM_GPU_kernel_performance/\n","data/regression-cat-large-0-SGEMM_GPU_kernel_performance/X_num_val.npy\n","data/regression-cat-large-0-SGEMM_GPU_kernel_performance/Y_val.npy\n","data/regression-cat-large-0-SGEMM_GPU_kernel_performance/X_bin_val.npy\n","data/regression-cat-large-0-SGEMM_GPU_kernel_performance/X_num_train.npy\n","data/regression-cat-large-0-SGEMM_GPU_kernel_performance/X_bin_train.npy\n","data/regression-cat-large-0-SGEMM_GPU_kernel_performance/info.json\n","data/regression-cat-large-0-SGEMM_GPU_kernel_performance/READY\n","data/regression-cat-large-0-SGEMM_GPU_kernel_performance/X_bin_test.npy\n","data/regression-cat-large-0-SGEMM_GPU_kernel_performance/X_num_test.npy\n","data/regression-cat-large-0-SGEMM_GPU_kernel_performance/Y_test.npy\n","data/regression-cat-large-0-SGEMM_GPU_kernel_performance/Y_train.npy\n","data/regression-num-medium-1-wine_quality/\n","data/regression-num-medium-1-wine_quality/X_num_val.npy\n","data/regression-num-medium-1-wine_quality/Y_val.npy\n","data/regression-num-medium-1-wine_quality/X_num_train.npy\n","data/regression-num-medium-1-wine_quality/info.json\n","data/regression-num-medium-1-wine_quality/READY\n","data/regression-num-medium-1-wine_quality/X_num_test.npy\n","data/regression-num-medium-1-wine_quality/Y_test.npy\n","data/regression-num-medium-1-wine_quality/Y_train.npy\n","data/regression-num-medium-0-cpu_act/\n","data/regression-num-medium-0-cpu_act/X_num_val.npy\n","data/regression-num-medium-0-cpu_act/Y_val.npy\n","data/regression-num-medium-0-cpu_act/X_num_train.npy\n","data/regression-num-medium-0-cpu_act/info.json\n","data/regression-num-medium-0-cpu_act/READY\n","data/regression-num-medium-0-cpu_act/X_num_test.npy\n","data/regression-num-medium-0-cpu_act/Y_test.npy\n","data/regression-num-medium-0-cpu_act/Y_train.npy\n","data/regression-cat-medium-0-Bike_Sharing_Demand/\n","data/regression-cat-medium-0-Bike_Sharing_Demand/X_cat_val.npy\n","data/regression-cat-medium-0-Bike_Sharing_Demand/X_num_val.npy\n","data/regression-cat-medium-0-Bike_Sharing_Demand/Y_val.npy\n","data/regression-cat-medium-0-Bike_Sharing_Demand/X_bin_val.npy\n","data/regression-cat-medium-0-Bike_Sharing_Demand/X_num_train.npy\n","data/regression-cat-medium-0-Bike_Sharing_Demand/X_cat_test.npy\n","data/regression-cat-medium-0-Bike_Sharing_Demand/X_bin_train.npy\n","data/regression-cat-medium-0-Bike_Sharing_Demand/X_cat_train.npy\n","data/regression-cat-medium-0-Bike_Sharing_Demand/info.json\n","data/regression-cat-medium-0-Bike_Sharing_Demand/READY\n","data/regression-cat-medium-0-Bike_Sharing_Demand/X_bin_test.npy\n","data/regression-cat-medium-0-Bike_Sharing_Demand/X_num_test.npy\n","data/regression-cat-medium-0-Bike_Sharing_Demand/Y_test.npy\n","data/regression-cat-medium-0-Bike_Sharing_Demand/Y_train.npy\n","data/regression-cat-medium-1-visualizing_soil/\n","data/regression-cat-medium-1-visualizing_soil/X_num_val.npy\n","data/regression-cat-medium-1-visualizing_soil/Y_val.npy\n","data/regression-cat-medium-1-visualizing_soil/X_bin_val.npy\n","data/regression-cat-medium-1-visualizing_soil/X_num_train.npy\n","data/regression-cat-medium-1-visualizing_soil/X_bin_train.npy\n","data/regression-cat-medium-1-visualizing_soil/info.json\n","data/regression-cat-medium-1-visualizing_soil/READY\n","data/regression-cat-medium-1-visualizing_soil/X_bin_test.npy\n","data/regression-cat-medium-1-visualizing_soil/X_num_test.npy\n","data/regression-cat-medium-1-visualizing_soil/Y_test.npy\n","data/regression-cat-medium-1-visualizing_soil/Y_train.npy\n","data/classif-num-medium-4-phoneme/\n","data/classif-num-medium-4-phoneme/X_num_val.npy\n","data/classif-num-medium-4-phoneme/Y_val.npy\n","data/classif-num-medium-4-phoneme/X_num_train.npy\n","data/classif-num-medium-4-phoneme/info.json\n","data/classif-num-medium-4-phoneme/READY\n","data/classif-num-medium-4-phoneme/X_num_test.npy\n","data/classif-num-medium-4-phoneme/Y_test.npy\n","data/classif-num-medium-4-phoneme/Y_train.npy\n","data/house/\n","data/house/X_num_val.npy\n","data/house/Y_val.npy\n","data/house/X_num_train.npy\n","data/house/info.json\n","data/house/READY\n","data/house/X_num_test.npy\n","data/house/Y_test.npy\n","data/house/Y_train.npy\n","data/regression-cat-medium-2-Brazilian_houses/\n","data/regression-cat-medium-2-Brazilian_houses/X_cat_val.npy\n","data/regression-cat-medium-2-Brazilian_houses/X_num_val.npy\n","data/regression-cat-medium-2-Brazilian_houses/Y_val.npy\n","data/regression-cat-medium-2-Brazilian_houses/X_bin_val.npy\n","data/regression-cat-medium-2-Brazilian_houses/X_num_train.npy\n","data/regression-cat-medium-2-Brazilian_houses/X_cat_test.npy\n","data/regression-cat-medium-2-Brazilian_houses/X_bin_train.npy\n","data/regression-cat-medium-2-Brazilian_houses/X_cat_train.npy\n","data/regression-cat-medium-2-Brazilian_houses/info.json\n","data/regression-cat-medium-2-Brazilian_houses/READY\n","data/regression-cat-medium-2-Brazilian_houses/X_bin_test.npy\n","data/regression-cat-medium-2-Brazilian_houses/X_num_test.npy\n","data/regression-cat-medium-2-Brazilian_houses/Y_test.npy\n","data/regression-cat-medium-2-Brazilian_houses/Y_train.npy\n","data/regression-cat-large-0-particulate-matter-ukair-2017/\n","data/regression-cat-large-0-particulate-matter-ukair-2017/X_cat_val.npy\n","data/regression-cat-large-0-particulate-matter-ukair-2017/X_num_val.npy\n","data/regression-cat-large-0-particulate-matter-ukair-2017/Y_val.npy\n","data/regression-cat-large-0-particulate-matter-ukair-2017/X_num_train.npy\n","data/regression-cat-large-0-particulate-matter-ukair-2017/X_cat_test.npy\n","data/regression-cat-large-0-particulate-matter-ukair-2017/X_cat_train.npy\n","data/regression-cat-large-0-particulate-matter-ukair-2017/info.json\n","data/regression-cat-large-0-particulate-matter-ukair-2017/READY\n","data/regression-cat-large-0-particulate-matter-ukair-2017/X_num_test.npy\n","data/regression-cat-large-0-particulate-matter-ukair-2017/Y_test.npy\n","data/regression-cat-large-0-particulate-matter-ukair-2017/Y_train.npy\n","data/regression-cat-medium-2-Mercedes_Benz_Greener_Manufacturing/\n","data/regression-cat-medium-2-Mercedes_Benz_Greener_Manufacturing/X_cat_val.npy\n","data/regression-cat-medium-2-Mercedes_Benz_Greener_Manufacturing/Y_val.npy\n","data/regression-cat-medium-2-Mercedes_Benz_Greener_Manufacturing/X_bin_val.npy\n","data/regression-cat-medium-2-Mercedes_Benz_Greener_Manufacturing/X_cat_test.npy\n","data/regression-cat-medium-2-Mercedes_Benz_Greener_Manufacturing/X_bin_train.npy\n","data/regression-cat-medium-2-Mercedes_Benz_Greener_Manufacturing/X_cat_train.npy\n","data/regression-cat-medium-2-Mercedes_Benz_Greener_Manufacturing/info.json\n","data/regression-cat-medium-2-Mercedes_Benz_Greener_Manufacturing/READY\n","data/regression-cat-medium-2-Mercedes_Benz_Greener_Manufacturing/X_bin_test.npy\n","data/regression-cat-medium-2-Mercedes_Benz_Greener_Manufacturing/Y_test.npy\n","data/regression-cat-medium-2-Mercedes_Benz_Greener_Manufacturing/Y_train.npy\n","data/black-friday/\n","data/black-friday/X_cat_val.npy\n","data/black-friday/X_num_val.npy\n","data/black-friday/Y_val.npy\n","data/black-friday/X_bin_val.npy\n","data/black-friday/X_num_train.npy\n","data/black-friday/X_cat_test.npy\n","data/black-friday/X_bin_train.npy\n","data/black-friday/X_cat_train.npy\n","data/black-friday/info.json\n","data/black-friday/X_bin_test.npy\n","data/black-friday/X_num_test.npy\n","data/black-friday/Y_test.npy\n","data/black-friday/Y_train.npy\n","data/regression-num-medium-1-sulfur/\n","data/regression-num-medium-1-sulfur/X_num_val.npy\n","data/regression-num-medium-1-sulfur/Y_val.npy\n","data/regression-num-medium-1-sulfur/X_num_train.npy\n","data/regression-num-medium-1-sulfur/info.json\n","data/regression-num-medium-1-sulfur/READY\n","data/regression-num-medium-1-sulfur/X_num_test.npy\n","data/regression-num-medium-1-sulfur/Y_test.npy\n","data/regression-num-medium-1-sulfur/Y_train.npy\n","data/classif-num-medium-0-wine/\n","data/classif-num-medium-0-wine/X_num_val.npy\n","data/classif-num-medium-0-wine/Y_val.npy\n","data/classif-num-medium-0-wine/X_num_train.npy\n","data/classif-num-medium-0-wine/info.json\n","data/classif-num-medium-0-wine/READY\n","data/classif-num-medium-0-wine/X_num_test.npy\n","data/classif-num-medium-0-wine/Y_test.npy\n","data/classif-num-medium-0-wine/Y_train.npy\n","data/covtype/\n","data/covtype/X_num_val.npy\n","data/covtype/Y_val.npy\n","data/covtype/X_bin_val.npy\n","data/covtype/X_num_train.npy\n","data/covtype/X_bin_train.npy\n","data/covtype/info.json\n","data/covtype/READY\n","data/covtype/X_bin_test.npy\n","data/covtype/X_num_test.npy\n","data/covtype/Y_test.npy\n","data/covtype/Y_train.npy\n","data/regression-cat-large-0-nyc-taxi-green-dec-2016/\n","data/regression-cat-large-0-nyc-taxi-green-dec-2016/X_cat_val.npy\n","data/regression-cat-large-0-nyc-taxi-green-dec-2016/X_num_val.npy\n","data/regression-cat-large-0-nyc-taxi-green-dec-2016/Y_val.npy\n","data/regression-cat-large-0-nyc-taxi-green-dec-2016/X_bin_val.npy\n","data/regression-cat-large-0-nyc-taxi-green-dec-2016/X_num_train.npy\n","data/regression-cat-large-0-nyc-taxi-green-dec-2016/X_cat_test.npy\n","data/regression-cat-large-0-nyc-taxi-green-dec-2016/X_bin_train.npy\n","data/regression-cat-large-0-nyc-taxi-green-dec-2016/X_cat_train.npy\n","data/regression-cat-large-0-nyc-taxi-green-dec-2016/info.json\n","data/regression-cat-large-0-nyc-taxi-green-dec-2016/READY\n","data/regression-cat-large-0-nyc-taxi-green-dec-2016/X_bin_test.npy\n","data/regression-cat-large-0-nyc-taxi-green-dec-2016/X_num_test.npy\n","data/regression-cat-large-0-nyc-taxi-green-dec-2016/Y_test.npy\n","data/regression-cat-large-0-nyc-taxi-green-dec-2016/Y_train.npy\n","data/classif-num-medium-0-MagicTelescope/\n","data/classif-num-medium-0-MagicTelescope/X_num_val.npy\n","data/classif-num-medium-0-MagicTelescope/Y_val.npy\n","data/classif-num-medium-0-MagicTelescope/X_num_train.npy\n","data/classif-num-medium-0-MagicTelescope/info.json\n","data/classif-num-medium-0-MagicTelescope/READY\n","data/classif-num-medium-0-MagicTelescope/X_num_test.npy\n","data/classif-num-medium-0-MagicTelescope/Y_test.npy\n","data/classif-num-medium-0-MagicTelescope/Y_train.npy\n","data/regression-cat-medium-3-analcatdata_supreme/\n","data/regression-cat-medium-3-analcatdata_supreme/X_num_val.npy\n","data/regression-cat-medium-3-analcatdata_supreme/Y_val.npy\n","data/regression-cat-medium-3-analcatdata_supreme/X_bin_val.npy\n","data/regression-cat-medium-3-analcatdata_supreme/X_num_train.npy\n","data/regression-cat-medium-3-analcatdata_supreme/X_bin_train.npy\n","data/regression-cat-medium-3-analcatdata_supreme/info.json\n","data/regression-cat-medium-3-analcatdata_supreme/READY\n","data/regression-cat-medium-3-analcatdata_supreme/X_bin_test.npy\n","data/regression-cat-medium-3-analcatdata_supreme/X_num_test.npy\n","data/regression-cat-medium-3-analcatdata_supreme/Y_test.npy\n","data/regression-cat-medium-3-analcatdata_supreme/Y_train.npy\n","data/regression-cat-medium-0-Mercedes_Benz_Greener_Manufacturing/\n","data/regression-cat-medium-0-Mercedes_Benz_Greener_Manufacturing/X_cat_val.npy\n","data/regression-cat-medium-0-Mercedes_Benz_Greener_Manufacturing/Y_val.npy\n","data/regression-cat-medium-0-Mercedes_Benz_Greener_Manufacturing/X_bin_val.npy\n","data/regression-cat-medium-0-Mercedes_Benz_Greener_Manufacturing/X_cat_test.npy\n","data/regression-cat-medium-0-Mercedes_Benz_Greener_Manufacturing/X_bin_train.npy\n","data/regression-cat-medium-0-Mercedes_Benz_Greener_Manufacturing/X_cat_train.npy\n","data/regression-cat-medium-0-Mercedes_Benz_Greener_Manufacturing/info.json\n","data/regression-cat-medium-0-Mercedes_Benz_Greener_Manufacturing/READY\n","data/regression-cat-medium-0-Mercedes_Benz_Greener_Manufacturing/X_bin_test.npy\n","data/regression-cat-medium-0-Mercedes_Benz_Greener_Manufacturing/Y_test.npy\n","data/regression-cat-medium-0-Mercedes_Benz_Greener_Manufacturing/Y_train.npy\n","data/microsoft/\n","data/microsoft/X_num_val.npy\n","data/microsoft/Y_val.npy\n","data/microsoft/X_bin_val.npy\n","data/microsoft/X_num_train.npy\n","data/microsoft/X_bin_train.npy\n","data/microsoft/info.json\n","data/microsoft/READY\n","data/microsoft/X_bin_test.npy\n","data/microsoft/X_num_test.npy\n","data/microsoft/Y_test.npy\n","data/microsoft/Y_train.npy\n","data/regression-cat-medium-4-analcatdata_supreme/\n","data/regression-cat-medium-4-analcatdata_supreme/X_num_val.npy\n","data/regression-cat-medium-4-analcatdata_supreme/Y_val.npy\n","data/regression-cat-medium-4-analcatdata_supreme/X_bin_val.npy\n","data/regression-cat-medium-4-analcatdata_supreme/X_num_train.npy\n","data/regression-cat-medium-4-analcatdata_supreme/X_bin_train.npy\n","data/regression-cat-medium-4-analcatdata_supreme/info.json\n","data/regression-cat-medium-4-analcatdata_supreme/READY\n","data/regression-cat-medium-4-analcatdata_supreme/X_bin_test.npy\n","data/regression-cat-medium-4-analcatdata_supreme/X_num_test.npy\n","data/regression-cat-medium-4-analcatdata_supreme/Y_test.npy\n","data/regression-cat-medium-4-analcatdata_supreme/Y_train.npy\n","data/regression-num-medium-1-fifa/\n","data/regression-num-medium-1-fifa/X_num_val.npy\n","data/regression-num-medium-1-fifa/Y_val.npy\n","data/regression-num-medium-1-fifa/X_num_train.npy\n","data/regression-num-medium-1-fifa/info.json\n","data/regression-num-medium-1-fifa/READY\n","data/regression-num-medium-1-fifa/X_num_test.npy\n","data/regression-num-medium-1-fifa/Y_test.npy\n","data/regression-num-medium-1-fifa/Y_train.npy\n","data/regression-num-medium-0-isolet/\n","data/regression-num-medium-0-isolet/X_num_val.npy\n","data/regression-num-medium-0-isolet/Y_val.npy\n","data/regression-num-medium-0-isolet/X_num_train.npy\n","data/regression-num-medium-0-isolet/info.json\n","data/regression-num-medium-0-isolet/READY\n","data/regression-num-medium-0-isolet/X_num_test.npy\n","data/regression-num-medium-0-isolet/Y_test.npy\n","data/regression-num-medium-0-isolet/Y_train.npy\n","data/classif-num-medium-3-phoneme/\n","data/classif-num-medium-3-phoneme/X_num_val.npy\n","data/classif-num-medium-3-phoneme/Y_val.npy\n","data/classif-num-medium-3-phoneme/X_num_train.npy\n","data/classif-num-medium-3-phoneme/info.json\n","data/classif-num-medium-3-phoneme/READY\n","data/classif-num-medium-3-phoneme/X_num_test.npy\n","data/classif-num-medium-3-phoneme/Y_test.npy\n","data/classif-num-medium-3-phoneme/Y_train.npy\n","data/regression-cat-medium-3-Mercedes_Benz_Greener_Manufacturing/\n","data/regression-cat-medium-3-Mercedes_Benz_Greener_Manufacturing/X_cat_val.npy\n","data/regression-cat-medium-3-Mercedes_Benz_Greener_Manufacturing/Y_val.npy\n","data/regression-cat-medium-3-Mercedes_Benz_Greener_Manufacturing/X_bin_val.npy\n","data/regression-cat-medium-3-Mercedes_Benz_Greener_Manufacturing/X_cat_test.npy\n","data/regression-cat-medium-3-Mercedes_Benz_Greener_Manufacturing/X_bin_train.npy\n","data/regression-cat-medium-3-Mercedes_Benz_Greener_Manufacturing/X_cat_train.npy\n","data/regression-cat-medium-3-Mercedes_Benz_Greener_Manufacturing/info.json\n","data/regression-cat-medium-3-Mercedes_Benz_Greener_Manufacturing/READY\n","data/regression-cat-medium-3-Mercedes_Benz_Greener_Manufacturing/X_bin_test.npy\n","data/regression-cat-medium-3-Mercedes_Benz_Greener_Manufacturing/Y_test.npy\n","data/regression-cat-medium-3-Mercedes_Benz_Greener_Manufacturing/Y_train.npy\n","data/california/\n","data/california/X_num_val.npy\n","data/california/Y_val.npy\n","data/california/X_num_train.npy\n","data/california/info.json\n","data/california/READY\n","data/california/X_num_test.npy\n","data/california/Y_test.npy\n","data/california/Y_train.npy\n","data/classif-cat-medium-2-rl/\n","data/classif-cat-medium-2-rl/X_cat_val.npy\n","data/classif-cat-medium-2-rl/X_num_val.npy\n","data/classif-cat-medium-2-rl/Y_val.npy\n","data/classif-cat-medium-2-rl/X_bin_val.npy\n","data/classif-cat-medium-2-rl/X_num_train.npy\n","data/classif-cat-medium-2-rl/X_cat_test.npy\n","data/classif-cat-medium-2-rl/X_bin_train.npy\n","data/classif-cat-medium-2-rl/X_cat_train.npy\n","data/classif-cat-medium-2-rl/info.json\n","data/classif-cat-medium-2-rl/READY\n","data/classif-cat-medium-2-rl/X_bin_test.npy\n","data/classif-cat-medium-2-rl/X_num_test.npy\n","data/classif-cat-medium-2-rl/Y_test.npy\n","data/classif-cat-medium-2-rl/Y_train.npy\n","data/regression-cat-medium-0-Brazilian_houses/\n","data/regression-cat-medium-0-Brazilian_houses/X_cat_val.npy\n","data/regression-cat-medium-0-Brazilian_houses/X_num_val.npy\n","data/regression-cat-medium-0-Brazilian_houses/Y_val.npy\n","data/regression-cat-medium-0-Brazilian_houses/X_bin_val.npy\n","data/regression-cat-medium-0-Brazilian_houses/X_num_train.npy\n","data/regression-cat-medium-0-Brazilian_houses/X_cat_test.npy\n","data/regression-cat-medium-0-Brazilian_houses/X_bin_train.npy\n","data/regression-cat-medium-0-Brazilian_houses/X_cat_train.npy\n","data/regression-cat-medium-0-Brazilian_houses/info.json\n","data/regression-cat-medium-0-Brazilian_houses/READY\n","data/regression-cat-medium-0-Brazilian_houses/X_bin_test.npy\n","data/regression-cat-medium-0-Brazilian_houses/X_num_test.npy\n","data/regression-cat-medium-0-Brazilian_houses/Y_test.npy\n","data/regression-cat-medium-0-Brazilian_houses/Y_train.npy\n","data/regression-cat-medium-1-analcatdata_supreme/\n","data/regression-cat-medium-1-analcatdata_supreme/X_num_val.npy\n","data/regression-cat-medium-1-analcatdata_supreme/Y_val.npy\n","data/regression-cat-medium-1-analcatdata_supreme/X_bin_val.npy\n","data/regression-cat-medium-1-analcatdata_supreme/X_num_train.npy\n","data/regression-cat-medium-1-analcatdata_supreme/X_bin_train.npy\n","data/regression-cat-medium-1-analcatdata_supreme/info.json\n","data/regression-cat-medium-1-analcatdata_supreme/READY\n","data/regression-cat-medium-1-analcatdata_supreme/X_bin_test.npy\n","data/regression-cat-medium-1-analcatdata_supreme/X_num_test.npy\n","data/regression-cat-medium-1-analcatdata_supreme/Y_test.npy\n","data/regression-cat-medium-1-analcatdata_supreme/Y_train.npy\n","data/classif-num-medium-2-MagicTelescope/\n","data/classif-num-medium-2-MagicTelescope/X_num_val.npy\n","data/classif-num-medium-2-MagicTelescope/Y_val.npy\n","data/classif-num-medium-2-MagicTelescope/X_num_train.npy\n","data/classif-num-medium-2-MagicTelescope/info.json\n","data/classif-num-medium-2-MagicTelescope/READY\n","data/classif-num-medium-2-MagicTelescope/X_num_test.npy\n","data/classif-num-medium-2-MagicTelescope/Y_test.npy\n","data/classif-num-medium-2-MagicTelescope/Y_train.npy\n","data/classif-cat-medium-1-rl/\n","data/classif-cat-medium-1-rl/X_cat_val.npy\n","data/classif-cat-medium-1-rl/X_num_val.npy\n","data/classif-cat-medium-1-rl/Y_val.npy\n","data/classif-cat-medium-1-rl/X_bin_val.npy\n","data/classif-cat-medium-1-rl/X_num_train.npy\n","data/classif-cat-medium-1-rl/X_cat_test.npy\n","data/classif-cat-medium-1-rl/X_bin_train.npy\n","data/classif-cat-medium-1-rl/X_cat_train.npy\n","data/classif-cat-medium-1-rl/info.json\n","data/classif-cat-medium-1-rl/READY\n","data/classif-cat-medium-1-rl/X_bin_test.npy\n","data/classif-cat-medium-1-rl/X_num_test.npy\n","data/classif-cat-medium-1-rl/Y_test.npy\n","data/classif-cat-medium-1-rl/Y_train.npy\n","data/classif-cat-medium-0-compass/\n","data/classif-cat-medium-0-compass/X_cat_val.npy\n","data/classif-cat-medium-0-compass/X_num_val.npy\n","data/classif-cat-medium-0-compass/Y_val.npy\n","data/classif-cat-medium-0-compass/X_bin_val.npy\n","data/classif-cat-medium-0-compass/X_num_train.npy\n","data/classif-cat-medium-0-compass/X_cat_test.npy\n","data/classif-cat-medium-0-compass/X_bin_train.npy\n","data/classif-cat-medium-0-compass/X_cat_train.npy\n","data/classif-cat-medium-0-compass/info.json\n","data/classif-cat-medium-0-compass/READY\n","data/classif-cat-medium-0-compass/X_bin_test.npy\n","data/classif-cat-medium-0-compass/X_num_test.npy\n","data/classif-cat-medium-0-compass/Y_test.npy\n","data/classif-cat-medium-0-compass/Y_train.npy\n","data/regression-cat-medium-2-yprop_4_1/\n","data/regression-cat-medium-2-yprop_4_1/X_num_val.npy\n","data/regression-cat-medium-2-yprop_4_1/Y_val.npy\n","data/regression-cat-medium-2-yprop_4_1/X_bin_val.npy\n","data/regression-cat-medium-2-yprop_4_1/X_num_train.npy\n","data/regression-cat-medium-2-yprop_4_1/X_bin_train.npy\n","data/regression-cat-medium-2-yprop_4_1/info.json\n","data/regression-cat-medium-2-yprop_4_1/READY\n","data/regression-cat-medium-2-yprop_4_1/X_bin_test.npy\n","data/regression-cat-medium-2-yprop_4_1/X_num_test.npy\n","data/regression-cat-medium-2-yprop_4_1/Y_test.npy\n","data/regression-cat-medium-2-yprop_4_1/Y_train.npy\n","data/weather-small/\n","data/weather-small/X_num_val.npy\n","data/weather-small/Y_val.npy\n","data/weather-small/X_bin_val.npy\n","data/weather-small/X_num_train.npy\n","data/weather-small/X_bin_train.npy\n","data/weather-small/info.json\n","data/weather-small/READY\n","data/weather-small/X_bin_test.npy\n","data/weather-small/X_num_test.npy\n","data/weather-small/Y_test.npy\n","data/weather-small/Y_train.npy\n","data/diamond/\n","data/diamond/X_cat_val.npy\n","data/diamond/X_num_val.npy\n","data/diamond/Y_val.npy\n","data/diamond/X_num_train.npy\n","data/diamond/X_cat_test.npy\n","data/diamond/X_cat_train.npy\n","data/diamond/info.json\n","data/diamond/X_num_test.npy\n","data/diamond/Y_test.npy\n","data/diamond/Y_train.npy\n","data/regression-num-medium-0-fifa/\n","data/regression-num-medium-0-fifa/X_num_val.npy\n","data/regression-num-medium-0-fifa/Y_val.npy\n","data/regression-num-medium-0-fifa/X_num_train.npy\n","data/regression-num-medium-0-fifa/info.json\n","data/regression-num-medium-0-fifa/READY\n","data/regression-num-medium-0-fifa/X_num_test.npy\n","data/regression-num-medium-0-fifa/Y_test.npy\n","data/regression-num-medium-0-fifa/Y_train.npy\n","data/regression-num-medium-1-cpu_act/\n","data/regression-num-medium-1-cpu_act/X_num_val.npy\n","data/regression-num-medium-1-cpu_act/Y_val.npy\n","data/regression-num-medium-1-cpu_act/X_num_train.npy\n","data/regression-num-medium-1-cpu_act/info.json\n","data/regression-num-medium-1-cpu_act/READY\n","data/regression-num-medium-1-cpu_act/X_num_test.npy\n","data/regression-num-medium-1-cpu_act/Y_test.npy\n","data/regression-num-medium-1-cpu_act/Y_train.npy\n","data/regression-num-medium-1-pol/\n","data/regression-num-medium-1-pol/X_num_val.npy\n","data/regression-num-medium-1-pol/Y_val.npy\n","data/regression-num-medium-1-pol/X_num_train.npy\n","data/regression-num-medium-1-pol/info.json\n","data/regression-num-medium-1-pol/READY\n","data/regression-num-medium-1-pol/X_num_test.npy\n","data/regression-num-medium-1-pol/Y_test.npy\n","data/regression-num-medium-1-pol/Y_train.npy\n","data/regression-num-medium-0-elevators/\n","data/regression-num-medium-0-elevators/X_num_val.npy\n","data/regression-num-medium-0-elevators/Y_val.npy\n","data/regression-num-medium-0-elevators/X_num_train.npy\n","data/regression-num-medium-0-elevators/info.json\n","data/regression-num-medium-0-elevators/READY\n","data/regression-num-medium-0-elevators/X_num_test.npy\n","data/regression-num-medium-0-elevators/Y_test.npy\n","data/regression-num-medium-0-elevators/Y_train.npy\n","data/regression-cat-medium-4-Mercedes_Benz_Greener_Manufacturing/\n","data/regression-cat-medium-4-Mercedes_Benz_Greener_Manufacturing/X_cat_val.npy\n","data/regression-cat-medium-4-Mercedes_Benz_Greener_Manufacturing/Y_val.npy\n","data/regression-cat-medium-4-Mercedes_Benz_Greener_Manufacturing/X_bin_val.npy\n","data/regression-cat-medium-4-Mercedes_Benz_Greener_Manufacturing/X_cat_test.npy\n","data/regression-cat-medium-4-Mercedes_Benz_Greener_Manufacturing/X_bin_train.npy\n","data/regression-cat-medium-4-Mercedes_Benz_Greener_Manufacturing/X_cat_train.npy\n","data/regression-cat-medium-4-Mercedes_Benz_Greener_Manufacturing/info.json\n","data/regression-cat-medium-4-Mercedes_Benz_Greener_Manufacturing/READY\n","data/regression-cat-medium-4-Mercedes_Benz_Greener_Manufacturing/X_bin_test.npy\n","data/regression-cat-medium-4-Mercedes_Benz_Greener_Manufacturing/Y_test.npy\n","data/regression-cat-medium-4-Mercedes_Benz_Greener_Manufacturing/Y_train.npy\n","data/regression-num-medium-2-MiamiHousing2016/\n","data/regression-num-medium-2-MiamiHousing2016/X_num_val.npy\n","data/regression-num-medium-2-MiamiHousing2016/Y_val.npy\n","data/regression-num-medium-2-MiamiHousing2016/X_num_train.npy\n","data/regression-num-medium-2-MiamiHousing2016/info.json\n","data/regression-num-medium-2-MiamiHousing2016/READY\n","data/regression-num-medium-2-MiamiHousing2016/X_num_test.npy\n","data/regression-num-medium-2-MiamiHousing2016/Y_test.npy\n","data/regression-num-medium-2-MiamiHousing2016/Y_train.npy\n","data/regression-num-medium-1-Ailerons/\n","data/regression-num-medium-1-Ailerons/X_num_val.npy\n","data/regression-num-medium-1-Ailerons/Y_val.npy\n","data/regression-num-medium-1-Ailerons/X_num_train.npy\n","data/regression-num-medium-1-Ailerons/info.json\n","data/regression-num-medium-1-Ailerons/READY\n","data/regression-num-medium-1-Ailerons/X_num_test.npy\n","data/regression-num-medium-1-Ailerons/Y_test.npy\n","data/regression-num-medium-1-Ailerons/Y_train.npy\n","data/regression-num-medium-0-medical_charges/\n","data/regression-num-medium-0-medical_charges/X_num_val.npy\n","data/regression-num-medium-0-medical_charges/Y_val.npy\n","data/regression-num-medium-0-medical_charges/X_num_train.npy\n","data/regression-num-medium-0-medical_charges/info.json\n","data/regression-num-medium-0-medical_charges/READY\n","data/regression-num-medium-0-medical_charges/X_num_test.npy\n","data/regression-num-medium-0-medical_charges/Y_test.npy\n","data/regression-num-medium-0-medical_charges/Y_train.npy\n","data/classif-num-medium-0-bank-marketing/\n","data/classif-num-medium-0-bank-marketing/X_num_val.npy\n","data/classif-num-medium-0-bank-marketing/Y_val.npy\n","data/classif-num-medium-0-bank-marketing/X_num_train.npy\n","data/classif-num-medium-0-bank-marketing/info.json\n","data/classif-num-medium-0-bank-marketing/READY\n","data/classif-num-medium-0-bank-marketing/X_num_test.npy\n","data/classif-num-medium-0-bank-marketing/Y_test.npy\n","data/classif-num-medium-0-bank-marketing/Y_train.npy\n","data/classif-num-medium-3-wine/\n","data/classif-num-medium-3-wine/X_num_val.npy\n","data/classif-num-medium-3-wine/Y_val.npy\n","data/classif-num-medium-3-wine/X_num_train.npy\n","data/classif-num-medium-3-wine/info.json\n","data/classif-num-medium-3-wine/READY\n","data/classif-num-medium-3-wine/X_num_test.npy\n","data/classif-num-medium-3-wine/Y_test.npy\n","data/classif-num-medium-3-wine/Y_train.npy\n","data/classif-num-medium-2-bank-marketing/\n","data/classif-num-medium-2-bank-marketing/X_num_val.npy\n","data/classif-num-medium-2-bank-marketing/Y_val.npy\n","data/classif-num-medium-2-bank-marketing/X_num_train.npy\n","data/classif-num-medium-2-bank-marketing/info.json\n","data/classif-num-medium-2-bank-marketing/READY\n","data/classif-num-medium-2-bank-marketing/X_num_test.npy\n","data/classif-num-medium-2-bank-marketing/Y_test.npy\n","data/classif-num-medium-2-bank-marketing/Y_train.npy\n","data/classif-num-large-0-jannis/\n","data/classif-num-large-0-jannis/X_num_val.npy\n","data/classif-num-large-0-jannis/Y_val.npy\n","data/classif-num-large-0-jannis/X_num_train.npy\n","data/classif-num-large-0-jannis/info.json\n","data/classif-num-large-0-jannis/READY\n","data/classif-num-large-0-jannis/X_num_test.npy\n","data/classif-num-large-0-jannis/Y_test.npy\n","data/classif-num-large-0-jannis/Y_train.npy\n","data/regression-num-medium-0-houses/\n","data/regression-num-medium-0-houses/X_num_val.npy\n","data/regression-num-medium-0-houses/Y_val.npy\n","data/regression-num-medium-0-houses/X_num_train.npy\n","data/regression-num-medium-0-houses/info.json\n","data/regression-num-medium-0-houses/READY\n","data/regression-num-medium-0-houses/X_num_test.npy\n","data/regression-num-medium-0-houses/Y_test.npy\n","data/regression-num-medium-0-houses/Y_train.npy\n","data/regression-num-large-0-year/\n","data/regression-num-large-0-year/X_num_val.npy\n","data/regression-num-large-0-year/Y_val.npy\n","data/regression-num-large-0-year/X_num_train.npy\n","data/regression-num-large-0-year/info.json\n","data/regression-num-large-0-year/READY\n","data/regression-num-large-0-year/X_num_test.npy\n","data/regression-num-large-0-year/Y_test.npy\n","data/regression-num-large-0-year/Y_train.npy\n","data/classif-cat-medium-1-KDDCup09_upselling/\n","data/classif-cat-medium-1-KDDCup09_upselling/X_cat_val.npy\n","data/classif-cat-medium-1-KDDCup09_upselling/X_num_val.npy\n","data/classif-cat-medium-1-KDDCup09_upselling/Y_val.npy\n","data/classif-cat-medium-1-KDDCup09_upselling/X_bin_val.npy\n","data/classif-cat-medium-1-KDDCup09_upselling/X_num_train.npy\n","data/classif-cat-medium-1-KDDCup09_upselling/X_cat_test.npy\n","data/classif-cat-medium-1-KDDCup09_upselling/X_bin_train.npy\n","data/classif-cat-medium-1-KDDCup09_upselling/X_cat_train.npy\n","data/classif-cat-medium-1-KDDCup09_upselling/info.json\n","data/classif-cat-medium-1-KDDCup09_upselling/READY\n","data/classif-cat-medium-1-KDDCup09_upselling/X_bin_test.npy\n","data/classif-cat-medium-1-KDDCup09_upselling/X_num_test.npy\n","data/classif-cat-medium-1-KDDCup09_upselling/Y_test.npy\n","data/classif-cat-medium-1-KDDCup09_upselling/Y_train.npy\n","data/classif-cat-medium-0-KDDCup09_upselling/\n","data/classif-cat-medium-0-KDDCup09_upselling/X_cat_val.npy\n","data/classif-cat-medium-0-KDDCup09_upselling/X_num_val.npy\n","data/classif-cat-medium-0-KDDCup09_upselling/Y_val.npy\n","data/classif-cat-medium-0-KDDCup09_upselling/X_bin_val.npy\n","data/classif-cat-medium-0-KDDCup09_upselling/X_num_train.npy\n","data/classif-cat-medium-0-KDDCup09_upselling/X_cat_test.npy\n","data/classif-cat-medium-0-KDDCup09_upselling/X_bin_train.npy\n","data/classif-cat-medium-0-KDDCup09_upselling/X_cat_train.npy\n","data/classif-cat-medium-0-KDDCup09_upselling/info.json\n","data/classif-cat-medium-0-KDDCup09_upselling/READY\n","data/classif-cat-medium-0-KDDCup09_upselling/X_bin_test.npy\n","data/classif-cat-medium-0-KDDCup09_upselling/X_num_test.npy\n","data/classif-cat-medium-0-KDDCup09_upselling/Y_test.npy\n","data/classif-cat-medium-0-KDDCup09_upselling/Y_train.npy\n","data/classif-num-large-0-MiniBooNE/\n","data/classif-num-large-0-MiniBooNE/X_num_val.npy\n","data/classif-num-large-0-MiniBooNE/Y_val.npy\n","data/classif-num-large-0-MiniBooNE/X_num_train.npy\n","data/classif-num-large-0-MiniBooNE/info.json\n","data/classif-num-large-0-MiniBooNE/READY\n","data/classif-num-large-0-MiniBooNE/X_num_test.npy\n","data/classif-num-large-0-MiniBooNE/Y_test.npy\n","data/classif-num-large-0-MiniBooNE/Y_train.npy\n","data/regression-num-medium-0-MiamiHousing2016/\n","data/regression-num-medium-0-MiamiHousing2016/X_num_val.npy\n","data/regression-num-medium-0-MiamiHousing2016/Y_val.npy\n","data/regression-num-medium-0-MiamiHousing2016/X_num_train.npy\n","data/regression-num-medium-0-MiamiHousing2016/info.json\n","data/regression-num-medium-0-MiamiHousing2016/READY\n","data/regression-num-medium-0-MiamiHousing2016/X_num_test.npy\n","data/regression-num-medium-0-MiamiHousing2016/Y_test.npy\n","data/regression-num-medium-0-MiamiHousing2016/Y_train.npy\n","data/regression-num-medium-2-Ailerons/\n","data/regression-num-medium-2-Ailerons/X_num_val.npy\n","data/regression-num-medium-2-Ailerons/Y_val.npy\n","data/regression-num-medium-2-Ailerons/X_num_train.npy\n","data/regression-num-medium-2-Ailerons/info.json\n","data/regression-num-medium-2-Ailerons/READY\n","data/regression-num-medium-2-Ailerons/X_num_test.npy\n","data/regression-num-medium-2-Ailerons/Y_test.npy\n","data/regression-num-medium-2-Ailerons/Y_train.npy\n","data/classif-num-medium-0-credit/\n","data/classif-num-medium-0-credit/X_num_val.npy\n","data/classif-num-medium-0-credit/Y_val.npy\n","data/classif-num-medium-0-credit/X_num_train.npy\n","data/classif-num-medium-0-credit/info.json\n","data/classif-num-medium-0-credit/READY\n","data/classif-num-medium-0-credit/X_num_test.npy\n","data/classif-num-medium-0-credit/Y_test.npy\n","data/classif-num-medium-0-credit/Y_train.npy\n","data/classif-num-medium-4-wine/\n","data/classif-num-medium-4-wine/X_num_val.npy\n","data/classif-num-medium-4-wine/Y_val.npy\n","data/classif-num-medium-4-wine/X_num_train.npy\n","data/classif-num-medium-4-wine/info.json\n","data/classif-num-medium-4-wine/READY\n","data/classif-num-medium-4-wine/X_num_test.npy\n","data/classif-num-medium-4-wine/Y_test.npy\n","data/classif-num-medium-4-wine/Y_train.npy\n","data/higgs-small/\n","data/higgs-small/X_num_val.npy\n","data/higgs-small/Y_val.npy\n","data/higgs-small/X_num_train.npy\n","data/higgs-small/info.json\n","data/higgs-small/READY\n","data/higgs-small/X_num_test.npy\n","data/higgs-small/Y_test.npy\n","data/higgs-small/Y_train.npy\n","data/classif-cat-medium-1-compass/\n","data/classif-cat-medium-1-compass/X_cat_val.npy\n","data/classif-cat-medium-1-compass/X_num_val.npy\n","data/classif-cat-medium-1-compass/Y_val.npy\n","data/classif-cat-medium-1-compass/X_bin_val.npy\n","data/classif-cat-medium-1-compass/X_num_train.npy\n","data/classif-cat-medium-1-compass/X_cat_test.npy\n","data/classif-cat-medium-1-compass/X_bin_train.npy\n","data/classif-cat-medium-1-compass/X_cat_train.npy\n","data/classif-cat-medium-1-compass/info.json\n","data/classif-cat-medium-1-compass/READY\n","data/classif-cat-medium-1-compass/X_bin_test.npy\n","data/classif-cat-medium-1-compass/X_num_test.npy\n","data/classif-cat-medium-1-compass/Y_test.npy\n","data/classif-cat-medium-1-compass/Y_train.npy\n","data/classif-cat-medium-0-rl/\n","data/classif-cat-medium-0-rl/X_cat_val.npy\n","data/classif-cat-medium-0-rl/X_num_val.npy\n","data/classif-cat-medium-0-rl/Y_val.npy\n","data/classif-cat-medium-0-rl/X_bin_val.npy\n","data/classif-cat-medium-0-rl/X_num_train.npy\n","data/classif-cat-medium-0-rl/X_cat_test.npy\n","data/classif-cat-medium-0-rl/X_bin_train.npy\n","data/classif-cat-medium-0-rl/X_cat_train.npy\n","data/classif-cat-medium-0-rl/info.json\n","data/classif-cat-medium-0-rl/READY\n","data/classif-cat-medium-0-rl/X_bin_test.npy\n","data/classif-cat-medium-0-rl/X_num_test.npy\n","data/classif-cat-medium-0-rl/Y_test.npy\n","data/classif-cat-medium-0-rl/Y_train.npy\n","data/regression-num-medium-2-cpu_act/\n","data/regression-num-medium-2-cpu_act/X_num_val.npy\n","data/regression-num-medium-2-cpu_act/Y_val.npy\n","data/regression-num-medium-2-cpu_act/X_num_train.npy\n","data/regression-num-medium-2-cpu_act/info.json\n","data/regression-num-medium-2-cpu_act/READY\n","data/regression-num-medium-2-cpu_act/X_num_test.npy\n","data/regression-num-medium-2-cpu_act/Y_test.npy\n","data/regression-num-medium-2-cpu_act/Y_train.npy\n","data/otto/\n","data/otto/X_num_val.npy\n","data/otto/Y_val.npy\n","data/otto/X_num_train.npy\n","data/otto/info.json\n","data/otto/READY\n","data/otto/X_num_test.npy\n","data/otto/Y_test.npy\n","data/otto/Y_train.npy\n","data/regression-cat-medium-0-yprop_4_1/\n","data/regression-cat-medium-0-yprop_4_1/X_num_val.npy\n","data/regression-cat-medium-0-yprop_4_1/Y_val.npy\n","data/regression-cat-medium-0-yprop_4_1/X_bin_val.npy\n","data/regression-cat-medium-0-yprop_4_1/X_num_train.npy\n","data/regression-cat-medium-0-yprop_4_1/X_bin_train.npy\n","data/regression-cat-medium-0-yprop_4_1/info.json\n","data/regression-cat-medium-0-yprop_4_1/READY\n","data/regression-cat-medium-0-yprop_4_1/X_bin_test.npy\n","data/regression-cat-medium-0-yprop_4_1/X_num_test.npy\n","data/regression-cat-medium-0-yprop_4_1/Y_test.npy\n","data/regression-cat-medium-0-yprop_4_1/Y_train.npy\n","data/classif-cat-large-0-covertype/\n","data/classif-cat-large-0-covertype/X_num_val.npy\n","data/classif-cat-large-0-covertype/Y_val.npy\n","data/classif-cat-large-0-covertype/X_bin_val.npy\n","data/classif-cat-large-0-covertype/X_num_train.npy\n","data/classif-cat-large-0-covertype/X_bin_train.npy\n","data/classif-cat-large-0-covertype/info.json\n","data/classif-cat-large-0-covertype/READY\n","data/classif-cat-large-0-covertype/X_bin_test.npy\n","data/classif-cat-large-0-covertype/X_num_test.npy\n","data/classif-cat-large-0-covertype/Y_test.npy\n","data/classif-cat-large-0-covertype/Y_train.npy\n","data/regression-cat-medium-1-Bike_Sharing_Demand/\n","data/regression-cat-medium-1-Bike_Sharing_Demand/X_cat_val.npy\n","data/regression-cat-medium-1-Bike_Sharing_Demand/X_num_val.npy\n","data/regression-cat-medium-1-Bike_Sharing_Demand/Y_val.npy\n","data/regression-cat-medium-1-Bike_Sharing_Demand/X_bin_val.npy\n","data/regression-cat-medium-1-Bike_Sharing_Demand/X_num_train.npy\n","data/regression-cat-medium-1-Bike_Sharing_Demand/X_cat_test.npy\n","data/regression-cat-medium-1-Bike_Sharing_Demand/X_bin_train.npy\n","data/regression-cat-medium-1-Bike_Sharing_Demand/X_cat_train.npy\n","data/regression-cat-medium-1-Bike_Sharing_Demand/info.json\n","data/regression-cat-medium-1-Bike_Sharing_Demand/READY\n","data/regression-cat-medium-1-Bike_Sharing_Demand/X_bin_test.npy\n","data/regression-cat-medium-1-Bike_Sharing_Demand/X_num_test.npy\n","data/regression-cat-medium-1-Bike_Sharing_Demand/Y_test.npy\n","data/regression-cat-medium-1-Bike_Sharing_Demand/Y_train.npy\n","data/classif-cat-medium-0-electricity/\n","data/classif-cat-medium-0-electricity/X_cat_val.npy\n","data/classif-cat-medium-0-electricity/X_num_val.npy\n","data/classif-cat-medium-0-electricity/Y_val.npy\n","data/classif-cat-medium-0-electricity/X_num_train.npy\n","data/classif-cat-medium-0-electricity/X_cat_test.npy\n","data/classif-cat-medium-0-electricity/X_cat_train.npy\n","data/classif-cat-medium-0-electricity/info.json\n","data/classif-cat-medium-0-electricity/READY\n","data/classif-cat-medium-0-electricity/X_num_test.npy\n","data/classif-cat-medium-0-electricity/Y_test.npy\n","data/classif-cat-medium-0-electricity/Y_train.npy\n","data/regression-cat-medium-2-visualizing_soil/\n","data/regression-cat-medium-2-visualizing_soil/X_num_val.npy\n","data/regression-cat-medium-2-visualizing_soil/Y_val.npy\n","data/regression-cat-medium-2-visualizing_soil/X_bin_val.npy\n","data/regression-cat-medium-2-visualizing_soil/X_num_train.npy\n","data/regression-cat-medium-2-visualizing_soil/X_bin_train.npy\n","data/regression-cat-medium-2-visualizing_soil/info.json\n","data/regression-cat-medium-2-visualizing_soil/READY\n","data/regression-cat-medium-2-visualizing_soil/X_bin_test.npy\n","data/regression-cat-medium-2-visualizing_soil/X_num_test.npy\n","data/regression-cat-medium-2-visualizing_soil/Y_test.npy\n","data/regression-cat-medium-2-visualizing_soil/Y_train.npy\n","data/regression-cat-medium-1-yprop_4_1/\n","data/regression-cat-medium-1-yprop_4_1/X_num_val.npy\n","data/regression-cat-medium-1-yprop_4_1/Y_val.npy\n","data/regression-cat-medium-1-yprop_4_1/X_bin_val.npy\n","data/regression-cat-medium-1-yprop_4_1/X_num_train.npy\n","data/regression-cat-medium-1-yprop_4_1/X_bin_train.npy\n","data/regression-cat-medium-1-yprop_4_1/info.json\n","data/regression-cat-medium-1-yprop_4_1/READY\n","data/regression-cat-medium-1-yprop_4_1/X_bin_test.npy\n","data/regression-cat-medium-1-yprop_4_1/X_num_test.npy\n","data/regression-cat-medium-1-yprop_4_1/Y_test.npy\n","data/regression-cat-medium-1-yprop_4_1/Y_train.npy\n","data/classif-num-medium-1-bank-marketing/\n","data/classif-num-medium-1-bank-marketing/X_num_val.npy\n","data/classif-num-medium-1-bank-marketing/Y_val.npy\n","data/classif-num-medium-1-bank-marketing/X_num_train.npy\n","data/classif-num-medium-1-bank-marketing/info.json\n","data/classif-num-medium-1-bank-marketing/READY\n","data/classif-num-medium-1-bank-marketing/X_num_test.npy\n","data/classif-num-medium-1-bank-marketing/Y_test.npy\n","data/classif-num-medium-1-bank-marketing/Y_train.npy\n","data/classif-num-medium-1-credit/\n","data/classif-num-medium-1-credit/X_num_val.npy\n","data/classif-num-medium-1-credit/Y_val.npy\n","data/classif-num-medium-1-credit/X_num_train.npy\n","data/classif-num-medium-1-credit/info.json\n","data/classif-num-medium-1-credit/READY\n","data/classif-num-medium-1-credit/X_num_test.npy\n","data/classif-num-medium-1-credit/Y_test.npy\n","data/classif-num-medium-1-credit/Y_train.npy\n"]}]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-glTe-NrxA3S","executionInfo":{"status":"ok","timestamp":1728990736639,"user_tz":-480,"elapsed":3500,"user":{"displayName":"Jonindo Pasaribu","userId":"10958990953097471082"}},"outputId":"616dd7cb-b6e7-49ff-c7e7-f0e5f84a74a6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pytorch-tabnet\n","  Downloading pytorch_tabnet-4.1.0-py3-none-any.whl.metadata (15 kB)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from pytorch-tabnet) (1.26.4)\n","Requirement already satisfied: scikit_learn>0.21 in /usr/local/lib/python3.10/dist-packages (from pytorch-tabnet) (1.5.2)\n","Requirement already satisfied: scipy>1.4 in /usr/local/lib/python3.10/dist-packages (from pytorch-tabnet) (1.13.1)\n","Requirement already satisfied: torch>=1.3 in /usr/local/lib/python3.10/dist-packages (from pytorch-tabnet) (2.4.1+cu121)\n","Requirement already satisfied: tqdm>=4.36 in /usr/local/lib/python3.10/dist-packages (from pytorch-tabnet) (4.66.5)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit_learn>0.21->pytorch-tabnet) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit_learn>0.21->pytorch-tabnet) (3.5.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (3.16.1)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (1.13.3)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (3.4)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (2024.6.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.3->pytorch-tabnet) (3.0.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.3->pytorch-tabnet) (1.3.0)\n","Downloading pytorch_tabnet-4.1.0-py3-none-any.whl (44 kB)\n","\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/44.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.5/44.5 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: pytorch-tabnet\n","Successfully installed pytorch-tabnet-4.1.0\n"]}],"source":["!pip install pytorch-tabnet"]},{"cell_type":"code","source":["!pip install optuna"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T3kebgsowkp0","executionInfo":{"status":"ok","timestamp":1728990740765,"user_tz":-480,"elapsed":4130,"user":{"displayName":"Jonindo Pasaribu","userId":"10958990953097471082"}},"outputId":"031a28a5-061f-4808-dd47-c9a35636b240"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting optuna\n","  Downloading optuna-4.0.0-py3-none-any.whl.metadata (16 kB)\n","Collecting alembic>=1.5.0 (from optuna)\n","  Downloading alembic-1.13.3-py3-none-any.whl.metadata (7.4 kB)\n","Collecting colorlog (from optuna)\n","  Downloading colorlog-6.8.2-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (24.1)\n","Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.35)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.66.5)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0.2)\n","Collecting Mako (from alembic>=1.5.0->optuna)\n","  Downloading Mako-1.3.5-py3-none-any.whl.metadata (2.9 kB)\n","Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.12.2)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna) (3.1.1)\n","Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna) (3.0.1)\n","Downloading optuna-4.0.0-py3-none-any.whl (362 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m362.8/362.8 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading alembic-1.13.3-py3-none-any.whl (233 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.2/233.2 kB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading colorlog-6.8.2-py3-none-any.whl (11 kB)\n","Downloading Mako-1.3.5-py3-none-any.whl (78 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: Mako, colorlog, alembic, optuna\n","Successfully installed Mako-1.3.5 alembic-1.13.3 colorlog-6.8.2 optuna-4.0.0\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import optuna\n","import torch.optim\n","\n","from pytorch_tabnet.tab_model import TabNetRegressor\n","from sklearn.preprocessing import QuantileTransformer"],"metadata":{"id":"085aiY1dzlHG","executionInfo":{"status":"ok","timestamp":1728990746888,"user_tz":-480,"elapsed":6127,"user":{"displayName":"Jonindo Pasaribu","userId":"10958990953097471082"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["tnr = TabNetRegressor()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pr7k2hel51eb","executionInfo":{"status":"ok","timestamp":1728990746888,"user_tz":-480,"elapsed":7,"user":{"displayName":"Jonindo Pasaribu","userId":"10958990953097471082"}},"outputId":"36f0e932-6375-4702-cd7b-9c519f728b5e"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]}]},{"cell_type":"code","source":["X_train = np.load('/content/data/regression-num-medium-0-houses/X_num_train.npy')\n","y_train = np.load('/content/data/regression-num-medium-0-houses/Y_train.npy').reshape(-1, 1)\n","\n","X_valid = np.load('/content/data/regression-num-medium-0-houses/X_num_val.npy')\n","y_valid = np.load('/content/data/regression-num-medium-0-houses/Y_val.npy').reshape(-1, 1)\n","\n","X_test = np.load('/content/data/regression-num-medium-0-houses/X_num_test.npy')\n","y_test = np.load('/content/data/regression-num-medium-0-houses/Y_test.npy').reshape(-1, 1)"],"metadata":{"id":"ml0RPc_76dZx","executionInfo":{"status":"ok","timestamp":1728990746888,"user_tz":-480,"elapsed":5,"user":{"displayName":"Jonindo Pasaribu","userId":"10958990953097471082"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["normalizer = QuantileTransformer(\n","            output_distribution='normal',\n","            n_quantiles=max(min(X_train.shape[0] // 30, 1000), 10),\n","            subsample=1_000_000_000,\n","            )\n","normalizer.fit_transform(X_train)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"19PUhYavmHsh","executionInfo":{"status":"ok","timestamp":1728990746889,"user_tz":-480,"elapsed":6,"user":{"displayName":"Jonindo Pasaribu","userId":"10958990953097471082"}},"outputId":"d21bf74f-374f-46bc-9983-e8191b137c0b"},"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[ 5.1993375 ,  0.19758019,  1.2819047 , ...,  0.39101908,\n","         0.56026226, -1.4062883 ],\n","       [ 1.0876423 , -1.0403167 ,  0.7731656 , ...,  0.41970792,\n","         1.086838  , -1.1877301 ],\n","       [ 0.900424  , -0.30279225, -0.3982458 , ..., -0.7325131 ,\n","        -0.7325131 ,  0.7776982 ],\n","       ...,\n","       [-0.95394254, -0.30279225,  0.5515898 , ...,  0.84323615,\n","        -2.0318518 ,  1.5784693 ],\n","       [-0.95394254, -0.6095368 , -1.3299519 , ..., -1.2430336 ,\n","         0.3215784 , -0.26943094],\n","       [ 0.5209385 , -0.5383124 , -0.8256636 , ..., -1.0599736 ,\n","         1.1725812 , -0.45711386]], dtype=float32)"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["#Baseline\n","tnr.fit(\n","    X_train=X_train, y_train=y_train,\n","    eval_set=[(X_train, y_train), (X_valid, y_valid)],\n","    eval_name=['train', 'valid'],\n","    eval_metric=['mae', 'rmse'],\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dmadZ12j7CO_","executionInfo":{"status":"ok","timestamp":1728990770947,"user_tz":-480,"elapsed":24063,"user":{"displayName":"Jonindo Pasaribu","userId":"10958990953097471082"}},"outputId":"e3eb141e-d5ee-4b9d-b8a2-39273da99a72"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 119.72114| train_mae: 18.196269989013672| train_rmse: 18.36054039001465| valid_mae: 18.17620086669922| valid_rmse: 18.341190338134766|  0:00:03s\n","epoch 1  | loss: 56.94198| train_mae: 67.64131927490234| train_rmse: 67.88523864746094| valid_mae: 67.5953598022461| valid_rmse: 67.8174819946289|  0:00:03s\n","epoch 2  | loss: 12.14867| train_mae: 181.90896606445312| train_rmse: 182.11813354492188| valid_mae: 181.6089630126953| valid_rmse: 181.9517059326172|  0:00:04s\n","epoch 3  | loss: 3.97199 | train_mae: 132.9217529296875| train_rmse: 133.19354248046875| valid_mae: 132.9796600341797| valid_rmse: 133.26284790039062|  0:00:05s\n","epoch 4  | loss: 1.30861 | train_mae: 187.6407012939453| train_rmse: 187.92210388183594| valid_mae: 187.54623413085938| valid_rmse: 187.79681396484375|  0:00:06s\n","epoch 5  | loss: 0.75816 | train_mae: 130.90032958984375| train_rmse: 131.1944580078125| valid_mae: 130.7469940185547| valid_rmse: 131.01199340820312|  0:00:06s\n","epoch 6  | loss: 0.4557  | train_mae: 117.15902709960938| train_rmse: 117.7574691772461| valid_mae: 117.21658325195312| valid_rmse: 117.70108032226562|  0:00:07s\n","epoch 7  | loss: 0.37421 | train_mae: 92.8554916381836| train_rmse: 93.10891723632812| valid_mae: 92.90335083007812| valid_rmse: 93.12477111816406|  0:00:08s\n","epoch 8  | loss: 0.32327 | train_mae: 8.170479774475098| train_rmse: 8.28285026550293| valid_mae: 8.142919540405273| valid_rmse: 8.224149703979492|  0:00:09s\n","epoch 9  | loss: 0.3626  | train_mae: 6.906479835510254| train_rmse: 9.59475040435791| valid_mae: 7.019330024719238| valid_rmse: 9.680950164794922|  0:00:09s\n","epoch 10 | loss: 0.26316 | train_mae: 8.858920097351074| train_rmse: 14.980170249938965| valid_mae: 9.1602201461792| valid_rmse: 15.256389617919922|  0:00:10s\n","epoch 11 | loss: 0.23061 | train_mae: 6.368770122528076| train_rmse: 9.326020240783691| valid_mae: 6.658170223236084| valid_rmse: 9.54220962524414|  0:00:11s\n","epoch 12 | loss: 0.21859 | train_mae: 2.961819887161255| train_rmse: 4.282939910888672| valid_mae: 2.9146499633789062| valid_rmse: 4.181079864501953|  0:00:12s\n","epoch 13 | loss: 0.20278 | train_mae: 1.231850028038025| train_rmse: 1.8420900106430054| valid_mae: 1.2094899415969849| valid_rmse: 1.7856899499893188|  0:00:12s\n","epoch 14 | loss: 0.17782 | train_mae: 4.125470161437988| train_rmse: 4.2246599197387695| valid_mae: 4.117579936981201| valid_rmse: 4.219399929046631|  0:00:13s\n","epoch 15 | loss: 0.17332 | train_mae: 2.1785500049591064| train_rmse: 2.2897000312805176| valid_mae: 2.1512300968170166| valid_rmse: 2.261080026626587|  0:00:14s\n","epoch 16 | loss: 0.16059 | train_mae: 2.306989908218384| train_rmse: 2.455009937286377| valid_mae: 2.315500020980835| valid_rmse: 2.472170114517212|  0:00:14s\n","epoch 17 | loss: 0.15652 | train_mae: 2.4827001094818115| train_rmse: 2.9275999069213867| valid_mae: 2.46304988861084| valid_rmse: 2.9410998821258545|  0:00:15s\n","epoch 18 | loss: 0.14574 | train_mae: 2.28125 | train_rmse: 2.5759799480438232| valid_mae: 2.2995500564575195| valid_rmse: 2.600480079650879|  0:00:16s\n","epoch 19 | loss: 0.14179 | train_mae: 1.9268900156021118| train_rmse: 2.0969901084899902| valid_mae: 1.9056199789047241| valid_rmse: 2.073280096054077|  0:00:16s\n","epoch 20 | loss: 0.14579 | train_mae: 2.461060047149658| train_rmse: 2.606489896774292| valid_mae: 2.469330072402954| valid_rmse: 2.611949920654297|  0:00:17s\n","epoch 21 | loss: 0.13529 | train_mae: 5.856339931488037| train_rmse: 6.286300182342529| valid_mae: 5.906370162963867| valid_rmse: 6.316740036010742|  0:00:18s\n","epoch 22 | loss: 0.13118 | train_mae: 7.6474199295043945| train_rmse: 8.059980392456055| valid_mae: 7.6697001457214355| valid_rmse: 8.080160140991211|  0:00:18s\n","epoch 23 | loss: 0.11867 | train_mae: 4.376440048217773| train_rmse: 4.518249988555908| valid_mae: 4.4074602127075195| valid_rmse: 4.542610168457031|  0:00:19s\n","\n","Early stopping occurred at epoch 23 with best_epoch = 13 and best_valid_rmse = 1.7856899499893188\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n"]}]},{"cell_type":"code","source":["def objective(trial):\n","    n_d = trial.suggest_int('n_d', 8, 64)\n","    n_a = n_d\n","\n","    params = {\n","        #'n_d': trial.suggest_int('n_d', 8, 64),\n","        #'n_a': trial.suggest_int('n_a', 8, 64),\n","        'n_d': n_d,\n","        'n_a': n_a,\n","        'n_steps': trial.suggest_int('n_steps', 3, 10),\n","        'gamma': trial.suggest_float('gamma', 1.0, 2.0),\n","        'n_independent': trial.suggest_int('n_independent', 1, 5),\n","        'n_shared': trial.suggest_int('n_shared', 1, 5),\n","        'momentum': trial.suggest_float('momentum', 0.01, 0.4),\n","    }\n","\n","    model = TabNetRegressor(**params)\n","    model.fit(X_train, y_train, eval_set=[(X_valid, y_valid)], patience=10)\n","\n","    # Evaluate model performance\n","    score = model.best_cost  # or any other metric\n","\n","    return score\n","\n","study = optuna.create_study(direction='minimize')\n","study.optimize(objective, n_trials=100)\n","\n","best_params = study.best_params"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rKJAw0W-w7sc","executionInfo":{"status":"ok","timestamp":1728995780437,"user_tz":-480,"elapsed":5009496,"user":{"displayName":"Jonindo Pasaribu","userId":"10958990953097471082"}},"outputId":"a26968a6-34fd-45d7-9cb7-f23796800201"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stderr","text":["[I 2024-10-15 11:12:50,407] A new study created in memory with name: no-name-7f2b7437-00da-4867-88b6-57e6e8a227fb\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 68.52406| val_0_mse: 16831.72265625|  0:00:01s\n","epoch 1  | loss: 7.44925 | val_0_mse: 61428.3515625|  0:00:03s\n","epoch 2  | loss: 5.82488 | val_0_mse: 21581.439453125|  0:00:05s\n","epoch 3  | loss: 3.44415 | val_0_mse: 17933.81640625|  0:00:07s\n","epoch 4  | loss: 3.95225 | val_0_mse: 6629.34716796875|  0:00:08s\n","epoch 5  | loss: 3.79965 | val_0_mse: 4497.40673828125|  0:00:10s\n","epoch 6  | loss: 2.88478 | val_0_mse: 1417.0181884765625|  0:00:12s\n","epoch 7  | loss: 8.69818 | val_0_mse: 1241.676513671875|  0:00:13s\n","epoch 8  | loss: 1.55253 | val_0_mse: 251.8632354736328|  0:00:15s\n","epoch 9  | loss: 1.17761 | val_0_mse: 393.4658508300781|  0:00:17s\n","epoch 10 | loss: 1.52531 | val_0_mse: 544.6976318359375|  0:00:19s\n","epoch 11 | loss: 2.32103 | val_0_mse: 562.0308837890625|  0:00:20s\n","epoch 12 | loss: 2.00032 | val_0_mse: 379.9363708496094|  0:00:22s\n","epoch 13 | loss: 1.04612 | val_0_mse: 268.2509460449219|  0:00:24s\n","epoch 14 | loss: 1.54981 | val_0_mse: 96.57469940185547|  0:00:25s\n","epoch 15 | loss: 0.82148 | val_0_mse: 83.51840209960938|  0:00:27s\n","epoch 16 | loss: 0.55458 | val_0_mse: 76.87355041503906|  0:00:29s\n","epoch 17 | loss: 0.37987 | val_0_mse: 3.3701400756835938|  0:00:31s\n","epoch 18 | loss: 0.51929 | val_0_mse: 19.568519592285156|  0:00:32s\n","epoch 19 | loss: 0.30302 | val_0_mse: 21.18391990661621|  0:00:34s\n","epoch 20 | loss: 0.30591 | val_0_mse: 8.54086971282959|  0:00:36s\n","epoch 21 | loss: 0.66288 | val_0_mse: 7.173659801483154|  0:00:37s\n","epoch 22 | loss: 1.00482 | val_0_mse: 23.426210403442383|  0:00:39s\n","epoch 23 | loss: 0.62703 | val_0_mse: 14.540670394897461|  0:00:41s\n","epoch 24 | loss: 0.32854 | val_0_mse: 7.478640079498291|  0:00:42s\n","epoch 25 | loss: 0.23731 | val_0_mse: 6.928030014038086|  0:00:44s\n","epoch 26 | loss: 0.20545 | val_0_mse: 5.450829982757568|  0:00:46s\n","epoch 27 | loss: 0.16622 | val_0_mse: 2.004430055618286|  0:00:47s\n","epoch 28 | loss: 0.37722 | val_0_mse: 1.658270001411438|  0:00:49s\n","epoch 29 | loss: 1.13801 | val_0_mse: 1.9250199794769287|  0:00:51s\n","epoch 30 | loss: 1.48712 | val_0_mse: 1.3464000225067139|  0:00:53s\n","epoch 31 | loss: 0.52712 | val_0_mse: 4.713160037994385|  0:00:54s\n","epoch 32 | loss: 0.42204 | val_0_mse: 0.9431599974632263|  0:00:56s\n","epoch 33 | loss: 0.40769 | val_0_mse: 0.9605699777603149|  0:00:58s\n","epoch 34 | loss: 0.31125 | val_0_mse: 1.1721999645233154|  0:00:59s\n","epoch 35 | loss: 0.27272 | val_0_mse: 0.521589994430542|  0:01:01s\n","epoch 36 | loss: 0.29871 | val_0_mse: 0.41471999883651733|  0:01:03s\n","epoch 37 | loss: 0.44598 | val_0_mse: 0.4278300106525421|  0:01:05s\n","epoch 38 | loss: 0.25469 | val_0_mse: 0.680899977684021|  0:01:06s\n","epoch 39 | loss: 0.29443 | val_0_mse: 0.5070899724960327|  0:01:08s\n","epoch 40 | loss: 0.19287 | val_0_mse: 0.3354400098323822|  0:01:10s\n","epoch 41 | loss: 0.22892 | val_0_mse: 0.5506299734115601|  0:01:11s\n","epoch 42 | loss: 0.18279 | val_0_mse: 0.4030900001525879|  0:01:13s\n","epoch 43 | loss: 0.18763 | val_0_mse: 0.4192900061607361|  0:01:15s\n","epoch 44 | loss: 0.17706 | val_0_mse: 0.29850998520851135|  0:01:16s\n","epoch 45 | loss: 0.17994 | val_0_mse: 0.29627999663352966|  0:01:18s\n","epoch 46 | loss: 0.26202 | val_0_mse: 0.3019300103187561|  0:01:20s\n","epoch 47 | loss: 0.32387 | val_0_mse: 0.3631500005722046|  0:01:21s\n","epoch 48 | loss: 0.26366 | val_0_mse: 0.24111999571323395|  0:01:23s\n","epoch 49 | loss: 0.20211 | val_0_mse: 0.2544099986553192|  0:01:25s\n","epoch 50 | loss: 0.2612  | val_0_mse: 0.16888000071048737|  0:01:27s\n","epoch 51 | loss: 0.20201 | val_0_mse: 0.3296400010585785|  0:01:28s\n","epoch 52 | loss: 0.16638 | val_0_mse: 0.41690999269485474|  0:01:30s\n","epoch 53 | loss: 0.25427 | val_0_mse: 0.424780011177063|  0:01:32s\n","epoch 54 | loss: 0.23183 | val_0_mse: 0.1720999926328659|  0:01:33s\n","epoch 55 | loss: 0.22161 | val_0_mse: 0.3186599910259247|  0:01:35s\n","epoch 56 | loss: 0.1902  | val_0_mse: 0.18975000083446503|  0:01:37s\n","epoch 57 | loss: 0.19036 | val_0_mse: 0.24090999364852905|  0:01:38s\n","epoch 58 | loss: 0.1944  | val_0_mse: 0.21277999877929688|  0:01:40s\n","epoch 59 | loss: 0.17053 | val_0_mse: 0.2472500056028366|  0:01:42s\n","epoch 60 | loss: 0.17987 | val_0_mse: 0.2215700000524521|  0:01:43s\n","\n","Early stopping occurred at epoch 60 with best_epoch = 50 and best_val_0_mse = 0.16888000071048737\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 11:14:35,183] Trial 0 finished with value: 0.16888196766376495 and parameters: {'n_d': 42, 'n_steps': 10, 'gamma': 1.4984488351630505, 'n_independent': 4, 'n_shared': 3, 'momentum': 0.03503733376112773}. Best is trial 0 with value: 0.16888196766376495.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 64.65764| val_0_mse: 253206.984375|  0:00:01s\n","epoch 1  | loss: 3.32787 | val_0_mse: 5503.8173828125|  0:00:02s\n","epoch 2  | loss: 3.16464 | val_0_mse: 29989.36328125|  0:00:03s\n","epoch 3  | loss: 1.74983 | val_0_mse: 4553.85400390625|  0:00:05s\n","epoch 4  | loss: 0.7659  | val_0_mse: 1153.7091064453125|  0:00:06s\n","epoch 5  | loss: 1.17989 | val_0_mse: 1059.1920166015625|  0:00:07s\n","epoch 6  | loss: 0.82339 | val_0_mse: 282.9734802246094|  0:00:09s\n","epoch 7  | loss: 0.38877 | val_0_mse: 507.0717468261719|  0:00:10s\n","epoch 8  | loss: 0.35704 | val_0_mse: 274.5067443847656|  0:00:11s\n","epoch 9  | loss: 0.36699 | val_0_mse: 377.7467346191406|  0:00:13s\n","epoch 10 | loss: 0.41735 | val_0_mse: 268.4640808105469|  0:00:14s\n","epoch 11 | loss: 0.43722 | val_0_mse: 36.11714172363281|  0:00:15s\n","epoch 12 | loss: 0.33481 | val_0_mse: 130.6616973876953|  0:00:16s\n","epoch 13 | loss: 0.31982 | val_0_mse: 126.85266876220703|  0:00:18s\n","epoch 14 | loss: 0.31901 | val_0_mse: 255.60313415527344|  0:00:19s\n","epoch 15 | loss: 0.31673 | val_0_mse: 86.3702163696289|  0:00:20s\n","epoch 16 | loss: 0.36959 | val_0_mse: 64.85195922851562|  0:00:22s\n","epoch 17 | loss: 0.41975 | val_0_mse: 45.940399169921875|  0:00:23s\n","epoch 18 | loss: 0.39623 | val_0_mse: 58.30921936035156|  0:00:24s\n","epoch 19 | loss: 0.27303 | val_0_mse: 16.78990936279297|  0:00:25s\n","epoch 20 | loss: 0.46307 | val_0_mse: 18.28066062927246|  0:00:27s\n","epoch 21 | loss: 0.42854 | val_0_mse: 19.377460479736328|  0:00:28s\n","epoch 22 | loss: 0.45895 | val_0_mse: 13.946880340576172|  0:00:29s\n","epoch 23 | loss: 0.23556 | val_0_mse: 4.102839946746826|  0:00:30s\n","epoch 24 | loss: 0.28329 | val_0_mse: 5.868569850921631|  0:00:32s\n","epoch 25 | loss: 0.20457 | val_0_mse: 4.26446008682251|  0:00:33s\n","epoch 26 | loss: 0.19189 | val_0_mse: 1.1655900478363037|  0:00:34s\n","epoch 27 | loss: 0.18005 | val_0_mse: 0.675599992275238|  0:00:36s\n","epoch 28 | loss: 0.18048 | val_0_mse: 0.6091300249099731|  0:00:37s\n","epoch 29 | loss: 0.16513 | val_0_mse: 1.030210018157959|  0:00:38s\n","epoch 30 | loss: 0.19066 | val_0_mse: 0.42162999510765076|  0:00:40s\n","epoch 31 | loss: 0.28233 | val_0_mse: 0.4849399924278259|  0:00:41s\n","epoch 32 | loss: 0.27774 | val_0_mse: 1.2024600505828857|  0:00:42s\n","epoch 33 | loss: 0.23001 | val_0_mse: 0.5513100028038025|  0:00:43s\n","epoch 34 | loss: 0.22384 | val_0_mse: 0.3960300087928772|  0:00:45s\n","epoch 35 | loss: 0.20507 | val_0_mse: 0.28637999296188354|  0:00:46s\n","epoch 36 | loss: 0.20444 | val_0_mse: 0.44565001130104065|  0:00:47s\n","epoch 37 | loss: 0.18013 | val_0_mse: 0.4382300078868866|  0:00:49s\n","epoch 38 | loss: 0.17269 | val_0_mse: 0.3622100055217743|  0:00:50s\n","epoch 39 | loss: 0.17394 | val_0_mse: 0.23160000145435333|  0:00:51s\n","epoch 40 | loss: 0.15768 | val_0_mse: 0.2649500072002411|  0:00:52s\n","epoch 41 | loss: 0.16428 | val_0_mse: 0.22088000178337097|  0:00:54s\n","epoch 42 | loss: 0.19449 | val_0_mse: 0.2951500117778778|  0:00:55s\n","epoch 43 | loss: 0.21278 | val_0_mse: 0.3667199909687042|  0:00:56s\n","epoch 44 | loss: 0.20866 | val_0_mse: 0.4600299894809723|  0:00:57s\n","epoch 45 | loss: 0.24453 | val_0_mse: 0.2924500107765198|  0:00:59s\n","epoch 46 | loss: 0.19333 | val_0_mse: 0.1975499987602234|  0:01:00s\n","epoch 47 | loss: 0.22052 | val_0_mse: 0.20035000145435333|  0:01:01s\n","epoch 48 | loss: 0.22855 | val_0_mse: 0.2058899998664856|  0:01:02s\n","epoch 49 | loss: 0.20444 | val_0_mse: 0.26923999190330505|  0:01:04s\n","epoch 50 | loss: 0.19511 | val_0_mse: 0.241689994931221|  0:01:05s\n","epoch 51 | loss: 0.14855 | val_0_mse: 0.19257999956607819|  0:01:06s\n","epoch 52 | loss: 0.13532 | val_0_mse: 0.2164900004863739|  0:01:07s\n","epoch 53 | loss: 0.16059 | val_0_mse: 0.16656999289989471|  0:01:09s\n","epoch 54 | loss: 0.2225  | val_0_mse: 0.34852999448776245|  0:01:10s\n","epoch 55 | loss: 0.36902 | val_0_mse: 0.4690000116825104|  0:01:11s\n","epoch 56 | loss: 0.32117 | val_0_mse: 0.2513900101184845|  0:01:13s\n","epoch 57 | loss: 0.28732 | val_0_mse: 0.15365000069141388|  0:01:14s\n","epoch 58 | loss: 0.28195 | val_0_mse: 0.30129000544548035|  0:01:15s\n","epoch 59 | loss: 0.28565 | val_0_mse: 0.41359999775886536|  0:01:16s\n","epoch 60 | loss: 0.2797  | val_0_mse: 0.30160999298095703|  0:01:18s\n","epoch 61 | loss: 0.25462 | val_0_mse: 0.15678000450134277|  0:01:19s\n","epoch 62 | loss: 0.21677 | val_0_mse: 0.19109000265598297|  0:01:20s\n","epoch 63 | loss: 0.17895 | val_0_mse: 0.19588999450206757|  0:01:21s\n","epoch 64 | loss: 0.16556 | val_0_mse: 0.1457899957895279|  0:01:23s\n","epoch 65 | loss: 0.1776  | val_0_mse: 0.17494000494480133|  0:01:24s\n","epoch 66 | loss: 0.16978 | val_0_mse: 0.1585099995136261|  0:01:25s\n","epoch 67 | loss: 0.15836 | val_0_mse: 0.14890000224113464|  0:01:26s\n","epoch 68 | loss: 0.16852 | val_0_mse: 0.16843000054359436|  0:01:28s\n","epoch 69 | loss: 0.16078 | val_0_mse: 0.1418900042772293|  0:01:29s\n","epoch 70 | loss: 0.17585 | val_0_mse: 0.16050000488758087|  0:01:30s\n","epoch 71 | loss: 0.16715 | val_0_mse: 0.1383499950170517|  0:01:32s\n","epoch 72 | loss: 0.17224 | val_0_mse: 0.17136000096797943|  0:01:33s\n","epoch 73 | loss: 0.16119 | val_0_mse: 0.131290003657341|  0:01:34s\n","epoch 74 | loss: 0.17511 | val_0_mse: 0.1818699985742569|  0:01:36s\n","epoch 75 | loss: 0.15903 | val_0_mse: 0.12901000678539276|  0:01:37s\n","epoch 76 | loss: 0.17861 | val_0_mse: 0.18799999356269836|  0:01:38s\n","epoch 77 | loss: 0.16635 | val_0_mse: 0.14300000667572021|  0:01:39s\n","epoch 78 | loss: 0.17314 | val_0_mse: 0.1675499975681305|  0:01:40s\n","epoch 79 | loss: 0.15599 | val_0_mse: 0.15313999354839325|  0:01:42s\n","epoch 80 | loss: 0.15688 | val_0_mse: 0.14628000557422638|  0:01:43s\n","epoch 81 | loss: 0.15948 | val_0_mse: 0.15252000093460083|  0:01:44s\n","epoch 82 | loss: 0.16877 | val_0_mse: 0.16574999690055847|  0:01:46s\n","epoch 83 | loss: 0.15531 | val_0_mse: 0.12759000062942505|  0:01:47s\n","epoch 84 | loss: 0.18114 | val_0_mse: 0.19986000657081604|  0:01:48s\n","epoch 85 | loss: 0.17339 | val_0_mse: 0.19156000018119812|  0:01:49s\n","epoch 86 | loss: 0.16772 | val_0_mse: 0.24386000633239746|  0:01:51s\n","epoch 87 | loss: 0.1922  | val_0_mse: 0.2490299940109253|  0:01:52s\n","epoch 88 | loss: 0.1761  | val_0_mse: 0.2577599883079529|  0:01:53s\n","epoch 89 | loss: 0.17396 | val_0_mse: 0.18490999937057495|  0:01:54s\n","epoch 90 | loss: 0.16512 | val_0_mse: 0.2334199994802475|  0:01:56s\n","epoch 91 | loss: 0.16378 | val_0_mse: 0.16572999954223633|  0:01:57s\n","epoch 92 | loss: 0.1511  | val_0_mse: 0.2200399935245514|  0:01:58s\n","epoch 93 | loss: 0.15949 | val_0_mse: 0.1678999960422516|  0:01:59s\n","\n","Early stopping occurred at epoch 93 with best_epoch = 83 and best_val_0_mse = 0.12759000062942505\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 11:16:35,743] Trial 1 finished with value: 0.12759467959403992 and parameters: {'n_d': 57, 'n_steps': 7, 'gamma': 1.535307161324784, 'n_independent': 3, 'n_shared': 4, 'momentum': 0.14238175249363208}. Best is trial 1 with value: 0.12759467959403992.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 61.15518| val_0_mse: 250577.90625|  0:00:01s\n","epoch 1  | loss: 5.24302 | val_0_mse: 19424.201171875|  0:00:02s\n","epoch 2  | loss: 1.30424 | val_0_mse: 7075.7470703125|  0:00:03s\n","epoch 3  | loss: 0.81674 | val_0_mse: 3264.983642578125|  0:00:04s\n","epoch 4  | loss: 0.56482 | val_0_mse: 1870.60986328125|  0:00:05s\n","epoch 5  | loss: 0.42857 | val_0_mse: 640.31005859375|  0:00:06s\n","epoch 6  | loss: 0.3855  | val_0_mse: 750.6838989257812|  0:00:07s\n","epoch 7  | loss: 0.31526 | val_0_mse: 220.97105407714844|  0:00:08s\n","epoch 8  | loss: 0.26519 | val_0_mse: 212.90208435058594|  0:00:09s\n","epoch 9  | loss: 0.23458 | val_0_mse: 109.98059844970703|  0:00:10s\n","epoch 10 | loss: 0.21702 | val_0_mse: 51.86043167114258|  0:00:11s\n","epoch 11 | loss: 0.21785 | val_0_mse: 14.781769752502441|  0:00:12s\n","epoch 12 | loss: 0.22194 | val_0_mse: 9.633600234985352|  0:00:14s\n","epoch 13 | loss: 0.21473 | val_0_mse: 6.638840198516846|  0:00:15s\n","epoch 14 | loss: 0.17328 | val_0_mse: 15.164839744567871|  0:00:16s\n","epoch 15 | loss: 0.17091 | val_0_mse: 32.3636589050293|  0:00:17s\n","epoch 16 | loss: 0.15727 | val_0_mse: 2.6022400856018066|  0:00:18s\n","epoch 17 | loss: 0.16991 | val_0_mse: 2.2872700691223145|  0:00:19s\n","epoch 18 | loss: 0.16822 | val_0_mse: 2.064199924468994|  0:00:20s\n","epoch 19 | loss: 0.18805 | val_0_mse: 5.526360034942627|  0:00:21s\n","epoch 20 | loss: 0.14904 | val_0_mse: 5.976140022277832|  0:00:22s\n","epoch 21 | loss: 0.1494  | val_0_mse: 7.592780113220215|  0:00:24s\n","epoch 22 | loss: 0.1463  | val_0_mse: 4.806159973144531|  0:00:25s\n","epoch 23 | loss: 0.17904 | val_0_mse: 7.730909824371338|  0:00:26s\n","epoch 24 | loss: 0.19497 | val_0_mse: 15.341580390930176|  0:00:27s\n","epoch 25 | loss: 0.1694  | val_0_mse: 5.9639201164245605|  0:00:28s\n","epoch 26 | loss: 0.16298 | val_0_mse: 6.305210113525391|  0:00:29s\n","epoch 27 | loss: 0.18255 | val_0_mse: 4.31279993057251|  0:00:30s\n","epoch 28 | loss: 0.15809 | val_0_mse: 2.5568199157714844|  0:00:31s\n","\n","Early stopping occurred at epoch 28 with best_epoch = 18 and best_val_0_mse = 2.064199924468994\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 11:17:08,211] Trial 2 finished with value: 2.0641977787017822 and parameters: {'n_d': 16, 'n_steps': 5, 'gamma': 1.318887539156387, 'n_independent': 4, 'n_shared': 4, 'momentum': 0.3800263992804687}. Best is trial 1 with value: 0.12759467959403992.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 119.54294| val_0_mse: 122693.921875|  0:00:01s\n","epoch 1  | loss: 31.27798| val_0_mse: 56191.328125|  0:00:02s\n","epoch 2  | loss: 7.26752 | val_0_mse: 100771.0546875|  0:00:03s\n","epoch 3  | loss: 3.77946 | val_0_mse: 23025.98828125|  0:00:03s\n","epoch 4  | loss: 1.8367  | val_0_mse: 3883.533203125|  0:00:04s\n","epoch 5  | loss: 1.75827 | val_0_mse: 5844.2548828125|  0:00:06s\n","epoch 6  | loss: 0.93545 | val_0_mse: 6141.09228515625|  0:00:07s\n","epoch 7  | loss: 0.92109 | val_0_mse: 16803.705078125|  0:00:08s\n","epoch 8  | loss: 0.80024 | val_0_mse: 737.5097045898438|  0:00:09s\n","epoch 9  | loss: 0.81598 | val_0_mse: 578.6539306640625|  0:00:10s\n","epoch 10 | loss: 0.74868 | val_0_mse: 695.4750366210938|  0:00:11s\n","epoch 11 | loss: 0.32037 | val_0_mse: 687.8184814453125|  0:00:12s\n","epoch 12 | loss: 0.29022 | val_0_mse: 128.7975311279297|  0:00:13s\n","epoch 13 | loss: 0.278   | val_0_mse: 157.9763641357422|  0:00:14s\n","epoch 14 | loss: 0.25627 | val_0_mse: 9.608650207519531|  0:00:15s\n","epoch 15 | loss: 0.23207 | val_0_mse: 28.121639251708984|  0:00:16s\n","epoch 16 | loss: 0.22404 | val_0_mse: 66.63056945800781|  0:00:17s\n","epoch 17 | loss: 0.23377 | val_0_mse: 13.432100296020508|  0:00:18s\n","epoch 18 | loss: 0.19181 | val_0_mse: 26.814659118652344|  0:00:19s\n","epoch 19 | loss: 0.2538  | val_0_mse: 15.887800216674805|  0:00:20s\n","epoch 20 | loss: 0.29832 | val_0_mse: 9.361209869384766|  0:00:21s\n","epoch 21 | loss: 0.32823 | val_0_mse: 17.11358070373535|  0:00:22s\n","epoch 22 | loss: 0.28618 | val_0_mse: 17.72831916809082|  0:00:23s\n","epoch 23 | loss: 0.26401 | val_0_mse: 17.680639266967773|  0:00:24s\n","epoch 24 | loss: 0.3065  | val_0_mse: 5.056069850921631|  0:00:25s\n","epoch 25 | loss: 0.21993 | val_0_mse: 6.201879978179932|  0:00:26s\n","epoch 26 | loss: 0.16687 | val_0_mse: 1.889840006828308|  0:00:27s\n","epoch 27 | loss: 0.1684  | val_0_mse: 0.8607100248336792|  0:00:28s\n","epoch 28 | loss: 0.20124 | val_0_mse: 1.7822099924087524|  0:00:29s\n","epoch 29 | loss: 0.2643  | val_0_mse: 0.939769983291626|  0:00:30s\n","epoch 30 | loss: 0.26085 | val_0_mse: 0.7508299946784973|  0:00:31s\n","epoch 31 | loss: 0.1931  | val_0_mse: 0.8188199996948242|  0:00:32s\n","epoch 32 | loss: 0.17007 | val_0_mse: 0.414110004901886|  0:00:33s\n","epoch 33 | loss: 0.26216 | val_0_mse: 0.36535000801086426|  0:00:34s\n","epoch 34 | loss: 0.31574 | val_0_mse: 0.7009400129318237|  0:00:35s\n","epoch 35 | loss: 0.32167 | val_0_mse: 0.47971001267433167|  0:00:36s\n","epoch 36 | loss: 0.2511  | val_0_mse: 0.33827000856399536|  0:00:37s\n","epoch 37 | loss: 0.24133 | val_0_mse: 0.3261699974536896|  0:00:38s\n","epoch 38 | loss: 0.1645  | val_0_mse: 0.32850998640060425|  0:00:39s\n","epoch 39 | loss: 0.15307 | val_0_mse: 0.29754000902175903|  0:00:40s\n","epoch 40 | loss: 0.15991 | val_0_mse: 0.3907099962234497|  0:00:41s\n","epoch 41 | loss: 0.1556  | val_0_mse: 0.3453400135040283|  0:00:43s\n","epoch 42 | loss: 0.14802 | val_0_mse: 0.24220000207424164|  0:00:44s\n","epoch 43 | loss: 0.15099 | val_0_mse: 0.270220011472702|  0:00:45s\n","epoch 44 | loss: 0.1417  | val_0_mse: 0.3377400040626526|  0:00:46s\n","epoch 45 | loss: 0.135   | val_0_mse: 0.2517299950122833|  0:00:47s\n","epoch 46 | loss: 0.12134 | val_0_mse: 0.26534000039100647|  0:00:48s\n","epoch 47 | loss: 0.12726 | val_0_mse: 0.31540000438690186|  0:00:49s\n","epoch 48 | loss: 0.14842 | val_0_mse: 0.3525699973106384|  0:00:50s\n","epoch 49 | loss: 0.13351 | val_0_mse: 0.16565999388694763|  0:00:51s\n","epoch 50 | loss: 0.15722 | val_0_mse: 0.1492300033569336|  0:00:52s\n","epoch 51 | loss: 0.14595 | val_0_mse: 0.14342999458312988|  0:00:53s\n","epoch 52 | loss: 0.12222 | val_0_mse: 0.19992999732494354|  0:00:54s\n","epoch 53 | loss: 0.12238 | val_0_mse: 0.22146999835968018|  0:00:55s\n","epoch 54 | loss: 0.14938 | val_0_mse: 0.14643999934196472|  0:00:56s\n","epoch 55 | loss: 0.15521 | val_0_mse: 0.252810001373291|  0:00:57s\n","epoch 56 | loss: 0.14388 | val_0_mse: 0.13686999678611755|  0:00:58s\n","epoch 57 | loss: 0.14616 | val_0_mse: 0.19814999401569366|  0:00:59s\n","epoch 58 | loss: 0.15166 | val_0_mse: 0.23738999664783478|  0:01:00s\n","epoch 59 | loss: 0.16816 | val_0_mse: 0.27994000911712646|  0:01:01s\n","epoch 60 | loss: 0.1504  | val_0_mse: 0.14591999351978302|  0:01:02s\n","epoch 61 | loss: 0.12766 | val_0_mse: 0.13377000391483307|  0:01:03s\n","epoch 62 | loss: 0.1302  | val_0_mse: 0.14138999581336975|  0:01:04s\n","epoch 63 | loss: 0.13058 | val_0_mse: 0.13745999336242676|  0:01:05s\n","epoch 64 | loss: 0.13504 | val_0_mse: 0.14374999701976776|  0:01:06s\n","epoch 65 | loss: 0.13991 | val_0_mse: 0.12921999394893646|  0:01:07s\n","epoch 66 | loss: 0.1374  | val_0_mse: 0.13871000707149506|  0:01:08s\n","epoch 67 | loss: 0.12659 | val_0_mse: 0.12703000009059906|  0:01:09s\n","epoch 68 | loss: 0.12448 | val_0_mse: 0.1359899938106537|  0:01:10s\n","epoch 69 | loss: 0.12345 | val_0_mse: 0.13293999433517456|  0:01:11s\n","epoch 70 | loss: 0.13398 | val_0_mse: 0.12977999448776245|  0:01:12s\n","epoch 71 | loss: 0.1397  | val_0_mse: 0.12110999971628189|  0:01:13s\n","epoch 72 | loss: 0.11993 | val_0_mse: 0.12364999949932098|  0:01:14s\n","epoch 73 | loss: 0.12691 | val_0_mse: 0.1411599963903427|  0:01:15s\n","epoch 74 | loss: 0.15041 | val_0_mse: 0.1314699947834015|  0:01:16s\n","epoch 75 | loss: 0.13538 | val_0_mse: 0.13366000354290009|  0:01:17s\n","epoch 76 | loss: 0.14157 | val_0_mse: 0.13736000657081604|  0:01:18s\n","epoch 77 | loss: 0.12628 | val_0_mse: 0.15410999953746796|  0:01:19s\n","epoch 78 | loss: 0.11982 | val_0_mse: 0.1414799988269806|  0:01:20s\n","epoch 79 | loss: 0.12061 | val_0_mse: 0.13420000672340393|  0:01:21s\n","epoch 80 | loss: 0.1129  | val_0_mse: 0.11269000172615051|  0:01:22s\n","epoch 81 | loss: 0.10783 | val_0_mse: 0.10890000313520432|  0:01:23s\n","epoch 82 | loss: 0.10949 | val_0_mse: 0.10672000050544739|  0:01:24s\n","epoch 83 | loss: 0.10661 | val_0_mse: 0.10554999858140945|  0:01:25s\n","epoch 84 | loss: 0.11635 | val_0_mse: 0.11994999647140503|  0:01:26s\n","epoch 85 | loss: 0.1059  | val_0_mse: 0.10506000369787216|  0:01:27s\n","epoch 86 | loss: 0.11594 | val_0_mse: 0.12269999831914902|  0:01:28s\n","epoch 87 | loss: 0.11214 | val_0_mse: 0.11494000256061554|  0:01:29s\n","epoch 88 | loss: 0.10336 | val_0_mse: 0.11203999817371368|  0:01:30s\n","epoch 89 | loss: 0.10659 | val_0_mse: 0.10425999760627747|  0:01:31s\n","epoch 90 | loss: 0.10248 | val_0_mse: 0.10621999949216843|  0:01:32s\n","epoch 91 | loss: 0.09833 | val_0_mse: 0.10081999748945236|  0:01:33s\n","epoch 92 | loss: 0.10041 | val_0_mse: 0.1044899970293045|  0:01:34s\n","epoch 93 | loss: 0.10576 | val_0_mse: 0.1039000004529953|  0:01:35s\n","epoch 94 | loss: 0.10291 | val_0_mse: 0.1109900027513504|  0:01:36s\n","epoch 95 | loss: 0.10479 | val_0_mse: 0.10154999792575836|  0:01:37s\n","epoch 96 | loss: 0.1061  | val_0_mse: 0.11151999980211258|  0:01:38s\n","epoch 97 | loss: 0.1078  | val_0_mse: 0.10970000177621841|  0:01:39s\n","epoch 98 | loss: 0.11162 | val_0_mse: 0.09995999932289124|  0:01:40s\n","epoch 99 | loss: 0.11419 | val_0_mse: 0.137130007147789|  0:01:41s\n","Stop training because you reached max_epochs = 100 with best_epoch = 98 and best_val_0_mse = 0.09995999932289124\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 11:18:50,156] Trial 3 finished with value: 0.09995829313993454 and parameters: {'n_d': 10, 'n_steps': 7, 'gamma': 1.9033357159726578, 'n_independent': 3, 'n_shared': 2, 'momentum': 0.23180238687965868}. Best is trial 3 with value: 0.09995829313993454.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 44.661  | val_0_mse: 223864.53125|  0:00:01s\n","epoch 1  | loss: 3.7685  | val_0_mse: 32088.173828125|  0:00:03s\n","epoch 2  | loss: 4.3001  | val_0_mse: 5257.61669921875|  0:00:04s\n","epoch 3  | loss: 2.24814 | val_0_mse: 16443.458984375|  0:00:06s\n","epoch 4  | loss: 1.52382 | val_0_mse: 30945.572265625|  0:00:07s\n","epoch 5  | loss: 1.50152 | val_0_mse: 584.89990234375|  0:00:09s\n","epoch 6  | loss: 0.69518 | val_0_mse: 2671.52099609375|  0:00:10s\n","epoch 7  | loss: 0.50719 | val_0_mse: 22.5869197845459|  0:00:12s\n","epoch 8  | loss: 0.45442 | val_0_mse: 61.27069854736328|  0:00:13s\n","epoch 9  | loss: 0.66816 | val_0_mse: 126.8984375|  0:00:15s\n","epoch 10 | loss: 1.164   | val_0_mse: 428.2922668457031|  0:00:17s\n","epoch 11 | loss: 1.46027 | val_0_mse: 223.63255310058594|  0:00:18s\n","epoch 12 | loss: 0.72608 | val_0_mse: 55.5955696105957|  0:00:20s\n","epoch 13 | loss: 0.55458 | val_0_mse: 24.024599075317383|  0:00:21s\n","epoch 14 | loss: 0.66249 | val_0_mse: 23.906719207763672|  0:00:23s\n","epoch 15 | loss: 0.59113 | val_0_mse: 130.2052001953125|  0:00:24s\n","epoch 16 | loss: 0.7103  | val_0_mse: 961.1036987304688|  0:00:26s\n","epoch 17 | loss: 0.61319 | val_0_mse: 253.70013427734375|  0:00:27s\n","\n","Early stopping occurred at epoch 17 with best_epoch = 7 and best_val_0_mse = 22.5869197845459\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 11:19:18,658] Trial 4 finished with value: 22.586923599243164 and parameters: {'n_d': 53, 'n_steps': 10, 'gamma': 1.244505821704345, 'n_independent': 1, 'n_shared': 5, 'momentum': 0.20083607661462993}. Best is trial 3 with value: 0.09995829313993454.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 62.21692| val_0_mse: 167664.9375|  0:00:01s\n","epoch 1  | loss: 6.89918 | val_0_mse: 9603.681640625|  0:00:02s\n","epoch 2  | loss: 2.22222 | val_0_mse: 9171.76171875|  0:00:04s\n","epoch 3  | loss: 1.02408 | val_0_mse: 1107.252197265625|  0:00:05s\n","epoch 4  | loss: 0.82396 | val_0_mse: 1537.5054931640625|  0:00:07s\n","epoch 5  | loss: 0.68244 | val_0_mse: 1338.8555908203125|  0:00:08s\n","epoch 6  | loss: 0.51505 | val_0_mse: 568.1080932617188|  0:00:09s\n","epoch 7  | loss: 0.4284  | val_0_mse: 467.0436096191406|  0:00:11s\n","epoch 8  | loss: 0.40321 | val_0_mse: 248.60064697265625|  0:00:12s\n","epoch 9  | loss: 0.79358 | val_0_mse: 374.1790466308594|  0:00:14s\n","epoch 10 | loss: 0.35613 | val_0_mse: 417.78369140625|  0:00:15s\n","epoch 11 | loss: 0.27386 | val_0_mse: 312.4207458496094|  0:00:16s\n","epoch 12 | loss: 0.30988 | val_0_mse: 174.8208465576172|  0:00:18s\n","epoch 13 | loss: 0.25876 | val_0_mse: 102.84229278564453|  0:00:19s\n","epoch 14 | loss: 0.36162 | val_0_mse: 41.7276611328125|  0:00:21s\n","epoch 15 | loss: 0.24457 | val_0_mse: 23.227100372314453|  0:00:22s\n","epoch 16 | loss: 0.23321 | val_0_mse: 19.387239456176758|  0:00:23s\n","epoch 17 | loss: 0.21436 | val_0_mse: 18.901060104370117|  0:00:25s\n","epoch 18 | loss: 0.20376 | val_0_mse: 29.40597915649414|  0:00:26s\n","epoch 19 | loss: 0.18201 | val_0_mse: 3.547529935836792|  0:00:28s\n","epoch 20 | loss: 0.22036 | val_0_mse: 3.77878999710083|  0:00:29s\n","epoch 21 | loss: 0.34742 | val_0_mse: 4.298110008239746|  0:00:31s\n","epoch 22 | loss: 0.29807 | val_0_mse: 0.8506199717521667|  0:00:32s\n","epoch 23 | loss: 0.20541 | val_0_mse: 0.4577000141143799|  0:00:33s\n","epoch 24 | loss: 0.23181 | val_0_mse: 0.47541001439094543|  0:00:35s\n","epoch 25 | loss: 0.2498  | val_0_mse: 0.5672900080680847|  0:00:36s\n","epoch 26 | loss: 0.18954 | val_0_mse: 0.41154998540878296|  0:00:38s\n","epoch 27 | loss: 0.21096 | val_0_mse: 0.3896999955177307|  0:00:39s\n","epoch 28 | loss: 0.22355 | val_0_mse: 0.41499999165534973|  0:00:41s\n","epoch 29 | loss: 0.31442 | val_0_mse: 0.6124699711799622|  0:00:42s\n","epoch 30 | loss: 0.30571 | val_0_mse: 0.6485999822616577|  0:00:43s\n","epoch 31 | loss: 0.26027 | val_0_mse: 0.7262099981307983|  0:00:45s\n","epoch 32 | loss: 0.28556 | val_0_mse: 0.4574100077152252|  0:00:46s\n","epoch 33 | loss: 0.28055 | val_0_mse: 0.33118000626564026|  0:00:47s\n","epoch 34 | loss: 0.25388 | val_0_mse: 0.29201000928878784|  0:00:49s\n","epoch 35 | loss: 0.1461  | val_0_mse: 0.26194000244140625|  0:00:50s\n","epoch 36 | loss: 0.19502 | val_0_mse: 0.26923999190330505|  0:00:52s\n","epoch 37 | loss: 0.21499 | val_0_mse: 0.26041001081466675|  0:00:53s\n","epoch 38 | loss: 0.15108 | val_0_mse: 0.21859000623226166|  0:00:55s\n","epoch 39 | loss: 0.13939 | val_0_mse: 0.22958999872207642|  0:00:56s\n","epoch 40 | loss: 0.14153 | val_0_mse: 0.25672000646591187|  0:00:57s\n","epoch 41 | loss: 0.15751 | val_0_mse: 0.21407000720500946|  0:00:59s\n","epoch 42 | loss: 0.1442  | val_0_mse: 0.19272999465465546|  0:01:00s\n","epoch 43 | loss: 0.14081 | val_0_mse: 0.20250999927520752|  0:01:02s\n","epoch 44 | loss: 0.13939 | val_0_mse: 0.18554000556468964|  0:01:03s\n","epoch 45 | loss: 0.13514 | val_0_mse: 0.20034000277519226|  0:01:05s\n","epoch 46 | loss: 0.15091 | val_0_mse: 0.3107599914073944|  0:01:06s\n","epoch 47 | loss: 0.15265 | val_0_mse: 0.2152400016784668|  0:01:07s\n","epoch 48 | loss: 0.13813 | val_0_mse: 0.19046999514102936|  0:01:09s\n","epoch 49 | loss: 0.13123 | val_0_mse: 0.19321000576019287|  0:01:10s\n","epoch 50 | loss: 0.13818 | val_0_mse: 0.18905000388622284|  0:01:12s\n","epoch 51 | loss: 0.13718 | val_0_mse: 0.17600999772548676|  0:01:13s\n","epoch 52 | loss: 0.12366 | val_0_mse: 0.1739100068807602|  0:01:15s\n","epoch 53 | loss: 0.12731 | val_0_mse: 0.188510000705719|  0:01:16s\n","epoch 54 | loss: 0.12734 | val_0_mse: 0.15411999821662903|  0:01:17s\n","epoch 55 | loss: 0.12516 | val_0_mse: 0.16288000345230103|  0:01:19s\n","epoch 56 | loss: 0.11667 | val_0_mse: 0.1627500057220459|  0:01:20s\n","epoch 57 | loss: 0.12191 | val_0_mse: 0.14163999259471893|  0:01:22s\n","epoch 58 | loss: 0.11617 | val_0_mse: 0.1326099932193756|  0:01:23s\n","epoch 59 | loss: 0.11541 | val_0_mse: 0.14955000579357147|  0:01:25s\n","epoch 60 | loss: 0.11274 | val_0_mse: 0.130840003490448|  0:01:26s\n","epoch 61 | loss: 0.1169  | val_0_mse: 0.12501999735832214|  0:01:28s\n","epoch 62 | loss: 0.11604 | val_0_mse: 0.12109000235795975|  0:01:29s\n","epoch 63 | loss: 0.10897 | val_0_mse: 0.11737000197172165|  0:01:31s\n","epoch 64 | loss: 0.13305 | val_0_mse: 0.30741000175476074|  0:01:32s\n","epoch 65 | loss: 0.24023 | val_0_mse: 0.16856999695301056|  0:01:34s\n","epoch 66 | loss: 0.13037 | val_0_mse: 0.1175599992275238|  0:01:35s\n","epoch 67 | loss: 0.12057 | val_0_mse: 0.11153999716043472|  0:01:37s\n","epoch 68 | loss: 0.11317 | val_0_mse: 0.12466000020503998|  0:01:38s\n","epoch 69 | loss: 0.11094 | val_0_mse: 0.12138000130653381|  0:01:39s\n","epoch 70 | loss: 0.10829 | val_0_mse: 0.11249999701976776|  0:01:41s\n","epoch 71 | loss: 0.10844 | val_0_mse: 0.11121000349521637|  0:01:42s\n","epoch 72 | loss: 0.1115  | val_0_mse: 0.12506000697612762|  0:01:44s\n","epoch 73 | loss: 0.11096 | val_0_mse: 0.1185000017285347|  0:01:45s\n","epoch 74 | loss: 0.10391 | val_0_mse: 0.10774999856948853|  0:01:47s\n","epoch 75 | loss: 0.10621 | val_0_mse: 0.10272999852895737|  0:01:48s\n","epoch 76 | loss: 0.11347 | val_0_mse: 0.20588000118732452|  0:01:50s\n","epoch 77 | loss: 0.13576 | val_0_mse: 0.12381000071763992|  0:01:51s\n","epoch 78 | loss: 0.15934 | val_0_mse: 0.16221000254154205|  0:01:52s\n","epoch 79 | loss: 0.1419  | val_0_mse: 0.13027000427246094|  0:01:54s\n","epoch 80 | loss: 0.13442 | val_0_mse: 0.17633000016212463|  0:01:55s\n","epoch 81 | loss: 0.1303  | val_0_mse: 0.13853999972343445|  0:01:57s\n","epoch 82 | loss: 0.12885 | val_0_mse: 0.16434000432491302|  0:01:58s\n","epoch 83 | loss: 0.12047 | val_0_mse: 0.14302000403404236|  0:02:00s\n","epoch 84 | loss: 0.12808 | val_0_mse: 0.1561799943447113|  0:02:01s\n","epoch 85 | loss: 0.12383 | val_0_mse: 0.14598999917507172|  0:02:02s\n","\n","Early stopping occurred at epoch 85 with best_epoch = 75 and best_val_0_mse = 0.10272999852895737\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 11:21:22,384] Trial 5 finished with value: 0.10272902250289917 and parameters: {'n_d': 25, 'n_steps': 7, 'gamma': 1.2558924546821708, 'n_independent': 5, 'n_shared': 3, 'momentum': 0.1824024579132416}. Best is trial 3 with value: 0.09995829313993454.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 38.78914| val_0_mse: 19196.8203125|  0:00:01s\n","epoch 1  | loss: 6.07851 | val_0_mse: 69521.8828125|  0:00:03s\n","epoch 2  | loss: 7.04211 | val_0_mse: 13541.6943359375|  0:00:04s\n","epoch 3  | loss: 19.40503| val_0_mse: 1193.136962890625|  0:00:06s\n","epoch 4  | loss: 7.22488 | val_0_mse: 1418.3455810546875|  0:00:07s\n","epoch 5  | loss: 6.69605 | val_0_mse: 255.11306762695312|  0:00:09s\n","epoch 6  | loss: 1.64343 | val_0_mse: 192.14486694335938|  0:00:11s\n","epoch 7  | loss: 3.61509 | val_0_mse: 681.0805053710938|  0:00:12s\n","epoch 8  | loss: 1.48174 | val_0_mse: 957.6506958007812|  0:00:14s\n","epoch 9  | loss: 1.44317 | val_0_mse: 265.2470703125|  0:00:15s\n","epoch 10 | loss: 0.84113 | val_0_mse: 156.1675567626953|  0:00:17s\n","epoch 11 | loss: 0.58641 | val_0_mse: 114.33056640625|  0:00:18s\n","epoch 12 | loss: 0.32015 | val_0_mse: 173.092041015625|  0:00:20s\n","epoch 13 | loss: 0.32016 | val_0_mse: 86.53536987304688|  0:00:22s\n","epoch 14 | loss: 0.43917 | val_0_mse: 69.5915298461914|  0:00:23s\n","epoch 15 | loss: 1.1313  | val_0_mse: 43.25651168823242|  0:00:25s\n","epoch 16 | loss: 1.09664 | val_0_mse: 95.26701354980469|  0:00:26s\n","epoch 17 | loss: 0.43435 | val_0_mse: 76.72651672363281|  0:00:28s\n","epoch 18 | loss: 0.33226 | val_0_mse: 15.0346097946167|  0:00:29s\n","epoch 19 | loss: 0.76242 | val_0_mse: 7.796679973602295|  0:00:31s\n","epoch 20 | loss: 0.97973 | val_0_mse: 7.107490062713623|  0:00:32s\n","epoch 21 | loss: 0.41504 | val_0_mse: 5.472390174865723|  0:00:34s\n","epoch 22 | loss: 0.30633 | val_0_mse: 5.414569854736328|  0:00:36s\n","epoch 23 | loss: 0.29559 | val_0_mse: 2.7035601139068604|  0:00:37s\n","epoch 24 | loss: 0.40561 | val_0_mse: 1.908400058746338|  0:00:39s\n","epoch 25 | loss: 0.42647 | val_0_mse: 0.8648800253868103|  0:00:40s\n","epoch 26 | loss: 0.30998 | val_0_mse: 0.6213099956512451|  0:00:42s\n","epoch 27 | loss: 0.28756 | val_0_mse: 0.958620011806488|  0:00:43s\n","epoch 28 | loss: 0.27091 | val_0_mse: 0.5532299876213074|  0:00:45s\n","epoch 29 | loss: 0.22336 | val_0_mse: 0.36535999178886414|  0:00:47s\n","epoch 30 | loss: 0.23582 | val_0_mse: 0.6135299801826477|  0:00:48s\n","epoch 31 | loss: 0.29846 | val_0_mse: 0.5899900197982788|  0:00:50s\n","epoch 32 | loss: 0.25607 | val_0_mse: 0.6993799805641174|  0:00:51s\n","epoch 33 | loss: 0.23455 | val_0_mse: 0.390749990940094|  0:00:53s\n","epoch 34 | loss: 0.23609 | val_0_mse: 0.3554700016975403|  0:00:54s\n","epoch 35 | loss: 0.29632 | val_0_mse: 0.3465000092983246|  0:00:56s\n","epoch 36 | loss: 0.1875  | val_0_mse: 0.3005799949169159|  0:00:58s\n","epoch 37 | loss: 0.19575 | val_0_mse: 0.4291299879550934|  0:00:59s\n","epoch 38 | loss: 0.17888 | val_0_mse: 0.24855999648571014|  0:01:01s\n","epoch 39 | loss: 0.15986 | val_0_mse: 0.2989499866962433|  0:01:02s\n","epoch 40 | loss: 0.27155 | val_0_mse: 0.41356000304222107|  0:01:04s\n","epoch 41 | loss: 0.33297 | val_0_mse: 0.9185400009155273|  0:01:05s\n","epoch 42 | loss: 0.56476 | val_0_mse: 0.4142099916934967|  0:01:07s\n","epoch 43 | loss: 0.18659 | val_0_mse: 0.27456000447273254|  0:01:08s\n","epoch 44 | loss: 0.15331 | val_0_mse: 0.3209899961948395|  0:01:10s\n","epoch 45 | loss: 0.16981 | val_0_mse: 0.2691499888896942|  0:01:11s\n","epoch 46 | loss: 0.15389 | val_0_mse: 0.2747200131416321|  0:01:13s\n","epoch 47 | loss: 0.18761 | val_0_mse: 0.27410000562667847|  0:01:15s\n","epoch 48 | loss: 0.15537 | val_0_mse: 0.1988700032234192|  0:01:16s\n","epoch 49 | loss: 0.1855  | val_0_mse: 0.22843000292778015|  0:01:18s\n","epoch 50 | loss: 0.17988 | val_0_mse: 0.23634999990463257|  0:01:19s\n","epoch 51 | loss: 0.21208 | val_0_mse: 0.36197999119758606|  0:01:21s\n","epoch 52 | loss: 0.20275 | val_0_mse: 0.22269000113010406|  0:01:22s\n","epoch 53 | loss: 0.17668 | val_0_mse: 0.46950000524520874|  0:01:24s\n","epoch 54 | loss: 0.19059 | val_0_mse: 0.21012000739574432|  0:01:25s\n","epoch 55 | loss: 0.17599 | val_0_mse: 0.18408000469207764|  0:01:27s\n","epoch 56 | loss: 0.26661 | val_0_mse: 0.271230012178421|  0:01:28s\n","epoch 57 | loss: 0.2448  | val_0_mse: 0.3749600052833557|  0:01:30s\n","epoch 58 | loss: 0.39818 | val_0_mse: 0.24817000329494476|  0:01:32s\n","epoch 59 | loss: 0.70607 | val_0_mse: 0.9212300181388855|  0:01:33s\n","epoch 60 | loss: 0.56586 | val_0_mse: 1.0435500144958496|  0:01:35s\n","epoch 61 | loss: 0.49419 | val_0_mse: 0.7731900215148926|  0:01:36s\n","epoch 62 | loss: 0.38302 | val_0_mse: 0.4924199879169464|  0:01:38s\n","epoch 63 | loss: 0.24723 | val_0_mse: 0.17892999947071075|  0:01:39s\n","epoch 64 | loss: 0.26638 | val_0_mse: 0.29388999938964844|  0:01:41s\n","epoch 65 | loss: 0.29037 | val_0_mse: 0.15725000202655792|  0:01:42s\n","epoch 66 | loss: 0.23532 | val_0_mse: 0.30037999153137207|  0:01:44s\n","epoch 67 | loss: 0.25738 | val_0_mse: 0.20523999631404877|  0:01:45s\n","epoch 68 | loss: 0.2043  | val_0_mse: 0.1942099928855896|  0:01:47s\n","epoch 69 | loss: 0.1613  | val_0_mse: 0.1586499959230423|  0:01:49s\n","epoch 70 | loss: 0.17235 | val_0_mse: 0.1960500031709671|  0:01:50s\n","epoch 71 | loss: 0.21043 | val_0_mse: 0.1468300074338913|  0:01:52s\n","epoch 72 | loss: 0.19364 | val_0_mse: 0.13615000247955322|  0:01:53s\n","epoch 73 | loss: 0.34384 | val_0_mse: 0.42566999793052673|  0:01:55s\n","epoch 74 | loss: 0.33886 | val_0_mse: 0.2541700005531311|  0:01:56s\n","epoch 75 | loss: 0.2673  | val_0_mse: 0.19436000287532806|  0:01:58s\n","epoch 76 | loss: 0.18841 | val_0_mse: 0.1832599937915802|  0:01:59s\n","epoch 77 | loss: 0.15977 | val_0_mse: 0.16269999742507935|  0:02:01s\n","epoch 78 | loss: 0.21192 | val_0_mse: 0.4021500051021576|  0:02:02s\n","epoch 79 | loss: 0.31731 | val_0_mse: 0.17023000121116638|  0:02:04s\n","epoch 80 | loss: 0.13536 | val_0_mse: 0.16967999935150146|  0:02:06s\n","epoch 81 | loss: 0.19673 | val_0_mse: 0.1579899936914444|  0:02:07s\n","epoch 82 | loss: 0.15206 | val_0_mse: 0.13680000603199005|  0:02:09s\n","\n","Early stopping occurred at epoch 82 with best_epoch = 72 and best_val_0_mse = 0.13615000247955322\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 11:23:32,225] Trial 6 finished with value: 0.1361493617296219 and parameters: {'n_d': 56, 'n_steps': 10, 'gamma': 1.7796502105417908, 'n_independent': 2, 'n_shared': 4, 'momentum': 0.21917471387683904}. Best is trial 3 with value: 0.09995829313993454.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 45.08315| val_0_mse: 49767.328125|  0:00:00s\n","epoch 1  | loss: 3.39036 | val_0_mse: 1304.786865234375|  0:00:01s\n","epoch 2  | loss: 1.11241 | val_0_mse: 221.87408447265625|  0:00:02s\n","epoch 3  | loss: 0.62254 | val_0_mse: 360.8001708984375|  0:00:03s\n","epoch 4  | loss: 0.40804 | val_0_mse: 758.2656860351562|  0:00:04s\n","epoch 5  | loss: 0.34908 | val_0_mse: 105.38770294189453|  0:00:05s\n","epoch 6  | loss: 0.30049 | val_0_mse: 90.08354949951172|  0:00:06s\n","epoch 7  | loss: 0.3112  | val_0_mse: 44.172340393066406|  0:00:07s\n","epoch 8  | loss: 0.35059 | val_0_mse: 21.493440628051758|  0:00:08s\n","epoch 9  | loss: 0.34136 | val_0_mse: 25.33938980102539|  0:00:09s\n","epoch 10 | loss: 0.22665 | val_0_mse: 21.90744972229004|  0:00:10s\n","epoch 11 | loss: 0.23469 | val_0_mse: 23.949960708618164|  0:00:11s\n","epoch 12 | loss: 0.24279 | val_0_mse: 28.656740188598633|  0:00:12s\n","epoch 13 | loss: 0.23005 | val_0_mse: 19.40838050842285|  0:00:12s\n","epoch 14 | loss: 0.21101 | val_0_mse: 19.139999389648438|  0:00:13s\n","epoch 15 | loss: 0.17258 | val_0_mse: 19.986669540405273|  0:00:14s\n","epoch 16 | loss: 0.18078 | val_0_mse: 9.850569725036621|  0:00:15s\n","epoch 17 | loss: 0.16696 | val_0_mse: 7.993350028991699|  0:00:16s\n","epoch 18 | loss: 0.19334 | val_0_mse: 7.466800212860107|  0:00:17s\n","epoch 19 | loss: 0.16095 | val_0_mse: 6.434939861297607|  0:00:18s\n","epoch 20 | loss: 0.20476 | val_0_mse: 3.32207989692688|  0:00:19s\n","epoch 21 | loss: 0.26411 | val_0_mse: 3.827280044555664|  0:00:20s\n","epoch 22 | loss: 0.23894 | val_0_mse: 2.068279981613159|  0:00:21s\n","epoch 23 | loss: 0.23122 | val_0_mse: 2.400059938430786|  0:00:22s\n","epoch 24 | loss: 0.2152  | val_0_mse: 2.0137600898742676|  0:00:23s\n","epoch 25 | loss: 0.20238 | val_0_mse: 2.345900058746338|  0:00:24s\n","epoch 26 | loss: 0.21912 | val_0_mse: 1.3938100337982178|  0:00:25s\n","epoch 27 | loss: 0.20446 | val_0_mse: 1.288640022277832|  0:00:25s\n","epoch 28 | loss: 0.2105  | val_0_mse: 0.516979992389679|  0:00:26s\n","epoch 29 | loss: 0.20701 | val_0_mse: 0.7570499777793884|  0:00:27s\n","epoch 30 | loss: 0.19233 | val_0_mse: 0.4360699951648712|  0:00:28s\n","epoch 31 | loss: 0.18419 | val_0_mse: 0.6920400261878967|  0:00:29s\n","epoch 32 | loss: 0.18299 | val_0_mse: 0.4239799976348877|  0:00:30s\n","epoch 33 | loss: 0.27533 | val_0_mse: 0.6091099977493286|  0:00:31s\n","epoch 34 | loss: 0.25776 | val_0_mse: 0.4379200041294098|  0:00:32s\n","epoch 35 | loss: 0.22791 | val_0_mse: 0.25922998785972595|  0:00:33s\n","epoch 36 | loss: 0.20513 | val_0_mse: 0.28891000151634216|  0:00:34s\n","epoch 37 | loss: 0.17748 | val_0_mse: 0.26030001044273376|  0:00:34s\n","epoch 38 | loss: 0.17582 | val_0_mse: 0.2862899899482727|  0:00:35s\n","epoch 39 | loss: 0.16585 | val_0_mse: 0.31964999437332153|  0:00:36s\n","epoch 40 | loss: 0.21064 | val_0_mse: 0.33656999468803406|  0:00:37s\n","epoch 41 | loss: 0.17663 | val_0_mse: 0.35155001282691956|  0:00:38s\n","epoch 42 | loss: 0.17649 | val_0_mse: 0.2148900032043457|  0:00:39s\n","epoch 43 | loss: 0.14789 | val_0_mse: 0.23280000686645508|  0:00:40s\n","epoch 44 | loss: 0.17835 | val_0_mse: 0.2002899944782257|  0:00:41s\n","epoch 45 | loss: 0.1636  | val_0_mse: 0.1969199925661087|  0:00:42s\n","epoch 46 | loss: 0.16994 | val_0_mse: 0.2408600002527237|  0:00:43s\n","epoch 47 | loss: 0.13926 | val_0_mse: 0.23569999635219574|  0:00:44s\n","epoch 48 | loss: 0.12567 | val_0_mse: 0.17002999782562256|  0:00:45s\n","epoch 49 | loss: 0.12342 | val_0_mse: 0.1895499974489212|  0:00:45s\n","epoch 50 | loss: 0.12328 | val_0_mse: 0.19009000062942505|  0:00:46s\n","epoch 51 | loss: 0.16548 | val_0_mse: 0.1558700054883957|  0:00:47s\n","epoch 52 | loss: 0.1602  | val_0_mse: 0.20799000561237335|  0:00:48s\n","epoch 53 | loss: 0.15371 | val_0_mse: 0.13423000276088715|  0:00:49s\n","epoch 54 | loss: 0.14764 | val_0_mse: 0.2439499944448471|  0:00:50s\n","epoch 55 | loss: 0.15067 | val_0_mse: 0.1370300054550171|  0:00:51s\n","epoch 56 | loss: 0.17202 | val_0_mse: 0.20430999994277954|  0:00:52s\n","epoch 57 | loss: 0.16559 | val_0_mse: 0.13568000495433807|  0:00:53s\n","epoch 58 | loss: 0.12396 | val_0_mse: 0.14653000235557556|  0:00:54s\n","epoch 59 | loss: 0.13656 | val_0_mse: 0.12455999851226807|  0:00:55s\n","epoch 60 | loss: 0.12616 | val_0_mse: 0.13957999646663666|  0:00:56s\n","epoch 61 | loss: 0.16248 | val_0_mse: 0.15910999476909637|  0:00:56s\n","epoch 62 | loss: 0.16575 | val_0_mse: 0.17507000267505646|  0:00:57s\n","epoch 63 | loss: 0.15241 | val_0_mse: 0.12705999612808228|  0:00:58s\n","epoch 64 | loss: 0.14614 | val_0_mse: 0.14723999798297882|  0:00:59s\n","epoch 65 | loss: 0.14517 | val_0_mse: 0.12443999946117401|  0:01:00s\n","epoch 66 | loss: 0.14592 | val_0_mse: 0.15341000258922577|  0:01:01s\n","epoch 67 | loss: 0.13881 | val_0_mse: 0.11336000263690948|  0:01:02s\n","epoch 68 | loss: 0.13657 | val_0_mse: 0.13569000363349915|  0:01:03s\n","epoch 69 | loss: 0.13062 | val_0_mse: 0.10707999765872955|  0:01:04s\n","epoch 70 | loss: 0.13094 | val_0_mse: 0.13214999437332153|  0:01:05s\n","epoch 71 | loss: 0.12743 | val_0_mse: 0.1097399964928627|  0:01:06s\n","epoch 72 | loss: 0.13269 | val_0_mse: 0.12937000393867493|  0:01:07s\n","epoch 73 | loss: 0.12528 | val_0_mse: 0.10226999968290329|  0:01:07s\n","epoch 74 | loss: 0.13196 | val_0_mse: 0.1289999932050705|  0:01:08s\n","epoch 75 | loss: 0.12263 | val_0_mse: 0.11229000240564346|  0:01:09s\n","epoch 76 | loss: 0.1295  | val_0_mse: 0.12223000079393387|  0:01:10s\n","epoch 77 | loss: 0.13075 | val_0_mse: 0.11591999977827072|  0:01:11s\n","epoch 78 | loss: 0.12268 | val_0_mse: 0.11878000199794769|  0:01:12s\n","epoch 79 | loss: 0.12846 | val_0_mse: 0.1163100004196167|  0:01:13s\n","epoch 80 | loss: 0.13214 | val_0_mse: 0.10999000072479248|  0:01:14s\n","epoch 81 | loss: 0.12843 | val_0_mse: 0.11979000270366669|  0:01:15s\n","epoch 82 | loss: 0.12484 | val_0_mse: 0.10705000162124634|  0:01:16s\n","epoch 83 | loss: 0.12443 | val_0_mse: 0.1064700037240982|  0:01:17s\n","\n","Early stopping occurred at epoch 83 with best_epoch = 73 and best_val_0_mse = 0.10226999968290329\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 11:24:49,707] Trial 7 finished with value: 0.10226794332265854 and parameters: {'n_d': 50, 'n_steps': 4, 'gamma': 1.8748472664378508, 'n_independent': 4, 'n_shared': 4, 'momentum': 0.031248554386822683}. Best is trial 3 with value: 0.09995829313993454.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 38.00843| val_0_mse: 433021.0625|  0:00:01s\n","epoch 1  | loss: 5.10512 | val_0_mse: 48921.875|  0:00:02s\n","epoch 2  | loss: 3.20903 | val_0_mse: 14770.16796875|  0:00:03s\n","epoch 3  | loss: 2.27928 | val_0_mse: 179.92762756347656|  0:00:05s\n","epoch 4  | loss: 1.58718 | val_0_mse: 3494.1748046875|  0:00:06s\n","epoch 5  | loss: 0.68245 | val_0_mse: 1109.2401123046875|  0:00:07s\n","epoch 6  | loss: 0.44418 | val_0_mse: 310.89410400390625|  0:00:09s\n","epoch 7  | loss: 0.69721 | val_0_mse: 659.9266967773438|  0:00:10s\n","epoch 8  | loss: 0.88814 | val_0_mse: 73.54785919189453|  0:00:11s\n","epoch 9  | loss: 0.56963 | val_0_mse: 24.20322036743164|  0:00:12s\n","epoch 10 | loss: 0.50038 | val_0_mse: 45.43191146850586|  0:00:14s\n","epoch 11 | loss: 0.48336 | val_0_mse: 118.7665023803711|  0:00:15s\n","epoch 12 | loss: 0.48206 | val_0_mse: 127.74813842773438|  0:00:16s\n","epoch 13 | loss: 0.33195 | val_0_mse: 56.708961486816406|  0:00:18s\n","epoch 14 | loss: 0.28195 | val_0_mse: 3.533440113067627|  0:00:19s\n","epoch 15 | loss: 0.41464 | val_0_mse: 50.323638916015625|  0:00:20s\n","epoch 16 | loss: 0.45254 | val_0_mse: 49.98114013671875|  0:00:22s\n","epoch 17 | loss: 0.35819 | val_0_mse: 73.97815704345703|  0:00:23s\n","epoch 18 | loss: 0.39666 | val_0_mse: 7.750879764556885|  0:00:24s\n","epoch 19 | loss: 0.69083 | val_0_mse: 141.4864959716797|  0:00:25s\n","epoch 20 | loss: 0.40289 | val_0_mse: 59.80345916748047|  0:00:27s\n","epoch 21 | loss: 0.38284 | val_0_mse: 2.458859920501709|  0:00:28s\n","epoch 22 | loss: 0.32245 | val_0_mse: 3.2729299068450928|  0:00:29s\n","epoch 23 | loss: 0.25145 | val_0_mse: 0.9731600284576416|  0:00:30s\n","epoch 24 | loss: 0.21344 | val_0_mse: 0.3899199962615967|  0:00:32s\n","epoch 25 | loss: 0.18935 | val_0_mse: 0.32635000348091125|  0:00:33s\n","epoch 26 | loss: 0.17303 | val_0_mse: 0.36682000756263733|  0:00:34s\n","epoch 27 | loss: 0.27172 | val_0_mse: 0.8266299962997437|  0:00:36s\n","epoch 28 | loss: 0.1857  | val_0_mse: 1.9204800128936768|  0:00:37s\n","epoch 29 | loss: 0.20416 | val_0_mse: 2.08951997756958|  0:00:38s\n","epoch 30 | loss: 0.3839  | val_0_mse: 0.7410399913787842|  0:00:40s\n","epoch 31 | loss: 0.25128 | val_0_mse: 0.4646100103855133|  0:00:41s\n","epoch 32 | loss: 0.25896 | val_0_mse: 0.6365799903869629|  0:00:42s\n","epoch 33 | loss: 0.26601 | val_0_mse: 0.2997100055217743|  0:00:43s\n","epoch 34 | loss: 0.2465  | val_0_mse: 0.5308899879455566|  0:00:45s\n","epoch 35 | loss: 0.28218 | val_0_mse: 0.28227999806404114|  0:00:46s\n","epoch 36 | loss: 0.22268 | val_0_mse: 0.3264000117778778|  0:00:47s\n","epoch 37 | loss: 0.23462 | val_0_mse: 0.47767001390457153|  0:00:49s\n","epoch 38 | loss: 0.38709 | val_0_mse: 0.8148599863052368|  0:00:50s\n","epoch 39 | loss: 0.27693 | val_0_mse: 0.6210600137710571|  0:00:51s\n","epoch 40 | loss: 0.2587  | val_0_mse: 0.2214300036430359|  0:00:52s\n","epoch 41 | loss: 0.26786 | val_0_mse: 0.36458998918533325|  0:00:54s\n","epoch 42 | loss: 0.24169 | val_0_mse: 0.265749990940094|  0:00:55s\n","epoch 43 | loss: 0.25216 | val_0_mse: 0.39948999881744385|  0:00:56s\n","epoch 44 | loss: 0.25779 | val_0_mse: 0.21956999599933624|  0:00:58s\n","epoch 45 | loss: 0.21874 | val_0_mse: 0.22920000553131104|  0:00:59s\n","epoch 46 | loss: 0.23942 | val_0_mse: 0.1851699948310852|  0:01:00s\n","epoch 47 | loss: 0.22348 | val_0_mse: 0.18242000043392181|  0:01:01s\n","epoch 48 | loss: 0.15876 | val_0_mse: 0.16440999507904053|  0:01:03s\n","epoch 49 | loss: 0.24515 | val_0_mse: 0.42089998722076416|  0:01:04s\n","epoch 50 | loss: 0.29263 | val_0_mse: 0.15327000617980957|  0:01:05s\n","epoch 51 | loss: 0.14058 | val_0_mse: 0.24214999377727509|  0:01:07s\n","epoch 52 | loss: 0.32411 | val_0_mse: 0.6062300205230713|  0:01:08s\n","epoch 53 | loss: 0.25032 | val_0_mse: 0.18027999997138977|  0:01:09s\n","epoch 54 | loss: 0.23158 | val_0_mse: 0.209989994764328|  0:01:10s\n","epoch 55 | loss: 0.18462 | val_0_mse: 0.15092000365257263|  0:01:11s\n","epoch 56 | loss: 0.17767 | val_0_mse: 0.5301200151443481|  0:01:13s\n","epoch 57 | loss: 0.3391  | val_0_mse: 0.22713999450206757|  0:01:14s\n","epoch 58 | loss: 0.21735 | val_0_mse: 0.24987000226974487|  0:01:15s\n","epoch 59 | loss: 0.29031 | val_0_mse: 0.16749000549316406|  0:01:17s\n","epoch 60 | loss: 0.22161 | val_0_mse: 0.15636000037193298|  0:01:18s\n","epoch 61 | loss: 0.18103 | val_0_mse: 0.20413999259471893|  0:01:19s\n","epoch 62 | loss: 0.18219 | val_0_mse: 0.18416999280452728|  0:01:21s\n","epoch 63 | loss: 0.19013 | val_0_mse: 0.3124200105667114|  0:01:22s\n","epoch 64 | loss: 0.32304 | val_0_mse: 0.4408800005912781|  0:01:23s\n","epoch 65 | loss: 0.33494 | val_0_mse: 0.3921000063419342|  0:01:24s\n","\n","Early stopping occurred at epoch 65 with best_epoch = 55 and best_val_0_mse = 0.15092000365257263\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 11:26:15,088] Trial 8 finished with value: 0.15092313289642334 and parameters: {'n_d': 60, 'n_steps': 7, 'gamma': 1.7895979447259527, 'n_independent': 5, 'n_shared': 2, 'momentum': 0.020513243709782088}. Best is trial 3 with value: 0.09995829313993454.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 29.36794| val_0_mse: 6404.8359375|  0:00:00s\n","epoch 1  | loss: 2.5546  | val_0_mse: 7574.44482421875|  0:00:01s\n","epoch 2  | loss: 1.00376 | val_0_mse: 5411.4775390625|  0:00:02s\n","epoch 3  | loss: 0.50898 | val_0_mse: 6443.09375|  0:00:03s\n","epoch 4  | loss: 0.38572 | val_0_mse: 3108.58984375|  0:00:04s\n","epoch 5  | loss: 0.37933 | val_0_mse: 140.44903564453125|  0:00:05s\n","epoch 6  | loss: 0.5175  | val_0_mse: 51.87736129760742|  0:00:06s\n","epoch 7  | loss: 0.33497 | val_0_mse: 63.079139709472656|  0:00:07s\n","epoch 8  | loss: 0.29613 | val_0_mse: 37.09077835083008|  0:00:08s\n","epoch 9  | loss: 0.28115 | val_0_mse: 111.82845306396484|  0:00:08s\n","epoch 10 | loss: 0.40111 | val_0_mse: 93.55948638916016|  0:00:09s\n","epoch 11 | loss: 0.40311 | val_0_mse: 42.34469985961914|  0:00:10s\n","epoch 12 | loss: 0.34144 | val_0_mse: 53.240501403808594|  0:00:11s\n","epoch 13 | loss: 0.26916 | val_0_mse: 13.464719772338867|  0:00:12s\n","epoch 14 | loss: 0.45246 | val_0_mse: 7.81866979598999|  0:00:13s\n","epoch 15 | loss: 0.38189 | val_0_mse: 18.181360244750977|  0:00:14s\n","epoch 16 | loss: 0.44793 | val_0_mse: 12.331649780273438|  0:00:15s\n","epoch 17 | loss: 0.27882 | val_0_mse: 14.992879867553711|  0:00:16s\n","epoch 18 | loss: 0.28479 | val_0_mse: 90.84512329101562|  0:00:16s\n","epoch 19 | loss: 0.35355 | val_0_mse: 25.81382942199707|  0:00:17s\n","epoch 20 | loss: 0.22757 | val_0_mse: 19.820720672607422|  0:00:18s\n","epoch 21 | loss: 0.21808 | val_0_mse: 18.84623908996582|  0:00:19s\n","epoch 22 | loss: 0.2151  | val_0_mse: 8.754599571228027|  0:00:20s\n","epoch 23 | loss: 0.18539 | val_0_mse: 6.850279808044434|  0:00:21s\n","epoch 24 | loss: 0.15977 | val_0_mse: 2.388700008392334|  0:00:22s\n","epoch 25 | loss: 0.15183 | val_0_mse: 2.7560200691223145|  0:00:23s\n","epoch 26 | loss: 0.14156 | val_0_mse: 3.1123099327087402|  0:00:24s\n","epoch 27 | loss: 0.13603 | val_0_mse: 2.013200044631958|  0:00:24s\n","epoch 28 | loss: 0.14092 | val_0_mse: 1.1741600036621094|  0:00:25s\n","epoch 29 | loss: 0.20066 | val_0_mse: 1.5569900274276733|  0:00:26s\n","epoch 30 | loss: 0.20344 | val_0_mse: 1.506700038909912|  0:00:27s\n","epoch 31 | loss: 0.18776 | val_0_mse: 0.580780029296875|  0:00:28s\n","epoch 32 | loss: 0.18252 | val_0_mse: 0.829069972038269|  0:00:29s\n","epoch 33 | loss: 0.15821 | val_0_mse: 0.441540002822876|  0:00:30s\n","epoch 34 | loss: 0.1627  | val_0_mse: 0.3608799874782562|  0:00:31s\n","epoch 35 | loss: 0.17361 | val_0_mse: 0.3015899956226349|  0:00:31s\n","epoch 36 | loss: 0.16867 | val_0_mse: 0.37487998604774475|  0:00:32s\n","epoch 37 | loss: 0.15472 | val_0_mse: 0.2694999873638153|  0:00:33s\n","epoch 38 | loss: 0.15882 | val_0_mse: 0.496289998292923|  0:00:34s\n","epoch 39 | loss: 0.14989 | val_0_mse: 0.22244000434875488|  0:00:35s\n","epoch 40 | loss: 0.15215 | val_0_mse: 0.412990003824234|  0:00:36s\n","epoch 41 | loss: 0.15646 | val_0_mse: 0.2071399986743927|  0:00:37s\n","epoch 42 | loss: 0.14362 | val_0_mse: 0.2884199917316437|  0:00:38s\n","epoch 43 | loss: 0.14927 | val_0_mse: 0.17607000470161438|  0:00:39s\n","epoch 44 | loss: 0.14835 | val_0_mse: 0.34521999955177307|  0:00:40s\n","epoch 45 | loss: 0.14166 | val_0_mse: 0.17162999510765076|  0:00:40s\n","epoch 46 | loss: 0.15449 | val_0_mse: 0.3183799982070923|  0:00:41s\n","epoch 47 | loss: 0.14538 | val_0_mse: 0.1532299965620041|  0:00:42s\n","epoch 48 | loss: 0.14664 | val_0_mse: 0.27309998869895935|  0:00:43s\n","epoch 49 | loss: 0.14232 | val_0_mse: 0.1555899977684021|  0:00:44s\n","epoch 50 | loss: 0.14719 | val_0_mse: 0.2537899911403656|  0:00:45s\n","epoch 51 | loss: 0.14302 | val_0_mse: 0.15964999794960022|  0:00:46s\n","epoch 52 | loss: 0.14212 | val_0_mse: 0.2003600001335144|  0:00:47s\n","epoch 53 | loss: 0.14342 | val_0_mse: 0.14395999908447266|  0:00:48s\n","epoch 54 | loss: 0.14632 | val_0_mse: 0.20032000541687012|  0:00:48s\n","epoch 55 | loss: 0.14178 | val_0_mse: 0.13425999879837036|  0:00:49s\n","epoch 56 | loss: 0.14578 | val_0_mse: 0.18499000370502472|  0:00:50s\n","epoch 57 | loss: 0.13867 | val_0_mse: 0.13048000633716583|  0:00:51s\n","epoch 58 | loss: 0.13646 | val_0_mse: 0.16190999746322632|  0:00:52s\n","epoch 59 | loss: 0.13761 | val_0_mse: 0.13030999898910522|  0:00:53s\n","epoch 60 | loss: 0.14755 | val_0_mse: 0.15463000535964966|  0:00:54s\n","epoch 61 | loss: 0.13259 | val_0_mse: 0.1070299968123436|  0:00:55s\n","epoch 62 | loss: 0.14427 | val_0_mse: 0.17114000022411346|  0:00:56s\n","epoch 63 | loss: 0.1348  | val_0_mse: 0.11399000138044357|  0:00:56s\n","epoch 64 | loss: 0.13684 | val_0_mse: 0.17761999368667603|  0:00:57s\n","epoch 65 | loss: 0.13917 | val_0_mse: 0.12320999801158905|  0:00:58s\n","epoch 66 | loss: 0.13692 | val_0_mse: 0.18568000197410583|  0:00:59s\n","epoch 67 | loss: 0.14874 | val_0_mse: 0.12547999620437622|  0:01:00s\n","epoch 68 | loss: 0.13387 | val_0_mse: 0.16362999379634857|  0:01:01s\n","epoch 69 | loss: 0.13141 | val_0_mse: 0.1363299936056137|  0:01:02s\n","epoch 70 | loss: 0.12741 | val_0_mse: 0.14187000691890717|  0:01:03s\n","epoch 71 | loss: 0.11028 | val_0_mse: 0.12094999849796295|  0:01:04s\n","\n","Early stopping occurred at epoch 71 with best_epoch = 61 and best_val_0_mse = 0.1070299968123436\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 11:27:19,611] Trial 9 finished with value: 0.10702574998140335 and parameters: {'n_d': 63, 'n_steps': 5, 'gamma': 1.410487289597009, 'n_independent': 5, 'n_shared': 1, 'momentum': 0.25602453717276863}. Best is trial 3 with value: 0.09995829313993454.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 79.53661| val_0_mse: 31960.27734375|  0:00:00s\n","epoch 1  | loss: 16.68315| val_0_mse: 253558.65625|  0:00:01s\n","epoch 2  | loss: 5.20828 | val_0_mse: 11964.5615234375|  0:00:02s\n","epoch 3  | loss: 2.7088  | val_0_mse: 1823.984375|  0:00:03s\n","epoch 4  | loss: 1.93184 | val_0_mse: 4479.63232421875|  0:00:03s\n","epoch 5  | loss: 0.82311 | val_0_mse: 438.0045471191406|  0:00:04s\n","epoch 6  | loss: 0.4742  | val_0_mse: 559.17724609375|  0:00:05s\n","epoch 7  | loss: 0.4265  | val_0_mse: 1362.18896484375|  0:00:06s\n","epoch 8  | loss: 0.377   | val_0_mse: 503.7178649902344|  0:00:07s\n","epoch 9  | loss: 0.31358 | val_0_mse: 175.39126586914062|  0:00:08s\n","epoch 10 | loss: 0.30496 | val_0_mse: 137.59291076660156|  0:00:08s\n","epoch 11 | loss: 0.2991  | val_0_mse: 380.6746520996094|  0:00:09s\n","epoch 12 | loss: 0.30571 | val_0_mse: 132.7115020751953|  0:00:10s\n","epoch 13 | loss: 0.33732 | val_0_mse: 66.70809936523438|  0:00:11s\n","epoch 14 | loss: 0.28163 | val_0_mse: 43.03812026977539|  0:00:12s\n","epoch 15 | loss: 0.2661  | val_0_mse: 30.354780197143555|  0:00:13s\n","epoch 16 | loss: 0.23427 | val_0_mse: 40.54697036743164|  0:00:13s\n","epoch 17 | loss: 0.22788 | val_0_mse: 25.37537956237793|  0:00:14s\n","epoch 18 | loss: 0.19936 | val_0_mse: 19.31930923461914|  0:00:15s\n","epoch 19 | loss: 0.21607 | val_0_mse: 12.364910125732422|  0:00:16s\n","epoch 20 | loss: 0.20738 | val_0_mse: 8.67611026763916|  0:00:17s\n","epoch 21 | loss: 0.23417 | val_0_mse: 6.187819957733154|  0:00:17s\n","epoch 22 | loss: 0.20224 | val_0_mse: 6.990570068359375|  0:00:18s\n","epoch 23 | loss: 0.2158  | val_0_mse: 3.404449939727783|  0:00:19s\n","epoch 24 | loss: 0.18154 | val_0_mse: 3.217439889907837|  0:00:20s\n","epoch 25 | loss: 0.17795 | val_0_mse: 1.860640048980713|  0:00:21s\n","epoch 26 | loss: 0.21691 | val_0_mse: 1.6632200479507446|  0:00:22s\n","epoch 27 | loss: 0.20347 | val_0_mse: 1.531790018081665|  0:00:22s\n","epoch 28 | loss: 0.22205 | val_0_mse: 1.299839973449707|  0:00:23s\n","epoch 29 | loss: 0.24415 | val_0_mse: 0.9462800025939941|  0:00:24s\n","epoch 30 | loss: 0.19479 | val_0_mse: 0.6858999729156494|  0:00:25s\n","epoch 31 | loss: 0.18053 | val_0_mse: 0.8391900062561035|  0:00:26s\n","epoch 32 | loss: 0.27942 | val_0_mse: 0.9470999836921692|  0:00:27s\n","epoch 33 | loss: 0.23848 | val_0_mse: 0.5593699812889099|  0:00:27s\n","epoch 34 | loss: 0.23039 | val_0_mse: 0.5378100275993347|  0:00:28s\n","epoch 35 | loss: 0.23379 | val_0_mse: 0.5172899961471558|  0:00:29s\n","epoch 36 | loss: 0.22405 | val_0_mse: 0.5164399743080139|  0:00:30s\n","epoch 37 | loss: 0.21399 | val_0_mse: 0.40206000208854675|  0:00:31s\n","epoch 38 | loss: 0.2033  | val_0_mse: 0.38523998856544495|  0:00:32s\n","epoch 39 | loss: 0.20446 | val_0_mse: 0.3858200013637543|  0:00:32s\n","epoch 40 | loss: 0.21454 | val_0_mse: 0.31801000237464905|  0:00:33s\n","epoch 41 | loss: 0.16087 | val_0_mse: 0.47745999693870544|  0:00:34s\n","epoch 42 | loss: 0.20073 | val_0_mse: 0.38628000020980835|  0:00:35s\n","epoch 43 | loss: 0.16818 | val_0_mse: 0.2877500057220459|  0:00:36s\n","epoch 44 | loss: 0.15317 | val_0_mse: 0.25501999258995056|  0:00:36s\n","epoch 45 | loss: 0.15015 | val_0_mse: 0.224590003490448|  0:00:37s\n","epoch 46 | loss: 0.15085 | val_0_mse: 0.21747000515460968|  0:00:38s\n","epoch 47 | loss: 0.14878 | val_0_mse: 0.19809000194072723|  0:00:39s\n","epoch 48 | loss: 0.16502 | val_0_mse: 0.2232699990272522|  0:00:40s\n","epoch 49 | loss: 0.17108 | val_0_mse: 0.2616400122642517|  0:00:41s\n","epoch 50 | loss: 0.22801 | val_0_mse: 0.23467999696731567|  0:00:41s\n","epoch 51 | loss: 0.23083 | val_0_mse: 0.18413999676704407|  0:00:42s\n","epoch 52 | loss: 0.21184 | val_0_mse: 0.19191999733448029|  0:00:43s\n","epoch 53 | loss: 0.16587 | val_0_mse: 0.1662600040435791|  0:00:44s\n","epoch 54 | loss: 0.13153 | val_0_mse: 0.17353999614715576|  0:00:45s\n","epoch 55 | loss: 0.16957 | val_0_mse: 0.15053999423980713|  0:00:46s\n","epoch 56 | loss: 0.12928 | val_0_mse: 0.1542699933052063|  0:00:46s\n","epoch 57 | loss: 0.12918 | val_0_mse: 0.16502000391483307|  0:00:47s\n","epoch 58 | loss: 0.1304  | val_0_mse: 0.14861999452114105|  0:00:48s\n","epoch 59 | loss: 0.14517 | val_0_mse: 0.19643999636173248|  0:00:49s\n","epoch 60 | loss: 0.1536  | val_0_mse: 0.15941999852657318|  0:00:50s\n","epoch 61 | loss: 0.18163 | val_0_mse: 0.2536599934101105|  0:00:50s\n","epoch 62 | loss: 0.22441 | val_0_mse: 0.43463999032974243|  0:00:51s\n","epoch 63 | loss: 0.35197 | val_0_mse: 0.1739100068807602|  0:00:52s\n","epoch 64 | loss: 0.24745 | val_0_mse: 0.20369000732898712|  0:00:53s\n","epoch 65 | loss: 0.26453 | val_0_mse: 0.298660010099411|  0:00:54s\n","epoch 66 | loss: 0.20351 | val_0_mse: 0.17860999703407288|  0:00:54s\n","epoch 67 | loss: 0.17505 | val_0_mse: 0.22327999770641327|  0:00:55s\n","epoch 68 | loss: 0.1653  | val_0_mse: 0.1611499935388565|  0:00:56s\n","\n","Early stopping occurred at epoch 68 with best_epoch = 58 and best_val_0_mse = 0.14861999452114105\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 11:28:16,581] Trial 10 finished with value: 0.14861977100372314 and parameters: {'n_d': 10, 'n_steps': 8, 'gamma': 1.9777809071940897, 'n_independent': 2, 'n_shared': 1, 'momentum': 0.3211480645880235}. Best is trial 3 with value: 0.09995829313993454.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 29.89072| val_0_mse: 31813.130859375|  0:00:00s\n","epoch 1  | loss: 1.08609 | val_0_mse: 4649.52587890625|  0:00:01s\n","epoch 2  | loss: 0.6293  | val_0_mse: 466.21173095703125|  0:00:02s\n","epoch 3  | loss: 0.46589 | val_0_mse: 6518.4248046875|  0:00:02s\n","epoch 4  | loss: 0.40711 | val_0_mse: 1482.38037109375|  0:00:03s\n","epoch 5  | loss: 0.35346 | val_0_mse: 1608.1920166015625|  0:00:03s\n","epoch 6  | loss: 0.29085 | val_0_mse: 3387.751953125|  0:00:04s\n","epoch 7  | loss: 0.32864 | val_0_mse: 1552.48388671875|  0:00:05s\n","epoch 8  | loss: 0.27781 | val_0_mse: 2050.225341796875|  0:00:05s\n","epoch 9  | loss: 0.28556 | val_0_mse: 601.7047119140625|  0:00:06s\n","epoch 10 | loss: 0.25428 | val_0_mse: 467.2451477050781|  0:00:07s\n","epoch 11 | loss: 0.23788 | val_0_mse: 196.78720092773438|  0:00:07s\n","epoch 12 | loss: 0.19129 | val_0_mse: 75.21320343017578|  0:00:08s\n","epoch 13 | loss: 0.18948 | val_0_mse: 27.41407012939453|  0:00:09s\n","epoch 14 | loss: 0.20106 | val_0_mse: 31.32607078552246|  0:00:09s\n","epoch 15 | loss: 0.19161 | val_0_mse: 20.442169189453125|  0:00:10s\n","epoch 16 | loss: 0.16294 | val_0_mse: 9.17350959777832|  0:00:11s\n","epoch 17 | loss: 0.18397 | val_0_mse: 11.287759780883789|  0:00:12s\n","epoch 18 | loss: 0.16076 | val_0_mse: 9.35260009765625|  0:00:12s\n","epoch 19 | loss: 0.15922 | val_0_mse: 17.629180908203125|  0:00:13s\n","epoch 20 | loss: 0.15617 | val_0_mse: 14.498970031738281|  0:00:14s\n","epoch 21 | loss: 0.19798 | val_0_mse: 3.1764299869537354|  0:00:14s\n","epoch 22 | loss: 0.14553 | val_0_mse: 3.239759922027588|  0:00:15s\n","epoch 23 | loss: 0.17944 | val_0_mse: 2.8183999061584473|  0:00:16s\n","epoch 24 | loss: 0.14263 | val_0_mse: 1.7802499532699585|  0:00:16s\n","epoch 25 | loss: 0.12982 | val_0_mse: 1.964050054550171|  0:00:17s\n","epoch 26 | loss: 0.15246 | val_0_mse: 1.9292700290679932|  0:00:18s\n","epoch 27 | loss: 0.15158 | val_0_mse: 1.458490014076233|  0:00:18s\n","epoch 28 | loss: 0.1464  | val_0_mse: 2.0325798988342285|  0:00:19s\n","epoch 29 | loss: 0.14626 | val_0_mse: 1.6465599536895752|  0:00:20s\n","epoch 30 | loss: 0.13843 | val_0_mse: 0.8179900050163269|  0:00:20s\n","epoch 31 | loss: 0.14292 | val_0_mse: 0.36438000202178955|  0:00:21s\n","epoch 32 | loss: 0.1543  | val_0_mse: 0.424919992685318|  0:00:22s\n","epoch 33 | loss: 0.13881 | val_0_mse: 0.6027200222015381|  0:00:22s\n","epoch 34 | loss: 0.17306 | val_0_mse: 0.4775800108909607|  0:00:23s\n","epoch 35 | loss: 0.18618 | val_0_mse: 0.3833500146865845|  0:00:23s\n","epoch 36 | loss: 0.14903 | val_0_mse: 0.45844998955726624|  0:00:24s\n","epoch 37 | loss: 0.15882 | val_0_mse: 0.3481200039386749|  0:00:25s\n","epoch 38 | loss: 0.12402 | val_0_mse: 0.34918999671936035|  0:00:25s\n","epoch 39 | loss: 0.13896 | val_0_mse: 0.3728800117969513|  0:00:26s\n","epoch 40 | loss: 0.17472 | val_0_mse: 0.35005998611450195|  0:00:27s\n","epoch 41 | loss: 0.14326 | val_0_mse: 0.27136000990867615|  0:00:27s\n","epoch 42 | loss: 0.14125 | val_0_mse: 0.25409001111984253|  0:00:28s\n","epoch 43 | loss: 0.12749 | val_0_mse: 0.261680006980896|  0:00:29s\n","epoch 44 | loss: 0.12948 | val_0_mse: 0.23778000473976135|  0:00:29s\n","epoch 45 | loss: 0.12836 | val_0_mse: 0.24899999797344208|  0:00:30s\n","epoch 46 | loss: 0.13924 | val_0_mse: 0.23074999451637268|  0:00:31s\n","epoch 47 | loss: 0.15553 | val_0_mse: 0.24424000084400177|  0:00:31s\n","epoch 48 | loss: 0.25659 | val_0_mse: 0.20258000493049622|  0:00:32s\n","epoch 49 | loss: 0.12957 | val_0_mse: 0.1759600043296814|  0:00:33s\n","epoch 50 | loss: 0.12729 | val_0_mse: 0.18220999836921692|  0:00:33s\n","epoch 51 | loss: 0.16404 | val_0_mse: 0.20396000146865845|  0:00:34s\n","epoch 52 | loss: 0.15469 | val_0_mse: 0.21182000637054443|  0:00:35s\n","epoch 53 | loss: 0.15331 | val_0_mse: 0.14086000621318817|  0:00:35s\n","epoch 54 | loss: 0.14113 | val_0_mse: 0.2133300006389618|  0:00:36s\n","epoch 55 | loss: 0.14759 | val_0_mse: 0.1386599987745285|  0:00:37s\n","epoch 56 | loss: 0.14318 | val_0_mse: 0.19193999469280243|  0:00:37s\n","epoch 57 | loss: 0.15168 | val_0_mse: 0.13360999524593353|  0:00:38s\n","epoch 58 | loss: 0.1461  | val_0_mse: 0.1662299931049347|  0:00:39s\n","epoch 59 | loss: 0.11844 | val_0_mse: 0.1699800044298172|  0:00:39s\n","epoch 60 | loss: 0.11852 | val_0_mse: 0.14125999808311462|  0:00:40s\n","epoch 61 | loss: 0.11239 | val_0_mse: 0.14384999871253967|  0:00:41s\n","epoch 62 | loss: 0.1215  | val_0_mse: 0.12144999951124191|  0:00:41s\n","epoch 63 | loss: 0.12268 | val_0_mse: 0.1412300020456314|  0:00:42s\n","epoch 64 | loss: 0.11859 | val_0_mse: 0.14706000685691833|  0:00:43s\n","epoch 65 | loss: 0.14475 | val_0_mse: 0.12602999806404114|  0:00:43s\n","epoch 66 | loss: 0.14105 | val_0_mse: 0.12949000298976898|  0:00:44s\n","epoch 67 | loss: 0.14829 | val_0_mse: 0.18568000197410583|  0:00:45s\n","epoch 68 | loss: 0.14493 | val_0_mse: 0.1220100000500679|  0:00:45s\n","epoch 69 | loss: 0.12579 | val_0_mse: 0.12387000024318695|  0:00:46s\n","epoch 70 | loss: 0.12595 | val_0_mse: 0.121799997985363|  0:00:46s\n","epoch 71 | loss: 0.11793 | val_0_mse: 0.11403000354766846|  0:00:47s\n","epoch 72 | loss: 0.12861 | val_0_mse: 0.11738999933004379|  0:00:48s\n","epoch 73 | loss: 0.13335 | val_0_mse: 0.2323800027370453|  0:00:48s\n","epoch 74 | loss: 0.14612 | val_0_mse: 0.1561499983072281|  0:00:49s\n","epoch 75 | loss: 0.169   | val_0_mse: 0.13176999986171722|  0:00:50s\n","epoch 76 | loss: 0.12645 | val_0_mse: 0.13476000726222992|  0:00:50s\n","epoch 77 | loss: 0.13545 | val_0_mse: 0.1456100046634674|  0:00:51s\n","epoch 78 | loss: 0.13389 | val_0_mse: 0.14810000360012054|  0:00:52s\n","epoch 79 | loss: 0.12116 | val_0_mse: 0.11934000253677368|  0:00:52s\n","epoch 80 | loss: 0.13304 | val_0_mse: 0.13280999660491943|  0:00:53s\n","epoch 81 | loss: 0.15862 | val_0_mse: 0.19789999723434448|  0:00:54s\n","\n","Early stopping occurred at epoch 81 with best_epoch = 71 and best_val_0_mse = 0.11403000354766846\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 11:29:11,080] Trial 11 finished with value: 0.11402839422225952 and parameters: {'n_d': 39, 'n_steps': 4, 'gamma': 1.999155889087659, 'n_independent': 3, 'n_shared': 2, 'momentum': 0.10368145303424997}. Best is trial 3 with value: 0.09995829313993454.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 49.44267| val_0_mse: 45297.67578125|  0:00:00s\n","epoch 1  | loss: 1.64139 | val_0_mse: 11116.29296875|  0:00:01s\n","epoch 2  | loss: 0.66964 | val_0_mse: 5025.60546875|  0:00:01s\n","epoch 3  | loss: 0.41193 | val_0_mse: 7882.8896484375|  0:00:02s\n","epoch 4  | loss: 0.32598 | val_0_mse: 2529.6328125|  0:00:03s\n","epoch 5  | loss: 0.27067 | val_0_mse: 1579.3204345703125|  0:00:03s\n","epoch 6  | loss: 0.28377 | val_0_mse: 1260.19873046875|  0:00:04s\n","epoch 7  | loss: 0.21054 | val_0_mse: 928.2348022460938|  0:00:04s\n","epoch 8  | loss: 0.1823  | val_0_mse: 423.379150390625|  0:00:05s\n","epoch 9  | loss: 0.1717  | val_0_mse: 299.9019775390625|  0:00:06s\n","epoch 10 | loss: 0.1754  | val_0_mse: 337.9399719238281|  0:00:06s\n","epoch 11 | loss: 0.15259 | val_0_mse: 257.21441650390625|  0:00:07s\n","epoch 12 | loss: 0.16048 | val_0_mse: 50.08898162841797|  0:00:08s\n","epoch 13 | loss: 0.16592 | val_0_mse: 64.63835906982422|  0:00:08s\n","epoch 14 | loss: 0.217   | val_0_mse: 91.81379699707031|  0:00:09s\n","epoch 15 | loss: 0.14671 | val_0_mse: 13.46914005279541|  0:00:09s\n","epoch 16 | loss: 0.13395 | val_0_mse: 11.016519546508789|  0:00:10s\n","epoch 17 | loss: 0.12365 | val_0_mse: 20.780120849609375|  0:00:11s\n","epoch 18 | loss: 0.12662 | val_0_mse: 13.68517017364502|  0:00:11s\n","epoch 19 | loss: 0.12773 | val_0_mse: 14.623740196228027|  0:00:12s\n","epoch 20 | loss: 0.1181  | val_0_mse: 2.875570058822632|  0:00:13s\n","epoch 21 | loss: 0.12991 | val_0_mse: 3.835860013961792|  0:00:13s\n","epoch 22 | loss: 0.12646 | val_0_mse: 3.8330299854278564|  0:00:14s\n","epoch 23 | loss: 0.14064 | val_0_mse: 1.420609951019287|  0:00:14s\n","epoch 24 | loss: 0.1391  | val_0_mse: 4.760550022125244|  0:00:15s\n","epoch 25 | loss: 0.16975 | val_0_mse: 3.5635199546813965|  0:00:16s\n","epoch 26 | loss: 0.11759 | val_0_mse: 3.1909101009368896|  0:00:16s\n","epoch 27 | loss: 0.1112  | val_0_mse: 2.680530071258545|  0:00:17s\n","epoch 28 | loss: 0.10616 | val_0_mse: 1.7273800373077393|  0:00:17s\n","epoch 29 | loss: 0.12357 | val_0_mse: 1.8401199579238892|  0:00:18s\n","epoch 30 | loss: 0.1212  | val_0_mse: 1.2738699913024902|  0:00:19s\n","epoch 31 | loss: 0.10952 | val_0_mse: 1.144700050354004|  0:00:19s\n","epoch 32 | loss: 0.10628 | val_0_mse: 0.6441699862480164|  0:00:20s\n","epoch 33 | loss: 0.0984  | val_0_mse: 0.4233799874782562|  0:00:21s\n","epoch 34 | loss: 0.10245 | val_0_mse: 0.7137899994850159|  0:00:21s\n","epoch 35 | loss: 0.09822 | val_0_mse: 0.5892500281333923|  0:00:22s\n","epoch 36 | loss: 0.09812 | val_0_mse: 0.8442100286483765|  0:00:22s\n","epoch 37 | loss: 0.11199 | val_0_mse: 0.5189399719238281|  0:00:23s\n","epoch 38 | loss: 0.10102 | val_0_mse: 0.38374000787734985|  0:00:24s\n","epoch 39 | loss: 0.09523 | val_0_mse: 0.43027999997138977|  0:00:24s\n","epoch 40 | loss: 0.09665 | val_0_mse: 0.40661999583244324|  0:00:25s\n","epoch 41 | loss: 0.09234 | val_0_mse: 0.3257499933242798|  0:00:25s\n","epoch 42 | loss: 0.09052 | val_0_mse: 0.28068000078201294|  0:00:26s\n","epoch 43 | loss: 0.0905  | val_0_mse: 0.22227999567985535|  0:00:27s\n","epoch 44 | loss: 0.10139 | val_0_mse: 0.2737500071525574|  0:00:27s\n","epoch 45 | loss: 0.0962  | val_0_mse: 0.24853000044822693|  0:00:28s\n","epoch 46 | loss: 0.10061 | val_0_mse: 0.45370998978614807|  0:00:29s\n","epoch 47 | loss: 0.11572 | val_0_mse: 0.17719000577926636|  0:00:29s\n","epoch 48 | loss: 0.11766 | val_0_mse: 0.32425999641418457|  0:00:30s\n","epoch 49 | loss: 0.1172  | val_0_mse: 0.1447799950838089|  0:00:30s\n","epoch 50 | loss: 0.12436 | val_0_mse: 0.24887999892234802|  0:00:31s\n","epoch 51 | loss: 0.11802 | val_0_mse: 0.19856999814510345|  0:00:32s\n","epoch 52 | loss: 0.09847 | val_0_mse: 0.12536999583244324|  0:00:32s\n","epoch 53 | loss: 0.09141 | val_0_mse: 0.12705999612808228|  0:00:33s\n","epoch 54 | loss: 0.08435 | val_0_mse: 0.1396699994802475|  0:00:33s\n","epoch 55 | loss: 0.08202 | val_0_mse: 0.1302500069141388|  0:00:34s\n","epoch 56 | loss: 0.08144 | val_0_mse: 0.16479000449180603|  0:00:35s\n","epoch 57 | loss: 0.08893 | val_0_mse: 0.11844000220298767|  0:00:35s\n","epoch 58 | loss: 0.08009 | val_0_mse: 0.10919000208377838|  0:00:36s\n","epoch 59 | loss: 0.0822  | val_0_mse: 0.10619000345468521|  0:00:37s\n","epoch 60 | loss: 0.08394 | val_0_mse: 0.10377000272274017|  0:00:37s\n","epoch 61 | loss: 0.08111 | val_0_mse: 0.09844999760389328|  0:00:38s\n","epoch 62 | loss: 0.08449 | val_0_mse: 0.0970500037074089|  0:00:38s\n","epoch 63 | loss: 0.08806 | val_0_mse: 0.08998999744653702|  0:00:39s\n","epoch 64 | loss: 0.08354 | val_0_mse: 0.1080700010061264|  0:00:40s\n","epoch 65 | loss: 0.086   | val_0_mse: 0.12135999649763107|  0:00:40s\n","epoch 66 | loss: 0.09917 | val_0_mse: 0.08912999927997589|  0:00:41s\n","epoch 67 | loss: 0.11627 | val_0_mse: 0.18463000655174255|  0:00:42s\n","epoch 68 | loss: 0.11916 | val_0_mse: 0.10672000050544739|  0:00:42s\n","epoch 69 | loss: 0.10499 | val_0_mse: 0.11898999661207199|  0:00:43s\n","epoch 70 | loss: 0.09918 | val_0_mse: 0.09352000057697296|  0:00:43s\n","epoch 71 | loss: 0.10106 | val_0_mse: 0.12014000117778778|  0:00:44s\n","epoch 72 | loss: 0.10015 | val_0_mse: 0.09793999791145325|  0:00:45s\n","epoch 73 | loss: 0.08569 | val_0_mse: 0.08562999963760376|  0:00:45s\n","epoch 74 | loss: 0.08329 | val_0_mse: 0.10688000172376633|  0:00:46s\n","epoch 75 | loss: 0.10274 | val_0_mse: 0.1606599986553192|  0:00:46s\n","epoch 76 | loss: 0.12074 | val_0_mse: 0.1723400056362152|  0:00:47s\n","epoch 77 | loss: 0.11022 | val_0_mse: 0.09926000237464905|  0:00:48s\n","epoch 78 | loss: 0.09425 | val_0_mse: 0.09284999966621399|  0:00:48s\n","epoch 79 | loss: 0.08251 | val_0_mse: 0.09443999826908112|  0:00:49s\n","epoch 80 | loss: 0.08137 | val_0_mse: 0.09766999632120132|  0:00:49s\n","epoch 81 | loss: 0.08436 | val_0_mse: 0.1001800000667572|  0:00:50s\n","epoch 82 | loss: 0.08195 | val_0_mse: 0.1054999977350235|  0:00:51s\n","epoch 83 | loss: 0.07768 | val_0_mse: 0.09836000204086304|  0:00:51s\n","\n","Early stopping occurred at epoch 83 with best_epoch = 73 and best_val_0_mse = 0.08562999963760376\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 11:30:03,176] Trial 12 finished with value: 0.0856318473815918 and parameters: {'n_d': 28, 'n_steps': 3, 'gamma': 1.0249382864437258, 'n_independent': 4, 'n_shared': 2, 'momentum': 0.30324899236394176}. Best is trial 12 with value: 0.0856318473815918.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 110.51625| val_0_mse: 1598.6817626953125|  0:00:00s\n","epoch 1  | loss: 18.9072 | val_0_mse: 5740.0703125|  0:00:00s\n","epoch 2  | loss: 1.79248 | val_0_mse: 4377.6728515625|  0:00:01s\n","epoch 3  | loss: 0.57138 | val_0_mse: 157.4858856201172|  0:00:01s\n","epoch 4  | loss: 0.35835 | val_0_mse: 579.2479858398438|  0:00:02s\n","epoch 5  | loss: 0.25445 | val_0_mse: 213.19061279296875|  0:00:02s\n","epoch 6  | loss: 0.25097 | val_0_mse: 295.88824462890625|  0:00:03s\n","epoch 7  | loss: 0.26091 | val_0_mse: 141.8118896484375|  0:00:03s\n","epoch 8  | loss: 0.19552 | val_0_mse: 533.0950927734375|  0:00:04s\n","epoch 9  | loss: 0.16414 | val_0_mse: 928.4179077148438|  0:00:04s\n","epoch 10 | loss: 0.15211 | val_0_mse: 636.9527587890625|  0:00:05s\n","epoch 11 | loss: 0.14337 | val_0_mse: 473.5918273925781|  0:00:05s\n","epoch 12 | loss: 0.14219 | val_0_mse: 464.820068359375|  0:00:06s\n","epoch 13 | loss: 0.1308  | val_0_mse: 391.82110595703125|  0:00:06s\n","epoch 14 | loss: 0.12918 | val_0_mse: 428.047607421875|  0:00:07s\n","epoch 15 | loss: 0.12219 | val_0_mse: 269.79852294921875|  0:00:07s\n","epoch 16 | loss: 0.11456 | val_0_mse: 277.0073547363281|  0:00:08s\n","epoch 17 | loss: 0.11981 | val_0_mse: 269.02923583984375|  0:00:08s\n","\n","Early stopping occurred at epoch 17 with best_epoch = 7 and best_val_0_mse = 141.8118896484375\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 11:30:12,022] Trial 13 finished with value: 141.8118896484375 and parameters: {'n_d': 25, 'n_steps': 3, 'gamma': 1.0737265145420611, 'n_independent': 2, 'n_shared': 2, 'momentum': 0.293145123083172}. Best is trial 12 with value: 0.0856318473815918.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 42.18663| val_0_mse: 6724.47802734375|  0:00:01s\n","epoch 1  | loss: 3.29798 | val_0_mse: 4842.251953125|  0:00:02s\n","epoch 2  | loss: 2.33463 | val_0_mse: 1002.7803955078125|  0:00:03s\n","epoch 3  | loss: 1.44337 | val_0_mse: 7498.38134765625|  0:00:04s\n","epoch 4  | loss: 1.38514 | val_0_mse: 2202.349853515625|  0:00:05s\n","epoch 5  | loss: 0.84391 | val_0_mse: 2305.271728515625|  0:00:06s\n","epoch 6  | loss: 0.60021 | val_0_mse: 832.9343872070312|  0:00:07s\n","epoch 7  | loss: 0.42092 | val_0_mse: 549.5338134765625|  0:00:08s\n","epoch 8  | loss: 0.43099 | val_0_mse: 989.3995971679688|  0:00:10s\n","epoch 9  | loss: 0.34033 | val_0_mse: 574.6557006835938|  0:00:11s\n","epoch 10 | loss: 0.28499 | val_0_mse: 635.1338500976562|  0:00:12s\n","epoch 11 | loss: 0.2257  | val_0_mse: 373.58917236328125|  0:00:13s\n","epoch 12 | loss: 0.19793 | val_0_mse: 184.95217895507812|  0:00:14s\n","epoch 13 | loss: 0.16619 | val_0_mse: 60.11101150512695|  0:00:15s\n","epoch 14 | loss: 0.20564 | val_0_mse: 83.87972259521484|  0:00:17s\n","epoch 15 | loss: 0.22601 | val_0_mse: 125.04696655273438|  0:00:18s\n","epoch 16 | loss: 0.21064 | val_0_mse: 65.21002197265625|  0:00:19s\n","epoch 17 | loss: 0.17972 | val_0_mse: 62.46501922607422|  0:00:20s\n","epoch 18 | loss: 0.17665 | val_0_mse: 49.553009033203125|  0:00:21s\n","epoch 19 | loss: 0.19116 | val_0_mse: 22.931760787963867|  0:00:22s\n","epoch 20 | loss: 0.15608 | val_0_mse: 11.624099731445312|  0:00:23s\n","epoch 21 | loss: 0.324   | val_0_mse: 12.389619827270508|  0:00:24s\n","epoch 22 | loss: 0.24805 | val_0_mse: 12.847439765930176|  0:00:25s\n","epoch 23 | loss: 0.17768 | val_0_mse: 8.551460266113281|  0:00:27s\n","epoch 24 | loss: 0.20236 | val_0_mse: 3.93257999420166|  0:00:28s\n","epoch 25 | loss: 0.17576 | val_0_mse: 5.392710208892822|  0:00:29s\n","epoch 26 | loss: 0.15879 | val_0_mse: 2.6578099727630615|  0:00:30s\n","epoch 27 | loss: 0.16072 | val_0_mse: 5.403349876403809|  0:00:31s\n","epoch 28 | loss: 0.23156 | val_0_mse: 3.3063600063323975|  0:00:32s\n","epoch 29 | loss: 0.19812 | val_0_mse: 1.1721099615097046|  0:00:33s\n","epoch 30 | loss: 0.2019  | val_0_mse: 0.6878200173377991|  0:00:34s\n","epoch 31 | loss: 0.23632 | val_0_mse: 0.5738400220870972|  0:00:36s\n","epoch 32 | loss: 0.22067 | val_0_mse: 1.6482000350952148|  0:00:37s\n","epoch 33 | loss: 0.24664 | val_0_mse: 2.468179941177368|  0:00:38s\n","epoch 34 | loss: 0.23254 | val_0_mse: 3.1050899028778076|  0:00:39s\n","epoch 35 | loss: 0.20045 | val_0_mse: 0.7372300028800964|  0:00:40s\n","epoch 36 | loss: 0.12907 | val_0_mse: 0.8274000287055969|  0:00:41s\n","epoch 37 | loss: 0.11984 | val_0_mse: 0.5856599807739258|  0:00:42s\n","epoch 38 | loss: 0.12062 | val_0_mse: 0.6794099807739258|  0:00:44s\n","epoch 39 | loss: 0.178   | val_0_mse: 0.5397199988365173|  0:00:45s\n","epoch 40 | loss: 0.15025 | val_0_mse: 0.25029000639915466|  0:00:46s\n","epoch 41 | loss: 0.13789 | val_0_mse: 0.2540999948978424|  0:00:47s\n","epoch 42 | loss: 0.13111 | val_0_mse: 0.3723500072956085|  0:00:48s\n","epoch 43 | loss: 0.14829 | val_0_mse: 0.18517999351024628|  0:00:49s\n","epoch 44 | loss: 0.14014 | val_0_mse: 0.29385998845100403|  0:00:50s\n","epoch 45 | loss: 0.14066 | val_0_mse: 0.18148000538349152|  0:00:51s\n","epoch 46 | loss: 0.17317 | val_0_mse: 0.48041999340057373|  0:00:52s\n","epoch 47 | loss: 0.25928 | val_0_mse: 0.4109100103378296|  0:00:54s\n","epoch 48 | loss: 0.21189 | val_0_mse: 0.5130199790000916|  0:00:55s\n","epoch 49 | loss: 0.216   | val_0_mse: 0.14053000509738922|  0:00:56s\n","epoch 50 | loss: 0.22985 | val_0_mse: 0.1791599988937378|  0:00:57s\n","epoch 51 | loss: 0.21556 | val_0_mse: 0.1645199954509735|  0:00:58s\n","epoch 52 | loss: 0.18582 | val_0_mse: 0.14876000583171844|  0:00:59s\n","epoch 53 | loss: 0.19678 | val_0_mse: 0.2680000066757202|  0:01:00s\n","epoch 54 | loss: 0.1938  | val_0_mse: 0.4454199969768524|  0:01:01s\n","epoch 55 | loss: 0.21143 | val_0_mse: 0.47001999616622925|  0:01:02s\n","epoch 56 | loss: 0.19375 | val_0_mse: 0.23231999576091766|  0:01:04s\n","epoch 57 | loss: 0.15989 | val_0_mse: 0.13145999610424042|  0:01:05s\n","epoch 58 | loss: 0.21428 | val_0_mse: 0.13753999769687653|  0:01:06s\n","epoch 59 | loss: 0.11121 | val_0_mse: 0.16274000704288483|  0:01:07s\n","epoch 60 | loss: 0.10369 | val_0_mse: 0.10719999670982361|  0:01:08s\n","epoch 61 | loss: 0.10733 | val_0_mse: 0.11973000317811966|  0:01:09s\n","epoch 62 | loss: 0.1105  | val_0_mse: 0.1109900027513504|  0:01:10s\n","epoch 63 | loss: 0.15219 | val_0_mse: 0.23555999994277954|  0:01:11s\n","epoch 64 | loss: 0.17279 | val_0_mse: 0.12167999893426895|  0:01:12s\n","epoch 65 | loss: 0.12897 | val_0_mse: 0.21913999319076538|  0:01:14s\n","epoch 66 | loss: 0.14309 | val_0_mse: 0.11348000168800354|  0:01:15s\n","epoch 67 | loss: 0.11962 | val_0_mse: 0.12845000624656677|  0:01:16s\n","epoch 68 | loss: 0.12162 | val_0_mse: 0.10930000245571136|  0:01:17s\n","epoch 69 | loss: 0.10532 | val_0_mse: 0.12845000624656677|  0:01:18s\n","epoch 70 | loss: 0.1143  | val_0_mse: 0.13684000074863434|  0:01:19s\n","\n","Early stopping occurred at epoch 70 with best_epoch = 60 and best_val_0_mse = 0.10719999670982361\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 11:31:32,258] Trial 14 finished with value: 0.1072029173374176 and parameters: {'n_d': 27, 'n_steps': 8, 'gamma': 1.0099046999576036, 'n_independent': 3, 'n_shared': 2, 'momentum': 0.3574557533170827}. Best is trial 12 with value: 0.0856318473815918.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 96.4679 | val_0_mse: 36239.76953125|  0:00:00s\n","epoch 1  | loss: 24.34534| val_0_mse: 168740.8125|  0:00:01s\n","epoch 2  | loss: 6.54648 | val_0_mse: 36869.37890625|  0:00:02s\n","epoch 3  | loss: 2.19683 | val_0_mse: 13603.16015625|  0:00:03s\n","epoch 4  | loss: 1.05893 | val_0_mse: 1073.6614990234375|  0:00:04s\n","epoch 5  | loss: 0.95343 | val_0_mse: 656.101806640625|  0:00:05s\n","epoch 6  | loss: 0.5668  | val_0_mse: 258.017578125|  0:00:06s\n","epoch 7  | loss: 0.53028 | val_0_mse: 897.4254150390625|  0:00:07s\n","epoch 8  | loss: 0.573   | val_0_mse: 1293.8206787109375|  0:00:07s\n","epoch 9  | loss: 0.34428 | val_0_mse: 95.82079315185547|  0:00:08s\n","epoch 10 | loss: 0.33553 | val_0_mse: 82.46714782714844|  0:00:09s\n","epoch 11 | loss: 0.28728 | val_0_mse: 44.281131744384766|  0:00:10s\n","epoch 12 | loss: 0.50347 | val_0_mse: 129.1817626953125|  0:00:11s\n","epoch 13 | loss: 0.39142 | val_0_mse: 63.526039123535156|  0:00:12s\n","epoch 14 | loss: 0.32094 | val_0_mse: 59.13037872314453|  0:00:13s\n","epoch 15 | loss: 0.29221 | val_0_mse: 63.911460876464844|  0:00:14s\n","epoch 16 | loss: 0.21858 | val_0_mse: 8.53831958770752|  0:00:14s\n","epoch 17 | loss: 0.2277  | val_0_mse: 15.697680473327637|  0:00:15s\n","epoch 18 | loss: 0.22026 | val_0_mse: 37.950828552246094|  0:00:16s\n","epoch 19 | loss: 0.20072 | val_0_mse: 37.808868408203125|  0:00:17s\n","epoch 20 | loss: 0.23142 | val_0_mse: 13.088040351867676|  0:00:18s\n","epoch 21 | loss: 0.20226 | val_0_mse: 6.943779945373535|  0:00:19s\n","epoch 22 | loss: 0.2091  | val_0_mse: 5.002999782562256|  0:00:20s\n","epoch 23 | loss: 0.19688 | val_0_mse: 3.9039900302886963|  0:00:21s\n","epoch 24 | loss: 0.21518 | val_0_mse: 2.034060001373291|  0:00:22s\n","epoch 25 | loss: 0.23618 | val_0_mse: 2.756659984588623|  0:00:23s\n","epoch 26 | loss: 0.2035  | val_0_mse: 0.9950199723243713|  0:00:24s\n","epoch 27 | loss: 0.20307 | val_0_mse: 1.4767500162124634|  0:00:24s\n","epoch 28 | loss: 0.19404 | val_0_mse: 0.6564499735832214|  0:00:25s\n","epoch 29 | loss: 0.19002 | val_0_mse: 1.0914700031280518|  0:00:26s\n","epoch 30 | loss: 0.17835 | val_0_mse: 0.7519000172615051|  0:00:27s\n","epoch 31 | loss: 0.16056 | val_0_mse: 0.4672499895095825|  0:00:28s\n","epoch 32 | loss: 0.17231 | val_0_mse: 0.37946999073028564|  0:00:29s\n","epoch 33 | loss: 0.15073 | val_0_mse: 0.5478900074958801|  0:00:30s\n","epoch 34 | loss: 0.15815 | val_0_mse: 0.3000600039958954|  0:00:31s\n","epoch 35 | loss: 0.1551  | val_0_mse: 0.25200000405311584|  0:00:32s\n","epoch 36 | loss: 0.17466 | val_0_mse: 0.36201998591423035|  0:00:32s\n","epoch 37 | loss: 0.21809 | val_0_mse: 0.43942001461982727|  0:00:33s\n","epoch 38 | loss: 0.17213 | val_0_mse: 0.2547599971294403|  0:00:34s\n","epoch 39 | loss: 0.18797 | val_0_mse: 0.28621000051498413|  0:00:35s\n","epoch 40 | loss: 0.16221 | val_0_mse: 0.2332800030708313|  0:00:36s\n","epoch 41 | loss: 0.15921 | val_0_mse: 0.29328998923301697|  0:00:37s\n","epoch 42 | loss: 0.15754 | val_0_mse: 0.33708998560905457|  0:00:38s\n","epoch 43 | loss: 0.16396 | val_0_mse: 0.2397499978542328|  0:00:39s\n","epoch 44 | loss: 0.17206 | val_0_mse: 0.28356999158859253|  0:00:39s\n","epoch 45 | loss: 0.16918 | val_0_mse: 0.29927000403404236|  0:00:40s\n","epoch 46 | loss: 0.17082 | val_0_mse: 0.2195100039243698|  0:00:41s\n","epoch 47 | loss: 0.171   | val_0_mse: 0.2006700038909912|  0:00:42s\n","epoch 48 | loss: 0.16053 | val_0_mse: 0.19061000645160675|  0:00:43s\n","epoch 49 | loss: 0.14772 | val_0_mse: 0.19394999742507935|  0:00:44s\n","epoch 50 | loss: 0.14691 | val_0_mse: 0.16457000374794006|  0:00:45s\n","epoch 51 | loss: 0.15317 | val_0_mse: 0.21723000705242157|  0:00:46s\n","epoch 52 | loss: 0.14868 | val_0_mse: 0.18885000050067902|  0:00:47s\n","epoch 53 | loss: 0.14994 | val_0_mse: 0.23538999259471893|  0:00:47s\n","epoch 54 | loss: 0.15992 | val_0_mse: 0.1774500012397766|  0:00:48s\n","epoch 55 | loss: 0.13662 | val_0_mse: 0.15344999730587006|  0:00:49s\n","epoch 56 | loss: 0.13623 | val_0_mse: 0.1676200032234192|  0:00:50s\n","epoch 57 | loss: 0.13872 | val_0_mse: 0.13134999573230743|  0:00:51s\n","epoch 58 | loss: 0.12154 | val_0_mse: 0.12043000012636185|  0:00:52s\n","epoch 59 | loss: 0.1352  | val_0_mse: 0.14607000350952148|  0:00:53s\n","epoch 60 | loss: 0.11243 | val_0_mse: 0.1412000060081482|  0:00:54s\n","epoch 61 | loss: 0.11141 | val_0_mse: 0.11971999704837799|  0:00:55s\n","epoch 62 | loss: 0.11665 | val_0_mse: 0.12116000056266785|  0:00:56s\n","epoch 63 | loss: 0.10658 | val_0_mse: 0.10875000059604645|  0:00:57s\n","epoch 64 | loss: 0.10772 | val_0_mse: 0.10626000165939331|  0:00:57s\n","epoch 65 | loss: 0.10667 | val_0_mse: 0.10813000053167343|  0:00:58s\n","epoch 66 | loss: 0.12061 | val_0_mse: 0.11821000277996063|  0:00:59s\n","epoch 67 | loss: 0.11547 | val_0_mse: 0.10790000110864639|  0:01:00s\n","epoch 68 | loss: 0.125   | val_0_mse: 0.15217000246047974|  0:01:01s\n","epoch 69 | loss: 0.12368 | val_0_mse: 0.11533000320196152|  0:01:02s\n","epoch 70 | loss: 0.11158 | val_0_mse: 0.11548999696969986|  0:01:03s\n","epoch 71 | loss: 0.14617 | val_0_mse: 0.14655999839305878|  0:01:04s\n","epoch 72 | loss: 0.16183 | val_0_mse: 0.1806900054216385|  0:01:04s\n","epoch 73 | loss: 0.14081 | val_0_mse: 0.14146000146865845|  0:01:05s\n","epoch 74 | loss: 0.12624 | val_0_mse: 0.11649999767541885|  0:01:06s\n","\n","Early stopping occurred at epoch 74 with best_epoch = 64 and best_val_0_mse = 0.10626000165939331\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 11:32:39,456] Trial 15 finished with value: 0.10625522583723068 and parameters: {'n_d': 8, 'n_steps': 6, 'gamma': 1.6313271192846805, 'n_independent': 4, 'n_shared': 1, 'momentum': 0.26927458514609104}. Best is trial 12 with value: 0.0856318473815918.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 63.79294| val_0_mse: 222886.21875|  0:00:00s\n","epoch 1  | loss: 4.40936 | val_0_mse: 80648.9140625|  0:00:00s\n","epoch 2  | loss: 0.8126  | val_0_mse: 905.8243408203125|  0:00:01s\n","epoch 3  | loss: 0.40291 | val_0_mse: 208.60133361816406|  0:00:01s\n","epoch 4  | loss: 0.28394 | val_0_mse: 369.7546691894531|  0:00:02s\n","epoch 5  | loss: 0.25854 | val_0_mse: 137.3215789794922|  0:00:02s\n","epoch 6  | loss: 0.23349 | val_0_mse: 56.394771575927734|  0:00:03s\n","epoch 7  | loss: 0.22187 | val_0_mse: 66.21631622314453|  0:00:03s\n","epoch 8  | loss: 0.19753 | val_0_mse: 93.85201263427734|  0:00:04s\n","epoch 9  | loss: 0.17534 | val_0_mse: 57.17612075805664|  0:00:04s\n","epoch 10 | loss: 0.177   | val_0_mse: 67.64649963378906|  0:00:05s\n","epoch 11 | loss: 0.16592 | val_0_mse: 22.980070114135742|  0:00:05s\n","epoch 12 | loss: 0.17252 | val_0_mse: 18.928930282592773|  0:00:06s\n","epoch 13 | loss: 0.15858 | val_0_mse: 10.854120254516602|  0:00:06s\n","epoch 14 | loss: 0.15236 | val_0_mse: 9.594389915466309|  0:00:07s\n","epoch 15 | loss: 0.13197 | val_0_mse: 6.558680057525635|  0:00:07s\n","epoch 16 | loss: 0.13735 | val_0_mse: 4.616340160369873|  0:00:08s\n","epoch 17 | loss: 0.14202 | val_0_mse: 4.202660083770752|  0:00:08s\n","epoch 18 | loss: 0.12411 | val_0_mse: 3.419610023498535|  0:00:09s\n","epoch 19 | loss: 0.14141 | val_0_mse: 2.8792099952697754|  0:00:09s\n","epoch 20 | loss: 0.13095 | val_0_mse: 1.9874399900436401|  0:00:10s\n","epoch 21 | loss: 0.11876 | val_0_mse: 1.4881099462509155|  0:00:10s\n","epoch 22 | loss: 0.14336 | val_0_mse: 1.3124099969863892|  0:00:11s\n","epoch 23 | loss: 0.11794 | val_0_mse: 1.894670009613037|  0:00:11s\n","epoch 24 | loss: 0.11205 | val_0_mse: 2.118849992752075|  0:00:12s\n","epoch 25 | loss: 0.11265 | val_0_mse: 1.418969988822937|  0:00:12s\n","epoch 26 | loss: 0.10891 | val_0_mse: 1.9378000497817993|  0:00:13s\n","epoch 27 | loss: 0.10854 | val_0_mse: 1.1776599884033203|  0:00:13s\n","epoch 28 | loss: 0.10528 | val_0_mse: 0.858240008354187|  0:00:13s\n","epoch 29 | loss: 0.10564 | val_0_mse: 0.9223499894142151|  0:00:14s\n","epoch 30 | loss: 0.09998 | val_0_mse: 1.1099400520324707|  0:00:14s\n","epoch 31 | loss: 0.10147 | val_0_mse: 0.7883300185203552|  0:00:15s\n","epoch 32 | loss: 0.097   | val_0_mse: 0.6629700064659119|  0:00:15s\n","epoch 33 | loss: 0.09847 | val_0_mse: 0.8473700284957886|  0:00:16s\n","epoch 34 | loss: 0.10367 | val_0_mse: 0.6319199800491333|  0:00:16s\n","epoch 35 | loss: 0.11032 | val_0_mse: 0.5831199884414673|  0:00:17s\n","epoch 36 | loss: 0.10917 | val_0_mse: 0.4152199923992157|  0:00:17s\n","epoch 37 | loss: 0.11011 | val_0_mse: 0.461760014295578|  0:00:18s\n","epoch 38 | loss: 0.10252 | val_0_mse: 0.4619100093841553|  0:00:18s\n","epoch 39 | loss: 0.10026 | val_0_mse: 0.37297001481056213|  0:00:19s\n","epoch 40 | loss: 0.09927 | val_0_mse: 0.27643001079559326|  0:00:19s\n","epoch 41 | loss: 0.09864 | val_0_mse: 0.38600000739097595|  0:00:20s\n","epoch 42 | loss: 0.10341 | val_0_mse: 0.39412999153137207|  0:00:20s\n","epoch 43 | loss: 0.13155 | val_0_mse: 0.20506000518798828|  0:00:21s\n","epoch 44 | loss: 0.11843 | val_0_mse: 0.257750004529953|  0:00:21s\n","epoch 45 | loss: 0.09453 | val_0_mse: 0.2720299959182739|  0:00:22s\n","epoch 46 | loss: 0.09457 | val_0_mse: 0.28395000100135803|  0:00:22s\n","epoch 47 | loss: 0.10474 | val_0_mse: 0.24762000143527985|  0:00:22s\n","epoch 48 | loss: 0.10332 | val_0_mse: 0.13428999483585358|  0:00:23s\n","epoch 49 | loss: 0.09835 | val_0_mse: 0.2004700005054474|  0:00:23s\n","epoch 50 | loss: 0.09547 | val_0_mse: 0.17441999912261963|  0:00:24s\n","epoch 51 | loss: 0.0967  | val_0_mse: 0.21131999790668488|  0:00:24s\n","epoch 52 | loss: 0.09478 | val_0_mse: 0.14090999960899353|  0:00:25s\n","epoch 53 | loss: 0.1117  | val_0_mse: 0.17372000217437744|  0:00:25s\n","epoch 54 | loss: 0.10435 | val_0_mse: 0.12472999840974808|  0:00:26s\n","epoch 55 | loss: 0.09488 | val_0_mse: 0.11525999754667282|  0:00:26s\n","epoch 56 | loss: 0.10492 | val_0_mse: 0.17479999363422394|  0:00:27s\n","epoch 57 | loss: 0.09738 | val_0_mse: 0.12561999261379242|  0:00:27s\n","epoch 58 | loss: 0.10203 | val_0_mse: 0.11959999799728394|  0:00:28s\n","epoch 59 | loss: 0.11159 | val_0_mse: 0.2054000049829483|  0:00:28s\n","epoch 60 | loss: 0.10799 | val_0_mse: 0.09923999756574631|  0:00:29s\n","epoch 61 | loss: 0.10497 | val_0_mse: 0.13394999504089355|  0:00:29s\n","epoch 62 | loss: 0.08724 | val_0_mse: 0.10361000150442123|  0:00:30s\n","epoch 63 | loss: 0.08687 | val_0_mse: 0.09735000133514404|  0:00:30s\n","epoch 64 | loss: 0.0854  | val_0_mse: 0.08568999916315079|  0:00:31s\n","epoch 65 | loss: 0.0825  | val_0_mse: 0.09432999789714813|  0:00:31s\n","epoch 66 | loss: 0.08832 | val_0_mse: 0.09487999975681305|  0:00:31s\n","epoch 67 | loss: 0.08996 | val_0_mse: 0.09282000362873077|  0:00:32s\n","epoch 68 | loss: 0.08174 | val_0_mse: 0.09200000017881393|  0:00:32s\n","epoch 69 | loss: 0.08711 | val_0_mse: 0.08640000224113464|  0:00:33s\n","epoch 70 | loss: 0.0859  | val_0_mse: 0.09436000138521194|  0:00:33s\n","epoch 71 | loss: 0.08628 | val_0_mse: 0.10527999699115753|  0:00:34s\n","epoch 72 | loss: 0.08478 | val_0_mse: 0.1023700013756752|  0:00:34s\n","epoch 73 | loss: 0.08714 | val_0_mse: 0.08442000299692154|  0:00:35s\n","epoch 74 | loss: 0.08343 | val_0_mse: 0.08647999912500381|  0:00:35s\n","epoch 75 | loss: 0.08002 | val_0_mse: 0.08647000044584274|  0:00:36s\n","epoch 76 | loss: 0.08458 | val_0_mse: 0.08510000258684158|  0:00:36s\n","epoch 77 | loss: 0.10062 | val_0_mse: 0.08647000044584274|  0:00:37s\n","epoch 78 | loss: 0.09337 | val_0_mse: 0.10660000145435333|  0:00:37s\n","epoch 79 | loss: 0.10816 | val_0_mse: 0.09811999648809433|  0:00:38s\n","epoch 80 | loss: 0.10697 | val_0_mse: 0.11016999930143356|  0:00:38s\n","epoch 81 | loss: 0.09185 | val_0_mse: 0.08648999780416489|  0:00:39s\n","epoch 82 | loss: 0.08465 | val_0_mse: 0.08705999702215195|  0:00:39s\n","epoch 83 | loss: 0.08038 | val_0_mse: 0.08158999681472778|  0:00:39s\n","epoch 84 | loss: 0.07913 | val_0_mse: 0.09786000102758408|  0:00:40s\n","epoch 85 | loss: 0.08287 | val_0_mse: 0.08807999640703201|  0:00:40s\n","epoch 86 | loss: 0.07852 | val_0_mse: 0.0913499966263771|  0:00:41s\n","epoch 87 | loss: 0.08385 | val_0_mse: 0.0973299965262413|  0:00:41s\n","epoch 88 | loss: 0.08146 | val_0_mse: 0.08726000040769577|  0:00:42s\n","epoch 89 | loss: 0.08235 | val_0_mse: 0.090829998254776|  0:00:42s\n","epoch 90 | loss: 0.08852 | val_0_mse: 0.11123999953269958|  0:00:43s\n","epoch 91 | loss: 0.08614 | val_0_mse: 0.08901999890804291|  0:00:43s\n","epoch 92 | loss: 0.08249 | val_0_mse: 0.08794999867677689|  0:00:44s\n","epoch 93 | loss: 0.07874 | val_0_mse: 0.07794000208377838|  0:00:44s\n","epoch 94 | loss: 0.07766 | val_0_mse: 0.08314000070095062|  0:00:45s\n","epoch 95 | loss: 0.07778 | val_0_mse: 0.08085999637842178|  0:00:45s\n","epoch 96 | loss: 0.07754 | val_0_mse: 0.08020000159740448|  0:00:45s\n","epoch 97 | loss: 0.07883 | val_0_mse: 0.08781000226736069|  0:00:46s\n","epoch 98 | loss: 0.08165 | val_0_mse: 0.08619999885559082|  0:00:47s\n","epoch 99 | loss: 0.08252 | val_0_mse: 0.08998999744653702|  0:00:47s\n","Stop training because you reached max_epochs = 100 with best_epoch = 93 and best_val_0_mse = 0.07794000208377838\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 11:33:27,236] Trial 16 finished with value: 0.07793815433979034 and parameters: {'n_d': 19, 'n_steps': 3, 'gamma': 1.138422672805298, 'n_independent': 1, 'n_shared': 3, 'momentum': 0.3437524013145722}. Best is trial 16 with value: 0.07793815433979034.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 42.02395| val_0_mse: 31070.82421875|  0:00:00s\n","epoch 1  | loss: 1.72219 | val_0_mse: 4063.629638671875|  0:00:00s\n","epoch 2  | loss: 0.46801 | val_0_mse: 286.8109130859375|  0:00:01s\n","epoch 3  | loss: 0.33177 | val_0_mse: 170.1954345703125|  0:00:01s\n","epoch 4  | loss: 0.31609 | val_0_mse: 208.04786682128906|  0:00:02s\n","epoch 5  | loss: 0.27284 | val_0_mse: 128.84837341308594|  0:00:02s\n","epoch 6  | loss: 0.2474  | val_0_mse: 71.07698822021484|  0:00:03s\n","epoch 7  | loss: 0.19896 | val_0_mse: 81.06166076660156|  0:00:03s\n","epoch 8  | loss: 0.18129 | val_0_mse: 67.21945190429688|  0:00:04s\n","epoch 9  | loss: 0.18925 | val_0_mse: 21.498319625854492|  0:00:04s\n","epoch 10 | loss: 0.1674  | val_0_mse: 44.06428146362305|  0:00:05s\n","epoch 11 | loss: 0.17992 | val_0_mse: 63.965301513671875|  0:00:05s\n","epoch 12 | loss: 0.17847 | val_0_mse: 43.04161834716797|  0:00:06s\n","epoch 13 | loss: 0.1543  | val_0_mse: 32.83047103881836|  0:00:06s\n","epoch 14 | loss: 0.14135 | val_0_mse: 35.729740142822266|  0:00:06s\n","epoch 15 | loss: 0.16396 | val_0_mse: 26.207799911499023|  0:00:07s\n","epoch 16 | loss: 0.16075 | val_0_mse: 16.709510803222656|  0:00:07s\n","epoch 17 | loss: 0.16552 | val_0_mse: 8.994850158691406|  0:00:08s\n","epoch 18 | loss: 0.13234 | val_0_mse: 6.599989891052246|  0:00:08s\n","epoch 19 | loss: 0.12169 | val_0_mse: 6.516200065612793|  0:00:09s\n","epoch 20 | loss: 0.12631 | val_0_mse: 4.577899932861328|  0:00:09s\n","epoch 21 | loss: 0.12766 | val_0_mse: 3.182499885559082|  0:00:10s\n","epoch 22 | loss: 0.17131 | val_0_mse: 1.260040044784546|  0:00:10s\n","epoch 23 | loss: 0.1649  | val_0_mse: 1.3477200269699097|  0:00:11s\n","epoch 24 | loss: 0.14749 | val_0_mse: 1.0400400161743164|  0:00:11s\n","epoch 25 | loss: 0.13851 | val_0_mse: 0.6880199909210205|  0:00:12s\n","epoch 26 | loss: 0.11739 | val_0_mse: 1.6479599475860596|  0:00:12s\n","epoch 27 | loss: 0.11033 | val_0_mse: 1.1682699918746948|  0:00:13s\n","epoch 28 | loss: 0.12068 | val_0_mse: 1.473270058631897|  0:00:13s\n","epoch 29 | loss: 0.11142 | val_0_mse: 1.4333000183105469|  0:00:14s\n","epoch 30 | loss: 0.11747 | val_0_mse: 1.207129955291748|  0:00:14s\n","epoch 31 | loss: 0.11124 | val_0_mse: 1.1520400047302246|  0:00:15s\n","epoch 32 | loss: 0.10843 | val_0_mse: 1.0042099952697754|  0:00:15s\n","epoch 33 | loss: 0.1056  | val_0_mse: 1.0881199836730957|  0:00:15s\n","epoch 34 | loss: 0.10111 | val_0_mse: 0.5956199765205383|  0:00:16s\n","epoch 35 | loss: 0.11023 | val_0_mse: 0.6261799931526184|  0:00:17s\n","epoch 36 | loss: 0.11147 | val_0_mse: 0.6389300227165222|  0:00:17s\n","epoch 37 | loss: 0.12461 | val_0_mse: 0.43143001198768616|  0:00:18s\n","epoch 38 | loss: 0.11794 | val_0_mse: 0.31439998745918274|  0:00:18s\n","epoch 39 | loss: 0.11511 | val_0_mse: 0.3041299879550934|  0:00:18s\n","epoch 40 | loss: 0.10581 | val_0_mse: 0.35864999890327454|  0:00:19s\n","epoch 41 | loss: 0.09818 | val_0_mse: 0.28964999318122864|  0:00:19s\n","epoch 42 | loss: 0.0997  | val_0_mse: 0.25165000557899475|  0:00:20s\n","epoch 43 | loss: 0.10729 | val_0_mse: 0.20348000526428223|  0:00:20s\n","epoch 44 | loss: 0.11009 | val_0_mse: 0.263729989528656|  0:00:21s\n","epoch 45 | loss: 0.10092 | val_0_mse: 0.29385000467300415|  0:00:21s\n","epoch 46 | loss: 0.09473 | val_0_mse: 0.1814499944448471|  0:00:22s\n","epoch 47 | loss: 0.09563 | val_0_mse: 0.27204999327659607|  0:00:22s\n","epoch 48 | loss: 0.09954 | val_0_mse: 0.18855999410152435|  0:00:23s\n","epoch 49 | loss: 0.11541 | val_0_mse: 0.1925400048494339|  0:00:23s\n","epoch 50 | loss: 0.09869 | val_0_mse: 0.16943000257015228|  0:00:24s\n","epoch 51 | loss: 0.09485 | val_0_mse: 0.1620599925518036|  0:00:24s\n","epoch 52 | loss: 0.10215 | val_0_mse: 0.15522000193595886|  0:00:25s\n","epoch 53 | loss: 0.10026 | val_0_mse: 0.13595999777317047|  0:00:25s\n","epoch 54 | loss: 0.09747 | val_0_mse: 0.19130000472068787|  0:00:26s\n","epoch 55 | loss: 0.12133 | val_0_mse: 0.11022000014781952|  0:00:26s\n","epoch 56 | loss: 0.12264 | val_0_mse: 0.1595200002193451|  0:00:27s\n","epoch 57 | loss: 0.11361 | val_0_mse: 0.10108999907970428|  0:00:27s\n","epoch 58 | loss: 0.11617 | val_0_mse: 0.1596899926662445|  0:00:28s\n","epoch 59 | loss: 0.11384 | val_0_mse: 0.1044199988245964|  0:00:28s\n","epoch 60 | loss: 0.12278 | val_0_mse: 0.13744999468326569|  0:00:28s\n","epoch 61 | loss: 0.11714 | val_0_mse: 0.09939000010490417|  0:00:29s\n","epoch 62 | loss: 0.11547 | val_0_mse: 0.13481999933719635|  0:00:29s\n","epoch 63 | loss: 0.13075 | val_0_mse: 0.11339999735355377|  0:00:30s\n","epoch 64 | loss: 0.10929 | val_0_mse: 0.10735999792814255|  0:00:30s\n","epoch 65 | loss: 0.1031  | val_0_mse: 0.09780000150203705|  0:00:31s\n","epoch 66 | loss: 0.10047 | val_0_mse: 0.10271000117063522|  0:00:31s\n","epoch 67 | loss: 0.10526 | val_0_mse: 0.09172999858856201|  0:00:32s\n","epoch 68 | loss: 0.09912 | val_0_mse: 0.12286999821662903|  0:00:32s\n","epoch 69 | loss: 0.1227  | val_0_mse: 0.11148999631404877|  0:00:33s\n","epoch 70 | loss: 0.10935 | val_0_mse: 0.10051000118255615|  0:00:33s\n","epoch 71 | loss: 0.11227 | val_0_mse: 0.16726000607013702|  0:00:34s\n","epoch 72 | loss: 0.11984 | val_0_mse: 0.10869999974966049|  0:00:34s\n","epoch 73 | loss: 0.09569 | val_0_mse: 0.10631000250577927|  0:00:35s\n","epoch 74 | loss: 0.09694 | val_0_mse: 0.09724000096321106|  0:00:35s\n","epoch 75 | loss: 0.0926  | val_0_mse: 0.08510000258684158|  0:00:36s\n","epoch 76 | loss: 0.09343 | val_0_mse: 0.09802000224590302|  0:00:36s\n","epoch 77 | loss: 0.09125 | val_0_mse: 0.09093999862670898|  0:00:37s\n","epoch 78 | loss: 0.09308 | val_0_mse: 0.09258999675512314|  0:00:37s\n","epoch 79 | loss: 0.11761 | val_0_mse: 0.0895799994468689|  0:00:38s\n","epoch 80 | loss: 0.11613 | val_0_mse: 0.09855999797582626|  0:00:38s\n","epoch 81 | loss: 0.11116 | val_0_mse: 0.09076999872922897|  0:00:39s\n","epoch 82 | loss: 0.10686 | val_0_mse: 0.12244000285863876|  0:00:39s\n","epoch 83 | loss: 0.10853 | val_0_mse: 0.09926000237464905|  0:00:39s\n","epoch 84 | loss: 0.11129 | val_0_mse: 0.11304999887943268|  0:00:40s\n","epoch 85 | loss: 0.08986 | val_0_mse: 0.08507999777793884|  0:00:40s\n","epoch 86 | loss: 0.08862 | val_0_mse: 0.09232000261545181|  0:00:41s\n","epoch 87 | loss: 0.09377 | val_0_mse: 0.08647000044584274|  0:00:41s\n","epoch 88 | loss: 0.09452 | val_0_mse: 0.08760999888181686|  0:00:42s\n","epoch 89 | loss: 0.08651 | val_0_mse: 0.08489000052213669|  0:00:42s\n","epoch 90 | loss: 0.08715 | val_0_mse: 0.0836699977517128|  0:00:43s\n","epoch 91 | loss: 0.08907 | val_0_mse: 0.10706000030040741|  0:00:43s\n","epoch 92 | loss: 0.10488 | val_0_mse: 0.13391999900341034|  0:00:44s\n","epoch 93 | loss: 0.10765 | val_0_mse: 0.1141899973154068|  0:00:44s\n","epoch 94 | loss: 0.08818 | val_0_mse: 0.08614999800920486|  0:00:45s\n","epoch 95 | loss: 0.08581 | val_0_mse: 0.09898000210523605|  0:00:45s\n","epoch 96 | loss: 0.09129 | val_0_mse: 0.10085000097751617|  0:00:46s\n","epoch 97 | loss: 0.10147 | val_0_mse: 0.08399000018835068|  0:00:46s\n","epoch 98 | loss: 0.08348 | val_0_mse: 0.08713000267744064|  0:00:47s\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 11:34:14,969] Trial 17 finished with value: 0.08367348462343216 and parameters: {'n_d': 31, 'n_steps': 3, 'gamma': 1.1594455158029895, 'n_independent': 1, 'n_shared': 3, 'momentum': 0.32877144425867566}. Best is trial 16 with value: 0.07793815433979034.\n"]},{"output_type":"stream","name":"stdout","text":["epoch 99 | loss: 0.09259 | val_0_mse: 0.08833000063896179|  0:00:47s\n","Stop training because you reached max_epochs = 100 with best_epoch = 90 and best_val_0_mse = 0.0836699977517128\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 81.30343| val_0_mse: 93200.46875|  0:00:00s\n","epoch 1  | loss: 6.18569 | val_0_mse: 31090.74609375|  0:00:01s\n","epoch 2  | loss: 0.99395 | val_0_mse: 8192.74609375|  0:00:01s\n","epoch 3  | loss: 0.52853 | val_0_mse: 4892.16845703125|  0:00:02s\n","epoch 4  | loss: 0.33375 | val_0_mse: 2334.7109375|  0:00:02s\n","epoch 5  | loss: 0.24239 | val_0_mse: 1338.04638671875|  0:00:03s\n","epoch 6  | loss: 0.23323 | val_0_mse: 5862.19091796875|  0:00:03s\n","epoch 7  | loss: 0.21092 | val_0_mse: 3433.441650390625|  0:00:04s\n","epoch 8  | loss: 0.2138  | val_0_mse: 3082.848876953125|  0:00:05s\n","epoch 9  | loss: 0.17302 | val_0_mse: 2050.748046875|  0:00:05s\n","epoch 10 | loss: 0.15066 | val_0_mse: 950.404052734375|  0:00:06s\n","epoch 11 | loss: 0.14693 | val_0_mse: 782.2364501953125|  0:00:06s\n","epoch 12 | loss: 0.15096 | val_0_mse: 778.8351440429688|  0:00:07s\n","epoch 13 | loss: 0.15144 | val_0_mse: 649.1821899414062|  0:00:08s\n","epoch 14 | loss: 0.13501 | val_0_mse: 411.6010437011719|  0:00:08s\n","epoch 15 | loss: 0.12281 | val_0_mse: 338.9166259765625|  0:00:09s\n","epoch 16 | loss: 0.12469 | val_0_mse: 248.73202514648438|  0:00:09s\n","epoch 17 | loss: 0.13485 | val_0_mse: 213.51022338867188|  0:00:10s\n","epoch 18 | loss: 0.12227 | val_0_mse: 121.16219329833984|  0:00:10s\n","epoch 19 | loss: 0.11783 | val_0_mse: 106.09819793701172|  0:00:11s\n","epoch 20 | loss: 0.1227  | val_0_mse: 109.96806335449219|  0:00:12s\n","epoch 21 | loss: 0.13544 | val_0_mse: 98.66146087646484|  0:00:12s\n","epoch 22 | loss: 0.12706 | val_0_mse: 83.07591247558594|  0:00:13s\n","epoch 23 | loss: 0.11966 | val_0_mse: 72.29553985595703|  0:00:13s\n","epoch 24 | loss: 0.10703 | val_0_mse: 59.77320861816406|  0:00:14s\n","epoch 25 | loss: 0.11134 | val_0_mse: 31.342269897460938|  0:00:14s\n","epoch 26 | loss: 0.10615 | val_0_mse: 20.738840103149414|  0:00:15s\n","epoch 27 | loss: 0.11514 | val_0_mse: 15.278360366821289|  0:00:16s\n","epoch 28 | loss: 0.10992 | val_0_mse: 6.766860008239746|  0:00:16s\n","epoch 29 | loss: 0.10855 | val_0_mse: 6.331019878387451|  0:00:17s\n","epoch 30 | loss: 0.11063 | val_0_mse: 8.696539878845215|  0:00:17s\n","epoch 31 | loss: 0.10868 | val_0_mse: 6.23036003112793|  0:00:18s\n","epoch 32 | loss: 0.11027 | val_0_mse: 4.853750228881836|  0:00:18s\n","epoch 33 | loss: 0.10273 | val_0_mse: 2.9060800075531006|  0:00:19s\n","epoch 34 | loss: 0.10861 | val_0_mse: 2.182849884033203|  0:00:20s\n","epoch 35 | loss: 0.09945 | val_0_mse: 2.193589925765991|  0:00:20s\n","epoch 36 | loss: 0.09757 | val_0_mse: 0.9890999794006348|  0:00:21s\n","epoch 37 | loss: 0.09503 | val_0_mse: 1.121019959449768|  0:00:21s\n","epoch 38 | loss: 0.1021  | val_0_mse: 0.8246200084686279|  0:00:22s\n","epoch 39 | loss: 0.13088 | val_0_mse: 0.23886999487876892|  0:00:22s\n","epoch 40 | loss: 0.1063  | val_0_mse: 0.3693700134754181|  0:00:23s\n","epoch 41 | loss: 0.10855 | val_0_mse: 0.9627500176429749|  0:00:24s\n","epoch 42 | loss: 0.10392 | val_0_mse: 1.068179965019226|  0:00:24s\n","epoch 43 | loss: 0.10719 | val_0_mse: 1.0345200300216675|  0:00:25s\n","epoch 44 | loss: 0.10383 | val_0_mse: 0.9335700273513794|  0:00:25s\n","epoch 45 | loss: 0.10132 | val_0_mse: 0.2946400046348572|  0:00:26s\n","epoch 46 | loss: 0.10123 | val_0_mse: 0.25637999176979065|  0:00:26s\n","epoch 47 | loss: 0.10001 | val_0_mse: 0.2615799903869629|  0:00:27s\n","epoch 48 | loss: 0.09627 | val_0_mse: 0.23486000299453735|  0:00:28s\n","epoch 49 | loss: 0.09623 | val_0_mse: 0.21026000380516052|  0:00:28s\n","epoch 50 | loss: 0.09662 | val_0_mse: 0.15752999484539032|  0:00:29s\n","epoch 51 | loss: 0.1023  | val_0_mse: 0.21096999943256378|  0:00:29s\n","epoch 52 | loss: 0.09792 | val_0_mse: 0.16026000678539276|  0:00:30s\n","epoch 53 | loss: 0.10118 | val_0_mse: 0.18750999867916107|  0:00:30s\n","epoch 54 | loss: 0.10498 | val_0_mse: 0.17690999805927277|  0:00:31s\n","epoch 55 | loss: 0.09738 | val_0_mse: 0.17739999294281006|  0:00:32s\n","epoch 56 | loss: 0.10083 | val_0_mse: 0.14509999752044678|  0:00:32s\n","epoch 57 | loss: 0.09651 | val_0_mse: 0.14323000609874725|  0:00:33s\n","epoch 58 | loss: 0.09383 | val_0_mse: 0.12514999508857727|  0:00:33s\n","epoch 59 | loss: 0.09551 | val_0_mse: 0.11875999718904495|  0:00:34s\n","epoch 60 | loss: 0.08742 | val_0_mse: 0.11548999696969986|  0:00:34s\n","epoch 61 | loss: 0.09689 | val_0_mse: 0.11872000247240067|  0:00:35s\n","epoch 62 | loss: 0.09909 | val_0_mse: 0.10153999924659729|  0:00:36s\n","epoch 63 | loss: 0.10134 | val_0_mse: 0.13882000744342804|  0:00:36s\n","epoch 64 | loss: 0.09278 | val_0_mse: 0.10328000038862228|  0:00:37s\n","epoch 65 | loss: 0.09198 | val_0_mse: 0.10063000023365021|  0:00:37s\n","epoch 66 | loss: 0.09022 | val_0_mse: 0.10067000240087509|  0:00:38s\n","epoch 67 | loss: 0.09536 | val_0_mse: 0.14667999744415283|  0:00:38s\n","epoch 68 | loss: 0.10013 | val_0_mse: 0.10085000097751617|  0:00:39s\n","epoch 69 | loss: 0.09217 | val_0_mse: 0.1160300001502037|  0:00:40s\n","epoch 70 | loss: 0.0941  | val_0_mse: 0.11175999790430069|  0:00:40s\n","epoch 71 | loss: 0.09213 | val_0_mse: 0.09523999691009521|  0:00:41s\n","epoch 72 | loss: 0.08768 | val_0_mse: 0.09617000073194504|  0:00:41s\n","epoch 73 | loss: 0.08727 | val_0_mse: 0.093019999563694|  0:00:42s\n","epoch 74 | loss: 0.08532 | val_0_mse: 0.08882000297307968|  0:00:42s\n","epoch 75 | loss: 0.08843 | val_0_mse: 0.09269999712705612|  0:00:43s\n","epoch 76 | loss: 0.09157 | val_0_mse: 0.09177999943494797|  0:00:44s\n","epoch 77 | loss: 0.08772 | val_0_mse: 0.09397999942302704|  0:00:44s\n","epoch 78 | loss: 0.09499 | val_0_mse: 0.09608999639749527|  0:00:45s\n","epoch 79 | loss: 0.0955  | val_0_mse: 0.10373000055551529|  0:00:45s\n","epoch 80 | loss: 0.09232 | val_0_mse: 0.09001000225543976|  0:00:46s\n","epoch 81 | loss: 0.08676 | val_0_mse: 0.10813000053167343|  0:00:46s\n","epoch 82 | loss: 0.0881  | val_0_mse: 0.09297999739646912|  0:00:47s\n","epoch 83 | loss: 0.09238 | val_0_mse: 0.09729000180959702|  0:00:48s\n","epoch 84 | loss: 0.0889  | val_0_mse: 0.09429000318050385|  0:00:48s\n","\n","Early stopping occurred at epoch 84 with best_epoch = 74 and best_val_0_mse = 0.08882000297307968\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 11:35:03,933] Trial 18 finished with value: 0.0888156145811081 and parameters: {'n_d': 17, 'n_steps': 4, 'gamma': 1.1740849048321018, 'n_independent': 1, 'n_shared': 3, 'momentum': 0.3949769232632423}. Best is trial 16 with value: 0.07793815433979034.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 65.60349| val_0_mse: 40170.83984375|  0:00:00s\n","epoch 1  | loss: 2.97685 | val_0_mse: 38188.25390625|  0:00:01s\n","epoch 2  | loss: 0.75347 | val_0_mse: 24091.44140625|  0:00:01s\n","epoch 3  | loss: 0.42664 | val_0_mse: 3189.383056640625|  0:00:02s\n","epoch 4  | loss: 0.32054 | val_0_mse: 1116.1026611328125|  0:00:03s\n","epoch 5  | loss: 0.27707 | val_0_mse: 1429.5855712890625|  0:00:03s\n","epoch 6  | loss: 0.2736  | val_0_mse: 1006.88525390625|  0:00:04s\n","epoch 7  | loss: 0.25954 | val_0_mse: 787.683837890625|  0:00:05s\n","epoch 8  | loss: 0.21552 | val_0_mse: 758.7236938476562|  0:00:05s\n","epoch 9  | loss: 0.18037 | val_0_mse: 1004.1557006835938|  0:00:06s\n","epoch 10 | loss: 0.16471 | val_0_mse: 1098.49169921875|  0:00:07s\n","epoch 11 | loss: 0.16973 | val_0_mse: 789.0615844726562|  0:00:07s\n","epoch 12 | loss: 0.16918 | val_0_mse: 369.0905456542969|  0:00:08s\n","epoch 13 | loss: 0.15704 | val_0_mse: 224.1685028076172|  0:00:08s\n","epoch 14 | loss: 0.14879 | val_0_mse: 54.32883834838867|  0:00:09s\n","epoch 15 | loss: 0.14365 | val_0_mse: 43.798500061035156|  0:00:10s\n","epoch 16 | loss: 0.13971 | val_0_mse: 33.178138732910156|  0:00:10s\n","epoch 17 | loss: 0.13913 | val_0_mse: 18.700769424438477|  0:00:11s\n","epoch 18 | loss: 0.13751 | val_0_mse: 11.393730163574219|  0:00:11s\n","epoch 19 | loss: 0.14831 | val_0_mse: 17.707799911499023|  0:00:12s\n","epoch 20 | loss: 0.13486 | val_0_mse: 20.583860397338867|  0:00:13s\n","epoch 21 | loss: 0.12416 | val_0_mse: 12.331740379333496|  0:00:13s\n","epoch 22 | loss: 0.12666 | val_0_mse: 8.119159698486328|  0:00:14s\n","epoch 23 | loss: 0.12336 | val_0_mse: 5.240890026092529|  0:00:14s\n","epoch 24 | loss: 0.11883 | val_0_mse: 3.009860038757324|  0:00:15s\n","epoch 25 | loss: 0.12986 | val_0_mse: 1.344249963760376|  0:00:16s\n","epoch 26 | loss: 0.12575 | val_0_mse: 1.8007500171661377|  0:00:16s\n","epoch 27 | loss: 0.1098  | val_0_mse: 1.4808800220489502|  0:00:17s\n","epoch 28 | loss: 0.12641 | val_0_mse: 1.5088800191879272|  0:00:18s\n","epoch 29 | loss: 0.11119 | val_0_mse: 1.0667099952697754|  0:00:18s\n","epoch 30 | loss: 0.11118 | val_0_mse: 1.587399959564209|  0:00:19s\n","epoch 31 | loss: 0.10823 | val_0_mse: 1.1485999822616577|  0:00:19s\n","epoch 32 | loss: 0.10119 | val_0_mse: 0.9491900205612183|  0:00:20s\n","epoch 33 | loss: 0.10815 | val_0_mse: 1.3198100328445435|  0:00:21s\n","epoch 34 | loss: 0.10173 | val_0_mse: 1.5592800378799438|  0:00:21s\n","epoch 35 | loss: 0.09477 | val_0_mse: 0.5854799747467041|  0:00:22s\n","epoch 36 | loss: 0.09787 | val_0_mse: 0.5691699981689453|  0:00:22s\n","epoch 37 | loss: 0.11675 | val_0_mse: 0.402539998292923|  0:00:23s\n","epoch 38 | loss: 0.11548 | val_0_mse: 0.46838000416755676|  0:00:24s\n","epoch 39 | loss: 0.1059  | val_0_mse: 0.3342899978160858|  0:00:24s\n","epoch 40 | loss: 0.10351 | val_0_mse: 0.30118000507354736|  0:00:25s\n","epoch 41 | loss: 0.09999 | val_0_mse: 0.4205699861049652|  0:00:26s\n","epoch 42 | loss: 0.10947 | val_0_mse: 0.2319200038909912|  0:00:26s\n","epoch 43 | loss: 0.13801 | val_0_mse: 0.28036001324653625|  0:00:27s\n","epoch 44 | loss: 0.12859 | val_0_mse: 0.5516200065612793|  0:00:27s\n","epoch 45 | loss: 0.13785 | val_0_mse: 0.23003999888896942|  0:00:28s\n","epoch 46 | loss: 0.13161 | val_0_mse: 0.3493100106716156|  0:00:29s\n","epoch 47 | loss: 0.12456 | val_0_mse: 0.16210000216960907|  0:00:29s\n","epoch 48 | loss: 0.11978 | val_0_mse: 0.23773999512195587|  0:00:30s\n","epoch 49 | loss: 0.10336 | val_0_mse: 0.23752999305725098|  0:00:30s\n","epoch 50 | loss: 0.11712 | val_0_mse: 0.1451600044965744|  0:00:31s\n","epoch 51 | loss: 0.09903 | val_0_mse: 0.1818999946117401|  0:00:32s\n","epoch 52 | loss: 0.09814 | val_0_mse: 0.18931999802589417|  0:00:32s\n","epoch 53 | loss: 0.09264 | val_0_mse: 0.15150000154972076|  0:00:33s\n","epoch 54 | loss: 0.08992 | val_0_mse: 0.11883000284433365|  0:00:33s\n","epoch 55 | loss: 0.09185 | val_0_mse: 0.11240000277757645|  0:00:34s\n","epoch 56 | loss: 0.09516 | val_0_mse: 0.10394000262022018|  0:00:35s\n","epoch 57 | loss: 0.12255 | val_0_mse: 0.2119400054216385|  0:00:35s\n","epoch 58 | loss: 0.12051 | val_0_mse: 0.1043500006198883|  0:00:36s\n","epoch 59 | loss: 0.11158 | val_0_mse: 0.27744999527931213|  0:00:36s\n","epoch 60 | loss: 0.13727 | val_0_mse: 0.12201999872922897|  0:00:37s\n","epoch 61 | loss: 0.12083 | val_0_mse: 0.11801999807357788|  0:00:38s\n","epoch 62 | loss: 0.10679 | val_0_mse: 0.10995999723672867|  0:00:38s\n","epoch 63 | loss: 0.09939 | val_0_mse: 0.09294000267982483|  0:00:39s\n","epoch 64 | loss: 0.09447 | val_0_mse: 0.09245000034570694|  0:00:40s\n","epoch 65 | loss: 0.09475 | val_0_mse: 0.10685999691486359|  0:00:40s\n","epoch 66 | loss: 0.09457 | val_0_mse: 0.09122999757528305|  0:00:41s\n","epoch 67 | loss: 0.09357 | val_0_mse: 0.09585999697446823|  0:00:41s\n","epoch 68 | loss: 0.09254 | val_0_mse: 0.08856000006198883|  0:00:42s\n","epoch 69 | loss: 0.08681 | val_0_mse: 0.09830000251531601|  0:00:43s\n","epoch 70 | loss: 0.09368 | val_0_mse: 0.09380000084638596|  0:00:43s\n","epoch 71 | loss: 0.0926  | val_0_mse: 0.08393999934196472|  0:00:44s\n","epoch 72 | loss: 0.08905 | val_0_mse: 0.10126999765634537|  0:00:44s\n","epoch 73 | loss: 0.08665 | val_0_mse: 0.09385000169277191|  0:00:45s\n","epoch 74 | loss: 0.08321 | val_0_mse: 0.08388999849557877|  0:00:46s\n","epoch 75 | loss: 0.08088 | val_0_mse: 0.09509000182151794|  0:00:46s\n","epoch 76 | loss: 0.08681 | val_0_mse: 0.08792000263929367|  0:00:47s\n","epoch 77 | loss: 0.08711 | val_0_mse: 0.09160999953746796|  0:00:48s\n","epoch 78 | loss: 0.09316 | val_0_mse: 0.11450999975204468|  0:00:48s\n","epoch 79 | loss: 0.12756 | val_0_mse: 0.10107000172138214|  0:00:49s\n","epoch 80 | loss: 0.11364 | val_0_mse: 0.10086999833583832|  0:00:49s\n","epoch 81 | loss: 0.10649 | val_0_mse: 0.09071999788284302|  0:00:50s\n","epoch 82 | loss: 0.098   | val_0_mse: 0.09245000034570694|  0:00:51s\n","epoch 83 | loss: 0.10398 | val_0_mse: 0.08980000019073486|  0:00:51s\n","epoch 84 | loss: 0.09897 | val_0_mse: 0.08822000026702881|  0:00:52s\n","\n","Early stopping occurred at epoch 84 with best_epoch = 74 and best_val_0_mse = 0.08388999849557877\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 11:35:56,576] Trial 19 finished with value: 0.08388710767030716 and parameters: {'n_d': 33, 'n_steps': 3, 'gamma': 1.1396291982901956, 'n_independent': 1, 'n_shared': 5, 'momentum': 0.33985804157246285}. Best is trial 16 with value: 0.07793815433979034.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 41.743  | val_0_mse: 139237.46875|  0:00:00s\n","epoch 1  | loss: 3.17567 | val_0_mse: 9406.16015625|  0:00:01s\n","epoch 2  | loss: 0.76804 | val_0_mse: 5364.353515625|  0:00:01s\n","epoch 3  | loss: 0.6186  | val_0_mse: 557.447998046875|  0:00:02s\n","epoch 4  | loss: 0.47854 | val_0_mse: 1239.468994140625|  0:00:03s\n","epoch 5  | loss: 0.39735 | val_0_mse: 424.7896728515625|  0:00:03s\n","epoch 6  | loss: 0.31642 | val_0_mse: 1018.614990234375|  0:00:04s\n","epoch 7  | loss: 0.30536 | val_0_mse: 351.0198669433594|  0:00:05s\n","epoch 8  | loss: 0.27384 | val_0_mse: 109.18501281738281|  0:00:05s\n","epoch 9  | loss: 0.22071 | val_0_mse: 256.1922912597656|  0:00:06s\n","epoch 10 | loss: 0.19848 | val_0_mse: 254.0708770751953|  0:00:07s\n","epoch 11 | loss: 0.19412 | val_0_mse: 122.06566619873047|  0:00:07s\n","epoch 12 | loss: 0.17122 | val_0_mse: 53.83808135986328|  0:00:08s\n","epoch 13 | loss: 0.18171 | val_0_mse: 50.6327018737793|  0:00:09s\n","epoch 14 | loss: 0.16267 | val_0_mse: 67.82064056396484|  0:00:10s\n","epoch 15 | loss: 0.16005 | val_0_mse: 32.77643966674805|  0:00:10s\n","epoch 16 | loss: 0.1912  | val_0_mse: 36.897560119628906|  0:00:11s\n","epoch 17 | loss: 0.14323 | val_0_mse: 3.8406500816345215|  0:00:12s\n","epoch 18 | loss: 0.149   | val_0_mse: 9.621100425720215|  0:00:12s\n","epoch 19 | loss: 0.14805 | val_0_mse: 7.924190044403076|  0:00:13s\n","epoch 20 | loss: 0.14189 | val_0_mse: 8.370400428771973|  0:00:13s\n","epoch 21 | loss: 0.12963 | val_0_mse: 2.884500026702881|  0:00:14s\n","epoch 22 | loss: 0.12879 | val_0_mse: 2.623850107192993|  0:00:15s\n","epoch 23 | loss: 0.14528 | val_0_mse: 9.719490051269531|  0:00:15s\n","epoch 24 | loss: 0.13696 | val_0_mse: 15.381070137023926|  0:00:16s\n","epoch 25 | loss: 0.14671 | val_0_mse: 7.433430194854736|  0:00:17s\n","epoch 26 | loss: 0.152   | val_0_mse: 3.0055899620056152|  0:00:18s\n","epoch 27 | loss: 0.1438  | val_0_mse: 2.6463301181793213|  0:00:18s\n","epoch 28 | loss: 0.1376  | val_0_mse: 1.7681100368499756|  0:00:19s\n","epoch 29 | loss: 0.13829 | val_0_mse: 1.8903000354766846|  0:00:20s\n","epoch 30 | loss: 0.13523 | val_0_mse: 1.6130499839782715|  0:00:20s\n","epoch 31 | loss: 0.13354 | val_0_mse: 0.798799991607666|  0:00:21s\n","epoch 32 | loss: 0.13089 | val_0_mse: 0.6434800028800964|  0:00:22s\n","epoch 33 | loss: 0.13239 | val_0_mse: 0.6853899955749512|  0:00:22s\n","epoch 34 | loss: 0.12844 | val_0_mse: 0.5479300022125244|  0:00:23s\n","epoch 35 | loss: 0.13248 | val_0_mse: 0.40171998739242554|  0:00:24s\n","epoch 36 | loss: 0.12893 | val_0_mse: 0.2805199921131134|  0:00:24s\n","epoch 37 | loss: 0.1438  | val_0_mse: 0.27410998940467834|  0:00:25s\n","epoch 38 | loss: 0.18417 | val_0_mse: 0.2367600053548813|  0:00:26s\n","epoch 39 | loss: 0.1748  | val_0_mse: 0.24025000631809235|  0:00:26s\n","epoch 40 | loss: 0.13641 | val_0_mse: 0.19163000583648682|  0:00:27s\n","epoch 41 | loss: 0.13929 | val_0_mse: 0.22672000527381897|  0:00:28s\n","epoch 42 | loss: 0.1653  | val_0_mse: 0.1949699968099594|  0:00:28s\n","epoch 43 | loss: 0.13757 | val_0_mse: 0.19612999260425568|  0:00:29s\n","epoch 44 | loss: 0.13692 | val_0_mse: 0.22919000685214996|  0:00:30s\n","epoch 45 | loss: 0.13939 | val_0_mse: 0.20780999958515167|  0:00:30s\n","epoch 46 | loss: 0.13662 | val_0_mse: 0.20146000385284424|  0:00:31s\n","epoch 47 | loss: 0.13651 | val_0_mse: 0.1843400001525879|  0:00:32s\n","epoch 48 | loss: 0.13017 | val_0_mse: 0.24146999418735504|  0:00:33s\n","epoch 49 | loss: 0.14538 | val_0_mse: 0.16654999554157257|  0:00:33s\n","epoch 50 | loss: 0.12673 | val_0_mse: 0.189410001039505|  0:00:34s\n","epoch 51 | loss: 0.1253  | val_0_mse: 0.19800999760627747|  0:00:34s\n","epoch 52 | loss: 0.13611 | val_0_mse: 0.15392999351024628|  0:00:35s\n","epoch 53 | loss: 0.13689 | val_0_mse: 0.13819000124931335|  0:00:36s\n","epoch 54 | loss: 0.13597 | val_0_mse: 0.19829000532627106|  0:00:36s\n","epoch 55 | loss: 0.13199 | val_0_mse: 0.14236000180244446|  0:00:37s\n","epoch 56 | loss: 0.11553 | val_0_mse: 0.15191000699996948|  0:00:38s\n","epoch 57 | loss: 0.11768 | val_0_mse: 0.1582300066947937|  0:00:38s\n","epoch 58 | loss: 0.13171 | val_0_mse: 0.15313999354839325|  0:00:39s\n","epoch 59 | loss: 0.13578 | val_0_mse: 0.20743000507354736|  0:00:40s\n","epoch 60 | loss: 0.13289 | val_0_mse: 0.13917000591754913|  0:00:40s\n","epoch 61 | loss: 0.11788 | val_0_mse: 0.1554899960756302|  0:00:41s\n","epoch 62 | loss: 0.12142 | val_0_mse: 0.14458000659942627|  0:00:42s\n","epoch 63 | loss: 0.12023 | val_0_mse: 0.13845999538898468|  0:00:43s\n","\n","Early stopping occurred at epoch 63 with best_epoch = 53 and best_val_0_mse = 0.13819000124931335\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 11:36:40,072] Trial 20 finished with value: 0.1381937712430954 and parameters: {'n_d': 19, 'n_steps': 5, 'gamma': 1.3549690327744897, 'n_independent': 1, 'n_shared': 3, 'momentum': 0.35090733011063435}. Best is trial 16 with value: 0.07793815433979034.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 61.29058| val_0_mse: 62404.7265625|  0:00:00s\n","epoch 1  | loss: 2.22765 | val_0_mse: 31850.271484375|  0:00:01s\n","epoch 2  | loss: 0.65509 | val_0_mse: 947.781494140625|  0:00:01s\n","epoch 3  | loss: 0.48105 | val_0_mse: 310.7198181152344|  0:00:02s\n","epoch 4  | loss: 0.35106 | val_0_mse: 216.61257934570312|  0:00:02s\n","epoch 5  | loss: 0.30308 | val_0_mse: 186.03512573242188|  0:00:03s\n","epoch 6  | loss: 0.23317 | val_0_mse: 117.10843658447266|  0:00:04s\n","epoch 7  | loss: 0.19689 | val_0_mse: 106.58946228027344|  0:00:04s\n","epoch 8  | loss: 0.17327 | val_0_mse: 68.87458801269531|  0:00:05s\n","epoch 9  | loss: 0.21986 | val_0_mse: 56.02788162231445|  0:00:06s\n","epoch 10 | loss: 0.18824 | val_0_mse: 25.179279327392578|  0:00:06s\n","epoch 11 | loss: 0.16859 | val_0_mse: 20.74873924255371|  0:00:07s\n","epoch 12 | loss: 0.19989 | val_0_mse: 9.76144027709961|  0:00:07s\n","epoch 13 | loss: 0.1769  | val_0_mse: 5.906819820404053|  0:00:08s\n","epoch 14 | loss: 0.14801 | val_0_mse: 4.675159931182861|  0:00:09s\n","epoch 15 | loss: 0.14111 | val_0_mse: 3.225939989089966|  0:00:09s\n","epoch 16 | loss: 0.13837 | val_0_mse: 1.9982999563217163|  0:00:10s\n","epoch 17 | loss: 0.14329 | val_0_mse: 1.2891099452972412|  0:00:11s\n","epoch 18 | loss: 0.1404  | val_0_mse: 0.918910026550293|  0:00:11s\n","epoch 19 | loss: 0.13655 | val_0_mse: 0.7200599908828735|  0:00:12s\n","epoch 20 | loss: 0.12168 | val_0_mse: 1.0033700466156006|  0:00:12s\n","epoch 21 | loss: 0.11516 | val_0_mse: 1.075819969177246|  0:00:13s\n","epoch 22 | loss: 0.11899 | val_0_mse: 1.2704099416732788|  0:00:14s\n","epoch 23 | loss: 0.11155 | val_0_mse: 0.8083500266075134|  0:00:14s\n","epoch 24 | loss: 0.10888 | val_0_mse: 0.7974900007247925|  0:00:15s\n","epoch 25 | loss: 0.10485 | val_0_mse: 0.4455699920654297|  0:00:15s\n","epoch 26 | loss: 0.09894 | val_0_mse: 0.4966000020503998|  0:00:16s\n","epoch 27 | loss: 0.11116 | val_0_mse: 1.0380699634552002|  0:00:17s\n","epoch 28 | loss: 0.10915 | val_0_mse: 1.1291899681091309|  0:00:17s\n","epoch 29 | loss: 0.10555 | val_0_mse: 0.4431999921798706|  0:00:18s\n","epoch 30 | loss: 0.10418 | val_0_mse: 0.4134899973869324|  0:00:18s\n","epoch 31 | loss: 0.10811 | val_0_mse: 0.48600998520851135|  0:00:19s\n","epoch 32 | loss: 0.10526 | val_0_mse: 0.4886299967765808|  0:00:20s\n","epoch 33 | loss: 0.11026 | val_0_mse: 0.4057900011539459|  0:00:20s\n","epoch 34 | loss: 0.10179 | val_0_mse: 0.35293999314308167|  0:00:21s\n","epoch 35 | loss: 0.09403 | val_0_mse: 0.3192799985408783|  0:00:22s\n","epoch 36 | loss: 0.11401 | val_0_mse: 0.4634599983692169|  0:00:22s\n","epoch 37 | loss: 0.13709 | val_0_mse: 0.23171000182628632|  0:00:23s\n","epoch 38 | loss: 0.14983 | val_0_mse: 0.2641899883747101|  0:00:23s\n","epoch 39 | loss: 0.10581 | val_0_mse: 0.2828499972820282|  0:00:24s\n","epoch 40 | loss: 0.12284 | val_0_mse: 0.2236199975013733|  0:00:25s\n","epoch 41 | loss: 0.11936 | val_0_mse: 0.2571600079536438|  0:00:25s\n","epoch 42 | loss: 0.10108 | val_0_mse: 0.23205000162124634|  0:00:26s\n","epoch 43 | loss: 0.09295 | val_0_mse: 0.24786999821662903|  0:00:26s\n","epoch 44 | loss: 0.09121 | val_0_mse: 0.24624000489711761|  0:00:27s\n","epoch 45 | loss: 0.09039 | val_0_mse: 0.2254599928855896|  0:00:28s\n","epoch 46 | loss: 0.09027 | val_0_mse: 0.20427000522613525|  0:00:28s\n","epoch 47 | loss: 0.08991 | val_0_mse: 0.23262999951839447|  0:00:29s\n","epoch 48 | loss: 0.08767 | val_0_mse: 0.23890000581741333|  0:00:29s\n","epoch 49 | loss: 0.10917 | val_0_mse: 0.16072000563144684|  0:00:30s\n","epoch 50 | loss: 0.12095 | val_0_mse: 0.1679999977350235|  0:00:31s\n","epoch 51 | loss: 0.08842 | val_0_mse: 0.15275999903678894|  0:00:31s\n","epoch 52 | loss: 0.08727 | val_0_mse: 0.1666799932718277|  0:00:32s\n","epoch 53 | loss: 0.09078 | val_0_mse: 0.1384200006723404|  0:00:32s\n","epoch 54 | loss: 0.08967 | val_0_mse: 0.13524000346660614|  0:00:33s\n","epoch 55 | loss: 0.09146 | val_0_mse: 0.12351000308990479|  0:00:34s\n","epoch 56 | loss: 0.09191 | val_0_mse: 0.157150000333786|  0:00:34s\n","epoch 57 | loss: 0.08927 | val_0_mse: 0.16496999561786652|  0:00:35s\n","epoch 58 | loss: 0.08843 | val_0_mse: 0.11251000314950943|  0:00:36s\n","epoch 59 | loss: 0.10369 | val_0_mse: 0.1701499968767166|  0:00:36s\n","epoch 60 | loss: 0.10006 | val_0_mse: 0.1536400020122528|  0:00:37s\n","epoch 61 | loss: 0.12236 | val_0_mse: 0.09853000193834305|  0:00:37s\n","epoch 62 | loss: 0.11048 | val_0_mse: 0.1685599982738495|  0:00:38s\n","epoch 63 | loss: 0.10648 | val_0_mse: 0.09250999987125397|  0:00:39s\n","epoch 64 | loss: 0.11354 | val_0_mse: 0.13792000710964203|  0:00:39s\n","epoch 65 | loss: 0.10837 | val_0_mse: 0.09093999862670898|  0:00:40s\n","epoch 66 | loss: 0.10916 | val_0_mse: 0.13987000286579132|  0:00:40s\n","epoch 67 | loss: 0.105   | val_0_mse: 0.09935999661684036|  0:00:41s\n","epoch 68 | loss: 0.08987 | val_0_mse: 0.09009999781847|  0:00:42s\n","epoch 69 | loss: 0.08084 | val_0_mse: 0.0938199982047081|  0:00:42s\n","epoch 70 | loss: 0.08099 | val_0_mse: 0.09414999932050705|  0:00:43s\n","epoch 71 | loss: 0.08479 | val_0_mse: 0.09651000052690506|  0:00:44s\n","epoch 72 | loss: 0.08504 | val_0_mse: 0.08451999723911285|  0:00:44s\n","epoch 73 | loss: 0.08615 | val_0_mse: 0.08624999970197678|  0:00:45s\n","epoch 74 | loss: 0.08158 | val_0_mse: 0.08643999695777893|  0:00:46s\n","epoch 75 | loss: 0.08311 | val_0_mse: 0.09113000333309174|  0:00:46s\n","epoch 76 | loss: 0.0783  | val_0_mse: 0.08357000350952148|  0:00:47s\n","epoch 77 | loss: 0.08247 | val_0_mse: 0.08138000220060349|  0:00:47s\n","epoch 78 | loss: 0.07615 | val_0_mse: 0.09019999951124191|  0:00:48s\n","epoch 79 | loss: 0.08268 | val_0_mse: 0.087459996342659|  0:00:49s\n","epoch 80 | loss: 0.0823  | val_0_mse: 0.08409000188112259|  0:00:49s\n","epoch 81 | loss: 0.08059 | val_0_mse: 0.08333999663591385|  0:00:50s\n","epoch 82 | loss: 0.087   | val_0_mse: 0.08967000246047974|  0:00:50s\n","epoch 83 | loss: 0.09014 | val_0_mse: 0.08590999990701675|  0:00:51s\n","epoch 84 | loss: 0.07888 | val_0_mse: 0.09602999687194824|  0:00:52s\n","epoch 85 | loss: 0.07976 | val_0_mse: 0.07959999889135361|  0:00:52s\n","epoch 86 | loss: 0.08583 | val_0_mse: 0.10648000240325928|  0:00:53s\n","epoch 87 | loss: 0.0855  | val_0_mse: 0.09179999679327011|  0:00:53s\n","epoch 88 | loss: 0.07987 | val_0_mse: 0.09483999758958817|  0:00:54s\n","epoch 89 | loss: 0.09036 | val_0_mse: 0.09167999774217606|  0:00:55s\n","epoch 90 | loss: 0.09091 | val_0_mse: 0.0839800015091896|  0:00:55s\n","epoch 91 | loss: 0.08556 | val_0_mse: 0.08094000071287155|  0:00:56s\n","epoch 92 | loss: 0.08854 | val_0_mse: 0.14890000224113464|  0:00:56s\n","epoch 93 | loss: 0.08958 | val_0_mse: 0.08399000018835068|  0:00:57s\n","epoch 94 | loss: 0.07764 | val_0_mse: 0.07709000259637833|  0:00:58s\n","epoch 95 | loss: 0.07358 | val_0_mse: 0.07864999771118164|  0:00:58s\n","epoch 96 | loss: 0.07543 | val_0_mse: 0.07693000137805939|  0:00:59s\n","epoch 97 | loss: 0.07649 | val_0_mse: 0.0858599990606308|  0:01:00s\n","epoch 98 | loss: 0.08033 | val_0_mse: 0.07985000312328339|  0:01:00s\n","epoch 99 | loss: 0.07501 | val_0_mse: 0.07927999645471573|  0:01:01s\n","Stop training because you reached max_epochs = 100 with best_epoch = 96 and best_val_0_mse = 0.07693000137805939\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 11:37:41,629] Trial 21 finished with value: 0.0769263356924057 and parameters: {'n_d': 34, 'n_steps': 3, 'gamma': 1.1295780495198344, 'n_independent': 1, 'n_shared': 5, 'momentum': 0.33773158930742175}. Best is trial 21 with value: 0.0769263356924057.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 51.39173| val_0_mse: 2311.704833984375|  0:00:00s\n","epoch 1  | loss: 1.75623 | val_0_mse: 3190.06005859375|  0:00:01s\n","epoch 2  | loss: 0.87292 | val_0_mse: 1185.1099853515625|  0:00:02s\n","epoch 3  | loss: 0.38024 | val_0_mse: 3492.532470703125|  0:00:02s\n","epoch 4  | loss: 0.28006 | val_0_mse: 781.8914184570312|  0:00:03s\n","epoch 5  | loss: 0.30845 | val_0_mse: 644.0033569335938|  0:00:04s\n","epoch 6  | loss: 0.31381 | val_0_mse: 420.27532958984375|  0:00:04s\n","epoch 7  | loss: 0.24469 | val_0_mse: 133.8311004638672|  0:00:05s\n","epoch 8  | loss: 0.18672 | val_0_mse: 253.7183074951172|  0:00:06s\n","epoch 9  | loss: 0.25011 | val_0_mse: 186.09249877929688|  0:00:07s\n","epoch 10 | loss: 0.19869 | val_0_mse: 47.697750091552734|  0:00:07s\n","epoch 11 | loss: 0.17277 | val_0_mse: 8.33745002746582|  0:00:08s\n","epoch 12 | loss: 0.18927 | val_0_mse: 44.156288146972656|  0:00:09s\n","epoch 13 | loss: 0.18224 | val_0_mse: 3.976020097732544|  0:00:09s\n","epoch 14 | loss: 0.22971 | val_0_mse: 5.504129886627197|  0:00:10s\n","epoch 15 | loss: 0.18218 | val_0_mse: 12.130590438842773|  0:00:11s\n","epoch 16 | loss: 0.15237 | val_0_mse: 7.135540008544922|  0:00:11s\n","epoch 17 | loss: 0.14268 | val_0_mse: 4.566840171813965|  0:00:12s\n","epoch 18 | loss: 0.1641  | val_0_mse: 13.192560195922852|  0:00:13s\n","epoch 19 | loss: 0.15125 | val_0_mse: 68.91130065917969|  0:00:13s\n","epoch 20 | loss: 0.14478 | val_0_mse: 28.860319137573242|  0:00:14s\n","epoch 21 | loss: 0.14173 | val_0_mse: 16.834989547729492|  0:00:15s\n","epoch 22 | loss: 0.13961 | val_0_mse: 13.433270454406738|  0:00:15s\n","epoch 23 | loss: 0.1347  | val_0_mse: 2.3140499591827393|  0:00:16s\n","epoch 24 | loss: 0.13457 | val_0_mse: 1.9369800090789795|  0:00:17s\n","epoch 25 | loss: 0.10869 | val_0_mse: 7.092430114746094|  0:00:17s\n","epoch 26 | loss: 0.10831 | val_0_mse: 3.3575398921966553|  0:00:18s\n","epoch 27 | loss: 0.12875 | val_0_mse: 2.6849300861358643|  0:00:19s\n","epoch 28 | loss: 0.15264 | val_0_mse: 5.669159889221191|  0:00:19s\n","epoch 29 | loss: 0.11042 | val_0_mse: 1.8295199871063232|  0:00:20s\n","epoch 30 | loss: 0.10234 | val_0_mse: 2.0946600437164307|  0:00:21s\n","epoch 31 | loss: 0.10161 | val_0_mse: 1.1446599960327148|  0:00:21s\n","epoch 32 | loss: 0.10509 | val_0_mse: 1.9309500455856323|  0:00:22s\n","epoch 33 | loss: 0.10681 | val_0_mse: 0.7445600032806396|  0:00:23s\n","epoch 34 | loss: 0.10072 | val_0_mse: 1.5863399505615234|  0:00:23s\n","epoch 35 | loss: 0.09631 | val_0_mse: 0.5920000076293945|  0:00:24s\n","epoch 36 | loss: 0.09832 | val_0_mse: 0.7711700201034546|  0:00:25s\n","epoch 37 | loss: 0.11989 | val_0_mse: 0.332069993019104|  0:00:25s\n","epoch 38 | loss: 0.09455 | val_0_mse: 0.8506399989128113|  0:00:26s\n","epoch 39 | loss: 0.09814 | val_0_mse: 0.3454900085926056|  0:00:27s\n","epoch 40 | loss: 0.0934  | val_0_mse: 0.334960013628006|  0:00:28s\n","epoch 41 | loss: 0.10579 | val_0_mse: 0.45065000653266907|  0:00:28s\n","epoch 42 | loss: 0.10428 | val_0_mse: 0.24807000160217285|  0:00:29s\n","epoch 43 | loss: 0.1276  | val_0_mse: 0.5184100270271301|  0:00:30s\n","epoch 44 | loss: 0.12127 | val_0_mse: 0.19381000101566315|  0:00:30s\n","epoch 45 | loss: 0.11673 | val_0_mse: 0.3752399981021881|  0:00:31s\n","epoch 46 | loss: 0.11515 | val_0_mse: 0.2203100025653839|  0:00:32s\n","epoch 47 | loss: 0.10936 | val_0_mse: 0.4216099977493286|  0:00:32s\n","epoch 48 | loss: 0.12112 | val_0_mse: 0.14861999452114105|  0:00:33s\n","epoch 49 | loss: 0.1171  | val_0_mse: 0.404449999332428|  0:00:34s\n","epoch 50 | loss: 0.11315 | val_0_mse: 0.1400199979543686|  0:00:34s\n","epoch 51 | loss: 0.1065  | val_0_mse: 0.3143100142478943|  0:00:35s\n","epoch 52 | loss: 0.10589 | val_0_mse: 0.12349999696016312|  0:00:36s\n","epoch 53 | loss: 0.11323 | val_0_mse: 0.30726000666618347|  0:00:37s\n","epoch 54 | loss: 0.11004 | val_0_mse: 0.12167000025510788|  0:00:37s\n","epoch 55 | loss: 0.10743 | val_0_mse: 0.27028998732566833|  0:00:38s\n","epoch 56 | loss: 0.10518 | val_0_mse: 0.11107999831438065|  0:00:39s\n","epoch 57 | loss: 0.1077  | val_0_mse: 0.23833000659942627|  0:00:39s\n","epoch 58 | loss: 0.09932 | val_0_mse: 0.13346999883651733|  0:00:40s\n","epoch 59 | loss: 0.08553 | val_0_mse: 0.12118999660015106|  0:00:41s\n","epoch 60 | loss: 0.13224 | val_0_mse: 0.1826300024986267|  0:00:41s\n","epoch 61 | loss: 0.18916 | val_0_mse: 0.16267000138759613|  0:00:42s\n","epoch 62 | loss: 0.1438  | val_0_mse: 0.13612000644207|  0:00:43s\n","epoch 63 | loss: 0.11948 | val_0_mse: 0.12646999955177307|  0:00:43s\n","epoch 64 | loss: 0.12976 | val_0_mse: 0.097680002450943|  0:00:44s\n","epoch 65 | loss: 0.12222 | val_0_mse: 0.17780999839305878|  0:00:45s\n","epoch 66 | loss: 0.12018 | val_0_mse: 0.09350000321865082|  0:00:45s\n","epoch 67 | loss: 0.11502 | val_0_mse: 0.12358999997377396|  0:00:46s\n","epoch 68 | loss: 0.10798 | val_0_mse: 0.10681000351905823|  0:00:47s\n","epoch 69 | loss: 0.09589 | val_0_mse: 0.08354999870061874|  0:00:47s\n","epoch 70 | loss: 0.08386 | val_0_mse: 0.08788000047206879|  0:00:48s\n","epoch 71 | loss: 0.07645 | val_0_mse: 0.08538000285625458|  0:00:49s\n","epoch 72 | loss: 0.07798 | val_0_mse: 0.07953000068664551|  0:00:49s\n","epoch 73 | loss: 0.07658 | val_0_mse: 0.08180999755859375|  0:00:50s\n","epoch 74 | loss: 0.09175 | val_0_mse: 0.08303999900817871|  0:00:51s\n","epoch 75 | loss: 0.08815 | val_0_mse: 0.09582000225782394|  0:00:51s\n","epoch 76 | loss: 0.08615 | val_0_mse: 0.09352000057697296|  0:00:52s\n","epoch 77 | loss: 0.08799 | val_0_mse: 0.11789999902248383|  0:00:53s\n","epoch 78 | loss: 0.08068 | val_0_mse: 0.08174999803304672|  0:00:53s\n","epoch 79 | loss: 0.0793  | val_0_mse: 0.0914900004863739|  0:00:54s\n","epoch 80 | loss: 0.08312 | val_0_mse: 0.08053000271320343|  0:00:55s\n","epoch 81 | loss: 0.08582 | val_0_mse: 0.09397000074386597|  0:00:55s\n","epoch 82 | loss: 0.08979 | val_0_mse: 0.08924999833106995|  0:00:56s\n","\n","Early stopping occurred at epoch 82 with best_epoch = 72 and best_val_0_mse = 0.07953000068664551\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 11:38:38,669] Trial 22 finished with value: 0.07953248172998428 and parameters: {'n_d': 45, 'n_steps': 3, 'gamma': 1.170914626966535, 'n_independent': 2, 'n_shared': 5, 'momentum': 0.2755290613936109}. Best is trial 21 with value: 0.0769263356924057.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 25.95842| val_0_mse: 157297.84375|  0:00:00s\n","epoch 1  | loss: 1.28714 | val_0_mse: 8034.50927734375|  0:00:01s\n","epoch 2  | loss: 0.6499  | val_0_mse: 9368.7490234375|  0:00:02s\n","epoch 3  | loss: 0.40686 | val_0_mse: 200.54200744628906|  0:00:03s\n","epoch 4  | loss: 0.36111 | val_0_mse: 854.7493896484375|  0:00:04s\n","epoch 5  | loss: 0.24744 | val_0_mse: 1029.381591796875|  0:00:04s\n","epoch 6  | loss: 0.23173 | val_0_mse: 431.3324279785156|  0:00:05s\n","epoch 7  | loss: 0.18817 | val_0_mse: 249.59092712402344|  0:00:06s\n","epoch 8  | loss: 0.21048 | val_0_mse: 247.63128662109375|  0:00:07s\n","epoch 9  | loss: 0.22386 | val_0_mse: 570.6835327148438|  0:00:08s\n","epoch 10 | loss: 0.32361 | val_0_mse: 383.2447509765625|  0:00:09s\n","epoch 11 | loss: 0.32216 | val_0_mse: 428.9962463378906|  0:00:09s\n","epoch 12 | loss: 0.25664 | val_0_mse: 330.0542297363281|  0:00:10s\n","epoch 13 | loss: 0.18585 | val_0_mse: 348.3487548828125|  0:00:11s\n","\n","Early stopping occurred at epoch 13 with best_epoch = 3 and best_val_0_mse = 200.54200744628906\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 11:38:50,550] Trial 23 finished with value: 200.5419921875 and parameters: {'n_d': 44, 'n_steps': 4, 'gamma': 1.1232547284875511, 'n_independent': 2, 'n_shared': 5, 'momentum': 0.2726062007016967}. Best is trial 21 with value: 0.0769263356924057.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 47.02336| val_0_mse: 4075.775634765625|  0:00:00s\n","epoch 1  | loss: 1.89648 | val_0_mse: 4180.0419921875|  0:00:01s\n","epoch 2  | loss: 0.70527 | val_0_mse: 8410.681640625|  0:00:02s\n","epoch 3  | loss: 0.54115 | val_0_mse: 6377.69384765625|  0:00:02s\n","epoch 4  | loss: 0.33086 | val_0_mse: 1032.574951171875|  0:00:03s\n","epoch 5  | loss: 0.28257 | val_0_mse: 1606.0335693359375|  0:00:03s\n","epoch 6  | loss: 0.42291 | val_0_mse: 457.8185729980469|  0:00:04s\n","epoch 7  | loss: 0.26026 | val_0_mse: 651.3134155273438|  0:00:05s\n","epoch 8  | loss: 0.21543 | val_0_mse: 514.1029663085938|  0:00:06s\n","epoch 9  | loss: 0.20616 | val_0_mse: 241.3379364013672|  0:00:06s\n","epoch 10 | loss: 0.18149 | val_0_mse: 264.0182189941406|  0:00:07s\n","epoch 11 | loss: 0.20662 | val_0_mse: 165.01927185058594|  0:00:08s\n","epoch 12 | loss: 0.16896 | val_0_mse: 111.34092712402344|  0:00:08s\n","epoch 13 | loss: 0.15252 | val_0_mse: 80.921142578125|  0:00:09s\n","epoch 14 | loss: 0.15237 | val_0_mse: 52.455078125|  0:00:10s\n","epoch 15 | loss: 0.17869 | val_0_mse: 33.22336959838867|  0:00:10s\n","epoch 16 | loss: 0.24087 | val_0_mse: 42.96063995361328|  0:00:11s\n","epoch 17 | loss: 0.16485 | val_0_mse: 17.787309646606445|  0:00:12s\n","epoch 18 | loss: 0.14321 | val_0_mse: 17.635759353637695|  0:00:12s\n","epoch 19 | loss: 0.12376 | val_0_mse: 12.05597972869873|  0:00:13s\n","epoch 20 | loss: 0.11301 | val_0_mse: 11.301079750061035|  0:00:14s\n","epoch 21 | loss: 0.11509 | val_0_mse: 7.617489814758301|  0:00:14s\n","epoch 22 | loss: 0.12719 | val_0_mse: 5.418429851531982|  0:00:15s\n","epoch 23 | loss: 0.13759 | val_0_mse: 6.611219882965088|  0:00:16s\n","epoch 24 | loss: 0.12265 | val_0_mse: 4.55072021484375|  0:00:16s\n","epoch 25 | loss: 0.1199  | val_0_mse: 2.8682799339294434|  0:00:17s\n","epoch 26 | loss: 0.11425 | val_0_mse: 1.7475099563598633|  0:00:18s\n","epoch 27 | loss: 0.111   | val_0_mse: 0.7504600286483765|  0:00:19s\n","epoch 28 | loss: 0.11725 | val_0_mse: 1.1833200454711914|  0:00:19s\n","epoch 29 | loss: 0.12195 | val_0_mse: 0.5335000157356262|  0:00:20s\n","epoch 30 | loss: 0.14045 | val_0_mse: 1.2495299577713013|  0:00:21s\n","epoch 31 | loss: 0.11427 | val_0_mse: 0.689050018787384|  0:00:21s\n","epoch 32 | loss: 0.13786 | val_0_mse: 0.407039999961853|  0:00:22s\n","epoch 33 | loss: 0.13085 | val_0_mse: 0.6525499820709229|  0:00:23s\n","epoch 34 | loss: 0.12581 | val_0_mse: 0.48980000615119934|  0:00:23s\n","epoch 35 | loss: 0.12962 | val_0_mse: 0.6378399729728699|  0:00:24s\n","epoch 36 | loss: 0.12745 | val_0_mse: 0.45447999238967896|  0:00:25s\n","epoch 37 | loss: 0.12506 | val_0_mse: 0.3512600064277649|  0:00:25s\n","epoch 38 | loss: 0.11269 | val_0_mse: 0.3233500123023987|  0:00:26s\n","epoch 39 | loss: 0.11692 | val_0_mse: 0.34022998809814453|  0:00:27s\n","epoch 40 | loss: 0.14861 | val_0_mse: 0.3980199992656708|  0:00:27s\n","epoch 41 | loss: 0.13857 | val_0_mse: 0.33623000979423523|  0:00:28s\n","epoch 42 | loss: 0.13878 | val_0_mse: 0.33588001132011414|  0:00:29s\n","epoch 43 | loss: 0.13705 | val_0_mse: 0.2346400022506714|  0:00:29s\n","epoch 44 | loss: 0.12946 | val_0_mse: 0.30849000811576843|  0:00:30s\n","epoch 45 | loss: 0.13763 | val_0_mse: 0.2448199987411499|  0:00:31s\n","epoch 46 | loss: 0.13237 | val_0_mse: 0.27546000480651855|  0:00:31s\n","epoch 47 | loss: 0.11857 | val_0_mse: 0.1886799931526184|  0:00:32s\n","epoch 48 | loss: 0.14844 | val_0_mse: 0.28793999552726746|  0:00:33s\n","epoch 49 | loss: 0.13868 | val_0_mse: 0.25130000710487366|  0:00:33s\n","epoch 50 | loss: 0.10844 | val_0_mse: 0.2078700065612793|  0:00:34s\n","epoch 51 | loss: 0.10271 | val_0_mse: 0.1716800034046173|  0:00:35s\n","epoch 52 | loss: 0.09849 | val_0_mse: 0.16708000004291534|  0:00:36s\n","epoch 53 | loss: 0.13141 | val_0_mse: 0.15216000378131866|  0:00:36s\n","epoch 54 | loss: 0.11844 | val_0_mse: 0.2083899974822998|  0:00:37s\n","epoch 55 | loss: 0.11771 | val_0_mse: 0.1307699978351593|  0:00:38s\n","epoch 56 | loss: 0.12004 | val_0_mse: 0.182109996676445|  0:00:38s\n","epoch 57 | loss: 0.09887 | val_0_mse: 0.17719000577926636|  0:00:39s\n","epoch 58 | loss: 0.09013 | val_0_mse: 0.11417999863624573|  0:00:40s\n","epoch 59 | loss: 0.08907 | val_0_mse: 0.12245000153779984|  0:00:40s\n","epoch 60 | loss: 0.08415 | val_0_mse: 0.11508999764919281|  0:00:41s\n","epoch 61 | loss: 0.09075 | val_0_mse: 0.11582999676465988|  0:00:42s\n","epoch 62 | loss: 0.09098 | val_0_mse: 0.10221999883651733|  0:00:43s\n","epoch 63 | loss: 0.08995 | val_0_mse: 0.11733999848365784|  0:00:43s\n","epoch 64 | loss: 0.09118 | val_0_mse: 0.1049100011587143|  0:00:44s\n","epoch 65 | loss: 0.08779 | val_0_mse: 0.1042499989271164|  0:00:45s\n","epoch 66 | loss: 0.09687 | val_0_mse: 0.10752999782562256|  0:00:45s\n","epoch 67 | loss: 0.13594 | val_0_mse: 0.11852999776601791|  0:00:46s\n","epoch 68 | loss: 0.10212 | val_0_mse: 0.09714999794960022|  0:00:47s\n","epoch 69 | loss: 0.09546 | val_0_mse: 0.09528999775648117|  0:00:47s\n","epoch 70 | loss: 0.0956  | val_0_mse: 0.09038999676704407|  0:00:48s\n","epoch 71 | loss: 0.09028 | val_0_mse: 0.092289999127388|  0:00:49s\n","epoch 72 | loss: 0.08497 | val_0_mse: 0.09268999844789505|  0:00:49s\n","epoch 73 | loss: 0.09223 | val_0_mse: 0.09969999641180038|  0:00:50s\n","epoch 74 | loss: 0.0906  | val_0_mse: 0.11372999846935272|  0:00:51s\n","epoch 75 | loss: 0.08812 | val_0_mse: 0.09035000205039978|  0:00:51s\n","epoch 76 | loss: 0.0823  | val_0_mse: 0.09132999926805496|  0:00:52s\n","epoch 77 | loss: 0.09366 | val_0_mse: 0.11550000309944153|  0:00:53s\n","epoch 78 | loss: 0.12156 | val_0_mse: 0.1301400065422058|  0:00:53s\n","epoch 79 | loss: 0.12757 | val_0_mse: 0.10778000205755234|  0:00:54s\n","epoch 80 | loss: 0.1286  | val_0_mse: 0.10571999847888947|  0:00:55s\n","epoch 81 | loss: 0.09537 | val_0_mse: 0.09860000014305115|  0:00:55s\n","epoch 82 | loss: 0.1027  | val_0_mse: 0.09856999665498734|  0:00:56s\n","epoch 83 | loss: 0.09968 | val_0_mse: 0.08930999785661697|  0:00:57s\n","epoch 84 | loss: 0.09089 | val_0_mse: 0.0987199991941452|  0:00:57s\n","epoch 85 | loss: 0.08554 | val_0_mse: 0.08686999976634979|  0:00:58s\n","epoch 86 | loss: 0.08203 | val_0_mse: 0.08980000019073486|  0:00:59s\n","epoch 87 | loss: 0.08313 | val_0_mse: 0.08838000148534775|  0:00:59s\n","epoch 88 | loss: 0.08875 | val_0_mse: 0.10119999945163727|  0:01:00s\n","epoch 89 | loss: 0.08388 | val_0_mse: 0.09522999823093414|  0:01:01s\n","epoch 90 | loss: 0.10143 | val_0_mse: 0.17639000713825226|  0:01:02s\n","epoch 91 | loss: 0.1054  | val_0_mse: 0.08771000057458878|  0:01:02s\n","epoch 92 | loss: 0.08235 | val_0_mse: 0.09092000126838684|  0:01:03s\n","epoch 93 | loss: 0.09315 | val_0_mse: 0.0865899994969368|  0:01:04s\n","epoch 94 | loss: 0.08233 | val_0_mse: 0.0841199979186058|  0:01:04s\n","epoch 95 | loss: 0.08096 | val_0_mse: 0.09001000225543976|  0:01:05s\n","epoch 96 | loss: 0.08084 | val_0_mse: 0.0869000032544136|  0:01:06s\n","epoch 97 | loss: 0.08398 | val_0_mse: 0.08530999720096588|  0:01:06s\n","epoch 98 | loss: 0.09075 | val_0_mse: 0.09141000360250473|  0:01:07s\n","epoch 99 | loss: 0.09773 | val_0_mse: 0.16323000192642212|  0:01:08s\n","Stop training because you reached max_epochs = 100 with best_epoch = 94 and best_val_0_mse = 0.0841199979186058\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 11:39:59,200] Trial 24 finished with value: 0.08411869406700134 and parameters: {'n_d': 47, 'n_steps': 3, 'gamma': 1.246797664839891, 'n_independent': 2, 'n_shared': 5, 'momentum': 0.3711497380270433}. Best is trial 21 with value: 0.0769263356924057.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 33.49304| val_0_mse: 3525.378662109375|  0:00:00s\n","epoch 1  | loss: 1.06873 | val_0_mse: 509.2884826660156|  0:00:01s\n","epoch 2  | loss: 0.50805 | val_0_mse: 683.1913452148438|  0:00:01s\n","epoch 3  | loss: 0.39772 | val_0_mse: 1273.80517578125|  0:00:02s\n","epoch 4  | loss: 0.31823 | val_0_mse: 827.42626953125|  0:00:03s\n","epoch 5  | loss: 0.37394 | val_0_mse: 581.742431640625|  0:00:03s\n","epoch 6  | loss: 0.31133 | val_0_mse: 220.2201385498047|  0:00:04s\n","epoch 7  | loss: 0.28394 | val_0_mse: 216.55972290039062|  0:00:05s\n","epoch 8  | loss: 0.24039 | val_0_mse: 250.3722381591797|  0:00:05s\n","epoch 9  | loss: 0.21744 | val_0_mse: 8.701250076293945|  0:00:06s\n","epoch 10 | loss: 0.19684 | val_0_mse: 4.5117998123168945|  0:00:07s\n","epoch 11 | loss: 0.20358 | val_0_mse: 10.789380073547363|  0:00:08s\n","epoch 12 | loss: 0.17518 | val_0_mse: 7.889420032501221|  0:00:08s\n","epoch 13 | loss: 0.16073 | val_0_mse: 2.0509400367736816|  0:00:09s\n","epoch 14 | loss: 0.17893 | val_0_mse: 16.1724796295166|  0:00:09s\n","epoch 15 | loss: 0.16426 | val_0_mse: 10.189720153808594|  0:00:10s\n","epoch 16 | loss: 0.15828 | val_0_mse: 7.736440181732178|  0:00:11s\n","epoch 17 | loss: 0.20236 | val_0_mse: 3.253959894180298|  0:00:11s\n","epoch 18 | loss: 0.17821 | val_0_mse: 5.535920143127441|  0:00:12s\n","epoch 19 | loss: 0.19043 | val_0_mse: 5.009510040283203|  0:00:13s\n","epoch 20 | loss: 0.18148 | val_0_mse: 2.613919973373413|  0:00:13s\n","epoch 21 | loss: 0.16981 | val_0_mse: 1.5354499816894531|  0:00:14s\n","epoch 22 | loss: 0.16189 | val_0_mse: 1.4946399927139282|  0:00:15s\n","epoch 23 | loss: 0.1591  | val_0_mse: 1.3405799865722656|  0:00:15s\n","epoch 24 | loss: 0.15496 | val_0_mse: 1.5470900535583496|  0:00:16s\n","epoch 25 | loss: 0.16992 | val_0_mse: 0.8287400007247925|  0:00:17s\n","epoch 26 | loss: 0.16511 | val_0_mse: 0.8412700295448303|  0:00:17s\n","epoch 27 | loss: 0.15568 | val_0_mse: 0.8292199969291687|  0:00:18s\n","epoch 28 | loss: 0.15057 | val_0_mse: 0.6398599743843079|  0:00:19s\n","epoch 29 | loss: 0.15321 | val_0_mse: 0.49911001324653625|  0:00:20s\n","epoch 30 | loss: 0.15013 | val_0_mse: 0.5161100029945374|  0:00:20s\n","epoch 31 | loss: 0.15933 | val_0_mse: 0.40151000022888184|  0:00:21s\n","epoch 32 | loss: 0.13238 | val_0_mse: 0.49285998940467834|  0:00:21s\n","epoch 33 | loss: 0.12913 | val_0_mse: 0.3522000014781952|  0:00:22s\n","epoch 34 | loss: 0.13632 | val_0_mse: 0.4717699885368347|  0:00:23s\n","epoch 35 | loss: 0.13524 | val_0_mse: 0.3252899944782257|  0:00:23s\n","epoch 36 | loss: 0.14306 | val_0_mse: 0.5758500099182129|  0:00:24s\n","epoch 37 | loss: 0.13575 | val_0_mse: 0.296099990606308|  0:00:25s\n","epoch 38 | loss: 0.17558 | val_0_mse: 0.24321000277996063|  0:00:25s\n","epoch 39 | loss: 0.13889 | val_0_mse: 0.24379999935626984|  0:00:26s\n","epoch 40 | loss: 0.12319 | val_0_mse: 0.37836000323295593|  0:00:27s\n","epoch 41 | loss: 0.12563 | val_0_mse: 0.38752999901771545|  0:00:27s\n","epoch 42 | loss: 0.12024 | val_0_mse: 0.2800599932670593|  0:00:28s\n","epoch 43 | loss: 0.10739 | val_0_mse: 0.21272000670433044|  0:00:29s\n","epoch 44 | loss: 0.1186  | val_0_mse: 0.222680002450943|  0:00:30s\n","epoch 45 | loss: 0.16046 | val_0_mse: 0.23934000730514526|  0:00:30s\n","epoch 46 | loss: 0.15716 | val_0_mse: 0.20475000143051147|  0:00:31s\n","epoch 47 | loss: 0.14366 | val_0_mse: 0.26205000281333923|  0:00:31s\n","epoch 48 | loss: 0.14372 | val_0_mse: 0.16529999673366547|  0:00:32s\n","epoch 49 | loss: 0.13861 | val_0_mse: 0.2100200057029724|  0:00:33s\n","epoch 50 | loss: 0.12119 | val_0_mse: 0.20633000135421753|  0:00:33s\n","epoch 51 | loss: 0.15323 | val_0_mse: 0.16256000101566315|  0:00:34s\n","epoch 52 | loss: 0.15088 | val_0_mse: 0.287880003452301|  0:00:35s\n","epoch 53 | loss: 0.16141 | val_0_mse: 0.1705400049686432|  0:00:35s\n","epoch 54 | loss: 0.13436 | val_0_mse: 0.19508999586105347|  0:00:36s\n","epoch 55 | loss: 0.12386 | val_0_mse: 0.16708999872207642|  0:00:37s\n","epoch 56 | loss: 0.1171  | val_0_mse: 0.18661999702453613|  0:00:37s\n","epoch 57 | loss: 0.11437 | val_0_mse: 0.12771999835968018|  0:00:38s\n","epoch 58 | loss: 0.11287 | val_0_mse: 0.15559999644756317|  0:00:39s\n","epoch 59 | loss: 0.11712 | val_0_mse: 0.18856999278068542|  0:00:39s\n","epoch 60 | loss: 0.11463 | val_0_mse: 0.13327999413013458|  0:00:40s\n","epoch 61 | loss: 0.1239  | val_0_mse: 0.11901000142097473|  0:00:41s\n","epoch 62 | loss: 0.11391 | val_0_mse: 0.12407000362873077|  0:00:41s\n","epoch 63 | loss: 0.1053  | val_0_mse: 0.14585000276565552|  0:00:42s\n","epoch 64 | loss: 0.11073 | val_0_mse: 0.27351999282836914|  0:00:43s\n","epoch 65 | loss: 0.14244 | val_0_mse: 0.16064000129699707|  0:00:43s\n","epoch 66 | loss: 0.14244 | val_0_mse: 0.3050999939441681|  0:00:44s\n","epoch 67 | loss: 0.1426  | val_0_mse: 0.18556000292301178|  0:00:45s\n","epoch 68 | loss: 0.13761 | val_0_mse: 0.16116000711917877|  0:00:45s\n","epoch 69 | loss: 0.12782 | val_0_mse: 0.1467999964952469|  0:00:46s\n","epoch 70 | loss: 0.12428 | val_0_mse: 0.15934999287128448|  0:00:47s\n","epoch 71 | loss: 0.12955 | val_0_mse: 0.14693999290466309|  0:00:47s\n","\n","Early stopping occurred at epoch 71 with best_epoch = 61 and best_val_0_mse = 0.11901000142097473\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 11:40:47,294] Trial 25 finished with value: 0.11901204288005829 and parameters: {'n_d': 38, 'n_steps': 4, 'gamma': 1.4026218077337171, 'n_independent': 1, 'n_shared': 4, 'momentum': 0.3119229696524469}. Best is trial 21 with value: 0.0769263356924057.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 24.79373| val_0_mse: 15144.744140625|  0:00:00s\n","epoch 1  | loss: 2.35586 | val_0_mse: 9517.447265625|  0:00:01s\n","epoch 2  | loss: 1.7983  | val_0_mse: 11869.6162109375|  0:00:02s\n","epoch 3  | loss: 1.09167 | val_0_mse: 3968.894287109375|  0:00:03s\n","epoch 4  | loss: 1.20553 | val_0_mse: 38220.5625|  0:00:04s\n","epoch 5  | loss: 1.07028 | val_0_mse: 2831.213134765625|  0:00:05s\n","epoch 6  | loss: 0.4868  | val_0_mse: 171.6485137939453|  0:00:06s\n","epoch 7  | loss: 0.47616 | val_0_mse: 946.5191040039062|  0:00:07s\n","epoch 8  | loss: 0.3604  | val_0_mse: 289.51531982421875|  0:00:08s\n","epoch 9  | loss: 0.21677 | val_0_mse: 114.97347259521484|  0:00:09s\n","epoch 10 | loss: 0.18432 | val_0_mse: 19.669700622558594|  0:00:10s\n","epoch 11 | loss: 0.16736 | val_0_mse: 101.95303344726562|  0:00:11s\n","epoch 12 | loss: 0.22989 | val_0_mse: 45.71194076538086|  0:00:12s\n","epoch 13 | loss: 0.18654 | val_0_mse: 83.6436767578125|  0:00:13s\n","epoch 14 | loss: 0.18617 | val_0_mse: 109.33305358886719|  0:00:14s\n","epoch 15 | loss: 0.16069 | val_0_mse: 45.83694076538086|  0:00:15s\n","epoch 16 | loss: 0.15376 | val_0_mse: 16.782550811767578|  0:00:16s\n","epoch 17 | loss: 0.14049 | val_0_mse: 22.900989532470703|  0:00:17s\n","epoch 18 | loss: 0.12907 | val_0_mse: 16.796579360961914|  0:00:18s\n","epoch 19 | loss: 0.12681 | val_0_mse: 8.654979705810547|  0:00:19s\n","epoch 20 | loss: 0.12922 | val_0_mse: 8.959440231323242|  0:00:20s\n","epoch 21 | loss: 0.12422 | val_0_mse: 4.161489963531494|  0:00:21s\n","epoch 22 | loss: 0.1245  | val_0_mse: 3.624389886856079|  0:00:22s\n","epoch 23 | loss: 0.12776 | val_0_mse: 3.907560110092163|  0:00:23s\n","epoch 24 | loss: 0.1356  | val_0_mse: 2.068730115890503|  0:00:24s\n","epoch 25 | loss: 0.11517 | val_0_mse: 2.35152006149292|  0:00:25s\n","epoch 26 | loss: 0.12174 | val_0_mse: 0.9701499938964844|  0:00:26s\n","epoch 27 | loss: 0.12688 | val_0_mse: 1.2208800315856934|  0:00:27s\n","epoch 28 | loss: 0.10924 | val_0_mse: 0.8801699876785278|  0:00:28s\n","epoch 29 | loss: 0.1216  | val_0_mse: 0.9116100072860718|  0:00:29s\n","epoch 30 | loss: 0.11275 | val_0_mse: 0.6053699851036072|  0:00:30s\n","epoch 31 | loss: 0.16379 | val_0_mse: 0.6613799929618835|  0:00:31s\n","epoch 32 | loss: 0.13615 | val_0_mse: 0.5038599967956543|  0:00:32s\n","epoch 33 | loss: 0.1667  | val_0_mse: 1.5840500593185425|  0:00:33s\n","epoch 34 | loss: 0.16739 | val_0_mse: 0.6475800275802612|  0:00:34s\n","epoch 35 | loss: 0.1343  | val_0_mse: 0.6237800121307373|  0:00:35s\n","epoch 36 | loss: 0.10858 | val_0_mse: 0.36309999227523804|  0:00:36s\n","epoch 37 | loss: 0.11108 | val_0_mse: 0.2938399910926819|  0:00:37s\n","epoch 38 | loss: 0.10273 | val_0_mse: 0.31832000613212585|  0:00:38s\n","epoch 39 | loss: 0.10471 | val_0_mse: 0.3768100142478943|  0:00:39s\n","epoch 40 | loss: 0.13316 | val_0_mse: 0.2770400047302246|  0:00:40s\n","epoch 41 | loss: 0.14607 | val_0_mse: 0.424560010433197|  0:00:40s\n","epoch 42 | loss: 0.14298 | val_0_mse: 0.2587699890136719|  0:00:41s\n","epoch 43 | loss: 0.13683 | val_0_mse: 0.4449099898338318|  0:00:42s\n","epoch 44 | loss: 0.14295 | val_0_mse: 0.2599399983882904|  0:00:43s\n","epoch 45 | loss: 0.12816 | val_0_mse: 0.40116000175476074|  0:00:44s\n","epoch 46 | loss: 0.14402 | val_0_mse: 0.3216100037097931|  0:00:45s\n","epoch 47 | loss: 0.13051 | val_0_mse: 0.31560999155044556|  0:00:46s\n","epoch 48 | loss: 0.1423  | val_0_mse: 0.2151699960231781|  0:00:47s\n","epoch 49 | loss: 0.14444 | val_0_mse: 0.33327001333236694|  0:00:48s\n","epoch 50 | loss: 0.12727 | val_0_mse: 0.20377999544143677|  0:00:49s\n","epoch 51 | loss: 0.13379 | val_0_mse: 0.3174099922180176|  0:00:50s\n","epoch 52 | loss: 0.13844 | val_0_mse: 0.13484999537467957|  0:00:51s\n","epoch 53 | loss: 0.12779 | val_0_mse: 0.25266000628471375|  0:00:52s\n","epoch 54 | loss: 0.13503 | val_0_mse: 0.16167999804019928|  0:00:53s\n","epoch 55 | loss: 0.12268 | val_0_mse: 0.30371999740600586|  0:00:54s\n","epoch 56 | loss: 0.13886 | val_0_mse: 0.13596999645233154|  0:00:55s\n","epoch 57 | loss: 0.128   | val_0_mse: 0.2189600020647049|  0:00:56s\n","epoch 58 | loss: 0.12509 | val_0_mse: 0.12520000338554382|  0:00:57s\n","epoch 59 | loss: 0.12805 | val_0_mse: 0.20646999776363373|  0:00:58s\n","epoch 60 | loss: 0.12645 | val_0_mse: 0.12184000015258789|  0:00:59s\n","epoch 61 | loss: 0.12255 | val_0_mse: 0.1615699976682663|  0:01:00s\n","epoch 62 | loss: 0.12436 | val_0_mse: 0.10956999659538269|  0:01:01s\n","epoch 63 | loss: 0.11969 | val_0_mse: 0.19183999300003052|  0:01:02s\n","epoch 64 | loss: 0.14523 | val_0_mse: 0.1200300008058548|  0:01:03s\n","epoch 65 | loss: 0.10151 | val_0_mse: 0.15810999274253845|  0:01:04s\n","epoch 66 | loss: 0.10562 | val_0_mse: 0.14233000576496124|  0:01:05s\n","epoch 67 | loss: 0.10554 | val_0_mse: 0.16413000226020813|  0:01:06s\n","epoch 68 | loss: 0.10961 | val_0_mse: 0.14753000438213348|  0:01:07s\n","epoch 69 | loss: 0.1192  | val_0_mse: 0.12551000714302063|  0:01:07s\n","epoch 70 | loss: 0.11046 | val_0_mse: 0.1322299987077713|  0:01:08s\n","epoch 71 | loss: 0.12172 | val_0_mse: 0.11986000090837479|  0:01:09s\n","epoch 72 | loss: 0.1166  | val_0_mse: 0.12570999562740326|  0:01:10s\n","\n","Early stopping occurred at epoch 72 with best_epoch = 62 and best_val_0_mse = 0.10956999659538269\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 11:41:58,582] Trial 26 finished with value: 0.10957008600234985 and parameters: {'n_d': 34, 'n_steps': 5, 'gamma': 1.0920766540917153, 'n_independent': 2, 'n_shared': 5, 'momentum': 0.24400660507697414}. Best is trial 21 with value: 0.0769263356924057.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 38.97592| val_0_mse: 30535.6015625|  0:00:00s\n","epoch 1  | loss: 1.64588 | val_0_mse: 4018.368408203125|  0:00:01s\n","epoch 2  | loss: 0.48645 | val_0_mse: 584.3904418945312|  0:00:01s\n","epoch 3  | loss: 0.36799 | val_0_mse: 447.07269287109375|  0:00:02s\n","epoch 4  | loss: 0.26352 | val_0_mse: 1259.841064453125|  0:00:02s\n","epoch 5  | loss: 0.2353  | val_0_mse: 732.67578125|  0:00:03s\n","epoch 6  | loss: 0.22419 | val_0_mse: 1012.8970947265625|  0:00:03s\n","epoch 7  | loss: 0.19416 | val_0_mse: 1639.3101806640625|  0:00:04s\n","epoch 8  | loss: 0.15532 | val_0_mse: 1270.01123046875|  0:00:04s\n","epoch 9  | loss: 0.16267 | val_0_mse: 865.7777099609375|  0:00:05s\n","epoch 10 | loss: 0.17548 | val_0_mse: 506.6743469238281|  0:00:05s\n","epoch 11 | loss: 0.1561  | val_0_mse: 420.907470703125|  0:00:06s\n","epoch 12 | loss: 0.14737 | val_0_mse: 302.0332336425781|  0:00:06s\n","epoch 13 | loss: 0.13588 | val_0_mse: 274.7674560546875|  0:00:07s\n","epoch 14 | loss: 0.11824 | val_0_mse: 129.16407775878906|  0:00:07s\n","epoch 15 | loss: 0.12226 | val_0_mse: 78.57109832763672|  0:00:08s\n","epoch 16 | loss: 0.12714 | val_0_mse: 151.3542938232422|  0:00:08s\n","epoch 17 | loss: 0.1408  | val_0_mse: 86.71189880371094|  0:00:09s\n","epoch 18 | loss: 0.12947 | val_0_mse: 48.50086975097656|  0:00:10s\n","epoch 19 | loss: 0.12901 | val_0_mse: 61.066131591796875|  0:00:10s\n","epoch 20 | loss: 0.12151 | val_0_mse: 38.86085891723633|  0:00:11s\n","epoch 21 | loss: 0.12582 | val_0_mse: 14.956029891967773|  0:00:11s\n","epoch 22 | loss: 0.12216 | val_0_mse: 17.01202964782715|  0:00:12s\n","epoch 23 | loss: 0.11951 | val_0_mse: 12.620490074157715|  0:00:12s\n","epoch 24 | loss: 0.1054  | val_0_mse: 12.665390014648438|  0:00:13s\n","epoch 25 | loss: 0.10745 | val_0_mse: 12.043069839477539|  0:00:13s\n","epoch 26 | loss: 0.09618 | val_0_mse: 7.630459785461426|  0:00:14s\n","epoch 27 | loss: 0.10376 | val_0_mse: 4.694260120391846|  0:00:14s\n","epoch 28 | loss: 0.09709 | val_0_mse: 3.9699900150299072|  0:00:15s\n","epoch 29 | loss: 0.10953 | val_0_mse: 2.845629930496216|  0:00:16s\n","epoch 30 | loss: 0.17014 | val_0_mse: 0.7375699877738953|  0:00:16s\n","epoch 31 | loss: 0.13845 | val_0_mse: 1.4663399457931519|  0:00:17s\n","epoch 32 | loss: 0.13335 | val_0_mse: 2.8756699562072754|  0:00:17s\n","epoch 33 | loss: 0.12335 | val_0_mse: 2.1133201122283936|  0:00:18s\n","epoch 34 | loss: 0.12485 | val_0_mse: 2.397279977798462|  0:00:18s\n","epoch 35 | loss: 0.1213  | val_0_mse: 1.0056899785995483|  0:00:19s\n","epoch 36 | loss: 0.11918 | val_0_mse: 1.1737099885940552|  0:00:19s\n","epoch 37 | loss: 0.10471 | val_0_mse: 1.4088399410247803|  0:00:20s\n","epoch 38 | loss: 0.09781 | val_0_mse: 0.9279299974441528|  0:00:21s\n","epoch 39 | loss: 0.09321 | val_0_mse: 1.049299955368042|  0:00:21s\n","epoch 40 | loss: 0.09648 | val_0_mse: 0.5576599836349487|  0:00:22s\n","epoch 41 | loss: 0.09076 | val_0_mse: 0.5779899954795837|  0:00:22s\n","epoch 42 | loss: 0.09539 | val_0_mse: 0.3913100063800812|  0:00:23s\n","epoch 43 | loss: 0.09421 | val_0_mse: 0.5548700094223022|  0:00:23s\n","epoch 44 | loss: 0.09686 | val_0_mse: 0.41012001037597656|  0:00:24s\n","epoch 45 | loss: 0.08721 | val_0_mse: 0.29761001467704773|  0:00:24s\n","epoch 46 | loss: 0.08546 | val_0_mse: 0.47488999366760254|  0:00:25s\n","epoch 47 | loss: 0.08783 | val_0_mse: 0.23331999778747559|  0:00:25s\n","epoch 48 | loss: 0.08354 | val_0_mse: 0.25108999013900757|  0:00:26s\n","epoch 49 | loss: 0.08927 | val_0_mse: 0.18614999949932098|  0:00:26s\n","epoch 50 | loss: 0.09102 | val_0_mse: 0.2025499939918518|  0:00:27s\n","epoch 51 | loss: 0.08453 | val_0_mse: 0.21932999789714813|  0:00:28s\n","epoch 52 | loss: 0.08284 | val_0_mse: 0.15911999344825745|  0:00:28s\n","epoch 53 | loss: 0.07945 | val_0_mse: 0.18039999902248383|  0:00:29s\n","epoch 54 | loss: 0.07805 | val_0_mse: 0.1446399986743927|  0:00:29s\n","epoch 55 | loss: 0.09327 | val_0_mse: 0.19192999601364136|  0:00:30s\n","epoch 56 | loss: 0.13131 | val_0_mse: 0.2056400030851364|  0:00:31s\n","epoch 57 | loss: 0.11783 | val_0_mse: 0.1103300005197525|  0:00:31s\n","epoch 58 | loss: 0.11014 | val_0_mse: 0.1800300031900406|  0:00:32s\n","epoch 59 | loss: 0.10669 | val_0_mse: 0.10130999982357025|  0:00:32s\n","epoch 60 | loss: 0.09943 | val_0_mse: 0.1244100034236908|  0:00:33s\n","epoch 61 | loss: 0.1157  | val_0_mse: 0.14090000092983246|  0:00:33s\n","epoch 62 | loss: 0.10652 | val_0_mse: 0.10121999680995941|  0:00:34s\n","epoch 63 | loss: 0.08029 | val_0_mse: 0.11332999914884567|  0:00:34s\n","epoch 64 | loss: 0.08287 | val_0_mse: 0.09168999642133713|  0:00:35s\n","epoch 65 | loss: 0.07771 | val_0_mse: 0.09346000105142593|  0:00:35s\n","epoch 66 | loss: 0.07911 | val_0_mse: 0.0858599990606308|  0:00:36s\n","epoch 67 | loss: 0.08041 | val_0_mse: 0.08683999627828598|  0:00:36s\n","epoch 68 | loss: 0.08755 | val_0_mse: 0.11012999713420868|  0:00:37s\n","epoch 69 | loss: 0.09477 | val_0_mse: 0.11541999876499176|  0:00:37s\n","epoch 70 | loss: 0.0896  | val_0_mse: 0.11151999980211258|  0:00:38s\n","epoch 71 | loss: 0.09181 | val_0_mse: 0.0995199978351593|  0:00:39s\n","epoch 72 | loss: 0.08659 | val_0_mse: 0.08405999839305878|  0:00:39s\n","epoch 73 | loss: 0.08833 | val_0_mse: 0.10047999769449234|  0:00:40s\n","epoch 74 | loss: 0.08289 | val_0_mse: 0.08495000004768372|  0:00:40s\n","epoch 75 | loss: 0.08423 | val_0_mse: 0.08442000299692154|  0:00:41s\n","epoch 76 | loss: 0.08307 | val_0_mse: 0.08743000030517578|  0:00:41s\n","epoch 77 | loss: 0.08258 | val_0_mse: 0.08139000087976456|  0:00:42s\n","epoch 78 | loss: 0.07907 | val_0_mse: 0.07991000264883041|  0:00:42s\n","epoch 79 | loss: 0.08001 | val_0_mse: 0.08105000108480453|  0:00:43s\n","epoch 80 | loss: 0.08124 | val_0_mse: 0.08408000320196152|  0:00:43s\n","epoch 81 | loss: 0.08016 | val_0_mse: 0.09466999769210815|  0:00:44s\n","epoch 82 | loss: 0.09953 | val_0_mse: 0.07940000295639038|  0:00:45s\n","epoch 83 | loss: 0.07903 | val_0_mse: 0.08084999769926071|  0:00:45s\n","epoch 84 | loss: 0.07814 | val_0_mse: 0.08543000370264053|  0:00:46s\n","epoch 85 | loss: 0.08513 | val_0_mse: 0.0841199979186058|  0:00:46s\n","epoch 86 | loss: 0.08359 | val_0_mse: 0.07852999866008759|  0:00:47s\n","epoch 87 | loss: 0.07946 | val_0_mse: 0.09060999751091003|  0:00:47s\n","epoch 88 | loss: 0.09108 | val_0_mse: 0.09109000116586685|  0:00:48s\n","epoch 89 | loss: 0.08845 | val_0_mse: 0.0917000025510788|  0:00:48s\n","epoch 90 | loss: 0.08657 | val_0_mse: 0.10153999924659729|  0:00:49s\n","epoch 91 | loss: 0.09158 | val_0_mse: 0.09845999628305435|  0:00:49s\n","epoch 92 | loss: 0.08871 | val_0_mse: 0.08506999909877777|  0:00:50s\n","epoch 93 | loss: 0.08416 | val_0_mse: 0.08004999905824661|  0:00:50s\n","epoch 94 | loss: 0.08044 | val_0_mse: 0.08325999975204468|  0:00:51s\n","epoch 95 | loss: 0.08803 | val_0_mse: 0.0880500003695488|  0:00:52s\n","epoch 96 | loss: 0.08456 | val_0_mse: 0.07851000130176544|  0:00:52s\n","epoch 97 | loss: 0.07849 | val_0_mse: 0.07957000285387039|  0:00:53s\n","epoch 98 | loss: 0.08892 | val_0_mse: 0.0791499987244606|  0:00:53s\n","epoch 99 | loss: 0.0858  | val_0_mse: 0.08947999775409698|  0:00:54s\n","Stop training because you reached max_epochs = 100 with best_epoch = 96 and best_val_0_mse = 0.07851000130176544\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 11:42:53,186] Trial 27 finished with value: 0.07850775122642517 and parameters: {'n_d': 22, 'n_steps': 3, 'gamma': 1.2152127668642243, 'n_independent': 1, 'n_shared': 4, 'momentum': 0.2819773764561579}. Best is trial 21 with value: 0.0769263356924057.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 42.65549| val_0_mse: 75767.59375|  0:00:00s\n","epoch 1  | loss: 3.43172 | val_0_mse: 12231.6923828125|  0:00:01s\n","epoch 2  | loss: 0.87372 | val_0_mse: 417.1710510253906|  0:00:02s\n","epoch 3  | loss: 0.77358 | val_0_mse: 1161.505126953125|  0:00:03s\n","epoch 4  | loss: 0.86347 | val_0_mse: 719.4464111328125|  0:00:04s\n","epoch 5  | loss: 0.40494 | val_0_mse: 175.8802032470703|  0:00:05s\n","epoch 6  | loss: 0.3325  | val_0_mse: 68.80586242675781|  0:00:06s\n","epoch 7  | loss: 0.31611 | val_0_mse: 65.99414825439453|  0:00:06s\n","epoch 8  | loss: 0.27057 | val_0_mse: 91.73779296875|  0:00:07s\n","epoch 9  | loss: 0.27091 | val_0_mse: 51.60432815551758|  0:00:08s\n","epoch 10 | loss: 0.19966 | val_0_mse: 9.288379669189453|  0:00:09s\n","epoch 11 | loss: 0.21591 | val_0_mse: 8.355290412902832|  0:00:10s\n","epoch 12 | loss: 0.3276  | val_0_mse: 20.826099395751953|  0:00:11s\n","epoch 13 | loss: 0.37925 | val_0_mse: 73.2168197631836|  0:00:12s\n","epoch 14 | loss: 0.29642 | val_0_mse: 77.39891815185547|  0:00:13s\n","epoch 15 | loss: 0.30744 | val_0_mse: 50.4859504699707|  0:00:13s\n","epoch 16 | loss: 0.20688 | val_0_mse: 47.681461334228516|  0:00:14s\n","epoch 17 | loss: 0.1958  | val_0_mse: 29.261329650878906|  0:00:15s\n","epoch 18 | loss: 0.19414 | val_0_mse: 11.940739631652832|  0:00:16s\n","epoch 19 | loss: 0.18685 | val_0_mse: 14.262880325317383|  0:00:17s\n","epoch 20 | loss: 0.1842  | val_0_mse: 6.001039981842041|  0:00:18s\n","epoch 21 | loss: 0.17337 | val_0_mse: 2.7148900032043457|  0:00:19s\n","epoch 22 | loss: 0.16742 | val_0_mse: 1.1885000467300415|  0:00:20s\n","epoch 23 | loss: 0.17337 | val_0_mse: 1.309309959411621|  0:00:21s\n","epoch 24 | loss: 0.17171 | val_0_mse: 1.0485800504684448|  0:00:22s\n","epoch 25 | loss: 0.23536 | val_0_mse: 0.8597400188446045|  0:00:22s\n","epoch 26 | loss: 0.26816 | val_0_mse: 0.7545700073242188|  0:00:23s\n","epoch 27 | loss: 0.22564 | val_0_mse: 0.6033300161361694|  0:00:24s\n","epoch 28 | loss: 0.21075 | val_0_mse: 0.24773000180721283|  0:00:25s\n","epoch 29 | loss: 0.29212 | val_0_mse: 0.22877000272274017|  0:00:26s\n","epoch 30 | loss: 0.2066  | val_0_mse: 0.3145099878311157|  0:00:27s\n","epoch 31 | loss: 0.19781 | val_0_mse: 0.29888999462127686|  0:00:28s\n","epoch 32 | loss: 0.2034  | val_0_mse: 0.4501200020313263|  0:00:29s\n","epoch 33 | loss: 0.16646 | val_0_mse: 0.3618200123310089|  0:00:30s\n","epoch 34 | loss: 0.15696 | val_0_mse: 0.42844000458717346|  0:00:31s\n","epoch 35 | loss: 0.15609 | val_0_mse: 0.3842499852180481|  0:00:32s\n","epoch 36 | loss: 0.15694 | val_0_mse: 0.31292998790740967|  0:00:32s\n","epoch 37 | loss: 0.18869 | val_0_mse: 0.3504599928855896|  0:00:33s\n","epoch 38 | loss: 0.1663  | val_0_mse: 0.2249400019645691|  0:00:34s\n","epoch 39 | loss: 0.16463 | val_0_mse: 0.31567999720573425|  0:00:35s\n","epoch 40 | loss: 0.15034 | val_0_mse: 0.2000100016593933|  0:00:36s\n","epoch 41 | loss: 0.14947 | val_0_mse: 0.29392001032829285|  0:00:37s\n","epoch 42 | loss: 0.13857 | val_0_mse: 0.1812400072813034|  0:00:38s\n","epoch 43 | loss: 0.1378  | val_0_mse: 0.2279299944639206|  0:00:38s\n","epoch 44 | loss: 0.13607 | val_0_mse: 0.18171000480651855|  0:00:39s\n","epoch 45 | loss: 0.1401  | val_0_mse: 0.21950000524520874|  0:00:40s\n","epoch 46 | loss: 0.13028 | val_0_mse: 0.16859999299049377|  0:00:41s\n","epoch 47 | loss: 0.1352  | val_0_mse: 0.23590999841690063|  0:00:42s\n","epoch 48 | loss: 0.13092 | val_0_mse: 0.14403000473976135|  0:00:43s\n","epoch 49 | loss: 0.13222 | val_0_mse: 0.216389998793602|  0:00:44s\n","epoch 50 | loss: 0.13497 | val_0_mse: 0.13123999536037445|  0:00:44s\n","epoch 51 | loss: 0.13076 | val_0_mse: 0.19296999275684357|  0:00:45s\n","epoch 52 | loss: 0.13191 | val_0_mse: 0.12473999708890915|  0:00:46s\n","epoch 53 | loss: 0.12715 | val_0_mse: 0.15399999916553497|  0:00:47s\n","epoch 54 | loss: 0.13887 | val_0_mse: 0.12128999829292297|  0:00:48s\n","epoch 55 | loss: 0.12924 | val_0_mse: 0.20517000555992126|  0:00:49s\n","epoch 56 | loss: 0.1286  | val_0_mse: 0.1242000013589859|  0:00:50s\n","epoch 57 | loss: 0.12727 | val_0_mse: 0.22567999362945557|  0:00:51s\n","epoch 58 | loss: 0.11901 | val_0_mse: 0.1277499943971634|  0:00:51s\n","epoch 59 | loss: 0.10716 | val_0_mse: 0.1544100046157837|  0:00:52s\n","epoch 60 | loss: 0.11511 | val_0_mse: 0.20600000023841858|  0:00:53s\n","epoch 61 | loss: 0.13834 | val_0_mse: 0.10379000008106232|  0:00:54s\n","epoch 62 | loss: 0.112   | val_0_mse: 0.16752000153064728|  0:00:55s\n","epoch 63 | loss: 0.13942 | val_0_mse: 0.14608000218868256|  0:00:56s\n","epoch 64 | loss: 0.12151 | val_0_mse: 0.1014299988746643|  0:00:57s\n","epoch 65 | loss: 0.10055 | val_0_mse: 0.10708999633789062|  0:00:58s\n","epoch 66 | loss: 0.10626 | val_0_mse: 0.1057400032877922|  0:00:59s\n","epoch 67 | loss: 0.1316  | val_0_mse: 0.11169999837875366|  0:00:59s\n","epoch 68 | loss: 0.12466 | val_0_mse: 0.11082000285387039|  0:01:00s\n","epoch 69 | loss: 0.13898 | val_0_mse: 0.1422799974679947|  0:01:01s\n","epoch 70 | loss: 0.10832 | val_0_mse: 0.10829000174999237|  0:01:02s\n","epoch 71 | loss: 0.09788 | val_0_mse: 0.10553999990224838|  0:01:03s\n","epoch 72 | loss: 0.10418 | val_0_mse: 0.12818999588489532|  0:01:04s\n","epoch 73 | loss: 0.11732 | val_0_mse: 0.10016000270843506|  0:01:05s\n","epoch 74 | loss: 0.093   | val_0_mse: 0.1005299985408783|  0:01:06s\n","epoch 75 | loss: 0.09538 | val_0_mse: 0.09882999956607819|  0:01:06s\n","epoch 76 | loss: 0.09797 | val_0_mse: 0.09673000127077103|  0:01:07s\n","epoch 77 | loss: 0.11814 | val_0_mse: 0.18195000290870667|  0:01:08s\n","epoch 78 | loss: 0.11017 | val_0_mse: 0.1050100028514862|  0:01:09s\n","epoch 79 | loss: 0.10128 | val_0_mse: 0.10158000141382217|  0:01:10s\n","epoch 80 | loss: 0.1024  | val_0_mse: 0.0966000035405159|  0:01:11s\n","epoch 81 | loss: 0.10179 | val_0_mse: 0.12229999899864197|  0:01:12s\n","epoch 82 | loss: 0.10558 | val_0_mse: 0.1011200025677681|  0:01:13s\n","epoch 83 | loss: 0.10299 | val_0_mse: 0.13500000536441803|  0:01:13s\n","epoch 84 | loss: 0.12294 | val_0_mse: 0.16493000090122223|  0:01:14s\n","epoch 85 | loss: 0.12977 | val_0_mse: 0.17038999497890472|  0:01:15s\n","epoch 86 | loss: 0.12219 | val_0_mse: 0.10982999950647354|  0:01:16s\n","epoch 87 | loss: 0.11526 | val_0_mse: 0.09397999942302704|  0:01:17s\n","epoch 88 | loss: 0.10117 | val_0_mse: 0.1041100025177002|  0:01:18s\n","epoch 89 | loss: 0.11634 | val_0_mse: 0.12812000513076782|  0:01:19s\n","epoch 90 | loss: 0.12573 | val_0_mse: 0.09275999665260315|  0:01:20s\n","epoch 91 | loss: 0.10536 | val_0_mse: 0.0924300029873848|  0:01:20s\n","epoch 92 | loss: 0.10775 | val_0_mse: 0.16714000701904297|  0:01:21s\n","epoch 93 | loss: 0.14177 | val_0_mse: 0.09797000139951706|  0:01:22s\n","epoch 94 | loss: 0.1031  | val_0_mse: 0.13798999786376953|  0:01:23s\n","epoch 95 | loss: 0.12981 | val_0_mse: 0.10086999833583832|  0:01:24s\n","epoch 96 | loss: 0.11436 | val_0_mse: 0.1410900056362152|  0:01:25s\n","epoch 97 | loss: 0.1025  | val_0_mse: 0.09619999676942825|  0:01:26s\n","epoch 98 | loss: 0.08987 | val_0_mse: 0.09096000343561172|  0:01:27s\n","epoch 99 | loss: 0.08761 | val_0_mse: 0.08611000329256058|  0:01:28s\n","Stop training because you reached max_epochs = 100 with best_epoch = 99 and best_val_0_mse = 0.08611000329256058\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 11:44:21,773] Trial 28 finished with value: 0.08611296862363815 and parameters: {'n_d': 20, 'n_steps': 6, 'gamma': 1.2764506312295316, 'n_independent': 1, 'n_shared': 4, 'momentum': 0.39882166787948564}. Best is trial 21 with value: 0.0769263356924057.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 110.74322| val_0_mse: 51036.78515625|  0:00:00s\n","epoch 1  | loss: 9.75642 | val_0_mse: 7986.2041015625|  0:00:01s\n","epoch 2  | loss: 2.03612 | val_0_mse: 5450.0908203125|  0:00:01s\n","epoch 3  | loss: 0.69853 | val_0_mse: 405.5401916503906|  0:00:02s\n","epoch 4  | loss: 0.41085 | val_0_mse: 1916.230224609375|  0:00:03s\n","epoch 5  | loss: 0.28778 | val_0_mse: 2456.151123046875|  0:00:03s\n","epoch 6  | loss: 0.28602 | val_0_mse: 812.9271850585938|  0:00:04s\n","epoch 7  | loss: 0.26736 | val_0_mse: 393.050048828125|  0:00:05s\n","epoch 8  | loss: 0.23446 | val_0_mse: 138.09413146972656|  0:00:05s\n","epoch 9  | loss: 0.2107  | val_0_mse: 259.9665222167969|  0:00:06s\n","epoch 10 | loss: 0.19735 | val_0_mse: 87.40083312988281|  0:00:07s\n","epoch 11 | loss: 0.18579 | val_0_mse: 28.15567970275879|  0:00:07s\n","epoch 12 | loss: 0.18612 | val_0_mse: 19.767629623413086|  0:00:08s\n","epoch 13 | loss: 0.18256 | val_0_mse: 16.95117950439453|  0:00:09s\n","epoch 14 | loss: 0.18036 | val_0_mse: 42.93788146972656|  0:00:09s\n","epoch 15 | loss: 0.16006 | val_0_mse: 24.560510635375977|  0:00:10s\n","epoch 16 | loss: 0.14265 | val_0_mse: 16.80759048461914|  0:00:11s\n","epoch 17 | loss: 0.13988 | val_0_mse: 22.786890029907227|  0:00:11s\n","epoch 18 | loss: 0.13844 | val_0_mse: 6.425879955291748|  0:00:12s\n","epoch 19 | loss: 0.13251 | val_0_mse: 13.110699653625488|  0:00:13s\n","epoch 20 | loss: 0.13224 | val_0_mse: 3.5558199882507324|  0:00:13s\n","epoch 21 | loss: 0.13035 | val_0_mse: 1.0236400365829468|  0:00:14s\n","epoch 22 | loss: 0.12502 | val_0_mse: 0.5289899706840515|  0:00:15s\n","epoch 23 | loss: 0.13019 | val_0_mse: 0.5129799842834473|  0:00:15s\n","epoch 24 | loss: 0.12347 | val_0_mse: 1.3687299489974976|  0:00:16s\n","epoch 25 | loss: 0.12138 | val_0_mse: 1.2467800378799438|  0:00:17s\n","epoch 26 | loss: 0.13255 | val_0_mse: 0.5634899735450745|  0:00:17s\n","epoch 27 | loss: 0.12526 | val_0_mse: 1.4226900339126587|  0:00:18s\n","epoch 28 | loss: 0.12228 | val_0_mse: 1.9069600105285645|  0:00:19s\n","epoch 29 | loss: 0.13575 | val_0_mse: 8.2818603515625|  0:00:19s\n","epoch 30 | loss: 0.1267  | val_0_mse: 5.220719814300537|  0:00:20s\n","epoch 31 | loss: 0.13714 | val_0_mse: 0.29475000500679016|  0:00:21s\n","epoch 32 | loss: 0.13257 | val_0_mse: 0.9761300086975098|  0:00:21s\n","epoch 33 | loss: 0.11429 | val_0_mse: 0.7926999926567078|  0:00:22s\n","epoch 34 | loss: 0.11822 | val_0_mse: 0.9377599954605103|  0:00:23s\n","epoch 35 | loss: 0.13526 | val_0_mse: 1.236449956893921|  0:00:23s\n","epoch 36 | loss: 0.12903 | val_0_mse: 0.6880099773406982|  0:00:24s\n","epoch 37 | loss: 0.12071 | val_0_mse: 1.0305500030517578|  0:00:25s\n","epoch 38 | loss: 0.10795 | val_0_mse: 0.5751500129699707|  0:00:25s\n","epoch 39 | loss: 0.12219 | val_0_mse: 0.5339599847793579|  0:00:26s\n","epoch 40 | loss: 0.12766 | val_0_mse: 0.5017600059509277|  0:00:27s\n","epoch 41 | loss: 0.11745 | val_0_mse: 0.43268001079559326|  0:00:27s\n","\n","Early stopping occurred at epoch 41 with best_epoch = 31 and best_val_0_mse = 0.29475000500679016\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 11:44:50,009] Trial 29 finished with value: 0.2947530746459961 and parameters: {'n_d': 22, 'n_steps': 4, 'gamma': 1.5108649713602558, 'n_independent': 1, 'n_shared': 4, 'momentum': 0.2906809624996121}. Best is trial 21 with value: 0.0769263356924057.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 47.26821| val_0_mse: 21697.423828125|  0:00:01s\n","epoch 1  | loss: 8.49554 | val_0_mse: 6310.7412109375|  0:00:02s\n","epoch 2  | loss: 2.28388 | val_0_mse: 3865.112548828125|  0:00:03s\n","epoch 3  | loss: 1.17583 | val_0_mse: 6216.68408203125|  0:00:04s\n","epoch 4  | loss: 0.79257 | val_0_mse: 13521.6318359375|  0:00:05s\n","epoch 5  | loss: 0.7846  | val_0_mse: 8839.62109375|  0:00:06s\n","epoch 6  | loss: 0.55705 | val_0_mse: 2087.00341796875|  0:00:07s\n","epoch 7  | loss: 0.43083 | val_0_mse: 1097.2796630859375|  0:00:08s\n","epoch 8  | loss: 0.53418 | val_0_mse: 206.7244873046875|  0:00:09s\n","epoch 9  | loss: 0.77126 | val_0_mse: 181.9155731201172|  0:00:10s\n","epoch 10 | loss: 0.65013 | val_0_mse: 95.2071762084961|  0:00:11s\n","epoch 11 | loss: 0.61214 | val_0_mse: 109.60198974609375|  0:00:12s\n","epoch 12 | loss: 0.36294 | val_0_mse: 520.446044921875|  0:00:14s\n","epoch 13 | loss: 0.8777  | val_0_mse: 115.83096313476562|  0:00:15s\n","epoch 14 | loss: 1.14616 | val_0_mse: 100.395263671875|  0:00:16s\n","epoch 15 | loss: 2.28595 | val_0_mse: 160.2935333251953|  0:00:17s\n","epoch 16 | loss: 1.82515 | val_0_mse: 65.50431060791016|  0:00:18s\n","epoch 17 | loss: 0.67679 | val_0_mse: 49.69036865234375|  0:00:19s\n","epoch 18 | loss: 0.44218 | val_0_mse: 23.646150588989258|  0:00:20s\n","epoch 19 | loss: 0.42872 | val_0_mse: 5.994959831237793|  0:00:21s\n","epoch 20 | loss: 0.42998 | val_0_mse: 7.070899963378906|  0:00:22s\n","epoch 21 | loss: 0.24916 | val_0_mse: 6.221930027008057|  0:00:23s\n","epoch 22 | loss: 0.22666 | val_0_mse: 3.439919948577881|  0:00:24s\n","epoch 23 | loss: 0.18407 | val_0_mse: 5.165380001068115|  0:00:25s\n","epoch 24 | loss: 0.22468 | val_0_mse: 2.980220079421997|  0:00:26s\n","epoch 25 | loss: 0.27079 | val_0_mse: 1.1214799880981445|  0:00:27s\n","epoch 26 | loss: 0.2363  | val_0_mse: 0.7930200099945068|  0:00:29s\n","epoch 27 | loss: 0.22907 | val_0_mse: 0.5753600001335144|  0:00:30s\n","epoch 28 | loss: 0.20951 | val_0_mse: 0.5616400241851807|  0:00:31s\n","epoch 29 | loss: 0.2264  | val_0_mse: 0.4085800051689148|  0:00:32s\n","epoch 30 | loss: 0.24035 | val_0_mse: 0.35872000455856323|  0:00:33s\n","epoch 31 | loss: 0.23094 | val_0_mse: 0.43893998861312866|  0:00:34s\n","epoch 32 | loss: 0.23116 | val_0_mse: 0.2614299952983856|  0:00:35s\n","epoch 33 | loss: 0.19451 | val_0_mse: 0.325300008058548|  0:00:36s\n","epoch 34 | loss: 0.21311 | val_0_mse: 0.2488200068473816|  0:00:37s\n","epoch 35 | loss: 0.19098 | val_0_mse: 0.41251999139785767|  0:00:38s\n","epoch 36 | loss: 0.19634 | val_0_mse: 0.5039700269699097|  0:00:39s\n","epoch 37 | loss: 0.22628 | val_0_mse: 0.2502399981021881|  0:00:40s\n","epoch 38 | loss: 0.21997 | val_0_mse: 0.3110400140285492|  0:00:41s\n","epoch 39 | loss: 0.19849 | val_0_mse: 0.22376999258995056|  0:00:42s\n","epoch 40 | loss: 0.18233 | val_0_mse: 0.1883399933576584|  0:00:43s\n","epoch 41 | loss: 0.16664 | val_0_mse: 0.1952899992465973|  0:00:44s\n","epoch 42 | loss: 0.16289 | val_0_mse: 0.18371999263763428|  0:00:45s\n","epoch 43 | loss: 0.191   | val_0_mse: 0.16982999444007874|  0:00:47s\n","epoch 44 | loss: 0.16002 | val_0_mse: 0.18980999290943146|  0:00:48s\n","epoch 45 | loss: 0.17878 | val_0_mse: 0.23514999449253082|  0:00:49s\n","epoch 46 | loss: 0.23552 | val_0_mse: 0.19339999556541443|  0:00:50s\n","epoch 47 | loss: 0.17144 | val_0_mse: 0.15776999294757843|  0:00:51s\n","epoch 48 | loss: 0.16524 | val_0_mse: 0.148389995098114|  0:00:52s\n","epoch 49 | loss: 0.15249 | val_0_mse: 0.23191000521183014|  0:00:53s\n","epoch 50 | loss: 0.15331 | val_0_mse: 0.2120400071144104|  0:00:54s\n","epoch 51 | loss: 0.1621  | val_0_mse: 0.1640699952840805|  0:00:55s\n","epoch 52 | loss: 0.16487 | val_0_mse: 0.20624999701976776|  0:00:56s\n","epoch 53 | loss: 0.17389 | val_0_mse: 0.165010005235672|  0:00:57s\n","epoch 54 | loss: 0.15755 | val_0_mse: 0.1505099982023239|  0:00:58s\n","epoch 55 | loss: 0.19437 | val_0_mse: 0.15690000355243683|  0:00:59s\n","epoch 56 | loss: 0.18235 | val_0_mse: 0.14876000583171844|  0:01:00s\n","epoch 57 | loss: 0.14591 | val_0_mse: 0.16231000423431396|  0:01:01s\n","epoch 58 | loss: 0.15176 | val_0_mse: 0.1655299961566925|  0:01:03s\n","\n","Early stopping occurred at epoch 58 with best_epoch = 48 and best_val_0_mse = 0.148389995098114\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 11:45:53,604] Trial 30 finished with value: 0.14838652312755585 and parameters: {'n_d': 14, 'n_steps': 9, 'gamma': 1.58877383243223, 'n_independent': 1, 'n_shared': 3, 'momentum': 0.16074605727933772}. Best is trial 21 with value: 0.0769263356924057.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 44.52766| val_0_mse: 2533.099365234375|  0:00:00s\n","epoch 1  | loss: 1.30733 | val_0_mse: 558.7528076171875|  0:00:01s\n","epoch 2  | loss: 0.62433 | val_0_mse: 1637.180419921875|  0:00:02s\n","epoch 3  | loss: 0.3822  | val_0_mse: 776.7446899414062|  0:00:02s\n","epoch 4  | loss: 0.41969 | val_0_mse: 1741.451171875|  0:00:03s\n","epoch 5  | loss: 0.36811 | val_0_mse: 1422.9910888671875|  0:00:03s\n","epoch 6  | loss: 0.29171 | val_0_mse: 575.1278686523438|  0:00:04s\n","epoch 7  | loss: 0.23308 | val_0_mse: 746.1838989257812|  0:00:05s\n","epoch 8  | loss: 0.22296 | val_0_mse: 456.0056457519531|  0:00:05s\n","epoch 9  | loss: 0.18533 | val_0_mse: 127.59246826171875|  0:00:06s\n","epoch 10 | loss: 0.17432 | val_0_mse: 135.73898315429688|  0:00:07s\n","epoch 11 | loss: 0.19704 | val_0_mse: 362.1540832519531|  0:00:08s\n","epoch 12 | loss: 0.2657  | val_0_mse: 209.9578857421875|  0:00:08s\n","epoch 13 | loss: 0.21147 | val_0_mse: 167.31800842285156|  0:00:09s\n","epoch 14 | loss: 0.19738 | val_0_mse: 114.03929901123047|  0:00:10s\n","epoch 15 | loss: 0.19483 | val_0_mse: 98.27478790283203|  0:00:10s\n","epoch 16 | loss: 0.18055 | val_0_mse: 130.72923278808594|  0:00:11s\n","epoch 17 | loss: 0.17236 | val_0_mse: 42.38209915161133|  0:00:12s\n","epoch 18 | loss: 0.21107 | val_0_mse: 50.47663116455078|  0:00:12s\n","epoch 19 | loss: 0.18165 | val_0_mse: 26.606889724731445|  0:00:13s\n","epoch 20 | loss: 0.16935 | val_0_mse: 27.85849952697754|  0:00:14s\n","epoch 21 | loss: 0.15635 | val_0_mse: 11.265080451965332|  0:00:14s\n","epoch 22 | loss: 0.15615 | val_0_mse: 12.322819709777832|  0:00:15s\n","epoch 23 | loss: 0.16317 | val_0_mse: 11.157950401306152|  0:00:16s\n","epoch 24 | loss: 0.15197 | val_0_mse: 10.630049705505371|  0:00:16s\n","epoch 25 | loss: 0.15301 | val_0_mse: 4.051949977874756|  0:00:17s\n","epoch 26 | loss: 0.14395 | val_0_mse: 3.0313398838043213|  0:00:18s\n","epoch 27 | loss: 0.14581 | val_0_mse: 1.8025599718093872|  0:00:19s\n","epoch 28 | loss: 0.1627  | val_0_mse: 2.4028398990631104|  0:00:19s\n","epoch 29 | loss: 0.16037 | val_0_mse: 1.2575199604034424|  0:00:20s\n","epoch 30 | loss: 0.17413 | val_0_mse: 1.9214600324630737|  0:00:21s\n","epoch 31 | loss: 0.18415 | val_0_mse: 0.9510800242424011|  0:00:21s\n","epoch 32 | loss: 0.17868 | val_0_mse: 1.1538900136947632|  0:00:22s\n","epoch 33 | loss: 0.14782 | val_0_mse: 0.4717000126838684|  0:00:23s\n","epoch 34 | loss: 0.1432  | val_0_mse: 0.7287600040435791|  0:00:23s\n","epoch 35 | loss: 0.13184 | val_0_mse: 0.42653000354766846|  0:00:24s\n","epoch 36 | loss: 0.12844 | val_0_mse: 0.525439977645874|  0:00:25s\n","epoch 37 | loss: 0.1298  | val_0_mse: 0.30498000979423523|  0:00:25s\n","epoch 38 | loss: 0.12337 | val_0_mse: 0.5097000002861023|  0:00:26s\n","epoch 39 | loss: 0.12725 | val_0_mse: 0.26159000396728516|  0:00:27s\n","epoch 40 | loss: 0.15226 | val_0_mse: 0.30630001425743103|  0:00:27s\n","epoch 41 | loss: 0.13731 | val_0_mse: 0.2337000072002411|  0:00:28s\n","epoch 42 | loss: 0.11964 | val_0_mse: 0.21425999701023102|  0:00:29s\n","epoch 43 | loss: 0.1119  | val_0_mse: 0.24990999698638916|  0:00:29s\n","epoch 44 | loss: 0.10261 | val_0_mse: 0.2209099978208542|  0:00:30s\n","epoch 45 | loss: 0.10273 | val_0_mse: 0.1783200055360794|  0:00:31s\n","epoch 46 | loss: 0.10651 | val_0_mse: 0.15971000492572784|  0:00:32s\n","epoch 47 | loss: 0.10479 | val_0_mse: 0.20920999348163605|  0:00:32s\n","epoch 48 | loss: 0.09952 | val_0_mse: 0.15428000688552856|  0:00:33s\n","epoch 49 | loss: 0.12412 | val_0_mse: 0.3243100047111511|  0:00:34s\n","epoch 50 | loss: 0.1365  | val_0_mse: 0.13342000544071198|  0:00:34s\n","epoch 51 | loss: 0.12308 | val_0_mse: 0.22899000346660614|  0:00:35s\n","epoch 52 | loss: 0.12149 | val_0_mse: 0.12371999770402908|  0:00:36s\n","epoch 53 | loss: 0.1154  | val_0_mse: 0.19643999636173248|  0:00:36s\n","epoch 54 | loss: 0.11233 | val_0_mse: 0.12190999835729599|  0:00:37s\n","epoch 55 | loss: 0.08814 | val_0_mse: 0.12291000038385391|  0:00:38s\n","epoch 56 | loss: 0.08888 | val_0_mse: 0.17472000420093536|  0:00:38s\n","epoch 57 | loss: 0.10803 | val_0_mse: 0.1490900069475174|  0:00:39s\n","epoch 58 | loss: 0.11442 | val_0_mse: 0.11768999695777893|  0:00:40s\n","epoch 59 | loss: 0.13838 | val_0_mse: 0.11467000097036362|  0:00:41s\n","epoch 60 | loss: 0.10153 | val_0_mse: 0.1052199974656105|  0:00:41s\n","epoch 61 | loss: 0.1029  | val_0_mse: 0.11485999822616577|  0:00:42s\n","epoch 62 | loss: 0.09823 | val_0_mse: 0.12219999730587006|  0:00:43s\n","epoch 63 | loss: 0.1004  | val_0_mse: 0.09945999830961227|  0:00:43s\n","epoch 64 | loss: 0.10381 | val_0_mse: 0.1092199981212616|  0:00:44s\n","epoch 65 | loss: 0.0969  | val_0_mse: 0.09272000193595886|  0:00:45s\n","epoch 66 | loss: 0.09887 | val_0_mse: 0.10254999995231628|  0:00:45s\n","epoch 67 | loss: 0.12665 | val_0_mse: 0.11894000321626663|  0:00:46s\n","epoch 68 | loss: 0.1171  | val_0_mse: 0.13575999438762665|  0:00:47s\n","epoch 69 | loss: 0.11668 | val_0_mse: 0.11274000257253647|  0:00:47s\n","epoch 70 | loss: 0.12608 | val_0_mse: 0.1063700020313263|  0:00:48s\n","epoch 71 | loss: 0.10368 | val_0_mse: 0.10561999678611755|  0:00:49s\n","epoch 72 | loss: 0.10207 | val_0_mse: 0.09245000034570694|  0:00:49s\n","epoch 73 | loss: 0.09671 | val_0_mse: 0.10046999901533127|  0:00:50s\n","epoch 74 | loss: 0.10746 | val_0_mse: 0.10213000327348709|  0:00:51s\n","epoch 75 | loss: 0.09884 | val_0_mse: 0.08525999635457993|  0:00:51s\n","epoch 76 | loss: 0.09536 | val_0_mse: 0.11392000317573547|  0:00:52s\n","epoch 77 | loss: 0.09467 | val_0_mse: 0.08792000263929367|  0:00:53s\n","epoch 78 | loss: 0.08533 | val_0_mse: 0.08681999891996384|  0:00:54s\n","epoch 79 | loss: 0.08509 | val_0_mse: 0.10780999809503555|  0:00:54s\n","epoch 80 | loss: 0.08167 | val_0_mse: 0.08867000043392181|  0:00:55s\n","epoch 81 | loss: 0.08243 | val_0_mse: 0.08408000320196152|  0:00:56s\n","epoch 82 | loss: 0.08683 | val_0_mse: 0.08917000144720078|  0:00:56s\n","epoch 83 | loss: 0.09209 | val_0_mse: 0.09709999710321426|  0:00:57s\n","epoch 84 | loss: 0.08906 | val_0_mse: 0.08399000018835068|  0:00:58s\n","epoch 85 | loss: 0.08125 | val_0_mse: 0.09803999960422516|  0:00:58s\n","epoch 86 | loss: 0.09296 | val_0_mse: 0.08983000367879868|  0:00:59s\n","epoch 87 | loss: 0.11887 | val_0_mse: 0.09119000285863876|  0:01:00s\n","epoch 88 | loss: 0.11894 | val_0_mse: 0.08583000302314758|  0:01:00s\n","epoch 89 | loss: 0.09556 | val_0_mse: 0.09324999898672104|  0:01:01s\n","epoch 90 | loss: 0.07959 | val_0_mse: 0.07874000072479248|  0:01:02s\n","epoch 91 | loss: 0.08204 | val_0_mse: 0.08078999817371368|  0:01:03s\n","epoch 92 | loss: 0.08103 | val_0_mse: 0.07786999642848969|  0:01:03s\n","epoch 93 | loss: 0.11269 | val_0_mse: 0.11016000062227249|  0:01:04s\n","epoch 94 | loss: 0.10747 | val_0_mse: 0.09617999941110611|  0:01:05s\n","epoch 95 | loss: 0.10187 | val_0_mse: 0.0869000032544136|  0:01:05s\n","epoch 96 | loss: 0.10529 | val_0_mse: 0.09470999985933304|  0:01:06s\n","epoch 97 | loss: 0.10595 | val_0_mse: 0.0945499986410141|  0:01:07s\n","epoch 98 | loss: 0.08817 | val_0_mse: 0.07661999762058258|  0:01:07s\n","epoch 99 | loss: 0.07625 | val_0_mse: 0.08021000027656555|  0:01:08s\n","Stop training because you reached max_epochs = 100 with best_epoch = 98 and best_val_0_mse = 0.07661999762058258\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 11:47:02,403] Trial 31 finished with value: 0.07662469148635864 and parameters: {'n_d': 42, 'n_steps': 3, 'gamma': 1.1843093917318663, 'n_independent': 2, 'n_shared': 5, 'momentum': 0.27780831200927614}. Best is trial 31 with value: 0.07662469148635864.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 54.1211 | val_0_mse: 130835.1796875|  0:00:00s\n","epoch 1  | loss: 1.74039 | val_0_mse: 886.5135498046875|  0:00:01s\n","epoch 2  | loss: 0.68394 | val_0_mse: 253.09507751464844|  0:00:01s\n","epoch 3  | loss: 0.40368 | val_0_mse: 648.625732421875|  0:00:02s\n","epoch 4  | loss: 0.54029 | val_0_mse: 722.8941040039062|  0:00:03s\n","epoch 5  | loss: 0.33679 | val_0_mse: 122.68531036376953|  0:00:03s\n","epoch 6  | loss: 0.2775  | val_0_mse: 393.4025573730469|  0:00:04s\n","epoch 7  | loss: 0.20314 | val_0_mse: 401.5717468261719|  0:00:04s\n","epoch 8  | loss: 0.2475  | val_0_mse: 36.06087875366211|  0:00:05s\n","epoch 9  | loss: 0.26328 | val_0_mse: 18.57023048400879|  0:00:06s\n","epoch 10 | loss: 0.19813 | val_0_mse: 9.883509635925293|  0:00:06s\n","epoch 11 | loss: 0.20501 | val_0_mse: 9.0600004196167|  0:00:07s\n","epoch 12 | loss: 0.18997 | val_0_mse: 9.641220092773438|  0:00:07s\n","epoch 13 | loss: 0.17009 | val_0_mse: 12.901140213012695|  0:00:08s\n","epoch 14 | loss: 0.17121 | val_0_mse: 9.070099830627441|  0:00:09s\n","epoch 15 | loss: 0.15733 | val_0_mse: 13.041879653930664|  0:00:09s\n","epoch 16 | loss: 0.14825 | val_0_mse: 10.241840362548828|  0:00:10s\n","epoch 17 | loss: 0.14423 | val_0_mse: 3.781480073928833|  0:00:10s\n","epoch 18 | loss: 0.12466 | val_0_mse: 6.264639854431152|  0:00:11s\n","epoch 19 | loss: 0.11768 | val_0_mse: 8.926630020141602|  0:00:12s\n","epoch 20 | loss: 0.11545 | val_0_mse: 0.9693899750709534|  0:00:12s\n","epoch 21 | loss: 0.1185  | val_0_mse: 3.9681499004364014|  0:00:13s\n","epoch 22 | loss: 0.1586  | val_0_mse: 1.7818700075149536|  0:00:13s\n","epoch 23 | loss: 0.1524  | val_0_mse: 6.331600189208984|  0:00:14s\n","epoch 24 | loss: 0.14521 | val_0_mse: 3.6376099586486816|  0:00:15s\n","epoch 25 | loss: 0.15614 | val_0_mse: 15.217679977416992|  0:00:15s\n","epoch 26 | loss: 0.1456  | val_0_mse: 10.030170440673828|  0:00:16s\n","epoch 27 | loss: 0.11677 | val_0_mse: 1.0089600086212158|  0:00:16s\n","epoch 28 | loss: 0.12887 | val_0_mse: 6.604629993438721|  0:00:17s\n","epoch 29 | loss: 0.10606 | val_0_mse: 5.436369895935059|  0:00:18s\n","epoch 30 | loss: 0.11129 | val_0_mse: 9.158029556274414|  0:00:18s\n","\n","Early stopping occurred at epoch 30 with best_epoch = 20 and best_val_0_mse = 0.9693899750709534\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 11:47:21,509] Trial 32 finished with value: 0.9693887829780579 and parameters: {'n_d': 40, 'n_steps': 3, 'gamma': 1.2104974565540731, 'n_independent': 1, 'n_shared': 5, 'momentum': 0.3346189555832585}. Best is trial 31 with value: 0.07662469148635864.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 24.41074| val_0_mse: 64447.51953125|  0:00:00s\n","epoch 1  | loss: 1.16328 | val_0_mse: 3681.1337890625|  0:00:01s\n","epoch 2  | loss: 0.65472 | val_0_mse: 5130.3388671875|  0:00:02s\n","epoch 3  | loss: 0.40958 | val_0_mse: 1824.7396240234375|  0:00:02s\n","epoch 4  | loss: 0.32129 | val_0_mse: 705.131103515625|  0:00:03s\n","epoch 5  | loss: 0.22133 | val_0_mse: 567.7137451171875|  0:00:04s\n","epoch 6  | loss: 0.22456 | val_0_mse: 1063.5302734375|  0:00:05s\n","epoch 7  | loss: 0.19826 | val_0_mse: 344.3134460449219|  0:00:05s\n","epoch 8  | loss: 0.18945 | val_0_mse: 480.7198791503906|  0:00:06s\n","epoch 9  | loss: 0.25769 | val_0_mse: 300.357177734375|  0:00:07s\n","epoch 10 | loss: 0.2345  | val_0_mse: 217.32728576660156|  0:00:07s\n","epoch 11 | loss: 0.20844 | val_0_mse: 223.34957885742188|  0:00:08s\n","epoch 12 | loss: 0.17467 | val_0_mse: 125.37866973876953|  0:00:09s\n","epoch 13 | loss: 0.20197 | val_0_mse: 95.34236907958984|  0:00:10s\n","epoch 14 | loss: 0.17111 | val_0_mse: 39.029850006103516|  0:00:10s\n","epoch 15 | loss: 0.13701 | val_0_mse: 50.856849670410156|  0:00:11s\n","epoch 16 | loss: 0.14258 | val_0_mse: 24.0362491607666|  0:00:12s\n","epoch 17 | loss: 0.13201 | val_0_mse: 5.864109992980957|  0:00:13s\n","epoch 18 | loss: 0.17734 | val_0_mse: 6.83882999420166|  0:00:13s\n","epoch 19 | loss: 0.17205 | val_0_mse: 1.384179949760437|  0:00:14s\n","epoch 20 | loss: 0.15262 | val_0_mse: 1.6250100135803223|  0:00:15s\n","epoch 21 | loss: 0.15218 | val_0_mse: 0.49074000120162964|  0:00:15s\n","epoch 22 | loss: 0.14621 | val_0_mse: 0.550849974155426|  0:00:16s\n","epoch 23 | loss: 0.11748 | val_0_mse: 1.4622000455856323|  0:00:17s\n","epoch 24 | loss: 0.12237 | val_0_mse: 0.9839500188827515|  0:00:18s\n","epoch 25 | loss: 0.12524 | val_0_mse: 0.8016899824142456|  0:00:18s\n","epoch 26 | loss: 0.13824 | val_0_mse: 0.8611199855804443|  0:00:19s\n","epoch 27 | loss: 0.31045 | val_0_mse: 0.8699399828910828|  0:00:20s\n","epoch 28 | loss: 0.23202 | val_0_mse: 1.7317299842834473|  0:00:20s\n","epoch 29 | loss: 0.14317 | val_0_mse: 0.7773299813270569|  0:00:21s\n","epoch 30 | loss: 0.10996 | val_0_mse: 0.8766300082206726|  0:00:22s\n","epoch 31 | loss: 0.10535 | val_0_mse: 1.1463899612426758|  0:00:23s\n","\n","Early stopping occurred at epoch 31 with best_epoch = 21 and best_val_0_mse = 0.49074000120162964\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 11:47:45,234] Trial 33 finished with value: 0.490739643573761 and parameters: {'n_d': 30, 'n_steps': 4, 'gamma': 1.0677388267148296, 'n_independent': 2, 'n_shared': 4, 'momentum': 0.12072025173656839}. Best is trial 31 with value: 0.07662469148635864.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 61.86557| val_0_mse: 11187.4599609375|  0:00:00s\n","epoch 1  | loss: 1.68503 | val_0_mse: 3541.577392578125|  0:00:01s\n","epoch 2  | loss: 0.50659 | val_0_mse: 2532.59423828125|  0:00:01s\n","epoch 3  | loss: 0.35648 | val_0_mse: 464.99005126953125|  0:00:02s\n","epoch 4  | loss: 0.25046 | val_0_mse: 4517.54248046875|  0:00:03s\n","epoch 5  | loss: 0.2272  | val_0_mse: 4600.5830078125|  0:00:03s\n","epoch 6  | loss: 0.22476 | val_0_mse: 1757.4017333984375|  0:00:04s\n","epoch 7  | loss: 0.24086 | val_0_mse: 666.7544555664062|  0:00:04s\n","epoch 8  | loss: 0.32034 | val_0_mse: 356.86846923828125|  0:00:05s\n","epoch 9  | loss: 0.19183 | val_0_mse: 107.92666625976562|  0:00:05s\n","epoch 10 | loss: 0.18205 | val_0_mse: 58.899818420410156|  0:00:06s\n","epoch 11 | loss: 0.15159 | val_0_mse: 64.62165069580078|  0:00:07s\n","epoch 12 | loss: 0.15081 | val_0_mse: 52.049808502197266|  0:00:07s\n","epoch 13 | loss: 0.15082 | val_0_mse: 38.85573959350586|  0:00:08s\n","epoch 14 | loss: 0.13156 | val_0_mse: 29.447589874267578|  0:00:08s\n","epoch 15 | loss: 0.12593 | val_0_mse: 16.41699981689453|  0:00:09s\n","epoch 16 | loss: 0.13506 | val_0_mse: 18.964710235595703|  0:00:10s\n","epoch 17 | loss: 0.12962 | val_0_mse: 8.372469902038574|  0:00:10s\n","epoch 18 | loss: 0.12403 | val_0_mse: 12.662690162658691|  0:00:11s\n","epoch 19 | loss: 0.12229 | val_0_mse: 7.145959854125977|  0:00:12s\n","epoch 20 | loss: 0.12074 | val_0_mse: 4.253429889678955|  0:00:12s\n","epoch 21 | loss: 0.12196 | val_0_mse: 2.7832698822021484|  0:00:13s\n","epoch 22 | loss: 0.11317 | val_0_mse: 3.2260899543762207|  0:00:13s\n","epoch 23 | loss: 0.12312 | val_0_mse: 1.6046600341796875|  0:00:14s\n","epoch 24 | loss: 0.10098 | val_0_mse: 1.8617899417877197|  0:00:15s\n","epoch 25 | loss: 0.10378 | val_0_mse: 1.0815199613571167|  0:00:15s\n","epoch 26 | loss: 0.0979  | val_0_mse: 2.0294599533081055|  0:00:16s\n","epoch 27 | loss: 0.10591 | val_0_mse: 0.866159975528717|  0:00:16s\n","epoch 28 | loss: 0.10619 | val_0_mse: 0.7115700244903564|  0:00:17s\n","epoch 29 | loss: 0.09877 | val_0_mse: 0.7582700252532959|  0:00:17s\n","epoch 30 | loss: 0.1032  | val_0_mse: 0.552649974822998|  0:00:18s\n","epoch 31 | loss: 0.10723 | val_0_mse: 0.7501000165939331|  0:00:19s\n","epoch 32 | loss: 0.10065 | val_0_mse: 0.5881800055503845|  0:00:19s\n","epoch 33 | loss: 0.13635 | val_0_mse: 0.509880006313324|  0:00:20s\n","epoch 34 | loss: 0.12869 | val_0_mse: 0.5806999802589417|  0:00:21s\n","epoch 35 | loss: 0.12645 | val_0_mse: 0.5873799920082092|  0:00:21s\n","epoch 36 | loss: 0.09869 | val_0_mse: 0.5186399817466736|  0:00:22s\n","epoch 37 | loss: 0.09402 | val_0_mse: 0.5173900127410889|  0:00:22s\n","epoch 38 | loss: 0.10623 | val_0_mse: 0.3955700099468231|  0:00:23s\n","epoch 39 | loss: 0.11119 | val_0_mse: 0.5811600089073181|  0:00:24s\n","epoch 40 | loss: 0.12673 | val_0_mse: 0.2787199914455414|  0:00:24s\n","epoch 41 | loss: 0.12773 | val_0_mse: 0.5702800154685974|  0:00:25s\n","epoch 42 | loss: 0.12233 | val_0_mse: 0.23951999843120575|  0:00:25s\n","epoch 43 | loss: 0.11532 | val_0_mse: 0.4282900094985962|  0:00:26s\n","epoch 44 | loss: 0.11514 | val_0_mse: 0.2621900141239166|  0:00:27s\n","epoch 45 | loss: 0.10003 | val_0_mse: 0.21651999652385712|  0:00:27s\n","epoch 46 | loss: 0.10874 | val_0_mse: 0.33722999691963196|  0:00:28s\n","epoch 47 | loss: 0.13504 | val_0_mse: 0.1968500018119812|  0:00:28s\n","epoch 48 | loss: 0.10317 | val_0_mse: 0.21233999729156494|  0:00:29s\n","epoch 49 | loss: 0.09256 | val_0_mse: 0.16220000386238098|  0:00:29s\n","epoch 50 | loss: 0.10072 | val_0_mse: 0.22696000337600708|  0:00:30s\n","epoch 51 | loss: 0.09246 | val_0_mse: 0.16015000641345978|  0:00:31s\n","epoch 52 | loss: 0.08706 | val_0_mse: 0.15376999974250793|  0:00:31s\n","epoch 53 | loss: 0.08857 | val_0_mse: 0.13594000041484833|  0:00:32s\n","epoch 54 | loss: 0.10798 | val_0_mse: 0.18021999299526215|  0:00:33s\n","epoch 55 | loss: 0.10033 | val_0_mse: 0.1894499957561493|  0:00:33s\n","epoch 56 | loss: 0.09902 | val_0_mse: 0.12247999757528305|  0:00:34s\n","epoch 57 | loss: 0.09466 | val_0_mse: 0.16553999483585358|  0:00:34s\n","epoch 58 | loss: 0.0965  | val_0_mse: 0.1099499985575676|  0:00:35s\n","epoch 59 | loss: 0.08351 | val_0_mse: 0.11658000200986862|  0:00:35s\n","epoch 60 | loss: 0.08695 | val_0_mse: 0.12263000011444092|  0:00:36s\n","epoch 61 | loss: 0.09824 | val_0_mse: 0.10918000340461731|  0:00:37s\n","epoch 62 | loss: 0.08869 | val_0_mse: 0.11449000239372253|  0:00:37s\n","epoch 63 | loss: 0.08546 | val_0_mse: 0.12985000014305115|  0:00:38s\n","epoch 64 | loss: 0.08903 | val_0_mse: 0.10995999723672867|  0:00:38s\n","epoch 65 | loss: 0.09377 | val_0_mse: 0.11088000237941742|  0:00:39s\n","epoch 66 | loss: 0.09063 | val_0_mse: 0.09397999942302704|  0:00:40s\n","epoch 67 | loss: 0.08251 | val_0_mse: 0.12891000509262085|  0:00:40s\n","epoch 68 | loss: 0.12023 | val_0_mse: 0.09711000323295593|  0:00:41s\n","epoch 69 | loss: 0.09733 | val_0_mse: 0.11721000075340271|  0:00:41s\n","epoch 70 | loss: 0.09233 | val_0_mse: 0.10886000096797943|  0:00:42s\n","epoch 71 | loss: 0.08632 | val_0_mse: 0.09185999631881714|  0:00:43s\n","epoch 72 | loss: 0.08006 | val_0_mse: 0.09099999815225601|  0:00:43s\n","epoch 73 | loss: 0.07763 | val_0_mse: 0.08788000047206879|  0:00:44s\n","epoch 74 | loss: 0.08633 | val_0_mse: 0.10422000288963318|  0:00:45s\n","epoch 75 | loss: 0.09092 | val_0_mse: 0.09459000080823898|  0:00:45s\n","epoch 76 | loss: 0.08266 | val_0_mse: 0.10628999769687653|  0:00:46s\n","epoch 77 | loss: 0.07766 | val_0_mse: 0.09707000106573105|  0:00:46s\n","epoch 78 | loss: 0.07851 | val_0_mse: 0.09079000353813171|  0:00:47s\n","epoch 79 | loss: 0.09151 | val_0_mse: 0.16776999831199646|  0:00:48s\n","epoch 80 | loss: 0.10903 | val_0_mse: 0.1636900007724762|  0:00:48s\n","epoch 81 | loss: 0.09945 | val_0_mse: 0.11734999716281891|  0:00:49s\n","epoch 82 | loss: 0.08255 | val_0_mse: 0.08377999812364578|  0:00:49s\n","epoch 83 | loss: 0.07715 | val_0_mse: 0.09497000277042389|  0:00:50s\n","epoch 84 | loss: 0.08357 | val_0_mse: 0.0843999981880188|  0:00:51s\n","epoch 85 | loss: 0.08535 | val_0_mse: 0.08359000086784363|  0:00:51s\n","epoch 86 | loss: 0.08317 | val_0_mse: 0.08574000000953674|  0:00:52s\n","epoch 87 | loss: 0.07667 | val_0_mse: 0.090379998087883|  0:00:52s\n","epoch 88 | loss: 0.08745 | val_0_mse: 0.08974000066518784|  0:00:53s\n","epoch 89 | loss: 0.07744 | val_0_mse: 0.08263999968767166|  0:00:54s\n","epoch 90 | loss: 0.07545 | val_0_mse: 0.09985999763011932|  0:00:54s\n","epoch 91 | loss: 0.08935 | val_0_mse: 0.08634000271558762|  0:00:55s\n","epoch 92 | loss: 0.084   | val_0_mse: 0.08372999727725983|  0:00:55s\n","epoch 93 | loss: 0.08544 | val_0_mse: 0.10424000024795532|  0:00:56s\n","epoch 94 | loss: 0.1     | val_0_mse: 0.13273000717163086|  0:00:57s\n","epoch 95 | loss: 0.09836 | val_0_mse: 0.1351500004529953|  0:00:57s\n","epoch 96 | loss: 0.10302 | val_0_mse: 0.14597000181674957|  0:00:58s\n","epoch 97 | loss: 0.10608 | val_0_mse: 0.09583999961614609|  0:00:58s\n","epoch 98 | loss: 0.10169 | val_0_mse: 0.13009999692440033|  0:00:59s\n","epoch 99 | loss: 0.10003 | val_0_mse: 0.14246000349521637|  0:01:00s\n","\n","Early stopping occurred at epoch 99 with best_epoch = 89 and best_val_0_mse = 0.08263999968767166\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 11:48:45,584] Trial 34 finished with value: 0.0826413556933403 and parameters: {'n_d': 35, 'n_steps': 3, 'gamma': 1.3099511559502033, 'n_independent': 1, 'n_shared': 5, 'momentum': 0.36165891942876294}. Best is trial 31 with value: 0.07662469148635864.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 145.96702| val_0_mse: 17937.0625|  0:00:00s\n","epoch 1  | loss: 53.2911 | val_0_mse: 191488.484375|  0:00:01s\n","epoch 2  | loss: 9.46563 | val_0_mse: 231234.21875|  0:00:02s\n","epoch 3  | loss: 1.65159 | val_0_mse: 16833.150390625|  0:00:03s\n","epoch 4  | loss: 0.90414 | val_0_mse: 28074.873046875|  0:00:04s\n","epoch 5  | loss: 0.57458 | val_0_mse: 747.805908203125|  0:00:05s\n","epoch 6  | loss: 0.61964 | val_0_mse: 550.1039428710938|  0:00:06s\n","epoch 7  | loss: 0.42281 | val_0_mse: 163.84849548339844|  0:00:06s\n","epoch 8  | loss: 0.34023 | val_0_mse: 429.9570007324219|  0:00:07s\n","epoch 9  | loss: 0.27747 | val_0_mse: 520.3489379882812|  0:00:08s\n","epoch 10 | loss: 0.23391 | val_0_mse: 293.928955078125|  0:00:09s\n","epoch 11 | loss: 0.21464 | val_0_mse: 332.73492431640625|  0:00:10s\n","epoch 12 | loss: 0.23686 | val_0_mse: 108.60035705566406|  0:00:11s\n","epoch 13 | loss: 0.19394 | val_0_mse: 166.70118713378906|  0:00:12s\n","epoch 14 | loss: 0.17816 | val_0_mse: 47.79412841796875|  0:00:12s\n","epoch 15 | loss: 0.18041 | val_0_mse: 21.816560745239258|  0:00:13s\n","epoch 16 | loss: 0.17282 | val_0_mse: 27.101530075073242|  0:00:14s\n","epoch 17 | loss: 0.17012 | val_0_mse: 24.105920791625977|  0:00:15s\n","epoch 18 | loss: 0.18013 | val_0_mse: 21.798879623413086|  0:00:16s\n","epoch 19 | loss: 0.16002 | val_0_mse: 13.886190414428711|  0:00:17s\n","epoch 20 | loss: 0.15646 | val_0_mse: 8.608810424804688|  0:00:18s\n","epoch 21 | loss: 0.15546 | val_0_mse: 7.844170093536377|  0:00:18s\n","epoch 22 | loss: 0.15447 | val_0_mse: 6.513919830322266|  0:00:19s\n","epoch 23 | loss: 0.18473 | val_0_mse: 4.205379962921143|  0:00:20s\n","epoch 24 | loss: 0.16326 | val_0_mse: 2.0818700790405273|  0:00:21s\n","epoch 25 | loss: 0.16011 | val_0_mse: 1.387869954109192|  0:00:22s\n","epoch 26 | loss: 0.14683 | val_0_mse: 1.526960015296936|  0:00:23s\n","epoch 27 | loss: 0.15015 | val_0_mse: 2.226680040359497|  0:00:24s\n","epoch 28 | loss: 0.18158 | val_0_mse: 1.4849400520324707|  0:00:24s\n","epoch 29 | loss: 0.16386 | val_0_mse: 0.9332900047302246|  0:00:25s\n","epoch 30 | loss: 0.15598 | val_0_mse: 0.5503799915313721|  0:00:26s\n","epoch 31 | loss: 0.1599  | val_0_mse: 0.5420600175857544|  0:00:27s\n","epoch 32 | loss: 0.15907 | val_0_mse: 0.42857998609542847|  0:00:28s\n","epoch 33 | loss: 0.14794 | val_0_mse: 0.3767099976539612|  0:00:29s\n","epoch 34 | loss: 0.14028 | val_0_mse: 0.390610009431839|  0:00:30s\n","epoch 35 | loss: 0.14887 | val_0_mse: 0.3405799865722656|  0:00:30s\n","epoch 36 | loss: 0.14363 | val_0_mse: 0.28134000301361084|  0:00:31s\n","epoch 37 | loss: 0.14046 | val_0_mse: 0.29967001080513|  0:00:32s\n","epoch 38 | loss: 0.13987 | val_0_mse: 0.2783699929714203|  0:00:33s\n","epoch 39 | loss: 0.14074 | val_0_mse: 0.2020300030708313|  0:00:34s\n","epoch 40 | loss: 0.13939 | val_0_mse: 0.22488999366760254|  0:00:35s\n","epoch 41 | loss: 0.13785 | val_0_mse: 0.19538000226020813|  0:00:36s\n","epoch 42 | loss: 0.13403 | val_0_mse: 0.1954299956560135|  0:00:37s\n","epoch 43 | loss: 0.13806 | val_0_mse: 0.17887000739574432|  0:00:37s\n","epoch 44 | loss: 0.1341  | val_0_mse: 0.1709900051355362|  0:00:38s\n","epoch 45 | loss: 0.1386  | val_0_mse: 0.1857299953699112|  0:00:39s\n","epoch 46 | loss: 0.13864 | val_0_mse: 0.17038999497890472|  0:00:40s\n","epoch 47 | loss: 0.13748 | val_0_mse: 0.16761000454425812|  0:00:41s\n","epoch 48 | loss: 0.1358  | val_0_mse: 0.17757000029087067|  0:00:42s\n","epoch 49 | loss: 0.14947 | val_0_mse: 0.18512000143527985|  0:00:43s\n","epoch 50 | loss: 0.14992 | val_0_mse: 0.2272000014781952|  0:00:44s\n","epoch 51 | loss: 0.1571  | val_0_mse: 0.16760000586509705|  0:00:44s\n","epoch 52 | loss: 0.14788 | val_0_mse: 0.17330999672412872|  0:00:45s\n","epoch 53 | loss: 0.15131 | val_0_mse: 0.16814999282360077|  0:00:46s\n","epoch 54 | loss: 0.14746 | val_0_mse: 0.1637199968099594|  0:00:47s\n","epoch 55 | loss: 0.1585  | val_0_mse: 0.16572000086307526|  0:00:48s\n","epoch 56 | loss: 0.16654 | val_0_mse: 0.1682800054550171|  0:00:49s\n","epoch 57 | loss: 0.16361 | val_0_mse: 0.1649399995803833|  0:00:50s\n","epoch 58 | loss: 0.15028 | val_0_mse: 0.15139000117778778|  0:00:50s\n","epoch 59 | loss: 0.15709 | val_0_mse: 0.1702200025320053|  0:00:51s\n","epoch 60 | loss: 0.15585 | val_0_mse: 0.1609800010919571|  0:00:52s\n","epoch 61 | loss: 0.16205 | val_0_mse: 0.21623000502586365|  0:00:53s\n","epoch 62 | loss: 0.16357 | val_0_mse: 0.17539000511169434|  0:00:54s\n","epoch 63 | loss: 0.16061 | val_0_mse: 0.15283000469207764|  0:00:55s\n","epoch 64 | loss: 0.14484 | val_0_mse: 0.1522500067949295|  0:00:56s\n","epoch 65 | loss: 0.14441 | val_0_mse: 0.15286000072956085|  0:00:56s\n","epoch 66 | loss: 0.14151 | val_0_mse: 0.15283000469207764|  0:00:57s\n","epoch 67 | loss: 0.14831 | val_0_mse: 0.15000000596046448|  0:00:58s\n","epoch 68 | loss: 0.14932 | val_0_mse: 0.15313999354839325|  0:00:59s\n","epoch 69 | loss: 0.14438 | val_0_mse: 0.14945000410079956|  0:01:00s\n","epoch 70 | loss: 0.14593 | val_0_mse: 0.13928000628948212|  0:01:01s\n","epoch 71 | loss: 0.13786 | val_0_mse: 0.1434900015592575|  0:01:01s\n","epoch 72 | loss: 0.14107 | val_0_mse: 0.14850999414920807|  0:01:02s\n","epoch 73 | loss: 0.14802 | val_0_mse: 0.14218999445438385|  0:01:03s\n","epoch 74 | loss: 0.13872 | val_0_mse: 0.13806000351905823|  0:01:04s\n","epoch 75 | loss: 0.13719 | val_0_mse: 0.1430400013923645|  0:01:05s\n","epoch 76 | loss: 0.13565 | val_0_mse: 0.13851000368595123|  0:01:06s\n","epoch 77 | loss: 0.12941 | val_0_mse: 0.13062000274658203|  0:01:07s\n","epoch 78 | loss: 0.13122 | val_0_mse: 0.13270999491214752|  0:01:08s\n","epoch 79 | loss: 0.12928 | val_0_mse: 0.12814000248908997|  0:01:08s\n","epoch 80 | loss: 0.12264 | val_0_mse: 0.12382999807596207|  0:01:09s\n","epoch 81 | loss: 0.12024 | val_0_mse: 0.12161000072956085|  0:01:10s\n","epoch 82 | loss: 0.11952 | val_0_mse: 0.1212100014090538|  0:01:11s\n","epoch 83 | loss: 0.12132 | val_0_mse: 0.12846000492572784|  0:01:12s\n","epoch 84 | loss: 0.12102 | val_0_mse: 0.11630000174045563|  0:01:13s\n","epoch 85 | loss: 0.11102 | val_0_mse: 0.11122000217437744|  0:01:14s\n","epoch 86 | loss: 0.1145  | val_0_mse: 0.12256000190973282|  0:01:15s\n","epoch 87 | loss: 0.12147 | val_0_mse: 0.11545000225305557|  0:01:15s\n","epoch 88 | loss: 0.11882 | val_0_mse: 0.10741999745368958|  0:01:16s\n","epoch 89 | loss: 0.10972 | val_0_mse: 0.11326000094413757|  0:01:17s\n","epoch 90 | loss: 0.11737 | val_0_mse: 0.11771000176668167|  0:01:18s\n","epoch 91 | loss: 0.11356 | val_0_mse: 0.12099999934434891|  0:01:19s\n","epoch 92 | loss: 0.11177 | val_0_mse: 0.11482000350952148|  0:01:20s\n","epoch 93 | loss: 0.11579 | val_0_mse: 0.12196999788284302|  0:01:20s\n","epoch 94 | loss: 0.11337 | val_0_mse: 0.1092899963259697|  0:01:21s\n","epoch 95 | loss: 0.10832 | val_0_mse: 0.1373099982738495|  0:01:22s\n","epoch 96 | loss: 0.11802 | val_0_mse: 0.1527000069618225|  0:01:23s\n","epoch 97 | loss: 0.11225 | val_0_mse: 0.13054999709129333|  0:01:24s\n","epoch 98 | loss: 0.11151 | val_0_mse: 0.11258000135421753|  0:01:25s\n","\n","Early stopping occurred at epoch 98 with best_epoch = 88 and best_val_0_mse = 0.10741999745368958\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 11:50:11,163] Trial 35 finished with value: 0.10742346197366714 and parameters: {'n_d': 13, 'n_steps': 5, 'gamma': 1.4391833998074943, 'n_independent': 2, 'n_shared': 4, 'momentum': 0.24026535837328747}. Best is trial 31 with value: 0.07662469148635864.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 53.86773| val_0_mse: 602383.0625|  0:00:00s\n","epoch 1  | loss: 3.1698  | val_0_mse: 2810.583984375|  0:00:01s\n","epoch 2  | loss: 1.12107 | val_0_mse: 18810.3203125|  0:00:01s\n","epoch 3  | loss: 0.53077 | val_0_mse: 2323.859619140625|  0:00:02s\n","epoch 4  | loss: 0.45232 | val_0_mse: 846.5588989257812|  0:00:02s\n","epoch 5  | loss: 0.3192  | val_0_mse: 350.265625|  0:00:03s\n","epoch 6  | loss: 0.29185 | val_0_mse: 373.39007568359375|  0:00:03s\n","epoch 7  | loss: 0.2727  | val_0_mse: 118.03317260742188|  0:00:04s\n","epoch 8  | loss: 0.24416 | val_0_mse: 267.0332336425781|  0:00:04s\n","epoch 9  | loss: 0.21596 | val_0_mse: 308.56170654296875|  0:00:05s\n","epoch 10 | loss: 0.19079 | val_0_mse: 328.20379638671875|  0:00:05s\n","epoch 11 | loss: 0.17813 | val_0_mse: 205.4661865234375|  0:00:06s\n","epoch 12 | loss: 0.17661 | val_0_mse: 122.05911254882812|  0:00:07s\n","epoch 13 | loss: 0.18433 | val_0_mse: 168.91404724121094|  0:00:07s\n","epoch 14 | loss: 0.16854 | val_0_mse: 177.7586212158203|  0:00:08s\n","epoch 15 | loss: 0.15829 | val_0_mse: 69.43280792236328|  0:00:08s\n","epoch 16 | loss: 0.14578 | val_0_mse: 108.84880065917969|  0:00:09s\n","epoch 17 | loss: 0.19129 | val_0_mse: 75.9902572631836|  0:00:09s\n","epoch 18 | loss: 0.17722 | val_0_mse: 72.9400634765625|  0:00:10s\n","epoch 19 | loss: 0.17264 | val_0_mse: 61.50397872924805|  0:00:10s\n","epoch 20 | loss: 0.15474 | val_0_mse: 42.97663879394531|  0:00:11s\n","epoch 21 | loss: 0.15296 | val_0_mse: 34.83435821533203|  0:00:11s\n","epoch 22 | loss: 0.13972 | val_0_mse: 23.898269653320312|  0:00:12s\n","epoch 23 | loss: 0.14276 | val_0_mse: 21.587940216064453|  0:00:12s\n","epoch 24 | loss: 0.13734 | val_0_mse: 7.454500198364258|  0:00:13s\n","epoch 25 | loss: 0.13554 | val_0_mse: 2.503230094909668|  0:00:13s\n","epoch 26 | loss: 0.13478 | val_0_mse: 3.2387399673461914|  0:00:14s\n","epoch 27 | loss: 0.1355  | val_0_mse: 2.8596301078796387|  0:00:14s\n","epoch 28 | loss: 0.13048 | val_0_mse: 1.673009991645813|  0:00:15s\n","epoch 29 | loss: 0.13728 | val_0_mse: 2.397200107574463|  0:00:16s\n","epoch 30 | loss: 0.12259 | val_0_mse: 0.8370699882507324|  0:00:16s\n","epoch 31 | loss: 0.12248 | val_0_mse: 0.524940013885498|  0:00:17s\n","epoch 32 | loss: 0.11487 | val_0_mse: 0.6354699730873108|  0:00:17s\n","epoch 33 | loss: 0.12433 | val_0_mse: 0.374099999666214|  0:00:18s\n","epoch 34 | loss: 0.12733 | val_0_mse: 0.36847999691963196|  0:00:18s\n","epoch 35 | loss: 0.12618 | val_0_mse: 0.7307400107383728|  0:00:19s\n","epoch 36 | loss: 0.13839 | val_0_mse: 0.28534001111984253|  0:00:19s\n","epoch 37 | loss: 0.12206 | val_0_mse: 0.3209500014781952|  0:00:20s\n","epoch 38 | loss: 0.12135 | val_0_mse: 0.2956700026988983|  0:00:20s\n","epoch 39 | loss: 0.11885 | val_0_mse: 0.3127500116825104|  0:00:21s\n","epoch 40 | loss: 0.13222 | val_0_mse: 0.27674999833106995|  0:00:21s\n","epoch 41 | loss: 0.13889 | val_0_mse: 0.22682000696659088|  0:00:22s\n","epoch 42 | loss: 0.14712 | val_0_mse: 0.33445000648498535|  0:00:22s\n","epoch 43 | loss: 0.13887 | val_0_mse: 0.20214000344276428|  0:00:23s\n","epoch 44 | loss: 0.13501 | val_0_mse: 0.2614000141620636|  0:00:24s\n","epoch 45 | loss: 0.12939 | val_0_mse: 0.2620899975299835|  0:00:24s\n","epoch 46 | loss: 0.12624 | val_0_mse: 0.23968000710010529|  0:00:25s\n","epoch 47 | loss: 0.12298 | val_0_mse: 0.20214000344276428|  0:00:25s\n","epoch 48 | loss: 0.12235 | val_0_mse: 0.2592700123786926|  0:00:26s\n","epoch 49 | loss: 0.12643 | val_0_mse: 0.16585999727249146|  0:00:26s\n","epoch 50 | loss: 0.1005  | val_0_mse: 0.1729699969291687|  0:00:27s\n","epoch 51 | loss: 0.10106 | val_0_mse: 0.17556999623775482|  0:00:27s\n","epoch 52 | loss: 0.11427 | val_0_mse: 0.13420000672340393|  0:00:28s\n","epoch 53 | loss: 0.11094 | val_0_mse: 0.1563500016927719|  0:00:28s\n","epoch 54 | loss: 0.10573 | val_0_mse: 0.13819999992847443|  0:00:29s\n","epoch 55 | loss: 0.09713 | val_0_mse: 0.16121000051498413|  0:00:29s\n","epoch 56 | loss: 0.10225 | val_0_mse: 0.1500999927520752|  0:00:30s\n","epoch 57 | loss: 0.10134 | val_0_mse: 0.13428999483585358|  0:00:31s\n","epoch 58 | loss: 0.10927 | val_0_mse: 0.14483000338077545|  0:00:31s\n","epoch 59 | loss: 0.1037  | val_0_mse: 0.15351000428199768|  0:00:32s\n","epoch 60 | loss: 0.10516 | val_0_mse: 0.1179800033569336|  0:00:32s\n","epoch 61 | loss: 0.09406 | val_0_mse: 0.1035899966955185|  0:00:33s\n","epoch 62 | loss: 0.11037 | val_0_mse: 0.16259999573230743|  0:00:33s\n","epoch 63 | loss: 0.12465 | val_0_mse: 0.1076899990439415|  0:00:34s\n","epoch 64 | loss: 0.12022 | val_0_mse: 0.15650999546051025|  0:00:34s\n","epoch 65 | loss: 0.10281 | val_0_mse: 0.09528999775648117|  0:00:35s\n","epoch 66 | loss: 0.09102 | val_0_mse: 0.0965299978852272|  0:00:35s\n","epoch 67 | loss: 0.09813 | val_0_mse: 0.09079000353813171|  0:00:36s\n","epoch 68 | loss: 0.10655 | val_0_mse: 0.09478999674320221|  0:00:36s\n","epoch 69 | loss: 0.08871 | val_0_mse: 0.10642000287771225|  0:00:37s\n","epoch 70 | loss: 0.08854 | val_0_mse: 0.09459000080823898|  0:00:37s\n","epoch 71 | loss: 0.08708 | val_0_mse: 0.09294000267982483|  0:00:38s\n","epoch 72 | loss: 0.08604 | val_0_mse: 0.10158000141382217|  0:00:38s\n","epoch 73 | loss: 0.08879 | val_0_mse: 0.09155000001192093|  0:00:39s\n","epoch 74 | loss: 0.08971 | val_0_mse: 0.08889000117778778|  0:00:40s\n","epoch 75 | loss: 0.09031 | val_0_mse: 0.09600000083446503|  0:00:40s\n","epoch 76 | loss: 0.08839 | val_0_mse: 0.10181999951601028|  0:00:41s\n","epoch 77 | loss: 0.11935 | val_0_mse: 0.11496999859809875|  0:00:41s\n","epoch 78 | loss: 0.13156 | val_0_mse: 0.10304000228643417|  0:00:42s\n","epoch 79 | loss: 0.10667 | val_0_mse: 0.11044000089168549|  0:00:42s\n","epoch 80 | loss: 0.09645 | val_0_mse: 0.08766999840736389|  0:00:43s\n","epoch 81 | loss: 0.09107 | val_0_mse: 0.09410999715328217|  0:00:43s\n","epoch 82 | loss: 0.09306 | val_0_mse: 0.09391999989748001|  0:00:44s\n","epoch 83 | loss: 0.08708 | val_0_mse: 0.08914999663829803|  0:00:44s\n","epoch 84 | loss: 0.08644 | val_0_mse: 0.09464000165462494|  0:00:45s\n","epoch 85 | loss: 0.09004 | val_0_mse: 0.10768000036478043|  0:00:45s\n","epoch 86 | loss: 0.08632 | val_0_mse: 0.10767000168561935|  0:00:46s\n","epoch 87 | loss: 0.08597 | val_0_mse: 0.1014299988746643|  0:00:46s\n","epoch 88 | loss: 0.09636 | val_0_mse: 0.12080000340938568|  0:00:47s\n","epoch 89 | loss: 0.08659 | val_0_mse: 0.10473000258207321|  0:00:47s\n","epoch 90 | loss: 0.08298 | val_0_mse: 0.10892000049352646|  0:00:48s\n","\n","Early stopping occurred at epoch 90 with best_epoch = 80 and best_val_0_mse = 0.08766999840736389\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 11:51:00,021] Trial 36 finished with value: 0.08766869455575943 and parameters: {'n_d': 23, 'n_steps': 3, 'gamma': 1.347490397439351, 'n_independent': 1, 'n_shared': 4, 'momentum': 0.30374730144910744}. Best is trial 31 with value: 0.07662469148635864.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 60.87863| val_0_mse: 19006.525390625|  0:00:00s\n","epoch 1  | loss: 3.09966 | val_0_mse: 3020.8662109375|  0:00:01s\n","epoch 2  | loss: 0.91965 | val_0_mse: 3413.865966796875|  0:00:02s\n","epoch 3  | loss: 0.58897 | val_0_mse: 3095.321533203125|  0:00:03s\n","epoch 4  | loss: 0.42748 | val_0_mse: 2045.3399658203125|  0:00:03s\n","epoch 5  | loss: 0.32672 | val_0_mse: 767.0359497070312|  0:00:04s\n","epoch 6  | loss: 0.27911 | val_0_mse: 398.1968688964844|  0:00:05s\n","epoch 7  | loss: 0.25732 | val_0_mse: 298.49932861328125|  0:00:06s\n","epoch 8  | loss: 0.24    | val_0_mse: 124.18309783935547|  0:00:07s\n","epoch 9  | loss: 0.27206 | val_0_mse: 136.4027557373047|  0:00:08s\n","epoch 10 | loss: 0.21487 | val_0_mse: 86.46439361572266|  0:00:08s\n","epoch 11 | loss: 0.17921 | val_0_mse: 44.719581604003906|  0:00:09s\n","epoch 12 | loss: 0.20362 | val_0_mse: 44.00352096557617|  0:00:10s\n","epoch 13 | loss: 0.27613 | val_0_mse: 15.893010139465332|  0:00:11s\n","epoch 14 | loss: 0.28777 | val_0_mse: 10.932430267333984|  0:00:12s\n","epoch 15 | loss: 0.1818  | val_0_mse: 5.2548298835754395|  0:00:12s\n","epoch 16 | loss: 0.13833 | val_0_mse: 2.5617098808288574|  0:00:13s\n","epoch 17 | loss: 0.16889 | val_0_mse: 1.2199300527572632|  0:00:14s\n","epoch 18 | loss: 0.15785 | val_0_mse: 1.9891400337219238|  0:00:15s\n","epoch 19 | loss: 0.18757 | val_0_mse: 1.9033299684524536|  0:00:16s\n","epoch 20 | loss: 0.15681 | val_0_mse: 1.9027600288391113|  0:00:17s\n","epoch 21 | loss: 0.14455 | val_0_mse: 1.7490500211715698|  0:00:17s\n","epoch 22 | loss: 0.15078 | val_0_mse: 1.7126100063323975|  0:00:18s\n","epoch 23 | loss: 0.15107 | val_0_mse: 0.8611999750137329|  0:00:19s\n","epoch 24 | loss: 0.16045 | val_0_mse: 0.7290800213813782|  0:00:20s\n","epoch 25 | loss: 0.15477 | val_0_mse: 0.8699899911880493|  0:00:21s\n","epoch 26 | loss: 0.13561 | val_0_mse: 0.5930600166320801|  0:00:21s\n","epoch 27 | loss: 0.14191 | val_0_mse: 0.703279972076416|  0:00:22s\n","epoch 28 | loss: 0.14188 | val_0_mse: 0.5298299789428711|  0:00:23s\n","epoch 29 | loss: 0.13632 | val_0_mse: 0.629830002784729|  0:00:24s\n","epoch 30 | loss: 0.13611 | val_0_mse: 0.4398300051689148|  0:00:25s\n","epoch 31 | loss: 0.13965 | val_0_mse: 0.6949499845504761|  0:00:26s\n","epoch 32 | loss: 0.1311  | val_0_mse: 0.8067299723625183|  0:00:26s\n","epoch 33 | loss: 0.11234 | val_0_mse: 1.1356600522994995|  0:00:27s\n","epoch 34 | loss: 0.11949 | val_0_mse: 0.45879998803138733|  0:00:28s\n","epoch 35 | loss: 0.18904 | val_0_mse: 0.9139000177383423|  0:00:29s\n","epoch 36 | loss: 0.17282 | val_0_mse: 0.4206700026988983|  0:00:30s\n","epoch 37 | loss: 0.16346 | val_0_mse: 0.7911800146102905|  0:00:30s\n","epoch 38 | loss: 0.15322 | val_0_mse: 0.32280001044273376|  0:00:31s\n","epoch 39 | loss: 0.14451 | val_0_mse: 0.6224799752235413|  0:00:32s\n","epoch 40 | loss: 0.14593 | val_0_mse: 0.25598999857902527|  0:00:33s\n","epoch 41 | loss: 0.14149 | val_0_mse: 0.5007699728012085|  0:00:34s\n","epoch 42 | loss: 0.13725 | val_0_mse: 0.2478400021791458|  0:00:34s\n","epoch 43 | loss: 0.13056 | val_0_mse: 0.4944100081920624|  0:00:35s\n","epoch 44 | loss: 0.12839 | val_0_mse: 0.26857998967170715|  0:00:36s\n","epoch 45 | loss: 0.11205 | val_0_mse: 0.24327999353408813|  0:00:37s\n","epoch 46 | loss: 0.11249 | val_0_mse: 0.26464998722076416|  0:00:38s\n","epoch 47 | loss: 0.12725 | val_0_mse: 0.3248400092124939|  0:00:38s\n","epoch 48 | loss: 0.11851 | val_0_mse: 0.22470000386238098|  0:00:39s\n","epoch 49 | loss: 0.12113 | val_0_mse: 0.27417001128196716|  0:00:40s\n","epoch 50 | loss: 0.16472 | val_0_mse: 0.20066000521183014|  0:00:41s\n","epoch 51 | loss: 0.12166 | val_0_mse: 0.27608999609947205|  0:00:42s\n","epoch 52 | loss: 0.11717 | val_0_mse: 2.183540105819702|  0:00:42s\n","epoch 53 | loss: 0.16972 | val_0_mse: 0.17095999419689178|  0:00:43s\n","epoch 54 | loss: 0.17338 | val_0_mse: 0.33629000186920166|  0:00:44s\n","epoch 55 | loss: 0.12057 | val_0_mse: 0.20148000121116638|  0:00:45s\n","epoch 56 | loss: 0.11626 | val_0_mse: 0.13544000685214996|  0:00:46s\n","epoch 57 | loss: 0.10722 | val_0_mse: 0.19296999275684357|  0:00:47s\n","epoch 58 | loss: 0.11808 | val_0_mse: 0.16395999491214752|  0:00:47s\n","epoch 59 | loss: 0.14625 | val_0_mse: 0.11554999649524689|  0:00:48s\n","epoch 60 | loss: 0.11242 | val_0_mse: 0.13971999287605286|  0:00:49s\n","epoch 61 | loss: 0.09889 | val_0_mse: 0.1169700026512146|  0:00:50s\n","epoch 62 | loss: 0.12639 | val_0_mse: 0.24639999866485596|  0:00:51s\n","epoch 63 | loss: 0.13944 | val_0_mse: 0.10899999737739563|  0:00:51s\n","epoch 64 | loss: 0.09494 | val_0_mse: 0.23255999386310577|  0:00:52s\n","epoch 65 | loss: 0.12846 | val_0_mse: 0.16933000087738037|  0:00:53s\n","epoch 66 | loss: 0.12452 | val_0_mse: 0.288349986076355|  0:00:54s\n","epoch 67 | loss: 0.12463 | val_0_mse: 0.10843999683856964|  0:00:55s\n","epoch 68 | loss: 0.1311  | val_0_mse: 0.1898300051689148|  0:00:56s\n","epoch 69 | loss: 0.12687 | val_0_mse: 0.10847000032663345|  0:00:56s\n","epoch 70 | loss: 0.12677 | val_0_mse: 0.10503999888896942|  0:00:57s\n","epoch 71 | loss: 0.11721 | val_0_mse: 0.09282000362873077|  0:00:58s\n","epoch 72 | loss: 0.12678 | val_0_mse: 0.09392999857664108|  0:00:59s\n","epoch 73 | loss: 0.13504 | val_0_mse: 0.18147000670433044|  0:01:00s\n","epoch 74 | loss: 0.1225  | val_0_mse: 0.12276999652385712|  0:01:00s\n","epoch 75 | loss: 0.11539 | val_0_mse: 0.1529099941253662|  0:01:01s\n","epoch 76 | loss: 0.11805 | val_0_mse: 0.13845999538898468|  0:01:02s\n","epoch 77 | loss: 0.11674 | val_0_mse: 0.1315300017595291|  0:01:03s\n","epoch 78 | loss: 0.11766 | val_0_mse: 0.11818999797105789|  0:01:04s\n","epoch 79 | loss: 0.11016 | val_0_mse: 0.144569993019104|  0:01:04s\n","epoch 80 | loss: 0.11222 | val_0_mse: 0.12512999773025513|  0:01:05s\n","epoch 81 | loss: 0.11141 | val_0_mse: 0.12830999493598938|  0:01:06s\n","\n","Early stopping occurred at epoch 81 with best_epoch = 71 and best_val_0_mse = 0.09282000362873077\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 11:52:06,951] Trial 37 finished with value: 0.09282035380601883 and parameters: {'n_d': 37, 'n_steps': 4, 'gamma': 1.1972682392110368, 'n_independent': 2, 'n_shared': 5, 'momentum': 0.1985669651887063}. Best is trial 31 with value: 0.07662469148635864.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 41.38731| val_0_mse: 291267.9375|  0:00:00s\n","epoch 1  | loss: 1.68244 | val_0_mse: 3976.47900390625|  0:00:01s\n","epoch 2  | loss: 0.65361 | val_0_mse: 673.0339965820312|  0:00:02s\n","epoch 3  | loss: 0.45398 | val_0_mse: 345.7892150878906|  0:00:03s\n","epoch 4  | loss: 0.32116 | val_0_mse: 1476.467529296875|  0:00:04s\n","epoch 5  | loss: 0.27642 | val_0_mse: 1220.420166015625|  0:00:05s\n","epoch 6  | loss: 0.24877 | val_0_mse: 588.4354858398438|  0:00:06s\n","epoch 7  | loss: 0.26647 | val_0_mse: 255.3220672607422|  0:00:06s\n","epoch 8  | loss: 0.34385 | val_0_mse: 538.6484985351562|  0:00:07s\n","epoch 9  | loss: 0.24037 | val_0_mse: 559.3861694335938|  0:00:08s\n","epoch 10 | loss: 0.21933 | val_0_mse: 316.8702392578125|  0:00:09s\n","epoch 11 | loss: 0.19173 | val_0_mse: 91.00321197509766|  0:00:10s\n","epoch 12 | loss: 0.17074 | val_0_mse: 26.792089462280273|  0:00:11s\n","epoch 13 | loss: 0.15034 | val_0_mse: 56.003421783447266|  0:00:12s\n","epoch 14 | loss: 0.17132 | val_0_mse: 60.10057830810547|  0:00:13s\n","epoch 15 | loss: 0.17077 | val_0_mse: 11.347869873046875|  0:00:13s\n","epoch 16 | loss: 0.20089 | val_0_mse: 24.600059509277344|  0:00:14s\n","epoch 17 | loss: 0.22893 | val_0_mse: 10.381810188293457|  0:00:15s\n","epoch 18 | loss: 0.26926 | val_0_mse: 8.335740089416504|  0:00:16s\n","epoch 19 | loss: 0.3118  | val_0_mse: 5.103429794311523|  0:00:17s\n","epoch 20 | loss: 0.27637 | val_0_mse: 1.5427199602127075|  0:00:18s\n","epoch 21 | loss: 0.18868 | val_0_mse: 2.426110029220581|  0:00:19s\n","epoch 22 | loss: 0.18785 | val_0_mse: 7.326670169830322|  0:00:20s\n","epoch 23 | loss: 0.16436 | val_0_mse: 2.1619200706481934|  0:00:21s\n","epoch 24 | loss: 0.20203 | val_0_mse: 1.0836800336837769|  0:00:21s\n","epoch 25 | loss: 0.16282 | val_0_mse: 2.522700071334839|  0:00:22s\n","epoch 26 | loss: 0.25191 | val_0_mse: 2.149319887161255|  0:00:23s\n","epoch 27 | loss: 0.21548 | val_0_mse: 0.9134399890899658|  0:00:24s\n","epoch 28 | loss: 0.20521 | val_0_mse: 0.5951799750328064|  0:00:25s\n","epoch 29 | loss: 0.15087 | val_0_mse: 0.3961600065231323|  0:00:26s\n","epoch 30 | loss: 0.14255 | val_0_mse: 0.7195299863815308|  0:00:27s\n","epoch 31 | loss: 0.12747 | val_0_mse: 0.8960099816322327|  0:00:28s\n","epoch 32 | loss: 0.1357  | val_0_mse: 0.707859992980957|  0:00:28s\n","epoch 33 | loss: 0.12495 | val_0_mse: 0.7581599950790405|  0:00:29s\n","epoch 34 | loss: 0.11973 | val_0_mse: 0.5640299916267395|  0:00:30s\n","epoch 35 | loss: 0.11475 | val_0_mse: 0.595579981803894|  0:00:31s\n","epoch 36 | loss: 0.13405 | val_0_mse: 0.6650800108909607|  0:00:32s\n","epoch 37 | loss: 0.17209 | val_0_mse: 0.3994399905204773|  0:00:33s\n","epoch 38 | loss: 0.16722 | val_0_mse: 0.46219998598098755|  0:00:34s\n","epoch 39 | loss: 0.13596 | val_0_mse: 0.37893998622894287|  0:00:34s\n","epoch 40 | loss: 0.12261 | val_0_mse: 0.24602000415325165|  0:00:35s\n","epoch 41 | loss: 0.12357 | val_0_mse: 0.22739000618457794|  0:00:36s\n","epoch 42 | loss: 0.11994 | val_0_mse: 0.31000998616218567|  0:00:37s\n","epoch 43 | loss: 0.1309  | val_0_mse: 0.17385999858379364|  0:00:38s\n","epoch 44 | loss: 0.1509  | val_0_mse: 0.445279985666275|  0:00:39s\n","epoch 45 | loss: 0.15262 | val_0_mse: 0.1688700020313263|  0:00:40s\n","epoch 46 | loss: 0.11721 | val_0_mse: 0.15967999398708344|  0:00:41s\n","epoch 47 | loss: 0.11273 | val_0_mse: 0.21010999381542206|  0:00:42s\n","epoch 48 | loss: 0.10286 | val_0_mse: 0.22288000583648682|  0:00:43s\n","epoch 49 | loss: 0.11535 | val_0_mse: 0.2516399919986725|  0:00:43s\n","epoch 50 | loss: 0.13551 | val_0_mse: 0.15528999269008636|  0:00:44s\n","epoch 51 | loss: 0.1277  | val_0_mse: 0.12139999866485596|  0:00:45s\n","epoch 52 | loss: 0.10749 | val_0_mse: 0.11582999676465988|  0:00:46s\n","epoch 53 | loss: 0.10265 | val_0_mse: 0.1643500030040741|  0:00:47s\n","epoch 54 | loss: 0.11386 | val_0_mse: 0.1356000006198883|  0:00:48s\n","epoch 55 | loss: 0.12758 | val_0_mse: 0.1969500035047531|  0:00:49s\n","epoch 56 | loss: 0.11952 | val_0_mse: 0.15567000210285187|  0:00:50s\n","epoch 57 | loss: 0.11831 | val_0_mse: 0.1155100017786026|  0:00:51s\n","epoch 58 | loss: 0.11945 | val_0_mse: 0.18533000349998474|  0:00:52s\n","epoch 59 | loss: 0.17361 | val_0_mse: 0.22614000737667084|  0:00:53s\n","epoch 60 | loss: 0.18227 | val_0_mse: 0.15023000538349152|  0:00:54s\n","epoch 61 | loss: 0.12127 | val_0_mse: 0.1271899938583374|  0:00:55s\n","epoch 62 | loss: 0.12295 | val_0_mse: 0.1336199939250946|  0:00:56s\n","epoch 63 | loss: 0.12249 | val_0_mse: 0.20013000071048737|  0:00:57s\n","epoch 64 | loss: 0.14301 | val_0_mse: 0.12443000078201294|  0:00:58s\n","epoch 65 | loss: 0.12717 | val_0_mse: 0.13619999587535858|  0:00:59s\n","epoch 66 | loss: 0.11622 | val_0_mse: 0.10524000227451324|  0:01:00s\n","epoch 67 | loss: 0.10509 | val_0_mse: 0.10904999822378159|  0:01:01s\n","epoch 68 | loss: 0.11714 | val_0_mse: 0.11886999756097794|  0:01:02s\n","epoch 69 | loss: 0.14365 | val_0_mse: 0.11430999636650085|  0:01:03s\n","epoch 70 | loss: 0.13721 | val_0_mse: 0.14554999768733978|  0:01:04s\n","epoch 71 | loss: 0.12717 | val_0_mse: 0.13798999786376953|  0:01:05s\n","epoch 72 | loss: 0.15863 | val_0_mse: 0.16475999355316162|  0:01:06s\n","epoch 73 | loss: 0.15405 | val_0_mse: 0.1391800045967102|  0:01:07s\n","epoch 74 | loss: 0.14261 | val_0_mse: 0.13011999428272247|  0:01:08s\n","epoch 75 | loss: 0.13473 | val_0_mse: 0.11811000108718872|  0:01:09s\n","epoch 76 | loss: 0.13701 | val_0_mse: 0.13955000042915344|  0:01:10s\n","\n","Early stopping occurred at epoch 76 with best_epoch = 66 and best_val_0_mse = 0.10524000227451324\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 11:53:17,889] Trial 38 finished with value: 0.1052381843328476 and parameters: {'n_d': 42, 'n_steps': 6, 'gamma': 1.1095101216785455, 'n_independent': 1, 'n_shared': 4, 'momentum': 0.06612465114072946}. Best is trial 31 with value: 0.07662469148635864.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 29.86915| val_0_mse: 21548.689453125|  0:00:00s\n","epoch 1  | loss: 1.74761 | val_0_mse: 7772.43115234375|  0:00:01s\n","epoch 2  | loss: 0.75693 | val_0_mse: 1502.94580078125|  0:00:02s\n","epoch 3  | loss: 0.55055 | val_0_mse: 647.15771484375|  0:00:03s\n","epoch 4  | loss: 0.45496 | val_0_mse: 413.8751525878906|  0:00:04s\n","epoch 5  | loss: 0.49003 | val_0_mse: 351.351806640625|  0:00:05s\n","epoch 6  | loss: 0.29268 | val_0_mse: 128.99502563476562|  0:00:06s\n","epoch 7  | loss: 0.26234 | val_0_mse: 577.4674072265625|  0:00:07s\n","epoch 8  | loss: 0.22089 | val_0_mse: 625.0504760742188|  0:00:08s\n","epoch 9  | loss: 0.20263 | val_0_mse: 139.46841430664062|  0:00:09s\n","epoch 10 | loss: 0.24567 | val_0_mse: 133.550048828125|  0:00:10s\n","epoch 11 | loss: 0.29404 | val_0_mse: 49.697059631347656|  0:00:11s\n","epoch 12 | loss: 0.21527 | val_0_mse: 30.071430206298828|  0:00:12s\n","epoch 13 | loss: 0.17306 | val_0_mse: 14.535989761352539|  0:00:13s\n","epoch 14 | loss: 0.16059 | val_0_mse: 28.750520706176758|  0:00:14s\n","epoch 15 | loss: 0.21275 | val_0_mse: 24.48111915588379|  0:00:15s\n","epoch 16 | loss: 0.18105 | val_0_mse: 17.041540145874023|  0:00:15s\n","epoch 17 | loss: 0.13822 | val_0_mse: 19.42487907409668|  0:00:16s\n","epoch 18 | loss: 0.13709 | val_0_mse: 14.495539665222168|  0:00:17s\n","epoch 19 | loss: 0.17114 | val_0_mse: 7.2182297706604|  0:00:18s\n","epoch 20 | loss: 0.19658 | val_0_mse: 5.010930061340332|  0:00:19s\n","epoch 21 | loss: 0.166   | val_0_mse: 5.236599922180176|  0:00:20s\n","epoch 22 | loss: 0.18488 | val_0_mse: 3.2187299728393555|  0:00:21s\n","epoch 23 | loss: 0.1552  | val_0_mse: 4.358320236206055|  0:00:22s\n","epoch 24 | loss: 0.15856 | val_0_mse: 2.8588500022888184|  0:00:22s\n","epoch 25 | loss: 0.16003 | val_0_mse: 2.950579881668091|  0:00:23s\n","epoch 26 | loss: 0.16035 | val_0_mse: 1.3496999740600586|  0:00:24s\n","epoch 27 | loss: 0.1468  | val_0_mse: 2.022010087966919|  0:00:25s\n","epoch 28 | loss: 0.15542 | val_0_mse: 0.9737899899482727|  0:00:26s\n","epoch 29 | loss: 0.15534 | val_0_mse: 1.5391299724578857|  0:00:27s\n","epoch 30 | loss: 0.14779 | val_0_mse: 0.7369499802589417|  0:00:28s\n","epoch 31 | loss: 0.16168 | val_0_mse: 1.2359999418258667|  0:00:29s\n","epoch 32 | loss: 0.14341 | val_0_mse: 0.6011899709701538|  0:00:29s\n","epoch 33 | loss: 0.14666 | val_0_mse: 1.199180006980896|  0:00:30s\n","epoch 34 | loss: 0.15867 | val_0_mse: 0.6393200159072876|  0:00:31s\n","epoch 35 | loss: 0.1475  | val_0_mse: 0.9514600038528442|  0:00:32s\n","epoch 36 | loss: 0.1432  | val_0_mse: 0.3393400013446808|  0:00:33s\n","epoch 37 | loss: 0.15558 | val_0_mse: 0.6055999994277954|  0:00:34s\n","epoch 38 | loss: 0.14503 | val_0_mse: 0.2515000104904175|  0:00:34s\n","epoch 39 | loss: 0.14275 | val_0_mse: 0.64410001039505|  0:00:35s\n","epoch 40 | loss: 0.15516 | val_0_mse: 0.26263999938964844|  0:00:36s\n","epoch 41 | loss: 0.14239 | val_0_mse: 0.49779999256134033|  0:00:37s\n","epoch 42 | loss: 0.1458  | val_0_mse: 0.19277000427246094|  0:00:38s\n","epoch 43 | loss: 0.13577 | val_0_mse: 0.3716199994087219|  0:00:39s\n","epoch 44 | loss: 0.14303 | val_0_mse: 0.1933699995279312|  0:00:40s\n","epoch 45 | loss: 0.1356  | val_0_mse: 0.4219599962234497|  0:00:41s\n","epoch 46 | loss: 0.14051 | val_0_mse: 0.18306000530719757|  0:00:41s\n","epoch 47 | loss: 0.12919 | val_0_mse: 0.3441999852657318|  0:00:42s\n","epoch 48 | loss: 0.14047 | val_0_mse: 0.13902999460697174|  0:00:43s\n","epoch 49 | loss: 0.13374 | val_0_mse: 0.2854500114917755|  0:00:44s\n","epoch 50 | loss: 0.13668 | val_0_mse: 0.12385000288486481|  0:00:45s\n","epoch 51 | loss: 0.13498 | val_0_mse: 0.23120999336242676|  0:00:46s\n","epoch 52 | loss: 0.14156 | val_0_mse: 0.11705999821424484|  0:00:47s\n","epoch 53 | loss: 0.12822 | val_0_mse: 0.21231000125408173|  0:00:47s\n","epoch 54 | loss: 0.13734 | val_0_mse: 0.1050100028514862|  0:00:48s\n","epoch 55 | loss: 0.1346  | val_0_mse: 0.17980000376701355|  0:00:49s\n","epoch 56 | loss: 0.13467 | val_0_mse: 0.1157900020480156|  0:00:50s\n","epoch 57 | loss: 0.13723 | val_0_mse: 0.18937000632286072|  0:00:51s\n","epoch 58 | loss: 0.13541 | val_0_mse: 0.12055999785661697|  0:00:52s\n","epoch 59 | loss: 0.15245 | val_0_mse: 0.19221000373363495|  0:00:52s\n","epoch 60 | loss: 0.15829 | val_0_mse: 0.11166000366210938|  0:00:53s\n","epoch 61 | loss: 0.15294 | val_0_mse: 0.1818699985742569|  0:00:54s\n","epoch 62 | loss: 0.15253 | val_0_mse: 0.11719000339508057|  0:00:55s\n","epoch 63 | loss: 0.14072 | val_0_mse: 0.15217000246047974|  0:00:56s\n","epoch 64 | loss: 0.13983 | val_0_mse: 0.11003000289201736|  0:00:57s\n","\n","Early stopping occurred at epoch 64 with best_epoch = 54 and best_val_0_mse = 0.1050100028514862\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 11:54:15,618] Trial 39 finished with value: 0.10500957816839218 and parameters: {'n_d': 50, 'n_steps': 5, 'gamma': 1.0396840136305106, 'n_independent': 3, 'n_shared': 3, 'momentum': 0.37842654579475093}. Best is trial 31 with value: 0.07662469148635864.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 101.3177| val_0_mse: 217230.390625|  0:00:00s\n","epoch 1  | loss: 14.83922| val_0_mse: 4727.76806640625|  0:00:01s\n","epoch 2  | loss: 1.63959 | val_0_mse: 14095.8193359375|  0:00:01s\n","epoch 3  | loss: 0.43197 | val_0_mse: 4021.715576171875|  0:00:02s\n","epoch 4  | loss: 0.28798 | val_0_mse: 249.48507690429688|  0:00:02s\n","epoch 5  | loss: 0.22509 | val_0_mse: 642.1851196289062|  0:00:03s\n","epoch 6  | loss: 0.19524 | val_0_mse: 808.6417846679688|  0:00:04s\n","epoch 7  | loss: 0.18294 | val_0_mse: 1691.055419921875|  0:00:04s\n","epoch 8  | loss: 0.17507 | val_0_mse: 1160.2208251953125|  0:00:05s\n","epoch 9  | loss: 0.15536 | val_0_mse: 223.92361450195312|  0:00:05s\n","epoch 10 | loss: 0.14217 | val_0_mse: 116.12518310546875|  0:00:06s\n","epoch 11 | loss: 0.1543  | val_0_mse: 59.833438873291016|  0:00:07s\n","epoch 12 | loss: 0.13532 | val_0_mse: 48.787841796875|  0:00:07s\n","epoch 13 | loss: 0.15229 | val_0_mse: 35.389739990234375|  0:00:08s\n","epoch 14 | loss: 0.12821 | val_0_mse: 72.5921630859375|  0:00:08s\n","epoch 15 | loss: 0.12298 | val_0_mse: 105.09742736816406|  0:00:09s\n","epoch 16 | loss: 0.11671 | val_0_mse: 111.25238800048828|  0:00:10s\n","epoch 17 | loss: 0.11126 | val_0_mse: 49.006080627441406|  0:00:10s\n","epoch 18 | loss: 0.11585 | val_0_mse: 23.119159698486328|  0:00:11s\n","epoch 19 | loss: 0.11223 | val_0_mse: 11.465609550476074|  0:00:11s\n","epoch 20 | loss: 0.1199  | val_0_mse: 17.381059646606445|  0:00:12s\n","epoch 21 | loss: 0.1087  | val_0_mse: 18.903650283813477|  0:00:13s\n","epoch 22 | loss: 0.11112 | val_0_mse: 21.462810516357422|  0:00:13s\n","epoch 23 | loss: 0.10457 | val_0_mse: 15.083490371704102|  0:00:14s\n","epoch 24 | loss: 0.10405 | val_0_mse: 17.700510025024414|  0:00:14s\n","epoch 25 | loss: 0.10402 | val_0_mse: 10.618599891662598|  0:00:15s\n","epoch 26 | loss: 0.1019  | val_0_mse: 13.994059562683105|  0:00:16s\n","epoch 27 | loss: 0.1058  | val_0_mse: 11.995940208435059|  0:00:16s\n","epoch 28 | loss: 0.1106  | val_0_mse: 7.846030235290527|  0:00:17s\n","epoch 29 | loss: 0.13909 | val_0_mse: 6.153590202331543|  0:00:17s\n","epoch 30 | loss: 0.10989 | val_0_mse: 8.280369758605957|  0:00:18s\n","epoch 31 | loss: 0.1046  | val_0_mse: 5.543670177459717|  0:00:19s\n","epoch 32 | loss: 0.10354 | val_0_mse: 5.684659957885742|  0:00:19s\n","epoch 33 | loss: 0.09614 | val_0_mse: 5.170720100402832|  0:00:20s\n","epoch 34 | loss: 0.09702 | val_0_mse: 2.901360034942627|  0:00:20s\n","epoch 35 | loss: 0.09077 | val_0_mse: 3.1892499923706055|  0:00:21s\n","epoch 36 | loss: 0.09188 | val_0_mse: 2.164289951324463|  0:00:21s\n","epoch 37 | loss: 0.091   | val_0_mse: 2.2588601112365723|  0:00:22s\n","epoch 38 | loss: 0.09541 | val_0_mse: 1.5304800271987915|  0:00:23s\n","epoch 39 | loss: 0.09755 | val_0_mse: 1.299649953842163|  0:00:23s\n","epoch 40 | loss: 0.0946  | val_0_mse: 1.1492199897766113|  0:00:24s\n","epoch 41 | loss: 0.0916  | val_0_mse: 1.0463600158691406|  0:00:24s\n","epoch 42 | loss: 0.08728 | val_0_mse: 0.6030799746513367|  0:00:25s\n","epoch 43 | loss: 0.08746 | val_0_mse: 0.6607400178909302|  0:00:26s\n","epoch 44 | loss: 0.0889  | val_0_mse: 0.5016999840736389|  0:00:26s\n","epoch 45 | loss: 0.09139 | val_0_mse: 0.4221799969673157|  0:00:27s\n","epoch 46 | loss: 0.08821 | val_0_mse: 0.46733999252319336|  0:00:27s\n","epoch 47 | loss: 0.08781 | val_0_mse: 0.23544000089168549|  0:00:28s\n","epoch 48 | loss: 0.09497 | val_0_mse: 0.22532999515533447|  0:00:29s\n","epoch 49 | loss: 0.09268 | val_0_mse: 0.3072200119495392|  0:00:29s\n","epoch 50 | loss: 0.08434 | val_0_mse: 0.20962999761104584|  0:00:30s\n","epoch 51 | loss: 0.08529 | val_0_mse: 0.2214599996805191|  0:00:30s\n","epoch 52 | loss: 0.08975 | val_0_mse: 0.23423999547958374|  0:00:31s\n","epoch 53 | loss: 0.08541 | val_0_mse: 0.16220000386238098|  0:00:32s\n","epoch 54 | loss: 0.08617 | val_0_mse: 0.16575999557971954|  0:00:32s\n","epoch 55 | loss: 0.08335 | val_0_mse: 0.16044999659061432|  0:00:33s\n","epoch 56 | loss: 0.08261 | val_0_mse: 0.11987999826669693|  0:00:33s\n","epoch 57 | loss: 0.08657 | val_0_mse: 0.0914900004863739|  0:00:34s\n","epoch 58 | loss: 0.09802 | val_0_mse: 0.18567000329494476|  0:00:35s\n","epoch 59 | loss: 0.09408 | val_0_mse: 0.09895999729633331|  0:00:35s\n","epoch 60 | loss: 0.09091 | val_0_mse: 0.12499000132083893|  0:00:36s\n","epoch 61 | loss: 0.10873 | val_0_mse: 0.15655000507831573|  0:00:36s\n","epoch 62 | loss: 0.10403 | val_0_mse: 0.08622000366449356|  0:00:37s\n","epoch 63 | loss: 0.10704 | val_0_mse: 0.09773000329732895|  0:00:38s\n","epoch 64 | loss: 0.10087 | val_0_mse: 0.12227000296115875|  0:00:38s\n","epoch 65 | loss: 0.09806 | val_0_mse: 0.08861000090837479|  0:00:39s\n","epoch 66 | loss: 0.09447 | val_0_mse: 0.11189000308513641|  0:00:39s\n","epoch 67 | loss: 0.09576 | val_0_mse: 0.09065999835729599|  0:00:40s\n","epoch 68 | loss: 0.09392 | val_0_mse: 0.1175599992275238|  0:00:41s\n","epoch 69 | loss: 0.09531 | val_0_mse: 0.08726999908685684|  0:00:41s\n","epoch 70 | loss: 0.09449 | val_0_mse: 0.09645000100135803|  0:00:42s\n","epoch 71 | loss: 0.09462 | val_0_mse: 0.09799999743700027|  0:00:42s\n","epoch 72 | loss: 0.09545 | val_0_mse: 0.08488000184297562|  0:00:43s\n","epoch 73 | loss: 0.10376 | val_0_mse: 0.11282999813556671|  0:00:44s\n","epoch 74 | loss: 0.11063 | val_0_mse: 0.10819999873638153|  0:00:44s\n","epoch 75 | loss: 0.09914 | val_0_mse: 0.08736000210046768|  0:00:45s\n","epoch 76 | loss: 0.08784 | val_0_mse: 0.09232000261545181|  0:00:45s\n","epoch 77 | loss: 0.08485 | val_0_mse: 0.08585000038146973|  0:00:46s\n","epoch 78 | loss: 0.08514 | val_0_mse: 0.08980999886989594|  0:00:46s\n","epoch 79 | loss: 0.09005 | val_0_mse: 0.08440999686717987|  0:00:47s\n","epoch 80 | loss: 0.08544 | val_0_mse: 0.0879800021648407|  0:00:48s\n","epoch 81 | loss: 0.08222 | val_0_mse: 0.08507999777793884|  0:00:48s\n","epoch 82 | loss: 0.08145 | val_0_mse: 0.0849199965596199|  0:00:49s\n","epoch 83 | loss: 0.07893 | val_0_mse: 0.08202999830245972|  0:00:49s\n","epoch 84 | loss: 0.08753 | val_0_mse: 0.08952999860048294|  0:00:50s\n","epoch 85 | loss: 0.08008 | val_0_mse: 0.08269000053405762|  0:00:50s\n","epoch 86 | loss: 0.08662 | val_0_mse: 0.08410000056028366|  0:00:51s\n","epoch 87 | loss: 0.08577 | val_0_mse: 0.08466999977827072|  0:00:52s\n","epoch 88 | loss: 0.08352 | val_0_mse: 0.09312999993562698|  0:00:52s\n","epoch 89 | loss: 0.09271 | val_0_mse: 0.11176999658346176|  0:00:53s\n","epoch 90 | loss: 0.09754 | val_0_mse: 0.09466999769210815|  0:00:53s\n","epoch 91 | loss: 0.09338 | val_0_mse: 0.09105999767780304|  0:00:54s\n","epoch 92 | loss: 0.08741 | val_0_mse: 0.10007999837398529|  0:00:55s\n","epoch 93 | loss: 0.08757 | val_0_mse: 0.09397999942302704|  0:00:55s\n","\n","Early stopping occurred at epoch 93 with best_epoch = 83 and best_val_0_mse = 0.08202999830245972\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 11:55:11,799] Trial 40 finished with value: 0.08202675729990005 and parameters: {'n_d': 16, 'n_steps': 3, 'gamma': 1.3107513104873327, 'n_independent': 1, 'n_shared': 5, 'momentum': 0.2809752773028023}. Best is trial 31 with value: 0.07662469148635864.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 52.51346| val_0_mse: 77317.0390625|  0:00:00s\n","epoch 1  | loss: 1.71123 | val_0_mse: 15552.42578125|  0:00:01s\n","epoch 2  | loss: 0.58565 | val_0_mse: 2784.434814453125|  0:00:01s\n","epoch 3  | loss: 0.37195 | val_0_mse: 955.5972900390625|  0:00:02s\n","epoch 4  | loss: 0.33448 | val_0_mse: 2240.625732421875|  0:00:03s\n","epoch 5  | loss: 0.29547 | val_0_mse: 851.0657348632812|  0:00:03s\n","epoch 6  | loss: 0.31582 | val_0_mse: 1853.79931640625|  0:00:04s\n","epoch 7  | loss: 0.24414 | val_0_mse: 159.71083068847656|  0:00:05s\n","epoch 8  | loss: 0.20845 | val_0_mse: 162.48974609375|  0:00:05s\n","epoch 9  | loss: 0.188   | val_0_mse: 202.19241333007812|  0:00:06s\n","epoch 10 | loss: 0.15914 | val_0_mse: 748.381591796875|  0:00:07s\n","epoch 11 | loss: 0.16972 | val_0_mse: 142.49124145507812|  0:00:07s\n","epoch 12 | loss: 0.17338 | val_0_mse: 72.54965209960938|  0:00:08s\n","epoch 13 | loss: 0.15811 | val_0_mse: 36.174129486083984|  0:00:09s\n","epoch 14 | loss: 0.16429 | val_0_mse: 47.65293884277344|  0:00:09s\n","epoch 15 | loss: 0.18105 | val_0_mse: 101.64868927001953|  0:00:10s\n","epoch 16 | loss: 0.16878 | val_0_mse: 49.384971618652344|  0:00:11s\n","epoch 17 | loss: 0.13573 | val_0_mse: 19.538009643554688|  0:00:11s\n","epoch 18 | loss: 0.12757 | val_0_mse: 15.242819786071777|  0:00:12s\n","epoch 19 | loss: 0.1243  | val_0_mse: 9.71006965637207|  0:00:13s\n","epoch 20 | loss: 0.12307 | val_0_mse: 8.740030288696289|  0:00:13s\n","epoch 21 | loss: 0.12203 | val_0_mse: 3.430609941482544|  0:00:14s\n","epoch 22 | loss: 0.12184 | val_0_mse: 1.1575499773025513|  0:00:15s\n","epoch 23 | loss: 0.12467 | val_0_mse: 1.2210299968719482|  0:00:15s\n","epoch 24 | loss: 0.11425 | val_0_mse: 1.769569993019104|  0:00:16s\n","epoch 25 | loss: 0.12292 | val_0_mse: 1.2846299409866333|  0:00:17s\n","epoch 26 | loss: 0.26577 | val_0_mse: 2.1575698852539062|  0:00:17s\n","epoch 27 | loss: 0.23452 | val_0_mse: 1.1235699653625488|  0:00:18s\n","epoch 28 | loss: 0.17209 | val_0_mse: 1.3143999576568604|  0:00:19s\n","epoch 29 | loss: 0.1541  | val_0_mse: 0.9902399778366089|  0:00:19s\n","epoch 30 | loss: 0.15089 | val_0_mse: 1.0200400352478027|  0:00:20s\n","epoch 31 | loss: 0.13794 | val_0_mse: 0.5640000104904175|  0:00:21s\n","epoch 32 | loss: 0.1543  | val_0_mse: 0.7498000264167786|  0:00:21s\n","epoch 33 | loss: 0.26637 | val_0_mse: 0.8362299799919128|  0:00:22s\n","epoch 34 | loss: 0.17945 | val_0_mse: 0.4841899871826172|  0:00:23s\n","epoch 35 | loss: 0.13205 | val_0_mse: 0.5659800171852112|  0:00:23s\n","epoch 36 | loss: 0.12526 | val_0_mse: 0.7440699934959412|  0:00:24s\n","epoch 37 | loss: 0.14371 | val_0_mse: 0.6291499733924866|  0:00:25s\n","epoch 38 | loss: 0.11267 | val_0_mse: 0.5411099791526794|  0:00:25s\n","epoch 39 | loss: 0.13555 | val_0_mse: 0.2695299983024597|  0:00:26s\n","epoch 40 | loss: 0.134   | val_0_mse: 0.4719400107860565|  0:00:27s\n","epoch 41 | loss: 0.12019 | val_0_mse: 0.20859000086784363|  0:00:27s\n","epoch 42 | loss: 0.12722 | val_0_mse: 0.30831000208854675|  0:00:28s\n","epoch 43 | loss: 0.12203 | val_0_mse: 0.17896999418735504|  0:00:29s\n","epoch 44 | loss: 0.13365 | val_0_mse: 0.3196899890899658|  0:00:29s\n","epoch 45 | loss: 0.13082 | val_0_mse: 0.175369992852211|  0:00:30s\n","epoch 46 | loss: 0.1233  | val_0_mse: 0.24919000267982483|  0:00:31s\n","epoch 47 | loss: 0.12775 | val_0_mse: 0.15331999957561493|  0:00:31s\n","epoch 48 | loss: 0.12346 | val_0_mse: 0.2686600089073181|  0:00:32s\n","epoch 49 | loss: 0.12437 | val_0_mse: 0.1387699991464615|  0:00:33s\n","epoch 50 | loss: 0.11827 | val_0_mse: 0.24523000419139862|  0:00:33s\n","epoch 51 | loss: 0.11829 | val_0_mse: 0.1266299933195114|  0:00:34s\n","epoch 52 | loss: 0.11957 | val_0_mse: 0.20695999264717102|  0:00:35s\n","epoch 53 | loss: 0.11363 | val_0_mse: 0.11095000058412552|  0:00:35s\n","epoch 54 | loss: 0.11187 | val_0_mse: 0.1861100047826767|  0:00:36s\n","epoch 55 | loss: 0.11398 | val_0_mse: 0.09963999688625336|  0:00:37s\n","epoch 56 | loss: 0.11402 | val_0_mse: 0.19880999624729156|  0:00:37s\n","epoch 57 | loss: 0.11613 | val_0_mse: 0.09702999889850616|  0:00:38s\n","epoch 58 | loss: 0.11199 | val_0_mse: 0.1575700044631958|  0:00:39s\n","epoch 59 | loss: 0.11937 | val_0_mse: 0.10457000136375427|  0:00:39s\n","epoch 60 | loss: 0.1172  | val_0_mse: 0.1611499935388565|  0:00:40s\n","epoch 61 | loss: 0.11872 | val_0_mse: 0.10034999996423721|  0:00:40s\n","epoch 62 | loss: 0.11596 | val_0_mse: 0.14651000499725342|  0:00:41s\n","epoch 63 | loss: 0.1179  | val_0_mse: 0.09279000014066696|  0:00:42s\n","epoch 64 | loss: 0.11123 | val_0_mse: 0.13297000527381897|  0:00:42s\n","epoch 65 | loss: 0.11676 | val_0_mse: 0.13217000663280487|  0:00:43s\n","epoch 66 | loss: 0.14107 | val_0_mse: 0.176829993724823|  0:00:44s\n","epoch 67 | loss: 0.11812 | val_0_mse: 0.12432000041007996|  0:00:44s\n","epoch 68 | loss: 0.12411 | val_0_mse: 0.15378999710083008|  0:00:45s\n","epoch 69 | loss: 0.11914 | val_0_mse: 0.13116000592708588|  0:00:46s\n","epoch 70 | loss: 0.11656 | val_0_mse: 0.11238999664783478|  0:00:47s\n","epoch 71 | loss: 0.09494 | val_0_mse: 0.12935000658035278|  0:00:47s\n","epoch 72 | loss: 0.10446 | val_0_mse: 0.12273000180721283|  0:00:48s\n","epoch 73 | loss: 0.1136  | val_0_mse: 0.10723000019788742|  0:00:49s\n","\n","Early stopping occurred at epoch 73 with best_epoch = 63 and best_val_0_mse = 0.09279000014066696\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 11:56:01,314] Trial 41 finished with value: 0.09278571605682373 and parameters: {'n_d': 45, 'n_steps': 3, 'gamma': 1.2207462742085582, 'n_independent': 2, 'n_shared': 5, 'momentum': 0.22000806495332112}. Best is trial 31 with value: 0.07662469148635864.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 40.1567 | val_0_mse: 43948.86328125|  0:00:00s\n","epoch 1  | loss: 2.39404 | val_0_mse: 87226.2890625|  0:00:01s\n","epoch 2  | loss: 0.99582 | val_0_mse: 18277.669921875|  0:00:02s\n","epoch 3  | loss: 0.56069 | val_0_mse: 3293.04638671875|  0:00:03s\n","epoch 4  | loss: 0.54452 | val_0_mse: 911.89111328125|  0:00:04s\n","epoch 5  | loss: 0.34379 | val_0_mse: 482.57940673828125|  0:00:05s\n","epoch 6  | loss: 0.30606 | val_0_mse: 269.1136169433594|  0:00:06s\n","epoch 7  | loss: 0.3174  | val_0_mse: 36.097900390625|  0:00:07s\n","epoch 8  | loss: 0.28268 | val_0_mse: 21.582109451293945|  0:00:08s\n","epoch 9  | loss: 0.25676 | val_0_mse: 21.356069564819336|  0:00:08s\n","epoch 10 | loss: 0.2343  | val_0_mse: 11.686420440673828|  0:00:09s\n","epoch 11 | loss: 0.23951 | val_0_mse: 19.03510093688965|  0:00:10s\n","epoch 12 | loss: 0.20743 | val_0_mse: 15.590800285339355|  0:00:11s\n","epoch 13 | loss: 0.20751 | val_0_mse: 22.289339065551758|  0:00:12s\n","epoch 14 | loss: 0.19502 | val_0_mse: 14.542030334472656|  0:00:13s\n","epoch 15 | loss: 0.20103 | val_0_mse: 15.894269943237305|  0:00:14s\n","epoch 16 | loss: 0.1849  | val_0_mse: 10.975859642028809|  0:00:15s\n","epoch 17 | loss: 0.18422 | val_0_mse: 15.914839744567871|  0:00:16s\n","epoch 18 | loss: 0.20627 | val_0_mse: 7.5642900466918945|  0:00:17s\n","epoch 19 | loss: 0.2399  | val_0_mse: 7.541880130767822|  0:00:18s\n","epoch 20 | loss: 0.26232 | val_0_mse: 6.666530132293701|  0:00:19s\n","epoch 21 | loss: 0.18262 | val_0_mse: 3.173949956893921|  0:00:19s\n","epoch 22 | loss: 0.14982 | val_0_mse: 2.8783600330352783|  0:00:20s\n","epoch 23 | loss: 0.20991 | val_0_mse: 1.6750799417495728|  0:00:21s\n","epoch 24 | loss: 0.23996 | val_0_mse: 1.7142900228500366|  0:00:22s\n","epoch 25 | loss: 0.21012 | val_0_mse: 1.1240099668502808|  0:00:23s\n","epoch 26 | loss: 0.18014 | val_0_mse: 1.2660599946975708|  0:00:24s\n","epoch 27 | loss: 0.17081 | val_0_mse: 0.8287100195884705|  0:00:25s\n","epoch 28 | loss: 0.16475 | val_0_mse: 1.6353199481964111|  0:00:26s\n","epoch 29 | loss: 0.15744 | val_0_mse: 0.5989999771118164|  0:00:27s\n","epoch 30 | loss: 0.15586 | val_0_mse: 1.1145299673080444|  0:00:28s\n","epoch 31 | loss: 0.16025 | val_0_mse: 0.304610013961792|  0:00:29s\n","epoch 32 | loss: 0.14962 | val_0_mse: 0.6879199743270874|  0:00:30s\n","epoch 33 | loss: 0.15837 | val_0_mse: 0.3232499957084656|  0:00:30s\n","epoch 34 | loss: 0.16113 | val_0_mse: 0.8920400142669678|  0:00:31s\n","epoch 35 | loss: 0.16221 | val_0_mse: 0.29892000555992126|  0:00:32s\n","epoch 36 | loss: 0.15102 | val_0_mse: 0.7236899733543396|  0:00:33s\n","epoch 37 | loss: 0.15211 | val_0_mse: 0.3107599914073944|  0:00:34s\n","epoch 38 | loss: 0.15037 | val_0_mse: 0.7501999735832214|  0:00:35s\n","epoch 39 | loss: 0.14886 | val_0_mse: 0.2463800013065338|  0:00:36s\n","epoch 40 | loss: 0.14371 | val_0_mse: 0.6342899799346924|  0:00:37s\n","epoch 41 | loss: 0.14844 | val_0_mse: 0.22833000123500824|  0:00:38s\n","epoch 42 | loss: 0.14167 | val_0_mse: 0.5465700030326843|  0:00:39s\n","epoch 43 | loss: 0.13686 | val_0_mse: 0.19890999794006348|  0:00:40s\n","epoch 44 | loss: 0.14599 | val_0_mse: 0.3884199857711792|  0:00:41s\n","epoch 45 | loss: 0.15012 | val_0_mse: 0.1931000053882599|  0:00:41s\n","epoch 46 | loss: 0.14833 | val_0_mse: 0.36588001251220703|  0:00:42s\n","epoch 47 | loss: 0.11367 | val_0_mse: 0.26269999146461487|  0:00:43s\n","epoch 48 | loss: 0.11273 | val_0_mse: 0.2642599940299988|  0:00:44s\n","epoch 49 | loss: 0.11179 | val_0_mse: 0.32089999318122864|  0:00:45s\n","epoch 50 | loss: 0.12441 | val_0_mse: 0.2222599983215332|  0:00:46s\n","epoch 51 | loss: 0.13501 | val_0_mse: 0.18649999797344208|  0:00:47s\n","epoch 52 | loss: 0.14781 | val_0_mse: 0.2175000011920929|  0:00:48s\n","epoch 53 | loss: 0.11628 | val_0_mse: 0.17305000126361847|  0:00:49s\n","epoch 54 | loss: 0.10313 | val_0_mse: 0.21926000714302063|  0:00:50s\n","epoch 55 | loss: 0.1157  | val_0_mse: 0.18479999899864197|  0:00:51s\n","epoch 56 | loss: 0.10784 | val_0_mse: 0.14008000493049622|  0:00:51s\n","epoch 57 | loss: 0.1118  | val_0_mse: 0.12240999937057495|  0:00:52s\n","epoch 58 | loss: 0.11199 | val_0_mse: 0.17170999944210052|  0:00:53s\n","epoch 59 | loss: 0.10357 | val_0_mse: 0.16947999596595764|  0:00:54s\n","epoch 60 | loss: 0.13403 | val_0_mse: 0.15748000144958496|  0:00:55s\n","epoch 61 | loss: 0.1449  | val_0_mse: 0.19672000408172607|  0:00:56s\n","epoch 62 | loss: 0.13455 | val_0_mse: 0.12801000475883484|  0:00:57s\n","epoch 63 | loss: 0.13234 | val_0_mse: 0.18975000083446503|  0:00:58s\n","epoch 64 | loss: 0.12557 | val_0_mse: 0.13821999728679657|  0:00:59s\n","epoch 65 | loss: 0.12539 | val_0_mse: 0.20162999629974365|  0:01:00s\n","epoch 66 | loss: 0.12324 | val_0_mse: 0.1433899998664856|  0:01:01s\n","epoch 67 | loss: 0.12394 | val_0_mse: 0.15127000212669373|  0:01:02s\n","\n","Early stopping occurred at epoch 67 with best_epoch = 57 and best_val_0_mse = 0.12240999937057495\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 11:57:03,872] Trial 42 finished with value: 0.1224069595336914 and parameters: {'n_d': 49, 'n_steps': 4, 'gamma': 1.1555693209226554, 'n_independent': 3, 'n_shared': 5, 'momentum': 0.2616218183016858}. Best is trial 31 with value: 0.07662469148635864.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 47.33802| val_0_mse: 18191.20703125|  0:00:00s\n","epoch 1  | loss: 1.68831 | val_0_mse: 68734.0078125|  0:00:01s\n","epoch 2  | loss: 0.60787 | val_0_mse: 4203.02294921875|  0:00:02s\n","epoch 3  | loss: 0.45373 | val_0_mse: 675.6297607421875|  0:00:02s\n","epoch 4  | loss: 0.35548 | val_0_mse: 920.6557006835938|  0:00:03s\n","epoch 5  | loss: 0.35081 | val_0_mse: 1053.980224609375|  0:00:04s\n","epoch 6  | loss: 0.31729 | val_0_mse: 1010.2982177734375|  0:00:04s\n","epoch 7  | loss: 0.28905 | val_0_mse: 2137.056884765625|  0:00:05s\n","epoch 8  | loss: 0.25769 | val_0_mse: 939.8955078125|  0:00:06s\n","epoch 9  | loss: 0.3299  | val_0_mse: 748.4615478515625|  0:00:06s\n","epoch 10 | loss: 0.23375 | val_0_mse: 438.1000061035156|  0:00:07s\n","epoch 11 | loss: 0.21109 | val_0_mse: 442.6708679199219|  0:00:08s\n","epoch 12 | loss: 0.17208 | val_0_mse: 568.4199829101562|  0:00:08s\n","epoch 13 | loss: 0.15295 | val_0_mse: 393.5533752441406|  0:00:09s\n","epoch 14 | loss: 0.19361 | val_0_mse: 31.29224967956543|  0:00:10s\n","epoch 15 | loss: 0.16692 | val_0_mse: 98.0177230834961|  0:00:10s\n","epoch 16 | loss: 0.1513  | val_0_mse: 86.36045837402344|  0:00:11s\n","epoch 17 | loss: 0.16747 | val_0_mse: 188.26370239257812|  0:00:12s\n","epoch 18 | loss: 0.17347 | val_0_mse: 102.7645263671875|  0:00:12s\n","epoch 19 | loss: 0.14313 | val_0_mse: 66.81178283691406|  0:00:13s\n","epoch 20 | loss: 0.13955 | val_0_mse: 125.84971618652344|  0:00:14s\n","epoch 21 | loss: 0.12864 | val_0_mse: 68.91448211669922|  0:00:14s\n","epoch 22 | loss: 0.13228 | val_0_mse: 42.67512130737305|  0:00:15s\n","epoch 23 | loss: 0.15082 | val_0_mse: 24.51280975341797|  0:00:16s\n","epoch 24 | loss: 0.12891 | val_0_mse: 34.184688568115234|  0:00:16s\n","epoch 25 | loss: 0.13147 | val_0_mse: 46.97597885131836|  0:00:17s\n","epoch 26 | loss: 0.11289 | val_0_mse: 28.83846092224121|  0:00:18s\n","epoch 27 | loss: 0.11091 | val_0_mse: 22.79987907409668|  0:00:18s\n","epoch 28 | loss: 0.11258 | val_0_mse: 13.428250312805176|  0:00:19s\n","epoch 29 | loss: 0.11861 | val_0_mse: 8.574359893798828|  0:00:20s\n","epoch 30 | loss: 0.12982 | val_0_mse: 8.577400207519531|  0:00:21s\n","epoch 31 | loss: 0.16094 | val_0_mse: 3.369270086288452|  0:00:21s\n","epoch 32 | loss: 0.15243 | val_0_mse: 2.8620100021362305|  0:00:22s\n","epoch 33 | loss: 0.12998 | val_0_mse: 1.0687899589538574|  0:00:23s\n","epoch 34 | loss: 0.12319 | val_0_mse: 1.0966099500656128|  0:00:23s\n","epoch 35 | loss: 0.11928 | val_0_mse: 0.9003499746322632|  0:00:24s\n","epoch 36 | loss: 0.12707 | val_0_mse: 0.9594900012016296|  0:00:25s\n","epoch 37 | loss: 0.15155 | val_0_mse: 0.8039299845695496|  0:00:25s\n","epoch 38 | loss: 0.14898 | val_0_mse: 1.2294399738311768|  0:00:26s\n","epoch 39 | loss: 0.11596 | val_0_mse: 1.1384999752044678|  0:00:27s\n","epoch 40 | loss: 0.10462 | val_0_mse: 0.648859977722168|  0:00:27s\n","epoch 41 | loss: 0.09521 | val_0_mse: 0.41418999433517456|  0:00:28s\n","epoch 42 | loss: 0.10347 | val_0_mse: 0.34845998883247375|  0:00:29s\n","epoch 43 | loss: 0.10238 | val_0_mse: 0.25393998622894287|  0:00:29s\n","epoch 44 | loss: 0.09992 | val_0_mse: 0.3024100065231323|  0:00:30s\n","epoch 45 | loss: 0.0989  | val_0_mse: 0.22374999523162842|  0:00:31s\n","epoch 46 | loss: 0.09273 | val_0_mse: 0.21410000324249268|  0:00:31s\n","epoch 47 | loss: 0.13108 | val_0_mse: 0.18352000415325165|  0:00:32s\n","epoch 48 | loss: 0.1072  | val_0_mse: 0.1398800015449524|  0:00:33s\n","epoch 49 | loss: 0.09997 | val_0_mse: 0.1652899980545044|  0:00:33s\n","epoch 50 | loss: 0.09854 | val_0_mse: 0.14733999967575073|  0:00:34s\n","epoch 51 | loss: 0.10043 | val_0_mse: 0.21116000413894653|  0:00:35s\n","epoch 52 | loss: 0.09869 | val_0_mse: 0.22838999330997467|  0:00:35s\n","epoch 53 | loss: 0.105   | val_0_mse: 0.16508999466896057|  0:00:36s\n","epoch 54 | loss: 0.09735 | val_0_mse: 0.13380999863147736|  0:00:37s\n","epoch 55 | loss: 0.09462 | val_0_mse: 0.14483000338077545|  0:00:37s\n","epoch 56 | loss: 0.1068  | val_0_mse: 0.1190200001001358|  0:00:38s\n","epoch 57 | loss: 0.12241 | val_0_mse: 0.18472999334335327|  0:00:39s\n","epoch 58 | loss: 0.12059 | val_0_mse: 0.10414999723434448|  0:00:39s\n","epoch 59 | loss: 0.0973  | val_0_mse: 0.1072700023651123|  0:00:40s\n","epoch 60 | loss: 0.09171 | val_0_mse: 0.11202000081539154|  0:00:41s\n","epoch 61 | loss: 0.09071 | val_0_mse: 0.12338999658823013|  0:00:42s\n","epoch 62 | loss: 0.12253 | val_0_mse: 0.14076000452041626|  0:00:42s\n","epoch 63 | loss: 0.12257 | val_0_mse: 0.1696700006723404|  0:00:43s\n","epoch 64 | loss: 0.1179  | val_0_mse: 0.10345999896526337|  0:00:44s\n","epoch 65 | loss: 0.11851 | val_0_mse: 0.13499000668525696|  0:00:44s\n","epoch 66 | loss: 0.1191  | val_0_mse: 0.11269000172615051|  0:00:45s\n","epoch 67 | loss: 0.11553 | val_0_mse: 0.11721000075340271|  0:00:46s\n","epoch 68 | loss: 0.1153  | val_0_mse: 0.10027000308036804|  0:00:46s\n","epoch 69 | loss: 0.12093 | val_0_mse: 0.13199999928474426|  0:00:47s\n","epoch 70 | loss: 0.1158  | val_0_mse: 0.10925000160932541|  0:00:48s\n","epoch 71 | loss: 0.11183 | val_0_mse: 0.11140000075101852|  0:00:48s\n","epoch 72 | loss: 0.11893 | val_0_mse: 0.10498999804258347|  0:00:49s\n","epoch 73 | loss: 0.11617 | val_0_mse: 0.10779000073671341|  0:00:50s\n","epoch 74 | loss: 0.11404 | val_0_mse: 0.09927999973297119|  0:00:50s\n","epoch 75 | loss: 0.11267 | val_0_mse: 0.11665000021457672|  0:00:51s\n","epoch 76 | loss: 0.11352 | val_0_mse: 0.1046999990940094|  0:00:52s\n","epoch 77 | loss: 0.10505 | val_0_mse: 0.10057999938726425|  0:00:52s\n","epoch 78 | loss: 0.11401 | val_0_mse: 0.10756000131368637|  0:00:53s\n","epoch 79 | loss: 0.09343 | val_0_mse: 0.08893000334501266|  0:00:54s\n","epoch 80 | loss: 0.08639 | val_0_mse: 0.09533999860286713|  0:00:54s\n","epoch 81 | loss: 0.09183 | val_0_mse: 0.09724000096321106|  0:00:55s\n","epoch 82 | loss: 0.09482 | val_0_mse: 0.09220000356435776|  0:00:56s\n","epoch 83 | loss: 0.09114 | val_0_mse: 0.13446000218391418|  0:00:56s\n","epoch 84 | loss: 0.11334 | val_0_mse: 0.094930000603199|  0:00:57s\n","epoch 85 | loss: 0.09344 | val_0_mse: 0.1024399995803833|  0:00:58s\n","epoch 86 | loss: 0.08683 | val_0_mse: 0.09604000300168991|  0:00:58s\n","epoch 87 | loss: 0.0918  | val_0_mse: 0.11180000007152557|  0:00:59s\n","epoch 88 | loss: 0.09419 | val_0_mse: 0.09841000288724899|  0:01:00s\n","epoch 89 | loss: 0.08603 | val_0_mse: 0.10670000314712524|  0:01:00s\n","\n","Early stopping occurred at epoch 89 with best_epoch = 79 and best_val_0_mse = 0.08893000334501266\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 11:58:04,936] Trial 43 finished with value: 0.0889291763305664 and parameters: {'n_d': 42, 'n_steps': 3, 'gamma': 1.2794835416868533, 'n_independent': 2, 'n_shared': 5, 'momentum': 0.3199255239081848}. Best is trial 31 with value: 0.07662469148635864.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 37.51769| val_0_mse: 7084.56982421875|  0:00:00s\n","epoch 1  | loss: 2.82409 | val_0_mse: 336.22412109375|  0:00:01s\n","epoch 2  | loss: 0.9694  | val_0_mse: 1763.289794921875|  0:00:02s\n","epoch 3  | loss: 0.61425 | val_0_mse: 909.66650390625|  0:00:02s\n","epoch 4  | loss: 0.62692 | val_0_mse: 998.690185546875|  0:00:03s\n","epoch 5  | loss: 0.57026 | val_0_mse: 1664.0601806640625|  0:00:04s\n","epoch 6  | loss: 0.3771  | val_0_mse: 1451.1280517578125|  0:00:05s\n","epoch 7  | loss: 0.35302 | val_0_mse: 1610.1051025390625|  0:00:05s\n","epoch 8  | loss: 0.29051 | val_0_mse: 1061.6865234375|  0:00:06s\n","epoch 9  | loss: 0.27478 | val_0_mse: 195.78733825683594|  0:00:07s\n","epoch 10 | loss: 0.2114  | val_0_mse: 120.62471008300781|  0:00:08s\n","epoch 11 | loss: 0.19864 | val_0_mse: 139.71971130371094|  0:00:08s\n","epoch 12 | loss: 0.29481 | val_0_mse: 163.94290161132812|  0:00:09s\n","epoch 13 | loss: 0.21379 | val_0_mse: 56.8974609375|  0:00:10s\n","epoch 14 | loss: 0.18092 | val_0_mse: 54.422550201416016|  0:00:11s\n","epoch 15 | loss: 0.18018 | val_0_mse: 40.841941833496094|  0:00:11s\n","epoch 16 | loss: 0.15517 | val_0_mse: 39.33049011230469|  0:00:12s\n","epoch 17 | loss: 0.13898 | val_0_mse: 43.82347869873047|  0:00:13s\n","epoch 18 | loss: 0.13861 | val_0_mse: 40.79227828979492|  0:00:14s\n","epoch 19 | loss: 0.13591 | val_0_mse: 15.29380989074707|  0:00:14s\n","epoch 20 | loss: 0.14169 | val_0_mse: 21.072420120239258|  0:00:15s\n","epoch 21 | loss: 0.13327 | val_0_mse: 22.493099212646484|  0:00:16s\n","epoch 22 | loss: 0.13295 | val_0_mse: 12.935259819030762|  0:00:16s\n","epoch 23 | loss: 0.12553 | val_0_mse: 7.46599006652832|  0:00:17s\n","epoch 24 | loss: 0.12911 | val_0_mse: 6.379539966583252|  0:00:18s\n","epoch 25 | loss: 0.12613 | val_0_mse: 4.6267900466918945|  0:00:19s\n","epoch 26 | loss: 0.13245 | val_0_mse: 3.6733100414276123|  0:00:20s\n","epoch 27 | loss: 0.12366 | val_0_mse: 2.3277900218963623|  0:00:20s\n","epoch 28 | loss: 0.11302 | val_0_mse: 2.1447200775146484|  0:00:21s\n","epoch 29 | loss: 0.16549 | val_0_mse: 1.7943700551986694|  0:00:22s\n","epoch 30 | loss: 0.13597 | val_0_mse: 2.247529983520508|  0:00:22s\n","epoch 31 | loss: 0.13999 | val_0_mse: 1.4562599658966064|  0:00:23s\n","epoch 32 | loss: 0.26015 | val_0_mse: 0.6890699863433838|  0:00:24s\n","epoch 33 | loss: 0.23718 | val_0_mse: 1.2817599773406982|  0:00:25s\n","epoch 34 | loss: 0.21092 | val_0_mse: 0.7455999851226807|  0:00:25s\n","epoch 35 | loss: 0.21652 | val_0_mse: 0.37575000524520874|  0:00:26s\n","epoch 36 | loss: 0.22427 | val_0_mse: 0.46140000224113464|  0:00:27s\n","epoch 37 | loss: 0.20555 | val_0_mse: 0.2601200044155121|  0:00:28s\n","epoch 38 | loss: 0.18781 | val_0_mse: 0.5634400248527527|  0:00:28s\n","epoch 39 | loss: 0.19944 | val_0_mse: 0.7907900214195251|  0:00:29s\n","epoch 40 | loss: 0.2096  | val_0_mse: 0.7909700274467468|  0:00:30s\n","epoch 41 | loss: 0.2103  | val_0_mse: 0.48607000708580017|  0:00:30s\n","epoch 42 | loss: 0.18218 | val_0_mse: 0.2341099977493286|  0:00:31s\n","epoch 43 | loss: 0.17429 | val_0_mse: 0.2390100061893463|  0:00:32s\n","epoch 44 | loss: 0.1949  | val_0_mse: 0.2445099949836731|  0:00:33s\n","epoch 45 | loss: 0.18683 | val_0_mse: 0.21684999763965607|  0:00:33s\n","epoch 46 | loss: 0.18001 | val_0_mse: 0.4189800024032593|  0:00:34s\n","epoch 47 | loss: 0.18518 | val_0_mse: 0.53507000207901|  0:00:35s\n","epoch 48 | loss: 0.18867 | val_0_mse: 0.45914000272750854|  0:00:36s\n","epoch 49 | loss: 0.19649 | val_0_mse: 0.3107199966907501|  0:00:36s\n","epoch 50 | loss: 0.18987 | val_0_mse: 0.14458000659942627|  0:00:37s\n","epoch 51 | loss: 0.17804 | val_0_mse: 0.178739994764328|  0:00:38s\n","epoch 52 | loss: 0.18967 | val_0_mse: 0.2068600058555603|  0:00:39s\n","epoch 53 | loss: 0.17847 | val_0_mse: 0.15039999783039093|  0:00:39s\n","epoch 54 | loss: 0.17735 | val_0_mse: 0.23250000178813934|  0:00:40s\n","epoch 55 | loss: 0.18513 | val_0_mse: 0.36823999881744385|  0:00:41s\n","epoch 56 | loss: 0.17982 | val_0_mse: 0.36434999108314514|  0:00:41s\n","epoch 57 | loss: 0.17862 | val_0_mse: 0.1690800040960312|  0:00:42s\n","epoch 58 | loss: 0.14591 | val_0_mse: 0.1354999989271164|  0:00:43s\n","epoch 59 | loss: 0.13625 | val_0_mse: 0.1774200052022934|  0:00:44s\n","epoch 60 | loss: 0.15004 | val_0_mse: 0.13617999851703644|  0:00:44s\n","epoch 61 | loss: 0.24678 | val_0_mse: 0.23208999633789062|  0:00:45s\n","epoch 62 | loss: 0.17662 | val_0_mse: 0.14207999408245087|  0:00:46s\n","epoch 63 | loss: 0.11707 | val_0_mse: 0.14193999767303467|  0:00:46s\n","epoch 64 | loss: 0.10234 | val_0_mse: 0.11087000370025635|  0:00:47s\n","epoch 65 | loss: 0.09704 | val_0_mse: 0.10980000346899033|  0:00:48s\n","epoch 66 | loss: 0.10014 | val_0_mse: 0.10357999801635742|  0:00:49s\n","epoch 67 | loss: 0.09472 | val_0_mse: 0.09307000041007996|  0:00:49s\n","epoch 68 | loss: 0.09502 | val_0_mse: 0.09262000024318695|  0:00:50s\n","epoch 69 | loss: 0.09146 | val_0_mse: 0.12444999814033508|  0:00:51s\n","epoch 70 | loss: 0.09616 | val_0_mse: 0.10943000018596649|  0:00:52s\n","epoch 71 | loss: 0.0931  | val_0_mse: 0.094200000166893|  0:00:53s\n","epoch 72 | loss: 0.0917  | val_0_mse: 0.08809000253677368|  0:00:53s\n","epoch 73 | loss: 0.08787 | val_0_mse: 0.10058999806642532|  0:00:54s\n","epoch 74 | loss: 0.0943  | val_0_mse: 0.09754999727010727|  0:00:55s\n","epoch 75 | loss: 0.11378 | val_0_mse: 0.13030999898910522|  0:00:56s\n","epoch 76 | loss: 0.15051 | val_0_mse: 0.11720000207424164|  0:00:56s\n","epoch 77 | loss: 0.10904 | val_0_mse: 0.09386999905109406|  0:00:57s\n","epoch 78 | loss: 0.08488 | val_0_mse: 0.08992999792098999|  0:00:58s\n","epoch 79 | loss: 0.08771 | val_0_mse: 0.09104999899864197|  0:00:58s\n","epoch 80 | loss: 0.09069 | val_0_mse: 0.11672999709844589|  0:00:59s\n","epoch 81 | loss: 0.09872 | val_0_mse: 0.08906000107526779|  0:01:00s\n","epoch 82 | loss: 0.10188 | val_0_mse: 0.08781000226736069|  0:01:01s\n","epoch 83 | loss: 0.09119 | val_0_mse: 0.09291999787092209|  0:01:01s\n","epoch 84 | loss: 0.08326 | val_0_mse: 0.09471999853849411|  0:01:02s\n","epoch 85 | loss: 0.09269 | val_0_mse: 0.10400000214576721|  0:01:03s\n","epoch 86 | loss: 0.13111 | val_0_mse: 0.10930000245571136|  0:01:04s\n","epoch 87 | loss: 0.12434 | val_0_mse: 0.10209000110626221|  0:01:05s\n","epoch 88 | loss: 0.1161  | val_0_mse: 0.10138999670743942|  0:01:05s\n","epoch 89 | loss: 0.13165 | val_0_mse: 0.1131099984049797|  0:01:06s\n","epoch 90 | loss: 0.10803 | val_0_mse: 0.12308000028133392|  0:01:07s\n","epoch 91 | loss: 0.12042 | val_0_mse: 0.12963999807834625|  0:01:07s\n","epoch 92 | loss: 0.1173  | val_0_mse: 0.11529000103473663|  0:01:08s\n","\n","Early stopping occurred at epoch 92 with best_epoch = 82 and best_val_0_mse = 0.08781000226736069\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 11:59:14,007] Trial 44 finished with value: 0.08781222999095917 and parameters: {'n_d': 55, 'n_steps': 4, 'gamma': 1.1994783470513795, 'n_independent': 2, 'n_shared': 4, 'momentum': 0.3465949703445249}. Best is trial 31 with value: 0.07662469148635864.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 39.10965| val_0_mse: 11023.4287109375|  0:00:00s\n","epoch 1  | loss: 1.60171 | val_0_mse: 5086.5966796875|  0:00:01s\n","epoch 2  | loss: 0.64895 | val_0_mse: 2023.2181396484375|  0:00:01s\n","epoch 3  | loss: 0.5674  | val_0_mse: 1416.3541259765625|  0:00:02s\n","epoch 4  | loss: 0.41736 | val_0_mse: 292.0370788574219|  0:00:03s\n","epoch 5  | loss: 0.32034 | val_0_mse: 84.77095794677734|  0:00:03s\n","epoch 6  | loss: 0.32602 | val_0_mse: 91.42357635498047|  0:00:04s\n","epoch 7  | loss: 0.23499 | val_0_mse: 82.0966796875|  0:00:04s\n","epoch 8  | loss: 0.20846 | val_0_mse: 391.4386291503906|  0:00:05s\n","epoch 9  | loss: 0.19741 | val_0_mse: 68.83223724365234|  0:00:06s\n","epoch 10 | loss: 0.17025 | val_0_mse: 34.95370864868164|  0:00:06s\n","epoch 11 | loss: 0.15245 | val_0_mse: 7.741610050201416|  0:00:07s\n","epoch 12 | loss: 0.14193 | val_0_mse: 159.3287353515625|  0:00:07s\n","epoch 13 | loss: 0.13988 | val_0_mse: 81.66680908203125|  0:00:08s\n","epoch 14 | loss: 0.12461 | val_0_mse: 91.32521057128906|  0:00:09s\n","epoch 15 | loss: 0.23033 | val_0_mse: 41.81433868408203|  0:00:09s\n","epoch 16 | loss: 0.19373 | val_0_mse: 76.67607879638672|  0:00:10s\n","epoch 17 | loss: 0.15914 | val_0_mse: 40.76945114135742|  0:00:10s\n","epoch 18 | loss: 0.15242 | val_0_mse: 47.13655090332031|  0:00:11s\n","epoch 19 | loss: 0.17222 | val_0_mse: 41.11954879760742|  0:00:12s\n","epoch 20 | loss: 0.16076 | val_0_mse: 20.181360244750977|  0:00:12s\n","epoch 21 | loss: 0.12125 | val_0_mse: 14.647279739379883|  0:00:13s\n","\n","Early stopping occurred at epoch 21 with best_epoch = 11 and best_val_0_mse = 7.741610050201416\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 11:59:27,675] Trial 45 finished with value: 7.74160623550415 and parameters: {'n_d': 46, 'n_steps': 3, 'gamma': 1.1045907540675497, 'n_independent': 1, 'n_shared': 5, 'momentum': 0.2865471598038919}. Best is trial 31 with value: 0.07662469148635864.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 42.73474| val_0_mse: 3496.910400390625|  0:00:00s\n","epoch 1  | loss: 1.06961 | val_0_mse: 676.4801025390625|  0:00:01s\n","epoch 2  | loss: 0.46655 | val_0_mse: 293.26849365234375|  0:00:01s\n","epoch 3  | loss: 0.31048 | val_0_mse: 352.1988525390625|  0:00:02s\n","epoch 4  | loss: 0.30652 | val_0_mse: 348.8532409667969|  0:00:03s\n","epoch 5  | loss: 0.28802 | val_0_mse: 794.9467163085938|  0:00:04s\n","epoch 6  | loss: 0.26828 | val_0_mse: 292.45172119140625|  0:00:04s\n","epoch 7  | loss: 0.24663 | val_0_mse: 38.28723907470703|  0:00:05s\n","epoch 8  | loss: 0.23524 | val_0_mse: 186.30490112304688|  0:00:06s\n","epoch 9  | loss: 0.22473 | val_0_mse: 57.30418014526367|  0:00:06s\n","epoch 10 | loss: 0.40716 | val_0_mse: 127.64620208740234|  0:00:07s\n","epoch 11 | loss: 0.42854 | val_0_mse: 141.02284240722656|  0:00:08s\n","epoch 12 | loss: 0.27353 | val_0_mse: 101.8326187133789|  0:00:08s\n","epoch 13 | loss: 0.23295 | val_0_mse: 101.60745239257812|  0:00:09s\n","epoch 14 | loss: 0.1913  | val_0_mse: 166.17373657226562|  0:00:10s\n","epoch 15 | loss: 0.17655 | val_0_mse: 125.61174774169922|  0:00:10s\n","epoch 16 | loss: 0.16037 | val_0_mse: 170.2459259033203|  0:00:11s\n","epoch 17 | loss: 0.16148 | val_0_mse: 112.06343078613281|  0:00:12s\n","\n","Early stopping occurred at epoch 17 with best_epoch = 7 and best_val_0_mse = 38.28723907470703\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 11:59:40,339] Trial 46 finished with value: 38.28723907470703 and parameters: {'n_d': 52, 'n_steps': 3, 'gamma': 1.0478672054953804, 'n_independent': 3, 'n_shared': 4, 'momentum': 0.2503879594557004}. Best is trial 31 with value: 0.07662469148635864.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 59.29598| val_0_mse: 134453.046875|  0:00:00s\n","epoch 1  | loss: 3.66667 | val_0_mse: 21431.51953125|  0:00:01s\n","epoch 2  | loss: 1.06632 | val_0_mse: 4423.7958984375|  0:00:02s\n","epoch 3  | loss: 0.59921 | val_0_mse: 9236.7861328125|  0:00:03s\n","epoch 4  | loss: 0.44954 | val_0_mse: 22801.75390625|  0:00:04s\n","epoch 5  | loss: 0.33534 | val_0_mse: 3410.3515625|  0:00:04s\n","epoch 6  | loss: 0.2854  | val_0_mse: 1533.8406982421875|  0:00:05s\n","epoch 7  | loss: 0.23662 | val_0_mse: 457.8009338378906|  0:00:06s\n","epoch 8  | loss: 0.28084 | val_0_mse: 71.252197265625|  0:00:07s\n","epoch 9  | loss: 0.26241 | val_0_mse: 94.85751342773438|  0:00:08s\n","epoch 10 | loss: 0.20964 | val_0_mse: 103.10658264160156|  0:00:08s\n","epoch 11 | loss: 0.24229 | val_0_mse: 137.3997039794922|  0:00:09s\n","epoch 12 | loss: 0.22367 | val_0_mse: 182.30795288085938|  0:00:10s\n","epoch 13 | loss: 0.22329 | val_0_mse: 93.2220687866211|  0:00:11s\n","epoch 14 | loss: 0.17704 | val_0_mse: 95.49903869628906|  0:00:12s\n","epoch 15 | loss: 0.1682  | val_0_mse: 55.594398498535156|  0:00:12s\n","epoch 16 | loss: 0.18186 | val_0_mse: 306.6618957519531|  0:00:13s\n","epoch 17 | loss: 0.17219 | val_0_mse: 119.80082702636719|  0:00:14s\n","epoch 18 | loss: 0.17395 | val_0_mse: 4.349649906158447|  0:00:15s\n","epoch 19 | loss: 0.16506 | val_0_mse: 5.356359958648682|  0:00:16s\n","epoch 20 | loss: 0.18132 | val_0_mse: 6.223509788513184|  0:00:17s\n","epoch 21 | loss: 0.19159 | val_0_mse: 1.9794399738311768|  0:00:17s\n","epoch 22 | loss: 0.17228 | val_0_mse: 2.935610055923462|  0:00:18s\n","epoch 23 | loss: 0.19736 | val_0_mse: 6.765940189361572|  0:00:19s\n","epoch 24 | loss: 0.2037  | val_0_mse: 3.610379934310913|  0:00:20s\n","epoch 25 | loss: 0.1795  | val_0_mse: 1.4583200216293335|  0:00:21s\n","epoch 26 | loss: 0.1734  | val_0_mse: 1.133180022239685|  0:00:22s\n","epoch 27 | loss: 0.1571  | val_0_mse: 0.7293800115585327|  0:00:22s\n","epoch 28 | loss: 0.15885 | val_0_mse: 0.5722600221633911|  0:00:23s\n","epoch 29 | loss: 0.15516 | val_0_mse: 0.42921000719070435|  0:00:24s\n","epoch 30 | loss: 0.14687 | val_0_mse: 0.3624100089073181|  0:00:25s\n","epoch 31 | loss: 0.13655 | val_0_mse: 0.23996999859809875|  0:00:26s\n","epoch 32 | loss: 0.13812 | val_0_mse: 0.33980000019073486|  0:00:27s\n","epoch 33 | loss: 0.13675 | val_0_mse: 0.37424999475479126|  0:00:27s\n","epoch 34 | loss: 0.12952 | val_0_mse: 0.3709999918937683|  0:00:28s\n","epoch 35 | loss: 0.17717 | val_0_mse: 0.2531000077724457|  0:00:29s\n","epoch 36 | loss: 0.18626 | val_0_mse: 0.31317999958992004|  0:00:30s\n","epoch 37 | loss: 0.17005 | val_0_mse: 0.20247000455856323|  0:00:31s\n","epoch 38 | loss: 0.16181 | val_0_mse: 0.26298001408576965|  0:00:31s\n","epoch 39 | loss: 0.14896 | val_0_mse: 0.24296000599861145|  0:00:32s\n","epoch 40 | loss: 0.14532 | val_0_mse: 0.25527000427246094|  0:00:33s\n","epoch 41 | loss: 0.14234 | val_0_mse: 0.24050000309944153|  0:00:34s\n","epoch 42 | loss: 0.14957 | val_0_mse: 0.23788000643253326|  0:00:35s\n","epoch 43 | loss: 0.16443 | val_0_mse: 0.2289000004529953|  0:00:35s\n","epoch 44 | loss: 0.20071 | val_0_mse: 0.2526099979877472|  0:00:36s\n","epoch 45 | loss: 0.22616 | val_0_mse: 0.2297700047492981|  0:00:37s\n","epoch 46 | loss: 0.19728 | val_0_mse: 0.18591000139713287|  0:00:38s\n","epoch 47 | loss: 0.1855  | val_0_mse: 0.22940999269485474|  0:00:39s\n","epoch 48 | loss: 0.19122 | val_0_mse: 0.3270300030708313|  0:00:40s\n","epoch 49 | loss: 0.19332 | val_0_mse: 0.3158400058746338|  0:00:40s\n","epoch 50 | loss: 0.17786 | val_0_mse: 0.2294600009918213|  0:00:41s\n","epoch 51 | loss: 0.17683 | val_0_mse: 0.1509300023317337|  0:00:42s\n","epoch 52 | loss: 0.15149 | val_0_mse: 0.14902999997138977|  0:00:43s\n","epoch 53 | loss: 0.12264 | val_0_mse: 0.15331000089645386|  0:00:44s\n","epoch 54 | loss: 0.12234 | val_0_mse: 0.15049000084400177|  0:00:44s\n","epoch 55 | loss: 0.12925 | val_0_mse: 0.1727299988269806|  0:00:45s\n","epoch 56 | loss: 0.13091 | val_0_mse: 0.14666999876499176|  0:00:46s\n","epoch 57 | loss: 0.12809 | val_0_mse: 0.13095000386238098|  0:00:47s\n","epoch 58 | loss: 0.1218  | val_0_mse: 0.14621999859809875|  0:00:48s\n","epoch 59 | loss: 0.13422 | val_0_mse: 0.13782000541687012|  0:00:49s\n","epoch 60 | loss: 0.1355  | val_0_mse: 0.18604999780654907|  0:00:49s\n","epoch 61 | loss: 0.13322 | val_0_mse: 0.20002999901771545|  0:00:50s\n","epoch 62 | loss: 0.12059 | val_0_mse: 0.25672999024391174|  0:00:51s\n","epoch 63 | loss: 0.10867 | val_0_mse: 0.18005000054836273|  0:00:52s\n","epoch 64 | loss: 0.124   | val_0_mse: 0.12273000180721283|  0:00:53s\n","epoch 65 | loss: 0.10294 | val_0_mse: 0.10638000071048737|  0:00:54s\n","epoch 66 | loss: 0.10003 | val_0_mse: 0.10864999890327454|  0:00:54s\n","epoch 67 | loss: 0.12098 | val_0_mse: 0.17351000010967255|  0:00:55s\n","epoch 68 | loss: 0.13357 | val_0_mse: 0.1343899965286255|  0:00:56s\n","epoch 69 | loss: 0.12251 | val_0_mse: 0.13937999308109283|  0:00:57s\n","epoch 70 | loss: 0.14407 | val_0_mse: 0.13504000008106232|  0:00:58s\n","epoch 71 | loss: 0.17735 | val_0_mse: 0.21759000420570374|  0:00:58s\n","epoch 72 | loss: 0.14989 | val_0_mse: 0.14249999821186066|  0:00:59s\n","epoch 73 | loss: 0.1264  | val_0_mse: 0.1540600061416626|  0:01:00s\n","epoch 74 | loss: 0.12585 | val_0_mse: 0.14135000109672546|  0:01:01s\n","epoch 75 | loss: 0.12416 | val_0_mse: 0.13213999569416046|  0:01:02s\n","\n","Early stopping occurred at epoch 75 with best_epoch = 65 and best_val_0_mse = 0.10638000071048737\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 12:00:42,897] Trial 47 finished with value: 0.10638361424207687 and parameters: {'n_d': 26, 'n_steps': 4, 'gamma': 1.6935501350073185, 'n_independent': 2, 'n_shared': 5, 'momentum': 0.22350575553010243}. Best is trial 31 with value: 0.07662469148635864.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 75.26791| val_0_mse: 169711.234375|  0:00:00s\n","epoch 1  | loss: 3.84411 | val_0_mse: 5956.0576171875|  0:00:00s\n","epoch 2  | loss: 0.48947 | val_0_mse: 3985.529052734375|  0:00:01s\n","epoch 3  | loss: 0.4624  | val_0_mse: 2610.533935546875|  0:00:01s\n","epoch 4  | loss: 0.31407 | val_0_mse: 1103.7772216796875|  0:00:02s\n","epoch 5  | loss: 0.2387  | val_0_mse: 658.9472045898438|  0:00:02s\n","epoch 6  | loss: 0.25895 | val_0_mse: 442.9954528808594|  0:00:03s\n","epoch 7  | loss: 0.21819 | val_0_mse: 327.33062744140625|  0:00:03s\n","epoch 8  | loss: 0.18017 | val_0_mse: 208.77285766601562|  0:00:04s\n","epoch 9  | loss: 0.19152 | val_0_mse: 149.9786834716797|  0:00:04s\n","epoch 10 | loss: 0.17209 | val_0_mse: 22.340730667114258|  0:00:05s\n","epoch 11 | loss: 0.16989 | val_0_mse: 46.52817916870117|  0:00:05s\n","epoch 12 | loss: 0.15686 | val_0_mse: 42.82569885253906|  0:00:06s\n","epoch 13 | loss: 0.14101 | val_0_mse: 57.81562042236328|  0:00:06s\n","epoch 14 | loss: 0.13903 | val_0_mse: 182.2269744873047|  0:00:07s\n","epoch 15 | loss: 0.13385 | val_0_mse: 163.44325256347656|  0:00:07s\n","epoch 16 | loss: 0.13334 | val_0_mse: 151.02532958984375|  0:00:08s\n","epoch 17 | loss: 0.12499 | val_0_mse: 259.18719482421875|  0:00:08s\n","epoch 18 | loss: 0.12354 | val_0_mse: 181.55018615722656|  0:00:08s\n","epoch 19 | loss: 0.11829 | val_0_mse: 21.75798988342285|  0:00:09s\n","epoch 20 | loss: 0.15072 | val_0_mse: 5.696539878845215|  0:00:10s\n","epoch 21 | loss: 0.14381 | val_0_mse: 30.35597038269043|  0:00:10s\n","epoch 22 | loss: 0.14465 | val_0_mse: 11.51259994506836|  0:00:11s\n","epoch 23 | loss: 0.13697 | val_0_mse: 42.22214126586914|  0:00:11s\n","epoch 24 | loss: 0.12556 | val_0_mse: 16.43947982788086|  0:00:11s\n","epoch 25 | loss: 0.12722 | val_0_mse: 26.770280838012695|  0:00:12s\n","epoch 26 | loss: 0.12653 | val_0_mse: 25.09231948852539|  0:00:12s\n","epoch 27 | loss: 0.13318 | val_0_mse: 23.810909271240234|  0:00:13s\n","epoch 28 | loss: 0.11034 | val_0_mse: 22.55139923095703|  0:00:13s\n","epoch 29 | loss: 0.1053  | val_0_mse: 23.331470489501953|  0:00:14s\n","epoch 30 | loss: 0.10305 | val_0_mse: 17.996889114379883|  0:00:14s\n","\n","Early stopping occurred at epoch 30 with best_epoch = 20 and best_val_0_mse = 5.696539878845215\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 12:00:57,927] Trial 48 finished with value: 5.696539878845215 and parameters: {'n_d': 30, 'n_steps': 3, 'gamma': 1.2492864602021718, 'n_independent': 1, 'n_shared': 3, 'momentum': 0.3004263955580091}. Best is trial 31 with value: 0.07662469148635864.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 84.40092| val_0_mse: 19282.361328125|  0:00:00s\n","epoch 1  | loss: 6.28371 | val_0_mse: 49940.1640625|  0:00:01s\n","epoch 2  | loss: 1.27813 | val_0_mse: 10046.328125|  0:00:02s\n","epoch 3  | loss: 0.79981 | val_0_mse: 664.894287109375|  0:00:03s\n","epoch 4  | loss: 0.61712 | val_0_mse: 8925.1591796875|  0:00:04s\n","epoch 5  | loss: 0.49014 | val_0_mse: 973.8388671875|  0:00:05s\n","epoch 6  | loss: 0.50278 | val_0_mse: 479.2478942871094|  0:00:06s\n","epoch 7  | loss: 0.47765 | val_0_mse: 543.179443359375|  0:00:07s\n","epoch 8  | loss: 0.24743 | val_0_mse: 41.42359161376953|  0:00:08s\n","epoch 9  | loss: 0.23383 | val_0_mse: 180.21432495117188|  0:00:08s\n","epoch 10 | loss: 0.27936 | val_0_mse: 207.46502685546875|  0:00:09s\n","epoch 11 | loss: 0.2389  | val_0_mse: 40.357120513916016|  0:00:10s\n","epoch 12 | loss: 0.19508 | val_0_mse: 40.437679290771484|  0:00:11s\n","epoch 13 | loss: 0.19734 | val_0_mse: 28.94658088684082|  0:00:12s\n","epoch 14 | loss: 0.18779 | val_0_mse: 34.36824035644531|  0:00:13s\n","epoch 15 | loss: 0.18721 | val_0_mse: 22.72170066833496|  0:00:14s\n","epoch 16 | loss: 0.16147 | val_0_mse: 1.971019983291626|  0:00:15s\n","epoch 17 | loss: 0.16618 | val_0_mse: 3.3202500343322754|  0:00:15s\n","epoch 18 | loss: 0.18599 | val_0_mse: 1.3231300115585327|  0:00:16s\n","epoch 19 | loss: 0.18596 | val_0_mse: 2.0183799266815186|  0:00:17s\n","epoch 20 | loss: 0.21342 | val_0_mse: 5.934679985046387|  0:00:18s\n","epoch 21 | loss: 0.17153 | val_0_mse: 3.264620065689087|  0:00:19s\n","epoch 22 | loss: 0.1409  | val_0_mse: 2.305730104446411|  0:00:20s\n","epoch 23 | loss: 0.13997 | val_0_mse: 0.8578699827194214|  0:00:21s\n","epoch 24 | loss: 0.13464 | val_0_mse: 1.5344799757003784|  0:00:22s\n","epoch 25 | loss: 0.16815 | val_0_mse: 1.6491700410842896|  0:00:23s\n","epoch 26 | loss: 0.17494 | val_0_mse: 1.8895399570465088|  0:00:24s\n","epoch 27 | loss: 0.20714 | val_0_mse: 1.5686299800872803|  0:00:24s\n","epoch 28 | loss: 0.15516 | val_0_mse: 2.7642300128936768|  0:00:25s\n","epoch 29 | loss: 0.15745 | val_0_mse: 6.684390068054199|  0:00:26s\n","epoch 30 | loss: 0.1584  | val_0_mse: 4.316619873046875|  0:00:27s\n","epoch 31 | loss: 0.14578 | val_0_mse: 2.9862499237060547|  0:00:28s\n","epoch 32 | loss: 0.13588 | val_0_mse: 1.6225099563598633|  0:00:29s\n","epoch 33 | loss: 0.14466 | val_0_mse: 1.6841399669647217|  0:00:30s\n","\n","Early stopping occurred at epoch 33 with best_epoch = 23 and best_val_0_mse = 0.8578699827194214\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 12:01:28,600] Trial 49 finished with value: 0.8578651547431946 and parameters: {'n_d': 22, 'n_steps': 4, 'gamma': 1.4633059742813277, 'n_independent': 3, 'n_shared': 5, 'momentum': 0.32177493808307694}. Best is trial 31 with value: 0.07662469148635864.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 36.65134| val_0_mse: 63281.296875|  0:00:01s\n","epoch 1  | loss: 2.72006 | val_0_mse: 4701.01171875|  0:00:02s\n","epoch 2  | loss: 2.29146 | val_0_mse: 2999.81396484375|  0:00:03s\n","epoch 3  | loss: 1.71153 | val_0_mse: 1294.9110107421875|  0:00:04s\n","epoch 4  | loss: 0.77199 | val_0_mse: 1091.178955078125|  0:00:05s\n","epoch 5  | loss: 1.58875 | val_0_mse: 1331.0770263671875|  0:00:06s\n","epoch 6  | loss: 1.95071 | val_0_mse: 4841.75146484375|  0:00:07s\n","epoch 7  | loss: 1.49593 | val_0_mse: 533.9788818359375|  0:00:08s\n","epoch 8  | loss: 0.59086 | val_0_mse: 373.920654296875|  0:00:09s\n","epoch 9  | loss: 0.65193 | val_0_mse: 657.92724609375|  0:00:11s\n","epoch 10 | loss: 0.509   | val_0_mse: 1158.9244384765625|  0:00:12s\n","epoch 11 | loss: 0.32433 | val_0_mse: 505.7651672363281|  0:00:13s\n","epoch 12 | loss: 0.27405 | val_0_mse: 253.3868865966797|  0:00:14s\n","epoch 13 | loss: 0.29267 | val_0_mse: 35.31681823730469|  0:00:15s\n","epoch 14 | loss: 0.26753 | val_0_mse: 41.263301849365234|  0:00:16s\n","epoch 15 | loss: 0.31513 | val_0_mse: 13.35949993133545|  0:00:17s\n","epoch 16 | loss: 0.33555 | val_0_mse: 27.798809051513672|  0:00:18s\n","epoch 17 | loss: 0.31528 | val_0_mse: 14.733590126037598|  0:00:19s\n","epoch 18 | loss: 0.38631 | val_0_mse: 20.03982925415039|  0:00:21s\n","epoch 19 | loss: 0.2272  | val_0_mse: 2.422149896621704|  0:00:22s\n","epoch 20 | loss: 0.25294 | val_0_mse: 7.164780139923096|  0:00:23s\n","epoch 21 | loss: 0.25947 | val_0_mse: 3.3912200927734375|  0:00:24s\n","epoch 22 | loss: 0.24456 | val_0_mse: 5.803919792175293|  0:00:25s\n","epoch 23 | loss: 0.36552 | val_0_mse: 5.4582200050354|  0:00:26s\n","epoch 24 | loss: 0.47685 | val_0_mse: 5.0823798179626465|  0:00:27s\n","epoch 25 | loss: 0.45053 | val_0_mse: 0.8855599761009216|  0:00:28s\n","epoch 26 | loss: 0.22836 | val_0_mse: 1.2324700355529785|  0:00:29s\n","epoch 27 | loss: 0.19156 | val_0_mse: 1.1452100276947021|  0:00:30s\n","epoch 28 | loss: 0.22235 | val_0_mse: 0.45326000452041626|  0:00:31s\n","epoch 29 | loss: 0.26833 | val_0_mse: 0.453139990568161|  0:00:33s\n","epoch 30 | loss: 0.19651 | val_0_mse: 0.5439199805259705|  0:00:34s\n","epoch 31 | loss: 0.20464 | val_0_mse: 0.885450005531311|  0:00:35s\n","epoch 32 | loss: 0.35588 | val_0_mse: 0.8443199992179871|  0:00:36s\n","epoch 33 | loss: 0.27778 | val_0_mse: 0.4657599925994873|  0:00:37s\n","epoch 34 | loss: 0.2411  | val_0_mse: 0.49584999680519104|  0:00:38s\n","epoch 35 | loss: 0.20158 | val_0_mse: 0.4167400002479553|  0:00:39s\n","epoch 36 | loss: 0.22729 | val_0_mse: 0.32027000188827515|  0:00:40s\n","epoch 37 | loss: 0.1548  | val_0_mse: 0.5168899893760681|  0:00:41s\n","epoch 38 | loss: 0.21731 | val_0_mse: 0.26576000452041626|  0:00:42s\n","epoch 39 | loss: 0.19149 | val_0_mse: 0.4924300014972687|  0:00:44s\n","epoch 40 | loss: 0.30806 | val_0_mse: 0.8026599884033203|  0:00:45s\n","epoch 41 | loss: 0.29718 | val_0_mse: 0.40070000290870667|  0:00:46s\n","epoch 42 | loss: 0.20178 | val_0_mse: 0.21897999942302704|  0:00:47s\n","epoch 43 | loss: 0.19264 | val_0_mse: 0.23955999314785004|  0:00:48s\n","epoch 44 | loss: 0.16002 | val_0_mse: 0.37132999300956726|  0:00:49s\n","epoch 45 | loss: 0.1998  | val_0_mse: 0.2181600034236908|  0:00:50s\n","epoch 46 | loss: 0.15827 | val_0_mse: 0.3199999928474426|  0:00:51s\n","epoch 47 | loss: 0.209   | val_0_mse: 0.15174999833106995|  0:00:52s\n","epoch 48 | loss: 0.19065 | val_0_mse: 0.47846001386642456|  0:00:54s\n","epoch 49 | loss: 0.19218 | val_0_mse: 0.16346000134944916|  0:00:55s\n","epoch 50 | loss: 0.18481 | val_0_mse: 0.426690012216568|  0:00:56s\n","epoch 51 | loss: 0.18431 | val_0_mse: 0.18152999877929688|  0:00:57s\n","epoch 52 | loss: 0.13733 | val_0_mse: 0.15976999700069427|  0:00:58s\n","epoch 53 | loss: 0.18601 | val_0_mse: 0.2865000069141388|  0:00:59s\n","epoch 54 | loss: 0.35037 | val_0_mse: 0.6423500180244446|  0:01:00s\n","epoch 55 | loss: 0.34739 | val_0_mse: 0.3075700104236603|  0:01:01s\n","epoch 56 | loss: 0.23917 | val_0_mse: 0.19103999435901642|  0:01:02s\n","epoch 57 | loss: 0.18289 | val_0_mse: 0.17416000366210938|  0:01:03s\n","\n","Early stopping occurred at epoch 57 with best_epoch = 47 and best_val_0_mse = 0.15174999833106995\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 12:02:33,074] Trial 50 finished with value: 0.1517474353313446 and parameters: {'n_d': 43, 'n_steps': 8, 'gamma': 1.3522895387538623, 'n_independent': 1, 'n_shared': 4, 'momentum': 0.18864761665995253}. Best is trial 31 with value: 0.07662469148635864.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 98.90046| val_0_mse: 631.1323852539062|  0:00:00s\n","epoch 1  | loss: 14.16297| val_0_mse: 2821.818359375|  0:00:01s\n","epoch 2  | loss: 1.93092 | val_0_mse: 885.2420654296875|  0:00:01s\n","epoch 3  | loss: 0.54094 | val_0_mse: 126.63056182861328|  0:00:02s\n","epoch 4  | loss: 0.31115 | val_0_mse: 103.1113510131836|  0:00:03s\n","epoch 5  | loss: 0.29217 | val_0_mse: 139.16966247558594|  0:00:03s\n","epoch 6  | loss: 0.24109 | val_0_mse: 187.3968048095703|  0:00:04s\n","epoch 7  | loss: 0.22957 | val_0_mse: 280.9963073730469|  0:00:04s\n","epoch 8  | loss: 0.20535 | val_0_mse: 178.36199951171875|  0:00:05s\n","epoch 9  | loss: 0.19133 | val_0_mse: 176.55711364746094|  0:00:05s\n","epoch 10 | loss: 0.17322 | val_0_mse: 179.56382751464844|  0:00:06s\n","epoch 11 | loss: 0.16123 | val_0_mse: 100.45954895019531|  0:00:07s\n","epoch 12 | loss: 0.1505  | val_0_mse: 59.37110137939453|  0:00:07s\n","epoch 13 | loss: 0.15518 | val_0_mse: 21.918100357055664|  0:00:08s\n","epoch 14 | loss: 0.18321 | val_0_mse: 7.213580131530762|  0:00:08s\n","epoch 15 | loss: 0.16659 | val_0_mse: 5.265600204467773|  0:00:09s\n","epoch 16 | loss: 0.14639 | val_0_mse: 10.580769538879395|  0:00:10s\n","epoch 17 | loss: 0.14221 | val_0_mse: 14.218609809875488|  0:00:10s\n","epoch 18 | loss: 0.1288  | val_0_mse: 17.722579956054688|  0:00:11s\n","epoch 19 | loss: 0.13101 | val_0_mse: 12.410200119018555|  0:00:12s\n","epoch 20 | loss: 0.12659 | val_0_mse: 9.3785400390625|  0:00:12s\n","epoch 21 | loss: 0.12618 | val_0_mse: 6.15172004699707|  0:00:13s\n","epoch 22 | loss: 0.12851 | val_0_mse: 6.14818000793457|  0:00:13s\n","epoch 23 | loss: 0.13257 | val_0_mse: 3.652329921722412|  0:00:14s\n","epoch 24 | loss: 0.12604 | val_0_mse: 3.0408198833465576|  0:00:15s\n","epoch 25 | loss: 0.13181 | val_0_mse: 1.575469970703125|  0:00:15s\n","epoch 26 | loss: 0.11947 | val_0_mse: 1.6095099449157715|  0:00:16s\n","epoch 27 | loss: 0.12053 | val_0_mse: 0.9743899703025818|  0:00:16s\n","epoch 28 | loss: 0.10877 | val_0_mse: 1.006790041923523|  0:00:17s\n","epoch 29 | loss: 0.1139  | val_0_mse: 1.050089955329895|  0:00:18s\n","epoch 30 | loss: 0.11019 | val_0_mse: 0.7104600071907043|  0:00:18s\n","epoch 31 | loss: 0.11743 | val_0_mse: 0.5380499958992004|  0:00:19s\n","epoch 32 | loss: 0.11283 | val_0_mse: 0.6406599879264832|  0:00:19s\n","epoch 33 | loss: 0.11703 | val_0_mse: 0.39355000853538513|  0:00:20s\n","epoch 34 | loss: 0.10028 | val_0_mse: 0.45405998826026917|  0:00:21s\n","epoch 35 | loss: 0.10126 | val_0_mse: 0.4314199984073639|  0:00:21s\n","epoch 36 | loss: 0.09836 | val_0_mse: 0.446289986371994|  0:00:22s\n","epoch 37 | loss: 0.10481 | val_0_mse: 0.5119600296020508|  0:00:22s\n","epoch 38 | loss: 0.10677 | val_0_mse: 0.45179998874664307|  0:00:23s\n","epoch 39 | loss: 0.11394 | val_0_mse: 0.28068000078201294|  0:00:24s\n","epoch 40 | loss: 0.10253 | val_0_mse: 0.34163999557495117|  0:00:24s\n","epoch 41 | loss: 0.09733 | val_0_mse: 0.33507001399993896|  0:00:25s\n","epoch 42 | loss: 0.09828 | val_0_mse: 0.29679998755455017|  0:00:25s\n","epoch 43 | loss: 0.09751 | val_0_mse: 0.256630003452301|  0:00:26s\n","epoch 44 | loss: 0.09634 | val_0_mse: 0.30897000432014465|  0:00:27s\n","epoch 45 | loss: 0.09892 | val_0_mse: 0.24932999908924103|  0:00:27s\n","epoch 46 | loss: 0.09985 | val_0_mse: 0.2362000048160553|  0:00:28s\n","epoch 47 | loss: 0.09722 | val_0_mse: 0.21001000702381134|  0:00:28s\n","epoch 48 | loss: 0.10199 | val_0_mse: 0.3875199854373932|  0:00:29s\n","epoch 49 | loss: 0.10958 | val_0_mse: 0.2245199978351593|  0:00:30s\n","epoch 50 | loss: 0.10067 | val_0_mse: 0.18142999708652496|  0:00:30s\n","epoch 51 | loss: 0.0957  | val_0_mse: 0.17204999923706055|  0:00:31s\n","epoch 52 | loss: 0.10031 | val_0_mse: 0.15240000188350677|  0:00:31s\n","epoch 53 | loss: 0.10755 | val_0_mse: 0.2604900002479553|  0:00:32s\n","epoch 54 | loss: 0.11323 | val_0_mse: 0.14564000070095062|  0:00:33s\n","epoch 55 | loss: 0.10515 | val_0_mse: 0.16325999796390533|  0:00:33s\n","epoch 56 | loss: 0.10608 | val_0_mse: 0.12176000326871872|  0:00:34s\n","epoch 57 | loss: 0.11735 | val_0_mse: 0.23127000033855438|  0:00:35s\n","epoch 58 | loss: 0.13108 | val_0_mse: 0.10148999840021133|  0:00:35s\n","epoch 59 | loss: 0.10369 | val_0_mse: 0.1100199967622757|  0:00:36s\n","epoch 60 | loss: 0.10196 | val_0_mse: 0.16147999465465546|  0:00:36s\n","epoch 61 | loss: 0.111   | val_0_mse: 0.11416000127792358|  0:00:37s\n","epoch 62 | loss: 0.09834 | val_0_mse: 0.1067499965429306|  0:00:37s\n","epoch 63 | loss: 0.10035 | val_0_mse: 0.1020599976181984|  0:00:38s\n","epoch 64 | loss: 0.09421 | val_0_mse: 0.1074799969792366|  0:00:39s\n","epoch 65 | loss: 0.09538 | val_0_mse: 0.10332000255584717|  0:00:39s\n","epoch 66 | loss: 0.09315 | val_0_mse: 0.1039000004529953|  0:00:40s\n","epoch 67 | loss: 0.10617 | val_0_mse: 0.10344000160694122|  0:00:40s\n","epoch 68 | loss: 0.09361 | val_0_mse: 0.10532999783754349|  0:00:41s\n","\n","Early stopping occurred at epoch 68 with best_epoch = 58 and best_val_0_mse = 0.10148999840021133\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 12:03:14,882] Trial 51 finished with value: 0.10149127244949341 and parameters: {'n_d': 15, 'n_steps': 3, 'gamma': 1.1709468852716651, 'n_independent': 1, 'n_shared': 5, 'momentum': 0.2798296459829052}. Best is trial 31 with value: 0.07662469148635864.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 78.08063| val_0_mse: 176858.34375|  0:00:00s\n","epoch 1  | loss: 6.65959 | val_0_mse: 35658.0859375|  0:00:01s\n","epoch 2  | loss: 1.03561 | val_0_mse: 21666.833984375|  0:00:01s\n","epoch 3  | loss: 0.48549 | val_0_mse: 5811.703125|  0:00:02s\n","epoch 4  | loss: 0.31695 | val_0_mse: 5851.2744140625|  0:00:02s\n","epoch 5  | loss: 0.2714  | val_0_mse: 5013.73193359375|  0:00:03s\n","epoch 6  | loss: 0.25802 | val_0_mse: 1852.4573974609375|  0:00:04s\n","epoch 7  | loss: 0.19937 | val_0_mse: 1162.8450927734375|  0:00:04s\n","epoch 8  | loss: 0.17967 | val_0_mse: 305.3904724121094|  0:00:05s\n","epoch 9  | loss: 0.18501 | val_0_mse: 215.9971466064453|  0:00:06s\n","epoch 10 | loss: 0.21397 | val_0_mse: 211.37008666992188|  0:00:06s\n","epoch 11 | loss: 0.18411 | val_0_mse: 424.036865234375|  0:00:07s\n","epoch 12 | loss: 0.16906 | val_0_mse: 1.6751400232315063|  0:00:07s\n","epoch 13 | loss: 0.16217 | val_0_mse: 124.00614929199219|  0:00:08s\n","epoch 14 | loss: 0.16859 | val_0_mse: 46.417049407958984|  0:00:08s\n","epoch 15 | loss: 0.20105 | val_0_mse: 13.811050415039062|  0:00:09s\n","epoch 16 | loss: 0.1458  | val_0_mse: 30.953609466552734|  0:00:10s\n","epoch 17 | loss: 0.13824 | val_0_mse: 21.568199157714844|  0:00:10s\n","epoch 18 | loss: 0.13667 | val_0_mse: 166.08743286132812|  0:00:11s\n","epoch 19 | loss: 0.12642 | val_0_mse: 9.429309844970703|  0:00:12s\n","epoch 20 | loss: 0.13146 | val_0_mse: 4.756430149078369|  0:00:12s\n","epoch 21 | loss: 0.13383 | val_0_mse: 5.171319961547852|  0:00:13s\n","epoch 22 | loss: 0.13569 | val_0_mse: 8.600810050964355|  0:00:13s\n","\n","Early stopping occurred at epoch 22 with best_epoch = 12 and best_val_0_mse = 1.6751400232315063\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 12:03:29,161] Trial 52 finished with value: 1.6751445531845093 and parameters: {'n_d': 19, 'n_steps': 3, 'gamma': 1.3030709796391158, 'n_independent': 1, 'n_shared': 5, 'momentum': 0.2789747801064434}. Best is trial 31 with value: 0.07662469148635864.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 123.19361| val_0_mse: 49222.06640625|  0:00:00s\n","epoch 1  | loss: 50.87137| val_0_mse: 23328.68359375|  0:00:01s\n","epoch 2  | loss: 7.12438 | val_0_mse: 11516.4111328125|  0:00:01s\n","epoch 3  | loss: 1.64385 | val_0_mse: 5013.60986328125|  0:00:02s\n","epoch 4  | loss: 0.39794 | val_0_mse: 4187.755859375|  0:00:03s\n","epoch 5  | loss: 0.24417 | val_0_mse: 994.59326171875|  0:00:03s\n","epoch 6  | loss: 0.21938 | val_0_mse: 831.5252685546875|  0:00:04s\n","epoch 7  | loss: 0.18757 | val_0_mse: 662.2192993164062|  0:00:04s\n","epoch 8  | loss: 0.18371 | val_0_mse: 422.6125183105469|  0:00:05s\n","epoch 9  | loss: 0.16063 | val_0_mse: 323.23321533203125|  0:00:06s\n","epoch 10 | loss: 0.14678 | val_0_mse: 45.51136016845703|  0:00:06s\n","epoch 11 | loss: 0.13674 | val_0_mse: 39.3679313659668|  0:00:07s\n","epoch 12 | loss: 0.13052 | val_0_mse: 17.125139236450195|  0:00:08s\n","epoch 13 | loss: 0.13196 | val_0_mse: 36.61478042602539|  0:00:08s\n","epoch 14 | loss: 0.17258 | val_0_mse: 38.8827018737793|  0:00:09s\n","epoch 15 | loss: 0.1549  | val_0_mse: 16.37537956237793|  0:00:09s\n","epoch 16 | loss: 0.12376 | val_0_mse: 12.687580108642578|  0:00:10s\n","epoch 17 | loss: 0.11358 | val_0_mse: 12.024060249328613|  0:00:10s\n","epoch 18 | loss: 0.12007 | val_0_mse: 14.088330268859863|  0:00:11s\n","epoch 19 | loss: 0.11492 | val_0_mse: 13.686869621276855|  0:00:12s\n","epoch 20 | loss: 0.10831 | val_0_mse: 8.192770004272461|  0:00:12s\n","epoch 21 | loss: 0.12977 | val_0_mse: 4.230169773101807|  0:00:13s\n","epoch 22 | loss: 0.13467 | val_0_mse: 6.265260219573975|  0:00:14s\n","epoch 23 | loss: 0.12135 | val_0_mse: 4.789559841156006|  0:00:14s\n","epoch 24 | loss: 0.1263  | val_0_mse: 9.767709732055664|  0:00:15s\n","epoch 25 | loss: 0.11409 | val_0_mse: 13.900500297546387|  0:00:15s\n","epoch 26 | loss: 0.09942 | val_0_mse: 7.456920146942139|  0:00:16s\n","epoch 27 | loss: 0.09696 | val_0_mse: 8.933719635009766|  0:00:17s\n","epoch 28 | loss: 0.10169 | val_0_mse: 8.991530418395996|  0:00:17s\n","epoch 29 | loss: 0.10731 | val_0_mse: 12.755579948425293|  0:00:18s\n","epoch 30 | loss: 0.10701 | val_0_mse: 12.335160255432129|  0:00:18s\n","epoch 31 | loss: 0.10102 | val_0_mse: 10.79932975769043|  0:00:19s\n","\n","Early stopping occurred at epoch 31 with best_epoch = 21 and best_val_0_mse = 4.230169773101807\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 12:03:49,034] Trial 53 finished with value: 4.230167388916016 and parameters: {'n_d': 11, 'n_steps': 3, 'gamma': 1.1312515692746863, 'n_independent': 1, 'n_shared': 5, 'momentum': 0.2605708927453575}. Best is trial 31 with value: 0.07662469148635864.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 97.12263| val_0_mse: 9283.52734375|  0:00:00s\n","epoch 1  | loss: 11.13855| val_0_mse: 12903.2822265625|  0:00:01s\n","epoch 2  | loss: 1.45987 | val_0_mse: 301.6053466796875|  0:00:01s\n","epoch 3  | loss: 0.45422 | val_0_mse: 317.30572509765625|  0:00:02s\n","epoch 4  | loss: 0.30134 | val_0_mse: 335.52752685546875|  0:00:03s\n","epoch 5  | loss: 0.29598 | val_0_mse: 129.66653442382812|  0:00:03s\n","epoch 6  | loss: 0.21272 | val_0_mse: 33.75265884399414|  0:00:04s\n","epoch 7  | loss: 0.19956 | val_0_mse: 33.36764907836914|  0:00:04s\n","epoch 8  | loss: 0.18845 | val_0_mse: 36.47861862182617|  0:00:05s\n","epoch 9  | loss: 0.20197 | val_0_mse: 49.964881896972656|  0:00:06s\n","epoch 10 | loss: 0.16764 | val_0_mse: 86.41063690185547|  0:00:06s\n","epoch 11 | loss: 0.17402 | val_0_mse: 47.324581146240234|  0:00:07s\n","epoch 12 | loss: 0.15918 | val_0_mse: 12.115819931030273|  0:00:08s\n","epoch 13 | loss: 0.15541 | val_0_mse: 24.041790008544922|  0:00:08s\n","epoch 14 | loss: 0.13996 | val_0_mse: 1.3980799913406372|  0:00:09s\n","epoch 15 | loss: 0.16229 | val_0_mse: 10.201419830322266|  0:00:09s\n","epoch 16 | loss: 0.13811 | val_0_mse: 5.8475799560546875|  0:00:10s\n","epoch 17 | loss: 0.13438 | val_0_mse: 5.360020160675049|  0:00:11s\n","epoch 18 | loss: 0.13045 | val_0_mse: 2.569920063018799|  0:00:11s\n","epoch 19 | loss: 0.12597 | val_0_mse: 2.8864901065826416|  0:00:12s\n","epoch 20 | loss: 0.11674 | val_0_mse: 1.7454700469970703|  0:00:12s\n","epoch 21 | loss: 0.11346 | val_0_mse: 2.197279930114746|  0:00:13s\n","epoch 22 | loss: 0.1054  | val_0_mse: 2.032140016555786|  0:00:14s\n","epoch 23 | loss: 0.11085 | val_0_mse: 1.1186399459838867|  0:00:14s\n","epoch 24 | loss: 0.10317 | val_0_mse: 1.6580899953842163|  0:00:15s\n","epoch 25 | loss: 0.10606 | val_0_mse: 0.8504499793052673|  0:00:15s\n","epoch 26 | loss: 0.10345 | val_0_mse: 1.8546099662780762|  0:00:16s\n","epoch 27 | loss: 0.11172 | val_0_mse: 0.7656599879264832|  0:00:17s\n","epoch 28 | loss: 0.10933 | val_0_mse: 1.4764800071716309|  0:00:17s\n","epoch 29 | loss: 0.12946 | val_0_mse: 0.5255600214004517|  0:00:18s\n","epoch 30 | loss: 0.11198 | val_0_mse: 0.9977999925613403|  0:00:18s\n","epoch 31 | loss: 0.11136 | val_0_mse: 0.39983999729156494|  0:00:19s\n","epoch 32 | loss: 0.10668 | val_0_mse: 0.3761500120162964|  0:00:20s\n","epoch 33 | loss: 0.0985  | val_0_mse: 0.39864999055862427|  0:00:20s\n","epoch 34 | loss: 0.10448 | val_0_mse: 0.37766000628471375|  0:00:21s\n","epoch 35 | loss: 0.09837 | val_0_mse: 0.47971001267433167|  0:00:21s\n","epoch 36 | loss: 0.10584 | val_0_mse: 0.504800021648407|  0:00:22s\n","epoch 37 | loss: 0.09744 | val_0_mse: 0.5848299860954285|  0:00:23s\n","epoch 38 | loss: 0.09434 | val_0_mse: 0.5971400141716003|  0:00:23s\n","epoch 39 | loss: 0.09973 | val_0_mse: 0.4374600052833557|  0:00:24s\n","epoch 40 | loss: 0.09913 | val_0_mse: 0.4916499853134155|  0:00:24s\n","epoch 41 | loss: 0.09688 | val_0_mse: 0.4450100064277649|  0:00:25s\n","epoch 42 | loss: 0.11099 | val_0_mse: 0.4012700021266937|  0:00:26s\n","\n","Early stopping occurred at epoch 42 with best_epoch = 32 and best_val_0_mse = 0.3761500120162964\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 12:04:15,515] Trial 54 finished with value: 0.37615206837654114 and parameters: {'n_d': 16, 'n_steps': 3, 'gamma': 1.0073562821516762, 'n_independent': 1, 'n_shared': 5, 'momentum': 0.30877118708864576}. Best is trial 31 with value: 0.07662469148635864.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 150.63297| val_0_mse: 1266.090576171875|  0:00:00s\n","epoch 1  | loss: 102.43001| val_0_mse: 2267.689453125|  0:00:01s\n","epoch 2  | loss: 41.74241| val_0_mse: 7524.32373046875|  0:00:02s\n","epoch 3  | loss: 5.37247 | val_0_mse: 210.02403259277344|  0:00:03s\n","epoch 4  | loss: 1.80205 | val_0_mse: 40.2259407043457|  0:00:04s\n","epoch 5  | loss: 0.61741 | val_0_mse: 30.461719512939453|  0:00:04s\n","epoch 6  | loss: 0.3692  | val_0_mse: 20.992300033569336|  0:00:05s\n","epoch 7  | loss: 0.27188 | val_0_mse: 13.044159889221191|  0:00:06s\n","epoch 8  | loss: 0.23836 | val_0_mse: 12.938730239868164|  0:00:07s\n","epoch 9  | loss: 0.26334 | val_0_mse: 3.3368101119995117|  0:00:08s\n","epoch 10 | loss: 0.20637 | val_0_mse: 3.882469892501831|  0:00:08s\n","epoch 11 | loss: 0.20001 | val_0_mse: 4.230820178985596|  0:00:09s\n","epoch 12 | loss: 0.17954 | val_0_mse: 3.7480900287628174|  0:00:10s\n","epoch 13 | loss: 0.17347 | val_0_mse: 1.836300015449524|  0:00:11s\n","epoch 14 | loss: 0.16351 | val_0_mse: 0.9972800016403198|  0:00:12s\n","epoch 15 | loss: 0.14772 | val_0_mse: 0.9005799889564514|  0:00:12s\n","epoch 16 | loss: 0.14754 | val_0_mse: 0.8372600078582764|  0:00:13s\n","epoch 17 | loss: 0.14389 | val_0_mse: 0.5295199751853943|  0:00:14s\n","epoch 18 | loss: 0.1435  | val_0_mse: 0.47753000259399414|  0:00:15s\n","epoch 19 | loss: 0.13984 | val_0_mse: 0.5486599802970886|  0:00:16s\n","epoch 20 | loss: 0.13546 | val_0_mse: 0.6352099776268005|  0:00:17s\n","epoch 21 | loss: 0.13057 | val_0_mse: 0.4096199870109558|  0:00:17s\n","epoch 22 | loss: 0.1356  | val_0_mse: 0.4598099887371063|  0:00:18s\n","epoch 23 | loss: 0.13148 | val_0_mse: 0.45910000801086426|  0:00:19s\n","epoch 24 | loss: 0.12946 | val_0_mse: 0.5419300198554993|  0:00:20s\n","epoch 25 | loss: 0.12906 | val_0_mse: 0.5750600099563599|  0:00:21s\n","epoch 26 | loss: 0.12837 | val_0_mse: 0.5321400165557861|  0:00:21s\n","epoch 27 | loss: 0.1243  | val_0_mse: 0.5292900204658508|  0:00:22s\n","epoch 28 | loss: 0.12266 | val_0_mse: 0.5864700078964233|  0:00:23s\n","epoch 29 | loss: 0.12582 | val_0_mse: 0.5613600015640259|  0:00:24s\n","epoch 30 | loss: 0.11563 | val_0_mse: 0.4701400101184845|  0:00:25s\n","epoch 31 | loss: 0.12846 | val_0_mse: 0.48653000593185425|  0:00:26s\n","\n","Early stopping occurred at epoch 31 with best_epoch = 21 and best_val_0_mse = 0.4096199870109558\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 12:04:41,969] Trial 55 finished with value: 0.4096240997314453 and parameters: {'n_d': 8, 'n_steps': 4, 'gamma': 1.1852147508575128, 'n_independent': 2, 'n_shared': 5, 'momentum': 0.33764289726921193}. Best is trial 31 with value: 0.07662469148635864.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 52.11359| val_0_mse: 13397.318359375|  0:00:00s\n","epoch 1  | loss: 2.6069  | val_0_mse: 1840.040771484375|  0:00:00s\n","epoch 2  | loss: 0.54032 | val_0_mse: 941.3394165039062|  0:00:01s\n","epoch 3  | loss: 0.3867  | val_0_mse: 2078.233642578125|  0:00:01s\n","epoch 4  | loss: 0.28036 | val_0_mse: 450.72039794921875|  0:00:02s\n","epoch 5  | loss: 0.2447  | val_0_mse: 96.26883697509766|  0:00:02s\n","epoch 6  | loss: 0.25218 | val_0_mse: 85.30589294433594|  0:00:03s\n","epoch 7  | loss: 0.22171 | val_0_mse: 131.03765869140625|  0:00:03s\n","epoch 8  | loss: 0.23471 | val_0_mse: 72.89691925048828|  0:00:04s\n","epoch 9  | loss: 0.21122 | val_0_mse: 100.3722915649414|  0:00:04s\n","epoch 10 | loss: 0.20013 | val_0_mse: 57.72711944580078|  0:00:05s\n","epoch 11 | loss: 0.23178 | val_0_mse: 82.5586166381836|  0:00:05s\n","epoch 12 | loss: 0.18813 | val_0_mse: 68.30799102783203|  0:00:06s\n","epoch 13 | loss: 0.17578 | val_0_mse: 54.45668029785156|  0:00:06s\n","epoch 14 | loss: 0.16268 | val_0_mse: 55.787139892578125|  0:00:07s\n","epoch 15 | loss: 0.14589 | val_0_mse: 22.112979888916016|  0:00:07s\n","epoch 16 | loss: 0.14439 | val_0_mse: 35.207698822021484|  0:00:08s\n","epoch 17 | loss: 0.13311 | val_0_mse: 19.92197036743164|  0:00:08s\n","epoch 18 | loss: 0.1853  | val_0_mse: 20.788219451904297|  0:00:08s\n","epoch 19 | loss: 0.1698  | val_0_mse: 11.29181957244873|  0:00:09s\n","epoch 20 | loss: 0.14541 | val_0_mse: 7.411759853363037|  0:00:09s\n","epoch 21 | loss: 0.12979 | val_0_mse: 7.437349796295166|  0:00:10s\n","epoch 22 | loss: 0.12299 | val_0_mse: 2.9834799766540527|  0:00:10s\n","epoch 23 | loss: 0.12855 | val_0_mse: 2.07492995262146|  0:00:11s\n","epoch 24 | loss: 0.12687 | val_0_mse: 1.4587500095367432|  0:00:11s\n","epoch 25 | loss: 0.13009 | val_0_mse: 1.3934099674224854|  0:00:12s\n","epoch 26 | loss: 0.12564 | val_0_mse: 0.9672200083732605|  0:00:12s\n","epoch 27 | loss: 0.12534 | val_0_mse: 1.145419955253601|  0:00:13s\n","epoch 28 | loss: 0.14682 | val_0_mse: 1.3545700311660767|  0:00:13s\n","epoch 29 | loss: 0.1072  | val_0_mse: 1.0432699918746948|  0:00:14s\n","epoch 30 | loss: 0.10473 | val_0_mse: 0.9047499895095825|  0:00:14s\n","epoch 31 | loss: 0.10581 | val_0_mse: 0.9709100127220154|  0:00:15s\n","epoch 32 | loss: 0.10191 | val_0_mse: 1.321660041809082|  0:00:15s\n","epoch 33 | loss: 0.14132 | val_0_mse: 0.4716399908065796|  0:00:16s\n","epoch 34 | loss: 0.12354 | val_0_mse: 0.7105100154876709|  0:00:16s\n","epoch 35 | loss: 0.13773 | val_0_mse: 0.7188199758529663|  0:00:17s\n","epoch 36 | loss: 0.11305 | val_0_mse: 0.6921499967575073|  0:00:17s\n","epoch 37 | loss: 0.14296 | val_0_mse: 0.3103500008583069|  0:00:18s\n","epoch 38 | loss: 0.1374  | val_0_mse: 0.5241600275039673|  0:00:18s\n","epoch 39 | loss: 0.12927 | val_0_mse: 0.31202998757362366|  0:00:19s\n","epoch 40 | loss: 0.12267 | val_0_mse: 0.4356600046157837|  0:00:19s\n","epoch 41 | loss: 0.11561 | val_0_mse: 0.23199999332427979|  0:00:20s\n","epoch 42 | loss: 0.12509 | val_0_mse: 0.37272998690605164|  0:00:20s\n","epoch 43 | loss: 0.1242  | val_0_mse: 0.2013300061225891|  0:00:21s\n","epoch 44 | loss: 0.11612 | val_0_mse: 0.302619993686676|  0:00:21s\n","epoch 45 | loss: 0.12794 | val_0_mse: 0.1718599945306778|  0:00:22s\n","epoch 46 | loss: 0.12633 | val_0_mse: 0.29725000262260437|  0:00:22s\n","epoch 47 | loss: 0.11801 | val_0_mse: 0.14643000066280365|  0:00:22s\n","epoch 48 | loss: 0.11479 | val_0_mse: 0.22766999900341034|  0:00:23s\n","epoch 49 | loss: 0.11243 | val_0_mse: 0.12564000487327576|  0:00:23s\n","epoch 50 | loss: 0.11409 | val_0_mse: 0.21318000555038452|  0:00:24s\n","epoch 51 | loss: 0.11589 | val_0_mse: 0.12094999849796295|  0:00:24s\n","epoch 52 | loss: 0.10809 | val_0_mse: 0.20503999292850494|  0:00:25s\n","epoch 53 | loss: 0.11197 | val_0_mse: 0.11016999930143356|  0:00:25s\n","epoch 54 | loss: 0.1122  | val_0_mse: 0.21062999963760376|  0:00:26s\n","epoch 55 | loss: 0.11969 | val_0_mse: 0.10296999663114548|  0:00:26s\n","epoch 56 | loss: 0.11165 | val_0_mse: 0.17124000191688538|  0:00:27s\n","epoch 57 | loss: 0.1171  | val_0_mse: 0.10766000300645828|  0:00:27s\n","epoch 58 | loss: 0.11505 | val_0_mse: 0.14630000293254852|  0:00:28s\n","epoch 59 | loss: 0.11125 | val_0_mse: 0.10361000150442123|  0:00:28s\n","epoch 60 | loss: 0.11134 | val_0_mse: 0.13806000351905823|  0:00:29s\n","epoch 61 | loss: 0.11197 | val_0_mse: 0.09427999705076218|  0:00:29s\n","epoch 62 | loss: 0.09941 | val_0_mse: 0.09489999711513519|  0:00:30s\n","epoch 63 | loss: 0.09229 | val_0_mse: 0.0932300016283989|  0:00:30s\n","epoch 64 | loss: 0.09258 | val_0_mse: 0.08709000051021576|  0:00:30s\n","epoch 65 | loss: 0.08995 | val_0_mse: 0.09470000118017197|  0:00:31s\n","epoch 66 | loss: 0.08441 | val_0_mse: 0.09286999702453613|  0:00:31s\n","epoch 67 | loss: 0.0839  | val_0_mse: 0.0922200009226799|  0:00:32s\n","epoch 68 | loss: 0.0867  | val_0_mse: 0.10559000074863434|  0:00:32s\n","epoch 69 | loss: 0.10006 | val_0_mse: 0.10909000039100647|  0:00:33s\n","epoch 70 | loss: 0.12618 | val_0_mse: 0.08821000158786774|  0:00:33s\n","epoch 71 | loss: 0.09561 | val_0_mse: 0.10486999899148941|  0:00:34s\n","epoch 72 | loss: 0.09639 | val_0_mse: 0.09511999785900116|  0:00:34s\n","epoch 73 | loss: 0.08862 | val_0_mse: 0.09649000316858292|  0:00:35s\n","epoch 74 | loss: 0.09041 | val_0_mse: 0.0980599969625473|  0:00:35s\n","\n","Early stopping occurred at epoch 74 with best_epoch = 64 and best_val_0_mse = 0.08709000051021576\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 12:05:18,064] Trial 56 finished with value: 0.08708874136209488 and parameters: {'n_d': 40, 'n_steps': 3, 'gamma': 1.2397940784203278, 'n_independent': 1, 'n_shared': 3, 'momentum': 0.3659490700552247}. Best is trial 31 with value: 0.07662469148635864.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 57.30207| val_0_mse: 57645.85546875|  0:00:00s\n","epoch 1  | loss: 3.98771 | val_0_mse: 48689.609375|  0:00:01s\n","epoch 2  | loss: 1.10589 | val_0_mse: 1001.2348022460938|  0:00:02s\n","epoch 3  | loss: 0.63239 | val_0_mse: 2696.245849609375|  0:00:02s\n","epoch 4  | loss: 0.48697 | val_0_mse: 42903.8515625|  0:00:03s\n","epoch 5  | loss: 0.53614 | val_0_mse: 17449.078125|  0:00:04s\n","epoch 6  | loss: 0.37227 | val_0_mse: 5849.09033203125|  0:00:05s\n","epoch 7  | loss: 0.2915  | val_0_mse: 1143.5614013671875|  0:00:05s\n","epoch 8  | loss: 0.22549 | val_0_mse: 664.5614013671875|  0:00:06s\n","epoch 9  | loss: 0.18977 | val_0_mse: 781.3394165039062|  0:00:07s\n","epoch 10 | loss: 0.17901 | val_0_mse: 1057.8709716796875|  0:00:07s\n","epoch 11 | loss: 0.1569  | val_0_mse: 427.7830505371094|  0:00:08s\n","epoch 12 | loss: 0.13808 | val_0_mse: 286.47357177734375|  0:00:09s\n","epoch 13 | loss: 0.15262 | val_0_mse: 123.7728500366211|  0:00:10s\n","epoch 14 | loss: 0.14298 | val_0_mse: 133.52134704589844|  0:00:10s\n","epoch 15 | loss: 0.1405  | val_0_mse: 233.03256225585938|  0:00:11s\n","epoch 16 | loss: 0.13412 | val_0_mse: 174.8012237548828|  0:00:12s\n","epoch 17 | loss: 0.13147 | val_0_mse: 184.56790161132812|  0:00:13s\n","epoch 18 | loss: 0.11635 | val_0_mse: 138.3224334716797|  0:00:13s\n","epoch 19 | loss: 0.13317 | val_0_mse: 115.72367095947266|  0:00:14s\n","epoch 20 | loss: 0.15249 | val_0_mse: 109.71896362304688|  0:00:15s\n","epoch 21 | loss: 0.12354 | val_0_mse: 125.68282318115234|  0:00:15s\n","epoch 22 | loss: 0.12802 | val_0_mse: 114.2223892211914|  0:00:16s\n","epoch 23 | loss: 0.11669 | val_0_mse: 65.07620239257812|  0:00:17s\n","epoch 24 | loss: 0.11058 | val_0_mse: 79.67220306396484|  0:00:18s\n","epoch 25 | loss: 0.11548 | val_0_mse: 50.65581130981445|  0:00:18s\n","epoch 26 | loss: 0.1131  | val_0_mse: 34.12240982055664|  0:00:19s\n","epoch 27 | loss: 0.18896 | val_0_mse: 24.323339462280273|  0:00:20s\n","epoch 28 | loss: 0.23041 | val_0_mse: 16.85194969177246|  0:00:21s\n","epoch 29 | loss: 0.15407 | val_0_mse: 15.548250198364258|  0:00:21s\n","epoch 30 | loss: 0.14335 | val_0_mse: 8.787300109863281|  0:00:22s\n","epoch 31 | loss: 0.12581 | val_0_mse: 5.425360202789307|  0:00:23s\n","epoch 32 | loss: 0.11742 | val_0_mse: 4.303420066833496|  0:00:24s\n","epoch 33 | loss: 0.11504 | val_0_mse: 1.8474299907684326|  0:00:24s\n","epoch 34 | loss: 0.1363  | val_0_mse: 1.7004599571228027|  0:00:25s\n","epoch 35 | loss: 0.15106 | val_0_mse: 1.842919945716858|  0:00:26s\n","epoch 36 | loss: 0.11724 | val_0_mse: 1.0220099687576294|  0:00:26s\n","epoch 37 | loss: 0.12789 | val_0_mse: 1.1262099742889404|  0:00:27s\n","epoch 38 | loss: 0.12535 | val_0_mse: 0.3866899907588959|  0:00:28s\n","epoch 39 | loss: 0.13587 | val_0_mse: 0.5115000009536743|  0:00:29s\n","epoch 40 | loss: 0.12377 | val_0_mse: 0.23917999863624573|  0:00:29s\n","epoch 41 | loss: 0.12306 | val_0_mse: 0.3733200132846832|  0:00:30s\n","epoch 42 | loss: 0.1252  | val_0_mse: 0.2502399981021881|  0:00:31s\n","epoch 43 | loss: 0.1225  | val_0_mse: 0.4641000032424927|  0:00:32s\n","epoch 44 | loss: 0.1134  | val_0_mse: 0.24660000205039978|  0:00:32s\n","epoch 45 | loss: 0.11659 | val_0_mse: 0.3799299895763397|  0:00:33s\n","epoch 46 | loss: 0.11833 | val_0_mse: 0.16872000694274902|  0:00:34s\n","epoch 47 | loss: 0.11564 | val_0_mse: 0.2863999903202057|  0:00:34s\n","epoch 48 | loss: 0.12369 | val_0_mse: 0.15275000035762787|  0:00:35s\n","epoch 49 | loss: 0.11599 | val_0_mse: 0.31433001160621643|  0:00:36s\n","epoch 50 | loss: 0.1101  | val_0_mse: 0.12937000393867493|  0:00:37s\n","epoch 51 | loss: 0.11605 | val_0_mse: 0.20027999579906464|  0:00:37s\n","epoch 52 | loss: 0.11736 | val_0_mse: 0.11084000021219254|  0:00:38s\n","epoch 53 | loss: 0.10968 | val_0_mse: 0.19784000515937805|  0:00:39s\n","epoch 54 | loss: 0.11646 | val_0_mse: 0.11146000027656555|  0:00:39s\n","epoch 55 | loss: 0.11023 | val_0_mse: 0.18449999392032623|  0:00:40s\n","epoch 56 | loss: 0.11168 | val_0_mse: 0.11454000324010849|  0:00:41s\n","epoch 57 | loss: 0.13706 | val_0_mse: 0.4000200033187866|  0:00:42s\n","epoch 58 | loss: 0.20998 | val_0_mse: 0.30390000343322754|  0:00:42s\n","epoch 59 | loss: 0.15366 | val_0_mse: 0.14139999449253082|  0:00:43s\n","epoch 60 | loss: 0.15574 | val_0_mse: 0.15399999916553497|  0:00:44s\n","epoch 61 | loss: 0.13531 | val_0_mse: 0.15467000007629395|  0:00:44s\n","epoch 62 | loss: 0.12182 | val_0_mse: 0.10107000172138214|  0:00:45s\n","epoch 63 | loss: 0.11342 | val_0_mse: 0.15500999987125397|  0:00:46s\n","epoch 64 | loss: 0.11239 | val_0_mse: 0.11281999945640564|  0:00:47s\n","epoch 65 | loss: 0.1155  | val_0_mse: 0.1409900039434433|  0:00:47s\n","epoch 66 | loss: 0.11077 | val_0_mse: 0.09425999969244003|  0:00:48s\n","epoch 67 | loss: 0.11236 | val_0_mse: 0.12358000129461288|  0:00:49s\n","epoch 68 | loss: 0.10759 | val_0_mse: 0.10612999647855759|  0:00:50s\n","epoch 69 | loss: 0.12436 | val_0_mse: 0.17517000436782837|  0:00:50s\n","epoch 70 | loss: 0.11111 | val_0_mse: 0.11468999832868576|  0:00:51s\n","epoch 71 | loss: 0.10998 | val_0_mse: 0.13388000428676605|  0:00:52s\n","epoch 72 | loss: 0.10309 | val_0_mse: 0.10937000066041946|  0:00:53s\n","epoch 73 | loss: 0.09878 | val_0_mse: 0.09877999871969223|  0:00:53s\n","epoch 74 | loss: 0.11315 | val_0_mse: 0.20362000167369843|  0:00:54s\n","epoch 75 | loss: 0.11472 | val_0_mse: 0.1599300056695938|  0:00:55s\n","epoch 76 | loss: 0.14513 | val_0_mse: 0.16001999378204346|  0:00:55s\n","\n","Early stopping occurred at epoch 76 with best_epoch = 66 and best_val_0_mse = 0.09425999969244003\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 12:06:14,411] Trial 57 finished with value: 0.09426440298557281 and parameters: {'n_d': 24, 'n_steps': 4, 'gamma': 1.0791923015502902, 'n_independent': 1, 'n_shared': 5, 'momentum': 0.23723201935456492}. Best is trial 31 with value: 0.07662469148635864.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 69.22927| val_0_mse: 113425.234375|  0:00:00s\n","epoch 1  | loss: 6.17258 | val_0_mse: 20346.85546875|  0:00:00s\n","epoch 2  | loss: 1.02992 | val_0_mse: 6189.20947265625|  0:00:01s\n","epoch 3  | loss: 0.41565 | val_0_mse: 7385.03955078125|  0:00:01s\n","epoch 4  | loss: 0.30854 | val_0_mse: 5764.23291015625|  0:00:02s\n","epoch 5  | loss: 0.26126 | val_0_mse: 4839.70849609375|  0:00:02s\n","epoch 6  | loss: 0.20729 | val_0_mse: 3179.71484375|  0:00:03s\n","epoch 7  | loss: 0.20496 | val_0_mse: 1423.88330078125|  0:00:03s\n","epoch 8  | loss: 0.21822 | val_0_mse: 671.1467895507812|  0:00:04s\n","epoch 9  | loss: 0.19958 | val_0_mse: 301.4115295410156|  0:00:04s\n","epoch 10 | loss: 0.17606 | val_0_mse: 239.8328399658203|  0:00:05s\n","epoch 11 | loss: 0.18023 | val_0_mse: 170.24688720703125|  0:00:05s\n","epoch 12 | loss: 0.17146 | val_0_mse: 98.21449279785156|  0:00:06s\n","epoch 13 | loss: 0.16505 | val_0_mse: 127.43856811523438|  0:00:06s\n","epoch 14 | loss: 0.15358 | val_0_mse: 138.61053466796875|  0:00:06s\n","epoch 15 | loss: 0.14513 | val_0_mse: 99.57688903808594|  0:00:07s\n","epoch 16 | loss: 0.15065 | val_0_mse: 50.03681945800781|  0:00:07s\n","epoch 17 | loss: 0.12999 | val_0_mse: 38.816619873046875|  0:00:08s\n","epoch 18 | loss: 0.12041 | val_0_mse: 42.865440368652344|  0:00:08s\n","epoch 19 | loss: 0.11118 | val_0_mse: 34.048980712890625|  0:00:09s\n","epoch 20 | loss: 0.10855 | val_0_mse: 37.965579986572266|  0:00:09s\n","epoch 21 | loss: 0.1203  | val_0_mse: 22.29277992248535|  0:00:10s\n","epoch 22 | loss: 0.13241 | val_0_mse: 26.33806037902832|  0:00:10s\n","epoch 23 | loss: 0.11903 | val_0_mse: 15.35006046295166|  0:00:11s\n","epoch 24 | loss: 0.1103  | val_0_mse: 12.542269706726074|  0:00:11s\n","epoch 25 | loss: 0.1092  | val_0_mse: 14.678930282592773|  0:00:12s\n","epoch 26 | loss: 0.10551 | val_0_mse: 17.3452205657959|  0:00:12s\n","epoch 27 | loss: 0.10529 | val_0_mse: 9.492980003356934|  0:00:13s\n","epoch 28 | loss: 0.10175 | val_0_mse: 5.8541998863220215|  0:00:13s\n","epoch 29 | loss: 0.10344 | val_0_mse: 5.688089847564697|  0:00:14s\n","epoch 30 | loss: 0.09707 | val_0_mse: 4.769040107727051|  0:00:14s\n","epoch 31 | loss: 0.10537 | val_0_mse: 3.554419994354248|  0:00:15s\n","epoch 32 | loss: 0.11431 | val_0_mse: 3.7070300579071045|  0:00:15s\n","epoch 33 | loss: 0.11257 | val_0_mse: 2.495460033416748|  0:00:16s\n","epoch 34 | loss: 0.10902 | val_0_mse: 2.6795499324798584|  0:00:16s\n","epoch 35 | loss: 0.09949 | val_0_mse: 2.0681700706481934|  0:00:16s\n","epoch 36 | loss: 0.10429 | val_0_mse: 2.1095499992370605|  0:00:17s\n","epoch 37 | loss: 0.0956  | val_0_mse: 1.475950002670288|  0:00:17s\n","epoch 38 | loss: 0.09506 | val_0_mse: 1.2320300340652466|  0:00:18s\n","epoch 39 | loss: 0.09136 | val_0_mse: 0.911870002746582|  0:00:18s\n","epoch 40 | loss: 0.10273 | val_0_mse: 0.7570800185203552|  0:00:19s\n","epoch 41 | loss: 0.10863 | val_0_mse: 0.7723000049591064|  0:00:19s\n","epoch 42 | loss: 0.10332 | val_0_mse: 0.5592300295829773|  0:00:20s\n","epoch 43 | loss: 0.09924 | val_0_mse: 0.6475600004196167|  0:00:20s\n","epoch 44 | loss: 0.08985 | val_0_mse: 0.6232399940490723|  0:00:21s\n","epoch 45 | loss: 0.0883  | val_0_mse: 0.5504099726676941|  0:00:21s\n","epoch 46 | loss: 0.0936  | val_0_mse: 0.5239099860191345|  0:00:22s\n","epoch 47 | loss: 0.08949 | val_0_mse: 0.41266000270843506|  0:00:22s\n","epoch 48 | loss: 0.0851  | val_0_mse: 0.28262001276016235|  0:00:23s\n","epoch 49 | loss: 0.0843  | val_0_mse: 0.28207001090049744|  0:00:23s\n","epoch 50 | loss: 0.09553 | val_0_mse: 0.2574700117111206|  0:00:24s\n","epoch 51 | loss: 0.09985 | val_0_mse: 0.3055199980735779|  0:00:24s\n","epoch 52 | loss: 0.0934  | val_0_mse: 0.24650000035762787|  0:00:24s\n","epoch 53 | loss: 0.08968 | val_0_mse: 0.28115999698638916|  0:00:25s\n","epoch 54 | loss: 0.08611 | val_0_mse: 0.18750999867916107|  0:00:25s\n","epoch 55 | loss: 0.08415 | val_0_mse: 0.16179999709129333|  0:00:26s\n","epoch 56 | loss: 0.09783 | val_0_mse: 0.265749990940094|  0:00:26s\n","epoch 57 | loss: 0.09245 | val_0_mse: 0.12309999763965607|  0:00:27s\n","epoch 58 | loss: 0.08611 | val_0_mse: 0.09666000306606293|  0:00:27s\n","epoch 59 | loss: 0.09097 | val_0_mse: 0.16223999857902527|  0:00:28s\n","epoch 60 | loss: 0.08886 | val_0_mse: 0.13248999416828156|  0:00:28s\n","epoch 61 | loss: 0.09143 | val_0_mse: 0.10441000014543533|  0:00:29s\n","epoch 62 | loss: 0.08582 | val_0_mse: 0.10687000304460526|  0:00:29s\n","epoch 63 | loss: 0.08874 | val_0_mse: 0.08968000113964081|  0:00:30s\n","epoch 64 | loss: 0.08073 | val_0_mse: 0.11359000205993652|  0:00:30s\n","epoch 65 | loss: 0.08431 | val_0_mse: 0.1126599982380867|  0:00:30s\n","epoch 66 | loss: 0.08027 | val_0_mse: 0.10001999884843826|  0:00:31s\n","epoch 67 | loss: 0.07922 | val_0_mse: 0.08612000197172165|  0:00:32s\n","epoch 68 | loss: 0.07837 | val_0_mse: 0.09408000111579895|  0:00:32s\n","epoch 69 | loss: 0.08216 | val_0_mse: 0.09781000018119812|  0:00:33s\n","epoch 70 | loss: 0.08602 | val_0_mse: 0.08940000087022781|  0:00:33s\n","epoch 71 | loss: 0.08602 | val_0_mse: 0.08612000197172165|  0:00:33s\n","epoch 72 | loss: 0.08518 | val_0_mse: 0.08641999959945679|  0:00:34s\n","epoch 73 | loss: 0.08407 | val_0_mse: 0.08358000218868256|  0:00:34s\n","epoch 74 | loss: 0.0778  | val_0_mse: 0.08438000082969666|  0:00:35s\n","epoch 75 | loss: 0.07999 | val_0_mse: 0.08670999854803085|  0:00:35s\n","epoch 76 | loss: 0.07828 | val_0_mse: 0.0839800015091896|  0:00:36s\n","epoch 77 | loss: 0.08194 | val_0_mse: 0.0798100009560585|  0:00:36s\n","epoch 78 | loss: 0.07756 | val_0_mse: 0.08275999873876572|  0:00:37s\n","epoch 79 | loss: 0.08182 | val_0_mse: 0.10523000359535217|  0:00:37s\n","epoch 80 | loss: 0.08027 | val_0_mse: 0.09449999779462814|  0:00:38s\n","epoch 81 | loss: 0.0815  | val_0_mse: 0.08437000215053558|  0:00:38s\n","epoch 82 | loss: 0.09885 | val_0_mse: 0.08139999955892563|  0:00:39s\n","epoch 83 | loss: 0.0911  | val_0_mse: 0.08224999904632568|  0:00:39s\n","epoch 84 | loss: 0.08819 | val_0_mse: 0.08224999904632568|  0:00:39s\n","epoch 85 | loss: 0.08452 | val_0_mse: 0.08466999977827072|  0:00:40s\n","epoch 86 | loss: 0.08201 | val_0_mse: 0.08844000101089478|  0:00:40s\n","epoch 87 | loss: 0.09198 | val_0_mse: 0.1216999962925911|  0:00:41s\n","\n","Early stopping occurred at epoch 87 with best_epoch = 77 and best_val_0_mse = 0.0798100009560585\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 12:06:56,027] Trial 58 finished with value: 0.07980853319168091 and parameters: {'n_d': 17, 'n_steps': 3, 'gamma': 1.1407477544047189, 'n_independent': 2, 'n_shared': 2, 'momentum': 0.2108811442818767}. Best is trial 31 with value: 0.07662469148635864.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 65.30748| val_0_mse: 21616.72265625|  0:00:00s\n","epoch 1  | loss: 1.47671 | val_0_mse: 7350.63427734375|  0:00:01s\n","epoch 2  | loss: 0.61158 | val_0_mse: 1562.407470703125|  0:00:02s\n","epoch 3  | loss: 0.49341 | val_0_mse: 1791.360595703125|  0:00:03s\n","epoch 4  | loss: 0.29927 | val_0_mse: 3645.7568359375|  0:00:03s\n","epoch 5  | loss: 0.34932 | val_0_mse: 4800.67236328125|  0:00:04s\n","epoch 6  | loss: 0.30075 | val_0_mse: 2625.386474609375|  0:00:05s\n","epoch 7  | loss: 0.24488 | val_0_mse: 1613.65966796875|  0:00:05s\n","epoch 8  | loss: 0.23605 | val_0_mse: 1367.5328369140625|  0:00:06s\n","epoch 9  | loss: 0.20218 | val_0_mse: 1683.73876953125|  0:00:07s\n","epoch 10 | loss: 0.22663 | val_0_mse: 1841.681884765625|  0:00:08s\n","epoch 11 | loss: 0.21655 | val_0_mse: 2112.732421875|  0:00:08s\n","epoch 12 | loss: 0.1914  | val_0_mse: 898.9381103515625|  0:00:09s\n","epoch 13 | loss: 0.18315 | val_0_mse: 468.3934020996094|  0:00:10s\n","epoch 14 | loss: 0.16475 | val_0_mse: 390.8788757324219|  0:00:11s\n","epoch 15 | loss: 0.16351 | val_0_mse: 138.14492797851562|  0:00:12s\n","epoch 16 | loss: 0.14719 | val_0_mse: 160.27798461914062|  0:00:12s\n","epoch 17 | loss: 0.15028 | val_0_mse: 85.75093841552734|  0:00:13s\n","epoch 18 | loss: 0.14547 | val_0_mse: 76.95462036132812|  0:00:14s\n","epoch 19 | loss: 0.16235 | val_0_mse: 35.028900146484375|  0:00:15s\n","epoch 20 | loss: 0.15818 | val_0_mse: 39.9393310546875|  0:00:15s\n","epoch 21 | loss: 0.16468 | val_0_mse: 26.073959350585938|  0:00:16s\n","epoch 22 | loss: 0.13909 | val_0_mse: 30.802099227905273|  0:00:17s\n","epoch 23 | loss: 0.14971 | val_0_mse: 14.354310035705566|  0:00:18s\n","epoch 24 | loss: 0.14225 | val_0_mse: 16.899229049682617|  0:00:19s\n","epoch 25 | loss: 0.14235 | val_0_mse: 8.547490119934082|  0:00:19s\n","epoch 26 | loss: 0.13802 | val_0_mse: 11.116020202636719|  0:00:20s\n","epoch 27 | loss: 0.14041 | val_0_mse: 4.5223798751831055|  0:00:21s\n","epoch 28 | loss: 0.13983 | val_0_mse: 4.021200180053711|  0:00:22s\n","epoch 29 | loss: 0.14597 | val_0_mse: 4.051370143890381|  0:00:22s\n","epoch 30 | loss: 0.14788 | val_0_mse: 2.364609956741333|  0:00:23s\n","epoch 31 | loss: 0.13166 | val_0_mse: 5.027939796447754|  0:00:24s\n","epoch 32 | loss: 0.12305 | val_0_mse: 1.382290005683899|  0:00:25s\n","epoch 33 | loss: 0.11343 | val_0_mse: 1.1908299922943115|  0:00:25s\n","epoch 34 | loss: 0.17587 | val_0_mse: 1.2019399404525757|  0:00:26s\n","epoch 35 | loss: 0.13689 | val_0_mse: 0.4551900029182434|  0:00:27s\n","epoch 36 | loss: 0.12048 | val_0_mse: 0.5041300058364868|  0:00:28s\n","epoch 37 | loss: 0.14759 | val_0_mse: 0.9022499918937683|  0:00:28s\n","epoch 38 | loss: 0.18261 | val_0_mse: 0.34529000520706177|  0:00:29s\n","epoch 39 | loss: 0.22623 | val_0_mse: 0.27511999011039734|  0:00:30s\n","epoch 40 | loss: 0.21337 | val_0_mse: 0.3915799856185913|  0:00:31s\n","epoch 41 | loss: 0.19226 | val_0_mse: 0.22434000670909882|  0:00:31s\n","epoch 42 | loss: 0.18958 | val_0_mse: 0.24950000643730164|  0:00:32s\n","epoch 43 | loss: 0.16632 | val_0_mse: 0.3360300064086914|  0:00:33s\n","epoch 44 | loss: 0.17143 | val_0_mse: 0.5722600221633911|  0:00:34s\n","epoch 45 | loss: 0.17577 | val_0_mse: 0.5209000110626221|  0:00:34s\n","epoch 46 | loss: 0.16524 | val_0_mse: 0.25859999656677246|  0:00:35s\n","epoch 47 | loss: 0.18718 | val_0_mse: 0.18717999756336212|  0:00:36s\n","epoch 48 | loss: 0.12297 | val_0_mse: 0.29826000332832336|  0:00:37s\n","epoch 49 | loss: 0.1047  | val_0_mse: 0.23976999521255493|  0:00:38s\n","epoch 50 | loss: 0.09704 | val_0_mse: 0.1951500028371811|  0:00:38s\n","epoch 51 | loss: 0.11598 | val_0_mse: 0.22779999673366547|  0:00:39s\n","epoch 52 | loss: 0.11451 | val_0_mse: 0.217739999294281|  0:00:40s\n","epoch 53 | loss: 0.11623 | val_0_mse: 0.13926999270915985|  0:00:41s\n","epoch 54 | loss: 0.10727 | val_0_mse: 0.13845999538898468|  0:00:41s\n","epoch 55 | loss: 0.09963 | val_0_mse: 0.185589998960495|  0:00:42s\n","epoch 56 | loss: 0.10017 | val_0_mse: 0.11118000000715256|  0:00:43s\n","epoch 57 | loss: 0.10504 | val_0_mse: 0.12336000055074692|  0:00:44s\n","epoch 58 | loss: 0.09451 | val_0_mse: 0.10305000096559525|  0:00:44s\n","epoch 59 | loss: 0.10325 | val_0_mse: 0.10260000079870224|  0:00:45s\n","epoch 60 | loss: 0.19074 | val_0_mse: 0.17239999771118164|  0:00:46s\n","epoch 61 | loss: 0.14948 | val_0_mse: 0.13718000054359436|  0:00:47s\n","epoch 62 | loss: 0.13528 | val_0_mse: 0.11607000231742859|  0:00:47s\n","epoch 63 | loss: 0.22859 | val_0_mse: 0.21379999816417694|  0:00:48s\n","epoch 64 | loss: 0.18545 | val_0_mse: 0.14985999464988708|  0:00:49s\n","epoch 65 | loss: 0.16685 | val_0_mse: 0.09769999980926514|  0:00:50s\n","epoch 66 | loss: 0.16086 | val_0_mse: 0.14737999439239502|  0:00:50s\n","epoch 67 | loss: 0.15626 | val_0_mse: 0.21663999557495117|  0:00:51s\n","epoch 68 | loss: 0.15235 | val_0_mse: 0.19957999885082245|  0:00:52s\n","epoch 69 | loss: 0.15429 | val_0_mse: 0.10412999987602234|  0:00:53s\n","epoch 70 | loss: 0.14561 | val_0_mse: 0.12362000346183777|  0:00:53s\n","epoch 71 | loss: 0.16295 | val_0_mse: 0.19771000742912292|  0:00:54s\n","epoch 72 | loss: 0.16501 | val_0_mse: 0.13955000042915344|  0:00:55s\n","epoch 73 | loss: 0.168   | val_0_mse: 0.12330999970436096|  0:00:56s\n","epoch 74 | loss: 0.12639 | val_0_mse: 0.10318999737501144|  0:00:57s\n","epoch 75 | loss: 0.09581 | val_0_mse: 0.10526999831199646|  0:00:57s\n","\n","Early stopping occurred at epoch 75 with best_epoch = 65 and best_val_0_mse = 0.09769999980926514\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 12:07:54,252] Trial 59 finished with value: 0.09769628942012787 and parameters: {'n_d': 32, 'n_steps': 5, 'gamma': 1.1372751857574588, 'n_independent': 3, 'n_shared': 2, 'momentum': 0.17360690220588043}. Best is trial 31 with value: 0.07662469148635864.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 21.48095| val_0_mse: 61968.8125|  0:00:00s\n","epoch 1  | loss: 2.4079  | val_0_mse: 5884.6474609375|  0:00:01s\n","epoch 2  | loss: 1.96628 | val_0_mse: 5809.32470703125|  0:00:02s\n","epoch 3  | loss: 1.11236 | val_0_mse: 1653.770263671875|  0:00:03s\n","epoch 4  | loss: 0.52021 | val_0_mse: 183.4021759033203|  0:00:04s\n","epoch 5  | loss: 0.41275 | val_0_mse: 142.1325225830078|  0:00:05s\n","epoch 6  | loss: 0.34579 | val_0_mse: 53.15372085571289|  0:00:06s\n","epoch 7  | loss: 0.40232 | val_0_mse: 64.71272277832031|  0:00:07s\n","epoch 8  | loss: 0.29116 | val_0_mse: 44.70743942260742|  0:00:08s\n","epoch 9  | loss: 0.30768 | val_0_mse: 17.061119079589844|  0:00:09s\n","epoch 10 | loss: 0.37611 | val_0_mse: 42.84117889404297|  0:00:10s\n","epoch 11 | loss: 0.40833 | val_0_mse: 74.83348083496094|  0:00:11s\n","epoch 12 | loss: 0.27989 | val_0_mse: 54.61663055419922|  0:00:12s\n","epoch 13 | loss: 0.26945 | val_0_mse: 14.6537504196167|  0:00:13s\n","epoch 14 | loss: 0.46185 | val_0_mse: 5.370160102844238|  0:00:14s\n","epoch 15 | loss: 0.33163 | val_0_mse: 10.819600105285645|  0:00:15s\n","epoch 16 | loss: 0.23268 | val_0_mse: 5.803490161895752|  0:00:16s\n","epoch 17 | loss: 0.19942 | val_0_mse: 6.850910186767578|  0:00:17s\n","epoch 18 | loss: 0.17881 | val_0_mse: 4.093850135803223|  0:00:17s\n","epoch 19 | loss: 0.18697 | val_0_mse: 5.102359771728516|  0:00:18s\n","epoch 20 | loss: 0.20457 | val_0_mse: 2.3689000606536865|  0:00:19s\n","epoch 21 | loss: 0.19969 | val_0_mse: 5.872910022735596|  0:00:20s\n","epoch 22 | loss: 0.22818 | val_0_mse: 2.3429698944091797|  0:00:21s\n","epoch 23 | loss: 0.21433 | val_0_mse: 6.089159965515137|  0:00:22s\n","epoch 24 | loss: 0.19699 | val_0_mse: 3.129539966583252|  0:00:23s\n","epoch 25 | loss: 0.181   | val_0_mse: 4.418869972229004|  0:00:24s\n","epoch 26 | loss: 0.13576 | val_0_mse: 0.9110000133514404|  0:00:25s\n","epoch 27 | loss: 0.22825 | val_0_mse: 0.551829993724823|  0:00:26s\n","epoch 28 | loss: 0.24674 | val_0_mse: 1.2973599433898926|  0:00:27s\n","epoch 29 | loss: 0.21011 | val_0_mse: 0.6930099725723267|  0:00:28s\n","epoch 30 | loss: 0.1977  | val_0_mse: 1.048949956893921|  0:00:28s\n","epoch 31 | loss: 0.2521  | val_0_mse: 1.2790000438690186|  0:00:29s\n","epoch 32 | loss: 0.16302 | val_0_mse: 0.5566499829292297|  0:00:30s\n","epoch 33 | loss: 0.15019 | val_0_mse: 0.5772600173950195|  0:00:31s\n","epoch 34 | loss: 0.16589 | val_0_mse: 0.673259973526001|  0:00:32s\n","epoch 35 | loss: 0.14669 | val_0_mse: 0.3243600130081177|  0:00:33s\n","epoch 36 | loss: 0.14423 | val_0_mse: 0.4526500105857849|  0:00:34s\n","epoch 37 | loss: 0.13799 | val_0_mse: 0.5159599781036377|  0:00:35s\n","epoch 38 | loss: 0.1397  | val_0_mse: 0.44071999192237854|  0:00:36s\n","epoch 39 | loss: 0.13708 | val_0_mse: 0.25804001092910767|  0:00:37s\n","epoch 40 | loss: 0.13141 | val_0_mse: 0.23267999291419983|  0:00:38s\n","epoch 41 | loss: 0.13301 | val_0_mse: 0.2037999927997589|  0:00:38s\n","epoch 42 | loss: 0.17776 | val_0_mse: 0.34650999307632446|  0:00:39s\n","epoch 43 | loss: 0.16736 | val_0_mse: 0.16921000182628632|  0:00:40s\n","epoch 44 | loss: 0.1569  | val_0_mse: 0.3097899854183197|  0:00:41s\n","epoch 45 | loss: 0.16996 | val_0_mse: 0.18645000457763672|  0:00:42s\n","epoch 46 | loss: 0.11558 | val_0_mse: 0.24764999747276306|  0:00:43s\n","epoch 47 | loss: 0.14067 | val_0_mse: 0.22976000607013702|  0:00:44s\n","epoch 48 | loss: 0.12641 | val_0_mse: 0.19745999574661255|  0:00:45s\n","epoch 49 | loss: 0.12719 | val_0_mse: 0.21038000285625458|  0:00:46s\n","epoch 50 | loss: 0.1389  | val_0_mse: 0.1552799940109253|  0:00:47s\n","epoch 51 | loss: 0.1931  | val_0_mse: 0.6773599982261658|  0:00:48s\n","epoch 52 | loss: 0.21262 | val_0_mse: 0.12009000033140182|  0:00:49s\n","epoch 53 | loss: 0.16474 | val_0_mse: 0.3480199873447418|  0:00:50s\n","epoch 54 | loss: 0.24328 | val_0_mse: 0.3913800120353699|  0:00:51s\n","epoch 55 | loss: 0.23327 | val_0_mse: 0.33906999230384827|  0:00:52s\n","epoch 56 | loss: 0.22106 | val_0_mse: 0.18876999616622925|  0:00:53s\n","epoch 57 | loss: 0.20294 | val_0_mse: 0.12156999856233597|  0:00:53s\n","epoch 58 | loss: 0.20123 | val_0_mse: 0.23804999887943268|  0:00:54s\n","epoch 59 | loss: 0.24467 | val_0_mse: 0.10611999779939651|  0:00:55s\n","epoch 60 | loss: 0.14458 | val_0_mse: 0.2055799961090088|  0:00:56s\n","epoch 61 | loss: 0.2301  | val_0_mse: 0.23330000042915344|  0:00:57s\n","epoch 62 | loss: 0.13348 | val_0_mse: 0.12417999655008316|  0:00:58s\n","epoch 63 | loss: 0.10913 | val_0_mse: 0.1261499971151352|  0:00:59s\n","epoch 64 | loss: 0.1065  | val_0_mse: 0.09777999669313431|  0:01:00s\n","epoch 65 | loss: 0.11179 | val_0_mse: 0.10452999919652939|  0:01:01s\n","epoch 66 | loss: 0.11214 | val_0_mse: 0.11817000061273575|  0:01:02s\n","epoch 67 | loss: 0.11457 | val_0_mse: 0.15439000725746155|  0:01:03s\n","epoch 68 | loss: 0.11858 | val_0_mse: 0.13321000337600708|  0:01:04s\n","epoch 69 | loss: 0.13704 | val_0_mse: 0.23488999903202057|  0:01:05s\n","epoch 70 | loss: 0.15543 | val_0_mse: 0.11869999766349792|  0:01:05s\n","epoch 71 | loss: 0.12428 | val_0_mse: 0.12432999908924103|  0:01:06s\n","epoch 72 | loss: 0.14804 | val_0_mse: 0.2185399979352951|  0:01:07s\n","epoch 73 | loss: 0.16468 | val_0_mse: 0.16978000104427338|  0:01:08s\n","epoch 74 | loss: 0.161   | val_0_mse: 0.12852999567985535|  0:01:09s\n","\n","Early stopping occurred at epoch 74 with best_epoch = 64 and best_val_0_mse = 0.09777999669313431\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 12:09:04,192] Trial 60 finished with value: 0.09777820855379105 and parameters: {'n_d': 28, 'n_steps': 9, 'gamma': 1.0591274372949304, 'n_independent': 2, 'n_shared': 1, 'momentum': 0.14302192002053182}. Best is trial 31 with value: 0.07662469148635864.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 71.0146 | val_0_mse: 118830.1015625|  0:00:00s\n","epoch 1  | loss: 5.88385 | val_0_mse: 58500.84375|  0:00:01s\n","epoch 2  | loss: 0.76335 | val_0_mse: 22279.02734375|  0:00:01s\n","epoch 3  | loss: 0.40267 | val_0_mse: 964.2140502929688|  0:00:01s\n","epoch 4  | loss: 0.31264 | val_0_mse: 134.3595733642578|  0:00:02s\n","epoch 5  | loss: 0.25409 | val_0_mse: 301.81060791015625|  0:00:03s\n","epoch 6  | loss: 0.23476 | val_0_mse: 273.2045593261719|  0:00:03s\n","epoch 7  | loss: 0.20498 | val_0_mse: 815.0562133789062|  0:00:03s\n","epoch 8  | loss: 0.22779 | val_0_mse: 949.9201049804688|  0:00:04s\n","epoch 9  | loss: 0.20685 | val_0_mse: 572.1951293945312|  0:00:04s\n","epoch 10 | loss: 0.1798  | val_0_mse: 189.1421356201172|  0:00:05s\n","epoch 11 | loss: 0.15832 | val_0_mse: 25.060819625854492|  0:00:05s\n","epoch 12 | loss: 0.1534  | val_0_mse: 22.189170837402344|  0:00:06s\n","epoch 13 | loss: 0.21394 | val_0_mse: 62.975341796875|  0:00:06s\n","epoch 14 | loss: 0.20603 | val_0_mse: 7.912169933319092|  0:00:07s\n","epoch 15 | loss: 0.20022 | val_0_mse: 4.688010215759277|  0:00:07s\n","epoch 16 | loss: 0.16047 | val_0_mse: 0.41172000765800476|  0:00:08s\n","epoch 17 | loss: 0.13928 | val_0_mse: 3.2386300563812256|  0:00:08s\n","epoch 18 | loss: 0.13126 | val_0_mse: 5.945230007171631|  0:00:09s\n","epoch 19 | loss: 0.12582 | val_0_mse: 4.7837300300598145|  0:00:09s\n","epoch 20 | loss: 0.12706 | val_0_mse: 2.051379919052124|  0:00:10s\n","epoch 21 | loss: 0.11539 | val_0_mse: 2.75219988822937|  0:00:10s\n","epoch 22 | loss: 0.12135 | val_0_mse: 1.3046200275421143|  0:00:11s\n","epoch 23 | loss: 0.12148 | val_0_mse: 2.7092199325561523|  0:00:11s\n","epoch 24 | loss: 0.12556 | val_0_mse: 4.002449989318848|  0:00:11s\n","epoch 25 | loss: 0.12212 | val_0_mse: 6.814239978790283|  0:00:12s\n","epoch 26 | loss: 0.12282 | val_0_mse: 4.2399702072143555|  0:00:12s\n","\n","Early stopping occurred at epoch 26 with best_epoch = 16 and best_val_0_mse = 0.41172000765800476\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 12:09:17,387] Trial 61 finished with value: 0.41171786189079285 and parameters: {'n_d': 17, 'n_steps': 3, 'gamma': 1.2238375669841792, 'n_independent': 2, 'n_shared': 2, 'momentum': 0.20313449875252282}. Best is trial 31 with value: 0.07662469148635864.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 58.30466| val_0_mse: 8652.4921875|  0:00:00s\n","epoch 1  | loss: 4.0311  | val_0_mse: 1010.295654296875|  0:00:00s\n","epoch 2  | loss: 0.66875 | val_0_mse: 712.4507446289062|  0:00:01s\n","epoch 3  | loss: 0.32948 | val_0_mse: 226.43838500976562|  0:00:01s\n","epoch 4  | loss: 0.27015 | val_0_mse: 300.0290832519531|  0:00:02s\n","epoch 5  | loss: 0.26741 | val_0_mse: 163.8313751220703|  0:00:02s\n","epoch 6  | loss: 0.23407 | val_0_mse: 114.11868286132812|  0:00:03s\n","epoch 7  | loss: 0.20109 | val_0_mse: 66.48731994628906|  0:00:03s\n","epoch 8  | loss: 0.20097 | val_0_mse: 37.23984146118164|  0:00:04s\n","epoch 9  | loss: 0.16884 | val_0_mse: 18.755779266357422|  0:00:04s\n","epoch 10 | loss: 0.15358 | val_0_mse: 19.770009994506836|  0:00:05s\n","epoch 11 | loss: 0.15413 | val_0_mse: 14.636199951171875|  0:00:05s\n","epoch 12 | loss: 0.13973 | val_0_mse: 7.559160232543945|  0:00:06s\n","epoch 13 | loss: 0.15497 | val_0_mse: 13.223859786987305|  0:00:06s\n","epoch 14 | loss: 0.14903 | val_0_mse: 6.3313398361206055|  0:00:07s\n","epoch 15 | loss: 0.1365  | val_0_mse: 3.785290002822876|  0:00:07s\n","epoch 16 | loss: 0.13092 | val_0_mse: 4.163020133972168|  0:00:08s\n","epoch 17 | loss: 0.15153 | val_0_mse: 30.03775978088379|  0:00:08s\n","epoch 18 | loss: 0.13879 | val_0_mse: 48.05813980102539|  0:00:09s\n","epoch 19 | loss: 0.13855 | val_0_mse: 15.485179901123047|  0:00:09s\n","epoch 20 | loss: 0.13124 | val_0_mse: 11.346619606018066|  0:00:10s\n","epoch 21 | loss: 0.12609 | val_0_mse: 22.934480667114258|  0:00:10s\n","epoch 22 | loss: 0.1228  | val_0_mse: 16.638639450073242|  0:00:11s\n","epoch 23 | loss: 0.11575 | val_0_mse: 15.895400047302246|  0:00:11s\n","epoch 24 | loss: 0.12417 | val_0_mse: 25.902660369873047|  0:00:11s\n","epoch 25 | loss: 0.11321 | val_0_mse: 22.492429733276367|  0:00:12s\n","\n","Early stopping occurred at epoch 25 with best_epoch = 15 and best_val_0_mse = 3.785290002822876\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 12:09:30,083] Trial 62 finished with value: 3.7852866649627686 and parameters: {'n_d': 13, 'n_steps': 3, 'gamma': 1.2860443473721352, 'n_independent': 2, 'n_shared': 2, 'momentum': 0.2665143644148379}. Best is trial 31 with value: 0.07662469148635864.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 82.30935| val_0_mse: 212625.546875|  0:00:00s\n","epoch 1  | loss: 7.18105 | val_0_mse: 3841.8671875|  0:00:01s\n","epoch 2  | loss: 1.1445  | val_0_mse: 8449.095703125|  0:00:01s\n","epoch 3  | loss: 0.43195 | val_0_mse: 2824.21337890625|  0:00:02s\n","epoch 4  | loss: 0.3448  | val_0_mse: 6438.40087890625|  0:00:02s\n","epoch 5  | loss: 0.28336 | val_0_mse: 2509.48095703125|  0:00:03s\n","epoch 6  | loss: 0.25798 | val_0_mse: 1908.8135986328125|  0:00:03s\n","epoch 7  | loss: 0.24602 | val_0_mse: 1179.301025390625|  0:00:04s\n","epoch 8  | loss: 0.2009  | val_0_mse: 630.912353515625|  0:00:04s\n","epoch 9  | loss: 0.19161 | val_0_mse: 544.692138671875|  0:00:05s\n","epoch 10 | loss: 0.19373 | val_0_mse: 342.67279052734375|  0:00:05s\n","epoch 11 | loss: 0.17429 | val_0_mse: 79.40596771240234|  0:00:06s\n","epoch 12 | loss: 0.15504 | val_0_mse: 33.123878479003906|  0:00:06s\n","epoch 13 | loss: 0.15575 | val_0_mse: 8.834830284118652|  0:00:07s\n","epoch 14 | loss: 0.14496 | val_0_mse: 4.178659915924072|  0:00:07s\n","epoch 15 | loss: 0.13627 | val_0_mse: 7.199379920959473|  0:00:08s\n","epoch 16 | loss: 0.14301 | val_0_mse: 1.491379976272583|  0:00:09s\n","epoch 17 | loss: 0.13862 | val_0_mse: 0.9484400153160095|  0:00:09s\n","epoch 18 | loss: 0.12993 | val_0_mse: 5.2121100425720215|  0:00:10s\n","epoch 19 | loss: 0.14018 | val_0_mse: 3.779330015182495|  0:00:10s\n","epoch 20 | loss: 0.14653 | val_0_mse: 7.169280052185059|  0:00:11s\n","epoch 21 | loss: 0.13307 | val_0_mse: 4.458270072937012|  0:00:11s\n","epoch 22 | loss: 0.12218 | val_0_mse: 5.131400108337402|  0:00:12s\n","epoch 23 | loss: 0.11588 | val_0_mse: 2.9967100620269775|  0:00:12s\n","epoch 24 | loss: 0.1142  | val_0_mse: 1.9693900346755981|  0:00:13s\n","epoch 25 | loss: 0.11973 | val_0_mse: 5.137710094451904|  0:00:13s\n","epoch 26 | loss: 0.10789 | val_0_mse: 3.0400400161743164|  0:00:14s\n","epoch 27 | loss: 0.10572 | val_0_mse: 2.783090114593506|  0:00:15s\n","\n","Early stopping occurred at epoch 27 with best_epoch = 17 and best_val_0_mse = 0.9484400153160095\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 12:09:45,426] Trial 63 finished with value: 0.9484379887580872 and parameters: {'n_d': 18, 'n_steps': 3, 'gamma': 1.158040881430405, 'n_independent': 1, 'n_shared': 4, 'momentum': 0.2288353681039752}. Best is trial 31 with value: 0.07662469148635864.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 66.63003| val_0_mse: 71174.2890625|  0:00:00s\n","epoch 1  | loss: 5.46192 | val_0_mse: 40928.92578125|  0:00:01s\n","epoch 2  | loss: 0.91265 | val_0_mse: 1270.0228271484375|  0:00:01s\n","epoch 3  | loss: 0.4838  | val_0_mse: 4035.00341796875|  0:00:02s\n","epoch 4  | loss: 0.34895 | val_0_mse: 1713.5093994140625|  0:00:03s\n","epoch 5  | loss: 0.28197 | val_0_mse: 329.13824462890625|  0:00:03s\n","epoch 6  | loss: 0.25367 | val_0_mse: 148.41958618164062|  0:00:04s\n","epoch 7  | loss: 0.23995 | val_0_mse: 4.39316987991333|  0:00:05s\n","epoch 8  | loss: 0.21903 | val_0_mse: 2.8086299896240234|  0:00:05s\n","epoch 9  | loss: 0.21465 | val_0_mse: 28.132579803466797|  0:00:06s\n","epoch 10 | loss: 0.18882 | val_0_mse: 11.407039642333984|  0:00:07s\n","epoch 11 | loss: 0.17731 | val_0_mse: 4.37677001953125|  0:00:07s\n","epoch 12 | loss: 0.15836 | val_0_mse: 3.1513800621032715|  0:00:08s\n","epoch 13 | loss: 0.16468 | val_0_mse: 10.14264965057373|  0:00:09s\n","epoch 14 | loss: 0.25271 | val_0_mse: 8.51360034942627|  0:00:09s\n","epoch 15 | loss: 0.20918 | val_0_mse: 4.078780174255371|  0:00:10s\n","epoch 16 | loss: 0.1521  | val_0_mse: 1.828719973564148|  0:00:10s\n","epoch 17 | loss: 0.13463 | val_0_mse: 4.896870136260986|  0:00:11s\n","epoch 18 | loss: 0.13143 | val_0_mse: 2.9332199096679688|  0:00:12s\n","epoch 19 | loss: 0.1249  | val_0_mse: 1.2870800495147705|  0:00:12s\n","epoch 20 | loss: 0.12522 | val_0_mse: 1.0539499521255493|  0:00:13s\n","epoch 21 | loss: 0.12367 | val_0_mse: 1.9652600288391113|  0:00:14s\n","epoch 22 | loss: 0.16006 | val_0_mse: 1.1415499448776245|  0:00:14s\n","epoch 23 | loss: 0.21527 | val_0_mse: 0.8303800225257874|  0:00:15s\n","epoch 24 | loss: 0.1326  | val_0_mse: 0.9746900200843811|  0:00:16s\n","epoch 25 | loss: 0.13959 | val_0_mse: 0.5264599919319153|  0:00:16s\n","epoch 26 | loss: 0.1728  | val_0_mse: 0.7936800122261047|  0:00:17s\n","epoch 27 | loss: 0.14979 | val_0_mse: 0.6335300207138062|  0:00:18s\n","epoch 28 | loss: 0.13697 | val_0_mse: 0.8105000257492065|  0:00:18s\n","epoch 29 | loss: 0.13886 | val_0_mse: 0.44304001331329346|  0:00:19s\n","epoch 30 | loss: 0.12167 | val_0_mse: 0.37373000383377075|  0:00:20s\n","epoch 31 | loss: 0.14002 | val_0_mse: 0.7839000225067139|  0:00:20s\n","epoch 32 | loss: 0.1457  | val_0_mse: 0.8258000016212463|  0:00:21s\n","epoch 33 | loss: 0.13069 | val_0_mse: 0.664680004119873|  0:00:22s\n","epoch 34 | loss: 0.13097 | val_0_mse: 0.5180299878120422|  0:00:22s\n","epoch 35 | loss: 0.12777 | val_0_mse: 0.507669985294342|  0:00:23s\n","epoch 36 | loss: 0.11408 | val_0_mse: 0.44009000062942505|  0:00:24s\n","epoch 37 | loss: 0.11205 | val_0_mse: 0.37692999839782715|  0:00:24s\n","epoch 38 | loss: 0.10915 | val_0_mse: 0.3587999939918518|  0:00:25s\n","epoch 39 | loss: 0.11604 | val_0_mse: 0.4049299955368042|  0:00:26s\n","epoch 40 | loss: 0.10676 | val_0_mse: 0.3537899851799011|  0:00:26s\n","epoch 41 | loss: 0.11    | val_0_mse: 0.27487999200820923|  0:00:27s\n","epoch 42 | loss: 0.10378 | val_0_mse: 0.2544800043106079|  0:00:28s\n","epoch 43 | loss: 0.10813 | val_0_mse: 0.2070000022649765|  0:00:28s\n","epoch 44 | loss: 0.09884 | val_0_mse: 0.23929999768733978|  0:00:29s\n","epoch 45 | loss: 0.10123 | val_0_mse: 0.18559999763965607|  0:00:30s\n","epoch 46 | loss: 0.10399 | val_0_mse: 0.2053000032901764|  0:00:30s\n","epoch 47 | loss: 0.14497 | val_0_mse: 0.1953900009393692|  0:00:31s\n","epoch 48 | loss: 0.13349 | val_0_mse: 0.2180899977684021|  0:00:32s\n","epoch 49 | loss: 0.12197 | val_0_mse: 0.22227999567985535|  0:00:32s\n","epoch 50 | loss: 0.10766 | val_0_mse: 0.15922999382019043|  0:00:33s\n","epoch 51 | loss: 0.09999 | val_0_mse: 0.14722999930381775|  0:00:34s\n","epoch 52 | loss: 0.10123 | val_0_mse: 0.14160999655723572|  0:00:34s\n","epoch 53 | loss: 0.09352 | val_0_mse: 0.13293999433517456|  0:00:35s\n","epoch 54 | loss: 0.09289 | val_0_mse: 0.13503000140190125|  0:00:35s\n","epoch 55 | loss: 0.09011 | val_0_mse: 0.14219999313354492|  0:00:36s\n","epoch 56 | loss: 0.09904 | val_0_mse: 0.11388000100851059|  0:00:37s\n","epoch 57 | loss: 0.10014 | val_0_mse: 0.1433500051498413|  0:00:37s\n","epoch 58 | loss: 0.11293 | val_0_mse: 0.11737000197172165|  0:00:38s\n","epoch 59 | loss: 0.10364 | val_0_mse: 0.10597000271081924|  0:00:39s\n","epoch 60 | loss: 0.11437 | val_0_mse: 0.15476000308990479|  0:00:39s\n","epoch 61 | loss: 0.12085 | val_0_mse: 0.10621999949216843|  0:00:40s\n","epoch 62 | loss: 0.10467 | val_0_mse: 0.12717999517917633|  0:00:41s\n","epoch 63 | loss: 0.10985 | val_0_mse: 0.09373000264167786|  0:00:41s\n","epoch 64 | loss: 0.10502 | val_0_mse: 0.13843999803066254|  0:00:42s\n","epoch 65 | loss: 0.11258 | val_0_mse: 0.09672000259160995|  0:00:43s\n","epoch 66 | loss: 0.10706 | val_0_mse: 0.11034999787807465|  0:00:43s\n","epoch 67 | loss: 0.10901 | val_0_mse: 0.09967999905347824|  0:00:44s\n","epoch 68 | loss: 0.11228 | val_0_mse: 0.10570000112056732|  0:00:45s\n","epoch 69 | loss: 0.11105 | val_0_mse: 0.09009999781847|  0:00:45s\n","epoch 70 | loss: 0.09105 | val_0_mse: 0.08928000181913376|  0:00:46s\n","epoch 71 | loss: 0.09158 | val_0_mse: 0.09258999675512314|  0:00:47s\n","epoch 72 | loss: 0.09562 | val_0_mse: 0.09735000133514404|  0:00:47s\n","epoch 73 | loss: 0.09136 | val_0_mse: 0.09436000138521194|  0:00:48s\n","epoch 74 | loss: 0.09482 | val_0_mse: 0.09324999898672104|  0:00:49s\n","epoch 75 | loss: 0.09273 | val_0_mse: 0.09036999940872192|  0:00:49s\n","epoch 76 | loss: 0.08725 | val_0_mse: 0.09342999756336212|  0:00:50s\n","epoch 77 | loss: 0.09216 | val_0_mse: 0.09275999665260315|  0:00:51s\n","epoch 78 | loss: 0.09719 | val_0_mse: 0.1002499982714653|  0:00:51s\n","epoch 79 | loss: 0.133   | val_0_mse: 0.17743000388145447|  0:00:52s\n","epoch 80 | loss: 0.13589 | val_0_mse: 0.09809000045061111|  0:00:53s\n","\n","Early stopping occurred at epoch 80 with best_epoch = 70 and best_val_0_mse = 0.08928000181913376\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 12:10:38,771] Trial 64 finished with value: 0.08928468078374863 and parameters: {'n_d': 21, 'n_steps': 4, 'gamma': 1.4003907788672552, 'n_independent': 2, 'n_shared': 3, 'momentum': 0.290487764037365}. Best is trial 31 with value: 0.07662469148635864.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 74.63334| val_0_mse: 111210.484375|  0:00:00s\n","epoch 1  | loss: 8.56762 | val_0_mse: 194297.5625|  0:00:01s\n","epoch 2  | loss: 1.63217 | val_0_mse: 38484.56640625|  0:00:01s\n","epoch 3  | loss: 0.56964 | val_0_mse: 13323.5791015625|  0:00:02s\n","epoch 4  | loss: 0.35678 | val_0_mse: 3959.850830078125|  0:00:03s\n","epoch 5  | loss: 0.41167 | val_0_mse: 5067.45361328125|  0:00:03s\n","epoch 6  | loss: 0.30554 | val_0_mse: 2581.725830078125|  0:00:04s\n","epoch 7  | loss: 0.25238 | val_0_mse: 1142.412109375|  0:00:04s\n","epoch 8  | loss: 0.16757 | val_0_mse: 355.1436462402344|  0:00:05s\n","epoch 9  | loss: 0.15835 | val_0_mse: 349.5740051269531|  0:00:06s\n","epoch 10 | loss: 0.16175 | val_0_mse: 306.9843444824219|  0:00:06s\n","epoch 11 | loss: 0.14561 | val_0_mse: 277.08111572265625|  0:00:07s\n","epoch 12 | loss: 0.12847 | val_0_mse: 149.63302612304688|  0:00:07s\n","epoch 13 | loss: 0.13045 | val_0_mse: 130.01702880859375|  0:00:08s\n","epoch 14 | loss: 0.12631 | val_0_mse: 100.18222045898438|  0:00:09s\n","epoch 15 | loss: 0.1284  | val_0_mse: 69.05609893798828|  0:00:09s\n","epoch 16 | loss: 0.13071 | val_0_mse: 113.67091369628906|  0:00:10s\n","epoch 17 | loss: 0.12208 | val_0_mse: 78.88754272460938|  0:00:11s\n","epoch 18 | loss: 0.13465 | val_0_mse: 28.766769409179688|  0:00:11s\n","epoch 19 | loss: 0.13887 | val_0_mse: 43.17308044433594|  0:00:12s\n","epoch 20 | loss: 0.13493 | val_0_mse: 28.020240783691406|  0:00:12s\n","epoch 21 | loss: 0.12675 | val_0_mse: 37.02273941040039|  0:00:13s\n","epoch 22 | loss: 0.1185  | val_0_mse: 14.063179969787598|  0:00:14s\n","epoch 23 | loss: 0.11905 | val_0_mse: 10.42136001586914|  0:00:14s\n","epoch 24 | loss: 0.12411 | val_0_mse: 7.2761101722717285|  0:00:15s\n","epoch 25 | loss: 0.11661 | val_0_mse: 6.281209945678711|  0:00:16s\n","epoch 26 | loss: 0.11583 | val_0_mse: 4.534530162811279|  0:00:16s\n","epoch 27 | loss: 0.12891 | val_0_mse: 5.2654500007629395|  0:00:17s\n","epoch 28 | loss: 0.11688 | val_0_mse: 2.437730073928833|  0:00:18s\n","epoch 29 | loss: 0.12009 | val_0_mse: 1.02360999584198|  0:00:18s\n","epoch 30 | loss: 0.11647 | val_0_mse: 1.0844899415969849|  0:00:19s\n","epoch 31 | loss: 0.10936 | val_0_mse: 0.8218200206756592|  0:00:20s\n","epoch 32 | loss: 0.11089 | val_0_mse: 0.8427000045776367|  0:00:20s\n","epoch 33 | loss: 0.10554 | val_0_mse: 0.5607500076293945|  0:00:21s\n","epoch 34 | loss: 0.10088 | val_0_mse: 0.5141400098800659|  0:00:22s\n","epoch 35 | loss: 0.10224 | val_0_mse: 0.47975000739097595|  0:00:22s\n","epoch 36 | loss: 0.10339 | val_0_mse: 0.5246099829673767|  0:00:23s\n","epoch 37 | loss: 0.10563 | val_0_mse: 0.4079500138759613|  0:00:23s\n","epoch 38 | loss: 0.09858 | val_0_mse: 0.295089989900589|  0:00:24s\n","epoch 39 | loss: 0.0985  | val_0_mse: 0.31494998931884766|  0:00:25s\n","epoch 40 | loss: 0.09902 | val_0_mse: 0.307559996843338|  0:00:25s\n","epoch 41 | loss: 0.09979 | val_0_mse: 0.2880899906158447|  0:00:26s\n","epoch 42 | loss: 0.10224 | val_0_mse: 0.27880001068115234|  0:00:27s\n","epoch 43 | loss: 0.10609 | val_0_mse: 0.23935000598430634|  0:00:27s\n","epoch 44 | loss: 0.1052  | val_0_mse: 0.26636001467704773|  0:00:28s\n","epoch 45 | loss: 0.10328 | val_0_mse: 0.2711600065231323|  0:00:28s\n","epoch 46 | loss: 0.10527 | val_0_mse: 0.2347400039434433|  0:00:29s\n","epoch 47 | loss: 0.10042 | val_0_mse: 0.24268999695777893|  0:00:30s\n","epoch 48 | loss: 0.09586 | val_0_mse: 0.19384999573230743|  0:00:30s\n","epoch 49 | loss: 0.10464 | val_0_mse: 0.1785299926996231|  0:00:31s\n","epoch 50 | loss: 0.12461 | val_0_mse: 0.23205000162124634|  0:00:32s\n","epoch 51 | loss: 0.09957 | val_0_mse: 0.16846999526023865|  0:00:32s\n","epoch 52 | loss: 0.09965 | val_0_mse: 0.193900004029274|  0:00:33s\n","epoch 53 | loss: 0.09712 | val_0_mse: 0.14789000153541565|  0:00:34s\n","epoch 54 | loss: 0.09809 | val_0_mse: 0.15613999962806702|  0:00:34s\n","epoch 55 | loss: 0.09308 | val_0_mse: 0.16044999659061432|  0:00:35s\n","epoch 56 | loss: 0.09384 | val_0_mse: 0.19923999905586243|  0:00:35s\n","epoch 57 | loss: 0.10439 | val_0_mse: 0.12335000187158585|  0:00:36s\n","epoch 58 | loss: 0.09849 | val_0_mse: 0.11855000257492065|  0:00:37s\n","epoch 59 | loss: 0.0953  | val_0_mse: 0.11593999713659286|  0:00:37s\n","epoch 60 | loss: 0.09542 | val_0_mse: 0.10955999791622162|  0:00:38s\n","epoch 61 | loss: 0.09789 | val_0_mse: 0.11009000241756439|  0:00:39s\n","epoch 62 | loss: 0.09846 | val_0_mse: 0.14143000543117523|  0:00:39s\n","epoch 63 | loss: 0.10104 | val_0_mse: 0.1044199988245964|  0:00:40s\n","epoch 64 | loss: 0.09792 | val_0_mse: 0.11184000223875046|  0:00:41s\n","epoch 65 | loss: 0.0944  | val_0_mse: 0.10576999932527542|  0:00:41s\n","epoch 66 | loss: 0.09172 | val_0_mse: 0.11324000358581543|  0:00:42s\n","epoch 67 | loss: 0.09512 | val_0_mse: 0.10083000361919403|  0:00:43s\n","epoch 68 | loss: 0.09278 | val_0_mse: 0.10025999695062637|  0:00:43s\n","epoch 69 | loss: 0.09127 | val_0_mse: 0.10388000309467316|  0:00:44s\n","epoch 70 | loss: 0.08987 | val_0_mse: 0.09787999838590622|  0:00:45s\n","epoch 71 | loss: 0.09232 | val_0_mse: 0.10120999813079834|  0:00:45s\n","epoch 72 | loss: 0.09773 | val_0_mse: 0.12734000384807587|  0:00:46s\n","epoch 73 | loss: 0.109   | val_0_mse: 0.1261100023984909|  0:00:47s\n","epoch 74 | loss: 0.10137 | val_0_mse: 0.11240000277757645|  0:00:47s\n","epoch 75 | loss: 0.10478 | val_0_mse: 0.12370999902486801|  0:00:48s\n","epoch 76 | loss: 0.1042  | val_0_mse: 0.09766999632120132|  0:00:48s\n","epoch 77 | loss: 0.0942  | val_0_mse: 0.08852999657392502|  0:00:49s\n","epoch 78 | loss: 0.09273 | val_0_mse: 0.09362000226974487|  0:00:50s\n","epoch 79 | loss: 0.09149 | val_0_mse: 0.0964599996805191|  0:00:50s\n","epoch 80 | loss: 0.08794 | val_0_mse: 0.10741999745368958|  0:00:51s\n","epoch 81 | loss: 0.09216 | val_0_mse: 0.10346999764442444|  0:00:52s\n","epoch 82 | loss: 0.09152 | val_0_mse: 0.09408999979496002|  0:00:52s\n","epoch 83 | loss: 0.08912 | val_0_mse: 0.09803999960422516|  0:00:53s\n","epoch 84 | loss: 0.08875 | val_0_mse: 0.09949000179767609|  0:00:53s\n","epoch 85 | loss: 0.08854 | val_0_mse: 0.09617000073194504|  0:00:54s\n","epoch 86 | loss: 0.08513 | val_0_mse: 0.08827000111341476|  0:00:55s\n","epoch 87 | loss: 0.0894  | val_0_mse: 0.10344000160694122|  0:00:56s\n","epoch 88 | loss: 0.09531 | val_0_mse: 0.09390000253915787|  0:00:56s\n","epoch 89 | loss: 0.08791 | val_0_mse: 0.09289000183343887|  0:00:57s\n","epoch 90 | loss: 0.08777 | val_0_mse: 0.08992999792098999|  0:00:57s\n","epoch 91 | loss: 0.08538 | val_0_mse: 0.08628000319004059|  0:00:58s\n","epoch 92 | loss: 0.08478 | val_0_mse: 0.08928000181913376|  0:00:59s\n","epoch 93 | loss: 0.08209 | val_0_mse: 0.09495999664068222|  0:00:59s\n","epoch 94 | loss: 0.08538 | val_0_mse: 0.08702000230550766|  0:01:00s\n","epoch 95 | loss: 0.08531 | val_0_mse: 0.09482000023126602|  0:01:00s\n","epoch 96 | loss: 0.08858 | val_0_mse: 0.08979000151157379|  0:01:01s\n","epoch 97 | loss: 0.10222 | val_0_mse: 0.11437000334262848|  0:01:02s\n","epoch 98 | loss: 0.09032 | val_0_mse: 0.09528999775648117|  0:01:02s\n","epoch 99 | loss: 0.08901 | val_0_mse: 0.09216000139713287|  0:01:03s\n","Stop training because you reached max_epochs = 100 with best_epoch = 91 and best_val_0_mse = 0.08628000319004059\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 12:11:42,419] Trial 65 finished with value: 0.0862756296992302 and parameters: {'n_d': 11, 'n_steps': 3, 'gamma': 1.0979240731518873, 'n_independent': 5, 'n_shared': 1, 'momentum': 0.3286093689891541}. Best is trial 31 with value: 0.07662469148635864.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 55.82357| val_0_mse: 297767.25|  0:00:00s\n","epoch 1  | loss: 1.27049 | val_0_mse: 29952.623046875|  0:00:01s\n","epoch 2  | loss: 0.81415 | val_0_mse: 15342.0478515625|  0:00:01s\n","epoch 3  | loss: 0.42479 | val_0_mse: 7533.314453125|  0:00:02s\n","epoch 4  | loss: 0.34256 | val_0_mse: 5176.08154296875|  0:00:02s\n","epoch 5  | loss: 0.27098 | val_0_mse: 3492.7900390625|  0:00:03s\n","epoch 6  | loss: 0.24773 | val_0_mse: 1288.4835205078125|  0:00:04s\n","epoch 7  | loss: 0.27786 | val_0_mse: 1236.787353515625|  0:00:04s\n","epoch 8  | loss: 0.28022 | val_0_mse: 631.675537109375|  0:00:05s\n","epoch 9  | loss: 0.29618 | val_0_mse: 451.9149475097656|  0:00:05s\n","epoch 10 | loss: 0.23875 | val_0_mse: 284.3461608886719|  0:00:06s\n","epoch 11 | loss: 0.18673 | val_0_mse: 87.95752716064453|  0:00:06s\n","epoch 12 | loss: 0.16733 | val_0_mse: 22.88282012939453|  0:00:07s\n","epoch 13 | loss: 0.1665  | val_0_mse: 32.74161911010742|  0:00:07s\n","epoch 14 | loss: 0.16488 | val_0_mse: 45.453948974609375|  0:00:08s\n","epoch 15 | loss: 0.17816 | val_0_mse: 18.655879974365234|  0:00:09s\n","epoch 16 | loss: 0.16958 | val_0_mse: 22.246219635009766|  0:00:09s\n","epoch 17 | loss: 0.18243 | val_0_mse: 17.990459442138672|  0:00:10s\n","epoch 18 | loss: 0.16932 | val_0_mse: 14.035920143127441|  0:00:10s\n","epoch 19 | loss: 0.15437 | val_0_mse: 9.179180145263672|  0:00:11s\n","epoch 20 | loss: 0.14944 | val_0_mse: 9.02001953125|  0:00:11s\n","epoch 21 | loss: 0.13981 | val_0_mse: 6.897059917449951|  0:00:12s\n","epoch 22 | loss: 0.13927 | val_0_mse: 6.167840003967285|  0:00:12s\n","epoch 23 | loss: 0.16857 | val_0_mse: 5.004119873046875|  0:00:13s\n","epoch 24 | loss: 0.18766 | val_0_mse: 3.7464098930358887|  0:00:13s\n","epoch 25 | loss: 0.16687 | val_0_mse: 1.720139980316162|  0:00:14s\n","epoch 26 | loss: 0.14631 | val_0_mse: 1.727489948272705|  0:00:15s\n","epoch 27 | loss: 0.13907 | val_0_mse: 0.6951599717140198|  0:00:15s\n","epoch 28 | loss: 0.14178 | val_0_mse: 1.1966899633407593|  0:00:16s\n","epoch 29 | loss: 0.13776 | val_0_mse: 0.7329800128936768|  0:00:16s\n","epoch 30 | loss: 0.13357 | val_0_mse: 0.7613999843597412|  0:00:17s\n","epoch 31 | loss: 0.13928 | val_0_mse: 0.5711399912834167|  0:00:17s\n","epoch 32 | loss: 0.13357 | val_0_mse: 0.4902400076389313|  0:00:18s\n","epoch 33 | loss: 0.13452 | val_0_mse: 0.324180006980896|  0:00:18s\n","epoch 34 | loss: 0.13295 | val_0_mse: 0.6009399890899658|  0:00:19s\n","epoch 35 | loss: 0.13195 | val_0_mse: 0.2745699882507324|  0:00:20s\n","epoch 36 | loss: 0.14148 | val_0_mse: 0.41947001218795776|  0:00:20s\n","epoch 37 | loss: 0.13052 | val_0_mse: 0.2565099895000458|  0:00:21s\n","epoch 38 | loss: 0.13379 | val_0_mse: 0.4478600025177002|  0:00:21s\n","epoch 39 | loss: 0.13022 | val_0_mse: 0.2941400110721588|  0:00:22s\n","epoch 40 | loss: 0.122   | val_0_mse: 0.35958999395370483|  0:00:22s\n","epoch 41 | loss: 0.12904 | val_0_mse: 0.2307399958372116|  0:00:23s\n","epoch 42 | loss: 0.13207 | val_0_mse: 0.3192700147628784|  0:00:24s\n","epoch 43 | loss: 0.12643 | val_0_mse: 0.1920499950647354|  0:00:24s\n","epoch 44 | loss: 0.12563 | val_0_mse: 0.2949199974536896|  0:00:25s\n","epoch 45 | loss: 0.11983 | val_0_mse: 0.16759000718593597|  0:00:25s\n","epoch 46 | loss: 0.12576 | val_0_mse: 0.28428998589515686|  0:00:26s\n","epoch 47 | loss: 0.12024 | val_0_mse: 0.1404999941587448|  0:00:26s\n","epoch 48 | loss: 0.12354 | val_0_mse: 0.21297000348567963|  0:00:27s\n","epoch 49 | loss: 0.11938 | val_0_mse: 0.1829099953174591|  0:00:27s\n","epoch 50 | loss: 0.10277 | val_0_mse: 0.2013999968767166|  0:00:28s\n","epoch 51 | loss: 0.10764 | val_0_mse: 0.13811999559402466|  0:00:28s\n","epoch 52 | loss: 0.10602 | val_0_mse: 0.1612199991941452|  0:00:29s\n","epoch 53 | loss: 0.103   | val_0_mse: 0.15600000321865082|  0:00:30s\n","epoch 54 | loss: 0.10102 | val_0_mse: 0.19623999297618866|  0:00:30s\n","epoch 55 | loss: 0.10873 | val_0_mse: 0.1587499976158142|  0:00:31s\n","epoch 56 | loss: 0.10793 | val_0_mse: 0.11580999940633774|  0:00:31s\n","epoch 57 | loss: 0.11602 | val_0_mse: 0.10098999738693237|  0:00:32s\n","epoch 58 | loss: 0.10609 | val_0_mse: 0.2136400043964386|  0:00:32s\n","epoch 59 | loss: 0.18354 | val_0_mse: 0.2371399998664856|  0:00:33s\n","epoch 60 | loss: 0.11471 | val_0_mse: 0.09548000246286392|  0:00:33s\n","epoch 61 | loss: 0.09921 | val_0_mse: 0.09816999733448029|  0:00:34s\n","epoch 62 | loss: 0.09564 | val_0_mse: 0.11561000347137451|  0:00:34s\n","epoch 63 | loss: 0.09587 | val_0_mse: 0.10621000081300735|  0:00:35s\n","epoch 64 | loss: 0.08787 | val_0_mse: 0.1047699972987175|  0:00:35s\n","epoch 65 | loss: 0.08882 | val_0_mse: 0.0880500003695488|  0:00:36s\n","epoch 66 | loss: 0.08775 | val_0_mse: 0.09889999777078629|  0:00:37s\n","epoch 67 | loss: 0.09314 | val_0_mse: 0.10553999990224838|  0:00:37s\n","epoch 68 | loss: 0.08572 | val_0_mse: 0.09550999850034714|  0:00:38s\n","epoch 69 | loss: 0.08947 | val_0_mse: 0.09070000052452087|  0:00:38s\n","epoch 70 | loss: 0.09737 | val_0_mse: 0.09116999804973602|  0:00:39s\n","epoch 71 | loss: 0.08833 | val_0_mse: 0.08383999764919281|  0:00:39s\n","epoch 72 | loss: 0.08072 | val_0_mse: 0.08606000244617462|  0:00:40s\n","epoch 73 | loss: 0.08343 | val_0_mse: 0.09533999860286713|  0:00:40s\n","epoch 74 | loss: 0.09124 | val_0_mse: 0.08584000170230865|  0:00:41s\n","epoch 75 | loss: 0.08899 | val_0_mse: 0.090379998087883|  0:00:42s\n","epoch 76 | loss: 0.08868 | val_0_mse: 0.09527000039815903|  0:00:42s\n","epoch 77 | loss: 0.09662 | val_0_mse: 0.08671999722719193|  0:00:43s\n","epoch 78 | loss: 0.08615 | val_0_mse: 0.08528999984264374|  0:00:43s\n","epoch 79 | loss: 0.08055 | val_0_mse: 0.08087000250816345|  0:00:44s\n","epoch 80 | loss: 0.08699 | val_0_mse: 0.0853400006890297|  0:00:44s\n","epoch 81 | loss: 0.08128 | val_0_mse: 0.08123999834060669|  0:00:45s\n","epoch 82 | loss: 0.08181 | val_0_mse: 0.094030000269413|  0:00:45s\n","epoch 83 | loss: 0.09355 | val_0_mse: 0.07964000105857849|  0:00:46s\n","epoch 84 | loss: 0.08564 | val_0_mse: 0.09119000285863876|  0:00:47s\n","epoch 85 | loss: 0.09242 | val_0_mse: 0.08642999827861786|  0:00:47s\n","epoch 86 | loss: 0.09388 | val_0_mse: 0.08429999649524689|  0:00:48s\n","epoch 87 | loss: 0.1085  | val_0_mse: 0.09036000072956085|  0:00:48s\n","epoch 88 | loss: 0.10647 | val_0_mse: 0.0935399979352951|  0:00:49s\n","epoch 89 | loss: 0.10669 | val_0_mse: 0.09292999655008316|  0:00:49s\n","epoch 90 | loss: 0.10491 | val_0_mse: 0.09442000091075897|  0:00:50s\n","epoch 91 | loss: 0.10673 | val_0_mse: 0.089819997549057|  0:00:50s\n","epoch 92 | loss: 0.10097 | val_0_mse: 0.09337999671697617|  0:00:51s\n","epoch 93 | loss: 0.09826 | val_0_mse: 0.09363000094890594|  0:00:52s\n","\n","Early stopping occurred at epoch 93 with best_epoch = 83 and best_val_0_mse = 0.07964000105857849\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 12:12:34,719] Trial 66 finished with value: 0.07963748276233673 and parameters: {'n_d': 48, 'n_steps': 3, 'gamma': 1.3322126773569152, 'n_independent': 1, 'n_shared': 4, 'momentum': 0.21256486206988465}. Best is trial 31 with value: 0.07662469148635864.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 35.63852| val_0_mse: 7203.76708984375|  0:00:00s\n","epoch 1  | loss: 0.96589 | val_0_mse: 1001.3515014648438|  0:00:01s\n","epoch 2  | loss: 0.81478 | val_0_mse: 411.8045959472656|  0:00:01s\n","epoch 3  | loss: 0.49639 | val_0_mse: 563.6113891601562|  0:00:02s\n","epoch 4  | loss: 0.31407 | val_0_mse: 464.1937561035156|  0:00:03s\n","epoch 5  | loss: 0.27253 | val_0_mse: 29.096330642700195|  0:00:03s\n","epoch 6  | loss: 0.23328 | val_0_mse: 115.73648834228516|  0:00:04s\n","epoch 7  | loss: 0.18279 | val_0_mse: 215.25320434570312|  0:00:05s\n","epoch 8  | loss: 0.16589 | val_0_mse: 32.15951919555664|  0:00:05s\n","epoch 9  | loss: 0.18323 | val_0_mse: 47.318199157714844|  0:00:06s\n","epoch 10 | loss: 0.1642  | val_0_mse: 48.49919891357422|  0:00:07s\n","epoch 11 | loss: 0.17223 | val_0_mse: 26.652799606323242|  0:00:07s\n","epoch 12 | loss: 0.17052 | val_0_mse: 28.437700271606445|  0:00:08s\n","epoch 13 | loss: 0.14875 | val_0_mse: 48.83620834350586|  0:00:09s\n","epoch 14 | loss: 0.16099 | val_0_mse: 3.2893900871276855|  0:00:09s\n","epoch 15 | loss: 0.18365 | val_0_mse: 39.36933135986328|  0:00:10s\n","epoch 16 | loss: 0.16617 | val_0_mse: 14.864680290222168|  0:00:11s\n","epoch 17 | loss: 0.18213 | val_0_mse: 26.943309783935547|  0:00:11s\n","epoch 18 | loss: 0.20952 | val_0_mse: 12.044280052185059|  0:00:12s\n","epoch 19 | loss: 0.26358 | val_0_mse: 1.7723300457000732|  0:00:13s\n","epoch 20 | loss: 0.23102 | val_0_mse: 3.087019920349121|  0:00:13s\n","epoch 21 | loss: 0.19019 | val_0_mse: 3.1420600414276123|  0:00:14s\n","epoch 22 | loss: 0.16945 | val_0_mse: 3.8932700157165527|  0:00:15s\n","epoch 23 | loss: 0.14594 | val_0_mse: 2.5911099910736084|  0:00:15s\n","epoch 24 | loss: 0.15136 | val_0_mse: 5.4028801918029785|  0:00:16s\n","epoch 25 | loss: 0.13975 | val_0_mse: 1.7877700328826904|  0:00:17s\n","epoch 26 | loss: 0.15057 | val_0_mse: 0.6950700283050537|  0:00:17s\n","epoch 27 | loss: 0.13497 | val_0_mse: 0.8732699751853943|  0:00:18s\n","epoch 28 | loss: 0.12751 | val_0_mse: 1.0435600280761719|  0:00:19s\n","epoch 29 | loss: 0.1282  | val_0_mse: 0.6852700114250183|  0:00:19s\n","epoch 30 | loss: 0.12661 | val_0_mse: 0.6587200164794922|  0:00:20s\n","epoch 31 | loss: 0.11374 | val_0_mse: 0.8611599802970886|  0:00:21s\n","epoch 32 | loss: 0.15911 | val_0_mse: 0.6747099757194519|  0:00:22s\n","epoch 33 | loss: 0.18976 | val_0_mse: 0.931439995765686|  0:00:22s\n","epoch 34 | loss: 0.14019 | val_0_mse: 0.32199999690055847|  0:00:23s\n","epoch 35 | loss: 0.15175 | val_0_mse: 0.4444499909877777|  0:00:23s\n","epoch 36 | loss: 0.1344  | val_0_mse: 0.4316999912261963|  0:00:24s\n","epoch 37 | loss: 0.13553 | val_0_mse: 0.5944300293922424|  0:00:25s\n","epoch 38 | loss: 0.13682 | val_0_mse: 0.3229700028896332|  0:00:25s\n","epoch 39 | loss: 0.13899 | val_0_mse: 0.45236000418663025|  0:00:26s\n","epoch 40 | loss: 0.13684 | val_0_mse: 0.21863000094890594|  0:00:27s\n","epoch 41 | loss: 0.1339  | val_0_mse: 0.448170006275177|  0:00:27s\n","epoch 42 | loss: 0.1283  | val_0_mse: 0.2058199942111969|  0:00:28s\n","epoch 43 | loss: 0.12974 | val_0_mse: 0.3934600055217743|  0:00:29s\n","epoch 44 | loss: 0.12453 | val_0_mse: 0.1710200011730194|  0:00:29s\n","epoch 45 | loss: 0.12621 | val_0_mse: 0.3107999861240387|  0:00:30s\n","epoch 46 | loss: 0.12775 | val_0_mse: 0.18907000124454498|  0:00:31s\n","epoch 47 | loss: 0.13028 | val_0_mse: 0.26965001225471497|  0:00:31s\n","epoch 48 | loss: 0.12271 | val_0_mse: 0.16287000477313995|  0:00:32s\n","epoch 49 | loss: 0.12698 | val_0_mse: 0.2698499858379364|  0:00:33s\n","epoch 50 | loss: 0.12352 | val_0_mse: 0.14121000468730927|  0:00:33s\n","epoch 51 | loss: 0.13368 | val_0_mse: 0.2211800068616867|  0:00:34s\n","epoch 52 | loss: 0.13554 | val_0_mse: 0.13432000577449799|  0:00:35s\n","epoch 53 | loss: 0.13407 | val_0_mse: 0.18203000724315643|  0:00:35s\n","epoch 54 | loss: 0.12737 | val_0_mse: 0.12574000656604767|  0:00:36s\n","epoch 55 | loss: 0.13596 | val_0_mse: 0.20761999487876892|  0:00:37s\n","epoch 56 | loss: 0.12859 | val_0_mse: 0.11715999990701675|  0:00:37s\n","epoch 57 | loss: 0.12889 | val_0_mse: 0.1991499960422516|  0:00:38s\n","epoch 58 | loss: 0.12517 | val_0_mse: 0.11350999772548676|  0:00:39s\n","epoch 59 | loss: 0.12831 | val_0_mse: 0.17147000133991241|  0:00:39s\n","epoch 60 | loss: 0.12947 | val_0_mse: 0.10559999942779541|  0:00:40s\n","epoch 61 | loss: 0.13014 | val_0_mse: 0.14776000380516052|  0:00:41s\n","epoch 62 | loss: 0.12813 | val_0_mse: 0.11879999935626984|  0:00:41s\n","epoch 63 | loss: 0.13072 | val_0_mse: 0.1463800072669983|  0:00:42s\n","epoch 64 | loss: 0.12188 | val_0_mse: 0.10679999738931656|  0:00:43s\n","epoch 65 | loss: 0.09622 | val_0_mse: 0.10696999728679657|  0:00:43s\n","epoch 66 | loss: 0.0929  | val_0_mse: 0.11495000123977661|  0:00:44s\n","epoch 67 | loss: 0.10251 | val_0_mse: 0.14100000262260437|  0:00:45s\n","epoch 68 | loss: 0.10923 | val_0_mse: 0.1328199952840805|  0:00:45s\n","epoch 69 | loss: 0.11226 | val_0_mse: 0.12071000039577484|  0:00:46s\n","epoch 70 | loss: 0.13085 | val_0_mse: 0.16011999547481537|  0:00:47s\n","\n","Early stopping occurred at epoch 70 with best_epoch = 60 and best_val_0_mse = 0.10559999942779541\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 12:13:22,175] Trial 67 finished with value: 0.10560273379087448 and parameters: {'n_d': 47, 'n_steps': 4, 'gamma': 1.2650825947139983, 'n_independent': 1, 'n_shared': 4, 'momentum': 0.2092863128336619}. Best is trial 31 with value: 0.07662469148635864.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 53.02115| val_0_mse: 9534.1689453125|  0:00:00s\n","epoch 1  | loss: 1.50865 | val_0_mse: 189.37753295898438|  0:00:01s\n","epoch 2  | loss: 0.66117 | val_0_mse: 2999.65673828125|  0:00:01s\n","epoch 3  | loss: 0.43057 | val_0_mse: 239.30877685546875|  0:00:02s\n","epoch 4  | loss: 0.34075 | val_0_mse: 89.32421112060547|  0:00:03s\n","epoch 5  | loss: 0.24224 | val_0_mse: 240.84251403808594|  0:00:03s\n","epoch 6  | loss: 0.27696 | val_0_mse: 361.9667663574219|  0:00:04s\n","epoch 7  | loss: 0.3612  | val_0_mse: 686.2721557617188|  0:00:05s\n","epoch 8  | loss: 0.19722 | val_0_mse: 601.1650390625|  0:00:06s\n","epoch 9  | loss: 0.15915 | val_0_mse: 242.98843383789062|  0:00:06s\n","epoch 10 | loss: 0.1438  | val_0_mse: 185.5975341796875|  0:00:07s\n","epoch 11 | loss: 0.13366 | val_0_mse: 138.01519775390625|  0:00:08s\n","epoch 12 | loss: 0.1309  | val_0_mse: 111.92243194580078|  0:00:08s\n","epoch 13 | loss: 0.13188 | val_0_mse: 123.2577133178711|  0:00:09s\n","epoch 14 | loss: 0.13168 | val_0_mse: 88.86840057373047|  0:00:10s\n","epoch 15 | loss: 0.13299 | val_0_mse: 54.00693893432617|  0:00:10s\n","epoch 16 | loss: 0.12857 | val_0_mse: 51.78583908081055|  0:00:11s\n","epoch 17 | loss: 0.1146  | val_0_mse: 43.24808120727539|  0:00:12s\n","epoch 18 | loss: 0.12155 | val_0_mse: 37.52388000488281|  0:00:12s\n","epoch 19 | loss: 0.12033 | val_0_mse: 47.85919189453125|  0:00:13s\n","epoch 20 | loss: 0.11468 | val_0_mse: 45.28263854980469|  0:00:14s\n","epoch 21 | loss: 0.24345 | val_0_mse: 26.363239288330078|  0:00:15s\n","epoch 22 | loss: 0.21172 | val_0_mse: 2.260970115661621|  0:00:15s\n","epoch 23 | loss: 0.15896 | val_0_mse: 4.3961100578308105|  0:00:16s\n","epoch 24 | loss: 0.21753 | val_0_mse: 1.9663699865341187|  0:00:17s\n","epoch 25 | loss: 0.14017 | val_0_mse: 1.0640699863433838|  0:00:17s\n","epoch 26 | loss: 0.14735 | val_0_mse: 2.106489896774292|  0:00:18s\n","epoch 27 | loss: 0.1367  | val_0_mse: 1.491320013999939|  0:00:19s\n","epoch 28 | loss: 0.12282 | val_0_mse: 0.8060299754142761|  0:00:19s\n","epoch 29 | loss: 0.139   | val_0_mse: 1.8230899572372437|  0:00:20s\n","epoch 30 | loss: 0.1613  | val_0_mse: 1.000249981880188|  0:00:21s\n","epoch 31 | loss: 0.1496  | val_0_mse: 1.5591700077056885|  0:00:22s\n","epoch 32 | loss: 0.14858 | val_0_mse: 0.5295500159263611|  0:00:22s\n","epoch 33 | loss: 0.14021 | val_0_mse: 1.0502599477767944|  0:00:23s\n","epoch 34 | loss: 0.1273  | val_0_mse: 0.3550899922847748|  0:00:23s\n","epoch 35 | loss: 0.13196 | val_0_mse: 1.0238900184631348|  0:00:24s\n","epoch 36 | loss: 0.12514 | val_0_mse: 0.40678998827934265|  0:00:25s\n","epoch 37 | loss: 0.1279  | val_0_mse: 0.8338500261306763|  0:00:25s\n","epoch 38 | loss: 0.11796 | val_0_mse: 0.3289099931716919|  0:00:26s\n","epoch 39 | loss: 0.13207 | val_0_mse: 0.8252300024032593|  0:00:27s\n","epoch 40 | loss: 0.15801 | val_0_mse: 0.5293700098991394|  0:00:28s\n","epoch 41 | loss: 0.12695 | val_0_mse: 0.2547000050544739|  0:00:28s\n","epoch 42 | loss: 0.12229 | val_0_mse: 0.33542001247406006|  0:00:29s\n","epoch 43 | loss: 0.12974 | val_0_mse: 0.3658599853515625|  0:00:30s\n","epoch 44 | loss: 0.12696 | val_0_mse: 0.42991000413894653|  0:00:30s\n","epoch 45 | loss: 0.11889 | val_0_mse: 0.22339999675750732|  0:00:31s\n","epoch 46 | loss: 0.114   | val_0_mse: 0.36792999505996704|  0:00:32s\n","epoch 47 | loss: 0.11494 | val_0_mse: 0.18094000220298767|  0:00:32s\n","epoch 48 | loss: 0.11169 | val_0_mse: 0.29346001148223877|  0:00:33s\n","epoch 49 | loss: 0.11178 | val_0_mse: 0.1389400064945221|  0:00:34s\n","epoch 50 | loss: 0.11218 | val_0_mse: 0.2560099959373474|  0:00:34s\n","epoch 51 | loss: 0.10835 | val_0_mse: 0.15761999785900116|  0:00:35s\n","epoch 52 | loss: 0.10658 | val_0_mse: 0.18896999955177307|  0:00:36s\n","epoch 53 | loss: 0.11128 | val_0_mse: 0.12400999665260315|  0:00:36s\n","epoch 54 | loss: 0.10903 | val_0_mse: 0.22068999707698822|  0:00:37s\n","epoch 55 | loss: 0.11079 | val_0_mse: 0.10266000032424927|  0:00:38s\n","epoch 56 | loss: 0.10952 | val_0_mse: 0.22931000590324402|  0:00:38s\n","epoch 57 | loss: 0.1047  | val_0_mse: 0.11906000226736069|  0:00:39s\n","epoch 58 | loss: 0.08894 | val_0_mse: 0.1319900006055832|  0:00:40s\n","epoch 59 | loss: 0.09398 | val_0_mse: 0.1322699934244156|  0:00:41s\n","epoch 60 | loss: 0.08777 | val_0_mse: 0.11715000122785568|  0:00:41s\n","epoch 61 | loss: 0.08735 | val_0_mse: 0.14969000220298767|  0:00:42s\n","epoch 62 | loss: 0.09373 | val_0_mse: 0.11128000169992447|  0:00:43s\n","epoch 63 | loss: 0.08977 | val_0_mse: 0.10998000204563141|  0:00:43s\n","epoch 64 | loss: 0.09702 | val_0_mse: 0.12849999964237213|  0:00:44s\n","epoch 65 | loss: 0.09091 | val_0_mse: 0.11029999703168869|  0:00:45s\n","\n","Early stopping occurred at epoch 65 with best_epoch = 55 and best_val_0_mse = 0.10266000032424927\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 12:14:07,585] Trial 68 finished with value: 0.10265665501356125 and parameters: {'n_d': 52, 'n_steps': 3, 'gamma': 1.1890590050139425, 'n_independent': 4, 'n_shared': 3, 'momentum': 0.17191547199112656}. Best is trial 31 with value: 0.07662469148635864.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 66.96571| val_0_mse: 19658.6953125|  0:00:00s\n","epoch 1  | loss: 1.53494 | val_0_mse: 369.7699890136719|  0:00:01s\n","epoch 2  | loss: 0.80021 | val_0_mse: 4926.1103515625|  0:00:01s\n","epoch 3  | loss: 0.36317 | val_0_mse: 6105.08544921875|  0:00:02s\n","epoch 4  | loss: 0.3599  | val_0_mse: 1933.0328369140625|  0:00:03s\n","epoch 5  | loss: 0.28356 | val_0_mse: 189.04078674316406|  0:00:03s\n","epoch 6  | loss: 0.27334 | val_0_mse: 888.2033081054688|  0:00:04s\n","epoch 7  | loss: 0.29192 | val_0_mse: 184.1209259033203|  0:00:05s\n","epoch 8  | loss: 0.32257 | val_0_mse: 71.09275817871094|  0:00:05s\n","epoch 9  | loss: 0.2517  | val_0_mse: 8.521169662475586|  0:00:06s\n","epoch 10 | loss: 0.19858 | val_0_mse: 91.9093017578125|  0:00:07s\n","epoch 11 | loss: 0.19244 | val_0_mse: 124.07460021972656|  0:00:07s\n","epoch 12 | loss: 0.17078 | val_0_mse: 186.13340759277344|  0:00:08s\n","epoch 13 | loss: 0.20884 | val_0_mse: 279.9432067871094|  0:00:09s\n","epoch 14 | loss: 0.20872 | val_0_mse: 46.30453872680664|  0:00:09s\n","epoch 15 | loss: 0.20347 | val_0_mse: 57.07099914550781|  0:00:10s\n","epoch 16 | loss: 0.19149 | val_0_mse: 25.705299377441406|  0:00:11s\n","epoch 17 | loss: 0.17385 | val_0_mse: 23.996999740600586|  0:00:11s\n","epoch 18 | loss: 0.17131 | val_0_mse: 16.867210388183594|  0:00:12s\n","epoch 19 | loss: 0.17686 | val_0_mse: 19.5216007232666|  0:00:13s\n","\n","Early stopping occurred at epoch 19 with best_epoch = 9 and best_val_0_mse = 8.521169662475586\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 12:14:20,951] Trial 69 finished with value: 8.521174430847168 and parameters: {'n_d': 49, 'n_steps': 4, 'gamma': 1.1264035333965146, 'n_independent': 2, 'n_shared': 3, 'momentum': 0.3547180073077857}. Best is trial 31 with value: 0.07662469148635864.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 36.40863| val_0_mse: 573.02783203125|  0:00:00s\n","epoch 1  | loss: 0.98012 | val_0_mse: 275.4940185546875|  0:00:00s\n","epoch 2  | loss: 0.37184 | val_0_mse: 324.17901611328125|  0:00:01s\n","epoch 3  | loss: 0.2942  | val_0_mse: 263.9333801269531|  0:00:01s\n","epoch 4  | loss: 0.20469 | val_0_mse: 219.14068603515625|  0:00:01s\n","epoch 5  | loss: 0.19339 | val_0_mse: 139.95339965820312|  0:00:02s\n","epoch 6  | loss: 0.20659 | val_0_mse: 160.58055114746094|  0:00:02s\n","epoch 7  | loss: 0.2427  | val_0_mse: 61.011600494384766|  0:00:03s\n","epoch 8  | loss: 0.20227 | val_0_mse: 83.32144927978516|  0:00:03s\n","epoch 9  | loss: 0.18558 | val_0_mse: 44.80548858642578|  0:00:04s\n","epoch 10 | loss: 0.15686 | val_0_mse: 21.068479537963867|  0:00:04s\n","epoch 11 | loss: 0.13146 | val_0_mse: 17.119470596313477|  0:00:04s\n","epoch 12 | loss: 0.13743 | val_0_mse: 21.009159088134766|  0:00:05s\n","epoch 13 | loss: 0.14639 | val_0_mse: 16.29882049560547|  0:00:05s\n","epoch 14 | loss: 0.14857 | val_0_mse: 15.956259727478027|  0:00:06s\n","epoch 15 | loss: 0.18478 | val_0_mse: 21.06909942626953|  0:00:06s\n","epoch 16 | loss: 0.12913 | val_0_mse: 13.979439735412598|  0:00:07s\n","epoch 17 | loss: 0.1296  | val_0_mse: 7.6539201736450195|  0:00:07s\n","epoch 18 | loss: 0.16342 | val_0_mse: 9.045949935913086|  0:00:07s\n","epoch 19 | loss: 0.1604  | val_0_mse: 4.025040149688721|  0:00:08s\n","epoch 20 | loss: 0.15209 | val_0_mse: 5.458849906921387|  0:00:08s\n","epoch 21 | loss: 0.14315 | val_0_mse: 2.395859956741333|  0:00:09s\n","epoch 22 | loss: 0.14404 | val_0_mse: 4.62693977355957|  0:00:09s\n","epoch 23 | loss: 0.14246 | val_0_mse: 1.2957799434661865|  0:00:09s\n","epoch 24 | loss: 0.14492 | val_0_mse: 2.5850698947906494|  0:00:10s\n","epoch 25 | loss: 0.14428 | val_0_mse: 0.5942699909210205|  0:00:10s\n","epoch 26 | loss: 0.14218 | val_0_mse: 1.8433500528335571|  0:00:11s\n","epoch 27 | loss: 0.13725 | val_0_mse: 0.6018999814987183|  0:00:11s\n","epoch 28 | loss: 0.14245 | val_0_mse: 1.6061400175094604|  0:00:11s\n","epoch 29 | loss: 0.13617 | val_0_mse: 0.33017998933792114|  0:00:12s\n","epoch 30 | loss: 0.14123 | val_0_mse: 1.328220009803772|  0:00:12s\n","epoch 31 | loss: 0.14557 | val_0_mse: 0.3147299885749817|  0:00:13s\n","epoch 32 | loss: 0.13478 | val_0_mse: 0.6629800200462341|  0:00:13s\n","epoch 33 | loss: 0.13701 | val_0_mse: 0.26636001467704773|  0:00:13s\n","epoch 34 | loss: 0.13161 | val_0_mse: 0.6328700184822083|  0:00:14s\n","epoch 35 | loss: 0.14167 | val_0_mse: 0.34147000312805176|  0:00:14s\n","epoch 36 | loss: 0.15759 | val_0_mse: 0.4605399966239929|  0:00:15s\n","epoch 37 | loss: 0.13581 | val_0_mse: 0.40742000937461853|  0:00:15s\n","epoch 38 | loss: 0.128   | val_0_mse: 0.3596299886703491|  0:00:15s\n","epoch 39 | loss: 0.14817 | val_0_mse: 0.4535999894142151|  0:00:16s\n","epoch 40 | loss: 0.11827 | val_0_mse: 0.2648099958896637|  0:00:16s\n","epoch 41 | loss: 0.10938 | val_0_mse: 0.2291799932718277|  0:00:17s\n","epoch 42 | loss: 0.10835 | val_0_mse: 0.34586000442504883|  0:00:17s\n","epoch 43 | loss: 0.11357 | val_0_mse: 0.28422999382019043|  0:00:18s\n","epoch 44 | loss: 0.10727 | val_0_mse: 0.1984100043773651|  0:00:18s\n","epoch 45 | loss: 0.10171 | val_0_mse: 0.21332000195980072|  0:00:18s\n","epoch 46 | loss: 0.09805 | val_0_mse: 0.20350000262260437|  0:00:19s\n","epoch 47 | loss: 0.10512 | val_0_mse: 0.22606000304222107|  0:00:19s\n","epoch 48 | loss: 0.11056 | val_0_mse: 0.1710599958896637|  0:00:20s\n","epoch 49 | loss: 0.09341 | val_0_mse: 0.15734000504016876|  0:00:20s\n","epoch 50 | loss: 0.08918 | val_0_mse: 0.14735999703407288|  0:00:21s\n","epoch 51 | loss: 0.10431 | val_0_mse: 0.22304999828338623|  0:00:21s\n","epoch 52 | loss: 0.09883 | val_0_mse: 0.1742199957370758|  0:00:21s\n","epoch 53 | loss: 0.08977 | val_0_mse: 0.15589000284671783|  0:00:22s\n","epoch 54 | loss: 0.10119 | val_0_mse: 0.11841999739408493|  0:00:22s\n","epoch 55 | loss: 0.11219 | val_0_mse: 0.21191999316215515|  0:00:23s\n","epoch 56 | loss: 0.12942 | val_0_mse: 0.0974700003862381|  0:00:23s\n","epoch 57 | loss: 0.09994 | val_0_mse: 0.0933300033211708|  0:00:23s\n","epoch 58 | loss: 0.08947 | val_0_mse: 0.1464499980211258|  0:00:24s\n","epoch 59 | loss: 0.11036 | val_0_mse: 0.12752999365329742|  0:00:24s\n","epoch 60 | loss: 0.12368 | val_0_mse: 0.1843400001525879|  0:00:25s\n","epoch 61 | loss: 0.11835 | val_0_mse: 0.12334000319242477|  0:00:25s\n","epoch 62 | loss: 0.11923 | val_0_mse: 0.17550000548362732|  0:00:25s\n","epoch 63 | loss: 0.11861 | val_0_mse: 0.12278000265359879|  0:00:26s\n","epoch 64 | loss: 0.11427 | val_0_mse: 0.16997000575065613|  0:00:26s\n","epoch 65 | loss: 0.11187 | val_0_mse: 0.1131799966096878|  0:00:27s\n","epoch 66 | loss: 0.12197 | val_0_mse: 0.16943000257015228|  0:00:27s\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 12:14:49,184] Trial 70 finished with value: 0.09332501888275146 and parameters: {'n_d': 64, 'n_steps': 3, 'gamma': 1.2142874807837651, 'n_independent': 1, 'n_shared': 2, 'momentum': 0.2515930468929898}. Best is trial 31 with value: 0.07662469148635864.\n"]},{"output_type":"stream","name":"stdout","text":["epoch 67 | loss: 0.10974 | val_0_mse: 0.12075000256299973|  0:00:28s\n","\n","Early stopping occurred at epoch 67 with best_epoch = 57 and best_val_0_mse = 0.0933300033211708\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 85.57638| val_0_mse: 28136.7890625|  0:00:00s\n","epoch 1  | loss: 7.92804 | val_0_mse: 26901.46875|  0:00:01s\n","epoch 2  | loss: 1.15296 | val_0_mse: 12536.419921875|  0:00:01s\n","epoch 3  | loss: 0.46812 | val_0_mse: 3220.69384765625|  0:00:02s\n","epoch 4  | loss: 0.34665 | val_0_mse: 400.0045471191406|  0:00:03s\n","epoch 5  | loss: 0.3761  | val_0_mse: 20.509380340576172|  0:00:03s\n","epoch 6  | loss: 0.29507 | val_0_mse: 6.835010051727295|  0:00:04s\n","epoch 7  | loss: 0.21636 | val_0_mse: 39.748130798339844|  0:00:04s\n","epoch 8  | loss: 0.23206 | val_0_mse: 113.73399353027344|  0:00:05s\n","epoch 9  | loss: 0.1829  | val_0_mse: 351.8619689941406|  0:00:06s\n","epoch 10 | loss: 0.18268 | val_0_mse: 280.9817199707031|  0:00:06s\n","epoch 11 | loss: 0.21437 | val_0_mse: 372.4492492675781|  0:00:07s\n","epoch 12 | loss: 0.19088 | val_0_mse: 429.2177734375|  0:00:07s\n","epoch 13 | loss: 0.17734 | val_0_mse: 17.274450302124023|  0:00:08s\n","epoch 14 | loss: 0.15452 | val_0_mse: 97.85395050048828|  0:00:09s\n","epoch 15 | loss: 0.21255 | val_0_mse: 16.49574089050293|  0:00:09s\n","epoch 16 | loss: 0.21336 | val_0_mse: 5.9970197677612305|  0:00:10s\n","epoch 17 | loss: 0.1911  | val_0_mse: 40.60564041137695|  0:00:11s\n","epoch 18 | loss: 0.21268 | val_0_mse: 39.12141036987305|  0:00:11s\n","epoch 19 | loss: 0.17109 | val_0_mse: 28.006380081176758|  0:00:12s\n","epoch 20 | loss: 0.14118 | val_0_mse: 12.963569641113281|  0:00:12s\n","epoch 21 | loss: 0.13201 | val_0_mse: 15.020380020141602|  0:00:13s\n","epoch 22 | loss: 0.12392 | val_0_mse: 17.032020568847656|  0:00:14s\n","epoch 23 | loss: 0.12586 | val_0_mse: 12.777359962463379|  0:00:14s\n","epoch 24 | loss: 0.13128 | val_0_mse: 11.564530372619629|  0:00:15s\n","epoch 25 | loss: 0.12346 | val_0_mse: 9.265560150146484|  0:00:15s\n","epoch 26 | loss: 0.12526 | val_0_mse: 12.134779930114746|  0:00:16s\n","\n","Early stopping occurred at epoch 26 with best_epoch = 16 and best_val_0_mse = 5.9970197677612305\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 12:15:06,000] Trial 71 finished with value: 5.997021198272705 and parameters: {'n_d': 20, 'n_steps': 3, 'gamma': 1.384432467227749, 'n_independent': 1, 'n_shared': 5, 'momentum': 0.38844019966673293}. Best is trial 31 with value: 0.07662469148635864.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 67.36432| val_0_mse: 16488.712890625|  0:00:00s\n","epoch 1  | loss: 2.19425 | val_0_mse: 4862.45556640625|  0:00:01s\n","epoch 2  | loss: 0.58963 | val_0_mse: 7210.6943359375|  0:00:01s\n","epoch 3  | loss: 0.38058 | val_0_mse: 5174.61669921875|  0:00:02s\n","epoch 4  | loss: 0.30075 | val_0_mse: 2787.01953125|  0:00:02s\n","epoch 5  | loss: 0.25139 | val_0_mse: 3394.662841796875|  0:00:03s\n","epoch 6  | loss: 0.2126  | val_0_mse: 3567.266845703125|  0:00:04s\n","epoch 7  | loss: 0.22259 | val_0_mse: 3095.057373046875|  0:00:04s\n","epoch 8  | loss: 0.24763 | val_0_mse: 1490.39306640625|  0:00:05s\n","epoch 9  | loss: 0.23321 | val_0_mse: 1055.554931640625|  0:00:06s\n","epoch 10 | loss: 0.17559 | val_0_mse: 570.8790893554688|  0:00:06s\n","epoch 11 | loss: 0.16619 | val_0_mse: 296.1602783203125|  0:00:07s\n","epoch 12 | loss: 0.2017  | val_0_mse: 236.6301727294922|  0:00:07s\n","epoch 13 | loss: 0.18891 | val_0_mse: 191.57769775390625|  0:00:08s\n","epoch 14 | loss: 0.17593 | val_0_mse: 164.24363708496094|  0:00:09s\n","epoch 15 | loss: 0.16644 | val_0_mse: 66.23027801513672|  0:00:09s\n","epoch 16 | loss: 0.16542 | val_0_mse: 97.73483276367188|  0:00:10s\n","epoch 17 | loss: 0.146   | val_0_mse: 110.10623168945312|  0:00:10s\n","epoch 18 | loss: 0.12874 | val_0_mse: 79.53626251220703|  0:00:11s\n","epoch 19 | loss: 0.12789 | val_0_mse: 45.355899810791016|  0:00:12s\n","epoch 20 | loss: 0.11751 | val_0_mse: 24.67201042175293|  0:00:12s\n","epoch 21 | loss: 0.12372 | val_0_mse: 37.316341400146484|  0:00:13s\n","epoch 22 | loss: 0.1303  | val_0_mse: 29.716279983520508|  0:00:13s\n","epoch 23 | loss: 0.13364 | val_0_mse: 29.654659271240234|  0:00:14s\n","epoch 24 | loss: 0.1412  | val_0_mse: 12.135919570922852|  0:00:15s\n","epoch 25 | loss: 0.17088 | val_0_mse: 16.047229766845703|  0:00:15s\n","epoch 26 | loss: 0.18036 | val_0_mse: 8.590279579162598|  0:00:16s\n","epoch 27 | loss: 0.16931 | val_0_mse: 6.2741498947143555|  0:00:17s\n","epoch 28 | loss: 0.15285 | val_0_mse: 2.224639892578125|  0:00:17s\n","epoch 29 | loss: 0.14139 | val_0_mse: 3.766849994659424|  0:00:18s\n","epoch 30 | loss: 0.13543 | val_0_mse: 1.4812300205230713|  0:00:18s\n","epoch 31 | loss: 0.13322 | val_0_mse: 1.2717499732971191|  0:00:19s\n","epoch 32 | loss: 0.13351 | val_0_mse: 0.5034700036048889|  0:00:20s\n","epoch 33 | loss: 0.12392 | val_0_mse: 0.7288200259208679|  0:00:20s\n","epoch 34 | loss: 0.12569 | val_0_mse: 0.5129500031471252|  0:00:21s\n","epoch 35 | loss: 0.12198 | val_0_mse: 0.49184998869895935|  0:00:22s\n","epoch 36 | loss: 0.12913 | val_0_mse: 0.28762000799179077|  0:00:22s\n","epoch 37 | loss: 0.10703 | val_0_mse: 0.35712000727653503|  0:00:23s\n","epoch 38 | loss: 0.1035  | val_0_mse: 0.4548400044441223|  0:00:23s\n","epoch 39 | loss: 0.10063 | val_0_mse: 0.42798998951911926|  0:00:24s\n","epoch 40 | loss: 0.09537 | val_0_mse: 0.25753000378608704|  0:00:25s\n","epoch 41 | loss: 0.10024 | val_0_mse: 0.19623999297618866|  0:00:25s\n","epoch 42 | loss: 0.11222 | val_0_mse: 0.3136500120162964|  0:00:26s\n","epoch 43 | loss: 0.15356 | val_0_mse: 0.1838800013065338|  0:00:26s\n","epoch 44 | loss: 0.13876 | val_0_mse: 0.22577999532222748|  0:00:27s\n","epoch 45 | loss: 0.14051 | val_0_mse: 0.16198000311851501|  0:00:28s\n","epoch 46 | loss: 0.12763 | val_0_mse: 0.27911999821662903|  0:00:28s\n","epoch 47 | loss: 0.10545 | val_0_mse: 0.20416000485420227|  0:00:29s\n","epoch 48 | loss: 0.10031 | val_0_mse: 0.2039799988269806|  0:00:29s\n","epoch 49 | loss: 0.10305 | val_0_mse: 0.19346000254154205|  0:00:30s\n","epoch 50 | loss: 0.09374 | val_0_mse: 0.15498000383377075|  0:00:31s\n","epoch 51 | loss: 0.09303 | val_0_mse: 0.12263999879360199|  0:00:31s\n","epoch 52 | loss: 0.12494 | val_0_mse: 0.2252500057220459|  0:00:32s\n","epoch 53 | loss: 0.11036 | val_0_mse: 0.12230999767780304|  0:00:33s\n","epoch 54 | loss: 0.09924 | val_0_mse: 0.10896000266075134|  0:00:33s\n","epoch 55 | loss: 0.08943 | val_0_mse: 0.11350999772548676|  0:00:34s\n","epoch 56 | loss: 0.09158 | val_0_mse: 0.12520000338554382|  0:00:34s\n","epoch 57 | loss: 0.13255 | val_0_mse: 0.1840900033712387|  0:00:35s\n","epoch 58 | loss: 0.12351 | val_0_mse: 0.11620999872684479|  0:00:36s\n","epoch 59 | loss: 0.11437 | val_0_mse: 0.17121000587940216|  0:00:36s\n","epoch 60 | loss: 0.11097 | val_0_mse: 0.10321000218391418|  0:00:37s\n","epoch 61 | loss: 0.10611 | val_0_mse: 0.17552000284194946|  0:00:37s\n","epoch 62 | loss: 0.10547 | val_0_mse: 0.09843000024557114|  0:00:38s\n","epoch 63 | loss: 0.10995 | val_0_mse: 0.17398999631404877|  0:00:39s\n","epoch 64 | loss: 0.10415 | val_0_mse: 0.10198000073432922|  0:00:39s\n","epoch 65 | loss: 0.10231 | val_0_mse: 0.14437000453472137|  0:00:40s\n","epoch 66 | loss: 0.10726 | val_0_mse: 0.09762000292539597|  0:00:41s\n","epoch 67 | loss: 0.10345 | val_0_mse: 0.147039994597435|  0:00:41s\n","epoch 68 | loss: 0.10417 | val_0_mse: 0.1007699966430664|  0:00:42s\n","epoch 69 | loss: 0.10428 | val_0_mse: 0.14042000472545624|  0:00:43s\n","epoch 70 | loss: 0.10728 | val_0_mse: 0.09798000007867813|  0:00:43s\n","epoch 71 | loss: 0.10373 | val_0_mse: 0.14364999532699585|  0:00:44s\n","epoch 72 | loss: 0.10863 | val_0_mse: 0.12221000343561172|  0:00:44s\n","epoch 73 | loss: 0.10897 | val_0_mse: 0.10192999988794327|  0:00:45s\n","epoch 74 | loss: 0.10513 | val_0_mse: 0.09549999982118607|  0:00:46s\n","epoch 75 | loss: 0.10645 | val_0_mse: 0.10096000134944916|  0:00:46s\n","epoch 76 | loss: 0.08832 | val_0_mse: 0.08344999700784683|  0:00:47s\n","epoch 77 | loss: 0.08574 | val_0_mse: 0.09109999984502792|  0:00:47s\n","epoch 78 | loss: 0.08779 | val_0_mse: 0.08832000195980072|  0:00:48s\n","epoch 79 | loss: 0.08577 | val_0_mse: 0.08436000347137451|  0:00:48s\n","epoch 80 | loss: 0.08742 | val_0_mse: 0.08749999850988388|  0:00:49s\n","epoch 81 | loss: 0.08735 | val_0_mse: 0.09675999730825424|  0:00:50s\n","epoch 82 | loss: 0.08483 | val_0_mse: 0.08886999636888504|  0:00:50s\n","epoch 83 | loss: 0.08549 | val_0_mse: 0.09746000170707703|  0:00:51s\n","epoch 84 | loss: 0.08765 | val_0_mse: 0.09240999817848206|  0:00:51s\n","epoch 85 | loss: 0.0818  | val_0_mse: 0.08591999858617783|  0:00:52s\n","epoch 86 | loss: 0.08324 | val_0_mse: 0.09058000147342682|  0:00:53s\n","\n","Early stopping occurred at epoch 86 with best_epoch = 76 and best_val_0_mse = 0.08344999700784683\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 12:15:59,496] Trial 72 finished with value: 0.08345461636781693 and parameters: {'n_d': 37, 'n_steps': 3, 'gamma': 1.334576012876059, 'n_independent': 1, 'n_shared': 5, 'momentum': 0.211566647643968}. Best is trial 31 with value: 0.07662469148635864.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 60.10499| val_0_mse: 756.60400390625|  0:00:00s\n","epoch 1  | loss: 1.13267 | val_0_mse: 2001.3753662109375|  0:00:01s\n","epoch 2  | loss: 0.51405 | val_0_mse: 470.1417541503906|  0:00:01s\n","epoch 3  | loss: 0.40893 | val_0_mse: 119.82317352294922|  0:00:02s\n","epoch 4  | loss: 0.39803 | val_0_mse: 91.27828979492188|  0:00:02s\n","epoch 5  | loss: 0.25134 | val_0_mse: 98.14412689208984|  0:00:03s\n","epoch 6  | loss: 0.22445 | val_0_mse: 27.32440948486328|  0:00:03s\n","epoch 7  | loss: 0.28802 | val_0_mse: 82.59046173095703|  0:00:04s\n","epoch 8  | loss: 0.30182 | val_0_mse: 52.19028854370117|  0:00:04s\n","epoch 9  | loss: 0.17435 | val_0_mse: 18.761770248413086|  0:00:05s\n","epoch 10 | loss: 0.21871 | val_0_mse: 31.633350372314453|  0:00:05s\n","epoch 11 | loss: 0.22719 | val_0_mse: 21.79014015197754|  0:00:06s\n","epoch 12 | loss: 0.19927 | val_0_mse: 21.875619888305664|  0:00:06s\n","epoch 13 | loss: 0.19348 | val_0_mse: 18.119749069213867|  0:00:07s\n","epoch 14 | loss: 0.17523 | val_0_mse: 13.992719650268555|  0:00:08s\n","epoch 15 | loss: 0.15136 | val_0_mse: 8.007499694824219|  0:00:08s\n","epoch 16 | loss: 0.17126 | val_0_mse: 14.672050476074219|  0:00:09s\n","epoch 17 | loss: 0.14183 | val_0_mse: 13.778229713439941|  0:00:09s\n","epoch 18 | loss: 0.14128 | val_0_mse: 9.773280143737793|  0:00:10s\n","epoch 19 | loss: 0.17239 | val_0_mse: 8.24308967590332|  0:00:10s\n","epoch 20 | loss: 0.1917  | val_0_mse: 2.0085699558258057|  0:00:11s\n","epoch 21 | loss: 0.17547 | val_0_mse: 1.46343994140625|  0:00:12s\n","epoch 22 | loss: 0.1758  | val_0_mse: 1.209529995918274|  0:00:12s\n","epoch 23 | loss: 0.16169 | val_0_mse: 1.1960200071334839|  0:00:13s\n","epoch 24 | loss: 0.16502 | val_0_mse: 0.7262099981307983|  0:00:13s\n","epoch 25 | loss: 0.13523 | val_0_mse: 1.581779956817627|  0:00:14s\n","epoch 26 | loss: 0.18747 | val_0_mse: 1.80417001247406|  0:00:14s\n","epoch 27 | loss: 0.16341 | val_0_mse: 1.3544000387191772|  0:00:15s\n","epoch 28 | loss: 0.18439 | val_0_mse: 1.1068099737167358|  0:00:15s\n","epoch 29 | loss: 0.16248 | val_0_mse: 1.1699700355529785|  0:00:16s\n","epoch 30 | loss: 0.1491  | val_0_mse: 0.9815899729728699|  0:00:16s\n","epoch 31 | loss: 0.14768 | val_0_mse: 1.0383700132369995|  0:00:17s\n","epoch 32 | loss: 0.14196 | val_0_mse: 1.0536799430847168|  0:00:17s\n","epoch 33 | loss: 0.14876 | val_0_mse: 1.0210000276565552|  0:00:18s\n","epoch 34 | loss: 0.14682 | val_0_mse: 0.879859983921051|  0:00:18s\n","\n","Early stopping occurred at epoch 34 with best_epoch = 24 and best_val_0_mse = 0.7262099981307983\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 12:16:18,730] Trial 73 finished with value: 0.7262097001075745 and parameters: {'n_d': 61, 'n_steps': 3, 'gamma': 1.3202536752843461, 'n_independent': 1, 'n_shared': 4, 'momentum': 0.27384069841733777}. Best is trial 31 with value: 0.07662469148635864.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 54.86449| val_0_mse: 70191.90625|  0:00:00s\n","epoch 1  | loss: 1.96566 | val_0_mse: 404.1437072753906|  0:00:01s\n","epoch 2  | loss: 0.64671 | val_0_mse: 188.89613342285156|  0:00:01s\n","epoch 3  | loss: 0.39396 | val_0_mse: 146.0665740966797|  0:00:02s\n","epoch 4  | loss: 0.3378  | val_0_mse: 111.79000091552734|  0:00:03s\n","epoch 5  | loss: 0.26823 | val_0_mse: 111.9329833984375|  0:00:03s\n","epoch 6  | loss: 0.22346 | val_0_mse: 88.27102661132812|  0:00:04s\n","epoch 7  | loss: 0.25276 | val_0_mse: 45.67802047729492|  0:00:04s\n","epoch 8  | loss: 0.21121 | val_0_mse: 95.04390716552734|  0:00:05s\n","epoch 9  | loss: 0.18946 | val_0_mse: 12.678199768066406|  0:00:06s\n","epoch 10 | loss: 0.16063 | val_0_mse: 43.951358795166016|  0:00:06s\n","epoch 11 | loss: 0.16432 | val_0_mse: 21.021669387817383|  0:00:07s\n","epoch 12 | loss: 0.15804 | val_0_mse: 10.471770286560059|  0:00:07s\n","epoch 13 | loss: 0.14744 | val_0_mse: 21.316709518432617|  0:00:08s\n","epoch 14 | loss: 0.20046 | val_0_mse: 3.700010061264038|  0:00:09s\n","epoch 15 | loss: 0.19466 | val_0_mse: 8.123700141906738|  0:00:09s\n","epoch 16 | loss: 0.14313 | val_0_mse: 10.750829696655273|  0:00:10s\n","epoch 17 | loss: 0.13002 | val_0_mse: 3.738729953765869|  0:00:11s\n","epoch 18 | loss: 0.14079 | val_0_mse: 4.699289798736572|  0:00:11s\n","epoch 19 | loss: 0.12492 | val_0_mse: 1.2040400505065918|  0:00:12s\n","epoch 20 | loss: 0.12378 | val_0_mse: 4.069369792938232|  0:00:12s\n","epoch 21 | loss: 0.12492 | val_0_mse: 5.636899948120117|  0:00:13s\n","epoch 22 | loss: 0.1267  | val_0_mse: 4.56879997253418|  0:00:14s\n","epoch 23 | loss: 0.13712 | val_0_mse: 6.31525993347168|  0:00:14s\n","epoch 24 | loss: 0.11657 | val_0_mse: 6.160099983215332|  0:00:15s\n","epoch 25 | loss: 0.12333 | val_0_mse: 3.361680030822754|  0:00:15s\n","epoch 26 | loss: 0.13267 | val_0_mse: 4.953310012817383|  0:00:16s\n","epoch 27 | loss: 0.12002 | val_0_mse: 4.920720100402832|  0:00:17s\n","epoch 28 | loss: 0.11326 | val_0_mse: 5.0188398361206055|  0:00:17s\n","epoch 29 | loss: 0.10604 | val_0_mse: 4.60152006149292|  0:00:18s\n","\n","Early stopping occurred at epoch 29 with best_epoch = 19 and best_val_0_mse = 1.2040400505065918\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 12:16:37,416] Trial 74 finished with value: 1.2040387392044067 and parameters: {'n_d': 40, 'n_steps': 3, 'gamma': 1.2393498253616724, 'n_independent': 1, 'n_shared': 5, 'momentum': 0.3125344099058497}. Best is trial 31 with value: 0.07662469148635864.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 29.60673| val_0_mse: 46276.40234375|  0:00:00s\n","epoch 1  | loss: 0.8307  | val_0_mse: 3028.057373046875|  0:00:01s\n","epoch 2  | loss: 0.38592 | val_0_mse: 2470.931884765625|  0:00:01s\n","epoch 3  | loss: 0.36763 | val_0_mse: 102.1932373046875|  0:00:02s\n","epoch 4  | loss: 0.33724 | val_0_mse: 148.78497314453125|  0:00:03s\n","epoch 5  | loss: 0.31253 | val_0_mse: 161.50790405273438|  0:00:03s\n","epoch 6  | loss: 0.308   | val_0_mse: 116.58186340332031|  0:00:04s\n","epoch 7  | loss: 0.19755 | val_0_mse: 100.34053802490234|  0:00:05s\n","epoch 8  | loss: 0.23173 | val_0_mse: 195.051025390625|  0:00:05s\n","epoch 9  | loss: 0.21434 | val_0_mse: 447.9201965332031|  0:00:06s\n","epoch 10 | loss: 0.16946 | val_0_mse: 1017.4794311523438|  0:00:07s\n","epoch 11 | loss: 0.21122 | val_0_mse: 232.9287872314453|  0:00:07s\n","epoch 12 | loss: 0.23083 | val_0_mse: 584.0401611328125|  0:00:08s\n","epoch 13 | loss: 0.16211 | val_0_mse: 457.9197082519531|  0:00:09s\n","epoch 14 | loss: 0.15393 | val_0_mse: 250.00233459472656|  0:00:09s\n","epoch 15 | loss: 0.1492  | val_0_mse: 257.7536315917969|  0:00:10s\n","epoch 16 | loss: 0.16649 | val_0_mse: 271.1155090332031|  0:00:11s\n","epoch 17 | loss: 0.20333 | val_0_mse: 123.20947265625|  0:00:11s\n","\n","Early stopping occurred at epoch 17 with best_epoch = 7 and best_val_0_mse = 100.34053802490234\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 12:16:49,472] Trial 75 finished with value: 100.34053802490234 and parameters: {'n_d': 45, 'n_steps': 4, 'gamma': 1.1792234174534229, 'n_independent': 1, 'n_shared': 4, 'momentum': 0.2323702781568725}. Best is trial 31 with value: 0.07662469148635864.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 116.3641| val_0_mse: 16506.4453125|  0:00:00s\n","epoch 1  | loss: 29.36365| val_0_mse: 35034.28125|  0:00:01s\n","epoch 2  | loss: 2.56307 | val_0_mse: 10758.80078125|  0:00:02s\n","epoch 3  | loss: 0.69838 | val_0_mse: 10642.1904296875|  0:00:03s\n","epoch 4  | loss: 0.42058 | val_0_mse: 2080.223876953125|  0:00:03s\n","epoch 5  | loss: 0.3082  | val_0_mse: 4514.90185546875|  0:00:04s\n","epoch 6  | loss: 0.30456 | val_0_mse: 1129.0977783203125|  0:00:05s\n","epoch 7  | loss: 0.22896 | val_0_mse: 1616.44580078125|  0:00:06s\n","epoch 8  | loss: 0.24765 | val_0_mse: 558.263916015625|  0:00:06s\n","epoch 9  | loss: 0.20298 | val_0_mse: 434.04400634765625|  0:00:07s\n","epoch 10 | loss: 0.16948 | val_0_mse: 53.286888122558594|  0:00:08s\n","epoch 11 | loss: 0.16108 | val_0_mse: 16.756500244140625|  0:00:09s\n","epoch 12 | loss: 0.1595  | val_0_mse: 34.704349517822266|  0:00:09s\n","epoch 13 | loss: 0.15152 | val_0_mse: 17.005359649658203|  0:00:10s\n","epoch 14 | loss: 0.16198 | val_0_mse: 18.67530059814453|  0:00:11s\n","epoch 15 | loss: 0.14913 | val_0_mse: 7.890120029449463|  0:00:11s\n","epoch 16 | loss: 0.14338 | val_0_mse: 4.691889762878418|  0:00:12s\n","epoch 17 | loss: 0.13684 | val_0_mse: 3.453809976577759|  0:00:13s\n","epoch 18 | loss: 0.12724 | val_0_mse: 4.669750213623047|  0:00:14s\n","epoch 19 | loss: 0.15218 | val_0_mse: 12.01653003692627|  0:00:14s\n","epoch 20 | loss: 0.15798 | val_0_mse: 6.3596601486206055|  0:00:15s\n","epoch 21 | loss: 0.13411 | val_0_mse: 9.336759567260742|  0:00:16s\n","epoch 22 | loss: 0.11784 | val_0_mse: 7.2984299659729|  0:00:17s\n","epoch 23 | loss: 0.11538 | val_0_mse: 6.2347002029418945|  0:00:17s\n","epoch 24 | loss: 0.13651 | val_0_mse: 3.7651000022888184|  0:00:18s\n","epoch 25 | loss: 0.12778 | val_0_mse: 3.2680699825286865|  0:00:19s\n","epoch 26 | loss: 0.10254 | val_0_mse: 4.889920234680176|  0:00:20s\n","epoch 27 | loss: 0.106   | val_0_mse: 3.1795899868011475|  0:00:20s\n","epoch 28 | loss: 0.10777 | val_0_mse: 2.504960060119629|  0:00:21s\n","epoch 29 | loss: 0.11363 | val_0_mse: 3.0201399326324463|  0:00:22s\n","epoch 30 | loss: 0.11169 | val_0_mse: 1.8879499435424805|  0:00:23s\n","epoch 31 | loss: 0.10886 | val_0_mse: 1.270509958267212|  0:00:23s\n","epoch 32 | loss: 0.11922 | val_0_mse: 2.194920063018799|  0:00:24s\n","epoch 33 | loss: 0.10885 | val_0_mse: 0.7176499962806702|  0:00:25s\n","epoch 34 | loss: 0.10603 | val_0_mse: 0.5345600247383118|  0:00:26s\n","epoch 35 | loss: 0.1001  | val_0_mse: 0.7278000116348267|  0:00:26s\n","epoch 36 | loss: 0.10292 | val_0_mse: 0.5630599856376648|  0:00:27s\n","epoch 37 | loss: 0.09566 | val_0_mse: 0.5043200254440308|  0:00:28s\n","epoch 38 | loss: 0.09473 | val_0_mse: 0.5182399749755859|  0:00:29s\n","epoch 39 | loss: 0.11132 | val_0_mse: 0.219310000538826|  0:00:29s\n","epoch 40 | loss: 0.10244 | val_0_mse: 0.4558599889278412|  0:00:30s\n","epoch 41 | loss: 0.10393 | val_0_mse: 0.22639000415802002|  0:00:31s\n","epoch 42 | loss: 0.1081  | val_0_mse: 0.3670800030231476|  0:00:32s\n","epoch 43 | loss: 0.12439 | val_0_mse: 0.3463599979877472|  0:00:32s\n","epoch 44 | loss: 0.1038  | val_0_mse: 0.2240699976682663|  0:00:33s\n","epoch 45 | loss: 0.09852 | val_0_mse: 0.2437800019979477|  0:00:34s\n","epoch 46 | loss: 0.11    | val_0_mse: 0.17511999607086182|  0:00:34s\n","epoch 47 | loss: 0.10203 | val_0_mse: 0.14674000442028046|  0:00:35s\n","epoch 48 | loss: 0.0962  | val_0_mse: 0.21299000084400177|  0:00:36s\n","epoch 49 | loss: 0.09743 | val_0_mse: 0.17329999804496765|  0:00:37s\n","epoch 50 | loss: 0.09752 | val_0_mse: 0.24525000154972076|  0:00:37s\n","epoch 51 | loss: 0.0984  | val_0_mse: 0.14240999519824982|  0:00:38s\n","epoch 52 | loss: 0.0915  | val_0_mse: 0.1439799964427948|  0:00:39s\n","epoch 53 | loss: 0.08861 | val_0_mse: 0.15132999420166016|  0:00:40s\n","epoch 54 | loss: 0.09324 | val_0_mse: 0.16955000162124634|  0:00:40s\n","epoch 55 | loss: 0.11689 | val_0_mse: 0.11960999667644501|  0:00:41s\n","epoch 56 | loss: 0.10409 | val_0_mse: 0.1850000023841858|  0:00:42s\n","epoch 57 | loss: 0.09838 | val_0_mse: 0.1425199955701828|  0:00:43s\n","epoch 58 | loss: 0.11345 | val_0_mse: 0.16391000151634216|  0:00:43s\n","epoch 59 | loss: 0.10928 | val_0_mse: 0.1314699947834015|  0:00:44s\n","epoch 60 | loss: 0.10666 | val_0_mse: 0.14172999560832977|  0:00:45s\n","epoch 61 | loss: 0.10693 | val_0_mse: 0.10354000329971313|  0:00:46s\n","epoch 62 | loss: 0.11323 | val_0_mse: 0.11197999864816666|  0:00:46s\n","epoch 63 | loss: 0.10076 | val_0_mse: 0.0963200032711029|  0:00:47s\n","epoch 64 | loss: 0.09785 | val_0_mse: 0.11022000014781952|  0:00:48s\n","epoch 65 | loss: 0.09352 | val_0_mse: 0.09568999707698822|  0:00:48s\n","epoch 66 | loss: 0.08828 | val_0_mse: 0.08828999847173691|  0:00:49s\n","epoch 67 | loss: 0.08944 | val_0_mse: 0.10187999904155731|  0:00:50s\n","epoch 68 | loss: 0.08801 | val_0_mse: 0.08772999793291092|  0:00:51s\n","epoch 69 | loss: 0.09524 | val_0_mse: 0.0830100029706955|  0:00:51s\n","epoch 70 | loss: 0.09161 | val_0_mse: 0.09544999897480011|  0:00:52s\n","epoch 71 | loss: 0.08488 | val_0_mse: 0.08801999688148499|  0:00:53s\n","epoch 72 | loss: 0.09263 | val_0_mse: 0.11038000136613846|  0:00:54s\n","epoch 73 | loss: 0.09102 | val_0_mse: 0.10492999851703644|  0:00:54s\n","epoch 74 | loss: 0.10041 | val_0_mse: 0.08942999690771103|  0:00:55s\n","epoch 75 | loss: 0.08472 | val_0_mse: 0.08601000159978867|  0:00:56s\n","epoch 76 | loss: 0.09854 | val_0_mse: 0.15421999990940094|  0:00:57s\n","epoch 77 | loss: 0.13048 | val_0_mse: 0.18276000022888184|  0:00:57s\n","epoch 78 | loss: 0.13211 | val_0_mse: 0.10459999740123749|  0:00:58s\n","epoch 79 | loss: 0.12362 | val_0_mse: 0.09730999916791916|  0:00:59s\n","\n","Early stopping occurred at epoch 79 with best_epoch = 69 and best_val_0_mse = 0.0830100029706955\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 12:17:49,103] Trial 76 finished with value: 0.08301489055156708 and parameters: {'n_d': 15, 'n_steps': 3, 'gamma': 1.1510365886852236, 'n_independent': 3, 'n_shared': 5, 'momentum': 0.29851249495970944}. Best is trial 31 with value: 0.07662469148635864.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 50.13993| val_0_mse: 4892.08837890625|  0:00:00s\n","epoch 1  | loss: 1.51666 | val_0_mse: 16728.701171875|  0:00:01s\n","epoch 2  | loss: 0.70668 | val_0_mse: 12557.8017578125|  0:00:02s\n","epoch 3  | loss: 0.46198 | val_0_mse: 5695.41162109375|  0:00:02s\n","epoch 4  | loss: 0.32855 | val_0_mse: 5443.67724609375|  0:00:03s\n","epoch 5  | loss: 0.31379 | val_0_mse: 1571.8355712890625|  0:00:04s\n","epoch 6  | loss: 0.25636 | val_0_mse: 1054.3048095703125|  0:00:04s\n","epoch 7  | loss: 0.2081  | val_0_mse: 724.2984008789062|  0:00:05s\n","epoch 8  | loss: 0.19625 | val_0_mse: 609.5049438476562|  0:00:06s\n","epoch 9  | loss: 0.18032 | val_0_mse: 469.0634460449219|  0:00:06s\n","epoch 10 | loss: 0.1519  | val_0_mse: 464.08404541015625|  0:00:07s\n","epoch 11 | loss: 0.14257 | val_0_mse: 438.1935729980469|  0:00:08s\n","epoch 12 | loss: 0.1545  | val_0_mse: 234.03387451171875|  0:00:08s\n","epoch 13 | loss: 0.13539 | val_0_mse: 144.04591369628906|  0:00:09s\n","epoch 14 | loss: 0.18751 | val_0_mse: 133.75213623046875|  0:00:10s\n","epoch 15 | loss: 0.17455 | val_0_mse: 51.8969612121582|  0:00:11s\n","epoch 16 | loss: 0.13574 | val_0_mse: 53.1350212097168|  0:00:11s\n","epoch 17 | loss: 0.16224 | val_0_mse: 40.59175109863281|  0:00:12s\n","epoch 18 | loss: 0.13211 | val_0_mse: 20.655019760131836|  0:00:13s\n","epoch 19 | loss: 0.16824 | val_0_mse: 17.006370544433594|  0:00:13s\n","epoch 20 | loss: 0.14185 | val_0_mse: 11.77299976348877|  0:00:14s\n","epoch 21 | loss: 0.11549 | val_0_mse: 8.696359634399414|  0:00:15s\n","epoch 22 | loss: 0.12158 | val_0_mse: 4.390429973602295|  0:00:15s\n","epoch 23 | loss: 0.10914 | val_0_mse: 3.0767900943756104|  0:00:16s\n","epoch 24 | loss: 0.10311 | val_0_mse: 1.8951200246810913|  0:00:17s\n","epoch 25 | loss: 0.11344 | val_0_mse: 2.3656299114227295|  0:00:17s\n","epoch 26 | loss: 0.10685 | val_0_mse: 1.3248000144958496|  0:00:18s\n","epoch 27 | loss: 0.11973 | val_0_mse: 2.3961799144744873|  0:00:19s\n","epoch 28 | loss: 0.12388 | val_0_mse: 2.1135900020599365|  0:00:20s\n","epoch 29 | loss: 0.11174 | val_0_mse: 0.8067200183868408|  0:00:20s\n","epoch 30 | loss: 0.1042  | val_0_mse: 1.130120038986206|  0:00:21s\n","epoch 31 | loss: 0.10406 | val_0_mse: 1.2069300413131714|  0:00:22s\n","epoch 32 | loss: 0.10021 | val_0_mse: 0.9602599740028381|  0:00:22s\n","epoch 33 | loss: 0.09366 | val_0_mse: 0.5754600167274475|  0:00:23s\n","epoch 34 | loss: 0.10305 | val_0_mse: 0.6058400273323059|  0:00:24s\n","epoch 35 | loss: 0.0953  | val_0_mse: 0.45170000195503235|  0:00:24s\n","epoch 36 | loss: 0.12074 | val_0_mse: 0.6194400191307068|  0:00:25s\n","epoch 37 | loss: 0.09819 | val_0_mse: 0.30485999584198|  0:00:26s\n","epoch 38 | loss: 0.09833 | val_0_mse: 0.5601400136947632|  0:00:26s\n","epoch 39 | loss: 0.10865 | val_0_mse: 0.21589000523090363|  0:00:27s\n","epoch 40 | loss: 0.13524 | val_0_mse: 0.8822699785232544|  0:00:28s\n","epoch 41 | loss: 0.1435  | val_0_mse: 0.24504999816417694|  0:00:28s\n","epoch 42 | loss: 0.13251 | val_0_mse: 0.44457998871803284|  0:00:29s\n","epoch 43 | loss: 0.141   | val_0_mse: 0.2827799916267395|  0:00:30s\n","epoch 44 | loss: 0.12594 | val_0_mse: 0.45021000504493713|  0:00:30s\n","epoch 45 | loss: 0.11869 | val_0_mse: 0.39539000391960144|  0:00:31s\n","epoch 46 | loss: 0.13876 | val_0_mse: 0.18126000463962555|  0:00:32s\n","epoch 47 | loss: 0.13476 | val_0_mse: 0.18727999925613403|  0:00:32s\n","epoch 48 | loss: 0.12563 | val_0_mse: 0.13041000068187714|  0:00:33s\n","epoch 49 | loss: 0.11697 | val_0_mse: 0.20532000064849854|  0:00:34s\n","epoch 50 | loss: 0.12592 | val_0_mse: 0.1295199990272522|  0:00:34s\n","epoch 51 | loss: 0.1124  | val_0_mse: 0.1968500018119812|  0:00:35s\n","epoch 52 | loss: 0.12201 | val_0_mse: 0.10984999686479568|  0:00:36s\n","epoch 53 | loss: 0.1176  | val_0_mse: 0.16167999804019928|  0:00:36s\n","epoch 54 | loss: 0.11252 | val_0_mse: 0.11527000367641449|  0:00:37s\n","epoch 55 | loss: 0.10964 | val_0_mse: 0.14509999752044678|  0:00:38s\n","epoch 56 | loss: 0.11313 | val_0_mse: 0.09380999952554703|  0:00:38s\n","epoch 57 | loss: 0.11874 | val_0_mse: 0.13526000082492828|  0:00:39s\n","epoch 58 | loss: 0.11069 | val_0_mse: 0.09691999852657318|  0:00:40s\n","epoch 59 | loss: 0.11665 | val_0_mse: 0.15598000586032867|  0:00:41s\n","epoch 60 | loss: 0.11201 | val_0_mse: 0.09113000333309174|  0:00:41s\n","epoch 61 | loss: 0.11664 | val_0_mse: 0.1354299932718277|  0:00:42s\n","epoch 62 | loss: 0.1123  | val_0_mse: 0.10857000201940536|  0:00:43s\n","epoch 63 | loss: 0.10945 | val_0_mse: 0.13794000446796417|  0:00:43s\n","epoch 64 | loss: 0.11193 | val_0_mse: 0.09300000220537186|  0:00:44s\n","epoch 65 | loss: 0.10812 | val_0_mse: 0.13214999437332153|  0:00:45s\n","epoch 66 | loss: 0.11584 | val_0_mse: 0.09855999797582626|  0:00:46s\n","epoch 67 | loss: 0.10725 | val_0_mse: 0.11552999913692474|  0:00:46s\n","epoch 68 | loss: 0.10719 | val_0_mse: 0.08962000161409378|  0:00:47s\n","epoch 69 | loss: 0.11055 | val_0_mse: 0.12182000279426575|  0:00:48s\n","epoch 70 | loss: 0.11762 | val_0_mse: 0.10135000199079514|  0:00:48s\n","epoch 71 | loss: 0.10745 | val_0_mse: 0.11309000104665756|  0:00:49s\n","epoch 72 | loss: 0.10829 | val_0_mse: 0.09726999700069427|  0:00:50s\n","epoch 73 | loss: 0.10836 | val_0_mse: 0.11158999800682068|  0:00:50s\n","epoch 74 | loss: 0.10806 | val_0_mse: 0.09313999861478806|  0:00:51s\n","epoch 75 | loss: 0.11023 | val_0_mse: 0.09339000284671783|  0:00:52s\n","epoch 76 | loss: 0.10765 | val_0_mse: 0.08601000159978867|  0:00:52s\n","epoch 77 | loss: 0.10849 | val_0_mse: 0.09009999781847|  0:00:53s\n","epoch 78 | loss: 0.10397 | val_0_mse: 0.09374000132083893|  0:00:54s\n","epoch 79 | loss: 0.11301 | val_0_mse: 0.08162999898195267|  0:00:55s\n","epoch 80 | loss: 0.11082 | val_0_mse: 0.08320999890565872|  0:00:55s\n","epoch 81 | loss: 0.08719 | val_0_mse: 0.09410999715328217|  0:00:56s\n","epoch 82 | loss: 0.0873  | val_0_mse: 0.08425000309944153|  0:00:57s\n","epoch 83 | loss: 0.08718 | val_0_mse: 0.09324999898672104|  0:00:58s\n","epoch 84 | loss: 0.0974  | val_0_mse: 0.10264000296592712|  0:00:58s\n","epoch 85 | loss: 0.11643 | val_0_mse: 0.10371000319719315|  0:00:59s\n","epoch 86 | loss: 0.11594 | val_0_mse: 0.12262000143527985|  0:01:00s\n","epoch 87 | loss: 0.1032  | val_0_mse: 0.09861999750137329|  0:01:01s\n","epoch 88 | loss: 0.08219 | val_0_mse: 0.0824199989438057|  0:01:01s\n","epoch 89 | loss: 0.08472 | val_0_mse: 0.0941699966788292|  0:01:02s\n","\n","Early stopping occurred at epoch 89 with best_epoch = 79 and best_val_0_mse = 0.08162999898195267\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 12:18:51,964] Trial 77 finished with value: 0.08162955194711685 and parameters: {'n_d': 48, 'n_steps': 3, 'gamma': 1.09089845229924, 'n_independent': 2, 'n_shared': 5, 'momentum': 0.19071373416509177}. Best is trial 31 with value: 0.07662469148635864.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 18.71779| val_0_mse: 59819.25|  0:00:01s\n","epoch 1  | loss: 3.65352 | val_0_mse: 66302.65625|  0:00:02s\n","epoch 2  | loss: 2.13354 | val_0_mse: 8404.1572265625|  0:00:03s\n","epoch 3  | loss: 0.99086 | val_0_mse: 2100.96044921875|  0:00:04s\n","epoch 4  | loss: 0.73159 | val_0_mse: 1549.9066162109375|  0:00:05s\n","epoch 5  | loss: 0.55003 | val_0_mse: 338.0345458984375|  0:00:06s\n","epoch 6  | loss: 0.48098 | val_0_mse: 117.18309783935547|  0:00:07s\n","epoch 7  | loss: 0.42    | val_0_mse: 79.78704071044922|  0:00:08s\n","epoch 8  | loss: 0.39828 | val_0_mse: 34.47727966308594|  0:00:09s\n","epoch 9  | loss: 0.39069 | val_0_mse: 156.64767456054688|  0:00:10s\n","epoch 10 | loss: 0.29022 | val_0_mse: 134.08116149902344|  0:00:11s\n","epoch 11 | loss: 0.34575 | val_0_mse: 363.6270446777344|  0:00:12s\n","epoch 12 | loss: 0.27735 | val_0_mse: 627.9359130859375|  0:00:13s\n","epoch 13 | loss: 0.29197 | val_0_mse: 344.383544921875|  0:00:15s\n","epoch 14 | loss: 0.2589  | val_0_mse: 216.66639709472656|  0:00:16s\n","epoch 15 | loss: 0.29539 | val_0_mse: 148.78036499023438|  0:00:17s\n","epoch 16 | loss: 0.40114 | val_0_mse: 205.63351440429688|  0:00:18s\n","epoch 17 | loss: 0.38671 | val_0_mse: 98.61739349365234|  0:00:19s\n","epoch 18 | loss: 0.35474 | val_0_mse: 61.862449645996094|  0:00:20s\n","\n","Early stopping occurred at epoch 18 with best_epoch = 8 and best_val_0_mse = 34.47727966308594\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 12:19:12,564] Trial 78 finished with value: 34.4772834777832 and parameters: {'n_d': 54, 'n_steps': 7, 'gamma': 1.1049230257013098, 'n_independent': 2, 'n_shared': 3, 'momentum': 0.14706454009705333}. Best is trial 31 with value: 0.07662469148635864.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 50.07555| val_0_mse: 36653.015625|  0:00:00s\n","epoch 1  | loss: 3.5797  | val_0_mse: 11160.814453125|  0:00:01s\n","epoch 2  | loss: 1.15949 | val_0_mse: 3454.90966796875|  0:00:02s\n","epoch 3  | loss: 0.45777 | val_0_mse: 235.9946746826172|  0:00:03s\n","epoch 4  | loss: 0.38366 | val_0_mse: 1050.662353515625|  0:00:04s\n","epoch 5  | loss: 0.30303 | val_0_mse: 847.6648559570312|  0:00:05s\n","epoch 6  | loss: 0.25267 | val_0_mse: 236.88592529296875|  0:00:06s\n","epoch 7  | loss: 0.26593 | val_0_mse: 315.7422180175781|  0:00:07s\n","epoch 8  | loss: 0.27129 | val_0_mse: 3909.416748046875|  0:00:08s\n","epoch 9  | loss: 0.22578 | val_0_mse: 988.0657348632812|  0:00:08s\n","epoch 10 | loss: 0.20459 | val_0_mse: 759.6024169921875|  0:00:09s\n","epoch 11 | loss: 0.19963 | val_0_mse: 258.5386962890625|  0:00:10s\n","epoch 12 | loss: 0.2008  | val_0_mse: 196.55087280273438|  0:00:11s\n","epoch 13 | loss: 0.17825 | val_0_mse: 314.8928527832031|  0:00:12s\n","epoch 14 | loss: 0.15334 | val_0_mse: 255.73257446289062|  0:00:13s\n","epoch 15 | loss: 0.14904 | val_0_mse: 131.48236083984375|  0:00:14s\n","epoch 16 | loss: 0.14821 | val_0_mse: 101.70889282226562|  0:00:15s\n","epoch 17 | loss: 0.14927 | val_0_mse: 64.45690155029297|  0:00:16s\n","epoch 18 | loss: 0.14875 | val_0_mse: 42.23849868774414|  0:00:17s\n","epoch 19 | loss: 0.13544 | val_0_mse: 38.36629104614258|  0:00:18s\n","epoch 20 | loss: 0.13048 | val_0_mse: 22.676389694213867|  0:00:19s\n","epoch 21 | loss: 0.12588 | val_0_mse: 19.241500854492188|  0:00:20s\n","epoch 22 | loss: 0.12661 | val_0_mse: 8.621740341186523|  0:00:21s\n","epoch 23 | loss: 0.12438 | val_0_mse: 10.621179580688477|  0:00:22s\n","epoch 24 | loss: 0.11749 | val_0_mse: 8.944140434265137|  0:00:22s\n","epoch 25 | loss: 0.10967 | val_0_mse: 5.907040119171143|  0:00:23s\n","epoch 26 | loss: 0.1098  | val_0_mse: 4.7495598793029785|  0:00:24s\n","epoch 27 | loss: 0.11229 | val_0_mse: 2.1457200050354004|  0:00:25s\n","epoch 28 | loss: 0.10543 | val_0_mse: 2.736180067062378|  0:00:26s\n","epoch 29 | loss: 0.12144 | val_0_mse: 2.786099910736084|  0:00:27s\n","epoch 30 | loss: 0.12276 | val_0_mse: 1.3736499547958374|  0:00:28s\n","epoch 31 | loss: 0.11611 | val_0_mse: 1.2942800521850586|  0:00:29s\n","epoch 32 | loss: 0.11241 | val_0_mse: 1.3145099878311157|  0:00:30s\n","epoch 33 | loss: 0.11349 | val_0_mse: 1.1875499486923218|  0:00:31s\n","epoch 34 | loss: 0.1094  | val_0_mse: 0.7531499862670898|  0:00:32s\n","epoch 35 | loss: 0.11259 | val_0_mse: 0.7642800211906433|  0:00:33s\n","epoch 36 | loss: 0.10618 | val_0_mse: 0.947700023651123|  0:00:33s\n","epoch 37 | loss: 0.1128  | val_0_mse: 0.8148699998855591|  0:00:34s\n","epoch 38 | loss: 0.176   | val_0_mse: 0.24695999920368195|  0:00:35s\n","epoch 39 | loss: 0.14868 | val_0_mse: 1.0583399534225464|  0:00:36s\n","epoch 40 | loss: 0.15479 | val_0_mse: 0.5964999794960022|  0:00:37s\n","epoch 41 | loss: 0.1434  | val_0_mse: 0.4957900047302246|  0:00:38s\n","epoch 42 | loss: 0.17158 | val_0_mse: 0.4567599892616272|  0:00:39s\n","epoch 43 | loss: 0.17555 | val_0_mse: 0.2664499878883362|  0:00:40s\n","epoch 44 | loss: 0.1712  | val_0_mse: 0.42712000012397766|  0:00:41s\n","epoch 45 | loss: 0.14792 | val_0_mse: 0.24654999375343323|  0:00:41s\n","epoch 46 | loss: 0.14063 | val_0_mse: 0.37397998571395874|  0:00:42s\n","epoch 47 | loss: 0.13792 | val_0_mse: 0.2627300024032593|  0:00:43s\n","epoch 48 | loss: 0.12725 | val_0_mse: 0.4289900064468384|  0:00:44s\n","epoch 49 | loss: 0.12991 | val_0_mse: 0.23528000712394714|  0:00:45s\n","epoch 50 | loss: 0.13083 | val_0_mse: 0.3748199939727783|  0:00:46s\n","epoch 51 | loss: 0.12616 | val_0_mse: 0.18695999681949615|  0:00:47s\n","epoch 52 | loss: 0.12476 | val_0_mse: 0.2574999928474426|  0:00:48s\n","epoch 53 | loss: 0.12266 | val_0_mse: 0.1921900063753128|  0:00:49s\n","epoch 54 | loss: 0.12794 | val_0_mse: 0.2521499991416931|  0:00:49s\n","epoch 55 | loss: 0.12617 | val_0_mse: 0.14640000462532043|  0:00:50s\n","epoch 56 | loss: 0.12662 | val_0_mse: 0.2922399938106537|  0:00:51s\n","epoch 57 | loss: 0.12354 | val_0_mse: 0.17990000545978546|  0:00:52s\n","epoch 58 | loss: 0.12305 | val_0_mse: 0.2825700044631958|  0:00:53s\n","epoch 59 | loss: 0.12649 | val_0_mse: 0.21371999382972717|  0:00:54s\n","epoch 60 | loss: 0.14382 | val_0_mse: 0.1743900030851364|  0:00:54s\n","epoch 61 | loss: 0.14299 | val_0_mse: 0.21953999996185303|  0:00:55s\n","epoch 62 | loss: 0.15252 | val_0_mse: 0.22100000083446503|  0:00:56s\n","epoch 63 | loss: 0.1462  | val_0_mse: 0.12099000066518784|  0:00:57s\n","epoch 64 | loss: 0.12483 | val_0_mse: 0.20861999690532684|  0:00:58s\n","epoch 65 | loss: 0.12742 | val_0_mse: 0.1200300008058548|  0:00:59s\n","epoch 66 | loss: 0.12451 | val_0_mse: 0.180759996175766|  0:00:59s\n","epoch 67 | loss: 0.12311 | val_0_mse: 0.11761999875307083|  0:01:00s\n","epoch 68 | loss: 0.11805 | val_0_mse: 0.17428000271320343|  0:01:01s\n","epoch 69 | loss: 0.12364 | val_0_mse: 0.11840999871492386|  0:01:02s\n","epoch 70 | loss: 0.12313 | val_0_mse: 0.15127000212669373|  0:01:03s\n","epoch 71 | loss: 0.11835 | val_0_mse: 0.1287499964237213|  0:01:04s\n","epoch 72 | loss: 0.12096 | val_0_mse: 0.2087700068950653|  0:01:05s\n","epoch 73 | loss: 0.13348 | val_0_mse: 0.10897000133991241|  0:01:06s\n","epoch 74 | loss: 0.12488 | val_0_mse: 0.12913000583648682|  0:01:06s\n","epoch 75 | loss: 0.12717 | val_0_mse: 0.16502000391483307|  0:01:07s\n","epoch 76 | loss: 0.12563 | val_0_mse: 0.14946000277996063|  0:01:08s\n","epoch 77 | loss: 0.12006 | val_0_mse: 0.13155999779701233|  0:01:09s\n","epoch 78 | loss: 0.11886 | val_0_mse: 0.17354999482631683|  0:01:10s\n","epoch 79 | loss: 0.11742 | val_0_mse: 0.12200000137090683|  0:01:11s\n","epoch 80 | loss: 0.11821 | val_0_mse: 0.14571000635623932|  0:01:12s\n","epoch 81 | loss: 0.11597 | val_0_mse: 0.12937000393867493|  0:01:13s\n","epoch 82 | loss: 0.11463 | val_0_mse: 0.14910000562667847|  0:01:14s\n","epoch 83 | loss: 0.11556 | val_0_mse: 0.13367000222206116|  0:01:14s\n","\n","Early stopping occurred at epoch 83 with best_epoch = 73 and best_val_0_mse = 0.10897000133991241\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 12:20:28,015] Trial 79 finished with value: 0.10897083580493927 and parameters: {'n_d': 57, 'n_steps': 4, 'gamma': 1.0434496880630628, 'n_independent': 2, 'n_shared': 5, 'momentum': 0.18846322475629523}. Best is trial 31 with value: 0.07662469148635864.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 27.4025 | val_0_mse: 310314.1875|  0:00:00s\n","epoch 1  | loss: 2.55251 | val_0_mse: 44669.21875|  0:00:01s\n","epoch 2  | loss: 0.75454 | val_0_mse: 2701.945068359375|  0:00:02s\n","epoch 3  | loss: 0.48698 | val_0_mse: 1298.5634765625|  0:00:03s\n","epoch 4  | loss: 0.3036  | val_0_mse: 1748.145263671875|  0:00:04s\n","epoch 5  | loss: 0.28139 | val_0_mse: 2022.586181640625|  0:00:04s\n","epoch 6  | loss: 0.23432 | val_0_mse: 712.0128173828125|  0:00:05s\n","epoch 7  | loss: 0.17298 | val_0_mse: 156.22096252441406|  0:00:06s\n","epoch 8  | loss: 0.1788  | val_0_mse: 239.35409545898438|  0:00:07s\n","epoch 9  | loss: 0.24829 | val_0_mse: 448.98382568359375|  0:00:08s\n","epoch 10 | loss: 0.19556 | val_0_mse: 447.3096923828125|  0:00:09s\n","epoch 11 | loss: 0.25484 | val_0_mse: 500.2403564453125|  0:00:09s\n","epoch 12 | loss: 0.21093 | val_0_mse: 158.1751251220703|  0:00:10s\n","epoch 13 | loss: 0.27527 | val_0_mse: 59.28160858154297|  0:00:11s\n","epoch 14 | loss: 0.2715  | val_0_mse: 91.7728500366211|  0:00:12s\n","epoch 15 | loss: 0.17682 | val_0_mse: 46.285430908203125|  0:00:13s\n","epoch 16 | loss: 0.18379 | val_0_mse: 31.229320526123047|  0:00:14s\n","epoch 17 | loss: 0.19694 | val_0_mse: 13.3129301071167|  0:00:14s\n","epoch 18 | loss: 0.22278 | val_0_mse: 8.685219764709473|  0:00:15s\n","epoch 19 | loss: 0.1723  | val_0_mse: 18.808570861816406|  0:00:16s\n","epoch 20 | loss: 0.1414  | val_0_mse: 11.850709915161133|  0:00:17s\n","epoch 21 | loss: 0.13251 | val_0_mse: 21.235170364379883|  0:00:18s\n","epoch 22 | loss: 0.12465 | val_0_mse: 17.2618408203125|  0:00:18s\n","epoch 23 | loss: 0.1642  | val_0_mse: 6.690569877624512|  0:00:19s\n","epoch 24 | loss: 0.19517 | val_0_mse: 4.064859867095947|  0:00:20s\n","epoch 25 | loss: 0.16832 | val_0_mse: 3.506350040435791|  0:00:21s\n","epoch 26 | loss: 0.12597 | val_0_mse: 4.451000213623047|  0:00:22s\n","epoch 27 | loss: 0.14307 | val_0_mse: 3.304270029067993|  0:00:23s\n","epoch 28 | loss: 0.17294 | val_0_mse: 1.915410041809082|  0:00:23s\n","epoch 29 | loss: 0.15974 | val_0_mse: 1.5491100549697876|  0:00:24s\n","epoch 30 | loss: 0.11146 | val_0_mse: 1.7339500188827515|  0:00:25s\n","epoch 31 | loss: 0.10748 | val_0_mse: 0.8357300162315369|  0:00:26s\n","epoch 32 | loss: 0.11504 | val_0_mse: 0.835860013961792|  0:00:26s\n","epoch 33 | loss: 0.12912 | val_0_mse: 0.6140499711036682|  0:00:27s\n","epoch 34 | loss: 0.13388 | val_0_mse: 0.968970000743866|  0:00:28s\n","epoch 35 | loss: 0.11081 | val_0_mse: 0.6439899802207947|  0:00:29s\n","epoch 36 | loss: 0.1051  | val_0_mse: 0.6297100186347961|  0:00:29s\n","epoch 37 | loss: 0.11411 | val_0_mse: 0.6465499997138977|  0:00:30s\n","epoch 38 | loss: 0.12763 | val_0_mse: 0.45340999960899353|  0:00:31s\n","epoch 39 | loss: 0.10803 | val_0_mse: 0.3832100033760071|  0:00:32s\n","epoch 40 | loss: 0.10288 | val_0_mse: 0.29545000195503235|  0:00:33s\n","epoch 41 | loss: 0.11611 | val_0_mse: 0.37268999218940735|  0:00:34s\n","epoch 42 | loss: 0.10909 | val_0_mse: 0.4007999897003174|  0:00:34s\n","epoch 43 | loss: 0.10052 | val_0_mse: 0.24618999660015106|  0:00:35s\n","epoch 44 | loss: 0.14053 | val_0_mse: 0.22020000219345093|  0:00:36s\n","epoch 45 | loss: 0.15152 | val_0_mse: 0.1888599991798401|  0:00:37s\n","epoch 46 | loss: 0.15337 | val_0_mse: 0.6913300156593323|  0:00:37s\n","epoch 47 | loss: 0.17005 | val_0_mse: 0.26396000385284424|  0:00:38s\n","epoch 48 | loss: 0.1518  | val_0_mse: 0.32708999514579773|  0:00:39s\n","epoch 49 | loss: 0.13415 | val_0_mse: 0.15744000673294067|  0:00:40s\n","epoch 50 | loss: 0.12395 | val_0_mse: 0.24722999334335327|  0:00:41s\n","epoch 51 | loss: 0.12634 | val_0_mse: 0.11494000256061554|  0:00:41s\n","epoch 52 | loss: 0.12087 | val_0_mse: 0.19175000488758087|  0:00:42s\n","epoch 53 | loss: 0.12888 | val_0_mse: 0.11309999972581863|  0:00:43s\n","epoch 54 | loss: 0.12795 | val_0_mse: 0.1993499994277954|  0:00:44s\n","epoch 55 | loss: 0.1248  | val_0_mse: 0.11168999969959259|  0:00:44s\n","epoch 56 | loss: 0.12192 | val_0_mse: 0.1813099980354309|  0:00:45s\n","epoch 57 | loss: 0.1188  | val_0_mse: 0.10405000299215317|  0:00:46s\n","epoch 58 | loss: 0.12359 | val_0_mse: 0.16222000122070312|  0:00:47s\n","epoch 59 | loss: 0.11792 | val_0_mse: 0.09424000233411789|  0:00:48s\n","epoch 60 | loss: 0.11714 | val_0_mse: 0.13607999682426453|  0:00:48s\n","epoch 61 | loss: 0.12176 | val_0_mse: 0.09921000152826309|  0:00:49s\n","epoch 62 | loss: 0.12007 | val_0_mse: 0.1385200023651123|  0:00:50s\n","epoch 63 | loss: 0.11792 | val_0_mse: 0.09668999910354614|  0:00:51s\n","epoch 64 | loss: 0.12478 | val_0_mse: 0.1393900066614151|  0:00:51s\n","epoch 65 | loss: 0.11957 | val_0_mse: 0.11163999885320663|  0:00:52s\n","epoch 66 | loss: 0.1214  | val_0_mse: 0.12907999753952026|  0:00:53s\n","epoch 67 | loss: 0.1213  | val_0_mse: 0.10067000240087509|  0:00:54s\n","epoch 68 | loss: 0.1155  | val_0_mse: 0.11422999948263168|  0:00:55s\n","epoch 69 | loss: 0.12408 | val_0_mse: 0.11649999767541885|  0:00:55s\n","\n","Early stopping occurred at epoch 69 with best_epoch = 59 and best_val_0_mse = 0.09424000233411789\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 12:21:24,373] Trial 80 finished with value: 0.09423740953207016 and parameters: {'n_d': 48, 'n_steps': 4, 'gamma': 1.0003508060872361, 'n_independent': 2, 'n_shared': 4, 'momentum': 0.16294508447905603}. Best is trial 31 with value: 0.07662469148635864.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 53.42971| val_0_mse: 3430.7109375|  0:00:00s\n","epoch 1  | loss: 1.42507 | val_0_mse: 2224.1669921875|  0:00:01s\n","epoch 2  | loss: 0.47537 | val_0_mse: 646.556396484375|  0:00:01s\n","epoch 3  | loss: 0.37841 | val_0_mse: 1889.2601318359375|  0:00:02s\n","epoch 4  | loss: 0.30884 | val_0_mse: 1054.4676513671875|  0:00:03s\n","epoch 5  | loss: 0.31289 | val_0_mse: 1313.3831787109375|  0:00:03s\n","epoch 6  | loss: 0.2894  | val_0_mse: 623.9158325195312|  0:00:04s\n","epoch 7  | loss: 0.24426 | val_0_mse: 228.76544189453125|  0:00:05s\n","epoch 8  | loss: 0.28961 | val_0_mse: 89.58000183105469|  0:00:05s\n","epoch 9  | loss: 0.26716 | val_0_mse: 223.24362182617188|  0:00:06s\n","epoch 10 | loss: 0.22273 | val_0_mse: 252.0267333984375|  0:00:07s\n","epoch 11 | loss: 0.21352 | val_0_mse: 149.88902282714844|  0:00:07s\n","epoch 12 | loss: 0.1844  | val_0_mse: 31.187780380249023|  0:00:08s\n","epoch 13 | loss: 0.1855  | val_0_mse: 27.28561019897461|  0:00:09s\n","epoch 14 | loss: 0.14403 | val_0_mse: 36.04507827758789|  0:00:09s\n","epoch 15 | loss: 0.17505 | val_0_mse: 18.947460174560547|  0:00:10s\n","epoch 16 | loss: 0.14788 | val_0_mse: 6.771349906921387|  0:00:11s\n","epoch 17 | loss: 0.18487 | val_0_mse: 8.780699729919434|  0:00:11s\n","epoch 18 | loss: 0.16457 | val_0_mse: 7.0475897789001465|  0:00:12s\n","epoch 19 | loss: 0.14338 | val_0_mse: 2.6355299949645996|  0:00:12s\n","epoch 20 | loss: 0.13294 | val_0_mse: 2.060580015182495|  0:00:13s\n","epoch 21 | loss: 0.12188 | val_0_mse: 1.8013299703598022|  0:00:14s\n","epoch 22 | loss: 0.11497 | val_0_mse: 1.842769980430603|  0:00:14s\n","epoch 23 | loss: 0.11953 | val_0_mse: 1.504870057106018|  0:00:15s\n","epoch 24 | loss: 0.11362 | val_0_mse: 1.5627700090408325|  0:00:16s\n","epoch 25 | loss: 0.12456 | val_0_mse: 1.0359200239181519|  0:00:16s\n","epoch 26 | loss: 0.1395  | val_0_mse: 0.9281200170516968|  0:00:17s\n","epoch 27 | loss: 0.10678 | val_0_mse: 0.5161399841308594|  0:00:18s\n","epoch 28 | loss: 0.10841 | val_0_mse: 1.029520034790039|  0:00:18s\n","epoch 29 | loss: 0.11027 | val_0_mse: 0.6593499779701233|  0:00:19s\n","epoch 30 | loss: 0.11416 | val_0_mse: 0.628059983253479|  0:00:19s\n","epoch 31 | loss: 0.09947 | val_0_mse: 0.9260600209236145|  0:00:20s\n","epoch 32 | loss: 0.09755 | val_0_mse: 0.6837499737739563|  0:00:21s\n","epoch 33 | loss: 0.11221 | val_0_mse: 0.9739400148391724|  0:00:21s\n","epoch 34 | loss: 0.12929 | val_0_mse: 0.3873099982738495|  0:00:22s\n","epoch 35 | loss: 0.12366 | val_0_mse: 0.7515699863433838|  0:00:23s\n","epoch 36 | loss: 0.09566 | val_0_mse: 0.4602000117301941|  0:00:23s\n","epoch 37 | loss: 0.09309 | val_0_mse: 0.5098299980163574|  0:00:24s\n","epoch 38 | loss: 0.09841 | val_0_mse: 0.35148000717163086|  0:00:25s\n","epoch 39 | loss: 0.09539 | val_0_mse: 0.30647000670433044|  0:00:25s\n","epoch 40 | loss: 0.13763 | val_0_mse: 0.44652000069618225|  0:00:26s\n","epoch 41 | loss: 0.1501  | val_0_mse: 0.24514000117778778|  0:00:27s\n","epoch 42 | loss: 0.13534 | val_0_mse: 0.360509991645813|  0:00:27s\n","epoch 43 | loss: 0.11901 | val_0_mse: 0.2030400037765503|  0:00:28s\n","epoch 44 | loss: 0.11963 | val_0_mse: 0.31255999207496643|  0:00:28s\n","epoch 45 | loss: 0.11916 | val_0_mse: 0.18698999285697937|  0:00:29s\n","epoch 46 | loss: 0.11863 | val_0_mse: 0.2655999958515167|  0:00:30s\n","epoch 47 | loss: 0.11851 | val_0_mse: 0.13639000058174133|  0:00:30s\n","epoch 48 | loss: 0.11758 | val_0_mse: 0.20860999822616577|  0:00:31s\n","epoch 49 | loss: 0.11928 | val_0_mse: 0.16580000519752502|  0:00:32s\n","epoch 50 | loss: 0.11188 | val_0_mse: 0.20983999967575073|  0:00:32s\n","epoch 51 | loss: 0.10499 | val_0_mse: 0.13122999668121338|  0:00:33s\n","epoch 52 | loss: 0.09541 | val_0_mse: 0.1879899948835373|  0:00:34s\n","epoch 53 | loss: 0.09882 | val_0_mse: 0.11263000220060349|  0:00:34s\n","epoch 54 | loss: 0.0895  | val_0_mse: 0.15685999393463135|  0:00:35s\n","epoch 55 | loss: 0.09552 | val_0_mse: 0.17201000452041626|  0:00:35s\n","epoch 56 | loss: 0.0916  | val_0_mse: 0.09960000216960907|  0:00:36s\n","epoch 57 | loss: 0.09603 | val_0_mse: 0.10462000221014023|  0:00:37s\n","epoch 58 | loss: 0.11211 | val_0_mse: 0.1177700012922287|  0:00:37s\n","epoch 59 | loss: 0.11912 | val_0_mse: 0.10576000064611435|  0:00:38s\n","epoch 60 | loss: 0.12503 | val_0_mse: 0.08918000012636185|  0:00:39s\n","epoch 61 | loss: 0.22784 | val_0_mse: 0.16071000695228577|  0:00:39s\n","epoch 62 | loss: 0.13694 | val_0_mse: 0.09354999661445618|  0:00:40s\n","epoch 63 | loss: 0.11996 | val_0_mse: 0.14174999296665192|  0:00:41s\n","epoch 64 | loss: 0.11916 | val_0_mse: 0.09198000282049179|  0:00:41s\n","epoch 65 | loss: 0.10867 | val_0_mse: 0.10430999845266342|  0:00:42s\n","epoch 66 | loss: 0.10566 | val_0_mse: 0.08739999681711197|  0:00:42s\n","epoch 67 | loss: 0.10672 | val_0_mse: 0.09311000257730484|  0:00:43s\n","epoch 68 | loss: 0.1004  | val_0_mse: 0.087459996342659|  0:00:44s\n","epoch 69 | loss: 0.11074 | val_0_mse: 0.09628999978303909|  0:00:44s\n","epoch 70 | loss: 0.10398 | val_0_mse: 0.08281999826431274|  0:00:45s\n","epoch 71 | loss: 0.10672 | val_0_mse: 0.09942000359296799|  0:00:46s\n","epoch 72 | loss: 0.10426 | val_0_mse: 0.09077999740839005|  0:00:46s\n","epoch 73 | loss: 0.10613 | val_0_mse: 0.09193000197410583|  0:00:47s\n","epoch 74 | loss: 0.10538 | val_0_mse: 0.08229999989271164|  0:00:48s\n","epoch 75 | loss: 0.10288 | val_0_mse: 0.10287000238895416|  0:00:48s\n","epoch 76 | loss: 0.1036  | val_0_mse: 0.08229000121355057|  0:00:49s\n","epoch 77 | loss: 0.10696 | val_0_mse: 0.09346000105142593|  0:00:49s\n","epoch 78 | loss: 0.09756 | val_0_mse: 0.09437999874353409|  0:00:50s\n","epoch 79 | loss: 0.1044  | val_0_mse: 0.09929999709129333|  0:00:51s\n","epoch 80 | loss: 0.10026 | val_0_mse: 0.09877000004053116|  0:00:51s\n","epoch 81 | loss: 0.10267 | val_0_mse: 0.09726999700069427|  0:00:52s\n","epoch 82 | loss: 0.10036 | val_0_mse: 0.08952999860048294|  0:00:53s\n","epoch 83 | loss: 0.09978 | val_0_mse: 0.08799999952316284|  0:00:53s\n","epoch 84 | loss: 0.10017 | val_0_mse: 0.09848999977111816|  0:00:54s\n","epoch 85 | loss: 0.10428 | val_0_mse: 0.08184999972581863|  0:00:55s\n","epoch 86 | loss: 0.09835 | val_0_mse: 0.08669000118970871|  0:00:55s\n","epoch 87 | loss: 0.10689 | val_0_mse: 0.093019999563694|  0:00:56s\n","epoch 88 | loss: 0.10131 | val_0_mse: 0.09465999901294708|  0:00:57s\n","epoch 89 | loss: 0.10273 | val_0_mse: 0.08816999942064285|  0:00:57s\n","epoch 90 | loss: 0.1032  | val_0_mse: 0.10273999720811844|  0:00:58s\n","epoch 91 | loss: 0.09783 | val_0_mse: 0.08133000135421753|  0:00:59s\n","epoch 92 | loss: 0.08517 | val_0_mse: 0.0865899994969368|  0:00:59s\n","epoch 93 | loss: 0.08656 | val_0_mse: 0.09210000187158585|  0:01:00s\n","epoch 94 | loss: 0.07992 | val_0_mse: 0.08323000371456146|  0:01:00s\n","epoch 95 | loss: 0.08749 | val_0_mse: 0.08058000355958939|  0:01:01s\n","epoch 96 | loss: 0.07769 | val_0_mse: 0.08614999800920486|  0:01:02s\n","epoch 97 | loss: 0.08002 | val_0_mse: 0.10971999913454056|  0:01:02s\n","epoch 98 | loss: 0.08857 | val_0_mse: 0.08208999782800674|  0:01:03s\n","epoch 99 | loss: 0.11109 | val_0_mse: 0.1190200001001358|  0:01:04s\n","Stop training because you reached max_epochs = 100 with best_epoch = 95 and best_val_0_mse = 0.08058000355958939\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 12:22:28,780] Trial 81 finished with value: 0.0805770680308342 and parameters: {'n_d': 51, 'n_steps': 3, 'gamma': 1.0734164425388755, 'n_independent': 1, 'n_shared': 5, 'momentum': 0.24190854972445303}. Best is trial 31 with value: 0.07662469148635864.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 34.92177| val_0_mse: 5396.1181640625|  0:00:00s\n","epoch 1  | loss: 2.51163 | val_0_mse: 968.1228637695312|  0:00:01s\n","epoch 2  | loss: 0.99335 | val_0_mse: 1386.5673828125|  0:00:02s\n","epoch 3  | loss: 0.63908 | val_0_mse: 307.2853088378906|  0:00:02s\n","epoch 4  | loss: 0.37016 | val_0_mse: 1913.5025634765625|  0:00:03s\n","epoch 5  | loss: 0.40039 | val_0_mse: 851.0115966796875|  0:00:04s\n","epoch 6  | loss: 0.31432 | val_0_mse: 295.9464416503906|  0:00:04s\n","epoch 7  | loss: 0.33176 | val_0_mse: 126.88773345947266|  0:00:05s\n","epoch 8  | loss: 0.25453 | val_0_mse: 153.1664276123047|  0:00:06s\n","epoch 9  | loss: 0.23534 | val_0_mse: 63.5726203918457|  0:00:07s\n","epoch 10 | loss: 0.19026 | val_0_mse: 64.93434143066406|  0:00:07s\n","epoch 11 | loss: 0.22314 | val_0_mse: 30.20599937438965|  0:00:08s\n","epoch 12 | loss: 0.19545 | val_0_mse: 61.04962158203125|  0:00:09s\n","epoch 13 | loss: 0.17982 | val_0_mse: 36.67866134643555|  0:00:09s\n","epoch 14 | loss: 0.16032 | val_0_mse: 41.240169525146484|  0:00:10s\n","epoch 15 | loss: 0.13825 | val_0_mse: 26.715360641479492|  0:00:11s\n","epoch 16 | loss: 0.12307 | val_0_mse: 15.867420196533203|  0:00:12s\n","epoch 17 | loss: 0.12634 | val_0_mse: 14.49647045135498|  0:00:12s\n","epoch 18 | loss: 0.11883 | val_0_mse: 13.10260009765625|  0:00:13s\n","epoch 19 | loss: 0.1426  | val_0_mse: 14.56050968170166|  0:00:14s\n","epoch 20 | loss: 0.16213 | val_0_mse: 8.248749732971191|  0:00:15s\n","epoch 21 | loss: 0.12604 | val_0_mse: 5.801050186157227|  0:00:15s\n","epoch 22 | loss: 0.11827 | val_0_mse: 4.1456298828125|  0:00:16s\n","epoch 23 | loss: 0.11112 | val_0_mse: 3.5864899158477783|  0:00:17s\n","epoch 24 | loss: 0.11209 | val_0_mse: 3.4991700649261475|  0:00:17s\n","epoch 25 | loss: 0.15233 | val_0_mse: 2.0156500339508057|  0:00:18s\n","epoch 26 | loss: 0.11144 | val_0_mse: 2.906019926071167|  0:00:19s\n","epoch 27 | loss: 0.09872 | val_0_mse: 1.1604399681091309|  0:00:20s\n","epoch 28 | loss: 0.09748 | val_0_mse: 1.7100199460983276|  0:00:20s\n","epoch 29 | loss: 0.10772 | val_0_mse: 0.542169988155365|  0:00:21s\n","epoch 30 | loss: 0.10645 | val_0_mse: 0.6080899834632874|  0:00:22s\n","epoch 31 | loss: 0.14402 | val_0_mse: 0.8913599848747253|  0:00:23s\n","epoch 32 | loss: 0.27694 | val_0_mse: 0.9487699866294861|  0:00:23s\n","epoch 33 | loss: 0.17784 | val_0_mse: 0.6849899888038635|  0:00:24s\n","epoch 34 | loss: 0.1635  | val_0_mse: 1.1198500394821167|  0:00:25s\n","epoch 35 | loss: 0.12643 | val_0_mse: 0.5278400182723999|  0:00:25s\n","epoch 36 | loss: 0.12739 | val_0_mse: 0.7032399773597717|  0:00:26s\n","epoch 37 | loss: 0.12526 | val_0_mse: 0.33748000860214233|  0:00:27s\n","epoch 38 | loss: 0.12117 | val_0_mse: 0.7104799747467041|  0:00:28s\n","epoch 39 | loss: 0.1245  | val_0_mse: 0.321289986371994|  0:00:28s\n","epoch 40 | loss: 0.1192  | val_0_mse: 0.6413000226020813|  0:00:29s\n","epoch 41 | loss: 0.12024 | val_0_mse: 0.2035599946975708|  0:00:30s\n","epoch 42 | loss: 0.12239 | val_0_mse: 0.5292999744415283|  0:00:31s\n","epoch 43 | loss: 0.12085 | val_0_mse: 0.19554999470710754|  0:00:31s\n","epoch 44 | loss: 0.11837 | val_0_mse: 0.4816400110721588|  0:00:32s\n","epoch 45 | loss: 0.11443 | val_0_mse: 0.17102999985218048|  0:00:33s\n","epoch 46 | loss: 0.12153 | val_0_mse: 0.4133400022983551|  0:00:34s\n","epoch 47 | loss: 0.11421 | val_0_mse: 0.14799000322818756|  0:00:34s\n","epoch 48 | loss: 0.11533 | val_0_mse: 0.38732999563217163|  0:00:35s\n","epoch 49 | loss: 0.11418 | val_0_mse: 0.13262000679969788|  0:00:36s\n","epoch 50 | loss: 0.11127 | val_0_mse: 0.3743700087070465|  0:00:37s\n","epoch 51 | loss: 0.12208 | val_0_mse: 0.1378600001335144|  0:00:37s\n","epoch 52 | loss: 0.13258 | val_0_mse: 0.2871899902820587|  0:00:38s\n","epoch 53 | loss: 0.13108 | val_0_mse: 0.12144000083208084|  0:00:39s\n","epoch 54 | loss: 0.11736 | val_0_mse: 0.24400000274181366|  0:00:40s\n","epoch 55 | loss: 0.11545 | val_0_mse: 0.13134999573230743|  0:00:40s\n","epoch 56 | loss: 0.12573 | val_0_mse: 0.22513000667095184|  0:00:41s\n","epoch 57 | loss: 0.12138 | val_0_mse: 0.10997000336647034|  0:00:42s\n","epoch 58 | loss: 0.11712 | val_0_mse: 0.2119700014591217|  0:00:42s\n","epoch 59 | loss: 0.11697 | val_0_mse: 0.09617999941110611|  0:00:43s\n","epoch 60 | loss: 0.1094  | val_0_mse: 0.19509999454021454|  0:00:44s\n","epoch 61 | loss: 0.11287 | val_0_mse: 0.10181999951601028|  0:00:44s\n","epoch 62 | loss: 0.12947 | val_0_mse: 0.16540999710559845|  0:00:45s\n","epoch 63 | loss: 0.10892 | val_0_mse: 0.10920000076293945|  0:00:46s\n","epoch 64 | loss: 0.10721 | val_0_mse: 0.17925000190734863|  0:00:46s\n","epoch 65 | loss: 0.10684 | val_0_mse: 0.10085000097751617|  0:00:47s\n","epoch 66 | loss: 0.11094 | val_0_mse: 0.17903000116348267|  0:00:48s\n","epoch 67 | loss: 0.10492 | val_0_mse: 0.12032999843358994|  0:00:49s\n","epoch 68 | loss: 0.10628 | val_0_mse: 0.1415800005197525|  0:00:49s\n","epoch 69 | loss: 0.10523 | val_0_mse: 0.11722999811172485|  0:00:50s\n","\n","Early stopping occurred at epoch 69 with best_epoch = 59 and best_val_0_mse = 0.09617999941110611\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 12:23:19,614] Trial 82 finished with value: 0.09617979824542999 and parameters: {'n_d': 50, 'n_steps': 3, 'gamma': 1.08543482762157, 'n_independent': 2, 'n_shared': 5, 'momentum': 0.24484987145042864}. Best is trial 31 with value: 0.07662469148635864.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 39.38835| val_0_mse: 1633.0338134765625|  0:00:00s\n","epoch 1  | loss: 1.59029 | val_0_mse: 89.82492065429688|  0:00:01s\n","epoch 2  | loss: 0.5317  | val_0_mse: 65.5363998413086|  0:00:01s\n","epoch 3  | loss: 0.409   | val_0_mse: 173.40769958496094|  0:00:02s\n","epoch 4  | loss: 0.45611 | val_0_mse: 60.38059997558594|  0:00:03s\n","epoch 5  | loss: 0.27474 | val_0_mse: 110.50801086425781|  0:00:03s\n","epoch 6  | loss: 0.23753 | val_0_mse: 67.37596130371094|  0:00:04s\n","epoch 7  | loss: 0.32248 | val_0_mse: 15.385809898376465|  0:00:04s\n","epoch 8  | loss: 0.29907 | val_0_mse: 23.940820693969727|  0:00:05s\n","epoch 9  | loss: 0.27516 | val_0_mse: 10.604669570922852|  0:00:06s\n","epoch 10 | loss: 0.23167 | val_0_mse: 5.5183000564575195|  0:00:06s\n","epoch 11 | loss: 0.29452 | val_0_mse: 13.427189826965332|  0:00:07s\n","epoch 12 | loss: 0.23919 | val_0_mse: 6.693620204925537|  0:00:08s\n","epoch 13 | loss: 0.20812 | val_0_mse: 3.9051198959350586|  0:00:08s\n","epoch 14 | loss: 0.1858  | val_0_mse: 3.272200107574463|  0:00:09s\n","epoch 15 | loss: 0.24762 | val_0_mse: 2.2365400791168213|  0:00:10s\n","epoch 16 | loss: 0.22922 | val_0_mse: 3.841099977493286|  0:00:10s\n","epoch 17 | loss: 0.16826 | val_0_mse: 3.0197598934173584|  0:00:11s\n","epoch 18 | loss: 0.1792  | val_0_mse: 1.3319799900054932|  0:00:12s\n","epoch 19 | loss: 0.16577 | val_0_mse: 1.3953800201416016|  0:00:12s\n","epoch 20 | loss: 0.19356 | val_0_mse: 0.6430799961090088|  0:00:13s\n","epoch 21 | loss: 0.23339 | val_0_mse: 2.7161900997161865|  0:00:13s\n","epoch 22 | loss: 0.15308 | val_0_mse: 1.6877599954605103|  0:00:14s\n","epoch 23 | loss: 0.14605 | val_0_mse: 1.5728600025177002|  0:00:15s\n","epoch 24 | loss: 0.14278 | val_0_mse: 1.1395200490951538|  0:00:15s\n","epoch 25 | loss: 0.1644  | val_0_mse: 1.2888400554656982|  0:00:16s\n","epoch 26 | loss: 0.13202 | val_0_mse: 0.718209981918335|  0:00:16s\n","epoch 27 | loss: 0.13457 | val_0_mse: 0.7999600172042847|  0:00:17s\n","epoch 28 | loss: 0.12482 | val_0_mse: 0.586650013923645|  0:00:18s\n","epoch 29 | loss: 0.13339 | val_0_mse: 0.6717600226402283|  0:00:18s\n","epoch 30 | loss: 0.16246 | val_0_mse: 0.69309002161026|  0:00:19s\n","epoch 31 | loss: 0.16255 | val_0_mse: 0.39647001028060913|  0:00:20s\n","epoch 32 | loss: 0.12508 | val_0_mse: 0.463809996843338|  0:00:20s\n","epoch 33 | loss: 0.14644 | val_0_mse: 0.30483001470565796|  0:00:21s\n","epoch 34 | loss: 0.15032 | val_0_mse: 0.36531001329421997|  0:00:22s\n","epoch 35 | loss: 0.1539  | val_0_mse: 0.6251000165939331|  0:00:22s\n","epoch 36 | loss: 0.14512 | val_0_mse: 0.30834001302719116|  0:00:23s\n","epoch 37 | loss: 0.11091 | val_0_mse: 0.328359991312027|  0:00:24s\n","epoch 38 | loss: 0.12043 | val_0_mse: 0.2837600111961365|  0:00:24s\n","epoch 39 | loss: 0.10929 | val_0_mse: 0.33105000853538513|  0:00:25s\n","epoch 40 | loss: 0.11496 | val_0_mse: 0.5208100080490112|  0:00:25s\n","epoch 41 | loss: 0.13069 | val_0_mse: 0.18671000003814697|  0:00:26s\n","epoch 42 | loss: 0.14174 | val_0_mse: 0.3797000050544739|  0:00:27s\n","epoch 43 | loss: 0.11223 | val_0_mse: 0.3275899887084961|  0:00:27s\n","epoch 44 | loss: 0.13023 | val_0_mse: 0.20473000407218933|  0:00:28s\n","epoch 45 | loss: 0.09598 | val_0_mse: 0.17558999359607697|  0:00:28s\n","epoch 46 | loss: 0.11074 | val_0_mse: 0.1705400049686432|  0:00:29s\n","epoch 47 | loss: 0.09839 | val_0_mse: 0.18216000497341156|  0:00:30s\n","epoch 48 | loss: 0.12376 | val_0_mse: 0.15588000416755676|  0:00:30s\n","epoch 49 | loss: 0.14722 | val_0_mse: 0.14699000120162964|  0:00:31s\n","epoch 50 | loss: 0.14756 | val_0_mse: 0.4241499900817871|  0:00:32s\n","epoch 51 | loss: 0.18013 | val_0_mse: 0.1592700034379959|  0:00:32s\n","epoch 52 | loss: 0.11689 | val_0_mse: 0.12172999978065491|  0:00:33s\n","epoch 53 | loss: 0.09815 | val_0_mse: 0.22045999765396118|  0:00:34s\n","epoch 54 | loss: 0.10602 | val_0_mse: 0.1457500010728836|  0:00:34s\n","epoch 55 | loss: 0.10022 | val_0_mse: 0.1502700001001358|  0:00:35s\n","epoch 56 | loss: 0.1118  | val_0_mse: 0.09764999896287918|  0:00:36s\n","epoch 57 | loss: 0.09694 | val_0_mse: 0.09961999952793121|  0:00:36s\n","epoch 58 | loss: 0.10942 | val_0_mse: 0.17509999871253967|  0:00:37s\n","epoch 59 | loss: 0.10669 | val_0_mse: 0.11699000000953674|  0:00:37s\n","epoch 60 | loss: 0.10115 | val_0_mse: 0.12031999975442886|  0:00:38s\n","epoch 61 | loss: 0.09891 | val_0_mse: 0.14796000719070435|  0:00:39s\n","epoch 62 | loss: 0.09813 | val_0_mse: 0.09035000205039978|  0:00:39s\n","epoch 63 | loss: 0.09639 | val_0_mse: 0.09203000366687775|  0:00:40s\n","epoch 64 | loss: 0.09384 | val_0_mse: 0.10716000199317932|  0:00:40s\n","epoch 65 | loss: 0.09869 | val_0_mse: 0.09842000156641006|  0:00:41s\n","epoch 66 | loss: 0.09785 | val_0_mse: 0.12044999748468399|  0:00:42s\n","epoch 67 | loss: 0.09253 | val_0_mse: 0.11283999681472778|  0:00:42s\n","epoch 68 | loss: 0.09753 | val_0_mse: 0.11873999983072281|  0:00:43s\n","epoch 69 | loss: 0.09803 | val_0_mse: 0.10987000167369843|  0:00:44s\n","epoch 70 | loss: 0.09231 | val_0_mse: 0.10349000245332718|  0:00:44s\n","epoch 71 | loss: 0.10334 | val_0_mse: 0.1085600033402443|  0:00:45s\n","epoch 72 | loss: 0.12875 | val_0_mse: 0.11283999681472778|  0:00:46s\n","\n","Early stopping occurred at epoch 72 with best_epoch = 62 and best_val_0_mse = 0.09035000205039978\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 12:24:05,951] Trial 83 finished with value: 0.09034698456525803 and parameters: {'n_d': 57, 'n_steps': 3, 'gamma': 1.0736851624605384, 'n_independent': 1, 'n_shared': 5, 'momentum': 0.1951489419447487}. Best is trial 31 with value: 0.07662469148635864.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 29.32762| val_0_mse: 20823.15234375|  0:00:00s\n","epoch 1  | loss: 1.53853 | val_0_mse: 1564.8968505859375|  0:00:01s\n","epoch 2  | loss: 0.61586 | val_0_mse: 1936.9561767578125|  0:00:02s\n","epoch 3  | loss: 0.39922 | val_0_mse: 393.60980224609375|  0:00:02s\n","epoch 4  | loss: 0.36308 | val_0_mse: 1203.6837158203125|  0:00:03s\n","epoch 5  | loss: 0.30788 | val_0_mse: 71.31230163574219|  0:00:04s\n","epoch 6  | loss: 0.28668 | val_0_mse: 671.5382690429688|  0:00:04s\n","epoch 7  | loss: 0.21463 | val_0_mse: 386.5269470214844|  0:00:05s\n","epoch 8  | loss: 0.26099 | val_0_mse: 324.1037292480469|  0:00:06s\n","epoch 9  | loss: 0.23312 | val_0_mse: 169.25180053710938|  0:00:06s\n","epoch 10 | loss: 0.21163 | val_0_mse: 207.5974578857422|  0:00:07s\n","epoch 11 | loss: 0.17726 | val_0_mse: 141.76629638671875|  0:00:08s\n","epoch 12 | loss: 0.15588 | val_0_mse: 92.81507110595703|  0:00:08s\n","epoch 13 | loss: 0.17602 | val_0_mse: 72.0225830078125|  0:00:09s\n","epoch 14 | loss: 0.17254 | val_0_mse: 49.942420959472656|  0:00:10s\n","epoch 15 | loss: 0.17727 | val_0_mse: 45.65224075317383|  0:00:11s\n","epoch 16 | loss: 0.19774 | val_0_mse: 51.37797164916992|  0:00:11s\n","epoch 17 | loss: 0.18337 | val_0_mse: 32.22624969482422|  0:00:12s\n","epoch 18 | loss: 0.18736 | val_0_mse: 28.187129974365234|  0:00:13s\n","epoch 19 | loss: 0.1776  | val_0_mse: 18.328060150146484|  0:00:13s\n","epoch 20 | loss: 0.13782 | val_0_mse: 12.411860466003418|  0:00:14s\n","epoch 21 | loss: 0.1392  | val_0_mse: 8.977620124816895|  0:00:15s\n","epoch 22 | loss: 0.12977 | val_0_mse: 6.0047101974487305|  0:00:16s\n","epoch 23 | loss: 0.13041 | val_0_mse: 6.757559776306152|  0:00:16s\n","epoch 24 | loss: 0.12298 | val_0_mse: 7.003729820251465|  0:00:17s\n","epoch 25 | loss: 0.11594 | val_0_mse: 5.9268598556518555|  0:00:18s\n","epoch 26 | loss: 0.12144 | val_0_mse: 3.664180040359497|  0:00:18s\n","epoch 27 | loss: 0.10557 | val_0_mse: 2.891319990158081|  0:00:19s\n","epoch 28 | loss: 0.10183 | val_0_mse: 3.169290065765381|  0:00:20s\n","epoch 29 | loss: 0.10372 | val_0_mse: 2.817500114440918|  0:00:20s\n","epoch 30 | loss: 0.10327 | val_0_mse: 2.9134199619293213|  0:00:21s\n","epoch 31 | loss: 0.13373 | val_0_mse: 1.8291200399398804|  0:00:22s\n","epoch 32 | loss: 0.145   | val_0_mse: 1.1761499643325806|  0:00:23s\n","epoch 33 | loss: 0.10901 | val_0_mse: 0.594290018081665|  0:00:23s\n","epoch 34 | loss: 0.11854 | val_0_mse: 1.3907699584960938|  0:00:24s\n","epoch 35 | loss: 0.11235 | val_0_mse: 0.9452400207519531|  0:00:25s\n","epoch 36 | loss: 0.10099 | val_0_mse: 0.906499981880188|  0:00:25s\n","epoch 37 | loss: 0.10453 | val_0_mse: 0.8729000091552734|  0:00:26s\n","epoch 38 | loss: 0.13136 | val_0_mse: 0.5717599987983704|  0:00:27s\n","epoch 39 | loss: 0.11498 | val_0_mse: 0.6009399890899658|  0:00:27s\n","epoch 40 | loss: 0.10664 | val_0_mse: 0.35646000504493713|  0:00:28s\n","epoch 41 | loss: 0.12576 | val_0_mse: 0.587369978427887|  0:00:29s\n","epoch 42 | loss: 0.14604 | val_0_mse: 0.20738999545574188|  0:00:29s\n","epoch 43 | loss: 0.12557 | val_0_mse: 0.48844999074935913|  0:00:30s\n","epoch 44 | loss: 0.12304 | val_0_mse: 0.22991999983787537|  0:00:31s\n","epoch 45 | loss: 0.11043 | val_0_mse: 0.23367999494075775|  0:00:31s\n","epoch 46 | loss: 0.10275 | val_0_mse: 0.2535899877548218|  0:00:32s\n","epoch 47 | loss: 0.11492 | val_0_mse: 0.16019999980926514|  0:00:33s\n","epoch 48 | loss: 0.12367 | val_0_mse: 0.2046699970960617|  0:00:34s\n","epoch 49 | loss: 0.09179 | val_0_mse: 0.15062999725341797|  0:00:34s\n","epoch 50 | loss: 0.11631 | val_0_mse: 0.41734999418258667|  0:00:35s\n","epoch 51 | loss: 0.1047  | val_0_mse: 0.2138500064611435|  0:00:36s\n","epoch 52 | loss: 0.0924  | val_0_mse: 0.19764000177383423|  0:00:36s\n","epoch 53 | loss: 0.08999 | val_0_mse: 0.10225000232458115|  0:00:37s\n","epoch 54 | loss: 0.09434 | val_0_mse: 0.09836000204086304|  0:00:38s\n","epoch 55 | loss: 0.1305  | val_0_mse: 0.1893099993467331|  0:00:39s\n","epoch 56 | loss: 0.10846 | val_0_mse: 0.09352999925613403|  0:00:39s\n","epoch 57 | loss: 0.12002 | val_0_mse: 0.18895000219345093|  0:00:40s\n","epoch 58 | loss: 0.09284 | val_0_mse: 0.10913000255823135|  0:00:41s\n","epoch 59 | loss: 0.08244 | val_0_mse: 0.10548000037670135|  0:00:41s\n","epoch 60 | loss: 0.08663 | val_0_mse: 0.09602999687194824|  0:00:42s\n","epoch 61 | loss: 0.0964  | val_0_mse: 0.090549997985363|  0:00:43s\n","epoch 62 | loss: 0.08265 | val_0_mse: 0.1137700006365776|  0:00:43s\n","epoch 63 | loss: 0.09667 | val_0_mse: 0.24324999749660492|  0:00:44s\n","epoch 64 | loss: 0.12531 | val_0_mse: 0.10151000320911407|  0:00:45s\n","epoch 65 | loss: 0.11516 | val_0_mse: 0.18185999989509583|  0:00:46s\n","epoch 66 | loss: 0.11341 | val_0_mse: 0.10586000233888626|  0:00:46s\n","epoch 67 | loss: 0.11122 | val_0_mse: 0.18578000366687775|  0:00:47s\n","epoch 68 | loss: 0.11303 | val_0_mse: 0.10998000204563141|  0:00:48s\n","epoch 69 | loss: 0.1146  | val_0_mse: 0.18140999972820282|  0:00:48s\n","epoch 70 | loss: 0.10661 | val_0_mse: 0.11167000234127045|  0:00:49s\n","epoch 71 | loss: 0.1061  | val_0_mse: 0.14187000691890717|  0:00:50s\n","\n","Early stopping occurred at epoch 71 with best_epoch = 61 and best_val_0_mse = 0.090549997985363\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 12:24:56,515] Trial 84 finished with value: 0.09054514765739441 and parameters: {'n_d': 43, 'n_steps': 3, 'gamma': 1.1357040938665404, 'n_independent': 2, 'n_shared': 5, 'momentum': 0.21349341401696062}. Best is trial 31 with value: 0.07662469148635864.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 50.5106 | val_0_mse: 925.639892578125|  0:00:00s\n","epoch 1  | loss: 2.20918 | val_0_mse: 302.1446533203125|  0:00:01s\n","epoch 2  | loss: 0.60301 | val_0_mse: 7116.59521484375|  0:00:01s\n","epoch 3  | loss: 0.39701 | val_0_mse: 3177.7294921875|  0:00:02s\n","epoch 4  | loss: 0.37723 | val_0_mse: 5613.15625|  0:00:03s\n","epoch 5  | loss: 0.25191 | val_0_mse: 715.8425903320312|  0:00:03s\n","epoch 6  | loss: 0.23885 | val_0_mse: 729.9463500976562|  0:00:04s\n","epoch 7  | loss: 0.25447 | val_0_mse: 794.7021484375|  0:00:05s\n","epoch 8  | loss: 0.21342 | val_0_mse: 143.54547119140625|  0:00:05s\n","epoch 9  | loss: 0.18997 | val_0_mse: 536.1813354492188|  0:00:06s\n","epoch 10 | loss: 0.19746 | val_0_mse: 166.5498504638672|  0:00:06s\n","epoch 11 | loss: 0.17131 | val_0_mse: 66.87095642089844|  0:00:07s\n","epoch 12 | loss: 0.13814 | val_0_mse: 219.6414794921875|  0:00:08s\n","epoch 13 | loss: 0.14485 | val_0_mse: 51.114498138427734|  0:00:08s\n","epoch 14 | loss: 0.17354 | val_0_mse: 104.10944366455078|  0:00:09s\n","epoch 15 | loss: 0.15342 | val_0_mse: 43.128421783447266|  0:00:10s\n","epoch 16 | loss: 0.13868 | val_0_mse: 94.24781036376953|  0:00:10s\n","epoch 17 | loss: 0.17204 | val_0_mse: 53.06623840332031|  0:00:11s\n","epoch 18 | loss: 0.18848 | val_0_mse: 26.120229721069336|  0:00:11s\n","epoch 19 | loss: 0.15794 | val_0_mse: 29.42414093017578|  0:00:12s\n","epoch 20 | loss: 0.12964 | val_0_mse: 6.291259765625|  0:00:13s\n","epoch 21 | loss: 0.17287 | val_0_mse: 4.042500019073486|  0:00:13s\n","epoch 22 | loss: 0.17    | val_0_mse: 4.650030136108398|  0:00:14s\n","epoch 23 | loss: 0.16229 | val_0_mse: 3.969059944152832|  0:00:15s\n","epoch 24 | loss: 0.1599  | val_0_mse: 9.030170440673828|  0:00:15s\n","epoch 25 | loss: 0.14725 | val_0_mse: 5.462039947509766|  0:00:16s\n","epoch 26 | loss: 0.15565 | val_0_mse: 3.958329916000366|  0:00:17s\n","epoch 27 | loss: 0.15227 | val_0_mse: 3.1524899005889893|  0:00:17s\n","epoch 28 | loss: 0.14015 | val_0_mse: 3.5801899433135986|  0:00:18s\n","epoch 29 | loss: 0.10831 | val_0_mse: 3.484260082244873|  0:00:18s\n","epoch 30 | loss: 0.11109 | val_0_mse: 1.6547900438308716|  0:00:19s\n","epoch 31 | loss: 0.10826 | val_0_mse: 0.7187399864196777|  0:00:20s\n","epoch 32 | loss: 0.10217 | val_0_mse: 0.9222800135612488|  0:00:20s\n","epoch 33 | loss: 0.10602 | val_0_mse: 0.758109986782074|  0:00:21s\n","epoch 34 | loss: 0.14012 | val_0_mse: 0.6483399868011475|  0:00:22s\n","epoch 35 | loss: 0.175   | val_0_mse: 1.5362399816513062|  0:00:22s\n","epoch 36 | loss: 0.15567 | val_0_mse: 1.053670048713684|  0:00:23s\n","epoch 37 | loss: 0.12542 | val_0_mse: 0.6057900190353394|  0:00:23s\n","epoch 38 | loss: 0.11351 | val_0_mse: 0.8200899958610535|  0:00:24s\n","epoch 39 | loss: 0.10255 | val_0_mse: 0.5257099866867065|  0:00:25s\n","epoch 40 | loss: 0.12671 | val_0_mse: 0.5379999876022339|  0:00:25s\n","epoch 41 | loss: 0.10651 | val_0_mse: 0.30153998732566833|  0:00:26s\n","epoch 42 | loss: 0.09587 | val_0_mse: 0.32041001319885254|  0:00:27s\n","epoch 43 | loss: 0.10351 | val_0_mse: 0.24342000484466553|  0:00:27s\n","epoch 44 | loss: 0.09697 | val_0_mse: 0.1895499974489212|  0:00:28s\n","epoch 45 | loss: 0.10982 | val_0_mse: 0.20709000527858734|  0:00:29s\n","epoch 46 | loss: 0.09311 | val_0_mse: 0.2178100049495697|  0:00:29s\n","epoch 47 | loss: 0.09505 | val_0_mse: 0.26238998770713806|  0:00:30s\n","epoch 48 | loss: 0.10216 | val_0_mse: 0.2097499966621399|  0:00:30s\n","epoch 49 | loss: 0.09344 | val_0_mse: 0.16957999765872955|  0:00:31s\n","epoch 50 | loss: 0.09896 | val_0_mse: 0.20949000120162964|  0:00:32s\n","epoch 51 | loss: 0.0964  | val_0_mse: 0.22179999947547913|  0:00:32s\n","epoch 52 | loss: 0.09427 | val_0_mse: 0.16574999690055847|  0:00:33s\n","epoch 53 | loss: 0.08756 | val_0_mse: 0.14614999294281006|  0:00:33s\n","epoch 54 | loss: 0.0917  | val_0_mse: 0.1193699985742569|  0:00:34s\n","epoch 55 | loss: 0.12167 | val_0_mse: 0.3078700006008148|  0:00:35s\n","epoch 56 | loss: 0.14431 | val_0_mse: 0.15863999724388123|  0:00:35s\n","epoch 57 | loss: 0.12673 | val_0_mse: 0.2834399938583374|  0:00:36s\n","epoch 58 | loss: 0.10734 | val_0_mse: 0.13936999440193176|  0:00:37s\n","epoch 59 | loss: 0.10123 | val_0_mse: 0.15534000098705292|  0:00:37s\n","epoch 60 | loss: 0.10545 | val_0_mse: 0.15320000052452087|  0:00:38s\n","epoch 61 | loss: 0.09978 | val_0_mse: 0.11191999912261963|  0:00:39s\n","epoch 62 | loss: 0.11742 | val_0_mse: 0.11793000251054764|  0:00:39s\n","epoch 63 | loss: 0.12476 | val_0_mse: 0.12997999787330627|  0:00:40s\n","epoch 64 | loss: 0.12076 | val_0_mse: 0.09239000082015991|  0:00:40s\n","epoch 65 | loss: 0.12017 | val_0_mse: 0.14388999342918396|  0:00:41s\n","epoch 66 | loss: 0.11674 | val_0_mse: 0.08816999942064285|  0:00:42s\n","epoch 67 | loss: 0.11379 | val_0_mse: 0.11174000054597855|  0:00:42s\n","epoch 68 | loss: 0.11299 | val_0_mse: 0.11016999930143356|  0:00:43s\n","epoch 69 | loss: 0.11348 | val_0_mse: 0.1084899976849556|  0:00:44s\n","epoch 70 | loss: 0.11402 | val_0_mse: 0.09842000156641006|  0:00:44s\n","epoch 71 | loss: 0.10894 | val_0_mse: 0.12657000124454498|  0:00:45s\n","epoch 72 | loss: 0.11112 | val_0_mse: 0.09538999944925308|  0:00:45s\n","epoch 73 | loss: 0.10741 | val_0_mse: 0.10881000012159348|  0:00:46s\n","epoch 74 | loss: 0.10637 | val_0_mse: 0.10728000104427338|  0:00:47s\n","epoch 75 | loss: 0.10739 | val_0_mse: 0.10192999988794327|  0:00:47s\n","epoch 76 | loss: 0.10883 | val_0_mse: 0.09058000147342682|  0:00:48s\n","\n","Early stopping occurred at epoch 76 with best_epoch = 66 and best_val_0_mse = 0.08816999942064285\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 12:25:45,242] Trial 85 finished with value: 0.08817200362682343 and parameters: {'n_d': 52, 'n_steps': 3, 'gamma': 1.030011957625451, 'n_independent': 1, 'n_shared': 5, 'momentum': 0.2277927193838531}. Best is trial 31 with value: 0.07662469148635864.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 39.34823| val_0_mse: 209435.203125|  0:00:00s\n","epoch 1  | loss: 1.66506 | val_0_mse: 15828.2802734375|  0:00:01s\n","epoch 2  | loss: 0.89385 | val_0_mse: 4399.4580078125|  0:00:02s\n","epoch 3  | loss: 0.61246 | val_0_mse: 2385.02685546875|  0:00:02s\n","epoch 4  | loss: 0.53783 | val_0_mse: 1236.802734375|  0:00:03s\n","epoch 5  | loss: 0.41577 | val_0_mse: 419.8395080566406|  0:00:04s\n","epoch 6  | loss: 0.27048 | val_0_mse: 300.44610595703125|  0:00:04s\n","epoch 7  | loss: 0.32541 | val_0_mse: 173.79498291015625|  0:00:05s\n","epoch 8  | loss: 0.25319 | val_0_mse: 172.6171875|  0:00:06s\n","epoch 9  | loss: 0.21468 | val_0_mse: 234.6758270263672|  0:00:06s\n","epoch 10 | loss: 0.23428 | val_0_mse: 414.1752014160156|  0:00:07s\n","epoch 11 | loss: 0.34735 | val_0_mse: 556.797607421875|  0:00:08s\n","epoch 12 | loss: 0.22791 | val_0_mse: 318.6337585449219|  0:00:09s\n","epoch 13 | loss: 0.13902 | val_0_mse: 189.81507873535156|  0:00:09s\n","epoch 14 | loss: 0.13553 | val_0_mse: 158.83485412597656|  0:00:10s\n","epoch 15 | loss: 0.13482 | val_0_mse: 164.53485107421875|  0:00:11s\n","epoch 16 | loss: 0.14946 | val_0_mse: 104.53431701660156|  0:00:11s\n","epoch 17 | loss: 0.1451  | val_0_mse: 40.117130279541016|  0:00:12s\n","epoch 18 | loss: 0.14769 | val_0_mse: 64.12081146240234|  0:00:13s\n","epoch 19 | loss: 0.14651 | val_0_mse: 71.18003845214844|  0:00:14s\n","epoch 20 | loss: 0.12699 | val_0_mse: 33.072139739990234|  0:00:14s\n","epoch 21 | loss: 0.12785 | val_0_mse: 36.770179748535156|  0:00:15s\n","epoch 22 | loss: 0.15295 | val_0_mse: 15.815139770507812|  0:00:16s\n","epoch 23 | loss: 0.1666  | val_0_mse: 17.425100326538086|  0:00:16s\n","epoch 24 | loss: 0.15991 | val_0_mse: 21.382959365844727|  0:00:17s\n","epoch 25 | loss: 0.14222 | val_0_mse: 7.728270053863525|  0:00:18s\n","epoch 26 | loss: 0.15447 | val_0_mse: 8.543169975280762|  0:00:18s\n","epoch 27 | loss: 0.12379 | val_0_mse: 5.3689799308776855|  0:00:19s\n","epoch 28 | loss: 0.11071 | val_0_mse: 3.8922998905181885|  0:00:20s\n","epoch 29 | loss: 0.12204 | val_0_mse: 9.504429817199707|  0:00:20s\n","epoch 30 | loss: 0.17998 | val_0_mse: 0.9336400032043457|  0:00:21s\n","epoch 31 | loss: 0.13708 | val_0_mse: 8.506750106811523|  0:00:22s\n","epoch 32 | loss: 0.13438 | val_0_mse: 5.477709770202637|  0:00:23s\n","epoch 33 | loss: 0.13166 | val_0_mse: 5.101779937744141|  0:00:23s\n","epoch 34 | loss: 0.12951 | val_0_mse: 1.997290015220642|  0:00:24s\n","epoch 35 | loss: 0.10467 | val_0_mse: 1.3301899433135986|  0:00:25s\n","epoch 36 | loss: 0.09555 | val_0_mse: 1.0311100482940674|  0:00:25s\n","epoch 37 | loss: 0.09303 | val_0_mse: 0.8378999829292297|  0:00:26s\n","epoch 38 | loss: 0.10418 | val_0_mse: 0.8436999917030334|  0:00:27s\n","epoch 39 | loss: 0.09435 | val_0_mse: 0.9238399863243103|  0:00:27s\n","epoch 40 | loss: 0.10144 | val_0_mse: 1.2091799974441528|  0:00:28s\n","epoch 41 | loss: 0.10277 | val_0_mse: 0.43946999311447144|  0:00:29s\n","epoch 42 | loss: 0.09406 | val_0_mse: 0.48717001080513|  0:00:30s\n","epoch 43 | loss: 0.09336 | val_0_mse: 0.43250998854637146|  0:00:30s\n","epoch 44 | loss: 0.09244 | val_0_mse: 0.4191800057888031|  0:00:31s\n","epoch 45 | loss: 0.09423 | val_0_mse: 0.37185999751091003|  0:00:32s\n","epoch 46 | loss: 0.10428 | val_0_mse: 0.2925400137901306|  0:00:32s\n","epoch 47 | loss: 0.09793 | val_0_mse: 0.42899999022483826|  0:00:33s\n","epoch 48 | loss: 0.08833 | val_0_mse: 0.175819993019104|  0:00:34s\n","epoch 49 | loss: 0.08941 | val_0_mse: 0.20802000164985657|  0:00:34s\n","epoch 50 | loss: 0.08848 | val_0_mse: 0.20825999975204468|  0:00:35s\n","epoch 51 | loss: 0.08876 | val_0_mse: 0.23523999750614166|  0:00:36s\n","epoch 52 | loss: 0.11309 | val_0_mse: 0.3102799952030182|  0:00:37s\n","epoch 53 | loss: 0.14648 | val_0_mse: 0.16256000101566315|  0:00:37s\n","epoch 54 | loss: 0.10235 | val_0_mse: 0.1830199956893921|  0:00:38s\n","epoch 55 | loss: 0.09423 | val_0_mse: 0.12789000570774078|  0:00:39s\n","epoch 56 | loss: 0.09421 | val_0_mse: 0.22724999487400055|  0:00:39s\n","epoch 57 | loss: 0.09633 | val_0_mse: 0.16098999977111816|  0:00:40s\n","epoch 58 | loss: 0.09654 | val_0_mse: 0.14597000181674957|  0:00:41s\n","epoch 59 | loss: 0.08748 | val_0_mse: 0.12560999393463135|  0:00:41s\n","epoch 60 | loss: 0.08701 | val_0_mse: 0.1756500005722046|  0:00:42s\n","epoch 61 | loss: 0.10624 | val_0_mse: 0.1798499971628189|  0:00:43s\n","epoch 62 | loss: 0.12354 | val_0_mse: 0.18324999511241913|  0:00:44s\n","epoch 63 | loss: 0.1588  | val_0_mse: 0.18289999663829803|  0:00:44s\n","epoch 64 | loss: 0.11112 | val_0_mse: 0.10919000208377838|  0:00:45s\n","epoch 65 | loss: 0.10034 | val_0_mse: 0.1486400067806244|  0:00:46s\n","epoch 66 | loss: 0.1125  | val_0_mse: 0.11062999814748764|  0:00:46s\n","epoch 67 | loss: 0.09982 | val_0_mse: 0.1080000028014183|  0:00:47s\n","epoch 68 | loss: 0.09796 | val_0_mse: 0.09711000323295593|  0:00:48s\n","epoch 69 | loss: 0.08786 | val_0_mse: 0.09109000116586685|  0:00:48s\n","epoch 70 | loss: 0.09547 | val_0_mse: 0.12154000252485275|  0:00:49s\n","epoch 71 | loss: 0.08296 | val_0_mse: 0.09290000051259995|  0:00:50s\n","epoch 72 | loss: 0.08258 | val_0_mse: 0.09777999669313431|  0:00:50s\n","epoch 73 | loss: 0.09048 | val_0_mse: 0.11704999953508377|  0:00:51s\n","epoch 74 | loss: 0.08676 | val_0_mse: 0.11467000097036362|  0:00:52s\n","epoch 75 | loss: 0.08917 | val_0_mse: 0.08795999735593796|  0:00:52s\n","epoch 76 | loss: 0.08118 | val_0_mse: 0.10405000299215317|  0:00:53s\n","epoch 77 | loss: 0.09304 | val_0_mse: 0.10738000273704529|  0:00:54s\n","epoch 78 | loss: 0.09045 | val_0_mse: 0.0899600014090538|  0:00:55s\n","epoch 79 | loss: 0.08251 | val_0_mse: 0.10029000043869019|  0:00:55s\n","epoch 80 | loss: 0.0985  | val_0_mse: 0.11807999759912491|  0:00:56s\n","epoch 81 | loss: 0.13054 | val_0_mse: 0.09900999814271927|  0:00:57s\n","epoch 82 | loss: 0.11495 | val_0_mse: 0.0968099981546402|  0:00:57s\n","epoch 83 | loss: 0.09794 | val_0_mse: 0.0954200029373169|  0:00:58s\n","epoch 84 | loss: 0.13274 | val_0_mse: 0.17674000561237335|  0:00:59s\n","epoch 85 | loss: 0.11176 | val_0_mse: 0.09786999970674515|  0:00:59s\n","\n","Early stopping occurred at epoch 85 with best_epoch = 75 and best_val_0_mse = 0.08795999735593796\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 12:26:45,530] Trial 86 finished with value: 0.0879598930478096 and parameters: {'n_d': 47, 'n_steps': 3, 'gamma': 1.1177613568677105, 'n_independent': 3, 'n_shared': 4, 'momentum': 0.2547729698346182}. Best is trial 31 with value: 0.07662469148635864.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 27.72356| val_0_mse: 285409.53125|  0:00:00s\n","epoch 1  | loss: 2.64366 | val_0_mse: 3640.046142578125|  0:00:01s\n","epoch 2  | loss: 0.89022 | val_0_mse: 7084.4755859375|  0:00:02s\n","epoch 3  | loss: 0.50354 | val_0_mse: 728.2115478515625|  0:00:03s\n","epoch 4  | loss: 0.47208 | val_0_mse: 480.1940002441406|  0:00:04s\n","epoch 5  | loss: 0.3985  | val_0_mse: 794.572509765625|  0:00:05s\n","epoch 6  | loss: 0.28473 | val_0_mse: 232.45919799804688|  0:00:06s\n","epoch 7  | loss: 0.3387  | val_0_mse: 119.4065933227539|  0:00:06s\n","epoch 8  | loss: 0.26546 | val_0_mse: 117.21083068847656|  0:00:07s\n","epoch 9  | loss: 0.25006 | val_0_mse: 82.60330200195312|  0:00:08s\n","epoch 10 | loss: 0.20732 | val_0_mse: 107.48786163330078|  0:00:09s\n","epoch 11 | loss: 0.21549 | val_0_mse: 43.05329132080078|  0:00:10s\n","epoch 12 | loss: 0.19064 | val_0_mse: 18.68246078491211|  0:00:11s\n","epoch 13 | loss: 0.19259 | val_0_mse: 7.9870100021362305|  0:00:11s\n","epoch 14 | loss: 0.16806 | val_0_mse: 14.47128963470459|  0:00:12s\n","epoch 15 | loss: 0.16261 | val_0_mse: 8.208649635314941|  0:00:13s\n","epoch 16 | loss: 0.14531 | val_0_mse: 4.928140163421631|  0:00:14s\n","epoch 17 | loss: 0.12437 | val_0_mse: 3.802570104598999|  0:00:15s\n","epoch 18 | loss: 0.12281 | val_0_mse: 3.779129981994629|  0:00:15s\n","epoch 19 | loss: 0.12252 | val_0_mse: 6.725249767303467|  0:00:16s\n","epoch 20 | loss: 0.11764 | val_0_mse: 2.994080066680908|  0:00:17s\n","epoch 21 | loss: 0.11675 | val_0_mse: 3.057610034942627|  0:00:18s\n","epoch 22 | loss: 0.11306 | val_0_mse: 3.7164299488067627|  0:00:19s\n","epoch 23 | loss: 0.11836 | val_0_mse: 1.2798899412155151|  0:00:20s\n","epoch 24 | loss: 0.13817 | val_0_mse: 1.1230599880218506|  0:00:20s\n","epoch 25 | loss: 0.13473 | val_0_mse: 0.6945300102233887|  0:00:21s\n","epoch 26 | loss: 0.1224  | val_0_mse: 0.9641299843788147|  0:00:22s\n","epoch 27 | loss: 0.11732 | val_0_mse: 0.6030799746513367|  0:00:23s\n","epoch 28 | loss: 0.12212 | val_0_mse: 0.417820006608963|  0:00:24s\n","epoch 29 | loss: 0.13149 | val_0_mse: 0.505299985408783|  0:00:25s\n","epoch 30 | loss: 0.14995 | val_0_mse: 0.40794000029563904|  0:00:25s\n","epoch 31 | loss: 0.1177  | val_0_mse: 0.47209998965263367|  0:00:26s\n","epoch 32 | loss: 0.12923 | val_0_mse: 0.47854000329971313|  0:00:27s\n","epoch 33 | loss: 0.11785 | val_0_mse: 0.5637800097465515|  0:00:28s\n","epoch 34 | loss: 0.12589 | val_0_mse: 0.5618100166320801|  0:00:29s\n","epoch 35 | loss: 0.117   | val_0_mse: 0.5123199820518494|  0:00:30s\n","epoch 36 | loss: 0.10846 | val_0_mse: 0.4768199920654297|  0:00:30s\n","epoch 37 | loss: 0.0977  | val_0_mse: 0.4699600040912628|  0:00:31s\n","epoch 38 | loss: 0.09542 | val_0_mse: 0.4277699887752533|  0:00:32s\n","epoch 39 | loss: 0.08914 | val_0_mse: 0.3115899860858917|  0:00:33s\n","epoch 40 | loss: 0.09241 | val_0_mse: 0.42820000648498535|  0:00:34s\n","epoch 41 | loss: 0.09611 | val_0_mse: 0.6120399832725525|  0:00:35s\n","epoch 42 | loss: 0.09483 | val_0_mse: 0.34880998730659485|  0:00:36s\n","epoch 43 | loss: 0.11075 | val_0_mse: 0.18302999436855316|  0:00:36s\n","epoch 44 | loss: 0.11598 | val_0_mse: 0.28084999322891235|  0:00:37s\n","epoch 45 | loss: 0.11548 | val_0_mse: 0.26225998997688293|  0:00:38s\n","epoch 46 | loss: 0.11585 | val_0_mse: 0.291949987411499|  0:00:39s\n","epoch 47 | loss: 0.1108  | val_0_mse: 0.1862100064754486|  0:00:40s\n","epoch 48 | loss: 0.10211 | val_0_mse: 0.1652899980545044|  0:00:41s\n","epoch 49 | loss: 0.09329 | val_0_mse: 0.18562999367713928|  0:00:41s\n","epoch 50 | loss: 0.09708 | val_0_mse: 0.15973000228405|  0:00:42s\n","epoch 51 | loss: 0.13453 | val_0_mse: 0.15037000179290771|  0:00:43s\n","epoch 52 | loss: 0.15111 | val_0_mse: 0.24098999798297882|  0:00:44s\n","epoch 53 | loss: 0.12386 | val_0_mse: 0.1262200027704239|  0:00:45s\n","epoch 54 | loss: 0.12312 | val_0_mse: 0.12748999893665314|  0:00:46s\n","epoch 55 | loss: 0.09733 | val_0_mse: 0.11247000098228455|  0:00:46s\n","epoch 56 | loss: 0.08694 | val_0_mse: 0.10778000205755234|  0:00:47s\n","epoch 57 | loss: 0.08549 | val_0_mse: 0.12771999835968018|  0:00:48s\n","epoch 58 | loss: 0.0859  | val_0_mse: 0.11214999854564667|  0:00:49s\n","epoch 59 | loss: 0.08835 | val_0_mse: 0.08760000020265579|  0:00:50s\n","epoch 60 | loss: 0.09862 | val_0_mse: 0.22644999623298645|  0:00:51s\n","epoch 61 | loss: 0.11794 | val_0_mse: 0.12168999761343002|  0:00:51s\n","epoch 62 | loss: 0.12067 | val_0_mse: 0.20845000445842743|  0:00:52s\n","epoch 63 | loss: 0.11455 | val_0_mse: 0.11242000013589859|  0:00:53s\n","epoch 64 | loss: 0.11404 | val_0_mse: 0.15147000551223755|  0:00:54s\n","epoch 65 | loss: 0.10811 | val_0_mse: 0.09696999937295914|  0:00:55s\n","epoch 66 | loss: 0.1207  | val_0_mse: 0.21416999399662018|  0:00:55s\n","epoch 67 | loss: 0.14572 | val_0_mse: 0.18988999724388123|  0:00:56s\n","epoch 68 | loss: 0.11627 | val_0_mse: 0.09991999715566635|  0:00:57s\n","epoch 69 | loss: 0.11658 | val_0_mse: 0.1638599932193756|  0:00:58s\n","\n","Early stopping occurred at epoch 69 with best_epoch = 59 and best_val_0_mse = 0.08760000020265579\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 12:27:44,470] Trial 87 finished with value: 0.08760255575180054 and parameters: {'n_d': 45, 'n_steps': 3, 'gamma': 1.1690991184835335, 'n_independent': 4, 'n_shared': 5, 'momentum': 0.2175790801286897}. Best is trial 31 with value: 0.07662469148635864.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 56.71833| val_0_mse: 506.9609069824219|  0:00:00s\n","epoch 1  | loss: 1.2084  | val_0_mse: 714.8778686523438|  0:00:00s\n","epoch 2  | loss: 0.48043 | val_0_mse: 294.1384582519531|  0:00:01s\n","epoch 3  | loss: 0.34733 | val_0_mse: 7281.345703125|  0:00:02s\n","epoch 4  | loss: 0.30053 | val_0_mse: 5653.3984375|  0:00:02s\n","epoch 5  | loss: 0.34918 | val_0_mse: 220.2831268310547|  0:00:03s\n","epoch 6  | loss: 0.2712  | val_0_mse: 30.571460723876953|  0:00:03s\n","epoch 7  | loss: 0.23273 | val_0_mse: 20.374980926513672|  0:00:04s\n","epoch 8  | loss: 0.19153 | val_0_mse: 34.08823013305664|  0:00:04s\n","epoch 9  | loss: 0.16887 | val_0_mse: 15.691679954528809|  0:00:05s\n","epoch 10 | loss: 0.15317 | val_0_mse: 14.45343017578125|  0:00:05s\n","epoch 11 | loss: 0.15876 | val_0_mse: 13.947660446166992|  0:00:05s\n","epoch 12 | loss: 0.18642 | val_0_mse: 33.839881896972656|  0:00:06s\n","epoch 13 | loss: 0.17917 | val_0_mse: 37.80754089355469|  0:00:06s\n","epoch 14 | loss: 0.15973 | val_0_mse: 28.794340133666992|  0:00:07s\n","epoch 15 | loss: 0.15708 | val_0_mse: 4.632319927215576|  0:00:07s\n","epoch 16 | loss: 0.15087 | val_0_mse: 3.9669599533081055|  0:00:08s\n","epoch 17 | loss: 0.12961 | val_0_mse: 2.0041799545288086|  0:00:09s\n","epoch 18 | loss: 0.12482 | val_0_mse: 3.211590051651001|  0:00:09s\n","epoch 19 | loss: 0.12774 | val_0_mse: 6.003809928894043|  0:00:10s\n","epoch 20 | loss: 0.12436 | val_0_mse: 1.904710054397583|  0:00:10s\n","epoch 21 | loss: 0.12831 | val_0_mse: 7.181849956512451|  0:00:11s\n","epoch 22 | loss: 0.13659 | val_0_mse: 2.057529926300049|  0:00:11s\n","epoch 23 | loss: 0.16265 | val_0_mse: 4.003029823303223|  0:00:12s\n","epoch 24 | loss: 0.22328 | val_0_mse: 8.332249641418457|  0:00:12s\n","epoch 25 | loss: 0.19729 | val_0_mse: 7.470320224761963|  0:00:12s\n","epoch 26 | loss: 0.16211 | val_0_mse: 3.010780096054077|  0:00:13s\n","epoch 27 | loss: 0.1488  | val_0_mse: 2.2438900470733643|  0:00:13s\n","epoch 28 | loss: 0.13306 | val_0_mse: 2.515089988708496|  0:00:14s\n","epoch 29 | loss: 0.13662 | val_0_mse: 1.6728399991989136|  0:00:14s\n","epoch 30 | loss: 0.11218 | val_0_mse: 1.3643499612808228|  0:00:15s\n","epoch 31 | loss: 0.10863 | val_0_mse: 1.078220009803772|  0:00:15s\n","epoch 32 | loss: 0.10314 | val_0_mse: 0.7156599760055542|  0:00:16s\n","epoch 33 | loss: 0.09892 | val_0_mse: 0.7952799797058105|  0:00:16s\n","epoch 34 | loss: 0.10036 | val_0_mse: 0.9214900135993958|  0:00:17s\n","epoch 35 | loss: 0.1094  | val_0_mse: 1.041990041732788|  0:00:17s\n","epoch 36 | loss: 0.09703 | val_0_mse: 0.6166200041770935|  0:00:18s\n","epoch 37 | loss: 0.14139 | val_0_mse: 0.3300800025463104|  0:00:18s\n","epoch 38 | loss: 0.13098 | val_0_mse: 0.483460009098053|  0:00:19s\n","epoch 39 | loss: 0.10367 | val_0_mse: 0.33974000811576843|  0:00:19s\n","epoch 40 | loss: 0.1135  | val_0_mse: 0.3784700036048889|  0:00:20s\n","epoch 41 | loss: 0.12923 | val_0_mse: 0.22338999807834625|  0:00:20s\n","epoch 42 | loss: 0.09621 | val_0_mse: 0.28696998953819275|  0:00:21s\n","epoch 43 | loss: 0.09931 | val_0_mse: 0.33768999576568604|  0:00:21s\n","epoch 44 | loss: 0.09963 | val_0_mse: 0.23680000007152557|  0:00:22s\n","epoch 45 | loss: 0.10663 | val_0_mse: 0.29774001240730286|  0:00:22s\n","epoch 46 | loss: 0.0938  | val_0_mse: 0.17609000205993652|  0:00:23s\n","epoch 47 | loss: 0.10274 | val_0_mse: 0.18922999501228333|  0:00:23s\n","epoch 48 | loss: 0.09578 | val_0_mse: 0.20236000418663025|  0:00:24s\n","epoch 49 | loss: 0.10033 | val_0_mse: 0.19665999710559845|  0:00:24s\n","epoch 50 | loss: 0.09597 | val_0_mse: 0.16287000477313995|  0:00:25s\n","epoch 51 | loss: 0.09785 | val_0_mse: 0.17659999430179596|  0:00:25s\n","epoch 52 | loss: 0.09615 | val_0_mse: 0.16759000718593597|  0:00:26s\n","epoch 53 | loss: 0.09983 | val_0_mse: 0.16729000210762024|  0:00:26s\n","epoch 54 | loss: 0.10851 | val_0_mse: 0.2132599949836731|  0:00:27s\n","epoch 55 | loss: 0.11932 | val_0_mse: 0.1117200031876564|  0:00:27s\n","epoch 56 | loss: 0.09728 | val_0_mse: 0.12492000311613083|  0:00:28s\n","epoch 57 | loss: 0.09786 | val_0_mse: 0.0970500037074089|  0:00:28s\n","epoch 58 | loss: 0.08954 | val_0_mse: 0.09988000243902206|  0:00:29s\n","epoch 59 | loss: 0.09026 | val_0_mse: 0.12416999787092209|  0:00:29s\n","epoch 60 | loss: 0.08776 | val_0_mse: 0.09836000204086304|  0:00:30s\n","epoch 61 | loss: 0.08665 | val_0_mse: 0.12380000203847885|  0:00:30s\n","epoch 62 | loss: 0.11172 | val_0_mse: 0.1238899976015091|  0:00:31s\n","epoch 63 | loss: 0.11123 | val_0_mse: 0.13808000087738037|  0:00:31s\n","epoch 64 | loss: 0.09962 | val_0_mse: 0.10696999728679657|  0:00:32s\n","epoch 65 | loss: 0.09657 | val_0_mse: 0.10496000200510025|  0:00:32s\n","epoch 66 | loss: 0.09514 | val_0_mse: 0.08921000361442566|  0:00:33s\n","epoch 67 | loss: 0.09185 | val_0_mse: 0.10423000156879425|  0:00:33s\n","epoch 68 | loss: 0.09367 | val_0_mse: 0.10309000313282013|  0:00:33s\n","epoch 69 | loss: 0.09952 | val_0_mse: 0.10439000278711319|  0:00:34s\n","epoch 70 | loss: 0.11971 | val_0_mse: 0.1521500051021576|  0:00:34s\n","epoch 71 | loss: 0.18686 | val_0_mse: 0.17418000102043152|  0:00:35s\n","epoch 72 | loss: 0.12338 | val_0_mse: 0.19621999561786652|  0:00:35s\n","epoch 73 | loss: 0.11639 | val_0_mse: 0.09916999936103821|  0:00:36s\n","epoch 74 | loss: 0.098   | val_0_mse: 0.08681999891996384|  0:00:36s\n","epoch 75 | loss: 0.08491 | val_0_mse: 0.09183000028133392|  0:00:37s\n","epoch 76 | loss: 0.08596 | val_0_mse: 0.10405000299215317|  0:00:37s\n","epoch 77 | loss: 0.08722 | val_0_mse: 0.08743000030517578|  0:00:38s\n","epoch 78 | loss: 0.08588 | val_0_mse: 0.09264999628067017|  0:00:38s\n","epoch 79 | loss: 0.08481 | val_0_mse: 0.09793999791145325|  0:00:39s\n","epoch 80 | loss: 0.09196 | val_0_mse: 0.09239000082015991|  0:00:39s\n","epoch 81 | loss: 0.08621 | val_0_mse: 0.09734000265598297|  0:00:40s\n","epoch 82 | loss: 0.09885 | val_0_mse: 0.09098000079393387|  0:00:40s\n","epoch 83 | loss: 0.08556 | val_0_mse: 0.09160000085830688|  0:00:41s\n","epoch 84 | loss: 0.08887 | val_0_mse: 0.12325000017881393|  0:00:41s\n","\n","Early stopping occurred at epoch 84 with best_epoch = 74 and best_val_0_mse = 0.08681999891996384\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 12:28:26,545] Trial 88 finished with value: 0.08681706339120865 and parameters: {'n_d': 51, 'n_steps': 3, 'gamma': 1.0729635975698926, 'n_independent': 2, 'n_shared': 2, 'momentum': 0.2681828658293401}. Best is trial 31 with value: 0.07662469148635864.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 29.14749| val_0_mse: 60530.2109375|  0:00:01s\n","epoch 1  | loss: 2.5919  | val_0_mse: 1088.948486328125|  0:00:02s\n","epoch 2  | loss: 2.49274 | val_0_mse: 881.7398681640625|  0:00:03s\n","epoch 3  | loss: 1.59654 | val_0_mse: 2100.25537109375|  0:00:04s\n","epoch 4  | loss: 1.00635 | val_0_mse: 1866.4285888671875|  0:00:05s\n","epoch 5  | loss: 0.62441 | val_0_mse: 1076.4246826171875|  0:00:06s\n","epoch 6  | loss: 0.94767 | val_0_mse: 2208.669677734375|  0:00:07s\n","epoch 7  | loss: 0.40814 | val_0_mse: 1389.063720703125|  0:00:08s\n","epoch 8  | loss: 0.32146 | val_0_mse: 382.9052734375|  0:00:09s\n","epoch 9  | loss: 0.30909 | val_0_mse: 334.6345520019531|  0:00:10s\n","epoch 10 | loss: 0.34441 | val_0_mse: 454.48297119140625|  0:00:11s\n","epoch 11 | loss: 0.32427 | val_0_mse: 193.4229736328125|  0:00:12s\n","epoch 12 | loss: 0.28349 | val_0_mse: 174.72877502441406|  0:00:13s\n","epoch 13 | loss: 0.2575  | val_0_mse: 167.20794677734375|  0:00:14s\n","epoch 14 | loss: 0.18782 | val_0_mse: 40.91291046142578|  0:00:15s\n","epoch 15 | loss: 0.19324 | val_0_mse: 11.582209587097168|  0:00:16s\n","epoch 16 | loss: 0.23068 | val_0_mse: 7.852849960327148|  0:00:17s\n","epoch 17 | loss: 0.28817 | val_0_mse: 1.9647200107574463|  0:00:18s\n","epoch 18 | loss: 0.28637 | val_0_mse: 3.649090051651001|  0:00:19s\n","epoch 19 | loss: 0.21304 | val_0_mse: 1.565559983253479|  0:00:20s\n","epoch 20 | loss: 0.21299 | val_0_mse: 0.6434000134468079|  0:00:21s\n","epoch 21 | loss: 0.19311 | val_0_mse: 0.41075998544692993|  0:00:22s\n","epoch 22 | loss: 0.18769 | val_0_mse: 0.5188599824905396|  0:00:23s\n","epoch 23 | loss: 0.22767 | val_0_mse: 0.640030026435852|  0:00:24s\n","epoch 24 | loss: 0.15596 | val_0_mse: 0.44117000699043274|  0:00:25s\n","epoch 25 | loss: 0.1405  | val_0_mse: 0.2896899878978729|  0:00:26s\n","epoch 26 | loss: 0.14525 | val_0_mse: 0.6325299739837646|  0:00:27s\n","epoch 27 | loss: 0.14205 | val_0_mse: 0.39945998787879944|  0:00:28s\n","epoch 28 | loss: 0.15872 | val_0_mse: 0.6980000138282776|  0:00:29s\n","epoch 29 | loss: 0.21672 | val_0_mse: 0.30390000343322754|  0:00:30s\n","epoch 30 | loss: 0.14876 | val_0_mse: 0.47484999895095825|  0:00:31s\n","epoch 31 | loss: 0.14697 | val_0_mse: 0.4496699869632721|  0:00:32s\n","epoch 32 | loss: 0.13159 | val_0_mse: 0.44078001379966736|  0:00:33s\n","epoch 33 | loss: 0.15383 | val_0_mse: 0.4271000027656555|  0:00:34s\n","epoch 34 | loss: 0.12106 | val_0_mse: 0.37345999479293823|  0:00:35s\n","epoch 35 | loss: 0.17215 | val_0_mse: 0.39002999663352966|  0:00:36s\n","\n","Early stopping occurred at epoch 35 with best_epoch = 25 and best_val_0_mse = 0.2896899878978729\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 12:29:03,988] Trial 89 finished with value: 0.2896921932697296 and parameters: {'n_d': 41, 'n_steps': 6, 'gamma': 1.2069957853007522, 'n_independent': 1, 'n_shared': 5, 'momentum': 0.24227753133901617}. Best is trial 31 with value: 0.07662469148635864.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 76.18412| val_0_mse: 151942.984375|  0:00:00s\n","epoch 1  | loss: 2.13612 | val_0_mse: 2475.832763671875|  0:00:01s\n","epoch 2  | loss: 0.57337 | val_0_mse: 492.50506591796875|  0:00:02s\n","epoch 3  | loss: 0.40678 | val_0_mse: 1098.9488525390625|  0:00:03s\n","epoch 4  | loss: 0.31228 | val_0_mse: 375.7132263183594|  0:00:03s\n","epoch 5  | loss: 0.25859 | val_0_mse: 672.5695190429688|  0:00:04s\n","epoch 6  | loss: 0.21761 | val_0_mse: 2309.48291015625|  0:00:05s\n","epoch 7  | loss: 0.21525 | val_0_mse: 1175.5321044921875|  0:00:06s\n","epoch 8  | loss: 0.20398 | val_0_mse: 899.206298828125|  0:00:06s\n","epoch 9  | loss: 0.19079 | val_0_mse: 680.414794921875|  0:00:07s\n","epoch 10 | loss: 0.17902 | val_0_mse: 456.01385498046875|  0:00:08s\n","epoch 11 | loss: 0.17191 | val_0_mse: 376.1288146972656|  0:00:09s\n","epoch 12 | loss: 0.18225 | val_0_mse: 231.3041534423828|  0:00:09s\n","epoch 13 | loss: 0.17915 | val_0_mse: 174.7605743408203|  0:00:10s\n","epoch 14 | loss: 0.21157 | val_0_mse: 120.94624328613281|  0:00:11s\n","epoch 15 | loss: 0.19454 | val_0_mse: 103.00144958496094|  0:00:12s\n","epoch 16 | loss: 0.14833 | val_0_mse: 107.26286315917969|  0:00:12s\n","epoch 17 | loss: 0.15309 | val_0_mse: 75.2573013305664|  0:00:13s\n","epoch 18 | loss: 0.13508 | val_0_mse: 68.94481658935547|  0:00:14s\n","epoch 19 | loss: 0.15505 | val_0_mse: 61.11174011230469|  0:00:15s\n","epoch 20 | loss: 0.15611 | val_0_mse: 41.87131881713867|  0:00:16s\n","epoch 21 | loss: 0.14117 | val_0_mse: 51.08184051513672|  0:00:16s\n","epoch 22 | loss: 0.1322  | val_0_mse: 37.87662887573242|  0:00:17s\n","epoch 23 | loss: 0.13309 | val_0_mse: 20.24142074584961|  0:00:18s\n","epoch 24 | loss: 0.12476 | val_0_mse: 17.269359588623047|  0:00:19s\n","epoch 25 | loss: 0.12404 | val_0_mse: 8.003069877624512|  0:00:19s\n","epoch 26 | loss: 0.12111 | val_0_mse: 12.834779739379883|  0:00:20s\n","epoch 27 | loss: 0.11552 | val_0_mse: 10.841710090637207|  0:00:21s\n","epoch 28 | loss: 0.11999 | val_0_mse: 10.923410415649414|  0:00:22s\n","epoch 29 | loss: 0.12763 | val_0_mse: 5.082650184631348|  0:00:23s\n","epoch 30 | loss: 0.12018 | val_0_mse: 3.3274099826812744|  0:00:23s\n","epoch 31 | loss: 0.11233 | val_0_mse: 1.8191399574279785|  0:00:24s\n","epoch 32 | loss: 0.11333 | val_0_mse: 1.0239100456237793|  0:00:25s\n","epoch 33 | loss: 0.1187  | val_0_mse: 1.0040299892425537|  0:00:26s\n","epoch 34 | loss: 0.11162 | val_0_mse: 0.6594200134277344|  0:00:26s\n","epoch 35 | loss: 0.10648 | val_0_mse: 0.6857399940490723|  0:00:27s\n","epoch 36 | loss: 0.11065 | val_0_mse: 0.8324199914932251|  0:00:28s\n","epoch 37 | loss: 0.10758 | val_0_mse: 0.2583400011062622|  0:00:29s\n","epoch 38 | loss: 0.10218 | val_0_mse: 0.21315999329090118|  0:00:29s\n","epoch 39 | loss: 0.10275 | val_0_mse: 0.2521800100803375|  0:00:30s\n","epoch 40 | loss: 0.10705 | val_0_mse: 0.27312999963760376|  0:00:31s\n","epoch 41 | loss: 0.10217 | val_0_mse: 0.23705999553203583|  0:00:32s\n","epoch 42 | loss: 0.10014 | val_0_mse: 0.2545199990272522|  0:00:32s\n","epoch 43 | loss: 0.1044  | val_0_mse: 0.38207998871803284|  0:00:33s\n","epoch 44 | loss: 0.10387 | val_0_mse: 0.26965001225471497|  0:00:34s\n","epoch 45 | loss: 0.0917  | val_0_mse: 0.20607000589370728|  0:00:35s\n","epoch 46 | loss: 0.10189 | val_0_mse: 0.20366999506950378|  0:00:35s\n","epoch 47 | loss: 0.10026 | val_0_mse: 0.18429000675678253|  0:00:36s\n","epoch 48 | loss: 0.11674 | val_0_mse: 0.1996999979019165|  0:00:37s\n","epoch 49 | loss: 0.11446 | val_0_mse: 0.1534299999475479|  0:00:38s\n","epoch 50 | loss: 0.12873 | val_0_mse: 0.25363999605178833|  0:00:39s\n","epoch 51 | loss: 0.10202 | val_0_mse: 0.23451000452041626|  0:00:39s\n","epoch 52 | loss: 0.12607 | val_0_mse: 0.1280599981546402|  0:00:40s\n","epoch 53 | loss: 0.11646 | val_0_mse: 0.18337999284267426|  0:00:41s\n","epoch 54 | loss: 0.11317 | val_0_mse: 0.11027000099420547|  0:00:42s\n","epoch 55 | loss: 0.10651 | val_0_mse: 0.14768999814987183|  0:00:42s\n","epoch 56 | loss: 0.1093  | val_0_mse: 0.10952000319957733|  0:00:43s\n","epoch 57 | loss: 0.11218 | val_0_mse: 0.13818000257015228|  0:00:44s\n","epoch 58 | loss: 0.10676 | val_0_mse: 0.09655000269412994|  0:00:45s\n","epoch 59 | loss: 0.10794 | val_0_mse: 0.14722000062465668|  0:00:45s\n","epoch 60 | loss: 0.10678 | val_0_mse: 0.09837999939918518|  0:00:46s\n","epoch 61 | loss: 0.10614 | val_0_mse: 0.13529999554157257|  0:00:47s\n","epoch 62 | loss: 0.10674 | val_0_mse: 0.09570000320672989|  0:00:48s\n","epoch 63 | loss: 0.11713 | val_0_mse: 0.14751000702381134|  0:00:48s\n","epoch 64 | loss: 0.11537 | val_0_mse: 0.1114799976348877|  0:00:49s\n","epoch 65 | loss: 0.10904 | val_0_mse: 0.11840999871492386|  0:00:50s\n","epoch 66 | loss: 0.10567 | val_0_mse: 0.11810000240802765|  0:00:51s\n","epoch 67 | loss: 0.12059 | val_0_mse: 0.13267000019550323|  0:00:51s\n","epoch 68 | loss: 0.11308 | val_0_mse: 0.09681999683380127|  0:00:52s\n","epoch 69 | loss: 0.10806 | val_0_mse: 0.09691999852657318|  0:00:53s\n","epoch 70 | loss: 0.09243 | val_0_mse: 0.096950002014637|  0:00:54s\n","epoch 71 | loss: 0.10031 | val_0_mse: 0.09628000110387802|  0:00:54s\n","epoch 72 | loss: 0.09142 | val_0_mse: 0.09650000184774399|  0:00:55s\n","\n","Early stopping occurred at epoch 72 with best_epoch = 62 and best_val_0_mse = 0.09570000320672989\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 12:30:00,003] Trial 90 finished with value: 0.09569869190454483 and parameters: {'n_d': 35, 'n_steps': 4, 'gamma': 1.1522280657800574, 'n_independent': 1, 'n_shared': 5, 'momentum': 0.34502948342470896}. Best is trial 31 with value: 0.07662469148635864.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 32.15144| val_0_mse: 427019.03125|  0:00:00s\n","epoch 1  | loss: 1.04948 | val_0_mse: 11075.814453125|  0:00:01s\n","epoch 2  | loss: 0.50659 | val_0_mse: 474.6521911621094|  0:00:01s\n","epoch 3  | loss: 0.38645 | val_0_mse: 59.474918365478516|  0:00:02s\n","epoch 4  | loss: 0.27305 | val_0_mse: 186.9371795654297|  0:00:03s\n","epoch 5  | loss: 0.22931 | val_0_mse: 140.91632080078125|  0:00:03s\n","epoch 6  | loss: 0.2161  | val_0_mse: 308.1387939453125|  0:00:04s\n","epoch 7  | loss: 0.22549 | val_0_mse: 136.0988006591797|  0:00:05s\n","epoch 8  | loss: 0.20163 | val_0_mse: 69.42916107177734|  0:00:05s\n","epoch 9  | loss: 0.18962 | val_0_mse: 68.89398956298828|  0:00:06s\n","epoch 10 | loss: 0.1617  | val_0_mse: 37.07775115966797|  0:00:06s\n","epoch 11 | loss: 0.14838 | val_0_mse: 72.79837036132812|  0:00:07s\n","epoch 12 | loss: 0.14354 | val_0_mse: 207.74465942382812|  0:00:08s\n","epoch 13 | loss: 0.1773  | val_0_mse: 129.32931518554688|  0:00:08s\n","epoch 14 | loss: 0.16782 | val_0_mse: 11.032679557800293|  0:00:09s\n","epoch 15 | loss: 0.14609 | val_0_mse: 69.88111114501953|  0:00:09s\n","epoch 16 | loss: 0.1538  | val_0_mse: 32.03253936767578|  0:00:10s\n","epoch 17 | loss: 0.17657 | val_0_mse: 2.607029914855957|  0:00:11s\n","epoch 18 | loss: 0.15209 | val_0_mse: 26.742990493774414|  0:00:11s\n","epoch 19 | loss: 0.16708 | val_0_mse: 102.8619384765625|  0:00:12s\n","epoch 20 | loss: 0.18299 | val_0_mse: 16.511829376220703|  0:00:13s\n","epoch 21 | loss: 0.18407 | val_0_mse: 18.666919708251953|  0:00:13s\n","epoch 22 | loss: 0.16227 | val_0_mse: 4.7640299797058105|  0:00:14s\n","epoch 23 | loss: 0.16573 | val_0_mse: 2.06850004196167|  0:00:15s\n","epoch 24 | loss: 0.1585  | val_0_mse: 0.38938000798225403|  0:00:15s\n","epoch 25 | loss: 0.16083 | val_0_mse: 1.097790002822876|  0:00:16s\n","epoch 26 | loss: 0.15467 | val_0_mse: 9.408539772033691|  0:00:16s\n","epoch 27 | loss: 0.15897 | val_0_mse: 3.718400001525879|  0:00:17s\n","epoch 28 | loss: 0.14394 | val_0_mse: 0.46184998750686646|  0:00:18s\n","epoch 29 | loss: 0.12447 | val_0_mse: 59.83686828613281|  0:00:18s\n","epoch 30 | loss: 0.15193 | val_0_mse: 14.001199722290039|  0:00:19s\n","epoch 31 | loss: 0.17456 | val_0_mse: 3.8818299770355225|  0:00:19s\n","epoch 32 | loss: 0.1499  | val_0_mse: 1.3730900287628174|  0:00:20s\n","epoch 33 | loss: 0.12333 | val_0_mse: 0.2743600010871887|  0:00:21s\n","epoch 34 | loss: 0.1269  | val_0_mse: 0.24352000653743744|  0:00:21s\n","epoch 35 | loss: 0.12513 | val_0_mse: 0.2529599964618683|  0:00:22s\n","epoch 36 | loss: 0.11642 | val_0_mse: 0.6287999749183655|  0:00:23s\n","epoch 37 | loss: 0.13763 | val_0_mse: 0.3104900121688843|  0:00:23s\n","epoch 38 | loss: 0.14683 | val_0_mse: 0.6492000222206116|  0:00:24s\n","epoch 39 | loss: 0.14126 | val_0_mse: 0.2757999897003174|  0:00:24s\n","epoch 40 | loss: 0.1427  | val_0_mse: 0.5006800293922424|  0:00:25s\n","epoch 41 | loss: 0.13129 | val_0_mse: 0.33610999584198|  0:00:26s\n","epoch 42 | loss: 0.1386  | val_0_mse: 0.4402500092983246|  0:00:26s\n","epoch 43 | loss: 0.13807 | val_0_mse: 0.4439600110054016|  0:00:27s\n","epoch 44 | loss: 0.1241  | val_0_mse: 0.3722800016403198|  0:00:28s\n","\n","Early stopping occurred at epoch 44 with best_epoch = 34 and best_val_0_mse = 0.24352000653743744\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 12:30:28,501] Trial 91 finished with value: 0.2435227334499359 and parameters: {'n_d': 44, 'n_steps': 3, 'gamma': 1.5744871755398586, 'n_independent': 1, 'n_shared': 5, 'momentum': 0.28332476297012116}. Best is trial 31 with value: 0.07662469148635864.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 76.29883| val_0_mse: 433029.09375|  0:00:00s\n","epoch 1  | loss: 5.05921 | val_0_mse: 73927.1953125|  0:00:01s\n","epoch 2  | loss: 0.97157 | val_0_mse: 36281.94140625|  0:00:01s\n","epoch 3  | loss: 0.50659 | val_0_mse: 50879.41015625|  0:00:02s\n","epoch 4  | loss: 0.44554 | val_0_mse: 25170.13671875|  0:00:03s\n","epoch 5  | loss: 0.44664 | val_0_mse: 11580.162109375|  0:00:03s\n","epoch 6  | loss: 0.36468 | val_0_mse: 6989.38037109375|  0:00:04s\n","epoch 7  | loss: 0.27075 | val_0_mse: 10041.6015625|  0:00:04s\n","epoch 8  | loss: 0.25815 | val_0_mse: 5580.185546875|  0:00:05s\n","epoch 9  | loss: 0.25127 | val_0_mse: 2128.144775390625|  0:00:06s\n","epoch 10 | loss: 0.21566 | val_0_mse: 514.6932373046875|  0:00:06s\n","epoch 11 | loss: 0.27295 | val_0_mse: 78.40959930419922|  0:00:07s\n","epoch 12 | loss: 0.24317 | val_0_mse: 75.42491912841797|  0:00:08s\n","epoch 13 | loss: 0.22539 | val_0_mse: 87.37085723876953|  0:00:08s\n","epoch 14 | loss: 0.17118 | val_0_mse: 82.59333801269531|  0:00:09s\n","epoch 15 | loss: 0.16879 | val_0_mse: 95.4162368774414|  0:00:10s\n","epoch 16 | loss: 0.16329 | val_0_mse: 62.57870101928711|  0:00:10s\n","epoch 17 | loss: 0.15657 | val_0_mse: 21.582719802856445|  0:00:11s\n","epoch 18 | loss: 0.15163 | val_0_mse: 84.76690673828125|  0:00:11s\n","epoch 19 | loss: 0.149   | val_0_mse: 51.24094009399414|  0:00:12s\n","epoch 20 | loss: 0.15463 | val_0_mse: 31.100330352783203|  0:00:13s\n","epoch 21 | loss: 0.15228 | val_0_mse: 38.03826141357422|  0:00:13s\n","epoch 22 | loss: 0.14196 | val_0_mse: 57.88602828979492|  0:00:14s\n","epoch 23 | loss: 0.13566 | val_0_mse: 71.57009887695312|  0:00:15s\n","epoch 24 | loss: 0.12999 | val_0_mse: 32.608070373535156|  0:00:15s\n","epoch 25 | loss: 0.12088 | val_0_mse: 11.129969596862793|  0:00:16s\n","epoch 26 | loss: 0.12154 | val_0_mse: 11.834580421447754|  0:00:16s\n","epoch 27 | loss: 0.12575 | val_0_mse: 9.073450088500977|  0:00:17s\n","epoch 28 | loss: 0.11874 | val_0_mse: 3.57138991355896|  0:00:18s\n","epoch 29 | loss: 0.1205  | val_0_mse: 4.653900146484375|  0:00:18s\n","epoch 30 | loss: 0.11169 | val_0_mse: 3.6072800159454346|  0:00:19s\n","epoch 31 | loss: 0.11019 | val_0_mse: 1.9715900421142578|  0:00:20s\n","epoch 32 | loss: 0.11108 | val_0_mse: 1.1657400131225586|  0:00:20s\n","epoch 33 | loss: 0.11159 | val_0_mse: 0.8201599717140198|  0:00:21s\n","epoch 34 | loss: 0.11612 | val_0_mse: 0.5832399725914001|  0:00:21s\n","epoch 35 | loss: 0.11087 | val_0_mse: 0.4887700080871582|  0:00:22s\n","epoch 36 | loss: 0.10756 | val_0_mse: 0.39555999636650085|  0:00:23s\n","epoch 37 | loss: 0.10914 | val_0_mse: 0.5892699956893921|  0:00:23s\n","epoch 38 | loss: 0.11467 | val_0_mse: 0.3569900095462799|  0:00:24s\n","epoch 39 | loss: 0.11929 | val_0_mse: 0.4348199963569641|  0:00:25s\n","epoch 40 | loss: 0.11116 | val_0_mse: 0.5976799726486206|  0:00:25s\n","epoch 41 | loss: 0.10842 | val_0_mse: 0.47742000222206116|  0:00:26s\n","epoch 42 | loss: 0.10638 | val_0_mse: 0.5868600010871887|  0:00:26s\n","epoch 43 | loss: 0.12058 | val_0_mse: 0.4016200006008148|  0:00:27s\n","epoch 44 | loss: 0.11485 | val_0_mse: 0.5758399963378906|  0:00:28s\n","epoch 45 | loss: 0.1024  | val_0_mse: 0.3251599967479706|  0:00:28s\n","epoch 46 | loss: 0.10758 | val_0_mse: 0.32183998823165894|  0:00:29s\n","epoch 47 | loss: 0.10941 | val_0_mse: 0.24617999792099|  0:00:30s\n","epoch 48 | loss: 0.10669 | val_0_mse: 0.18271000683307648|  0:00:30s\n","epoch 49 | loss: 0.10583 | val_0_mse: 0.1607999950647354|  0:00:31s\n","epoch 50 | loss: 0.10791 | val_0_mse: 0.14125999808311462|  0:00:32s\n","epoch 51 | loss: 0.09862 | val_0_mse: 0.14957000315189362|  0:00:32s\n","epoch 52 | loss: 0.09998 | val_0_mse: 0.11834999918937683|  0:00:33s\n","epoch 53 | loss: 0.12561 | val_0_mse: 0.12296999990940094|  0:00:33s\n","epoch 54 | loss: 0.11795 | val_0_mse: 0.18209999799728394|  0:00:34s\n","epoch 55 | loss: 0.1144  | val_0_mse: 0.1139800027012825|  0:00:35s\n","epoch 56 | loss: 0.10777 | val_0_mse: 0.14730000495910645|  0:00:35s\n","epoch 57 | loss: 0.11094 | val_0_mse: 0.11242999881505966|  0:00:36s\n","epoch 58 | loss: 0.09237 | val_0_mse: 0.11663000285625458|  0:00:37s\n","epoch 59 | loss: 0.09879 | val_0_mse: 0.10803999751806259|  0:00:37s\n","epoch 60 | loss: 0.10213 | val_0_mse: 0.10610999912023544|  0:00:38s\n","epoch 61 | loss: 0.09395 | val_0_mse: 0.0989300012588501|  0:00:38s\n","epoch 62 | loss: 0.10357 | val_0_mse: 0.11100000143051147|  0:00:39s\n","epoch 63 | loss: 0.09365 | val_0_mse: 0.09616000205278397|  0:00:40s\n","epoch 64 | loss: 0.08894 | val_0_mse: 0.10251999646425247|  0:00:40s\n","epoch 65 | loss: 0.08873 | val_0_mse: 0.11445999890565872|  0:00:41s\n","epoch 66 | loss: 0.09294 | val_0_mse: 0.12346000224351883|  0:00:42s\n","epoch 67 | loss: 0.08955 | val_0_mse: 0.11483000218868256|  0:00:42s\n","epoch 68 | loss: 0.09239 | val_0_mse: 0.09630999714136124|  0:00:43s\n","epoch 69 | loss: 0.08542 | val_0_mse: 0.08958999812602997|  0:00:43s\n","epoch 70 | loss: 0.09082 | val_0_mse: 0.09177999943494797|  0:00:44s\n","epoch 71 | loss: 0.09449 | val_0_mse: 0.09576000273227692|  0:00:45s\n","epoch 72 | loss: 0.09105 | val_0_mse: 0.09277000278234482|  0:00:45s\n","epoch 73 | loss: 0.08633 | val_0_mse: 0.09079000353813171|  0:00:46s\n","epoch 74 | loss: 0.08633 | val_0_mse: 0.08945000171661377|  0:00:46s\n","epoch 75 | loss: 0.08817 | val_0_mse: 0.09058000147342682|  0:00:47s\n","epoch 76 | loss: 0.0917  | val_0_mse: 0.096220001578331|  0:00:48s\n","epoch 77 | loss: 0.09101 | val_0_mse: 0.09872999787330627|  0:00:48s\n","epoch 78 | loss: 0.09152 | val_0_mse: 0.10537999868392944|  0:00:49s\n","epoch 79 | loss: 0.08942 | val_0_mse: 0.09079000353813171|  0:00:49s\n","epoch 80 | loss: 0.08931 | val_0_mse: 0.10451000183820724|  0:00:50s\n","epoch 81 | loss: 0.09334 | val_0_mse: 0.09000000357627869|  0:00:51s\n","epoch 82 | loss: 0.08588 | val_0_mse: 0.08901999890804291|  0:00:51s\n","epoch 83 | loss: 0.0873  | val_0_mse: 0.0885699987411499|  0:00:52s\n","epoch 84 | loss: 0.08437 | val_0_mse: 0.08838000148534775|  0:00:53s\n","epoch 85 | loss: 0.08605 | val_0_mse: 0.09325999766588211|  0:00:53s\n","epoch 86 | loss: 0.09199 | val_0_mse: 0.11102999746799469|  0:00:54s\n","epoch 87 | loss: 0.09424 | val_0_mse: 0.08935999870300293|  0:00:54s\n","epoch 88 | loss: 0.08985 | val_0_mse: 0.09358999878168106|  0:00:55s\n","epoch 89 | loss: 0.08735 | val_0_mse: 0.08668000251054764|  0:00:56s\n","epoch 90 | loss: 0.08437 | val_0_mse: 0.09452000260353088|  0:00:56s\n","epoch 91 | loss: 0.08765 | val_0_mse: 0.08705999702215195|  0:00:57s\n","epoch 92 | loss: 0.08018 | val_0_mse: 0.08731000125408173|  0:00:58s\n","epoch 93 | loss: 0.08343 | val_0_mse: 0.08450999855995178|  0:00:58s\n","epoch 94 | loss: 0.08279 | val_0_mse: 0.08844999969005585|  0:00:59s\n","epoch 95 | loss: 0.09045 | val_0_mse: 0.08760000020265579|  0:00:59s\n","epoch 96 | loss: 0.09671 | val_0_mse: 0.08917000144720078|  0:01:00s\n","epoch 97 | loss: 0.08553 | val_0_mse: 0.0861700028181076|  0:01:01s\n","epoch 98 | loss: 0.08096 | val_0_mse: 0.08521000295877457|  0:01:01s\n","epoch 99 | loss: 0.08377 | val_0_mse: 0.08782999962568283|  0:01:02s\n","Stop training because you reached max_epochs = 100 with best_epoch = 93 and best_val_0_mse = 0.08450999855995178\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 12:31:31,077] Trial 92 finished with value: 0.0845106691122055 and parameters: {'n_d': 18, 'n_steps': 3, 'gamma': 1.8393014025872862, 'n_independent': 1, 'n_shared': 5, 'momentum': 0.2938741364145516}. Best is trial 31 with value: 0.07662469148635864.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 72.71958| val_0_mse: 500142.75|  0:00:00s\n","epoch 1  | loss: 3.85923 | val_0_mse: 8752.375|  0:00:01s\n","epoch 2  | loss: 1.12184 | val_0_mse: 5208.4560546875|  0:00:01s\n","epoch 3  | loss: 0.55302 | val_0_mse: 3840.321044921875|  0:00:02s\n","epoch 4  | loss: 0.3749  | val_0_mse: 928.78125|  0:00:03s\n","epoch 5  | loss: 0.2789  | val_0_mse: 843.4883422851562|  0:00:03s\n","epoch 6  | loss: 0.24009 | val_0_mse: 591.2516479492188|  0:00:04s\n","epoch 7  | loss: 0.2284  | val_0_mse: 598.51953125|  0:00:04s\n","epoch 8  | loss: 0.19618 | val_0_mse: 109.176513671875|  0:00:05s\n","epoch 9  | loss: 0.1888  | val_0_mse: 188.03988647460938|  0:00:06s\n","epoch 10 | loss: 0.16676 | val_0_mse: 75.32701873779297|  0:00:06s\n","epoch 11 | loss: 0.16405 | val_0_mse: 117.53150177001953|  0:00:07s\n","epoch 12 | loss: 0.18114 | val_0_mse: 74.42916870117188|  0:00:07s\n","epoch 13 | loss: 0.17694 | val_0_mse: 41.319461822509766|  0:00:08s\n","epoch 14 | loss: 0.16697 | val_0_mse: 18.315380096435547|  0:00:08s\n","epoch 15 | loss: 0.16138 | val_0_mse: 31.898670196533203|  0:00:09s\n","epoch 16 | loss: 0.14206 | val_0_mse: 13.742870330810547|  0:00:10s\n","epoch 17 | loss: 0.16678 | val_0_mse: 32.13373947143555|  0:00:10s\n","epoch 18 | loss: 0.16205 | val_0_mse: 25.96463966369629|  0:00:11s\n","epoch 19 | loss: 0.14704 | val_0_mse: 13.252309799194336|  0:00:11s\n","epoch 20 | loss: 0.15823 | val_0_mse: 15.406189918518066|  0:00:12s\n","epoch 21 | loss: 0.1341  | val_0_mse: 18.548219680786133|  0:00:13s\n","epoch 22 | loss: 0.12714 | val_0_mse: 17.354259490966797|  0:00:13s\n","epoch 23 | loss: 0.12955 | val_0_mse: 11.580849647521973|  0:00:14s\n","epoch 24 | loss: 0.12258 | val_0_mse: 8.858209609985352|  0:00:15s\n","epoch 25 | loss: 0.12168 | val_0_mse: 9.794770240783691|  0:00:15s\n","epoch 26 | loss: 0.11444 | val_0_mse: 2.6893699169158936|  0:00:16s\n","epoch 27 | loss: 0.12196 | val_0_mse: 2.6714799404144287|  0:00:16s\n","epoch 28 | loss: 0.11823 | val_0_mse: 1.6137399673461914|  0:00:17s\n","epoch 29 | loss: 0.10667 | val_0_mse: 1.3527899980545044|  0:00:18s\n","epoch 30 | loss: 0.10873 | val_0_mse: 0.60930997133255|  0:00:18s\n","epoch 31 | loss: 0.10424 | val_0_mse: 1.0990899801254272|  0:00:19s\n","epoch 32 | loss: 0.10801 | val_0_mse: 0.6708199977874756|  0:00:19s\n","epoch 33 | loss: 0.11429 | val_0_mse: 0.8181999921798706|  0:00:20s\n","epoch 34 | loss: 0.11766 | val_0_mse: 0.48820000886917114|  0:00:21s\n","epoch 35 | loss: 0.09981 | val_0_mse: 0.35624998807907104|  0:00:21s\n","epoch 36 | loss: 0.10962 | val_0_mse: 0.3202199935913086|  0:00:22s\n","epoch 37 | loss: 0.11777 | val_0_mse: 0.4968700110912323|  0:00:22s\n","epoch 38 | loss: 0.1199  | val_0_mse: 0.28845998644828796|  0:00:23s\n","epoch 39 | loss: 0.11666 | val_0_mse: 0.30357998609542847|  0:00:24s\n","epoch 40 | loss: 0.10728 | val_0_mse: 0.3734399974346161|  0:00:24s\n","epoch 41 | loss: 0.09404 | val_0_mse: 0.2286600023508072|  0:00:25s\n","epoch 42 | loss: 0.09195 | val_0_mse: 0.21313999593257904|  0:00:25s\n","epoch 43 | loss: 0.09593 | val_0_mse: 0.26947999000549316|  0:00:26s\n","epoch 44 | loss: 0.10156 | val_0_mse: 0.19169999659061432|  0:00:27s\n","epoch 45 | loss: 0.09576 | val_0_mse: 0.17026999592781067|  0:00:27s\n","epoch 46 | loss: 0.13092 | val_0_mse: 0.24605000019073486|  0:00:28s\n","epoch 47 | loss: 0.13042 | val_0_mse: 0.19468000531196594|  0:00:28s\n","epoch 48 | loss: 0.11111 | val_0_mse: 0.2188200056552887|  0:00:29s\n","epoch 49 | loss: 0.10264 | val_0_mse: 0.21447999775409698|  0:00:30s\n","epoch 50 | loss: 0.09042 | val_0_mse: 0.14589999616146088|  0:00:30s\n","epoch 51 | loss: 0.091   | val_0_mse: 0.16155000030994415|  0:00:31s\n","epoch 52 | loss: 0.08663 | val_0_mse: 0.16946999728679657|  0:00:31s\n","epoch 53 | loss: 0.08871 | val_0_mse: 0.1334799975156784|  0:00:32s\n","epoch 54 | loss: 0.08948 | val_0_mse: 0.11274000257253647|  0:00:33s\n","epoch 55 | loss: 0.08739 | val_0_mse: 0.1725900024175644|  0:00:33s\n","epoch 56 | loss: 0.09063 | val_0_mse: 0.13734999299049377|  0:00:34s\n","epoch 57 | loss: 0.08394 | val_0_mse: 0.11745999753475189|  0:00:34s\n","epoch 58 | loss: 0.09325 | val_0_mse: 0.09595999866724014|  0:00:35s\n","epoch 59 | loss: 0.08571 | val_0_mse: 0.10312999784946442|  0:00:36s\n","epoch 60 | loss: 0.08326 | val_0_mse: 0.10329999774694443|  0:00:36s\n","epoch 61 | loss: 0.08257 | val_0_mse: 0.10648000240325928|  0:00:37s\n","epoch 62 | loss: 0.08644 | val_0_mse: 0.09861999750137329|  0:00:38s\n","epoch 63 | loss: 0.08565 | val_0_mse: 0.10119999945163727|  0:00:38s\n","epoch 64 | loss: 0.09063 | val_0_mse: 0.12058000266551971|  0:00:39s\n","epoch 65 | loss: 0.08477 | val_0_mse: 0.1015700027346611|  0:00:39s\n","epoch 66 | loss: 0.0833  | val_0_mse: 0.09553000330924988|  0:00:40s\n","epoch 67 | loss: 0.0839  | val_0_mse: 0.10226999968290329|  0:00:41s\n","epoch 68 | loss: 0.08094 | val_0_mse: 0.08691000193357468|  0:00:41s\n","epoch 69 | loss: 0.08539 | val_0_mse: 0.09128999710083008|  0:00:42s\n","epoch 70 | loss: 0.08666 | val_0_mse: 0.0806099995970726|  0:00:42s\n","epoch 71 | loss: 0.08585 | val_0_mse: 0.09643000364303589|  0:00:43s\n","epoch 72 | loss: 0.08161 | val_0_mse: 0.09264999628067017|  0:00:44s\n","epoch 73 | loss: 0.08513 | val_0_mse: 0.10175999999046326|  0:00:44s\n","epoch 74 | loss: 0.0926  | val_0_mse: 0.11079999804496765|  0:00:45s\n","epoch 75 | loss: 0.09949 | val_0_mse: 0.13036000728607178|  0:00:45s\n","epoch 76 | loss: 0.10238 | val_0_mse: 0.12285999953746796|  0:00:46s\n","epoch 77 | loss: 0.10531 | val_0_mse: 0.12088000029325485|  0:00:47s\n","epoch 78 | loss: 0.10656 | val_0_mse: 0.09859000146389008|  0:00:47s\n","epoch 79 | loss: 0.10655 | val_0_mse: 0.10582000017166138|  0:00:48s\n","epoch 80 | loss: 0.10002 | val_0_mse: 0.10102999955415726|  0:00:48s\n","\n","Early stopping occurred at epoch 80 with best_epoch = 70 and best_val_0_mse = 0.0806099995970726\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 12:32:20,350] Trial 93 finished with value: 0.08061474561691284 and parameters: {'n_d': 24, 'n_steps': 3, 'gamma': 1.295599487211931, 'n_independent': 1, 'n_shared': 5, 'momentum': 0.25957854179494855}. Best is trial 31 with value: 0.07662469148635864.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 75.88932| val_0_mse: 356927.71875|  0:00:00s\n","epoch 1  | loss: 4.77421 | val_0_mse: 48223.53515625|  0:00:01s\n","epoch 2  | loss: 0.74239 | val_0_mse: 7162.30029296875|  0:00:01s\n","epoch 3  | loss: 0.46939 | val_0_mse: 254.61471557617188|  0:00:02s\n","epoch 4  | loss: 0.38284 | val_0_mse: 35.71788024902344|  0:00:02s\n","epoch 5  | loss: 0.29257 | val_0_mse: 5.853449821472168|  0:00:03s\n","epoch 6  | loss: 0.23645 | val_0_mse: 42.42475891113281|  0:00:04s\n","epoch 7  | loss: 0.21136 | val_0_mse: 31.288959503173828|  0:00:04s\n","epoch 8  | loss: 0.18456 | val_0_mse: 25.050430297851562|  0:00:05s\n","epoch 9  | loss: 0.1825  | val_0_mse: 15.633990287780762|  0:00:05s\n","epoch 10 | loss: 0.16456 | val_0_mse: 14.175629615783691|  0:00:06s\n","epoch 11 | loss: 0.15551 | val_0_mse: 10.59296989440918|  0:00:07s\n","epoch 12 | loss: 0.15953 | val_0_mse: 3.433840036392212|  0:00:07s\n","epoch 13 | loss: 0.15793 | val_0_mse: 2.1971399784088135|  0:00:08s\n","epoch 14 | loss: 0.15727 | val_0_mse: 2.6766700744628906|  0:00:08s\n","epoch 15 | loss: 0.14754 | val_0_mse: 1.538159966468811|  0:00:09s\n","epoch 16 | loss: 0.13628 | val_0_mse: 1.2212799787521362|  0:00:10s\n","epoch 17 | loss: 0.12575 | val_0_mse: 1.1049599647521973|  0:00:10s\n","epoch 18 | loss: 0.11566 | val_0_mse: 0.9116899967193604|  0:00:11s\n","epoch 19 | loss: 0.12047 | val_0_mse: 0.990809977054596|  0:00:12s\n","epoch 20 | loss: 0.11448 | val_0_mse: 0.9399399757385254|  0:00:12s\n","epoch 21 | loss: 0.11559 | val_0_mse: 1.2839200496673584|  0:00:13s\n","epoch 22 | loss: 0.1108  | val_0_mse: 1.0387200117111206|  0:00:13s\n","epoch 23 | loss: 0.11924 | val_0_mse: 0.8348600268363953|  0:00:14s\n","epoch 24 | loss: 0.11621 | val_0_mse: 1.2613699436187744|  0:00:15s\n","epoch 25 | loss: 0.10446 | val_0_mse: 1.1937299966812134|  0:00:15s\n","epoch 26 | loss: 0.10567 | val_0_mse: 0.8899999856948853|  0:00:16s\n","epoch 27 | loss: 0.10908 | val_0_mse: 0.8248699903488159|  0:00:16s\n","epoch 28 | loss: 0.10027 | val_0_mse: 1.2789599895477295|  0:00:17s\n","epoch 29 | loss: 0.1025  | val_0_mse: 0.9653400182723999|  0:00:18s\n","epoch 30 | loss: 0.09928 | val_0_mse: 0.6041799783706665|  0:00:18s\n","epoch 31 | loss: 0.1035  | val_0_mse: 0.7003499865531921|  0:00:19s\n","epoch 32 | loss: 0.10687 | val_0_mse: 0.5944499969482422|  0:00:20s\n","epoch 33 | loss: 0.11358 | val_0_mse: 0.42667001485824585|  0:00:20s\n","epoch 34 | loss: 0.09879 | val_0_mse: 0.49024999141693115|  0:00:21s\n","epoch 35 | loss: 0.10241 | val_0_mse: 0.4750800132751465|  0:00:22s\n","epoch 36 | loss: 0.09674 | val_0_mse: 0.4119499921798706|  0:00:22s\n","epoch 37 | loss: 0.09184 | val_0_mse: 0.44415000081062317|  0:00:23s\n","epoch 38 | loss: 0.09232 | val_0_mse: 0.37452998757362366|  0:00:23s\n","epoch 39 | loss: 0.09269 | val_0_mse: 0.38997000455856323|  0:00:24s\n","epoch 40 | loss: 0.09509 | val_0_mse: 0.2912299931049347|  0:00:25s\n","epoch 41 | loss: 0.09814 | val_0_mse: 0.32767000794410706|  0:00:25s\n","epoch 42 | loss: 0.09233 | val_0_mse: 0.3115600049495697|  0:00:26s\n","epoch 43 | loss: 0.09653 | val_0_mse: 0.2816999852657318|  0:00:27s\n","epoch 44 | loss: 0.09258 | val_0_mse: 0.3267599940299988|  0:00:27s\n","epoch 45 | loss: 0.0925  | val_0_mse: 0.2283399999141693|  0:00:28s\n","epoch 46 | loss: 0.08936 | val_0_mse: 0.19845999777317047|  0:00:28s\n","epoch 47 | loss: 0.08772 | val_0_mse: 0.19115999341011047|  0:00:29s\n","epoch 48 | loss: 0.08938 | val_0_mse: 0.1498900055885315|  0:00:30s\n","epoch 49 | loss: 0.08498 | val_0_mse: 0.2253199964761734|  0:00:30s\n","epoch 50 | loss: 0.09369 | val_0_mse: 0.17922000586986542|  0:00:31s\n","epoch 51 | loss: 0.08882 | val_0_mse: 0.14928999543190002|  0:00:32s\n","epoch 52 | loss: 0.08479 | val_0_mse: 0.16416999697685242|  0:00:32s\n","epoch 53 | loss: 0.09313 | val_0_mse: 0.15852999687194824|  0:00:33s\n","epoch 54 | loss: 0.08892 | val_0_mse: 0.13672000169754028|  0:00:34s\n","epoch 55 | loss: 0.08543 | val_0_mse: 0.16629000008106232|  0:00:34s\n","epoch 56 | loss: 0.08816 | val_0_mse: 0.09742999821901321|  0:00:35s\n","epoch 57 | loss: 0.08479 | val_0_mse: 0.11328999698162079|  0:00:36s\n","epoch 58 | loss: 0.08497 | val_0_mse: 0.11021000146865845|  0:00:36s\n","epoch 59 | loss: 0.09086 | val_0_mse: 0.1168999969959259|  0:00:37s\n","epoch 60 | loss: 0.08473 | val_0_mse: 0.0973299965262413|  0:00:37s\n","epoch 61 | loss: 0.0862  | val_0_mse: 0.11563000082969666|  0:00:38s\n","epoch 62 | loss: 0.10331 | val_0_mse: 0.09167999774217606|  0:00:39s\n","epoch 63 | loss: 0.10808 | val_0_mse: 0.09700000286102295|  0:00:39s\n","epoch 64 | loss: 0.09688 | val_0_mse: 0.12087000161409378|  0:00:40s\n","epoch 65 | loss: 0.08918 | val_0_mse: 0.09155000001192093|  0:00:40s\n","epoch 66 | loss: 0.08889 | val_0_mse: 0.08895000070333481|  0:00:41s\n","epoch 67 | loss: 0.08484 | val_0_mse: 0.09138999879360199|  0:00:42s\n","epoch 68 | loss: 0.08514 | val_0_mse: 0.08330000191926956|  0:00:42s\n","epoch 69 | loss: 0.08332 | val_0_mse: 0.0836699977517128|  0:00:43s\n","epoch 70 | loss: 0.08854 | val_0_mse: 0.10085999965667725|  0:00:44s\n","epoch 71 | loss: 0.10799 | val_0_mse: 0.14546999335289001|  0:00:44s\n","epoch 72 | loss: 0.1162  | val_0_mse: 0.1294099986553192|  0:00:45s\n","epoch 73 | loss: 0.09329 | val_0_mse: 0.09076999872922897|  0:00:45s\n","epoch 74 | loss: 0.08636 | val_0_mse: 0.0841199979186058|  0:00:46s\n","epoch 75 | loss: 0.1027  | val_0_mse: 0.11958999931812286|  0:00:47s\n","epoch 76 | loss: 0.10231 | val_0_mse: 0.11683999747037888|  0:00:47s\n","epoch 77 | loss: 0.10515 | val_0_mse: 0.08849000185728073|  0:00:48s\n","epoch 78 | loss: 0.10142 | val_0_mse: 0.09771999716758728|  0:00:48s\n","\n","Early stopping occurred at epoch 78 with best_epoch = 68 and best_val_0_mse = 0.08330000191926956\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 12:33:09,551] Trial 94 finished with value: 0.08329985290765762 and parameters: {'n_d': 24, 'n_steps': 3, 'gamma': 1.2924742720169329, 'n_independent': 1, 'n_shared': 5, 'momentum': 0.18291928658561196}. Best is trial 31 with value: 0.07662469148635864.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 108.18581| val_0_mse: 36532.07421875|  0:00:00s\n","epoch 1  | loss: 14.04783| val_0_mse: 8704.2998046875|  0:00:01s\n","epoch 2  | loss: 1.69205 | val_0_mse: 8967.744140625|  0:00:01s\n","epoch 3  | loss: 0.47432 | val_0_mse: 13984.5439453125|  0:00:02s\n","epoch 4  | loss: 0.50289 | val_0_mse: 15252.240234375|  0:00:02s\n","epoch 5  | loss: 0.34697 | val_0_mse: 1145.5096435546875|  0:00:03s\n","epoch 6  | loss: 0.28633 | val_0_mse: 825.2554931640625|  0:00:04s\n","epoch 7  | loss: 0.20776 | val_0_mse: 303.5456848144531|  0:00:04s\n","epoch 8  | loss: 0.17573 | val_0_mse: 129.92942810058594|  0:00:05s\n","epoch 9  | loss: 0.23282 | val_0_mse: 382.68707275390625|  0:00:06s\n","epoch 10 | loss: 0.21101 | val_0_mse: 358.25732421875|  0:00:06s\n","epoch 11 | loss: 0.17766 | val_0_mse: 208.9957275390625|  0:00:07s\n","epoch 12 | loss: 0.1741  | val_0_mse: 95.6140365600586|  0:00:08s\n","epoch 13 | loss: 0.17554 | val_0_mse: 233.36619567871094|  0:00:08s\n","epoch 14 | loss: 0.16956 | val_0_mse: 102.02323150634766|  0:00:09s\n","epoch 15 | loss: 0.1394  | val_0_mse: 63.83115005493164|  0:00:09s\n","epoch 16 | loss: 0.16172 | val_0_mse: 113.53251647949219|  0:00:10s\n","epoch 17 | loss: 0.15248 | val_0_mse: 53.77317810058594|  0:00:11s\n","epoch 18 | loss: 0.13968 | val_0_mse: 55.09785842895508|  0:00:11s\n","epoch 19 | loss: 0.13901 | val_0_mse: 45.41014099121094|  0:00:12s\n","epoch 20 | loss: 0.13309 | val_0_mse: 41.32625961303711|  0:00:12s\n","epoch 21 | loss: 0.11941 | val_0_mse: 34.0134391784668|  0:00:13s\n","epoch 22 | loss: 0.11196 | val_0_mse: 22.444019317626953|  0:00:14s\n","epoch 23 | loss: 0.11358 | val_0_mse: 21.63899040222168|  0:00:14s\n","epoch 24 | loss: 0.11133 | val_0_mse: 12.922410011291504|  0:00:15s\n","epoch 25 | loss: 0.11042 | val_0_mse: 14.573570251464844|  0:00:15s\n","epoch 26 | loss: 0.10268 | val_0_mse: 7.288609981536865|  0:00:16s\n","epoch 27 | loss: 0.10591 | val_0_mse: 2.4837799072265625|  0:00:17s\n","epoch 28 | loss: 0.1257  | val_0_mse: 6.371359825134277|  0:00:17s\n","epoch 29 | loss: 0.11961 | val_0_mse: 1.4150700569152832|  0:00:18s\n","epoch 30 | loss: 0.1208  | val_0_mse: 2.70238995552063|  0:00:19s\n","epoch 31 | loss: 0.11966 | val_0_mse: 1.064170002937317|  0:00:19s\n","epoch 32 | loss: 0.11662 | val_0_mse: 1.6413400173187256|  0:00:20s\n","epoch 33 | loss: 0.11216 | val_0_mse: 0.6814000010490417|  0:00:20s\n","epoch 34 | loss: 0.10607 | val_0_mse: 0.923520028591156|  0:00:21s\n","epoch 35 | loss: 0.10092 | val_0_mse: 0.8187999725341797|  0:00:22s\n","epoch 36 | loss: 0.09933 | val_0_mse: 0.5779100060462952|  0:00:22s\n","epoch 37 | loss: 0.10492 | val_0_mse: 0.4062199890613556|  0:00:23s\n","epoch 38 | loss: 0.11282 | val_0_mse: 0.31817999482154846|  0:00:23s\n","epoch 39 | loss: 0.10304 | val_0_mse: 0.31709998846054077|  0:00:24s\n","epoch 40 | loss: 0.09369 | val_0_mse: 0.3159700036048889|  0:00:25s\n","epoch 41 | loss: 0.09405 | val_0_mse: 0.30083000659942627|  0:00:25s\n","epoch 42 | loss: 0.09473 | val_0_mse: 0.2657400071620941|  0:00:26s\n","epoch 43 | loss: 0.1037  | val_0_mse: 0.26875001192092896|  0:00:26s\n","epoch 44 | loss: 0.09223 | val_0_mse: 0.2340800017118454|  0:00:27s\n","epoch 45 | loss: 0.10292 | val_0_mse: 0.1987999975681305|  0:00:28s\n","epoch 46 | loss: 0.10681 | val_0_mse: 0.256989985704422|  0:00:28s\n","epoch 47 | loss: 0.12123 | val_0_mse: 0.1515599936246872|  0:00:29s\n","epoch 48 | loss: 0.116   | val_0_mse: 0.2247599959373474|  0:00:30s\n","epoch 49 | loss: 0.0986  | val_0_mse: 0.16022999584674835|  0:00:30s\n","epoch 50 | loss: 0.1023  | val_0_mse: 0.21786999702453613|  0:00:31s\n","epoch 51 | loss: 0.12434 | val_0_mse: 0.1225999966263771|  0:00:32s\n","epoch 52 | loss: 0.10228 | val_0_mse: 0.1539199948310852|  0:00:32s\n","epoch 53 | loss: 0.10872 | val_0_mse: 0.15107999742031097|  0:00:33s\n","epoch 54 | loss: 0.09932 | val_0_mse: 0.17009000480175018|  0:00:33s\n","epoch 55 | loss: 0.10518 | val_0_mse: 0.15458999574184418|  0:00:34s\n","epoch 56 | loss: 0.09826 | val_0_mse: 0.1294099986553192|  0:00:35s\n","epoch 57 | loss: 0.09396 | val_0_mse: 0.11072999984025955|  0:00:35s\n","epoch 58 | loss: 0.08622 | val_0_mse: 0.1028899997472763|  0:00:36s\n","epoch 59 | loss: 0.08972 | val_0_mse: 0.10166999697685242|  0:00:36s\n","epoch 60 | loss: 0.08366 | val_0_mse: 0.09984999895095825|  0:00:37s\n","epoch 61 | loss: 0.09117 | val_0_mse: 0.12744000554084778|  0:00:38s\n","epoch 62 | loss: 0.09642 | val_0_mse: 0.09529999643564224|  0:00:38s\n","epoch 63 | loss: 0.11403 | val_0_mse: 0.13109000027179718|  0:00:39s\n","epoch 64 | loss: 0.09099 | val_0_mse: 0.1122799962759018|  0:00:40s\n","epoch 65 | loss: 0.08428 | val_0_mse: 0.08777999877929688|  0:00:40s\n","epoch 66 | loss: 0.08734 | val_0_mse: 0.0902400016784668|  0:00:41s\n","epoch 67 | loss: 0.08818 | val_0_mse: 0.09209000319242477|  0:00:41s\n","epoch 68 | loss: 0.11909 | val_0_mse: 0.1665000021457672|  0:00:42s\n","epoch 69 | loss: 0.10289 | val_0_mse: 0.0885000005364418|  0:00:43s\n","epoch 70 | loss: 0.08162 | val_0_mse: 0.08715999871492386|  0:00:43s\n","epoch 71 | loss: 0.08695 | val_0_mse: 0.08603999763727188|  0:00:44s\n","epoch 72 | loss: 0.0869  | val_0_mse: 0.09367000311613083|  0:00:44s\n","epoch 73 | loss: 0.08769 | val_0_mse: 0.08846999704837799|  0:00:45s\n","epoch 74 | loss: 0.10358 | val_0_mse: 0.09837000072002411|  0:00:46s\n","epoch 75 | loss: 0.10318 | val_0_mse: 0.0842600017786026|  0:00:46s\n","epoch 76 | loss: 0.09387 | val_0_mse: 0.10110999643802643|  0:00:47s\n","epoch 77 | loss: 0.10162 | val_0_mse: 0.08332999795675278|  0:00:47s\n","epoch 78 | loss: 0.09937 | val_0_mse: 0.08669000118970871|  0:00:48s\n","epoch 79 | loss: 0.09514 | val_0_mse: 0.08247999846935272|  0:00:49s\n","epoch 80 | loss: 0.08828 | val_0_mse: 0.11660999804735184|  0:00:49s\n","epoch 81 | loss: 0.1074  | val_0_mse: 0.09038999676704407|  0:00:50s\n","epoch 82 | loss: 0.08835 | val_0_mse: 0.08628000319004059|  0:00:50s\n","epoch 83 | loss: 0.08149 | val_0_mse: 0.08240000158548355|  0:00:51s\n","epoch 84 | loss: 0.08393 | val_0_mse: 0.08653999865055084|  0:00:52s\n","epoch 85 | loss: 0.08597 | val_0_mse: 0.08375000208616257|  0:00:53s\n","epoch 86 | loss: 0.07835 | val_0_mse: 0.08382000029087067|  0:00:53s\n","epoch 87 | loss: 0.08214 | val_0_mse: 0.08595000207424164|  0:00:54s\n","epoch 88 | loss: 0.08217 | val_0_mse: 0.08056999742984772|  0:00:54s\n","epoch 89 | loss: 0.08183 | val_0_mse: 0.08342000097036362|  0:00:55s\n","epoch 90 | loss: 0.08332 | val_0_mse: 0.0911799967288971|  0:00:56s\n","epoch 91 | loss: 0.08734 | val_0_mse: 0.08279000222682953|  0:00:56s\n","epoch 92 | loss: 0.08282 | val_0_mse: 0.08427000045776367|  0:00:57s\n","epoch 93 | loss: 0.07596 | val_0_mse: 0.08823999762535095|  0:00:57s\n","epoch 94 | loss: 0.08016 | val_0_mse: 0.0804700031876564|  0:00:58s\n","epoch 95 | loss: 0.08131 | val_0_mse: 0.09189999848604202|  0:00:59s\n","epoch 96 | loss: 0.08033 | val_0_mse: 0.0887800008058548|  0:00:59s\n","epoch 97 | loss: 0.07909 | val_0_mse: 0.08111999928951263|  0:01:00s\n","epoch 98 | loss: 0.07774 | val_0_mse: 0.08242999762296677|  0:01:00s\n","epoch 99 | loss: 0.08014 | val_0_mse: 0.07991000264883041|  0:01:01s\n","Stop training because you reached max_epochs = 100 with best_epoch = 99 and best_val_0_mse = 0.07991000264883041\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 12:34:11,352] Trial 95 finished with value: 0.07991483062505722 and parameters: {'n_d': 22, 'n_steps': 3, 'gamma': 1.265659960422455, 'n_independent': 1, 'n_shared': 5, 'momentum': 0.2623561299644828}. Best is trial 31 with value: 0.07662469148635864.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 76.02279| val_0_mse: 74510.609375|  0:00:01s\n","epoch 1  | loss: 6.09152 | val_0_mse: 32905.73046875|  0:00:03s\n","epoch 2  | loss: 3.27721 | val_0_mse: 5053.13427734375|  0:00:04s\n","epoch 3  | loss: 2.27544 | val_0_mse: 11263.6416015625|  0:00:06s\n","epoch 4  | loss: 2.41177 | val_0_mse: 7185.0810546875|  0:00:07s\n","epoch 5  | loss: 1.45103 | val_0_mse: 3615.508056640625|  0:00:09s\n","epoch 6  | loss: 1.30648 | val_0_mse: 1941.41748046875|  0:00:10s\n","epoch 7  | loss: 1.65155 | val_0_mse: 1302.89306640625|  0:00:12s\n","epoch 8  | loss: 1.40317 | val_0_mse: 1344.26123046875|  0:00:13s\n","epoch 9  | loss: 1.69107 | val_0_mse: 1108.436279296875|  0:00:15s\n","epoch 10 | loss: 1.78506 | val_0_mse: 353.841552734375|  0:00:16s\n","epoch 11 | loss: 0.48004 | val_0_mse: 247.89817810058594|  0:00:18s\n","epoch 12 | loss: 0.41949 | val_0_mse: 123.03070068359375|  0:00:20s\n","epoch 13 | loss: 0.45133 | val_0_mse: 151.24972534179688|  0:00:21s\n","epoch 14 | loss: 0.38221 | val_0_mse: 15.290840148925781|  0:00:23s\n","epoch 15 | loss: 0.44688 | val_0_mse: 11.292149543762207|  0:00:24s\n","epoch 16 | loss: 1.14395 | val_0_mse: 41.07973861694336|  0:00:26s\n","epoch 17 | loss: 0.993   | val_0_mse: 10.596759796142578|  0:00:27s\n","epoch 18 | loss: 1.02559 | val_0_mse: 5.959290027618408|  0:00:29s\n","epoch 19 | loss: 0.46736 | val_0_mse: 3.908979892730713|  0:00:30s\n","epoch 20 | loss: 0.38895 | val_0_mse: 2.0526599884033203|  0:00:32s\n","epoch 21 | loss: 0.31865 | val_0_mse: 3.161410093307495|  0:00:33s\n","epoch 22 | loss: 0.45287 | val_0_mse: 1.7395000457763672|  0:00:35s\n","epoch 23 | loss: 0.31179 | val_0_mse: 2.664330005645752|  0:00:37s\n","epoch 24 | loss: 0.59061 | val_0_mse: 5.85621976852417|  0:00:38s\n","epoch 25 | loss: 1.07322 | val_0_mse: 3.77987003326416|  0:00:40s\n","epoch 26 | loss: 1.1624  | val_0_mse: 0.6229900121688843|  0:00:41s\n","epoch 27 | loss: 1.25413 | val_0_mse: 0.4802300035953522|  0:00:43s\n","epoch 28 | loss: 0.682   | val_0_mse: 0.42886999249458313|  0:00:44s\n","epoch 29 | loss: 0.4354  | val_0_mse: 0.42440998554229736|  0:00:46s\n","epoch 30 | loss: 0.36198 | val_0_mse: 0.7189599871635437|  0:00:47s\n","epoch 31 | loss: 0.24032 | val_0_mse: 0.5164200067520142|  0:00:49s\n","epoch 32 | loss: 0.22081 | val_0_mse: 0.2959200143814087|  0:00:50s\n","epoch 33 | loss: 0.22538 | val_0_mse: 0.5624300241470337|  0:00:52s\n","epoch 34 | loss: 0.21235 | val_0_mse: 0.2880899906158447|  0:00:53s\n","epoch 35 | loss: 0.31681 | val_0_mse: 0.5158500075340271|  0:00:55s\n","epoch 36 | loss: 0.28856 | val_0_mse: 0.41784000396728516|  0:00:56s\n","epoch 37 | loss: 0.25546 | val_0_mse: 0.6113899946212769|  0:00:58s\n","epoch 38 | loss: 0.29061 | val_0_mse: 0.28073999285697937|  0:00:59s\n","epoch 39 | loss: 0.22563 | val_0_mse: 0.3098199963569641|  0:01:01s\n","epoch 40 | loss: 0.35286 | val_0_mse: 0.29760000109672546|  0:01:02s\n","epoch 41 | loss: 0.26771 | val_0_mse: 0.35892000794410706|  0:01:04s\n","epoch 42 | loss: 0.21024 | val_0_mse: 0.28376999497413635|  0:01:05s\n","epoch 43 | loss: 0.24745 | val_0_mse: 0.8625500202178955|  0:01:07s\n","epoch 44 | loss: 0.21023 | val_0_mse: 0.8169800043106079|  0:01:09s\n","epoch 45 | loss: 0.18644 | val_0_mse: 0.28468000888824463|  0:01:10s\n","epoch 46 | loss: 0.26629 | val_0_mse: 0.34104999899864197|  0:01:12s\n","epoch 47 | loss: 0.27452 | val_0_mse: 0.4559600055217743|  0:01:13s\n","epoch 48 | loss: 0.45681 | val_0_mse: 1.2312699556350708|  0:01:15s\n","\n","Early stopping occurred at epoch 48 with best_epoch = 38 and best_val_0_mse = 0.28073999285697937\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 12:35:27,130] Trial 96 finished with value: 0.2807367444038391 and parameters: {'n_d': 26, 'n_steps': 10, 'gamma': 1.373530763927008, 'n_independent': 1, 'n_shared': 5, 'momentum': 0.2716505852368739}. Best is trial 31 with value: 0.07662469148635864.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 112.48595| val_0_mse: 38162.3203125|  0:00:00s\n","epoch 1  | loss: 16.02342| val_0_mse: 7553.3369140625|  0:00:01s\n","epoch 2  | loss: 2.80433 | val_0_mse: 2953.81494140625|  0:00:01s\n","epoch 3  | loss: 0.85996 | val_0_mse: 112.47199249267578|  0:00:02s\n","epoch 4  | loss: 0.44409 | val_0_mse: 391.6549072265625|  0:00:03s\n","epoch 5  | loss: 0.33291 | val_0_mse: 120.06452941894531|  0:00:03s\n","epoch 6  | loss: 0.2275  | val_0_mse: 67.52538299560547|  0:00:04s\n","epoch 7  | loss: 0.20297 | val_0_mse: 65.4725112915039|  0:00:05s\n","epoch 8  | loss: 0.1909  | val_0_mse: 114.63067626953125|  0:00:05s\n","epoch 9  | loss: 0.19864 | val_0_mse: 94.50180053710938|  0:00:06s\n","epoch 10 | loss: 0.16658 | val_0_mse: 139.31568908691406|  0:00:07s\n","epoch 11 | loss: 0.17927 | val_0_mse: 60.4275016784668|  0:00:07s\n","epoch 12 | loss: 0.16058 | val_0_mse: 7.35722017288208|  0:00:08s\n","epoch 13 | loss: 0.15564 | val_0_mse: 2.2793400287628174|  0:00:09s\n","epoch 14 | loss: 0.14837 | val_0_mse: 29.010639190673828|  0:00:09s\n","epoch 15 | loss: 0.14174 | val_0_mse: 16.26905059814453|  0:00:10s\n","epoch 16 | loss: 0.1362  | val_0_mse: 14.283860206604004|  0:00:11s\n","epoch 17 | loss: 0.13212 | val_0_mse: 14.615659713745117|  0:00:11s\n","epoch 18 | loss: 0.1345  | val_0_mse: 14.070280075073242|  0:00:12s\n","epoch 19 | loss: 0.12878 | val_0_mse: 7.85276985168457|  0:00:13s\n","epoch 20 | loss: 0.13851 | val_0_mse: 7.953070163726807|  0:00:13s\n","epoch 21 | loss: 0.13604 | val_0_mse: 8.189849853515625|  0:00:14s\n","epoch 22 | loss: 0.12735 | val_0_mse: 2.419379949569702|  0:00:15s\n","epoch 23 | loss: 0.13089 | val_0_mse: 3.2780699729919434|  0:00:15s\n","\n","Early stopping occurred at epoch 23 with best_epoch = 13 and best_val_0_mse = 2.2793400287628174\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 12:35:43,360] Trial 97 finished with value: 2.2793352603912354 and parameters: {'n_d': 22, 'n_steps': 4, 'gamma': 1.264088310586051, 'n_independent': 1, 'n_shared': 4, 'momentum': 0.25666368373108206}. Best is trial 31 with value: 0.07662469148635864.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 85.65904| val_0_mse: 142470.46875|  0:00:00s\n","epoch 1  | loss: 7.61736 | val_0_mse: 841.6243896484375|  0:00:01s\n","epoch 2  | loss: 1.18257 | val_0_mse: 829.2387084960938|  0:00:01s\n","epoch 3  | loss: 0.57688 | val_0_mse: 651.9276123046875|  0:00:02s\n","epoch 4  | loss: 0.40369 | val_0_mse: 228.71620178222656|  0:00:03s\n","epoch 5  | loss: 0.33235 | val_0_mse: 2551.4296875|  0:00:03s\n","epoch 6  | loss: 0.26148 | val_0_mse: 68.2767105102539|  0:00:04s\n","epoch 7  | loss: 0.20931 | val_0_mse: 1469.9627685546875|  0:00:04s\n","epoch 8  | loss: 0.2845  | val_0_mse: 69.248779296875|  0:00:05s\n","epoch 9  | loss: 0.20695 | val_0_mse: 482.50555419921875|  0:00:05s\n","epoch 10 | loss: 0.21183 | val_0_mse: 68.66658020019531|  0:00:06s\n","epoch 11 | loss: 0.21446 | val_0_mse: 119.35640716552734|  0:00:07s\n","epoch 12 | loss: 0.26762 | val_0_mse: 52.56163024902344|  0:00:07s\n","epoch 13 | loss: 0.24471 | val_0_mse: 12.734379768371582|  0:00:08s\n","epoch 14 | loss: 0.16356 | val_0_mse: 8.212320327758789|  0:00:09s\n","epoch 15 | loss: 0.14113 | val_0_mse: 2.5995099544525146|  0:00:09s\n","epoch 16 | loss: 0.13431 | val_0_mse: 2.649749994277954|  0:00:10s\n","epoch 17 | loss: 0.12627 | val_0_mse: 1.8512799739837646|  0:00:10s\n","epoch 18 | loss: 0.12043 | val_0_mse: 1.2358399629592896|  0:00:11s\n","epoch 19 | loss: 0.11835 | val_0_mse: 1.8316500186920166|  0:00:12s\n","epoch 20 | loss: 0.11695 | val_0_mse: 2.2312099933624268|  0:00:12s\n","epoch 21 | loss: 0.11092 | val_0_mse: 2.7425599098205566|  0:00:13s\n","epoch 22 | loss: 0.10728 | val_0_mse: 2.3130500316619873|  0:00:13s\n","epoch 23 | loss: 0.1145  | val_0_mse: 4.043210029602051|  0:00:14s\n","epoch 24 | loss: 0.11191 | val_0_mse: 1.71274995803833|  0:00:15s\n","epoch 25 | loss: 0.10756 | val_0_mse: 5.401879787445068|  0:00:15s\n","epoch 26 | loss: 0.10743 | val_0_mse: 3.133080005645752|  0:00:16s\n","epoch 27 | loss: 0.11589 | val_0_mse: 4.9350199699401855|  0:00:16s\n","epoch 28 | loss: 0.1019  | val_0_mse: 6.617980003356934|  0:00:17s\n","\n","Early stopping occurred at epoch 28 with best_epoch = 18 and best_val_0_mse = 1.2358399629592896\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 12:36:01,282] Trial 98 finished with value: 1.235844612121582 and parameters: {'n_d': 20, 'n_steps': 3, 'gamma': 1.2386494942668158, 'n_independent': 1, 'n_shared': 5, 'momentum': 0.2363857537044406}. Best is trial 31 with value: 0.07662469148635864.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 67.79377| val_0_mse: 674565.125|  0:00:00s\n","epoch 1  | loss: 4.89473 | val_0_mse: 115179.578125|  0:00:00s\n","epoch 2  | loss: 1.04185 | val_0_mse: 9477.056640625|  0:00:01s\n","epoch 3  | loss: 0.44926 | val_0_mse: 3960.4912109375|  0:00:01s\n","epoch 4  | loss: 0.28695 | val_0_mse: 1194.78076171875|  0:00:02s\n","epoch 5  | loss: 0.24708 | val_0_mse: 726.3202514648438|  0:00:02s\n","epoch 6  | loss: 0.203   | val_0_mse: 788.6498413085938|  0:00:03s\n","epoch 7  | loss: 0.18572 | val_0_mse: 293.0550537109375|  0:00:03s\n","epoch 8  | loss: 0.16457 | val_0_mse: 268.44146728515625|  0:00:04s\n","epoch 9  | loss: 0.14446 | val_0_mse: 171.75262451171875|  0:00:04s\n","epoch 10 | loss: 0.13327 | val_0_mse: 117.51921081542969|  0:00:05s\n","epoch 11 | loss: 0.13428 | val_0_mse: 65.09851837158203|  0:00:05s\n","epoch 12 | loss: 0.13941 | val_0_mse: 83.35491180419922|  0:00:06s\n","epoch 13 | loss: 0.1194  | val_0_mse: 45.03028106689453|  0:00:06s\n","epoch 14 | loss: 0.12381 | val_0_mse: 9.484749794006348|  0:00:07s\n","epoch 15 | loss: 0.12525 | val_0_mse: 5.704989910125732|  0:00:07s\n","epoch 16 | loss: 0.12228 | val_0_mse: 4.053319931030273|  0:00:08s\n","epoch 17 | loss: 0.12853 | val_0_mse: 3.304810047149658|  0:00:08s\n","epoch 18 | loss: 0.13125 | val_0_mse: 2.14421010017395|  0:00:09s\n","epoch 19 | loss: 0.13174 | val_0_mse: 1.6275299787521362|  0:00:09s\n","epoch 20 | loss: 0.16499 | val_0_mse: 1.663540005683899|  0:00:10s\n","epoch 21 | loss: 0.12235 | val_0_mse: 1.8483500480651855|  0:00:10s\n","epoch 22 | loss: 0.11317 | val_0_mse: 0.9965199828147888|  0:00:11s\n","epoch 23 | loss: 0.11739 | val_0_mse: 5.043260097503662|  0:00:11s\n","epoch 24 | loss: 0.12565 | val_0_mse: 1.881309986114502|  0:00:12s\n","epoch 25 | loss: 0.11783 | val_0_mse: 2.4657700061798096|  0:00:12s\n","epoch 26 | loss: 0.11359 | val_0_mse: 1.0672099590301514|  0:00:13s\n","epoch 27 | loss: 0.09703 | val_0_mse: 0.34498998522758484|  0:00:13s\n","epoch 28 | loss: 0.10374 | val_0_mse: 0.3834899961948395|  0:00:14s\n","epoch 29 | loss: 0.11131 | val_0_mse: 0.587939977645874|  0:00:14s\n","epoch 30 | loss: 0.10437 | val_0_mse: 0.5356500148773193|  0:00:14s\n","epoch 31 | loss: 0.09773 | val_0_mse: 0.8548700213432312|  0:00:15s\n","epoch 32 | loss: 0.10416 | val_0_mse: 0.41137999296188354|  0:00:15s\n","epoch 33 | loss: 0.09961 | val_0_mse: 1.045930027961731|  0:00:16s\n","epoch 34 | loss: 0.10459 | val_0_mse: 0.5962600111961365|  0:00:16s\n","epoch 35 | loss: 0.10966 | val_0_mse: 0.7299100160598755|  0:00:17s\n","epoch 36 | loss: 0.10006 | val_0_mse: 0.552619993686676|  0:00:17s\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 12:36:19,850] Trial 99 finished with value: 0.34498584270477295 and parameters: {'n_d': 28, 'n_steps': 3, 'gamma': 1.4415681053206029, 'n_independent': 1, 'n_shared': 3, 'momentum': 0.24741609654337143}. Best is trial 31 with value: 0.07662469148635864.\n"]},{"output_type":"stream","name":"stdout","text":["epoch 37 | loss: 0.09261 | val_0_mse: 0.5105500221252441|  0:00:18s\n","\n","Early stopping occurred at epoch 37 with best_epoch = 27 and best_val_0_mse = 0.34498998522758484\n"]}]},{"cell_type":"code","source":["best_params"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sg7oYTivFBGe","executionInfo":{"status":"ok","timestamp":1728995780437,"user_tz":-480,"elapsed":90,"user":{"displayName":"Jonindo Pasaribu","userId":"10958990953097471082"}},"outputId":"e6e4e999-cb89-4094-cdf2-857bf58cf14c"},"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'n_d': 42,\n"," 'n_steps': 3,\n"," 'gamma': 1.1843093917318663,\n"," 'n_independent': 2,\n"," 'n_shared': 5,\n"," 'momentum': 0.27780831200927614}"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["# Train final model using best hyperparameters\n","best_model = TabNetRegressor(**best_params,\n","                             optimizer_fn=torch.optim.Adam,\n","                             optimizer_params=dict(lr=2e-2)\n","                             )\n","best_model.fit(\n","    X_train, y_train,\n","    eval_set=[(X_train, y_train), (X_valid, y_valid)],\n","    eval_name=['train', 'valid'],\n","    eval_metric=['mae', 'rmse'],\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rLdfMkJXw_Xl","executionInfo":{"status":"ok","timestamp":1728995873894,"user_tz":-480,"elapsed":93467,"user":{"displayName":"Jonindo Pasaribu","userId":"10958990953097471082"}},"outputId":"fe9d2d71-0d77-423a-9491-cd95419c2319"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 47.5885 | train_mae: 151.6673126220703| train_rmse: 169.80999755859375| valid_mae: 151.5447998046875| valid_rmse: 170.15371704101562|  0:00:01s\n","epoch 1  | loss: 1.91003 | train_mae: 24.213449478149414| train_rmse: 39.07899856567383| valid_mae: 23.855880737304688| valid_rmse: 37.579490661621094|  0:00:02s\n","epoch 2  | loss: 0.66181 | train_mae: 60.856910705566406| train_rmse: 64.10484313964844| valid_mae: 60.8583984375| valid_rmse: 64.0307388305664|  0:00:03s\n","epoch 3  | loss: 0.35606 | train_mae: 15.942700386047363| train_rmse: 23.77627944946289| valid_mae: 16.225099563598633| valid_rmse: 24.063390731811523|  0:00:03s\n","epoch 4  | loss: 0.27895 | train_mae: 15.864660263061523| train_rmse: 29.810279846191406| valid_mae: 16.26844024658203| valid_rmse: 30.31451988220215|  0:00:04s\n","epoch 5  | loss: 0.28293 | train_mae: 17.643680572509766| train_rmse: 27.13245964050293| valid_mae: 18.136930465698242| valid_rmse: 27.58064079284668|  0:00:05s\n","epoch 6  | loss: 0.28571 | train_mae: 14.781220436096191| train_rmse: 21.47187042236328| valid_mae: 14.705050468444824| valid_rmse: 21.349449157714844|  0:00:06s\n","epoch 7  | loss: 0.22264 | train_mae: 8.158459663391113| train_rmse: 13.789340019226074| valid_mae: 8.107049942016602| valid_rmse: 13.676899909973145|  0:00:07s\n","epoch 8  | loss: 0.2203  | train_mae: 9.394390106201172| train_rmse: 14.414790153503418| valid_mae: 9.343709945678711| valid_rmse: 14.270609855651855|  0:00:08s\n","epoch 9  | loss: 0.19305 | train_mae: 15.120059967041016| train_rmse: 18.90022087097168| valid_mae: 14.89406967163086| valid_rmse: 18.649669647216797|  0:00:09s\n","epoch 10 | loss: 0.18574 | train_mae: 12.919059753417969| train_rmse: 17.135499954223633| valid_mae: 12.518110275268555| valid_rmse: 16.73525047302246|  0:00:10s\n","epoch 11 | loss: 0.18728 | train_mae: 12.2462797164917| train_rmse: 15.239139556884766| valid_mae: 12.083620071411133| valid_rmse: 15.098640441894531|  0:00:11s\n","epoch 12 | loss: 0.19041 | train_mae: 11.619420051574707| train_rmse: 14.916150093078613| valid_mae: 11.215270042419434| valid_rmse: 14.469169616699219|  0:00:12s\n","epoch 13 | loss: 0.18549 | train_mae: 11.529919624328613| train_rmse: 14.308509826660156| valid_mae: 11.189000129699707| valid_rmse: 13.991499900817871|  0:00:13s\n","epoch 14 | loss: 0.18264 | train_mae: 4.466249942779541| train_rmse: 7.5122199058532715| valid_mae: 4.484099864959717| valid_rmse: 7.422420024871826|  0:00:14s\n","epoch 15 | loss: 0.17691 | train_mae: 3.5301899909973145| train_rmse: 5.3354902267456055| valid_mae: 3.5534698963165283| valid_rmse: 5.32243013381958|  0:00:15s\n","epoch 16 | loss: 0.17675 | train_mae: 2.7893500328063965| train_rmse: 4.1972198486328125| valid_mae: 2.866689920425415| valid_rmse: 4.276279926300049|  0:00:16s\n","epoch 17 | loss: 0.18693 | train_mae: 1.7841299772262573| train_rmse: 2.7375199794769287| valid_mae: 1.8100600242614746| valid_rmse: 2.7841899394989014|  0:00:17s\n","epoch 18 | loss: 0.18025 | train_mae: 1.8650000095367432| train_rmse: 2.9190800189971924| valid_mae: 1.905750036239624| valid_rmse: 3.046410083770752|  0:00:18s\n","epoch 19 | loss: 0.2077  | train_mae: 2.721299886703491| train_rmse: 4.185699939727783| valid_mae: 2.8063900470733643| valid_rmse: 4.274499893188477|  0:00:19s\n","epoch 20 | loss: 0.20625 | train_mae: 2.0843300819396973| train_rmse: 3.2261300086975098| valid_mae: 2.179270029067993| valid_rmse: 3.3711700439453125|  0:00:20s\n","epoch 21 | loss: 0.19043 | train_mae: 1.799299955368042| train_rmse: 2.263230085372925| valid_mae: 1.8409099578857422| valid_rmse: 2.3283400535583496|  0:00:21s\n","epoch 22 | loss: 0.21838 | train_mae: 1.1793999671936035| train_rmse: 1.8822799921035767| valid_mae: 1.1902300119400024| valid_rmse: 1.9313100576400757|  0:00:22s\n","epoch 23 | loss: 0.13968 | train_mae: 1.985859990119934| train_rmse: 2.6330599784851074| valid_mae: 1.9768699407577515| valid_rmse: 2.635050058364868|  0:00:23s\n","epoch 24 | loss: 0.12826 | train_mae: 3.725029945373535| train_rmse: 4.5313401222229| valid_mae: 3.78262996673584| valid_rmse: 4.590060234069824|  0:00:24s\n","epoch 25 | loss: 0.12404 | train_mae: 3.831239938735962| train_rmse: 4.417640209197998| valid_mae: 3.8358700275421143| valid_rmse: 4.412030220031738|  0:00:25s\n","epoch 26 | loss: 0.11017 | train_mae: 4.325930118560791| train_rmse: 4.8020100593566895| valid_mae: 4.314919948577881| valid_rmse: 4.7890801429748535|  0:00:26s\n","epoch 27 | loss: 0.10227 | train_mae: 3.878350019454956| train_rmse: 4.39394998550415| valid_mae: 3.868190050125122| valid_rmse: 4.377920150756836|  0:00:27s\n","epoch 28 | loss: 0.10235 | train_mae: 3.12746000289917| train_rmse: 3.625070095062256| valid_mae: 3.1258599758148193| valid_rmse: 3.613029956817627|  0:00:28s\n","epoch 29 | loss: 0.12136 | train_mae: 2.472130060195923| train_rmse: 2.951479911804199| valid_mae: 2.4722299575805664| valid_rmse: 2.9436099529266357|  0:00:29s\n","epoch 30 | loss: 0.11055 | train_mae: 1.7895300388336182| train_rmse: 2.292099952697754| valid_mae: 1.7860499620437622| valid_rmse: 2.2818899154663086|  0:00:30s\n","epoch 31 | loss: 0.13557 | train_mae: 2.3493399620056152| train_rmse: 2.6912200450897217| valid_mae: 2.3519299030303955| valid_rmse: 2.6842000484466553|  0:00:31s\n","epoch 32 | loss: 0.15149 | train_mae: 1.3609399795532227| train_rmse: 1.6834900379180908| valid_mae: 1.359660029411316| valid_rmse: 1.6707799434661865|  0:00:32s\n","epoch 33 | loss: 0.14215 | train_mae: 1.4888099431991577| train_rmse: 1.8136099576950073| valid_mae: 1.4865599870681763| valid_rmse: 1.8021999597549438|  0:00:33s\n","epoch 34 | loss: 0.13981 | train_mae: 1.0738699436187744| train_rmse: 1.3768500089645386| valid_mae: 1.0793399810791016| valid_rmse: 1.3859599828720093|  0:00:34s\n","epoch 35 | loss: 0.14349 | train_mae: 1.6493099927902222| train_rmse: 1.9288400411605835| valid_mae: 1.6447999477386475| valid_rmse: 1.9201799631118774|  0:00:35s\n","epoch 36 | loss: 0.1358  | train_mae: 0.974120020866394| train_rmse: 1.285099983215332| valid_mae: 0.9782500267028809| valid_rmse: 1.2818100452423096|  0:00:36s\n","epoch 37 | loss: 0.13731 | train_mae: 1.1252599954605103| train_rmse: 1.4000799655914307| valid_mae: 1.127959966659546| valid_rmse: 1.3937900066375732|  0:00:37s\n","epoch 38 | loss: 0.12434 | train_mae: 0.5577499866485596| train_rmse: 0.7304400205612183| valid_mae: 0.5620200037956238| valid_rmse: 0.7332199811935425|  0:00:38s\n","epoch 39 | loss: 0.13165 | train_mae: 0.8210600018501282| train_rmse: 1.035140037536621| valid_mae: 0.8352699875831604| valid_rmse: 1.0508500337600708|  0:00:39s\n","epoch 40 | loss: 0.12673 | train_mae: 0.5053600072860718| train_rmse: 0.6615599989891052| valid_mae: 0.5117499828338623| valid_rmse: 0.6669999957084656|  0:00:40s\n","epoch 41 | loss: 0.12852 | train_mae: 0.7053099870681763| train_rmse: 0.8670799732208252| valid_mae: 0.7169899940490723| valid_rmse: 0.8792200088500977|  0:00:41s\n","epoch 42 | loss: 0.12402 | train_mae: 0.3912999927997589| train_rmse: 0.49797001481056213| valid_mae: 0.4025300145149231| valid_rmse: 0.5134699940681458|  0:00:42s\n","epoch 43 | loss: 0.12063 | train_mae: 0.6460400223731995| train_rmse: 0.7620199918746948| valid_mae: 0.6580100059509277| valid_rmse: 0.7752599716186523|  0:00:43s\n","epoch 44 | loss: 0.12719 | train_mae: 0.3263300061225891| train_rmse: 0.41297000646591187| valid_mae: 0.3394699990749359| valid_rmse: 0.4314500093460083|  0:00:44s\n","epoch 45 | loss: 0.12242 | train_mae: 0.5701500177383423| train_rmse: 0.6637200117111206| valid_mae: 0.5831300020217896| valid_rmse: 0.6777899861335754|  0:00:45s\n","epoch 46 | loss: 0.12301 | train_mae: 0.31038999557495117| train_rmse: 0.39035001397132874| valid_mae: 0.3197700083255768| valid_rmse: 0.40724000334739685|  0:00:46s\n","epoch 47 | loss: 0.12073 | train_mae: 0.5619900226593018| train_rmse: 0.6505200266838074| valid_mae: 0.5706400275230408| valid_rmse: 0.6616700291633606|  0:00:47s\n","epoch 48 | loss: 0.12084 | train_mae: 0.2808600068092346| train_rmse: 0.3606700003147125| valid_mae: 0.2883000075817108| valid_rmse: 0.37551000714302063|  0:00:48s\n","epoch 49 | loss: 0.11986 | train_mae: 0.5307700037956238| train_rmse: 0.613789975643158| valid_mae: 0.5400300025939941| valid_rmse: 0.6230300068855286|  0:00:49s\n","epoch 50 | loss: 0.12265 | train_mae: 0.25613999366760254| train_rmse: 0.33153998851776123| valid_mae: 0.26357001066207886| valid_rmse: 0.34779998660087585|  0:00:50s\n","epoch 51 | loss: 0.12015 | train_mae: 0.5123500227928162| train_rmse: 0.5833899974822998| valid_mae: 0.5192199945449829| valid_rmse: 0.5925700068473816|  0:00:51s\n","epoch 52 | loss: 0.12209 | train_mae: 0.25091999769210815| train_rmse: 0.32572001218795776| valid_mae: 0.2584500014781952| valid_rmse: 0.3401400148868561|  0:00:52s\n","epoch 53 | loss: 0.12128 | train_mae: 0.4800899922847748| train_rmse: 0.5533400177955627| valid_mae: 0.48517000675201416| valid_rmse: 0.5621100068092346|  0:00:53s\n","epoch 54 | loss: 0.11703 | train_mae: 0.24819999933242798| train_rmse: 0.3285300135612488| valid_mae: 0.2559199929237366| valid_rmse: 0.34442999958992004|  0:00:54s\n","epoch 55 | loss: 0.11685 | train_mae: 0.44707000255584717| train_rmse: 0.5212399959564209| valid_mae: 0.45309001207351685| valid_rmse: 0.5296099781990051|  0:00:55s\n","epoch 56 | loss: 0.11502 | train_mae: 0.24762000143527985| train_rmse: 0.3281799852848053| valid_mae: 0.2540700137615204| valid_rmse: 0.3419800102710724|  0:00:56s\n","epoch 57 | loss: 0.12125 | train_mae: 0.416159987449646| train_rmse: 0.48510000109672546| valid_mae: 0.4253300130367279| valid_rmse: 0.4953399896621704|  0:00:57s\n","epoch 58 | loss: 0.11495 | train_mae: 0.22999000549316406| train_rmse: 0.3065899908542633| valid_mae: 0.2367600053548813| valid_rmse: 0.3228900134563446|  0:00:58s\n","epoch 59 | loss: 0.11481 | train_mae: 0.3763599991798401| train_rmse: 0.4452100098133087| valid_mae: 0.38291001319885254| valid_rmse: 0.4559299945831299|  0:00:59s\n","epoch 60 | loss: 0.11447 | train_mae: 0.2359900027513504| train_rmse: 0.3109799921512604| valid_mae: 0.2427700012922287| valid_rmse: 0.32631000876426697|  0:01:00s\n","epoch 61 | loss: 0.11683 | train_mae: 0.331059992313385| train_rmse: 0.39906999468803406| valid_mae: 0.3396399915218353| valid_rmse: 0.4125699996948242|  0:01:01s\n","epoch 62 | loss: 0.11578 | train_mae: 0.24476000666618347| train_rmse: 0.32113999128341675| valid_mae: 0.25352999567985535| valid_rmse: 0.337799996137619|  0:01:02s\n","epoch 63 | loss: 0.11475 | train_mae: 0.3637000024318695| train_rmse: 0.43345001339912415| valid_mae: 0.36726000905036926| valid_rmse: 0.4413500130176544|  0:01:03s\n","epoch 64 | loss: 0.11435 | train_mae: 0.22676999866962433| train_rmse: 0.30491000413894653| valid_mae: 0.23469999432563782| valid_rmse: 0.3195900022983551|  0:01:04s\n","epoch 65 | loss: 0.10902 | train_mae: 0.34154999256134033| train_rmse: 0.40966999530792236| valid_mae: 0.3498600125312805| valid_rmse: 0.4230700135231018|  0:01:06s\n","epoch 66 | loss: 0.1143  | train_mae: 0.24984000623226166| train_rmse: 0.33059999346733093| valid_mae: 0.2578299939632416| valid_rmse: 0.3450399935245514|  0:01:07s\n","epoch 67 | loss: 0.11333 | train_mae: 0.3755199909210205| train_rmse: 0.4498499929904938| valid_mae: 0.38363999128341675| valid_rmse: 0.46114999055862427|  0:01:08s\n","epoch 68 | loss: 0.11477 | train_mae: 0.31586000323295593| train_rmse: 0.38655999302864075| valid_mae: 0.32284998893737793| valid_rmse: 0.3993400037288666|  0:01:09s\n","epoch 69 | loss: 0.12775 | train_mae: 0.2665500044822693| train_rmse: 0.34549999237060547| valid_mae: 0.2743400037288666| valid_rmse: 0.35885998606681824|  0:01:10s\n","epoch 70 | loss: 0.09739 | train_mae: 0.22607000172138214| train_rmse: 0.2955999970436096| valid_mae: 0.23451000452041626| valid_rmse: 0.3133299946784973|  0:01:11s\n","epoch 71 | loss: 0.09393 | train_mae: 0.21039000153541565| train_rmse: 0.28317999839782715| valid_mae: 0.21991999447345734| valid_rmse: 0.3490599989891052|  0:01:11s\n","epoch 72 | loss: 0.0892  | train_mae: 0.22915999591350555| train_rmse: 0.3043699860572815| valid_mae: 0.23951999843120575| valid_rmse: 0.32315999269485474|  0:01:12s\n","epoch 73 | loss: 0.11069 | train_mae: 0.2252800017595291| train_rmse: 0.30316999554634094| valid_mae: 0.2327599972486496| valid_rmse: 0.31992000341415405|  0:01:13s\n","epoch 74 | loss: 0.10213 | train_mae: 0.21639999747276306| train_rmse: 0.28867000341415405| valid_mae: 0.22513000667095184| valid_rmse: 0.3047899901866913|  0:01:14s\n","epoch 75 | loss: 0.08525 | train_mae: 0.2142000049352646| train_rmse: 0.288129985332489| valid_mae: 0.2242099940776825| valid_rmse: 0.3090600073337555|  0:01:15s\n","epoch 76 | loss: 0.08638 | train_mae: 0.21644000709056854| train_rmse: 0.2871200144290924| valid_mae: 0.22618000209331512| valid_rmse: 0.3045699894428253|  0:01:16s\n","epoch 77 | loss: 0.0914  | train_mae: 0.21164000034332275| train_rmse: 0.28913000226020813| valid_mae: 0.22349999845027924| valid_rmse: 0.3112500011920929|  0:01:18s\n","epoch 78 | loss: 0.09752 | train_mae: 0.22623999416828156| train_rmse: 0.3007600009441376| valid_mae: 0.2359900027513504| valid_rmse: 0.31935998797416687|  0:01:19s\n","epoch 79 | loss: 0.09642 | train_mae: 0.2185399979352951| train_rmse: 0.28644999861717224| valid_mae: 0.22782999277114868| valid_rmse: 0.3038800060749054|  0:01:20s\n","epoch 80 | loss: 0.09599 | train_mae: 0.21182000637054443| train_rmse: 0.28119999170303345| valid_mae: 0.22184999287128448| valid_rmse: 0.2965100109577179|  0:01:21s\n","epoch 81 | loss: 0.0916  | train_mae: 0.20642000436782837| train_rmse: 0.2790699899196625| valid_mae: 0.21683000028133392| valid_rmse: 0.2963699996471405|  0:01:21s\n","epoch 82 | loss: 0.09351 | train_mae: 0.20145000517368317| train_rmse: 0.2722100019454956| valid_mae: 0.21355000138282776| valid_rmse: 0.29322999715805054|  0:01:22s\n","epoch 83 | loss: 0.09326 | train_mae: 0.2501800060272217| train_rmse: 0.32089999318122864| valid_mae: 0.26010000705718994| valid_rmse: 0.33610999584198|  0:01:23s\n","epoch 84 | loss: 0.09828 | train_mae: 0.2270199954509735| train_rmse: 0.3186199963092804| valid_mae: 0.23880000412464142| valid_rmse: 0.33535000681877136|  0:01:24s\n","epoch 85 | loss: 0.09638 | train_mae: 0.2107599973678589| train_rmse: 0.29524001479148865| valid_mae: 0.22202999889850616| valid_rmse: 0.31492000818252563|  0:01:26s\n","epoch 86 | loss: 0.0916  | train_mae: 0.23768000304698944| train_rmse: 0.7254599928855896| valid_mae: 0.2443699985742569| valid_rmse: 0.4752500057220459|  0:01:27s\n","epoch 87 | loss: 0.08828 | train_mae: 0.21390999853610992| train_rmse: 0.33098000288009644| valid_mae: 0.22378000617027283| valid_rmse: 0.303849995136261|  0:01:28s\n","epoch 88 | loss: 0.11036 | train_mae: 0.2386000007390976| train_rmse: 0.31248000264167786| valid_mae: 0.24719999730587006| valid_rmse: 0.32739999890327454|  0:01:29s\n","epoch 89 | loss: 0.14918 | train_mae: 0.28696998953819275| train_rmse: 0.4355599880218506| valid_mae: 0.29409998655319214| valid_rmse: 0.37084999680519104|  0:01:30s\n","epoch 90 | loss: 0.12037 | train_mae: 0.2549799978733063| train_rmse: 0.3522300124168396| valid_mae: 0.26322001218795776| valid_rmse: 0.3622100055217743|  0:01:31s\n","epoch 91 | loss: 0.12442 | train_mae: 0.3657900094985962| train_rmse: 0.4311699867248535| valid_mae: 0.3721500039100647| valid_rmse: 0.4414600133895874|  0:01:32s\n","epoch 92 | loss: 0.11359 | train_mae: 0.2326499968767166| train_rmse: 0.3130899965763092| valid_mae: 0.24488000571727753| valid_rmse: 0.3286699950695038|  0:01:33s\n","\n","Early stopping occurred at epoch 92 with best_epoch = 82 and best_valid_rmse = 0.29322999715805054\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n"]}]},{"cell_type":"code","source":["from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, classification_report\n","\n","preds = best_model.predict(X_test)\n","y_true = y_test\n","\n","mae_test = mean_absolute_error(y_pred=preds, y_true=y_true)\n","mse = mean_squared_error(y_pred=preds, y_true=y_true)\n","rmse_test = np.sqrt(mean_squared_error(y_true, y_pred=preds))\n","r2_test = r2_score(y_true=y_true, y_pred=preds)\n","\n","print(\"Best Valid RMSE:\", best_model.best_cost)\n","print(\"Test MAE:\", mae_test)\n","print(\"Test RMSE:\", rmse_test)\n","print(\"R-squared:\", r2_test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"o3TYXT_o_6oS","executionInfo":{"status":"ok","timestamp":1728995875517,"user_tz":-480,"elapsed":392,"user":{"displayName":"Jonindo Pasaribu","userId":"10958990953097471082"}},"outputId":"a66176c5-b617-43ec-8c18-c772dac55403"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Best Valid RMSE: 0.2932267\n","Test MAE: 0.20584235\n","Test RMSE: 0.2764833\n","R-squared: 0.7631413340568542\n"]}]},{"cell_type":"code","source":["base_preds = tnr.predict(X_test)\n","\n","base_mae_test = mean_absolute_error(y_pred=base_preds, y_true=y_true)\n","base_mse = mean_squared_error(y_pred=base_preds, y_true=y_true)\n","base_rmse_test = np.sqrt(mean_squared_error(y_true, y_pred=base_preds))\n","\n","print(\"Best Valid Score:\", tnr.best_cost)\n","print(\"Test MAE:\", base_mae_test)\n","print(\"Test RMSE:\", base_rmse_test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8nW4N4ls2O6R","executionInfo":{"status":"ok","timestamp":1716964790968,"user_tz":-420,"elapsed":411,"user":{"displayName":"Jonindo Pasaribu","userId":"10958990953097471082"}},"outputId":"5391d8bb-32dc-456e-81e1-cdb256aa9b35"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Best Valid Score: 3.4875755\n","Test MAE: 2.1245074\n","Test RMSE: 3.6020257\n"]}]},{"cell_type":"code","source":["from matplotlib import pyplot as plt"],"metadata":{"id":"sxa64ArkAahN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.plot(tnr.history['loss'])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":448},"id":"zqkBaf7btWFx","executionInfo":{"status":"ok","timestamp":1716965025700,"user_tz":-420,"elapsed":705,"user":{"displayName":"Jonindo Pasaribu","userId":"10958990953097471082"}},"outputId":"89efb4b7-f63d-43a3-f190-cfe48cfbc358"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[<matplotlib.lines.Line2D at 0x7c111013a6b0>]"]},"metadata":{},"execution_count":23},{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"code","source":["plt.plot(best_model.history['loss'])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":448},"id":"j7OdxaVNtYNt","executionInfo":{"status":"ok","timestamp":1716965029034,"user_tz":-420,"elapsed":403,"user":{"displayName":"Jonindo Pasaribu","userId":"10958990953097471082"}},"outputId":"30318817-264e-4a1c-84b8-5f4a3431f055"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[<matplotlib.lines.Line2D at 0x7c10c4119f00>]"]},"metadata":{},"execution_count":24},{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]}]}