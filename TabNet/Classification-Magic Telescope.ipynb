{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","machine_shape":"hm","authorship_tag":"ABX9TyNGh/hyCMiU/YhDmdp7hqKS"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["!wget https://huggingface.co/datasets/puhsu/tabular-benchmarks/resolve/main/data.tar -O tabular-dl-tabr.tar.gz\n","!tar -xvf tabular-dl-tabr.tar.gz"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pulqlCAgJDEt","executionInfo":{"status":"ok","timestamp":1731760014950,"user_tz":-420,"elapsed":48188,"user":{"displayName":"Jonindo Pasaribu","userId":"10958990953097471082"}},"outputId":"988818db-c1ba-40e9-ac22-ecd194794fc2"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["--2024-11-16 12:26:06--  https://huggingface.co/datasets/puhsu/tabular-benchmarks/resolve/main/data.tar\n","Resolving huggingface.co (huggingface.co)... 18.164.174.23, 18.164.174.118, 18.164.174.17, ...\n","Connecting to huggingface.co (huggingface.co)|18.164.174.23|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://cdn-lfs.hf.co/repos/1b/25/1b25d6e2556c827abfaf6ba9da6021338691cafc39fe9d77986955ae0a69243d/0d74e4b96febb48fbe4dd2d851f8638b5738354f82c3183f92adbd2abf2f256b?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27data.tar%3B+filename%3D%22data.tar%22%3B&response-content-type=application%2Fx-tar&Expires=1732019166&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTczMjAxOTE2Nn19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5oZi5jby9yZXBvcy8xYi8yNS8xYjI1ZDZlMjU1NmM4MjdhYmZhZjZiYTlkYTYwMjEzMzg2OTFjYWZjMzlmZTlkNzc5ODY5NTVhZTBhNjkyNDNkLzBkNzRlNGI5NmZlYmI0OGZiZTRkZDJkODUxZjg2MzhiNTczODM1NGY4MmMzMTgzZjkyYWRiZDJhYmYyZjI1NmI%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qJnJlc3BvbnNlLWNvbnRlbnQtdHlwZT0qIn1dfQ__&Signature=t86rxWzb8bBr5Rj0CAro1%7EiyTxC5S6F-mJLrSNmChaS8PJMjZXhKxUzQ59Ho4Nz8uOd0dw-fj94e-EO7J%7EGJQQyNdWHkPDq%7EYBgU1uZm1F%7EM3ez5gPsyG0W8zliEB2QkjZR%7EY4Sy2H7X2rEHIJAoxJAUYNruR68gOkglgZ6H4AVi7Nt4jnH42IBYFLP3vnLpvHrrTLJ0dd6RASpLRHFBQpiSgQ5Af4rfSgj2kkYgnRYbEzYLJj3ioSwjyGRR5jRt-c6SN-pjcUuj1N-D8ldtlUQPNkOHrf9eefqR5murXZ4VntgWH0PbS%7E33suN-scBMp2JSW5a0tHO-e4-tykkqmQ__&Key-Pair-Id=K3RPWS32NSSJCE [following]\n","--2024-11-16 12:26:06--  https://cdn-lfs.hf.co/repos/1b/25/1b25d6e2556c827abfaf6ba9da6021338691cafc39fe9d77986955ae0a69243d/0d74e4b96febb48fbe4dd2d851f8638b5738354f82c3183f92adbd2abf2f256b?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27data.tar%3B+filename%3D%22data.tar%22%3B&response-content-type=application%2Fx-tar&Expires=1732019166&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTczMjAxOTE2Nn19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5oZi5jby9yZXBvcy8xYi8yNS8xYjI1ZDZlMjU1NmM4MjdhYmZhZjZiYTlkYTYwMjEzMzg2OTFjYWZjMzlmZTlkNzc5ODY5NTVhZTBhNjkyNDNkLzBkNzRlNGI5NmZlYmI0OGZiZTRkZDJkODUxZjg2MzhiNTczODM1NGY4MmMzMTgzZjkyYWRiZDJhYmYyZjI1NmI%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qJnJlc3BvbnNlLWNvbnRlbnQtdHlwZT0qIn1dfQ__&Signature=t86rxWzb8bBr5Rj0CAro1%7EiyTxC5S6F-mJLrSNmChaS8PJMjZXhKxUzQ59Ho4Nz8uOd0dw-fj94e-EO7J%7EGJQQyNdWHkPDq%7EYBgU1uZm1F%7EM3ez5gPsyG0W8zliEB2QkjZR%7EY4Sy2H7X2rEHIJAoxJAUYNruR68gOkglgZ6H4AVi7Nt4jnH42IBYFLP3vnLpvHrrTLJ0dd6RASpLRHFBQpiSgQ5Af4rfSgj2kkYgnRYbEzYLJj3ioSwjyGRR5jRt-c6SN-pjcUuj1N-D8ldtlUQPNkOHrf9eefqR5murXZ4VntgWH0PbS%7E33suN-scBMp2JSW5a0tHO-e4-tykkqmQ__&Key-Pair-Id=K3RPWS32NSSJCE\n","Resolving cdn-lfs.hf.co (cdn-lfs.hf.co)... 3.168.132.51, 3.168.132.99, 3.168.132.25, ...\n","Connecting to cdn-lfs.hf.co (cdn-lfs.hf.co)|3.168.132.51|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 3094384640 (2.9G) [application/x-tar]\n","Saving to: ‘tabular-dl-tabr.tar.gz’\n","\n","tabular-dl-tabr.tar 100%[===================>]   2.88G  79.7MB/s    in 31s     \n","\n","2024-11-16 12:26:38 (95.1 MB/s) - ‘tabular-dl-tabr.tar.gz’ saved [3094384640/3094384640]\n","\n","data/\n","data/regression-num-medium-0-Ailerons/\n","data/regression-num-medium-0-Ailerons/X_num_val.npy\n","data/regression-num-medium-0-Ailerons/Y_val.npy\n","data/regression-num-medium-0-Ailerons/X_num_train.npy\n","data/regression-num-medium-0-Ailerons/info.json\n","data/regression-num-medium-0-Ailerons/READY\n","data/regression-num-medium-0-Ailerons/X_num_test.npy\n","data/regression-num-medium-0-Ailerons/Y_test.npy\n","data/regression-num-medium-0-Ailerons/Y_train.npy\n","data/regression-cat-medium-0-house_sales/\n","data/regression-cat-medium-0-house_sales/X_num_val.npy\n","data/regression-cat-medium-0-house_sales/Y_val.npy\n","data/regression-cat-medium-0-house_sales/X_bin_val.npy\n","data/regression-cat-medium-0-house_sales/X_num_train.npy\n","data/regression-cat-medium-0-house_sales/X_bin_train.npy\n","data/regression-cat-medium-0-house_sales/info.json\n","data/regression-cat-medium-0-house_sales/READY\n","data/regression-cat-medium-0-house_sales/X_bin_test.npy\n","data/regression-cat-medium-0-house_sales/X_num_test.npy\n","data/regression-cat-medium-0-house_sales/Y_test.npy\n","data/regression-cat-medium-0-house_sales/Y_train.npy\n","data/classif-cat-medium-2-KDDCup09_upselling/\n","data/classif-cat-medium-2-KDDCup09_upselling/X_cat_val.npy\n","data/classif-cat-medium-2-KDDCup09_upselling/X_num_val.npy\n","data/classif-cat-medium-2-KDDCup09_upselling/Y_val.npy\n","data/classif-cat-medium-2-KDDCup09_upselling/X_bin_val.npy\n","data/classif-cat-medium-2-KDDCup09_upselling/X_num_train.npy\n","data/classif-cat-medium-2-KDDCup09_upselling/X_cat_test.npy\n","data/classif-cat-medium-2-KDDCup09_upselling/X_bin_train.npy\n","data/classif-cat-medium-2-KDDCup09_upselling/X_cat_train.npy\n","data/classif-cat-medium-2-KDDCup09_upselling/info.json\n","data/classif-cat-medium-2-KDDCup09_upselling/READY\n","data/classif-cat-medium-2-KDDCup09_upselling/X_bin_test.npy\n","data/classif-cat-medium-2-KDDCup09_upselling/X_num_test.npy\n","data/classif-cat-medium-2-KDDCup09_upselling/Y_test.npy\n","data/classif-cat-medium-2-KDDCup09_upselling/Y_train.npy\n","data/regression-num-medium-2-isolet/\n","data/regression-num-medium-2-isolet/X_num_val.npy\n","data/regression-num-medium-2-isolet/Y_val.npy\n","data/regression-num-medium-2-isolet/X_num_train.npy\n","data/regression-num-medium-2-isolet/info.json\n","data/regression-num-medium-2-isolet/READY\n","data/regression-num-medium-2-isolet/X_num_test.npy\n","data/regression-num-medium-2-isolet/Y_test.npy\n","data/regression-num-medium-2-isolet/Y_train.npy\n","data/regression-cat-medium-1-Brazilian_houses/\n","data/regression-cat-medium-1-Brazilian_houses/X_cat_val.npy\n","data/regression-cat-medium-1-Brazilian_houses/X_num_val.npy\n","data/regression-cat-medium-1-Brazilian_houses/Y_val.npy\n","data/regression-cat-medium-1-Brazilian_houses/X_bin_val.npy\n","data/regression-cat-medium-1-Brazilian_houses/X_num_train.npy\n","data/regression-cat-medium-1-Brazilian_houses/X_cat_test.npy\n","data/regression-cat-medium-1-Brazilian_houses/X_bin_train.npy\n","data/regression-cat-medium-1-Brazilian_houses/X_cat_train.npy\n","data/regression-cat-medium-1-Brazilian_houses/info.json\n","data/regression-cat-medium-1-Brazilian_houses/READY\n","data/regression-cat-medium-1-Brazilian_houses/X_bin_test.npy\n","data/regression-cat-medium-1-Brazilian_houses/X_num_test.npy\n","data/regression-cat-medium-1-Brazilian_houses/Y_test.npy\n","data/regression-cat-medium-1-Brazilian_houses/Y_train.npy\n","data/regression-num-medium-2-wine_quality/\n","data/regression-num-medium-2-wine_quality/X_num_val.npy\n","data/regression-num-medium-2-wine_quality/Y_val.npy\n","data/regression-num-medium-2-wine_quality/X_num_train.npy\n","data/regression-num-medium-2-wine_quality/info.json\n","data/regression-num-medium-2-wine_quality/READY\n","data/regression-num-medium-2-wine_quality/X_num_test.npy\n","data/regression-num-medium-2-wine_quality/Y_test.npy\n","data/regression-num-medium-2-wine_quality/Y_train.npy\n","data/regression-num-medium-0-california/\n","data/regression-num-medium-0-california/X_num_val.npy\n","data/regression-num-medium-0-california/Y_val.npy\n","data/regression-num-medium-0-california/X_num_train.npy\n","data/regression-num-medium-0-california/info.json\n","data/regression-num-medium-0-california/READY\n","data/regression-num-medium-0-california/X_num_test.npy\n","data/regression-num-medium-0-california/Y_test.npy\n","data/regression-num-medium-0-california/Y_train.npy\n","data/classif-num-medium-2-wine/\n","data/classif-num-medium-2-wine/X_num_val.npy\n","data/classif-num-medium-2-wine/Y_val.npy\n","data/classif-num-medium-2-wine/X_num_train.npy\n","data/classif-num-medium-2-wine/info.json\n","data/classif-num-medium-2-wine/READY\n","data/classif-num-medium-2-wine/X_num_test.npy\n","data/classif-num-medium-2-wine/Y_test.npy\n","data/classif-num-medium-2-wine/Y_train.npy\n","data/classif-num-medium-1-phoneme/\n","data/classif-num-medium-1-phoneme/X_num_val.npy\n","data/classif-num-medium-1-phoneme/Y_val.npy\n","data/classif-num-medium-1-phoneme/X_num_train.npy\n","data/classif-num-medium-1-phoneme/info.json\n","data/classif-num-medium-1-phoneme/READY\n","data/classif-num-medium-1-phoneme/X_num_test.npy\n","data/classif-num-medium-1-phoneme/Y_test.npy\n","data/classif-num-medium-1-phoneme/Y_train.npy\n","data/regression-num-medium-1-isolet/\n","data/regression-num-medium-1-isolet/X_num_val.npy\n","data/regression-num-medium-1-isolet/Y_val.npy\n","data/regression-num-medium-1-isolet/X_num_train.npy\n","data/regression-num-medium-1-isolet/info.json\n","data/regression-num-medium-1-isolet/READY\n","data/regression-num-medium-1-isolet/X_num_test.npy\n","data/regression-num-medium-1-isolet/Y_test.npy\n","data/regression-num-medium-1-isolet/Y_train.npy\n","data/churn/\n","data/churn/X_cat_val.npy\n","data/churn/X_num_val.npy\n","data/churn/Y_val.npy\n","data/churn/X_bin_val.npy\n","data/churn/X_num_train.npy\n","data/churn/X_cat_test.npy\n","data/churn/X_bin_train.npy\n","data/churn/X_cat_train.npy\n","data/churn/info.json\n","data/churn/READY\n","data/churn/X_bin_test.npy\n","data/churn/X_num_test.npy\n","data/churn/Y_test.npy\n","data/churn/Y_train.npy\n","data/regression-num-medium-2-sulfur/\n","data/regression-num-medium-2-sulfur/X_num_val.npy\n","data/regression-num-medium-2-sulfur/Y_val.npy\n","data/regression-num-medium-2-sulfur/X_num_train.npy\n","data/regression-num-medium-2-sulfur/info.json\n","data/regression-num-medium-2-sulfur/READY\n","data/regression-num-medium-2-sulfur/X_num_test.npy\n","data/regression-num-medium-2-sulfur/Y_test.npy\n","data/regression-num-medium-2-sulfur/Y_train.npy\n","data/regression-cat-large-0-diamonds/\n","data/regression-cat-large-0-diamonds/X_cat_val.npy\n","data/regression-cat-large-0-diamonds/X_num_val.npy\n","data/regression-cat-large-0-diamonds/Y_val.npy\n","data/regression-cat-large-0-diamonds/X_num_train.npy\n","data/regression-cat-large-0-diamonds/X_cat_test.npy\n","data/regression-cat-large-0-diamonds/X_cat_train.npy\n","data/regression-cat-large-0-diamonds/info.json\n","data/regression-cat-large-0-diamonds/READY\n","data/regression-cat-large-0-diamonds/X_num_test.npy\n","data/regression-cat-large-0-diamonds/Y_test.npy\n","data/regression-cat-large-0-diamonds/Y_train.npy\n","data/classif-cat-large-0-road-safety/\n","data/classif-cat-large-0-road-safety/X_cat_val.npy\n","data/classif-cat-large-0-road-safety/X_num_val.npy\n","data/classif-cat-large-0-road-safety/Y_val.npy\n","data/classif-cat-large-0-road-safety/X_num_train.npy\n","data/classif-cat-large-0-road-safety/X_cat_test.npy\n","data/classif-cat-large-0-road-safety/X_cat_train.npy\n","data/classif-cat-large-0-road-safety/info.json\n","data/classif-cat-large-0-road-safety/READY\n","data/classif-cat-large-0-road-safety/X_num_test.npy\n","data/classif-cat-large-0-road-safety/Y_test.npy\n","data/classif-cat-large-0-road-safety/Y_train.npy\n","data/classif-num-medium-1-MagicTelescope/\n","data/classif-num-medium-1-MagicTelescope/X_num_val.npy\n","data/classif-num-medium-1-MagicTelescope/Y_val.npy\n","data/classif-num-medium-1-MagicTelescope/X_num_train.npy\n","data/classif-num-medium-1-MagicTelescope/info.json\n","data/classif-num-medium-1-MagicTelescope/READY\n","data/classif-num-medium-1-MagicTelescope/X_num_test.npy\n","data/classif-num-medium-1-MagicTelescope/Y_test.npy\n","data/classif-num-medium-1-MagicTelescope/Y_train.npy\n","data/regression-num-medium-0-wine_quality/\n","data/regression-num-medium-0-wine_quality/X_num_val.npy\n","data/regression-num-medium-0-wine_quality/Y_val.npy\n","data/regression-num-medium-0-wine_quality/X_num_train.npy\n","data/regression-num-medium-0-wine_quality/info.json\n","data/regression-num-medium-0-wine_quality/READY\n","data/regression-num-medium-0-wine_quality/X_num_test.npy\n","data/regression-num-medium-0-wine_quality/Y_test.npy\n","data/regression-num-medium-0-wine_quality/Y_train.npy\n","data/adult/\n","data/adult/X_cat_val.npy\n","data/adult/X_num_val.npy\n","data/adult/Y_val.npy\n","data/adult/X_bin_val.npy\n","data/adult/X_num_train.npy\n","data/adult/X_cat_test.npy\n","data/adult/X_bin_train.npy\n","data/adult/X_cat_train.npy\n","data/adult/info.json\n","data/adult/READY\n","data/adult/X_bin_test.npy\n","data/adult/X_num_test.npy\n","data/adult/Y_test.npy\n","data/adult/Y_train.npy\n","data/classif-num-medium-1-kdd_ipums_la_97-small/\n","data/classif-num-medium-1-kdd_ipums_la_97-small/X_num_val.npy\n","data/classif-num-medium-1-kdd_ipums_la_97-small/Y_val.npy\n","data/classif-num-medium-1-kdd_ipums_la_97-small/X_num_train.npy\n","data/classif-num-medium-1-kdd_ipums_la_97-small/info.json\n","data/classif-num-medium-1-kdd_ipums_la_97-small/READY\n","data/classif-num-medium-1-kdd_ipums_la_97-small/X_num_test.npy\n","data/classif-num-medium-1-kdd_ipums_la_97-small/Y_test.npy\n","data/classif-num-medium-1-kdd_ipums_la_97-small/Y_train.npy\n","data/regression-num-medium-0-superconduct/\n","data/regression-num-medium-0-superconduct/X_num_val.npy\n","data/regression-num-medium-0-superconduct/Y_val.npy\n","data/regression-num-medium-0-superconduct/X_num_train.npy\n","data/regression-num-medium-0-superconduct/info.json\n","data/regression-num-medium-0-superconduct/READY\n","data/regression-num-medium-0-superconduct/X_num_test.npy\n","data/regression-num-medium-0-superconduct/Y_test.npy\n","data/regression-num-medium-0-superconduct/Y_train.npy\n","data/regression-num-medium-0-house_16H/\n","data/regression-num-medium-0-house_16H/X_num_val.npy\n","data/regression-num-medium-0-house_16H/Y_val.npy\n","data/regression-num-medium-0-house_16H/X_num_train.npy\n","data/regression-num-medium-0-house_16H/info.json\n","data/regression-num-medium-0-house_16H/READY\n","data/regression-num-medium-0-house_16H/X_num_test.npy\n","data/regression-num-medium-0-house_16H/Y_test.npy\n","data/regression-num-medium-0-house_16H/Y_train.npy\n","data/weather-big/\n","data/weather-big/X_num_val.npy\n","data/weather-big/Y_val.npy\n","data/weather-big/X_bin_val.npy\n","data/weather-big/X_num_train.npy\n","data/weather-big/X_bin_train.npy\n","data/weather-big/LICENSE.md\n","data/weather-big/info.json\n","data/weather-big/READY\n","data/weather-big/X_bin_test.npy\n","data/weather-big/X_num_test.npy\n","data/weather-big/Y_test.npy\n","data/weather-big/Y_train.npy\n","data/classif-num-large-0-Higgs/\n","data/classif-num-large-0-Higgs/X_num_val.npy\n","data/classif-num-large-0-Higgs/Y_val.npy\n","data/classif-num-large-0-Higgs/X_num_train.npy\n","data/classif-num-large-0-Higgs/info.json\n","data/classif-num-large-0-Higgs/READY\n","data/classif-num-large-0-Higgs/X_num_test.npy\n","data/classif-num-large-0-Higgs/Y_test.npy\n","data/classif-num-large-0-Higgs/Y_train.npy\n","data/regression-cat-medium-2-analcatdata_supreme/\n","data/regression-cat-medium-2-analcatdata_supreme/X_num_val.npy\n","data/regression-cat-medium-2-analcatdata_supreme/Y_val.npy\n","data/regression-cat-medium-2-analcatdata_supreme/X_bin_val.npy\n","data/regression-cat-medium-2-analcatdata_supreme/X_num_train.npy\n","data/regression-cat-medium-2-analcatdata_supreme/X_bin_train.npy\n","data/regression-cat-medium-2-analcatdata_supreme/info.json\n","data/regression-cat-medium-2-analcatdata_supreme/READY\n","data/regression-cat-medium-2-analcatdata_supreme/X_bin_test.npy\n","data/regression-cat-medium-2-analcatdata_supreme/X_num_test.npy\n","data/regression-cat-medium-2-analcatdata_supreme/Y_test.npy\n","data/regression-cat-medium-2-analcatdata_supreme/Y_train.npy\n","data/regression-cat-large-0-black_friday/\n","data/regression-cat-large-0-black_friday/X_cat_val.npy\n","data/regression-cat-large-0-black_friday/X_num_val.npy\n","data/regression-cat-large-0-black_friday/Y_val.npy\n","data/regression-cat-large-0-black_friday/X_bin_val.npy\n","data/regression-cat-large-0-black_friday/X_num_train.npy\n","data/regression-cat-large-0-black_friday/X_cat_test.npy\n","data/regression-cat-large-0-black_friday/X_bin_train.npy\n","data/regression-cat-large-0-black_friday/X_cat_train.npy\n","data/regression-cat-large-0-black_friday/info.json\n","data/regression-cat-large-0-black_friday/READY\n","data/regression-cat-large-0-black_friday/X_bin_test.npy\n","data/regression-cat-large-0-black_friday/X_num_test.npy\n","data/regression-cat-large-0-black_friday/Y_test.npy\n","data/regression-cat-large-0-black_friday/Y_train.npy\n","data/classif-num-medium-1-wine/\n","data/classif-num-medium-1-wine/X_num_val.npy\n","data/classif-num-medium-1-wine/Y_val.npy\n","data/classif-num-medium-1-wine/X_num_train.npy\n","data/classif-num-medium-1-wine/info.json\n","data/classif-num-medium-1-wine/READY\n","data/classif-num-medium-1-wine/X_num_test.npy\n","data/classif-num-medium-1-wine/Y_test.npy\n","data/classif-num-medium-1-wine/Y_train.npy\n","data/regression-cat-medium-0-visualizing_soil/\n","data/regression-cat-medium-0-visualizing_soil/X_num_val.npy\n","data/regression-cat-medium-0-visualizing_soil/Y_val.npy\n","data/regression-cat-medium-0-visualizing_soil/X_bin_val.npy\n","data/regression-cat-medium-0-visualizing_soil/X_num_train.npy\n","data/regression-cat-medium-0-visualizing_soil/X_bin_train.npy\n","data/regression-cat-medium-0-visualizing_soil/info.json\n","data/regression-cat-medium-0-visualizing_soil/READY\n","data/regression-cat-medium-0-visualizing_soil/X_bin_test.npy\n","data/regression-cat-medium-0-visualizing_soil/X_num_test.npy\n","data/regression-cat-medium-0-visualizing_soil/Y_test.npy\n","data/regression-cat-medium-0-visualizing_soil/Y_train.npy\n","data/regression-cat-medium-1-Mercedes_Benz_Greener_Manufacturing/\n","data/regression-cat-medium-1-Mercedes_Benz_Greener_Manufacturing/X_cat_val.npy\n","data/regression-cat-medium-1-Mercedes_Benz_Greener_Manufacturing/Y_val.npy\n","data/regression-cat-medium-1-Mercedes_Benz_Greener_Manufacturing/X_bin_val.npy\n","data/regression-cat-medium-1-Mercedes_Benz_Greener_Manufacturing/X_cat_test.npy\n","data/regression-cat-medium-1-Mercedes_Benz_Greener_Manufacturing/X_bin_train.npy\n","data/regression-cat-medium-1-Mercedes_Benz_Greener_Manufacturing/X_cat_train.npy\n","data/regression-cat-medium-1-Mercedes_Benz_Greener_Manufacturing/info.json\n","data/regression-cat-medium-1-Mercedes_Benz_Greener_Manufacturing/READY\n","data/regression-cat-medium-1-Mercedes_Benz_Greener_Manufacturing/X_bin_test.npy\n","data/regression-cat-medium-1-Mercedes_Benz_Greener_Manufacturing/Y_test.npy\n","data/regression-cat-medium-1-Mercedes_Benz_Greener_Manufacturing/Y_train.npy\n","data/classif-num-medium-0-kdd_ipums_la_97-small/\n","data/classif-num-medium-0-kdd_ipums_la_97-small/X_num_val.npy\n","data/classif-num-medium-0-kdd_ipums_la_97-small/Y_val.npy\n","data/classif-num-medium-0-kdd_ipums_la_97-small/X_num_train.npy\n","data/classif-num-medium-0-kdd_ipums_la_97-small/info.json\n","data/classif-num-medium-0-kdd_ipums_la_97-small/READY\n","data/classif-num-medium-0-kdd_ipums_la_97-small/X_num_test.npy\n","data/classif-num-medium-0-kdd_ipums_la_97-small/Y_test.npy\n","data/classif-num-medium-0-kdd_ipums_la_97-small/Y_train.npy\n","data/regression-num-medium-1-MiamiHousing2016/\n","data/regression-num-medium-1-MiamiHousing2016/X_num_val.npy\n","data/regression-num-medium-1-MiamiHousing2016/Y_val.npy\n","data/regression-num-medium-1-MiamiHousing2016/X_num_train.npy\n","data/regression-num-medium-1-MiamiHousing2016/info.json\n","data/regression-num-medium-1-MiamiHousing2016/READY\n","data/regression-num-medium-1-MiamiHousing2016/X_num_test.npy\n","data/regression-num-medium-1-MiamiHousing2016/Y_test.npy\n","data/regression-num-medium-1-MiamiHousing2016/Y_train.npy\n","data/regression-cat-medium-0-OnlineNewsPopularity/\n","data/regression-cat-medium-0-OnlineNewsPopularity/X_num_val.npy\n","data/regression-cat-medium-0-OnlineNewsPopularity/Y_val.npy\n","data/regression-cat-medium-0-OnlineNewsPopularity/X_bin_val.npy\n","data/regression-cat-medium-0-OnlineNewsPopularity/X_num_train.npy\n","data/regression-cat-medium-0-OnlineNewsPopularity/X_bin_train.npy\n","data/regression-cat-medium-0-OnlineNewsPopularity/info.json\n","data/regression-cat-medium-0-OnlineNewsPopularity/READY\n","data/regression-cat-medium-0-OnlineNewsPopularity/X_bin_test.npy\n","data/regression-cat-medium-0-OnlineNewsPopularity/X_num_test.npy\n","data/regression-cat-medium-0-OnlineNewsPopularity/Y_test.npy\n","data/regression-cat-medium-0-OnlineNewsPopularity/Y_train.npy\n","data/regression-num-medium-1-elevators/\n","data/regression-num-medium-1-elevators/X_num_val.npy\n","data/regression-num-medium-1-elevators/Y_val.npy\n","data/regression-num-medium-1-elevators/X_num_train.npy\n","data/regression-num-medium-1-elevators/info.json\n","data/regression-num-medium-1-elevators/READY\n","data/regression-num-medium-1-elevators/X_num_test.npy\n","data/regression-num-medium-1-elevators/Y_test.npy\n","data/regression-num-medium-1-elevators/Y_train.npy\n","data/regression-num-medium-0-pol/\n","data/regression-num-medium-0-pol/X_num_val.npy\n","data/regression-num-medium-0-pol/Y_val.npy\n","data/regression-num-medium-0-pol/X_num_train.npy\n","data/regression-num-medium-0-pol/info.json\n","data/regression-num-medium-0-pol/READY\n","data/regression-num-medium-0-pol/X_num_test.npy\n","data/regression-num-medium-0-pol/Y_test.npy\n","data/regression-num-medium-0-pol/Y_train.npy\n","data/classif-num-medium-2-kdd_ipums_la_97-small/\n","data/classif-num-medium-2-kdd_ipums_la_97-small/X_num_val.npy\n","data/classif-num-medium-2-kdd_ipums_la_97-small/Y_val.npy\n","data/classif-num-medium-2-kdd_ipums_la_97-small/X_num_train.npy\n","data/classif-num-medium-2-kdd_ipums_la_97-small/info.json\n","data/classif-num-medium-2-kdd_ipums_la_97-small/READY\n","data/classif-num-medium-2-kdd_ipums_la_97-small/X_num_test.npy\n","data/classif-num-medium-2-kdd_ipums_la_97-small/Y_test.npy\n","data/classif-num-medium-2-kdd_ipums_la_97-small/Y_train.npy\n","data/classif-num-medium-0-phoneme/\n","data/classif-num-medium-0-phoneme/X_num_val.npy\n","data/classif-num-medium-0-phoneme/Y_val.npy\n","data/classif-num-medium-0-phoneme/X_num_train.npy\n","data/classif-num-medium-0-phoneme/info.json\n","data/classif-num-medium-0-phoneme/READY\n","data/classif-num-medium-0-phoneme/X_num_test.npy\n","data/classif-num-medium-0-phoneme/Y_test.npy\n","data/classif-num-medium-0-phoneme/Y_train.npy\n","data/regression-num-medium-0-sulfur/\n","data/regression-num-medium-0-sulfur/X_num_val.npy\n","data/regression-num-medium-0-sulfur/Y_val.npy\n","data/regression-num-medium-0-sulfur/X_num_train.npy\n","data/regression-num-medium-0-sulfur/info.json\n","data/regression-num-medium-0-sulfur/READY\n","data/regression-num-medium-0-sulfur/X_num_test.npy\n","data/regression-num-medium-0-sulfur/Y_test.npy\n","data/regression-num-medium-0-sulfur/Y_train.npy\n","data/regression-cat-medium-0-analcatdata_supreme/\n","data/regression-cat-medium-0-analcatdata_supreme/X_num_val.npy\n","data/regression-cat-medium-0-analcatdata_supreme/Y_val.npy\n","data/regression-cat-medium-0-analcatdata_supreme/X_bin_val.npy\n","data/regression-cat-medium-0-analcatdata_supreme/X_num_train.npy\n","data/regression-cat-medium-0-analcatdata_supreme/X_bin_train.npy\n","data/regression-cat-medium-0-analcatdata_supreme/info.json\n","data/regression-cat-medium-0-analcatdata_supreme/READY\n","data/regression-cat-medium-0-analcatdata_supreme/X_bin_test.npy\n","data/regression-cat-medium-0-analcatdata_supreme/X_num_test.npy\n","data/regression-cat-medium-0-analcatdata_supreme/Y_test.npy\n","data/regression-cat-medium-0-analcatdata_supreme/Y_train.npy\n","data/classif-num-medium-2-phoneme/\n","data/classif-num-medium-2-phoneme/X_num_val.npy\n","data/classif-num-medium-2-phoneme/Y_val.npy\n","data/classif-num-medium-2-phoneme/X_num_train.npy\n","data/classif-num-medium-2-phoneme/info.json\n","data/classif-num-medium-2-phoneme/READY\n","data/classif-num-medium-2-phoneme/X_num_test.npy\n","data/classif-num-medium-2-phoneme/Y_test.npy\n","data/classif-num-medium-2-phoneme/Y_train.npy\n","data/regression-cat-large-0-SGEMM_GPU_kernel_performance/\n","data/regression-cat-large-0-SGEMM_GPU_kernel_performance/X_num_val.npy\n","data/regression-cat-large-0-SGEMM_GPU_kernel_performance/Y_val.npy\n","data/regression-cat-large-0-SGEMM_GPU_kernel_performance/X_bin_val.npy\n","data/regression-cat-large-0-SGEMM_GPU_kernel_performance/X_num_train.npy\n","data/regression-cat-large-0-SGEMM_GPU_kernel_performance/X_bin_train.npy\n","data/regression-cat-large-0-SGEMM_GPU_kernel_performance/info.json\n","data/regression-cat-large-0-SGEMM_GPU_kernel_performance/READY\n","data/regression-cat-large-0-SGEMM_GPU_kernel_performance/X_bin_test.npy\n","data/regression-cat-large-0-SGEMM_GPU_kernel_performance/X_num_test.npy\n","data/regression-cat-large-0-SGEMM_GPU_kernel_performance/Y_test.npy\n","data/regression-cat-large-0-SGEMM_GPU_kernel_performance/Y_train.npy\n","data/regression-num-medium-1-wine_quality/\n","data/regression-num-medium-1-wine_quality/X_num_val.npy\n","data/regression-num-medium-1-wine_quality/Y_val.npy\n","data/regression-num-medium-1-wine_quality/X_num_train.npy\n","data/regression-num-medium-1-wine_quality/info.json\n","data/regression-num-medium-1-wine_quality/READY\n","data/regression-num-medium-1-wine_quality/X_num_test.npy\n","data/regression-num-medium-1-wine_quality/Y_test.npy\n","data/regression-num-medium-1-wine_quality/Y_train.npy\n","data/regression-num-medium-0-cpu_act/\n","data/regression-num-medium-0-cpu_act/X_num_val.npy\n","data/regression-num-medium-0-cpu_act/Y_val.npy\n","data/regression-num-medium-0-cpu_act/X_num_train.npy\n","data/regression-num-medium-0-cpu_act/info.json\n","data/regression-num-medium-0-cpu_act/READY\n","data/regression-num-medium-0-cpu_act/X_num_test.npy\n","data/regression-num-medium-0-cpu_act/Y_test.npy\n","data/regression-num-medium-0-cpu_act/Y_train.npy\n","data/regression-cat-medium-0-Bike_Sharing_Demand/\n","data/regression-cat-medium-0-Bike_Sharing_Demand/X_cat_val.npy\n","data/regression-cat-medium-0-Bike_Sharing_Demand/X_num_val.npy\n","data/regression-cat-medium-0-Bike_Sharing_Demand/Y_val.npy\n","data/regression-cat-medium-0-Bike_Sharing_Demand/X_bin_val.npy\n","data/regression-cat-medium-0-Bike_Sharing_Demand/X_num_train.npy\n","data/regression-cat-medium-0-Bike_Sharing_Demand/X_cat_test.npy\n","data/regression-cat-medium-0-Bike_Sharing_Demand/X_bin_train.npy\n","data/regression-cat-medium-0-Bike_Sharing_Demand/X_cat_train.npy\n","data/regression-cat-medium-0-Bike_Sharing_Demand/info.json\n","data/regression-cat-medium-0-Bike_Sharing_Demand/READY\n","data/regression-cat-medium-0-Bike_Sharing_Demand/X_bin_test.npy\n","data/regression-cat-medium-0-Bike_Sharing_Demand/X_num_test.npy\n","data/regression-cat-medium-0-Bike_Sharing_Demand/Y_test.npy\n","data/regression-cat-medium-0-Bike_Sharing_Demand/Y_train.npy\n","data/regression-cat-medium-1-visualizing_soil/\n","data/regression-cat-medium-1-visualizing_soil/X_num_val.npy\n","data/regression-cat-medium-1-visualizing_soil/Y_val.npy\n","data/regression-cat-medium-1-visualizing_soil/X_bin_val.npy\n","data/regression-cat-medium-1-visualizing_soil/X_num_train.npy\n","data/regression-cat-medium-1-visualizing_soil/X_bin_train.npy\n","data/regression-cat-medium-1-visualizing_soil/info.json\n","data/regression-cat-medium-1-visualizing_soil/READY\n","data/regression-cat-medium-1-visualizing_soil/X_bin_test.npy\n","data/regression-cat-medium-1-visualizing_soil/X_num_test.npy\n","data/regression-cat-medium-1-visualizing_soil/Y_test.npy\n","data/regression-cat-medium-1-visualizing_soil/Y_train.npy\n","data/classif-num-medium-4-phoneme/\n","data/classif-num-medium-4-phoneme/X_num_val.npy\n","data/classif-num-medium-4-phoneme/Y_val.npy\n","data/classif-num-medium-4-phoneme/X_num_train.npy\n","data/classif-num-medium-4-phoneme/info.json\n","data/classif-num-medium-4-phoneme/READY\n","data/classif-num-medium-4-phoneme/X_num_test.npy\n","data/classif-num-medium-4-phoneme/Y_test.npy\n","data/classif-num-medium-4-phoneme/Y_train.npy\n","data/house/\n","data/house/X_num_val.npy\n","data/house/Y_val.npy\n","data/house/X_num_train.npy\n","data/house/info.json\n","data/house/READY\n","data/house/X_num_test.npy\n","data/house/Y_test.npy\n","data/house/Y_train.npy\n","data/regression-cat-medium-2-Brazilian_houses/\n","data/regression-cat-medium-2-Brazilian_houses/X_cat_val.npy\n","data/regression-cat-medium-2-Brazilian_houses/X_num_val.npy\n","data/regression-cat-medium-2-Brazilian_houses/Y_val.npy\n","data/regression-cat-medium-2-Brazilian_houses/X_bin_val.npy\n","data/regression-cat-medium-2-Brazilian_houses/X_num_train.npy\n","data/regression-cat-medium-2-Brazilian_houses/X_cat_test.npy\n","data/regression-cat-medium-2-Brazilian_houses/X_bin_train.npy\n","data/regression-cat-medium-2-Brazilian_houses/X_cat_train.npy\n","data/regression-cat-medium-2-Brazilian_houses/info.json\n","data/regression-cat-medium-2-Brazilian_houses/READY\n","data/regression-cat-medium-2-Brazilian_houses/X_bin_test.npy\n","data/regression-cat-medium-2-Brazilian_houses/X_num_test.npy\n","data/regression-cat-medium-2-Brazilian_houses/Y_test.npy\n","data/regression-cat-medium-2-Brazilian_houses/Y_train.npy\n","data/regression-cat-large-0-particulate-matter-ukair-2017/\n","data/regression-cat-large-0-particulate-matter-ukair-2017/X_cat_val.npy\n","data/regression-cat-large-0-particulate-matter-ukair-2017/X_num_val.npy\n","data/regression-cat-large-0-particulate-matter-ukair-2017/Y_val.npy\n","data/regression-cat-large-0-particulate-matter-ukair-2017/X_num_train.npy\n","data/regression-cat-large-0-particulate-matter-ukair-2017/X_cat_test.npy\n","data/regression-cat-large-0-particulate-matter-ukair-2017/X_cat_train.npy\n","data/regression-cat-large-0-particulate-matter-ukair-2017/info.json\n","data/regression-cat-large-0-particulate-matter-ukair-2017/READY\n","data/regression-cat-large-0-particulate-matter-ukair-2017/X_num_test.npy\n","data/regression-cat-large-0-particulate-matter-ukair-2017/Y_test.npy\n","data/regression-cat-large-0-particulate-matter-ukair-2017/Y_train.npy\n","data/regression-cat-medium-2-Mercedes_Benz_Greener_Manufacturing/\n","data/regression-cat-medium-2-Mercedes_Benz_Greener_Manufacturing/X_cat_val.npy\n","data/regression-cat-medium-2-Mercedes_Benz_Greener_Manufacturing/Y_val.npy\n","data/regression-cat-medium-2-Mercedes_Benz_Greener_Manufacturing/X_bin_val.npy\n","data/regression-cat-medium-2-Mercedes_Benz_Greener_Manufacturing/X_cat_test.npy\n","data/regression-cat-medium-2-Mercedes_Benz_Greener_Manufacturing/X_bin_train.npy\n","data/regression-cat-medium-2-Mercedes_Benz_Greener_Manufacturing/X_cat_train.npy\n","data/regression-cat-medium-2-Mercedes_Benz_Greener_Manufacturing/info.json\n","data/regression-cat-medium-2-Mercedes_Benz_Greener_Manufacturing/READY\n","data/regression-cat-medium-2-Mercedes_Benz_Greener_Manufacturing/X_bin_test.npy\n","data/regression-cat-medium-2-Mercedes_Benz_Greener_Manufacturing/Y_test.npy\n","data/regression-cat-medium-2-Mercedes_Benz_Greener_Manufacturing/Y_train.npy\n","data/black-friday/\n","data/black-friday/X_cat_val.npy\n","data/black-friday/X_num_val.npy\n","data/black-friday/Y_val.npy\n","data/black-friday/X_bin_val.npy\n","data/black-friday/X_num_train.npy\n","data/black-friday/X_cat_test.npy\n","data/black-friday/X_bin_train.npy\n","data/black-friday/X_cat_train.npy\n","data/black-friday/info.json\n","data/black-friday/X_bin_test.npy\n","data/black-friday/X_num_test.npy\n","data/black-friday/Y_test.npy\n","data/black-friday/Y_train.npy\n","data/regression-num-medium-1-sulfur/\n","data/regression-num-medium-1-sulfur/X_num_val.npy\n","data/regression-num-medium-1-sulfur/Y_val.npy\n","data/regression-num-medium-1-sulfur/X_num_train.npy\n","data/regression-num-medium-1-sulfur/info.json\n","data/regression-num-medium-1-sulfur/READY\n","data/regression-num-medium-1-sulfur/X_num_test.npy\n","data/regression-num-medium-1-sulfur/Y_test.npy\n","data/regression-num-medium-1-sulfur/Y_train.npy\n","data/classif-num-medium-0-wine/\n","data/classif-num-medium-0-wine/X_num_val.npy\n","data/classif-num-medium-0-wine/Y_val.npy\n","data/classif-num-medium-0-wine/X_num_train.npy\n","data/classif-num-medium-0-wine/info.json\n","data/classif-num-medium-0-wine/READY\n","data/classif-num-medium-0-wine/X_num_test.npy\n","data/classif-num-medium-0-wine/Y_test.npy\n","data/classif-num-medium-0-wine/Y_train.npy\n","data/covtype/\n","data/covtype/X_num_val.npy\n","data/covtype/Y_val.npy\n","data/covtype/X_bin_val.npy\n","data/covtype/X_num_train.npy\n","data/covtype/X_bin_train.npy\n","data/covtype/info.json\n","data/covtype/READY\n","data/covtype/X_bin_test.npy\n","data/covtype/X_num_test.npy\n","data/covtype/Y_test.npy\n","data/covtype/Y_train.npy\n","data/regression-cat-large-0-nyc-taxi-green-dec-2016/\n","data/regression-cat-large-0-nyc-taxi-green-dec-2016/X_cat_val.npy\n","data/regression-cat-large-0-nyc-taxi-green-dec-2016/X_num_val.npy\n","data/regression-cat-large-0-nyc-taxi-green-dec-2016/Y_val.npy\n","data/regression-cat-large-0-nyc-taxi-green-dec-2016/X_bin_val.npy\n","data/regression-cat-large-0-nyc-taxi-green-dec-2016/X_num_train.npy\n","data/regression-cat-large-0-nyc-taxi-green-dec-2016/X_cat_test.npy\n","data/regression-cat-large-0-nyc-taxi-green-dec-2016/X_bin_train.npy\n","data/regression-cat-large-0-nyc-taxi-green-dec-2016/X_cat_train.npy\n","data/regression-cat-large-0-nyc-taxi-green-dec-2016/info.json\n","data/regression-cat-large-0-nyc-taxi-green-dec-2016/READY\n","data/regression-cat-large-0-nyc-taxi-green-dec-2016/X_bin_test.npy\n","data/regression-cat-large-0-nyc-taxi-green-dec-2016/X_num_test.npy\n","data/regression-cat-large-0-nyc-taxi-green-dec-2016/Y_test.npy\n","data/regression-cat-large-0-nyc-taxi-green-dec-2016/Y_train.npy\n","data/classif-num-medium-0-MagicTelescope/\n","data/classif-num-medium-0-MagicTelescope/X_num_val.npy\n","data/classif-num-medium-0-MagicTelescope/Y_val.npy\n","data/classif-num-medium-0-MagicTelescope/X_num_train.npy\n","data/classif-num-medium-0-MagicTelescope/info.json\n","data/classif-num-medium-0-MagicTelescope/READY\n","data/classif-num-medium-0-MagicTelescope/X_num_test.npy\n","data/classif-num-medium-0-MagicTelescope/Y_test.npy\n","data/classif-num-medium-0-MagicTelescope/Y_train.npy\n","data/regression-cat-medium-3-analcatdata_supreme/\n","data/regression-cat-medium-3-analcatdata_supreme/X_num_val.npy\n","data/regression-cat-medium-3-analcatdata_supreme/Y_val.npy\n","data/regression-cat-medium-3-analcatdata_supreme/X_bin_val.npy\n","data/regression-cat-medium-3-analcatdata_supreme/X_num_train.npy\n","data/regression-cat-medium-3-analcatdata_supreme/X_bin_train.npy\n","data/regression-cat-medium-3-analcatdata_supreme/info.json\n","data/regression-cat-medium-3-analcatdata_supreme/READY\n","data/regression-cat-medium-3-analcatdata_supreme/X_bin_test.npy\n","data/regression-cat-medium-3-analcatdata_supreme/X_num_test.npy\n","data/regression-cat-medium-3-analcatdata_supreme/Y_test.npy\n","data/regression-cat-medium-3-analcatdata_supreme/Y_train.npy\n","data/regression-cat-medium-0-Mercedes_Benz_Greener_Manufacturing/\n","data/regression-cat-medium-0-Mercedes_Benz_Greener_Manufacturing/X_cat_val.npy\n","data/regression-cat-medium-0-Mercedes_Benz_Greener_Manufacturing/Y_val.npy\n","data/regression-cat-medium-0-Mercedes_Benz_Greener_Manufacturing/X_bin_val.npy\n","data/regression-cat-medium-0-Mercedes_Benz_Greener_Manufacturing/X_cat_test.npy\n","data/regression-cat-medium-0-Mercedes_Benz_Greener_Manufacturing/X_bin_train.npy\n","data/regression-cat-medium-0-Mercedes_Benz_Greener_Manufacturing/X_cat_train.npy\n","data/regression-cat-medium-0-Mercedes_Benz_Greener_Manufacturing/info.json\n","data/regression-cat-medium-0-Mercedes_Benz_Greener_Manufacturing/READY\n","data/regression-cat-medium-0-Mercedes_Benz_Greener_Manufacturing/X_bin_test.npy\n","data/regression-cat-medium-0-Mercedes_Benz_Greener_Manufacturing/Y_test.npy\n","data/regression-cat-medium-0-Mercedes_Benz_Greener_Manufacturing/Y_train.npy\n","data/microsoft/\n","data/microsoft/X_num_val.npy\n","data/microsoft/Y_val.npy\n","data/microsoft/X_bin_val.npy\n","data/microsoft/X_num_train.npy\n","data/microsoft/X_bin_train.npy\n","data/microsoft/info.json\n","data/microsoft/READY\n","data/microsoft/X_bin_test.npy\n","data/microsoft/X_num_test.npy\n","data/microsoft/Y_test.npy\n","data/microsoft/Y_train.npy\n","data/regression-cat-medium-4-analcatdata_supreme/\n","data/regression-cat-medium-4-analcatdata_supreme/X_num_val.npy\n","data/regression-cat-medium-4-analcatdata_supreme/Y_val.npy\n","data/regression-cat-medium-4-analcatdata_supreme/X_bin_val.npy\n","data/regression-cat-medium-4-analcatdata_supreme/X_num_train.npy\n","data/regression-cat-medium-4-analcatdata_supreme/X_bin_train.npy\n","data/regression-cat-medium-4-analcatdata_supreme/info.json\n","data/regression-cat-medium-4-analcatdata_supreme/READY\n","data/regression-cat-medium-4-analcatdata_supreme/X_bin_test.npy\n","data/regression-cat-medium-4-analcatdata_supreme/X_num_test.npy\n","data/regression-cat-medium-4-analcatdata_supreme/Y_test.npy\n","data/regression-cat-medium-4-analcatdata_supreme/Y_train.npy\n","data/regression-num-medium-1-fifa/\n","data/regression-num-medium-1-fifa/X_num_val.npy\n","data/regression-num-medium-1-fifa/Y_val.npy\n","data/regression-num-medium-1-fifa/X_num_train.npy\n","data/regression-num-medium-1-fifa/info.json\n","data/regression-num-medium-1-fifa/READY\n","data/regression-num-medium-1-fifa/X_num_test.npy\n","data/regression-num-medium-1-fifa/Y_test.npy\n","data/regression-num-medium-1-fifa/Y_train.npy\n","data/regression-num-medium-0-isolet/\n","data/regression-num-medium-0-isolet/X_num_val.npy\n","data/regression-num-medium-0-isolet/Y_val.npy\n","data/regression-num-medium-0-isolet/X_num_train.npy\n","data/regression-num-medium-0-isolet/info.json\n","data/regression-num-medium-0-isolet/READY\n","data/regression-num-medium-0-isolet/X_num_test.npy\n","data/regression-num-medium-0-isolet/Y_test.npy\n","data/regression-num-medium-0-isolet/Y_train.npy\n","data/classif-num-medium-3-phoneme/\n","data/classif-num-medium-3-phoneme/X_num_val.npy\n","data/classif-num-medium-3-phoneme/Y_val.npy\n","data/classif-num-medium-3-phoneme/X_num_train.npy\n","data/classif-num-medium-3-phoneme/info.json\n","data/classif-num-medium-3-phoneme/READY\n","data/classif-num-medium-3-phoneme/X_num_test.npy\n","data/classif-num-medium-3-phoneme/Y_test.npy\n","data/classif-num-medium-3-phoneme/Y_train.npy\n","data/regression-cat-medium-3-Mercedes_Benz_Greener_Manufacturing/\n","data/regression-cat-medium-3-Mercedes_Benz_Greener_Manufacturing/X_cat_val.npy\n","data/regression-cat-medium-3-Mercedes_Benz_Greener_Manufacturing/Y_val.npy\n","data/regression-cat-medium-3-Mercedes_Benz_Greener_Manufacturing/X_bin_val.npy\n","data/regression-cat-medium-3-Mercedes_Benz_Greener_Manufacturing/X_cat_test.npy\n","data/regression-cat-medium-3-Mercedes_Benz_Greener_Manufacturing/X_bin_train.npy\n","data/regression-cat-medium-3-Mercedes_Benz_Greener_Manufacturing/X_cat_train.npy\n","data/regression-cat-medium-3-Mercedes_Benz_Greener_Manufacturing/info.json\n","data/regression-cat-medium-3-Mercedes_Benz_Greener_Manufacturing/READY\n","data/regression-cat-medium-3-Mercedes_Benz_Greener_Manufacturing/X_bin_test.npy\n","data/regression-cat-medium-3-Mercedes_Benz_Greener_Manufacturing/Y_test.npy\n","data/regression-cat-medium-3-Mercedes_Benz_Greener_Manufacturing/Y_train.npy\n","data/california/\n","data/california/X_num_val.npy\n","data/california/Y_val.npy\n","data/california/X_num_train.npy\n","data/california/info.json\n","data/california/READY\n","data/california/X_num_test.npy\n","data/california/Y_test.npy\n","data/california/Y_train.npy\n","data/classif-cat-medium-2-rl/\n","data/classif-cat-medium-2-rl/X_cat_val.npy\n","data/classif-cat-medium-2-rl/X_num_val.npy\n","data/classif-cat-medium-2-rl/Y_val.npy\n","data/classif-cat-medium-2-rl/X_bin_val.npy\n","data/classif-cat-medium-2-rl/X_num_train.npy\n","data/classif-cat-medium-2-rl/X_cat_test.npy\n","data/classif-cat-medium-2-rl/X_bin_train.npy\n","data/classif-cat-medium-2-rl/X_cat_train.npy\n","data/classif-cat-medium-2-rl/info.json\n","data/classif-cat-medium-2-rl/READY\n","data/classif-cat-medium-2-rl/X_bin_test.npy\n","data/classif-cat-medium-2-rl/X_num_test.npy\n","data/classif-cat-medium-2-rl/Y_test.npy\n","data/classif-cat-medium-2-rl/Y_train.npy\n","data/regression-cat-medium-0-Brazilian_houses/\n","data/regression-cat-medium-0-Brazilian_houses/X_cat_val.npy\n","data/regression-cat-medium-0-Brazilian_houses/X_num_val.npy\n","data/regression-cat-medium-0-Brazilian_houses/Y_val.npy\n","data/regression-cat-medium-0-Brazilian_houses/X_bin_val.npy\n","data/regression-cat-medium-0-Brazilian_houses/X_num_train.npy\n","data/regression-cat-medium-0-Brazilian_houses/X_cat_test.npy\n","data/regression-cat-medium-0-Brazilian_houses/X_bin_train.npy\n","data/regression-cat-medium-0-Brazilian_houses/X_cat_train.npy\n","data/regression-cat-medium-0-Brazilian_houses/info.json\n","data/regression-cat-medium-0-Brazilian_houses/READY\n","data/regression-cat-medium-0-Brazilian_houses/X_bin_test.npy\n","data/regression-cat-medium-0-Brazilian_houses/X_num_test.npy\n","data/regression-cat-medium-0-Brazilian_houses/Y_test.npy\n","data/regression-cat-medium-0-Brazilian_houses/Y_train.npy\n","data/regression-cat-medium-1-analcatdata_supreme/\n","data/regression-cat-medium-1-analcatdata_supreme/X_num_val.npy\n","data/regression-cat-medium-1-analcatdata_supreme/Y_val.npy\n","data/regression-cat-medium-1-analcatdata_supreme/X_bin_val.npy\n","data/regression-cat-medium-1-analcatdata_supreme/X_num_train.npy\n","data/regression-cat-medium-1-analcatdata_supreme/X_bin_train.npy\n","data/regression-cat-medium-1-analcatdata_supreme/info.json\n","data/regression-cat-medium-1-analcatdata_supreme/READY\n","data/regression-cat-medium-1-analcatdata_supreme/X_bin_test.npy\n","data/regression-cat-medium-1-analcatdata_supreme/X_num_test.npy\n","data/regression-cat-medium-1-analcatdata_supreme/Y_test.npy\n","data/regression-cat-medium-1-analcatdata_supreme/Y_train.npy\n","data/classif-num-medium-2-MagicTelescope/\n","data/classif-num-medium-2-MagicTelescope/X_num_val.npy\n","data/classif-num-medium-2-MagicTelescope/Y_val.npy\n","data/classif-num-medium-2-MagicTelescope/X_num_train.npy\n","data/classif-num-medium-2-MagicTelescope/info.json\n","data/classif-num-medium-2-MagicTelescope/READY\n","data/classif-num-medium-2-MagicTelescope/X_num_test.npy\n","data/classif-num-medium-2-MagicTelescope/Y_test.npy\n","data/classif-num-medium-2-MagicTelescope/Y_train.npy\n","data/classif-cat-medium-1-rl/\n","data/classif-cat-medium-1-rl/X_cat_val.npy\n","data/classif-cat-medium-1-rl/X_num_val.npy\n","data/classif-cat-medium-1-rl/Y_val.npy\n","data/classif-cat-medium-1-rl/X_bin_val.npy\n","data/classif-cat-medium-1-rl/X_num_train.npy\n","data/classif-cat-medium-1-rl/X_cat_test.npy\n","data/classif-cat-medium-1-rl/X_bin_train.npy\n","data/classif-cat-medium-1-rl/X_cat_train.npy\n","data/classif-cat-medium-1-rl/info.json\n","data/classif-cat-medium-1-rl/READY\n","data/classif-cat-medium-1-rl/X_bin_test.npy\n","data/classif-cat-medium-1-rl/X_num_test.npy\n","data/classif-cat-medium-1-rl/Y_test.npy\n","data/classif-cat-medium-1-rl/Y_train.npy\n","data/classif-cat-medium-0-compass/\n","data/classif-cat-medium-0-compass/X_cat_val.npy\n","data/classif-cat-medium-0-compass/X_num_val.npy\n","data/classif-cat-medium-0-compass/Y_val.npy\n","data/classif-cat-medium-0-compass/X_bin_val.npy\n","data/classif-cat-medium-0-compass/X_num_train.npy\n","data/classif-cat-medium-0-compass/X_cat_test.npy\n","data/classif-cat-medium-0-compass/X_bin_train.npy\n","data/classif-cat-medium-0-compass/X_cat_train.npy\n","data/classif-cat-medium-0-compass/info.json\n","data/classif-cat-medium-0-compass/READY\n","data/classif-cat-medium-0-compass/X_bin_test.npy\n","data/classif-cat-medium-0-compass/X_num_test.npy\n","data/classif-cat-medium-0-compass/Y_test.npy\n","data/classif-cat-medium-0-compass/Y_train.npy\n","data/regression-cat-medium-2-yprop_4_1/\n","data/regression-cat-medium-2-yprop_4_1/X_num_val.npy\n","data/regression-cat-medium-2-yprop_4_1/Y_val.npy\n","data/regression-cat-medium-2-yprop_4_1/X_bin_val.npy\n","data/regression-cat-medium-2-yprop_4_1/X_num_train.npy\n","data/regression-cat-medium-2-yprop_4_1/X_bin_train.npy\n","data/regression-cat-medium-2-yprop_4_1/info.json\n","data/regression-cat-medium-2-yprop_4_1/READY\n","data/regression-cat-medium-2-yprop_4_1/X_bin_test.npy\n","data/regression-cat-medium-2-yprop_4_1/X_num_test.npy\n","data/regression-cat-medium-2-yprop_4_1/Y_test.npy\n","data/regression-cat-medium-2-yprop_4_1/Y_train.npy\n","data/weather-small/\n","data/weather-small/X_num_val.npy\n","data/weather-small/Y_val.npy\n","data/weather-small/X_bin_val.npy\n","data/weather-small/X_num_train.npy\n","data/weather-small/X_bin_train.npy\n","data/weather-small/info.json\n","data/weather-small/READY\n","data/weather-small/X_bin_test.npy\n","data/weather-small/X_num_test.npy\n","data/weather-small/Y_test.npy\n","data/weather-small/Y_train.npy\n","data/diamond/\n","data/diamond/X_cat_val.npy\n","data/diamond/X_num_val.npy\n","data/diamond/Y_val.npy\n","data/diamond/X_num_train.npy\n","data/diamond/X_cat_test.npy\n","data/diamond/X_cat_train.npy\n","data/diamond/info.json\n","data/diamond/X_num_test.npy\n","data/diamond/Y_test.npy\n","data/diamond/Y_train.npy\n","data/regression-num-medium-0-fifa/\n","data/regression-num-medium-0-fifa/X_num_val.npy\n","data/regression-num-medium-0-fifa/Y_val.npy\n","data/regression-num-medium-0-fifa/X_num_train.npy\n","data/regression-num-medium-0-fifa/info.json\n","data/regression-num-medium-0-fifa/READY\n","data/regression-num-medium-0-fifa/X_num_test.npy\n","data/regression-num-medium-0-fifa/Y_test.npy\n","data/regression-num-medium-0-fifa/Y_train.npy\n","data/regression-num-medium-1-cpu_act/\n","data/regression-num-medium-1-cpu_act/X_num_val.npy\n","data/regression-num-medium-1-cpu_act/Y_val.npy\n","data/regression-num-medium-1-cpu_act/X_num_train.npy\n","data/regression-num-medium-1-cpu_act/info.json\n","data/regression-num-medium-1-cpu_act/READY\n","data/regression-num-medium-1-cpu_act/X_num_test.npy\n","data/regression-num-medium-1-cpu_act/Y_test.npy\n","data/regression-num-medium-1-cpu_act/Y_train.npy\n","data/regression-num-medium-1-pol/\n","data/regression-num-medium-1-pol/X_num_val.npy\n","data/regression-num-medium-1-pol/Y_val.npy\n","data/regression-num-medium-1-pol/X_num_train.npy\n","data/regression-num-medium-1-pol/info.json\n","data/regression-num-medium-1-pol/READY\n","data/regression-num-medium-1-pol/X_num_test.npy\n","data/regression-num-medium-1-pol/Y_test.npy\n","data/regression-num-medium-1-pol/Y_train.npy\n","data/regression-num-medium-0-elevators/\n","data/regression-num-medium-0-elevators/X_num_val.npy\n","data/regression-num-medium-0-elevators/Y_val.npy\n","data/regression-num-medium-0-elevators/X_num_train.npy\n","data/regression-num-medium-0-elevators/info.json\n","data/regression-num-medium-0-elevators/READY\n","data/regression-num-medium-0-elevators/X_num_test.npy\n","data/regression-num-medium-0-elevators/Y_test.npy\n","data/regression-num-medium-0-elevators/Y_train.npy\n","data/regression-cat-medium-4-Mercedes_Benz_Greener_Manufacturing/\n","data/regression-cat-medium-4-Mercedes_Benz_Greener_Manufacturing/X_cat_val.npy\n","data/regression-cat-medium-4-Mercedes_Benz_Greener_Manufacturing/Y_val.npy\n","data/regression-cat-medium-4-Mercedes_Benz_Greener_Manufacturing/X_bin_val.npy\n","data/regression-cat-medium-4-Mercedes_Benz_Greener_Manufacturing/X_cat_test.npy\n","data/regression-cat-medium-4-Mercedes_Benz_Greener_Manufacturing/X_bin_train.npy\n","data/regression-cat-medium-4-Mercedes_Benz_Greener_Manufacturing/X_cat_train.npy\n","data/regression-cat-medium-4-Mercedes_Benz_Greener_Manufacturing/info.json\n","data/regression-cat-medium-4-Mercedes_Benz_Greener_Manufacturing/READY\n","data/regression-cat-medium-4-Mercedes_Benz_Greener_Manufacturing/X_bin_test.npy\n","data/regression-cat-medium-4-Mercedes_Benz_Greener_Manufacturing/Y_test.npy\n","data/regression-cat-medium-4-Mercedes_Benz_Greener_Manufacturing/Y_train.npy\n","data/regression-num-medium-2-MiamiHousing2016/\n","data/regression-num-medium-2-MiamiHousing2016/X_num_val.npy\n","data/regression-num-medium-2-MiamiHousing2016/Y_val.npy\n","data/regression-num-medium-2-MiamiHousing2016/X_num_train.npy\n","data/regression-num-medium-2-MiamiHousing2016/info.json\n","data/regression-num-medium-2-MiamiHousing2016/READY\n","data/regression-num-medium-2-MiamiHousing2016/X_num_test.npy\n","data/regression-num-medium-2-MiamiHousing2016/Y_test.npy\n","data/regression-num-medium-2-MiamiHousing2016/Y_train.npy\n","data/regression-num-medium-1-Ailerons/\n","data/regression-num-medium-1-Ailerons/X_num_val.npy\n","data/regression-num-medium-1-Ailerons/Y_val.npy\n","data/regression-num-medium-1-Ailerons/X_num_train.npy\n","data/regression-num-medium-1-Ailerons/info.json\n","data/regression-num-medium-1-Ailerons/READY\n","data/regression-num-medium-1-Ailerons/X_num_test.npy\n","data/regression-num-medium-1-Ailerons/Y_test.npy\n","data/regression-num-medium-1-Ailerons/Y_train.npy\n","data/regression-num-medium-0-medical_charges/\n","data/regression-num-medium-0-medical_charges/X_num_val.npy\n","data/regression-num-medium-0-medical_charges/Y_val.npy\n","data/regression-num-medium-0-medical_charges/X_num_train.npy\n","data/regression-num-medium-0-medical_charges/info.json\n","data/regression-num-medium-0-medical_charges/READY\n","data/regression-num-medium-0-medical_charges/X_num_test.npy\n","data/regression-num-medium-0-medical_charges/Y_test.npy\n","data/regression-num-medium-0-medical_charges/Y_train.npy\n","data/classif-num-medium-0-bank-marketing/\n","data/classif-num-medium-0-bank-marketing/X_num_val.npy\n","data/classif-num-medium-0-bank-marketing/Y_val.npy\n","data/classif-num-medium-0-bank-marketing/X_num_train.npy\n","data/classif-num-medium-0-bank-marketing/info.json\n","data/classif-num-medium-0-bank-marketing/READY\n","data/classif-num-medium-0-bank-marketing/X_num_test.npy\n","data/classif-num-medium-0-bank-marketing/Y_test.npy\n","data/classif-num-medium-0-bank-marketing/Y_train.npy\n","data/classif-num-medium-3-wine/\n","data/classif-num-medium-3-wine/X_num_val.npy\n","data/classif-num-medium-3-wine/Y_val.npy\n","data/classif-num-medium-3-wine/X_num_train.npy\n","data/classif-num-medium-3-wine/info.json\n","data/classif-num-medium-3-wine/READY\n","data/classif-num-medium-3-wine/X_num_test.npy\n","data/classif-num-medium-3-wine/Y_test.npy\n","data/classif-num-medium-3-wine/Y_train.npy\n","data/classif-num-medium-2-bank-marketing/\n","data/classif-num-medium-2-bank-marketing/X_num_val.npy\n","data/classif-num-medium-2-bank-marketing/Y_val.npy\n","data/classif-num-medium-2-bank-marketing/X_num_train.npy\n","data/classif-num-medium-2-bank-marketing/info.json\n","data/classif-num-medium-2-bank-marketing/READY\n","data/classif-num-medium-2-bank-marketing/X_num_test.npy\n","data/classif-num-medium-2-bank-marketing/Y_test.npy\n","data/classif-num-medium-2-bank-marketing/Y_train.npy\n","data/classif-num-large-0-jannis/\n","data/classif-num-large-0-jannis/X_num_val.npy\n","data/classif-num-large-0-jannis/Y_val.npy\n","data/classif-num-large-0-jannis/X_num_train.npy\n","data/classif-num-large-0-jannis/info.json\n","data/classif-num-large-0-jannis/READY\n","data/classif-num-large-0-jannis/X_num_test.npy\n","data/classif-num-large-0-jannis/Y_test.npy\n","data/classif-num-large-0-jannis/Y_train.npy\n","data/regression-num-medium-0-houses/\n","data/regression-num-medium-0-houses/X_num_val.npy\n","data/regression-num-medium-0-houses/Y_val.npy\n","data/regression-num-medium-0-houses/X_num_train.npy\n","data/regression-num-medium-0-houses/info.json\n","data/regression-num-medium-0-houses/READY\n","data/regression-num-medium-0-houses/X_num_test.npy\n","data/regression-num-medium-0-houses/Y_test.npy\n","data/regression-num-medium-0-houses/Y_train.npy\n","data/regression-num-large-0-year/\n","data/regression-num-large-0-year/X_num_val.npy\n","data/regression-num-large-0-year/Y_val.npy\n","data/regression-num-large-0-year/X_num_train.npy\n","data/regression-num-large-0-year/info.json\n","data/regression-num-large-0-year/READY\n","data/regression-num-large-0-year/X_num_test.npy\n","data/regression-num-large-0-year/Y_test.npy\n","data/regression-num-large-0-year/Y_train.npy\n","data/classif-cat-medium-1-KDDCup09_upselling/\n","data/classif-cat-medium-1-KDDCup09_upselling/X_cat_val.npy\n","data/classif-cat-medium-1-KDDCup09_upselling/X_num_val.npy\n","data/classif-cat-medium-1-KDDCup09_upselling/Y_val.npy\n","data/classif-cat-medium-1-KDDCup09_upselling/X_bin_val.npy\n","data/classif-cat-medium-1-KDDCup09_upselling/X_num_train.npy\n","data/classif-cat-medium-1-KDDCup09_upselling/X_cat_test.npy\n","data/classif-cat-medium-1-KDDCup09_upselling/X_bin_train.npy\n","data/classif-cat-medium-1-KDDCup09_upselling/X_cat_train.npy\n","data/classif-cat-medium-1-KDDCup09_upselling/info.json\n","data/classif-cat-medium-1-KDDCup09_upselling/READY\n","data/classif-cat-medium-1-KDDCup09_upselling/X_bin_test.npy\n","data/classif-cat-medium-1-KDDCup09_upselling/X_num_test.npy\n","data/classif-cat-medium-1-KDDCup09_upselling/Y_test.npy\n","data/classif-cat-medium-1-KDDCup09_upselling/Y_train.npy\n","data/classif-cat-medium-0-KDDCup09_upselling/\n","data/classif-cat-medium-0-KDDCup09_upselling/X_cat_val.npy\n","data/classif-cat-medium-0-KDDCup09_upselling/X_num_val.npy\n","data/classif-cat-medium-0-KDDCup09_upselling/Y_val.npy\n","data/classif-cat-medium-0-KDDCup09_upselling/X_bin_val.npy\n","data/classif-cat-medium-0-KDDCup09_upselling/X_num_train.npy\n","data/classif-cat-medium-0-KDDCup09_upselling/X_cat_test.npy\n","data/classif-cat-medium-0-KDDCup09_upselling/X_bin_train.npy\n","data/classif-cat-medium-0-KDDCup09_upselling/X_cat_train.npy\n","data/classif-cat-medium-0-KDDCup09_upselling/info.json\n","data/classif-cat-medium-0-KDDCup09_upselling/READY\n","data/classif-cat-medium-0-KDDCup09_upselling/X_bin_test.npy\n","data/classif-cat-medium-0-KDDCup09_upselling/X_num_test.npy\n","data/classif-cat-medium-0-KDDCup09_upselling/Y_test.npy\n","data/classif-cat-medium-0-KDDCup09_upselling/Y_train.npy\n","data/classif-num-large-0-MiniBooNE/\n","data/classif-num-large-0-MiniBooNE/X_num_val.npy\n","data/classif-num-large-0-MiniBooNE/Y_val.npy\n","data/classif-num-large-0-MiniBooNE/X_num_train.npy\n","data/classif-num-large-0-MiniBooNE/info.json\n","data/classif-num-large-0-MiniBooNE/READY\n","data/classif-num-large-0-MiniBooNE/X_num_test.npy\n","data/classif-num-large-0-MiniBooNE/Y_test.npy\n","data/classif-num-large-0-MiniBooNE/Y_train.npy\n","data/regression-num-medium-0-MiamiHousing2016/\n","data/regression-num-medium-0-MiamiHousing2016/X_num_val.npy\n","data/regression-num-medium-0-MiamiHousing2016/Y_val.npy\n","data/regression-num-medium-0-MiamiHousing2016/X_num_train.npy\n","data/regression-num-medium-0-MiamiHousing2016/info.json\n","data/regression-num-medium-0-MiamiHousing2016/READY\n","data/regression-num-medium-0-MiamiHousing2016/X_num_test.npy\n","data/regression-num-medium-0-MiamiHousing2016/Y_test.npy\n","data/regression-num-medium-0-MiamiHousing2016/Y_train.npy\n","data/regression-num-medium-2-Ailerons/\n","data/regression-num-medium-2-Ailerons/X_num_val.npy\n","data/regression-num-medium-2-Ailerons/Y_val.npy\n","data/regression-num-medium-2-Ailerons/X_num_train.npy\n","data/regression-num-medium-2-Ailerons/info.json\n","data/regression-num-medium-2-Ailerons/READY\n","data/regression-num-medium-2-Ailerons/X_num_test.npy\n","data/regression-num-medium-2-Ailerons/Y_test.npy\n","data/regression-num-medium-2-Ailerons/Y_train.npy\n","data/classif-num-medium-0-credit/\n","data/classif-num-medium-0-credit/X_num_val.npy\n","data/classif-num-medium-0-credit/Y_val.npy\n","data/classif-num-medium-0-credit/X_num_train.npy\n","data/classif-num-medium-0-credit/info.json\n","data/classif-num-medium-0-credit/READY\n","data/classif-num-medium-0-credit/X_num_test.npy\n","data/classif-num-medium-0-credit/Y_test.npy\n","data/classif-num-medium-0-credit/Y_train.npy\n","data/classif-num-medium-4-wine/\n","data/classif-num-medium-4-wine/X_num_val.npy\n","data/classif-num-medium-4-wine/Y_val.npy\n","data/classif-num-medium-4-wine/X_num_train.npy\n","data/classif-num-medium-4-wine/info.json\n","data/classif-num-medium-4-wine/READY\n","data/classif-num-medium-4-wine/X_num_test.npy\n","data/classif-num-medium-4-wine/Y_test.npy\n","data/classif-num-medium-4-wine/Y_train.npy\n","data/higgs-small/\n","data/higgs-small/X_num_val.npy\n","data/higgs-small/Y_val.npy\n","data/higgs-small/X_num_train.npy\n","data/higgs-small/info.json\n","data/higgs-small/READY\n","data/higgs-small/X_num_test.npy\n","data/higgs-small/Y_test.npy\n","data/higgs-small/Y_train.npy\n","data/classif-cat-medium-1-compass/\n","data/classif-cat-medium-1-compass/X_cat_val.npy\n","data/classif-cat-medium-1-compass/X_num_val.npy\n","data/classif-cat-medium-1-compass/Y_val.npy\n","data/classif-cat-medium-1-compass/X_bin_val.npy\n","data/classif-cat-medium-1-compass/X_num_train.npy\n","data/classif-cat-medium-1-compass/X_cat_test.npy\n","data/classif-cat-medium-1-compass/X_bin_train.npy\n","data/classif-cat-medium-1-compass/X_cat_train.npy\n","data/classif-cat-medium-1-compass/info.json\n","data/classif-cat-medium-1-compass/READY\n","data/classif-cat-medium-1-compass/X_bin_test.npy\n","data/classif-cat-medium-1-compass/X_num_test.npy\n","data/classif-cat-medium-1-compass/Y_test.npy\n","data/classif-cat-medium-1-compass/Y_train.npy\n","data/classif-cat-medium-0-rl/\n","data/classif-cat-medium-0-rl/X_cat_val.npy\n","data/classif-cat-medium-0-rl/X_num_val.npy\n","data/classif-cat-medium-0-rl/Y_val.npy\n","data/classif-cat-medium-0-rl/X_bin_val.npy\n","data/classif-cat-medium-0-rl/X_num_train.npy\n","data/classif-cat-medium-0-rl/X_cat_test.npy\n","data/classif-cat-medium-0-rl/X_bin_train.npy\n","data/classif-cat-medium-0-rl/X_cat_train.npy\n","data/classif-cat-medium-0-rl/info.json\n","data/classif-cat-medium-0-rl/READY\n","data/classif-cat-medium-0-rl/X_bin_test.npy\n","data/classif-cat-medium-0-rl/X_num_test.npy\n","data/classif-cat-medium-0-rl/Y_test.npy\n","data/classif-cat-medium-0-rl/Y_train.npy\n","data/regression-num-medium-2-cpu_act/\n","data/regression-num-medium-2-cpu_act/X_num_val.npy\n","data/regression-num-medium-2-cpu_act/Y_val.npy\n","data/regression-num-medium-2-cpu_act/X_num_train.npy\n","data/regression-num-medium-2-cpu_act/info.json\n","data/regression-num-medium-2-cpu_act/READY\n","data/regression-num-medium-2-cpu_act/X_num_test.npy\n","data/regression-num-medium-2-cpu_act/Y_test.npy\n","data/regression-num-medium-2-cpu_act/Y_train.npy\n","data/otto/\n","data/otto/X_num_val.npy\n","data/otto/Y_val.npy\n","data/otto/X_num_train.npy\n","data/otto/info.json\n","data/otto/READY\n","data/otto/X_num_test.npy\n","data/otto/Y_test.npy\n","data/otto/Y_train.npy\n","data/regression-cat-medium-0-yprop_4_1/\n","data/regression-cat-medium-0-yprop_4_1/X_num_val.npy\n","data/regression-cat-medium-0-yprop_4_1/Y_val.npy\n","data/regression-cat-medium-0-yprop_4_1/X_bin_val.npy\n","data/regression-cat-medium-0-yprop_4_1/X_num_train.npy\n","data/regression-cat-medium-0-yprop_4_1/X_bin_train.npy\n","data/regression-cat-medium-0-yprop_4_1/info.json\n","data/regression-cat-medium-0-yprop_4_1/READY\n","data/regression-cat-medium-0-yprop_4_1/X_bin_test.npy\n","data/regression-cat-medium-0-yprop_4_1/X_num_test.npy\n","data/regression-cat-medium-0-yprop_4_1/Y_test.npy\n","data/regression-cat-medium-0-yprop_4_1/Y_train.npy\n","data/classif-cat-large-0-covertype/\n","data/classif-cat-large-0-covertype/X_num_val.npy\n","data/classif-cat-large-0-covertype/Y_val.npy\n","data/classif-cat-large-0-covertype/X_bin_val.npy\n","data/classif-cat-large-0-covertype/X_num_train.npy\n","data/classif-cat-large-0-covertype/X_bin_train.npy\n","data/classif-cat-large-0-covertype/info.json\n","data/classif-cat-large-0-covertype/READY\n","data/classif-cat-large-0-covertype/X_bin_test.npy\n","data/classif-cat-large-0-covertype/X_num_test.npy\n","data/classif-cat-large-0-covertype/Y_test.npy\n","data/classif-cat-large-0-covertype/Y_train.npy\n","data/regression-cat-medium-1-Bike_Sharing_Demand/\n","data/regression-cat-medium-1-Bike_Sharing_Demand/X_cat_val.npy\n","data/regression-cat-medium-1-Bike_Sharing_Demand/X_num_val.npy\n","data/regression-cat-medium-1-Bike_Sharing_Demand/Y_val.npy\n","data/regression-cat-medium-1-Bike_Sharing_Demand/X_bin_val.npy\n","data/regression-cat-medium-1-Bike_Sharing_Demand/X_num_train.npy\n","data/regression-cat-medium-1-Bike_Sharing_Demand/X_cat_test.npy\n","data/regression-cat-medium-1-Bike_Sharing_Demand/X_bin_train.npy\n","data/regression-cat-medium-1-Bike_Sharing_Demand/X_cat_train.npy\n","data/regression-cat-medium-1-Bike_Sharing_Demand/info.json\n","data/regression-cat-medium-1-Bike_Sharing_Demand/READY\n","data/regression-cat-medium-1-Bike_Sharing_Demand/X_bin_test.npy\n","data/regression-cat-medium-1-Bike_Sharing_Demand/X_num_test.npy\n","data/regression-cat-medium-1-Bike_Sharing_Demand/Y_test.npy\n","data/regression-cat-medium-1-Bike_Sharing_Demand/Y_train.npy\n","data/classif-cat-medium-0-electricity/\n","data/classif-cat-medium-0-electricity/X_cat_val.npy\n","data/classif-cat-medium-0-electricity/X_num_val.npy\n","data/classif-cat-medium-0-electricity/Y_val.npy\n","data/classif-cat-medium-0-electricity/X_num_train.npy\n","data/classif-cat-medium-0-electricity/X_cat_test.npy\n","data/classif-cat-medium-0-electricity/X_cat_train.npy\n","data/classif-cat-medium-0-electricity/info.json\n","data/classif-cat-medium-0-electricity/READY\n","data/classif-cat-medium-0-electricity/X_num_test.npy\n","data/classif-cat-medium-0-electricity/Y_test.npy\n","data/classif-cat-medium-0-electricity/Y_train.npy\n","data/regression-cat-medium-2-visualizing_soil/\n","data/regression-cat-medium-2-visualizing_soil/X_num_val.npy\n","data/regression-cat-medium-2-visualizing_soil/Y_val.npy\n","data/regression-cat-medium-2-visualizing_soil/X_bin_val.npy\n","data/regression-cat-medium-2-visualizing_soil/X_num_train.npy\n","data/regression-cat-medium-2-visualizing_soil/X_bin_train.npy\n","data/regression-cat-medium-2-visualizing_soil/info.json\n","data/regression-cat-medium-2-visualizing_soil/READY\n","data/regression-cat-medium-2-visualizing_soil/X_bin_test.npy\n","data/regression-cat-medium-2-visualizing_soil/X_num_test.npy\n","data/regression-cat-medium-2-visualizing_soil/Y_test.npy\n","data/regression-cat-medium-2-visualizing_soil/Y_train.npy\n","data/regression-cat-medium-1-yprop_4_1/\n","data/regression-cat-medium-1-yprop_4_1/X_num_val.npy\n","data/regression-cat-medium-1-yprop_4_1/Y_val.npy\n","data/regression-cat-medium-1-yprop_4_1/X_bin_val.npy\n","data/regression-cat-medium-1-yprop_4_1/X_num_train.npy\n","data/regression-cat-medium-1-yprop_4_1/X_bin_train.npy\n","data/regression-cat-medium-1-yprop_4_1/info.json\n","data/regression-cat-medium-1-yprop_4_1/READY\n","data/regression-cat-medium-1-yprop_4_1/X_bin_test.npy\n","data/regression-cat-medium-1-yprop_4_1/X_num_test.npy\n","data/regression-cat-medium-1-yprop_4_1/Y_test.npy\n","data/regression-cat-medium-1-yprop_4_1/Y_train.npy\n","data/classif-num-medium-1-bank-marketing/\n","data/classif-num-medium-1-bank-marketing/X_num_val.npy\n","data/classif-num-medium-1-bank-marketing/Y_val.npy\n","data/classif-num-medium-1-bank-marketing/X_num_train.npy\n","data/classif-num-medium-1-bank-marketing/info.json\n","data/classif-num-medium-1-bank-marketing/READY\n","data/classif-num-medium-1-bank-marketing/X_num_test.npy\n","data/classif-num-medium-1-bank-marketing/Y_test.npy\n","data/classif-num-medium-1-bank-marketing/Y_train.npy\n","data/classif-num-medium-1-credit/\n","data/classif-num-medium-1-credit/X_num_val.npy\n","data/classif-num-medium-1-credit/Y_val.npy\n","data/classif-num-medium-1-credit/X_num_train.npy\n","data/classif-num-medium-1-credit/info.json\n","data/classif-num-medium-1-credit/READY\n","data/classif-num-medium-1-credit/X_num_test.npy\n","data/classif-num-medium-1-credit/Y_test.npy\n","data/classif-num-medium-1-credit/Y_train.npy\n"]}]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-glTe-NrxA3S","executionInfo":{"status":"ok","timestamp":1731759935006,"user_tz":-420,"elapsed":8258,"user":{"displayName":"Jonindo Pasaribu","userId":"10958990953097471082"}},"outputId":"243fce84-733c-4f99-b464-bcf59a64890d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pytorch-tabnet\n","  Downloading pytorch_tabnet-4.1.0-py3-none-any.whl.metadata (15 kB)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from pytorch-tabnet) (1.26.4)\n","Requirement already satisfied: scikit_learn>0.21 in /usr/local/lib/python3.10/dist-packages (from pytorch-tabnet) (1.5.2)\n","Requirement already satisfied: scipy>1.4 in /usr/local/lib/python3.10/dist-packages (from pytorch-tabnet) (1.13.1)\n","Requirement already satisfied: torch>=1.3 in /usr/local/lib/python3.10/dist-packages (from pytorch-tabnet) (2.5.1+cu121)\n","Requirement already satisfied: tqdm>=4.36 in /usr/local/lib/python3.10/dist-packages (from pytorch-tabnet) (4.66.6)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit_learn>0.21->pytorch-tabnet) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit_learn>0.21->pytorch-tabnet) (3.5.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (3.16.1)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (4.12.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (2024.10.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.3->pytorch-tabnet) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.3->pytorch-tabnet) (3.0.2)\n","Downloading pytorch_tabnet-4.1.0-py3-none-any.whl (44 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.5/44.5 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: pytorch-tabnet\n","Successfully installed pytorch-tabnet-4.1.0\n"]}],"source":["!pip install pytorch-tabnet"]},{"cell_type":"code","source":["!pip install optuna"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T3kebgsowkp0","executionInfo":{"status":"ok","timestamp":1720244040744,"user_tz":-420,"elapsed":6704,"user":{"displayName":"Jonindo Pasaribu","userId":"10958990953097471082"}},"outputId":"7c503ee0-a890-4af1-c6e3-d3141e4ada90"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting optuna\n","  Downloading optuna-3.6.1-py3-none-any.whl (380 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m380.1/380.1 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting alembic>=1.5.0 (from optuna)\n","  Downloading alembic-1.13.2-py3-none-any.whl (232 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.0/233.0 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting colorlog (from optuna)\n","  Downloading colorlog-6.8.2-py3-none-any.whl (11 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna) (1.25.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (24.1)\n","Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.31)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.66.4)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0.1)\n","Collecting Mako (from alembic>=1.5.0->optuna)\n","  Downloading Mako-1.3.5-py3-none-any.whl (78 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.12.2)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna) (3.0.3)\n","Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.1.5)\n","Installing collected packages: Mako, colorlog, alembic, optuna\n","Successfully installed Mako-1.3.5 alembic-1.13.2 colorlog-6.8.2 optuna-3.6.1\n"]}]},{"cell_type":"code","source":["!pip install psutil"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Al_Dc4vO1LmW","executionInfo":{"status":"ok","timestamp":1731759940239,"user_tz":-420,"elapsed":5237,"user":{"displayName":"Jonindo Pasaribu","userId":"10958990953097471082"}},"outputId":"11eb527b-5fd6-46e2-95b9-e12d591f153a"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (5.9.5)\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","#import optuna\n","import torch.optim\n","import psutil\n","\n","from pytorch_tabnet.tab_model import TabNetClassifier\n","from sklearn.preprocessing import QuantileTransformer"],"metadata":{"id":"085aiY1dzlHG","executionInfo":{"status":"ok","timestamp":1731759952294,"user_tz":-420,"elapsed":12057,"user":{"displayName":"Jonindo Pasaribu","userId":"10958990953097471082"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["clf = TabNetClassifier()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pr7k2hel51eb","executionInfo":{"status":"ok","timestamp":1731752284803,"user_tz":-420,"elapsed":7,"user":{"displayName":"Jonindo Pasaribu","userId":"10958990953097471082"}},"outputId":"0b6e9553-9e1b-4aba-a32b-754f7a0be838"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]}]},{"cell_type":"code","source":["X_train = np.load('/content/data/classif-num-medium-0-MagicTelescope/X_num_train.npy')\n","y_train = np.load('/content/data/classif-num-medium-0-MagicTelescope/Y_train.npy')\n","\n","X_valid = np.load('/content/data/classif-num-medium-0-MagicTelescope/X_num_val.npy')\n","y_valid = np.load('/content/data/classif-num-medium-0-MagicTelescope/Y_val.npy')\n","\n","X_test = np.load('/content/data/classif-num-medium-0-MagicTelescope/X_num_test.npy')\n","y_test = np.load('/content/data/classif-num-medium-0-MagicTelescope/Y_test.npy')"],"metadata":{"id":"ml0RPc_76dZx","executionInfo":{"status":"ok","timestamp":1731760014951,"user_tz":-420,"elapsed":24,"user":{"displayName":"Jonindo Pasaribu","userId":"10958990953097471082"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["normalizer = QuantileTransformer(\n","            output_distribution='normal',\n","            n_quantiles=max(min(X_train.shape[0] // 30, 1000), 10),\n","            subsample=1_000_000_000,\n","            )\n","normalizer.fit_transform(X_train)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"19PUhYavmHsh","executionInfo":{"status":"ok","timestamp":1731760014951,"user_tz":-420,"elapsed":23,"user":{"displayName":"Jonindo Pasaribu","userId":"10958990953097471082"}},"outputId":"c34c8bb0-963e-49f0-d6f6-2711f546e012"},"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[-1.6393101 , -0.90230376, -1.3945612 , ..., -0.29131973,\n","        -0.737393  , -0.467348  ],\n","       [ 0.54153097, -0.07611426, -1.0577202 , ..., -1.0765651 ,\n","        -0.4129752 , -0.04665878],\n","       [ 1.7132984 ,  1.0078336 ,  0.42975497, ..., -1.0916998 ,\n","         0.24872102,  2.1620865 ],\n","       ...,\n","       [-1.0245086 , -1.0647414 , -0.80412334, ..., -0.6278598 ,\n","         0.6391125 , -0.27882308],\n","       [-1.203026  , -1.1980292 , -1.1129854 , ...,  0.06195614,\n","         0.6075059 ,  0.02848465],\n","       [ 1.1269407 ,  1.5216641 ,  1.2471416 , ...,  2.1540494 ,\n","         0.318182  ,  2.4361293 ]], dtype=float32)"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["#Baseline\n","clf.fit(\n","    X_train=X_train, y_train=y_train,\n","    eval_set=[(X_train, y_train), (X_valid, y_valid)],\n","    eval_name=['train', 'valid'],\n","    eval_metric=['accuracy'],\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dmadZ12j7CO_","executionInfo":{"status":"ok","timestamp":1720244134701,"user_tz":-420,"elapsed":36320,"user":{"displayName":"Jonindo Pasaribu","userId":"10958990953097471082"}},"outputId":"f064edd5-93e6-461a-d9e5-c1687955a796"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 0.67768 | train_accuracy: 0.57332 | valid_accuracy: 0.56276 |  0:00:00s\n","epoch 1  | loss: 0.55612 | train_accuracy: 0.48425 | valid_accuracy: 0.49127 |  0:00:01s\n","epoch 2  | loss: 0.49823 | train_accuracy: 0.48339 | valid_accuracy: 0.48961 |  0:00:01s\n","epoch 3  | loss: 0.44585 | train_accuracy: 0.55121 | valid_accuracy: 0.5611  |  0:00:02s\n","epoch 4  | loss: 0.41527 | train_accuracy: 0.53508 | valid_accuracy: 0.55694 |  0:00:02s\n","epoch 5  | loss: 0.40777 | train_accuracy: 0.51287 | valid_accuracy: 0.53616 |  0:00:03s\n","epoch 6  | loss: 0.40038 | train_accuracy: 0.50304 | valid_accuracy: 0.52618 |  0:00:03s\n","epoch 7  | loss: 0.39284 | train_accuracy: 0.52035 | valid_accuracy: 0.54613 |  0:00:04s\n","epoch 8  | loss: 0.38707 | train_accuracy: 0.58763 | valid_accuracy: 0.61596 |  0:00:05s\n","epoch 9  | loss: 0.38277 | train_accuracy: 0.56713 | valid_accuracy: 0.58271 |  0:00:05s\n","epoch 10 | loss: 0.38625 | train_accuracy: 0.54235 | valid_accuracy: 0.57024 |  0:00:06s\n","epoch 11 | loss: 0.37755 | train_accuracy: 0.64979 | valid_accuracy: 0.67249 |  0:00:06s\n","epoch 12 | loss: 0.36776 | train_accuracy: 0.64082 | valid_accuracy: 0.66584 |  0:00:07s\n","epoch 13 | loss: 0.36581 | train_accuracy: 0.64723 | valid_accuracy: 0.67332 |  0:00:07s\n","epoch 14 | loss: 0.36553 | train_accuracy: 0.66603 | valid_accuracy: 0.68495 |  0:00:08s\n","epoch 15 | loss: 0.36089 | train_accuracy: 0.6766  | valid_accuracy: 0.69327 |  0:00:09s\n","epoch 16 | loss: 0.35946 | train_accuracy: 0.6908  | valid_accuracy: 0.71155 |  0:00:09s\n","epoch 17 | loss: 0.36306 | train_accuracy: 0.70597 | valid_accuracy: 0.71904 |  0:00:10s\n","epoch 18 | loss: 0.37439 | train_accuracy: 0.74143 | valid_accuracy: 0.74314 |  0:00:10s\n","epoch 19 | loss: 0.36931 | train_accuracy: 0.73555 | valid_accuracy: 0.73982 |  0:00:11s\n","epoch 20 | loss: 0.36642 | train_accuracy: 0.73566 | valid_accuracy: 0.74231 |  0:00:11s\n","epoch 21 | loss: 0.35711 | train_accuracy: 0.7473  | valid_accuracy: 0.74813 |  0:00:12s\n","epoch 22 | loss: 0.35551 | train_accuracy: 0.74025 | valid_accuracy: 0.73566 |  0:00:13s\n","epoch 23 | loss: 0.35368 | train_accuracy: 0.76439 | valid_accuracy: 0.7581  |  0:00:13s\n","epoch 24 | loss: 0.35373 | train_accuracy: 0.77657 | valid_accuracy: 0.7714  |  0:00:14s\n","epoch 25 | loss: 0.35554 | train_accuracy: 0.76984 | valid_accuracy: 0.7606  |  0:00:14s\n","epoch 26 | loss: 0.35257 | train_accuracy: 0.79291 | valid_accuracy: 0.77639 |  0:00:15s\n","epoch 27 | loss: 0.34693 | train_accuracy: 0.80124 | valid_accuracy: 0.78803 |  0:00:15s\n","epoch 28 | loss: 0.34972 | train_accuracy: 0.78287 | valid_accuracy: 0.76808 |  0:00:16s\n","epoch 29 | loss: 0.34965 | train_accuracy: 0.79686 | valid_accuracy: 0.78554 |  0:00:17s\n","epoch 30 | loss: 0.34778 | train_accuracy: 0.81373 | valid_accuracy: 0.81214 |  0:00:17s\n","epoch 31 | loss: 0.34623 | train_accuracy: 0.81993 | valid_accuracy: 0.8138  |  0:00:18s\n","epoch 32 | loss: 0.34489 | train_accuracy: 0.82377 | valid_accuracy: 0.82045 |  0:00:18s\n","epoch 33 | loss: 0.33882 | train_accuracy: 0.83574 | valid_accuracy: 0.83541 |  0:00:19s\n","epoch 34 | loss: 0.33897 | train_accuracy: 0.83413 | valid_accuracy: 0.82793 |  0:00:19s\n","epoch 35 | loss: 0.34066 | train_accuracy: 0.84417 | valid_accuracy: 0.83957 |  0:00:20s\n","epoch 36 | loss: 0.34044 | train_accuracy: 0.83766 | valid_accuracy: 0.82461 |  0:00:20s\n","epoch 37 | loss: 0.33216 | train_accuracy: 0.84642 | valid_accuracy: 0.83874 |  0:00:21s\n","epoch 38 | loss: 0.33408 | train_accuracy: 0.84214 | valid_accuracy: 0.84289 |  0:00:22s\n","epoch 39 | loss: 0.33735 | train_accuracy: 0.84716 | valid_accuracy: 0.84372 |  0:00:22s\n","epoch 40 | loss: 0.33786 | train_accuracy: 0.84919 | valid_accuracy: 0.85204 |  0:00:23s\n","epoch 41 | loss: 0.33435 | train_accuracy: 0.85795 | valid_accuracy: 0.85287 |  0:00:23s\n","epoch 42 | loss: 0.33582 | train_accuracy: 0.84823 | valid_accuracy: 0.84871 |  0:00:24s\n","epoch 43 | loss: 0.33029 | train_accuracy: 0.85315 | valid_accuracy: 0.84123 |  0:00:24s\n","epoch 44 | loss: 0.33053 | train_accuracy: 0.85635 | valid_accuracy: 0.84871 |  0:00:25s\n","epoch 45 | loss: 0.32662 | train_accuracy: 0.85752 | valid_accuracy: 0.84871 |  0:00:26s\n","epoch 46 | loss: 0.32231 | train_accuracy: 0.85902 | valid_accuracy: 0.85037 |  0:00:26s\n","epoch 47 | loss: 0.32382 | train_accuracy: 0.85507 | valid_accuracy: 0.84871 |  0:00:27s\n","epoch 48 | loss: 0.32336 | train_accuracy: 0.85432 | valid_accuracy: 0.84871 |  0:00:27s\n","epoch 49 | loss: 0.32448 | train_accuracy: 0.85859 | valid_accuracy: 0.85786 |  0:00:28s\n","epoch 50 | loss: 0.32136 | train_accuracy: 0.86073 | valid_accuracy: 0.85121 |  0:00:28s\n","epoch 51 | loss: 0.32371 | train_accuracy: 0.86009 | valid_accuracy: 0.85204 |  0:00:29s\n","epoch 52 | loss: 0.32164 | train_accuracy: 0.86094 | valid_accuracy: 0.86201 |  0:00:30s\n","epoch 53 | loss: 0.31947 | train_accuracy: 0.85923 | valid_accuracy: 0.85619 |  0:00:30s\n","epoch 54 | loss: 0.32429 | train_accuracy: 0.85934 | valid_accuracy: 0.85121 |  0:00:31s\n","epoch 55 | loss: 0.32571 | train_accuracy: 0.85742 | valid_accuracy: 0.85786 |  0:00:31s\n","epoch 56 | loss: 0.32768 | train_accuracy: 0.86105 | valid_accuracy: 0.85204 |  0:00:32s\n","epoch 57 | loss: 0.32241 | train_accuracy: 0.85849 | valid_accuracy: 0.85204 |  0:00:32s\n","epoch 58 | loss: 0.31723 | train_accuracy: 0.86041 | valid_accuracy: 0.85702 |  0:00:33s\n","epoch 59 | loss: 0.31859 | train_accuracy: 0.86201 | valid_accuracy: 0.85204 |  0:00:34s\n","epoch 60 | loss: 0.31915 | train_accuracy: 0.86009 | valid_accuracy: 0.85121 |  0:00:34s\n","epoch 61 | loss: 0.31563 | train_accuracy: 0.86169 | valid_accuracy: 0.85536 |  0:00:35s\n","epoch 62 | loss: 0.3172  | train_accuracy: 0.86019 | valid_accuracy: 0.8537  |  0:00:35s\n","\n","Early stopping occurred at epoch 62 with best_epoch = 52 and best_valid_accuracy = 0.86201\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n"]}]},{"cell_type":"code","source":["def objective(trial):\n","    params = {\n","        'n_d': trial.suggest_int('n_d', 8, 64),\n","        'n_steps': trial.suggest_int('n_steps', 3, 10),\n","        'gamma': trial.suggest_float('gamma', 1.0, 2.0),\n","        'n_independent': trial.suggest_int('n_independent', 1, 5),\n","        'n_shared': trial.suggest_int('n_shared', 1, 5),\n","        'momentum': trial.suggest_float('momentum', 0.01, 0.4),\n","    }\n","\n","    model = TabNetClassifier(**params, n_a=params['n_d'])\n","    model.fit(X_train, y_train, eval_set=[(X_valid, y_valid)], eval_metric=['accuracy'], patience=10)\n","\n","    # Evaluate model performance\n","    score = model.best_cost  # or any other metric\n","\n","    return score\n","\n","study = optuna.create_study(direction='maximize')\n","study.optimize(objective, n_trials=100)\n","\n","best_params = study.best_params"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rKJAw0W-w7sc","outputId":"2338cf8b-f718-4d41-cdb8-1f6b097ead00","executionInfo":{"status":"ok","timestamp":1720248499342,"user_tz":-420,"elapsed":4364647,"user":{"displayName":"Jonindo Pasaribu","userId":"10958990953097471082"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[I 2024-07-06 05:35:34,206] A new study created in memory with name: no-name-d26137c2-df0a-4734-92d3-db32dc1ad167\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 0.98551 | val_0_accuracy: 0.51039 |  0:00:01s\n","epoch 1  | loss: 0.71362 | val_0_accuracy: 0.54281 |  0:00:02s\n","epoch 2  | loss: 0.65051 | val_0_accuracy: 0.5453  |  0:00:04s\n","epoch 3  | loss: 0.56729 | val_0_accuracy: 0.63259 |  0:00:05s\n","epoch 4  | loss: 0.51416 | val_0_accuracy: 0.57855 |  0:00:06s\n","epoch 5  | loss: 0.51703 | val_0_accuracy: 0.6251  |  0:00:08s\n","epoch 6  | loss: 0.53667 | val_0_accuracy: 0.665   |  0:00:09s\n","epoch 7  | loss: 0.51377 | val_0_accuracy: 0.60848 |  0:00:10s\n","epoch 8  | loss: 0.49653 | val_0_accuracy: 0.61845 |  0:00:12s\n","epoch 9  | loss: 0.48372 | val_0_accuracy: 0.63259 |  0:00:13s\n","epoch 10 | loss: 0.46441 | val_0_accuracy: 0.66168 |  0:00:14s\n","epoch 11 | loss: 0.461   | val_0_accuracy: 0.70324 |  0:00:16s\n","epoch 12 | loss: 0.46751 | val_0_accuracy: 0.70241 |  0:00:17s\n","epoch 13 | loss: 0.45615 | val_0_accuracy: 0.73982 |  0:00:18s\n","epoch 14 | loss: 0.43797 | val_0_accuracy: 0.75977 |  0:00:20s\n","epoch 15 | loss: 0.42962 | val_0_accuracy: 0.74065 |  0:00:21s\n","epoch 16 | loss: 0.41387 | val_0_accuracy: 0.73067 |  0:00:22s\n","epoch 17 | loss: 0.41653 | val_0_accuracy: 0.71155 |  0:00:24s\n","epoch 18 | loss: 0.41924 | val_0_accuracy: 0.72735 |  0:00:25s\n","epoch 19 | loss: 0.42043 | val_0_accuracy: 0.75727 |  0:00:26s\n","epoch 20 | loss: 0.4153  | val_0_accuracy: 0.77805 |  0:00:27s\n","epoch 21 | loss: 0.41183 | val_0_accuracy: 0.76309 |  0:00:29s\n","epoch 22 | loss: 0.41369 | val_0_accuracy: 0.77307 |  0:00:30s\n","epoch 23 | loss: 0.40479 | val_0_accuracy: 0.75977 |  0:00:32s\n","epoch 24 | loss: 0.40533 | val_0_accuracy: 0.77307 |  0:00:33s\n","epoch 25 | loss: 0.40865 | val_0_accuracy: 0.77224 |  0:00:34s\n","epoch 26 | loss: 0.40282 | val_0_accuracy: 0.77972 |  0:00:36s\n","epoch 27 | loss: 0.41131 | val_0_accuracy: 0.78803 |  0:00:37s\n","epoch 28 | loss: 0.41329 | val_0_accuracy: 0.79551 |  0:00:38s\n","epoch 29 | loss: 0.40422 | val_0_accuracy: 0.78803 |  0:00:40s\n","epoch 30 | loss: 0.40354 | val_0_accuracy: 0.80216 |  0:00:41s\n","epoch 31 | loss: 0.39668 | val_0_accuracy: 0.79385 |  0:00:42s\n","epoch 32 | loss: 0.39707 | val_0_accuracy: 0.79551 |  0:00:44s\n","epoch 33 | loss: 0.4023  | val_0_accuracy: 0.80216 |  0:00:45s\n","epoch 34 | loss: 0.39971 | val_0_accuracy: 0.79052 |  0:00:46s\n","epoch 35 | loss: 0.40045 | val_0_accuracy: 0.79551 |  0:00:48s\n","epoch 36 | loss: 0.39988 | val_0_accuracy: 0.81047 |  0:00:49s\n","epoch 37 | loss: 0.40423 | val_0_accuracy: 0.83292 |  0:00:50s\n","epoch 38 | loss: 0.40217 | val_0_accuracy: 0.82377 |  0:00:52s\n","epoch 39 | loss: 0.39428 | val_0_accuracy: 0.82544 |  0:00:53s\n","epoch 40 | loss: 0.39192 | val_0_accuracy: 0.83375 |  0:00:54s\n","epoch 41 | loss: 0.38455 | val_0_accuracy: 0.83292 |  0:00:56s\n","epoch 42 | loss: 0.38842 | val_0_accuracy: 0.82294 |  0:00:57s\n","epoch 43 | loss: 0.38727 | val_0_accuracy: 0.83541 |  0:00:58s\n","epoch 44 | loss: 0.38909 | val_0_accuracy: 0.83042 |  0:01:00s\n","epoch 45 | loss: 0.38704 | val_0_accuracy: 0.82793 |  0:01:01s\n","epoch 46 | loss: 0.38044 | val_0_accuracy: 0.83707 |  0:01:02s\n","epoch 47 | loss: 0.37978 | val_0_accuracy: 0.83624 |  0:01:04s\n","epoch 48 | loss: 0.39441 | val_0_accuracy: 0.8404  |  0:01:05s\n","epoch 49 | loss: 0.38798 | val_0_accuracy: 0.83292 |  0:01:06s\n","epoch 50 | loss: 0.39161 | val_0_accuracy: 0.83791 |  0:01:07s\n","epoch 51 | loss: 0.3854  | val_0_accuracy: 0.82461 |  0:01:09s\n","epoch 52 | loss: 0.38872 | val_0_accuracy: 0.84289 |  0:01:10s\n","epoch 53 | loss: 0.38386 | val_0_accuracy: 0.84622 |  0:01:11s\n","epoch 54 | loss: 0.37793 | val_0_accuracy: 0.82793 |  0:01:13s\n","epoch 55 | loss: 0.38117 | val_0_accuracy: 0.84206 |  0:01:14s\n","epoch 56 | loss: 0.38158 | val_0_accuracy: 0.83624 |  0:01:15s\n","epoch 57 | loss: 0.37586 | val_0_accuracy: 0.8404  |  0:01:17s\n","epoch 58 | loss: 0.37587 | val_0_accuracy: 0.84539 |  0:01:18s\n","epoch 59 | loss: 0.37374 | val_0_accuracy: 0.84289 |  0:01:19s\n","epoch 60 | loss: 0.3772  | val_0_accuracy: 0.83791 |  0:01:21s\n","epoch 61 | loss: 0.37474 | val_0_accuracy: 0.8404  |  0:01:22s\n","epoch 62 | loss: 0.37275 | val_0_accuracy: 0.84456 |  0:01:23s\n","epoch 63 | loss: 0.37477 | val_0_accuracy: 0.83957 |  0:01:25s\n","\n","Early stopping occurred at epoch 63 with best_epoch = 53 and best_val_0_accuracy = 0.84622\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-07-06 05:37:00,251] Trial 0 finished with value: 0.8462177888611804 and parameters: {'n_d': 44, 'n_steps': 8, 'gamma': 1.3332993841099636, 'n_independent': 3, 'n_shared': 5, 'momentum': 0.05281675134578197}. Best is trial 0 with value: 0.8462177888611804.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 2.80572 | val_0_accuracy: 0.52785 |  0:00:00s\n","epoch 1  | loss: 0.88648 | val_0_accuracy: 0.51538 |  0:00:01s\n","epoch 2  | loss: 0.72946 | val_0_accuracy: 0.54281 |  0:00:01s\n","epoch 3  | loss: 0.58104 | val_0_accuracy: 0.53034 |  0:00:02s\n","epoch 4  | loss: 0.50115 | val_0_accuracy: 0.61845 |  0:00:03s\n","epoch 5  | loss: 0.50166 | val_0_accuracy: 0.62926 |  0:00:03s\n","epoch 6  | loss: 0.46865 | val_0_accuracy: 0.63924 |  0:00:04s\n","epoch 7  | loss: 0.45609 | val_0_accuracy: 0.70823 |  0:00:04s\n","epoch 8  | loss: 0.45225 | val_0_accuracy: 0.64422 |  0:00:05s\n","epoch 9  | loss: 0.50457 | val_0_accuracy: 0.73234 |  0:00:06s\n","epoch 10 | loss: 0.46709 | val_0_accuracy: 0.73649 |  0:00:06s\n","epoch 11 | loss: 0.43461 | val_0_accuracy: 0.74231 |  0:00:07s\n","epoch 12 | loss: 0.43463 | val_0_accuracy: 0.7448  |  0:00:07s\n","epoch 13 | loss: 0.44363 | val_0_accuracy: 0.71737 |  0:00:08s\n","epoch 14 | loss: 0.49088 | val_0_accuracy: 0.74979 |  0:00:09s\n","epoch 15 | loss: 0.48043 | val_0_accuracy: 0.7581  |  0:00:09s\n","epoch 16 | loss: 0.43304 | val_0_accuracy: 0.75062 |  0:00:10s\n","epoch 17 | loss: 0.43399 | val_0_accuracy: 0.77224 |  0:00:10s\n","epoch 18 | loss: 0.42588 | val_0_accuracy: 0.76226 |  0:00:11s\n","epoch 19 | loss: 0.4303  | val_0_accuracy: 0.77057 |  0:00:12s\n","epoch 20 | loss: 0.42953 | val_0_accuracy: 0.76392 |  0:00:12s\n","epoch 21 | loss: 0.42263 | val_0_accuracy: 0.74813 |  0:00:13s\n","epoch 22 | loss: 0.41985 | val_0_accuracy: 0.75229 |  0:00:13s\n","epoch 23 | loss: 0.40753 | val_0_accuracy: 0.75229 |  0:00:14s\n","epoch 24 | loss: 0.39706 | val_0_accuracy: 0.76226 |  0:00:15s\n","epoch 25 | loss: 0.4005  | val_0_accuracy: 0.77639 |  0:00:15s\n","epoch 26 | loss: 0.39802 | val_0_accuracy: 0.77805 |  0:00:16s\n","epoch 27 | loss: 0.40433 | val_0_accuracy: 0.78803 |  0:00:17s\n","epoch 28 | loss: 0.39761 | val_0_accuracy: 0.79468 |  0:00:17s\n","epoch 29 | loss: 0.39115 | val_0_accuracy: 0.80216 |  0:00:18s\n","epoch 30 | loss: 0.3904  | val_0_accuracy: 0.80881 |  0:00:18s\n","epoch 31 | loss: 0.38972 | val_0_accuracy: 0.81546 |  0:00:19s\n","epoch 32 | loss: 0.39066 | val_0_accuracy: 0.81463 |  0:00:20s\n","epoch 33 | loss: 0.39552 | val_0_accuracy: 0.80382 |  0:00:20s\n","epoch 34 | loss: 0.39455 | val_0_accuracy: 0.81546 |  0:00:21s\n","epoch 35 | loss: 0.39612 | val_0_accuracy: 0.81546 |  0:00:21s\n","epoch 36 | loss: 0.3943  | val_0_accuracy: 0.81297 |  0:00:22s\n","epoch 37 | loss: 0.39639 | val_0_accuracy: 0.81131 |  0:00:23s\n","epoch 38 | loss: 0.39873 | val_0_accuracy: 0.81297 |  0:00:23s\n","epoch 39 | loss: 0.39538 | val_0_accuracy: 0.82461 |  0:00:24s\n","epoch 40 | loss: 0.3904  | val_0_accuracy: 0.82544 |  0:00:24s\n","epoch 41 | loss: 0.38093 | val_0_accuracy: 0.83957 |  0:00:25s\n","epoch 42 | loss: 0.37927 | val_0_accuracy: 0.83375 |  0:00:26s\n","epoch 43 | loss: 0.37977 | val_0_accuracy: 0.83624 |  0:00:26s\n","epoch 44 | loss: 0.38903 | val_0_accuracy: 0.83209 |  0:00:27s\n","epoch 45 | loss: 0.38646 | val_0_accuracy: 0.8271  |  0:00:28s\n","epoch 46 | loss: 0.38567 | val_0_accuracy: 0.82793 |  0:00:28s\n","epoch 47 | loss: 0.38319 | val_0_accuracy: 0.81962 |  0:00:29s\n","epoch 48 | loss: 0.38813 | val_0_accuracy: 0.8271  |  0:00:29s\n","epoch 49 | loss: 0.39022 | val_0_accuracy: 0.82128 |  0:00:30s\n","epoch 50 | loss: 0.39466 | val_0_accuracy: 0.82128 |  0:00:31s\n","epoch 51 | loss: 0.39147 | val_0_accuracy: 0.82627 |  0:00:31s\n","\n","Early stopping occurred at epoch 51 with best_epoch = 41 and best_val_0_accuracy = 0.83957\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-07-06 05:37:32,287] Trial 1 finished with value: 0.8395677472984207 and parameters: {'n_d': 61, 'n_steps': 9, 'gamma': 1.992974766879843, 'n_independent': 1, 'n_shared': 1, 'momentum': 0.24181114885526883}. Best is trial 0 with value: 0.8462177888611804.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 0.79015 | val_0_accuracy: 0.51455 |  0:00:00s\n","epoch 1  | loss: 0.53284 | val_0_accuracy: 0.50873 |  0:00:01s\n","epoch 2  | loss: 0.5022  | val_0_accuracy: 0.51704 |  0:00:01s\n","epoch 3  | loss: 0.48503 | val_0_accuracy: 0.5187  |  0:00:02s\n","epoch 4  | loss: 0.46953 | val_0_accuracy: 0.52951 |  0:00:02s\n","epoch 5  | loss: 0.45342 | val_0_accuracy: 0.53367 |  0:00:03s\n","epoch 6  | loss: 0.45328 | val_0_accuracy: 0.53117 |  0:00:03s\n","epoch 7  | loss: 0.44937 | val_0_accuracy: 0.5877  |  0:00:04s\n","epoch 8  | loss: 0.44832 | val_0_accuracy: 0.59684 |  0:00:05s\n","epoch 9  | loss: 0.44587 | val_0_accuracy: 0.59102 |  0:00:05s\n","epoch 10 | loss: 0.45458 | val_0_accuracy: 0.60765 |  0:00:06s\n","epoch 11 | loss: 0.45957 | val_0_accuracy: 0.64505 |  0:00:06s\n","epoch 12 | loss: 0.45606 | val_0_accuracy: 0.6916  |  0:00:07s\n","epoch 13 | loss: 0.44383 | val_0_accuracy: 0.70574 |  0:00:07s\n","epoch 14 | loss: 0.43625 | val_0_accuracy: 0.68329 |  0:00:08s\n","epoch 15 | loss: 0.42506 | val_0_accuracy: 0.7074  |  0:00:08s\n","epoch 16 | loss: 0.41875 | val_0_accuracy: 0.71488 |  0:00:09s\n","epoch 17 | loss: 0.41217 | val_0_accuracy: 0.70989 |  0:00:10s\n","epoch 18 | loss: 0.4049  | val_0_accuracy: 0.71239 |  0:00:10s\n","epoch 19 | loss: 0.39986 | val_0_accuracy: 0.7473  |  0:00:11s\n","epoch 20 | loss: 0.39646 | val_0_accuracy: 0.72735 |  0:00:11s\n","epoch 21 | loss: 0.38638 | val_0_accuracy: 0.73483 |  0:00:12s\n","epoch 22 | loss: 0.39141 | val_0_accuracy: 0.77057 |  0:00:12s\n","epoch 23 | loss: 0.38218 | val_0_accuracy: 0.75561 |  0:00:13s\n","epoch 24 | loss: 0.3846  | val_0_accuracy: 0.77057 |  0:00:13s\n","epoch 25 | loss: 0.3834  | val_0_accuracy: 0.77057 |  0:00:14s\n","epoch 26 | loss: 0.37315 | val_0_accuracy: 0.74896 |  0:00:14s\n","epoch 27 | loss: 0.37526 | val_0_accuracy: 0.79302 |  0:00:15s\n","epoch 28 | loss: 0.37712 | val_0_accuracy: 0.79385 |  0:00:15s\n","epoch 29 | loss: 0.37981 | val_0_accuracy: 0.79468 |  0:00:16s\n","epoch 30 | loss: 0.37142 | val_0_accuracy: 0.80466 |  0:00:17s\n","epoch 31 | loss: 0.36795 | val_0_accuracy: 0.80133 |  0:00:17s\n","epoch 32 | loss: 0.37059 | val_0_accuracy: 0.80798 |  0:00:18s\n","epoch 33 | loss: 0.37449 | val_0_accuracy: 0.81879 |  0:00:18s\n","epoch 34 | loss: 0.36749 | val_0_accuracy: 0.82211 |  0:00:19s\n","epoch 35 | loss: 0.36557 | val_0_accuracy: 0.81879 |  0:00:19s\n","epoch 36 | loss: 0.36879 | val_0_accuracy: 0.82959 |  0:00:20s\n","epoch 37 | loss: 0.36584 | val_0_accuracy: 0.83375 |  0:00:20s\n","epoch 38 | loss: 0.36543 | val_0_accuracy: 0.82959 |  0:00:21s\n","epoch 39 | loss: 0.36378 | val_0_accuracy: 0.82876 |  0:00:22s\n","epoch 40 | loss: 0.35741 | val_0_accuracy: 0.83957 |  0:00:22s\n","epoch 41 | loss: 0.35193 | val_0_accuracy: 0.83541 |  0:00:23s\n","epoch 42 | loss: 0.35342 | val_0_accuracy: 0.84289 |  0:00:23s\n","epoch 43 | loss: 0.35663 | val_0_accuracy: 0.84289 |  0:00:24s\n","epoch 44 | loss: 0.36053 | val_0_accuracy: 0.8404  |  0:00:24s\n","epoch 45 | loss: 0.35318 | val_0_accuracy: 0.84871 |  0:00:25s\n","epoch 46 | loss: 0.35296 | val_0_accuracy: 0.84954 |  0:00:25s\n","epoch 47 | loss: 0.34843 | val_0_accuracy: 0.84954 |  0:00:26s\n","epoch 48 | loss: 0.35022 | val_0_accuracy: 0.84705 |  0:00:26s\n","epoch 49 | loss: 0.36099 | val_0_accuracy: 0.84372 |  0:00:27s\n","epoch 50 | loss: 0.3575  | val_0_accuracy: 0.83541 |  0:00:28s\n","epoch 51 | loss: 0.34907 | val_0_accuracy: 0.83707 |  0:00:28s\n","epoch 52 | loss: 0.34632 | val_0_accuracy: 0.84289 |  0:00:29s\n","epoch 53 | loss: 0.35538 | val_0_accuracy: 0.84871 |  0:00:29s\n","epoch 54 | loss: 0.35483 | val_0_accuracy: 0.84788 |  0:00:30s\n","epoch 55 | loss: 0.34903 | val_0_accuracy: 0.84372 |  0:00:30s\n","epoch 56 | loss: 0.34854 | val_0_accuracy: 0.84123 |  0:00:31s\n","\n","Early stopping occurred at epoch 56 with best_epoch = 46 and best_val_0_accuracy = 0.84954\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-07-06 05:38:03,930] Trial 2 finished with value: 0.8495428096425602 and parameters: {'n_d': 10, 'n_steps': 4, 'gamma': 1.6214260360317287, 'n_independent': 3, 'n_shared': 2, 'momentum': 0.39899434565467273}. Best is trial 2 with value: 0.8495428096425602.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 0.71813 | val_0_accuracy: 0.56359 |  0:00:00s\n","epoch 1  | loss: 0.55165 | val_0_accuracy: 0.53782 |  0:00:01s\n","epoch 2  | loss: 0.48083 | val_0_accuracy: 0.5187  |  0:00:02s\n","epoch 3  | loss: 0.43475 | val_0_accuracy: 0.51787 |  0:00:03s\n","epoch 4  | loss: 0.41841 | val_0_accuracy: 0.57855 |  0:00:04s\n","epoch 5  | loss: 0.40223 | val_0_accuracy: 0.60515 |  0:00:05s\n","epoch 6  | loss: 0.38733 | val_0_accuracy: 0.59268 |  0:00:06s\n","epoch 7  | loss: 0.37777 | val_0_accuracy: 0.62677 |  0:00:06s\n","epoch 8  | loss: 0.36489 | val_0_accuracy: 0.63009 |  0:00:07s\n","epoch 9  | loss: 0.36539 | val_0_accuracy: 0.65503 |  0:00:08s\n","epoch 10 | loss: 0.36584 | val_0_accuracy: 0.69493 |  0:00:09s\n","epoch 11 | loss: 0.36531 | val_0_accuracy: 0.64755 |  0:00:10s\n","epoch 12 | loss: 0.36332 | val_0_accuracy: 0.64672 |  0:00:11s\n","epoch 13 | loss: 0.36841 | val_0_accuracy: 0.68495 |  0:00:11s\n","epoch 14 | loss: 0.36455 | val_0_accuracy: 0.71239 |  0:00:12s\n","epoch 15 | loss: 0.35834 | val_0_accuracy: 0.73234 |  0:00:13s\n","epoch 16 | loss: 0.35478 | val_0_accuracy: 0.70407 |  0:00:14s\n","epoch 17 | loss: 0.34991 | val_0_accuracy: 0.73317 |  0:00:15s\n","epoch 18 | loss: 0.34936 | val_0_accuracy: 0.72236 |  0:00:16s\n","epoch 19 | loss: 0.34582 | val_0_accuracy: 0.7606  |  0:00:16s\n","epoch 20 | loss: 0.35449 | val_0_accuracy: 0.72153 |  0:00:17s\n","epoch 21 | loss: 0.34553 | val_0_accuracy: 0.68662 |  0:00:18s\n","epoch 22 | loss: 0.35351 | val_0_accuracy: 0.73566 |  0:00:19s\n","epoch 23 | loss: 0.34791 | val_0_accuracy: 0.73899 |  0:00:20s\n","epoch 24 | loss: 0.33638 | val_0_accuracy: 0.77057 |  0:00:21s\n","epoch 25 | loss: 0.33491 | val_0_accuracy: 0.76143 |  0:00:21s\n","epoch 26 | loss: 0.33197 | val_0_accuracy: 0.76559 |  0:00:22s\n","epoch 27 | loss: 0.33488 | val_0_accuracy: 0.78969 |  0:00:23s\n","epoch 28 | loss: 0.33284 | val_0_accuracy: 0.82128 |  0:00:24s\n","epoch 29 | loss: 0.32976 | val_0_accuracy: 0.79052 |  0:00:25s\n","epoch 30 | loss: 0.33473 | val_0_accuracy: 0.80964 |  0:00:26s\n","epoch 31 | loss: 0.33226 | val_0_accuracy: 0.83707 |  0:00:26s\n","epoch 32 | loss: 0.33105 | val_0_accuracy: 0.81879 |  0:00:27s\n","epoch 33 | loss: 0.33324 | val_0_accuracy: 0.84871 |  0:00:28s\n","epoch 34 | loss: 0.32804 | val_0_accuracy: 0.81879 |  0:00:29s\n","epoch 35 | loss: 0.33224 | val_0_accuracy: 0.86118 |  0:00:30s\n","epoch 36 | loss: 0.32729 | val_0_accuracy: 0.85121 |  0:00:31s\n","epoch 37 | loss: 0.3328  | val_0_accuracy: 0.84871 |  0:00:31s\n","epoch 38 | loss: 0.32726 | val_0_accuracy: 0.85702 |  0:00:32s\n","epoch 39 | loss: 0.32485 | val_0_accuracy: 0.85037 |  0:00:33s\n","epoch 40 | loss: 0.3206  | val_0_accuracy: 0.85702 |  0:00:34s\n","epoch 41 | loss: 0.32504 | val_0_accuracy: 0.86451 |  0:00:35s\n","epoch 42 | loss: 0.32261 | val_0_accuracy: 0.86534 |  0:00:36s\n","epoch 43 | loss: 0.32004 | val_0_accuracy: 0.867   |  0:00:37s\n","epoch 44 | loss: 0.3183  | val_0_accuracy: 0.85619 |  0:00:37s\n","epoch 45 | loss: 0.3204  | val_0_accuracy: 0.85952 |  0:00:38s\n","epoch 46 | loss: 0.32227 | val_0_accuracy: 0.8537  |  0:00:39s\n","epoch 47 | loss: 0.32291 | val_0_accuracy: 0.86949 |  0:00:40s\n","epoch 48 | loss: 0.3183  | val_0_accuracy: 0.86118 |  0:00:41s\n","epoch 49 | loss: 0.31583 | val_0_accuracy: 0.86367 |  0:00:42s\n","epoch 50 | loss: 0.31001 | val_0_accuracy: 0.86783 |  0:00:42s\n","epoch 51 | loss: 0.31089 | val_0_accuracy: 0.86367 |  0:00:43s\n","epoch 52 | loss: 0.30891 | val_0_accuracy: 0.86118 |  0:00:44s\n","epoch 53 | loss: 0.31001 | val_0_accuracy: 0.85204 |  0:00:45s\n","epoch 54 | loss: 0.3124  | val_0_accuracy: 0.867   |  0:00:46s\n","epoch 55 | loss: 0.30371 | val_0_accuracy: 0.85121 |  0:00:47s\n","epoch 56 | loss: 0.30203 | val_0_accuracy: 0.86451 |  0:00:47s\n","epoch 57 | loss: 0.3025  | val_0_accuracy: 0.86534 |  0:00:48s\n","\n","Early stopping occurred at epoch 57 with best_epoch = 47 and best_val_0_accuracy = 0.86949\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-07-06 05:38:53,061] Trial 3 finished with value: 0.8694929343308395 and parameters: {'n_d': 44, 'n_steps': 4, 'gamma': 1.2821863155337851, 'n_independent': 5, 'n_shared': 4, 'momentum': 0.0878953325480076}. Best is trial 3 with value: 0.8694929343308395.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 0.91339 | val_0_accuracy: 0.60266 |  0:00:00s\n","epoch 1  | loss: 0.56008 | val_0_accuracy: 0.54281 |  0:00:01s\n","epoch 2  | loss: 0.46629 | val_0_accuracy: 0.51787 |  0:00:01s\n","epoch 3  | loss: 0.42668 | val_0_accuracy: 0.51455 |  0:00:02s\n","epoch 4  | loss: 0.4083  | val_0_accuracy: 0.51372 |  0:00:03s\n","epoch 5  | loss: 0.39971 | val_0_accuracy: 0.56608 |  0:00:03s\n","epoch 6  | loss: 0.38182 | val_0_accuracy: 0.5212  |  0:00:04s\n","epoch 7  | loss: 0.38011 | val_0_accuracy: 0.56359 |  0:00:04s\n","epoch 8  | loss: 0.37082 | val_0_accuracy: 0.56858 |  0:00:05s\n","epoch 9  | loss: 0.36887 | val_0_accuracy: 0.5744  |  0:00:06s\n","epoch 10 | loss: 0.37093 | val_0_accuracy: 0.57772 |  0:00:06s\n","\n","Early stopping occurred at epoch 10 with best_epoch = 0 and best_val_0_accuracy = 0.60266\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-07-06 05:39:00,148] Trial 4 finished with value: 0.6026600166251039 and parameters: {'n_d': 63, 'n_steps': 4, 'gamma': 1.5305857708497812, 'n_independent': 4, 'n_shared': 2, 'momentum': 0.1444837655934526}. Best is trial 3 with value: 0.8694929343308395.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 2.04104 | val_0_accuracy: 0.51372 |  0:00:01s\n","epoch 1  | loss: 0.61919 | val_0_accuracy: 0.58105 |  0:00:02s\n","epoch 2  | loss: 0.62458 | val_0_accuracy: 0.51288 |  0:00:04s\n","epoch 3  | loss: 0.56434 | val_0_accuracy: 0.64007 |  0:00:05s\n","epoch 4  | loss: 0.60617 | val_0_accuracy: 0.67415 |  0:00:06s\n","epoch 5  | loss: 0.64465 | val_0_accuracy: 0.64755 |  0:00:08s\n","epoch 6  | loss: 0.6143  | val_0_accuracy: 0.61762 |  0:00:09s\n","epoch 7  | loss: 0.54021 | val_0_accuracy: 0.66334 |  0:00:10s\n","epoch 8  | loss: 0.50876 | val_0_accuracy: 0.66168 |  0:00:12s\n","epoch 9  | loss: 0.49047 | val_0_accuracy: 0.67747 |  0:00:13s\n","epoch 10 | loss: 0.47874 | val_0_accuracy: 0.72569 |  0:00:14s\n","epoch 11 | loss: 0.46461 | val_0_accuracy: 0.67914 |  0:00:16s\n","epoch 12 | loss: 0.46236 | val_0_accuracy: 0.63591 |  0:00:17s\n","epoch 13 | loss: 0.46053 | val_0_accuracy: 0.69992 |  0:00:18s\n","epoch 14 | loss: 0.45104 | val_0_accuracy: 0.74065 |  0:00:20s\n","epoch 15 | loss: 0.44365 | val_0_accuracy: 0.77889 |  0:00:21s\n","epoch 16 | loss: 0.42966 | val_0_accuracy: 0.75062 |  0:00:22s\n","epoch 17 | loss: 0.42839 | val_0_accuracy: 0.76559 |  0:00:24s\n","epoch 18 | loss: 0.42165 | val_0_accuracy: 0.76309 |  0:00:25s\n","epoch 19 | loss: 0.42294 | val_0_accuracy: 0.76559 |  0:00:26s\n","epoch 20 | loss: 0.40803 | val_0_accuracy: 0.7581  |  0:00:28s\n","epoch 21 | loss: 0.40724 | val_0_accuracy: 0.74979 |  0:00:29s\n","epoch 22 | loss: 0.40946 | val_0_accuracy: 0.77307 |  0:00:30s\n","epoch 23 | loss: 0.40701 | val_0_accuracy: 0.75894 |  0:00:32s\n","epoch 24 | loss: 0.40373 | val_0_accuracy: 0.78221 |  0:00:33s\n","epoch 25 | loss: 0.40736 | val_0_accuracy: 0.77473 |  0:00:35s\n","epoch 26 | loss: 0.40298 | val_0_accuracy: 0.7872  |  0:00:36s\n","epoch 27 | loss: 0.40808 | val_0_accuracy: 0.77805 |  0:00:37s\n","epoch 28 | loss: 0.41027 | val_0_accuracy: 0.79219 |  0:00:39s\n","epoch 29 | loss: 0.41163 | val_0_accuracy: 0.77805 |  0:00:40s\n","epoch 30 | loss: 0.41562 | val_0_accuracy: 0.79468 |  0:00:41s\n","epoch 31 | loss: 0.41968 | val_0_accuracy: 0.81463 |  0:00:43s\n","epoch 32 | loss: 0.42277 | val_0_accuracy: 0.81712 |  0:00:44s\n","epoch 33 | loss: 0.41215 | val_0_accuracy: 0.81297 |  0:00:45s\n","epoch 34 | loss: 0.41573 | val_0_accuracy: 0.80299 |  0:00:47s\n","epoch 35 | loss: 0.41966 | val_0_accuracy: 0.81463 |  0:00:48s\n","epoch 36 | loss: 0.41864 | val_0_accuracy: 0.78969 |  0:00:49s\n","epoch 37 | loss: 0.41416 | val_0_accuracy: 0.82627 |  0:00:51s\n","epoch 38 | loss: 0.42441 | val_0_accuracy: 0.82294 |  0:00:52s\n","epoch 39 | loss: 0.40952 | val_0_accuracy: 0.79717 |  0:00:53s\n","epoch 40 | loss: 0.42149 | val_0_accuracy: 0.78221 |  0:00:55s\n","epoch 41 | loss: 0.42032 | val_0_accuracy: 0.80964 |  0:00:56s\n","epoch 42 | loss: 0.41019 | val_0_accuracy: 0.81796 |  0:00:57s\n","epoch 43 | loss: 0.4052  | val_0_accuracy: 0.82377 |  0:00:59s\n","epoch 44 | loss: 0.39376 | val_0_accuracy: 0.81796 |  0:01:00s\n","epoch 45 | loss: 0.39742 | val_0_accuracy: 0.83375 |  0:01:01s\n","epoch 46 | loss: 0.3938  | val_0_accuracy: 0.8271  |  0:01:03s\n","epoch 47 | loss: 0.39158 | val_0_accuracy: 0.83209 |  0:01:04s\n","epoch 48 | loss: 0.39745 | val_0_accuracy: 0.82211 |  0:01:05s\n","epoch 49 | loss: 0.39425 | val_0_accuracy: 0.8404  |  0:01:07s\n","epoch 50 | loss: 0.40501 | val_0_accuracy: 0.79468 |  0:01:08s\n","epoch 51 | loss: 0.40277 | val_0_accuracy: 0.80798 |  0:01:09s\n","epoch 52 | loss: 0.4014  | val_0_accuracy: 0.82377 |  0:01:11s\n","epoch 53 | loss: 0.39082 | val_0_accuracy: 0.8271  |  0:01:12s\n","epoch 54 | loss: 0.39068 | val_0_accuracy: 0.83126 |  0:01:14s\n","epoch 55 | loss: 0.38479 | val_0_accuracy: 0.8271  |  0:01:15s\n","epoch 56 | loss: 0.38492 | val_0_accuracy: 0.83707 |  0:01:16s\n","epoch 57 | loss: 0.38549 | val_0_accuracy: 0.83957 |  0:01:18s\n","epoch 58 | loss: 0.40015 | val_0_accuracy: 0.81879 |  0:01:19s\n","epoch 59 | loss: 0.40098 | val_0_accuracy: 0.8404  |  0:01:20s\n","\n","Early stopping occurred at epoch 59 with best_epoch = 49 and best_val_0_accuracy = 0.8404\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-07-06 05:40:21,661] Trial 5 finished with value: 0.8403990024937655 and parameters: {'n_d': 36, 'n_steps': 8, 'gamma': 1.6250838175803761, 'n_independent': 4, 'n_shared': 4, 'momentum': 0.3602789374634066}. Best is trial 3 with value: 0.8694929343308395.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 1.04753 | val_0_accuracy: 0.5852  |  0:00:00s\n","epoch 1  | loss: 0.67021 | val_0_accuracy: 0.54863 |  0:00:01s\n","epoch 2  | loss: 0.51975 | val_0_accuracy: 0.51039 |  0:00:02s\n","epoch 3  | loss: 0.4829  | val_0_accuracy: 0.54613 |  0:00:03s\n","epoch 4  | loss: 0.55877 | val_0_accuracy: 0.64505 |  0:00:03s\n","epoch 5  | loss: 0.52632 | val_0_accuracy: 0.65087 |  0:00:04s\n","epoch 6  | loss: 0.46928 | val_0_accuracy: 0.64256 |  0:00:05s\n","epoch 7  | loss: 0.44702 | val_0_accuracy: 0.62843 |  0:00:06s\n","epoch 8  | loss: 0.44668 | val_0_accuracy: 0.65586 |  0:00:06s\n","epoch 9  | loss: 0.43116 | val_0_accuracy: 0.60765 |  0:00:07s\n","epoch 10 | loss: 0.42083 | val_0_accuracy: 0.70241 |  0:00:08s\n","epoch 11 | loss: 0.41986 | val_0_accuracy: 0.69576 |  0:00:09s\n","epoch 12 | loss: 0.42208 | val_0_accuracy: 0.57357 |  0:00:09s\n","epoch 13 | loss: 0.41326 | val_0_accuracy: 0.71571 |  0:00:10s\n","epoch 14 | loss: 0.41573 | val_0_accuracy: 0.71322 |  0:00:11s\n","epoch 15 | loss: 0.41088 | val_0_accuracy: 0.68911 |  0:00:12s\n","epoch 16 | loss: 0.40025 | val_0_accuracy: 0.69244 |  0:00:12s\n","epoch 17 | loss: 0.40301 | val_0_accuracy: 0.70657 |  0:00:13s\n","epoch 18 | loss: 0.40648 | val_0_accuracy: 0.72153 |  0:00:14s\n","epoch 19 | loss: 0.41489 | val_0_accuracy: 0.73566 |  0:00:15s\n","epoch 20 | loss: 0.41292 | val_0_accuracy: 0.72569 |  0:00:15s\n","epoch 21 | loss: 0.40302 | val_0_accuracy: 0.75478 |  0:00:16s\n","epoch 22 | loss: 0.41334 | val_0_accuracy: 0.75478 |  0:00:17s\n","epoch 23 | loss: 0.41961 | val_0_accuracy: 0.6941  |  0:00:18s\n","epoch 24 | loss: 0.41974 | val_0_accuracy: 0.75062 |  0:00:18s\n","epoch 25 | loss: 0.4089  | val_0_accuracy: 0.75644 |  0:00:19s\n","epoch 26 | loss: 0.41113 | val_0_accuracy: 0.7581  |  0:00:20s\n","epoch 27 | loss: 0.4026  | val_0_accuracy: 0.7847  |  0:00:21s\n","epoch 28 | loss: 0.40563 | val_0_accuracy: 0.77805 |  0:00:21s\n","epoch 29 | loss: 0.40336 | val_0_accuracy: 0.77805 |  0:00:22s\n","epoch 30 | loss: 0.40175 | val_0_accuracy: 0.78554 |  0:00:23s\n","epoch 31 | loss: 0.40296 | val_0_accuracy: 0.79385 |  0:00:24s\n","epoch 32 | loss: 0.3979  | val_0_accuracy: 0.79634 |  0:00:24s\n","epoch 33 | loss: 0.38855 | val_0_accuracy: 0.78637 |  0:00:25s\n","epoch 34 | loss: 0.39463 | val_0_accuracy: 0.80964 |  0:00:26s\n","epoch 35 | loss: 0.39334 | val_0_accuracy: 0.81297 |  0:00:27s\n","epoch 36 | loss: 0.39664 | val_0_accuracy: 0.81297 |  0:00:27s\n","epoch 37 | loss: 0.38969 | val_0_accuracy: 0.81047 |  0:00:28s\n","epoch 38 | loss: 0.38407 | val_0_accuracy: 0.83042 |  0:00:29s\n","epoch 39 | loss: 0.37985 | val_0_accuracy: 0.83707 |  0:00:30s\n","epoch 40 | loss: 0.38268 | val_0_accuracy: 0.82128 |  0:00:30s\n","epoch 41 | loss: 0.38447 | val_0_accuracy: 0.83042 |  0:00:31s\n","epoch 42 | loss: 0.38703 | val_0_accuracy: 0.8138  |  0:00:32s\n","epoch 43 | loss: 0.38748 | val_0_accuracy: 0.81214 |  0:00:33s\n","epoch 44 | loss: 0.37745 | val_0_accuracy: 0.82876 |  0:00:33s\n","epoch 45 | loss: 0.37405 | val_0_accuracy: 0.83126 |  0:00:34s\n","epoch 46 | loss: 0.37438 | val_0_accuracy: 0.83209 |  0:00:35s\n","epoch 47 | loss: 0.37613 | val_0_accuracy: 0.82793 |  0:00:36s\n","epoch 48 | loss: 0.37031 | val_0_accuracy: 0.83541 |  0:00:37s\n","epoch 49 | loss: 0.37825 | val_0_accuracy: 0.83126 |  0:00:37s\n","\n","Early stopping occurred at epoch 49 with best_epoch = 39 and best_val_0_accuracy = 0.83707\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-07-06 05:40:59,907] Trial 6 finished with value: 0.8370739817123857 and parameters: {'n_d': 42, 'n_steps': 9, 'gamma': 1.2640206951267206, 'n_independent': 1, 'n_shared': 2, 'momentum': 0.28603045371527325}. Best is trial 3 with value: 0.8694929343308395.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 0.83014 | val_0_accuracy: 0.53367 |  0:00:00s\n","epoch 1  | loss: 0.54224 | val_0_accuracy: 0.60599 |  0:00:01s\n","epoch 2  | loss: 0.51614 | val_0_accuracy: 0.59601 |  0:00:01s\n","epoch 3  | loss: 0.50008 | val_0_accuracy: 0.57606 |  0:00:02s\n","epoch 4  | loss: 0.48405 | val_0_accuracy: 0.6251  |  0:00:03s\n","epoch 5  | loss: 0.46374 | val_0_accuracy: 0.63092 |  0:00:03s\n","epoch 6  | loss: 0.46387 | val_0_accuracy: 0.68246 |  0:00:04s\n","epoch 7  | loss: 0.44428 | val_0_accuracy: 0.70657 |  0:00:05s\n","epoch 8  | loss: 0.4462  | val_0_accuracy: 0.70241 |  0:00:05s\n","epoch 9  | loss: 0.43783 | val_0_accuracy: 0.69077 |  0:00:06s\n","epoch 10 | loss: 0.43267 | val_0_accuracy: 0.69576 |  0:00:07s\n","epoch 11 | loss: 0.43609 | val_0_accuracy: 0.7315  |  0:00:07s\n","epoch 12 | loss: 0.43697 | val_0_accuracy: 0.69659 |  0:00:08s\n","epoch 13 | loss: 0.42062 | val_0_accuracy: 0.69493 |  0:00:09s\n","epoch 14 | loss: 0.4232  | val_0_accuracy: 0.71322 |  0:00:09s\n","epoch 15 | loss: 0.41963 | val_0_accuracy: 0.72901 |  0:00:10s\n","epoch 16 | loss: 0.43037 | val_0_accuracy: 0.72569 |  0:00:10s\n","epoch 17 | loss: 0.42142 | val_0_accuracy: 0.73566 |  0:00:11s\n","epoch 18 | loss: 0.41559 | val_0_accuracy: 0.76226 |  0:00:12s\n","epoch 19 | loss: 0.41451 | val_0_accuracy: 0.75395 |  0:00:12s\n","epoch 20 | loss: 0.41421 | val_0_accuracy: 0.7739  |  0:00:13s\n","epoch 21 | loss: 0.40744 | val_0_accuracy: 0.76226 |  0:00:14s\n","epoch 22 | loss: 0.40121 | val_0_accuracy: 0.78138 |  0:00:14s\n","epoch 23 | loss: 0.41875 | val_0_accuracy: 0.77889 |  0:00:15s\n","epoch 24 | loss: 0.41406 | val_0_accuracy: 0.7714  |  0:00:16s\n","epoch 25 | loss: 0.41228 | val_0_accuracy: 0.77473 |  0:00:16s\n","epoch 26 | loss: 0.41042 | val_0_accuracy: 0.77639 |  0:00:17s\n","epoch 27 | loss: 0.41233 | val_0_accuracy: 0.78221 |  0:00:18s\n","epoch 28 | loss: 0.40748 | val_0_accuracy: 0.77972 |  0:00:18s\n","epoch 29 | loss: 0.39936 | val_0_accuracy: 0.77972 |  0:00:19s\n","epoch 30 | loss: 0.39605 | val_0_accuracy: 0.80382 |  0:00:19s\n","epoch 31 | loss: 0.40599 | val_0_accuracy: 0.78554 |  0:00:20s\n","epoch 32 | loss: 0.4003  | val_0_accuracy: 0.8005  |  0:00:21s\n","epoch 33 | loss: 0.40541 | val_0_accuracy: 0.81297 |  0:00:21s\n","epoch 34 | loss: 0.41466 | val_0_accuracy: 0.81047 |  0:00:22s\n","epoch 35 | loss: 0.40704 | val_0_accuracy: 0.81546 |  0:00:23s\n","epoch 36 | loss: 0.39838 | val_0_accuracy: 0.8138  |  0:00:23s\n","epoch 37 | loss: 0.41183 | val_0_accuracy: 0.79551 |  0:00:24s\n","epoch 38 | loss: 0.40077 | val_0_accuracy: 0.81546 |  0:00:25s\n","epoch 39 | loss: 0.40459 | val_0_accuracy: 0.8271  |  0:00:25s\n","epoch 40 | loss: 0.40063 | val_0_accuracy: 0.81962 |  0:00:26s\n","epoch 41 | loss: 0.40789 | val_0_accuracy: 0.79219 |  0:00:27s\n","epoch 42 | loss: 0.40214 | val_0_accuracy: 0.82461 |  0:00:27s\n","epoch 43 | loss: 0.39408 | val_0_accuracy: 0.83126 |  0:00:28s\n","epoch 44 | loss: 0.38938 | val_0_accuracy: 0.82959 |  0:00:29s\n","epoch 45 | loss: 0.39329 | val_0_accuracy: 0.8271  |  0:00:29s\n","epoch 46 | loss: 0.38816 | val_0_accuracy: 0.83957 |  0:00:30s\n","epoch 47 | loss: 0.38653 | val_0_accuracy: 0.83707 |  0:00:31s\n","epoch 48 | loss: 0.39432 | val_0_accuracy: 0.83126 |  0:00:31s\n","epoch 49 | loss: 0.40409 | val_0_accuracy: 0.82876 |  0:00:32s\n","epoch 50 | loss: 0.41015 | val_0_accuracy: 0.81047 |  0:00:32s\n","epoch 51 | loss: 0.40594 | val_0_accuracy: 0.82627 |  0:00:33s\n","epoch 52 | loss: 0.402   | val_0_accuracy: 0.82627 |  0:00:34s\n","epoch 53 | loss: 0.39563 | val_0_accuracy: 0.82793 |  0:00:34s\n","epoch 54 | loss: 0.3916  | val_0_accuracy: 0.83042 |  0:00:35s\n","epoch 55 | loss: 0.39535 | val_0_accuracy: 0.82377 |  0:00:36s\n","epoch 56 | loss: 0.38576 | val_0_accuracy: 0.83541 |  0:00:36s\n","\n","Early stopping occurred at epoch 56 with best_epoch = 46 and best_val_0_accuracy = 0.83957\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-07-06 05:41:37,064] Trial 7 finished with value: 0.8395677472984207 and parameters: {'n_d': 33, 'n_steps': 6, 'gamma': 1.6994433701950984, 'n_independent': 1, 'n_shared': 3, 'momentum': 0.1844748636663444}. Best is trial 3 with value: 0.8694929343308395.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 1.5626  | val_0_accuracy: 0.51372 |  0:00:01s\n","epoch 1  | loss: 0.71282 | val_0_accuracy: 0.55029 |  0:00:02s\n","epoch 2  | loss: 0.56774 | val_0_accuracy: 0.52702 |  0:00:03s\n","epoch 3  | loss: 0.51287 | val_0_accuracy: 0.53283 |  0:00:04s\n","epoch 4  | loss: 0.50826 | val_0_accuracy: 0.56775 |  0:00:05s\n","epoch 5  | loss: 0.49405 | val_0_accuracy: 0.61845 |  0:00:06s\n","epoch 6  | loss: 0.48163 | val_0_accuracy: 0.6276  |  0:00:07s\n","epoch 7  | loss: 0.48195 | val_0_accuracy: 0.56608 |  0:00:08s\n","epoch 8  | loss: 0.5138  | val_0_accuracy: 0.63259 |  0:00:09s\n","epoch 9  | loss: 0.54744 | val_0_accuracy: 0.55112 |  0:00:10s\n","epoch 10 | loss: 0.49639 | val_0_accuracy: 0.67997 |  0:00:11s\n","epoch 11 | loss: 0.47889 | val_0_accuracy: 0.62926 |  0:00:12s\n","epoch 12 | loss: 0.4726  | val_0_accuracy: 0.65835 |  0:00:13s\n","epoch 13 | loss: 0.47931 | val_0_accuracy: 0.72153 |  0:00:14s\n","epoch 14 | loss: 0.44982 | val_0_accuracy: 0.66916 |  0:00:15s\n","epoch 15 | loss: 0.44375 | val_0_accuracy: 0.70241 |  0:00:16s\n","epoch 16 | loss: 0.426   | val_0_accuracy: 0.73982 |  0:00:17s\n","epoch 17 | loss: 0.41551 | val_0_accuracy: 0.73815 |  0:00:18s\n","epoch 18 | loss: 0.42151 | val_0_accuracy: 0.69659 |  0:00:19s\n","epoch 19 | loss: 0.4299  | val_0_accuracy: 0.74647 |  0:00:20s\n","epoch 20 | loss: 0.42063 | val_0_accuracy: 0.7606  |  0:00:22s\n","epoch 21 | loss: 0.41608 | val_0_accuracy: 0.74813 |  0:00:23s\n","epoch 22 | loss: 0.42028 | val_0_accuracy: 0.73317 |  0:00:24s\n","epoch 23 | loss: 0.43168 | val_0_accuracy: 0.74148 |  0:00:25s\n","epoch 24 | loss: 0.43644 | val_0_accuracy: 0.74397 |  0:00:26s\n","epoch 25 | loss: 0.42286 | val_0_accuracy: 0.76974 |  0:00:27s\n","epoch 26 | loss: 0.42383 | val_0_accuracy: 0.77722 |  0:00:28s\n","epoch 27 | loss: 0.42139 | val_0_accuracy: 0.80382 |  0:00:29s\n","epoch 28 | loss: 0.42541 | val_0_accuracy: 0.76143 |  0:00:30s\n","epoch 29 | loss: 0.41632 | val_0_accuracy: 0.78554 |  0:00:31s\n","epoch 30 | loss: 0.40401 | val_0_accuracy: 0.79717 |  0:00:32s\n","epoch 31 | loss: 0.40521 | val_0_accuracy: 0.80133 |  0:00:33s\n","epoch 32 | loss: 0.41814 | val_0_accuracy: 0.81712 |  0:00:34s\n","epoch 33 | loss: 0.41069 | val_0_accuracy: 0.81712 |  0:00:35s\n","epoch 34 | loss: 0.40628 | val_0_accuracy: 0.82294 |  0:00:36s\n","epoch 35 | loss: 0.41326 | val_0_accuracy: 0.82211 |  0:00:37s\n","epoch 36 | loss: 0.40172 | val_0_accuracy: 0.81962 |  0:00:38s\n","epoch 37 | loss: 0.39489 | val_0_accuracy: 0.82461 |  0:00:39s\n","epoch 38 | loss: 0.39161 | val_0_accuracy: 0.82544 |  0:00:40s\n","epoch 39 | loss: 0.38915 | val_0_accuracy: 0.82544 |  0:00:41s\n","epoch 40 | loss: 0.37848 | val_0_accuracy: 0.83042 |  0:00:42s\n","epoch 41 | loss: 0.38325 | val_0_accuracy: 0.82294 |  0:00:44s\n","epoch 42 | loss: 0.38642 | val_0_accuracy: 0.83292 |  0:00:45s\n","epoch 43 | loss: 0.37965 | val_0_accuracy: 0.82876 |  0:00:46s\n","epoch 44 | loss: 0.3743  | val_0_accuracy: 0.83209 |  0:00:47s\n","epoch 45 | loss: 0.37211 | val_0_accuracy: 0.82294 |  0:00:48s\n","epoch 46 | loss: 0.37467 | val_0_accuracy: 0.83042 |  0:00:49s\n","epoch 47 | loss: 0.37767 | val_0_accuracy: 0.83541 |  0:00:50s\n","epoch 48 | loss: 0.37266 | val_0_accuracy: 0.8404  |  0:00:51s\n","epoch 49 | loss: 0.37444 | val_0_accuracy: 0.84539 |  0:00:52s\n","epoch 50 | loss: 0.37005 | val_0_accuracy: 0.83707 |  0:00:53s\n","epoch 51 | loss: 0.37446 | val_0_accuracy: 0.83791 |  0:00:54s\n","epoch 52 | loss: 0.37661 | val_0_accuracy: 0.82876 |  0:00:55s\n","epoch 53 | loss: 0.37731 | val_0_accuracy: 0.84206 |  0:00:56s\n","epoch 54 | loss: 0.37391 | val_0_accuracy: 0.83874 |  0:00:57s\n","epoch 55 | loss: 0.3694  | val_0_accuracy: 0.83874 |  0:00:58s\n","epoch 56 | loss: 0.37531 | val_0_accuracy: 0.84954 |  0:00:59s\n","epoch 57 | loss: 0.3694  | val_0_accuracy: 0.84456 |  0:01:01s\n","epoch 58 | loss: 0.37346 | val_0_accuracy: 0.83707 |  0:01:02s\n","epoch 59 | loss: 0.36556 | val_0_accuracy: 0.84622 |  0:01:03s\n","epoch 60 | loss: 0.37069 | val_0_accuracy: 0.84123 |  0:01:04s\n","epoch 61 | loss: 0.37793 | val_0_accuracy: 0.83126 |  0:01:05s\n","epoch 62 | loss: 0.37864 | val_0_accuracy: 0.82793 |  0:01:06s\n","epoch 63 | loss: 0.37625 | val_0_accuracy: 0.83541 |  0:01:07s\n","epoch 64 | loss: 0.37868 | val_0_accuracy: 0.83791 |  0:01:08s\n","epoch 65 | loss: 0.37678 | val_0_accuracy: 0.83874 |  0:01:09s\n","epoch 66 | loss: 0.36653 | val_0_accuracy: 0.84206 |  0:01:10s\n","\n","Early stopping occurred at epoch 66 with best_epoch = 56 and best_val_0_accuracy = 0.84954\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-07-06 05:42:48,055] Trial 8 finished with value: 0.8495428096425602 and parameters: {'n_d': 10, 'n_steps': 9, 'gamma': 1.29439791141874, 'n_independent': 3, 'n_shared': 2, 'momentum': 0.1413525352788493}. Best is trial 3 with value: 0.8694929343308395.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 1.1813  | val_0_accuracy: 0.52037 |  0:00:01s\n","epoch 1  | loss: 0.69494 | val_0_accuracy: 0.62095 |  0:00:02s\n","epoch 2  | loss: 0.70057 | val_0_accuracy: 0.62012 |  0:00:03s\n","epoch 3  | loss: 0.61492 | val_0_accuracy: 0.58105 |  0:00:05s\n","epoch 4  | loss: 0.66532 | val_0_accuracy: 0.61513 |  0:00:06s\n","epoch 5  | loss: 0.61474 | val_0_accuracy: 0.54447 |  0:00:07s\n","epoch 6  | loss: 0.6986  | val_0_accuracy: 0.58853 |  0:00:09s\n","epoch 7  | loss: 0.63329 | val_0_accuracy: 0.69077 |  0:00:10s\n","epoch 8  | loss: 0.57483 | val_0_accuracy: 0.68579 |  0:00:11s\n","epoch 9  | loss: 0.50171 | val_0_accuracy: 0.70823 |  0:00:13s\n","epoch 10 | loss: 0.46787 | val_0_accuracy: 0.65835 |  0:00:14s\n","epoch 11 | loss: 0.45319 | val_0_accuracy: 0.72818 |  0:00:16s\n","epoch 12 | loss: 0.44278 | val_0_accuracy: 0.734   |  0:00:17s\n","epoch 13 | loss: 0.4297  | val_0_accuracy: 0.72569 |  0:00:18s\n","epoch 14 | loss: 0.42454 | val_0_accuracy: 0.72984 |  0:00:20s\n","epoch 15 | loss: 0.44125 | val_0_accuracy: 0.75145 |  0:00:21s\n","epoch 16 | loss: 0.43213 | val_0_accuracy: 0.74564 |  0:00:22s\n","epoch 17 | loss: 0.42229 | val_0_accuracy: 0.74896 |  0:00:24s\n","epoch 18 | loss: 0.41714 | val_0_accuracy: 0.74397 |  0:00:25s\n","epoch 19 | loss: 0.41546 | val_0_accuracy: 0.75145 |  0:00:26s\n","epoch 20 | loss: 0.40461 | val_0_accuracy: 0.73317 |  0:00:28s\n","epoch 21 | loss: 0.39933 | val_0_accuracy: 0.7473  |  0:00:29s\n","epoch 22 | loss: 0.39786 | val_0_accuracy: 0.76309 |  0:00:30s\n","epoch 23 | loss: 0.40027 | val_0_accuracy: 0.75229 |  0:00:32s\n","epoch 24 | loss: 0.41205 | val_0_accuracy: 0.75727 |  0:00:33s\n","epoch 25 | loss: 0.41132 | val_0_accuracy: 0.78138 |  0:00:34s\n","epoch 26 | loss: 0.40742 | val_0_accuracy: 0.77805 |  0:00:36s\n","epoch 27 | loss: 0.40572 | val_0_accuracy: 0.79468 |  0:00:37s\n","epoch 28 | loss: 0.40476 | val_0_accuracy: 0.78221 |  0:00:38s\n","epoch 29 | loss: 0.40291 | val_0_accuracy: 0.79385 |  0:00:40s\n","epoch 30 | loss: 0.40254 | val_0_accuracy: 0.798   |  0:00:41s\n","epoch 31 | loss: 0.4022  | val_0_accuracy: 0.78387 |  0:00:42s\n","epoch 32 | loss: 0.43358 | val_0_accuracy: 0.74564 |  0:00:44s\n","epoch 33 | loss: 0.42628 | val_0_accuracy: 0.78304 |  0:00:45s\n","epoch 34 | loss: 0.4128  | val_0_accuracy: 0.81546 |  0:00:46s\n","epoch 35 | loss: 0.42421 | val_0_accuracy: 0.81214 |  0:00:48s\n","epoch 36 | loss: 0.41997 | val_0_accuracy: 0.80549 |  0:00:49s\n","epoch 37 | loss: 0.40612 | val_0_accuracy: 0.81463 |  0:00:50s\n","epoch 38 | loss: 0.39903 | val_0_accuracy: 0.81297 |  0:00:51s\n","epoch 39 | loss: 0.39961 | val_0_accuracy: 0.82959 |  0:00:53s\n","epoch 40 | loss: 0.3937  | val_0_accuracy: 0.8271  |  0:00:54s\n","epoch 41 | loss: 0.39812 | val_0_accuracy: 0.8271  |  0:00:56s\n","epoch 42 | loss: 0.3924  | val_0_accuracy: 0.81546 |  0:00:57s\n","epoch 43 | loss: 0.39783 | val_0_accuracy: 0.81712 |  0:00:58s\n","epoch 44 | loss: 0.40056 | val_0_accuracy: 0.8271  |  0:00:59s\n","epoch 45 | loss: 0.39275 | val_0_accuracy: 0.82544 |  0:01:01s\n","epoch 46 | loss: 0.38909 | val_0_accuracy: 0.83541 |  0:01:02s\n","epoch 47 | loss: 0.38606 | val_0_accuracy: 0.82544 |  0:01:03s\n","epoch 48 | loss: 0.39559 | val_0_accuracy: 0.82627 |  0:01:05s\n","epoch 49 | loss: 0.40258 | val_0_accuracy: 0.83375 |  0:01:06s\n","epoch 50 | loss: 0.39805 | val_0_accuracy: 0.83707 |  0:01:08s\n","epoch 51 | loss: 0.39292 | val_0_accuracy: 0.83209 |  0:01:09s\n","epoch 52 | loss: 0.39348 | val_0_accuracy: 0.83375 |  0:01:10s\n","epoch 53 | loss: 0.38762 | val_0_accuracy: 0.83375 |  0:01:11s\n","epoch 54 | loss: 0.38564 | val_0_accuracy: 0.83375 |  0:01:13s\n","epoch 55 | loss: 0.37909 | val_0_accuracy: 0.84622 |  0:01:14s\n","epoch 56 | loss: 0.3813  | val_0_accuracy: 0.84372 |  0:01:15s\n","epoch 57 | loss: 0.37447 | val_0_accuracy: 0.85037 |  0:01:17s\n","epoch 58 | loss: 0.37636 | val_0_accuracy: 0.84954 |  0:01:18s\n","epoch 59 | loss: 0.38458 | val_0_accuracy: 0.84539 |  0:01:20s\n","epoch 60 | loss: 0.39077 | val_0_accuracy: 0.84123 |  0:01:21s\n","epoch 61 | loss: 0.39653 | val_0_accuracy: 0.82544 |  0:01:22s\n","epoch 62 | loss: 0.38683 | val_0_accuracy: 0.84206 |  0:01:23s\n","epoch 63 | loss: 0.37774 | val_0_accuracy: 0.84788 |  0:01:25s\n","epoch 64 | loss: 0.37732 | val_0_accuracy: 0.84871 |  0:01:26s\n","epoch 65 | loss: 0.37389 | val_0_accuracy: 0.85121 |  0:01:27s\n","epoch 66 | loss: 0.37004 | val_0_accuracy: 0.85037 |  0:01:29s\n","epoch 67 | loss: 0.37063 | val_0_accuracy: 0.84871 |  0:01:30s\n","epoch 68 | loss: 0.37053 | val_0_accuracy: 0.85536 |  0:01:31s\n","epoch 69 | loss: 0.36563 | val_0_accuracy: 0.84788 |  0:01:33s\n","epoch 70 | loss: 0.36521 | val_0_accuracy: 0.85702 |  0:01:34s\n","epoch 71 | loss: 0.3696  | val_0_accuracy: 0.84456 |  0:01:36s\n","epoch 72 | loss: 0.37427 | val_0_accuracy: 0.84539 |  0:01:37s\n","epoch 73 | loss: 0.36582 | val_0_accuracy: 0.85037 |  0:01:38s\n","epoch 74 | loss: 0.3645  | val_0_accuracy: 0.84788 |  0:01:39s\n","epoch 75 | loss: 0.36717 | val_0_accuracy: 0.85287 |  0:01:41s\n","epoch 76 | loss: 0.36652 | val_0_accuracy: 0.83791 |  0:01:42s\n","epoch 77 | loss: 0.37004 | val_0_accuracy: 0.84788 |  0:01:43s\n","epoch 78 | loss: 0.36896 | val_0_accuracy: 0.83874 |  0:01:45s\n","epoch 79 | loss: 0.37205 | val_0_accuracy: 0.84539 |  0:01:46s\n","epoch 80 | loss: 0.36823 | val_0_accuracy: 0.84289 |  0:01:47s\n","\n","Early stopping occurred at epoch 80 with best_epoch = 70 and best_val_0_accuracy = 0.85702\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-07-06 05:44:36,692] Trial 9 finished with value: 0.857024106400665 and parameters: {'n_d': 61, 'n_steps': 10, 'gamma': 1.5785239003847829, 'n_independent': 3, 'n_shared': 3, 'momentum': 0.12857214485082646}. Best is trial 3 with value: 0.8694929343308395.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 0.67606 | val_0_accuracy: 0.51455 |  0:00:00s\n","epoch 1  | loss: 0.50438 | val_0_accuracy: 0.51538 |  0:00:01s\n","epoch 2  | loss: 0.45785 | val_0_accuracy: 0.4788  |  0:00:02s\n","epoch 3  | loss: 0.41833 | val_0_accuracy: 0.51787 |  0:00:03s\n","epoch 4  | loss: 0.39746 | val_0_accuracy: 0.52203 |  0:00:03s\n","epoch 5  | loss: 0.3853  | val_0_accuracy: 0.5345  |  0:00:04s\n","epoch 6  | loss: 0.38022 | val_0_accuracy: 0.52452 |  0:00:05s\n","epoch 7  | loss: 0.37403 | val_0_accuracy: 0.54281 |  0:00:06s\n","epoch 8  | loss: 0.3652  | val_0_accuracy: 0.59185 |  0:00:06s\n","epoch 9  | loss: 0.35858 | val_0_accuracy: 0.51704 |  0:00:07s\n","epoch 10 | loss: 0.36031 | val_0_accuracy: 0.57273 |  0:00:08s\n","epoch 11 | loss: 0.35818 | val_0_accuracy: 0.5453  |  0:00:09s\n","epoch 12 | loss: 0.34881 | val_0_accuracy: 0.54032 |  0:00:09s\n","epoch 13 | loss: 0.34835 | val_0_accuracy: 0.56941 |  0:00:10s\n","epoch 14 | loss: 0.34518 | val_0_accuracy: 0.71904 |  0:00:11s\n","epoch 15 | loss: 0.34387 | val_0_accuracy: 0.68412 |  0:00:12s\n","epoch 16 | loss: 0.3402  | val_0_accuracy: 0.64838 |  0:00:12s\n","epoch 17 | loss: 0.3401  | val_0_accuracy: 0.63092 |  0:00:13s\n","epoch 18 | loss: 0.33797 | val_0_accuracy: 0.61513 |  0:00:14s\n","epoch 19 | loss: 0.33313 | val_0_accuracy: 0.67082 |  0:00:15s\n","epoch 20 | loss: 0.33765 | val_0_accuracy: 0.66251 |  0:00:15s\n","epoch 21 | loss: 0.33589 | val_0_accuracy: 0.74231 |  0:00:16s\n","epoch 22 | loss: 0.33364 | val_0_accuracy: 0.74896 |  0:00:17s\n","epoch 23 | loss: 0.32855 | val_0_accuracy: 0.74564 |  0:00:18s\n","epoch 24 | loss: 0.32942 | val_0_accuracy: 0.77972 |  0:00:18s\n","epoch 25 | loss: 0.33144 | val_0_accuracy: 0.7581  |  0:00:19s\n","epoch 26 | loss: 0.33522 | val_0_accuracy: 0.78803 |  0:00:20s\n","epoch 27 | loss: 0.33364 | val_0_accuracy: 0.77556 |  0:00:21s\n","epoch 28 | loss: 0.32565 | val_0_accuracy: 0.78637 |  0:00:21s\n","epoch 29 | loss: 0.32469 | val_0_accuracy: 0.81879 |  0:00:22s\n","epoch 30 | loss: 0.323   | val_0_accuracy: 0.80299 |  0:00:23s\n","epoch 31 | loss: 0.32695 | val_0_accuracy: 0.81214 |  0:00:24s\n","epoch 32 | loss: 0.32627 | val_0_accuracy: 0.82959 |  0:00:24s\n","epoch 33 | loss: 0.32103 | val_0_accuracy: 0.84206 |  0:00:25s\n","epoch 34 | loss: 0.31825 | val_0_accuracy: 0.8404  |  0:00:26s\n","epoch 35 | loss: 0.32078 | val_0_accuracy: 0.84622 |  0:00:27s\n","epoch 36 | loss: 0.32312 | val_0_accuracy: 0.85453 |  0:00:27s\n","epoch 37 | loss: 0.3166  | val_0_accuracy: 0.82627 |  0:00:28s\n","epoch 38 | loss: 0.31799 | val_0_accuracy: 0.85037 |  0:00:29s\n","epoch 39 | loss: 0.32065 | val_0_accuracy: 0.84705 |  0:00:30s\n","epoch 40 | loss: 0.31991 | val_0_accuracy: 0.85786 |  0:00:30s\n","epoch 41 | loss: 0.32015 | val_0_accuracy: 0.84289 |  0:00:31s\n","epoch 42 | loss: 0.31559 | val_0_accuracy: 0.85619 |  0:00:32s\n","epoch 43 | loss: 0.31521 | val_0_accuracy: 0.86118 |  0:00:33s\n","epoch 44 | loss: 0.31178 | val_0_accuracy: 0.85952 |  0:00:33s\n","epoch 45 | loss: 0.31234 | val_0_accuracy: 0.85204 |  0:00:34s\n","epoch 46 | loss: 0.31507 | val_0_accuracy: 0.85204 |  0:00:35s\n","epoch 47 | loss: 0.31166 | val_0_accuracy: 0.85952 |  0:00:36s\n","epoch 48 | loss: 0.31455 | val_0_accuracy: 0.85702 |  0:00:36s\n","epoch 49 | loss: 0.31113 | val_0_accuracy: 0.86367 |  0:00:37s\n","epoch 50 | loss: 0.30607 | val_0_accuracy: 0.85287 |  0:00:38s\n","epoch 51 | loss: 0.30653 | val_0_accuracy: 0.85786 |  0:00:39s\n","epoch 52 | loss: 0.30813 | val_0_accuracy: 0.86284 |  0:00:39s\n","epoch 53 | loss: 0.30836 | val_0_accuracy: 0.85869 |  0:00:40s\n","epoch 54 | loss: 0.30411 | val_0_accuracy: 0.85786 |  0:00:41s\n","epoch 55 | loss: 0.30672 | val_0_accuracy: 0.86534 |  0:00:42s\n","epoch 56 | loss: 0.30196 | val_0_accuracy: 0.86201 |  0:00:42s\n","epoch 57 | loss: 0.30098 | val_0_accuracy: 0.86118 |  0:00:43s\n","epoch 58 | loss: 0.30277 | val_0_accuracy: 0.85619 |  0:00:44s\n","epoch 59 | loss: 0.3001  | val_0_accuracy: 0.85453 |  0:00:45s\n","epoch 60 | loss: 0.29989 | val_0_accuracy: 0.85453 |  0:00:45s\n","epoch 61 | loss: 0.30529 | val_0_accuracy: 0.86035 |  0:00:46s\n","epoch 62 | loss: 0.29851 | val_0_accuracy: 0.86118 |  0:00:47s\n","epoch 63 | loss: 0.29758 | val_0_accuracy: 0.86284 |  0:00:48s\n","epoch 64 | loss: 0.29526 | val_0_accuracy: 0.86118 |  0:00:48s\n","epoch 65 | loss: 0.29155 | val_0_accuracy: 0.86534 |  0:00:49s\n","\n","Early stopping occurred at epoch 65 with best_epoch = 55 and best_val_0_accuracy = 0.86534\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-07-06 05:45:26,706] Trial 10 finished with value: 0.8653366583541147 and parameters: {'n_d': 25, 'n_steps': 3, 'gamma': 1.0073594316332035, 'n_independent': 5, 'n_shared': 5, 'momentum': 0.04801222270796718}. Best is trial 3 with value: 0.8694929343308395.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 0.66582 | val_0_accuracy: 0.49875 |  0:00:00s\n","epoch 1  | loss: 0.49644 | val_0_accuracy: 0.51122 |  0:00:01s\n","epoch 2  | loss: 0.4634  | val_0_accuracy: 0.53117 |  0:00:02s\n","epoch 3  | loss: 0.4295  | val_0_accuracy: 0.52868 |  0:00:03s\n","epoch 4  | loss: 0.41467 | val_0_accuracy: 0.51787 |  0:00:03s\n","epoch 5  | loss: 0.40135 | val_0_accuracy: 0.53117 |  0:00:04s\n","epoch 6  | loss: 0.38683 | val_0_accuracy: 0.62843 |  0:00:05s\n","epoch 7  | loss: 0.37575 | val_0_accuracy: 0.67747 |  0:00:06s\n","epoch 8  | loss: 0.37577 | val_0_accuracy: 0.69825 |  0:00:06s\n","epoch 9  | loss: 0.36857 | val_0_accuracy: 0.68163 |  0:00:07s\n","epoch 10 | loss: 0.35474 | val_0_accuracy: 0.69742 |  0:00:08s\n","epoch 11 | loss: 0.35647 | val_0_accuracy: 0.70823 |  0:00:09s\n","epoch 12 | loss: 0.3596  | val_0_accuracy: 0.68662 |  0:00:09s\n","epoch 13 | loss: 0.34856 | val_0_accuracy: 0.6808  |  0:00:10s\n","epoch 14 | loss: 0.34031 | val_0_accuracy: 0.72569 |  0:00:11s\n","epoch 15 | loss: 0.34457 | val_0_accuracy: 0.69825 |  0:00:12s\n","epoch 16 | loss: 0.33847 | val_0_accuracy: 0.74314 |  0:00:12s\n","epoch 17 | loss: 0.3472  | val_0_accuracy: 0.7315  |  0:00:13s\n","epoch 18 | loss: 0.3385  | val_0_accuracy: 0.74065 |  0:00:14s\n","epoch 19 | loss: 0.33392 | val_0_accuracy: 0.71571 |  0:00:15s\n","epoch 20 | loss: 0.33225 | val_0_accuracy: 0.72153 |  0:00:15s\n","epoch 21 | loss: 0.33116 | val_0_accuracy: 0.75062 |  0:00:16s\n","epoch 22 | loss: 0.33568 | val_0_accuracy: 0.77224 |  0:00:17s\n","epoch 23 | loss: 0.33327 | val_0_accuracy: 0.77972 |  0:00:18s\n","epoch 24 | loss: 0.32646 | val_0_accuracy: 0.74896 |  0:00:18s\n","epoch 25 | loss: 0.32418 | val_0_accuracy: 0.77972 |  0:00:19s\n","epoch 26 | loss: 0.32499 | val_0_accuracy: 0.77307 |  0:00:20s\n","epoch 27 | loss: 0.32311 | val_0_accuracy: 0.82211 |  0:00:20s\n","epoch 28 | loss: 0.32053 | val_0_accuracy: 0.79385 |  0:00:21s\n","epoch 29 | loss: 0.31828 | val_0_accuracy: 0.80133 |  0:00:22s\n","epoch 30 | loss: 0.31721 | val_0_accuracy: 0.81131 |  0:00:23s\n","epoch 31 | loss: 0.31551 | val_0_accuracy: 0.81962 |  0:00:23s\n","epoch 32 | loss: 0.31686 | val_0_accuracy: 0.82128 |  0:00:24s\n","epoch 33 | loss: 0.31878 | val_0_accuracy: 0.84372 |  0:00:25s\n","epoch 34 | loss: 0.32268 | val_0_accuracy: 0.84788 |  0:00:26s\n","epoch 35 | loss: 0.31989 | val_0_accuracy: 0.8404  |  0:00:26s\n","epoch 36 | loss: 0.31232 | val_0_accuracy: 0.79219 |  0:00:27s\n","epoch 37 | loss: 0.31097 | val_0_accuracy: 0.84871 |  0:00:28s\n","epoch 38 | loss: 0.30932 | val_0_accuracy: 0.83126 |  0:00:29s\n","epoch 39 | loss: 0.31246 | val_0_accuracy: 0.84622 |  0:00:29s\n","epoch 40 | loss: 0.31776 | val_0_accuracy: 0.84456 |  0:00:30s\n","epoch 41 | loss: 0.3138  | val_0_accuracy: 0.83458 |  0:00:31s\n","epoch 42 | loss: 0.32044 | val_0_accuracy: 0.84206 |  0:00:32s\n","epoch 43 | loss: 0.32367 | val_0_accuracy: 0.85952 |  0:00:32s\n","epoch 44 | loss: 0.31581 | val_0_accuracy: 0.85287 |  0:00:33s\n","epoch 45 | loss: 0.31116 | val_0_accuracy: 0.84871 |  0:00:34s\n","epoch 46 | loss: 0.30766 | val_0_accuracy: 0.85037 |  0:00:35s\n","epoch 47 | loss: 0.31085 | val_0_accuracy: 0.85952 |  0:00:35s\n","epoch 48 | loss: 0.30765 | val_0_accuracy: 0.85453 |  0:00:36s\n","epoch 49 | loss: 0.30855 | val_0_accuracy: 0.82461 |  0:00:37s\n","epoch 50 | loss: 0.30051 | val_0_accuracy: 0.86201 |  0:00:37s\n","epoch 51 | loss: 0.30245 | val_0_accuracy: 0.86035 |  0:00:38s\n","epoch 52 | loss: 0.30548 | val_0_accuracy: 0.86201 |  0:00:39s\n","epoch 53 | loss: 0.30174 | val_0_accuracy: 0.85121 |  0:00:40s\n","epoch 54 | loss: 0.30085 | val_0_accuracy: 0.86617 |  0:00:40s\n","epoch 55 | loss: 0.29934 | val_0_accuracy: 0.84788 |  0:00:41s\n","epoch 56 | loss: 0.29793 | val_0_accuracy: 0.86035 |  0:00:42s\n","epoch 57 | loss: 0.29583 | val_0_accuracy: 0.84289 |  0:00:43s\n","epoch 58 | loss: 0.29481 | val_0_accuracy: 0.86949 |  0:00:43s\n","epoch 59 | loss: 0.30016 | val_0_accuracy: 0.85702 |  0:00:44s\n","epoch 60 | loss: 0.29278 | val_0_accuracy: 0.85287 |  0:00:45s\n","epoch 61 | loss: 0.29321 | val_0_accuracy: 0.85619 |  0:00:46s\n","epoch 62 | loss: 0.28861 | val_0_accuracy: 0.84622 |  0:00:46s\n","epoch 63 | loss: 0.29656 | val_0_accuracy: 0.867   |  0:00:47s\n","epoch 64 | loss: 0.28738 | val_0_accuracy: 0.86284 |  0:00:48s\n","epoch 65 | loss: 0.29186 | val_0_accuracy: 0.86035 |  0:00:49s\n","epoch 66 | loss: 0.29126 | val_0_accuracy: 0.85204 |  0:00:49s\n","epoch 67 | loss: 0.28995 | val_0_accuracy: 0.85702 |  0:00:50s\n","epoch 68 | loss: 0.28336 | val_0_accuracy: 0.83957 |  0:00:51s\n","\n","Early stopping occurred at epoch 68 with best_epoch = 58 and best_val_0_accuracy = 0.86949\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-07-06 05:46:18,452] Trial 11 finished with value: 0.8694929343308395 and parameters: {'n_d': 24, 'n_steps': 3, 'gamma': 1.0135342336674185, 'n_independent': 5, 'n_shared': 5, 'momentum': 0.01341722140300261}. Best is trial 3 with value: 0.8694929343308395.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 0.70531 | val_0_accuracy: 0.53283 |  0:00:00s\n","epoch 1  | loss: 0.53014 | val_0_accuracy: 0.51621 |  0:00:01s\n","epoch 2  | loss: 0.50079 | val_0_accuracy: 0.52868 |  0:00:02s\n","epoch 3  | loss: 0.47174 | val_0_accuracy: 0.5586  |  0:00:04s\n","epoch 4  | loss: 0.44935 | val_0_accuracy: 0.52203 |  0:00:05s\n","epoch 5  | loss: 0.43711 | val_0_accuracy: 0.54613 |  0:00:06s\n","epoch 6  | loss: 0.40749 | val_0_accuracy: 0.62344 |  0:00:07s\n","epoch 7  | loss: 0.39119 | val_0_accuracy: 0.56525 |  0:00:08s\n","epoch 8  | loss: 0.3934  | val_0_accuracy: 0.53616 |  0:00:09s\n","epoch 9  | loss: 0.38047 | val_0_accuracy: 0.54946 |  0:00:09s\n","epoch 10 | loss: 0.37956 | val_0_accuracy: 0.58437 |  0:00:10s\n","epoch 11 | loss: 0.37437 | val_0_accuracy: 0.60682 |  0:00:11s\n","epoch 12 | loss: 0.37235 | val_0_accuracy: 0.59684 |  0:00:12s\n","epoch 13 | loss: 0.37601 | val_0_accuracy: 0.65254 |  0:00:13s\n","epoch 14 | loss: 0.36923 | val_0_accuracy: 0.67249 |  0:00:14s\n","epoch 15 | loss: 0.3642  | val_0_accuracy: 0.68163 |  0:00:15s\n","epoch 16 | loss: 0.36577 | val_0_accuracy: 0.69576 |  0:00:16s\n","epoch 17 | loss: 0.36372 | val_0_accuracy: 0.70324 |  0:00:17s\n","epoch 18 | loss: 0.35426 | val_0_accuracy: 0.73732 |  0:00:18s\n","epoch 19 | loss: 0.36033 | val_0_accuracy: 0.73483 |  0:00:19s\n","epoch 20 | loss: 0.36347 | val_0_accuracy: 0.76309 |  0:00:20s\n","epoch 21 | loss: 0.3601  | val_0_accuracy: 0.76808 |  0:00:21s\n","epoch 22 | loss: 0.35344 | val_0_accuracy: 0.77639 |  0:00:22s\n","epoch 23 | loss: 0.3541  | val_0_accuracy: 0.76475 |  0:00:23s\n","epoch 24 | loss: 0.34616 | val_0_accuracy: 0.77224 |  0:00:24s\n","epoch 25 | loss: 0.34828 | val_0_accuracy: 0.78803 |  0:00:25s\n","epoch 26 | loss: 0.34619 | val_0_accuracy: 0.78387 |  0:00:27s\n","epoch 27 | loss: 0.34563 | val_0_accuracy: 0.79967 |  0:00:27s\n","epoch 28 | loss: 0.34881 | val_0_accuracy: 0.80133 |  0:00:28s\n","epoch 29 | loss: 0.34665 | val_0_accuracy: 0.82793 |  0:00:29s\n","epoch 30 | loss: 0.35295 | val_0_accuracy: 0.81463 |  0:00:30s\n","epoch 31 | loss: 0.34793 | val_0_accuracy: 0.83375 |  0:00:31s\n","epoch 32 | loss: 0.34758 | val_0_accuracy: 0.81214 |  0:00:32s\n","epoch 33 | loss: 0.34707 | val_0_accuracy: 0.82876 |  0:00:33s\n","epoch 34 | loss: 0.35145 | val_0_accuracy: 0.82294 |  0:00:35s\n","epoch 35 | loss: 0.34716 | val_0_accuracy: 0.82876 |  0:00:35s\n","epoch 36 | loss: 0.34037 | val_0_accuracy: 0.83292 |  0:00:36s\n","epoch 37 | loss: 0.33702 | val_0_accuracy: 0.83375 |  0:00:38s\n","epoch 38 | loss: 0.34196 | val_0_accuracy: 0.82876 |  0:00:39s\n","epoch 39 | loss: 0.33756 | val_0_accuracy: 0.83209 |  0:00:40s\n","epoch 40 | loss: 0.33986 | val_0_accuracy: 0.8404  |  0:00:40s\n","epoch 41 | loss: 0.33929 | val_0_accuracy: 0.85453 |  0:00:41s\n","epoch 42 | loss: 0.3359  | val_0_accuracy: 0.84705 |  0:00:42s\n","epoch 43 | loss: 0.3312  | val_0_accuracy: 0.84954 |  0:00:43s\n","epoch 44 | loss: 0.32863 | val_0_accuracy: 0.85453 |  0:00:44s\n","epoch 45 | loss: 0.33709 | val_0_accuracy: 0.8537  |  0:00:45s\n","epoch 46 | loss: 0.33088 | val_0_accuracy: 0.84954 |  0:00:46s\n","epoch 47 | loss: 0.33089 | val_0_accuracy: 0.84705 |  0:00:47s\n","epoch 48 | loss: 0.33414 | val_0_accuracy: 0.83957 |  0:00:48s\n","epoch 49 | loss: 0.3349  | val_0_accuracy: 0.84954 |  0:00:49s\n","epoch 50 | loss: 0.33171 | val_0_accuracy: 0.85536 |  0:00:50s\n","epoch 51 | loss: 0.33448 | val_0_accuracy: 0.85204 |  0:00:51s\n","epoch 52 | loss: 0.33421 | val_0_accuracy: 0.84788 |  0:00:52s\n","epoch 53 | loss: 0.32891 | val_0_accuracy: 0.83541 |  0:00:53s\n","epoch 54 | loss: 0.33088 | val_0_accuracy: 0.85453 |  0:00:54s\n","epoch 55 | loss: 0.33159 | val_0_accuracy: 0.85287 |  0:00:55s\n","epoch 56 | loss: 0.3295  | val_0_accuracy: 0.85121 |  0:00:56s\n","epoch 57 | loss: 0.33104 | val_0_accuracy: 0.84705 |  0:00:57s\n","epoch 58 | loss: 0.32787 | val_0_accuracy: 0.86035 |  0:00:58s\n","epoch 59 | loss: 0.33463 | val_0_accuracy: 0.85204 |  0:00:59s\n","epoch 60 | loss: 0.33906 | val_0_accuracy: 0.83707 |  0:01:00s\n","epoch 61 | loss: 0.33785 | val_0_accuracy: 0.85453 |  0:01:01s\n","epoch 62 | loss: 0.33819 | val_0_accuracy: 0.83874 |  0:01:02s\n","epoch 63 | loss: 0.34028 | val_0_accuracy: 0.85037 |  0:01:03s\n","epoch 64 | loss: 0.34297 | val_0_accuracy: 0.85204 |  0:01:04s\n","epoch 65 | loss: 0.33676 | val_0_accuracy: 0.85204 |  0:01:05s\n","epoch 66 | loss: 0.3411  | val_0_accuracy: 0.84954 |  0:01:06s\n","epoch 67 | loss: 0.34326 | val_0_accuracy: 0.84871 |  0:01:07s\n","epoch 68 | loss: 0.33942 | val_0_accuracy: 0.85121 |  0:01:08s\n","\n","Early stopping occurred at epoch 68 with best_epoch = 58 and best_val_0_accuracy = 0.86035\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-07-06 05:47:27,772] Trial 12 finished with value: 0.8603491271820449 and parameters: {'n_d': 21, 'n_steps': 5, 'gamma': 1.093087612164031, 'n_independent': 5, 'n_shared': 4, 'momentum': 0.02327400626770776}. Best is trial 3 with value: 0.8694929343308395.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 0.69641 | val_0_accuracy: 0.48712 |  0:00:00s\n","epoch 1  | loss: 0.50518 | val_0_accuracy: 0.52037 |  0:00:01s\n","epoch 2  | loss: 0.43176 | val_0_accuracy: 0.51704 |  0:00:02s\n","epoch 3  | loss: 0.39953 | val_0_accuracy: 0.51704 |  0:00:02s\n","epoch 4  | loss: 0.40972 | val_0_accuracy: 0.6276  |  0:00:03s\n","epoch 5  | loss: 0.40729 | val_0_accuracy: 0.66667 |  0:00:04s\n","epoch 6  | loss: 0.39494 | val_0_accuracy: 0.6276  |  0:00:05s\n","epoch 7  | loss: 0.38184 | val_0_accuracy: 0.52452 |  0:00:05s\n","epoch 8  | loss: 0.37614 | val_0_accuracy: 0.61264 |  0:00:06s\n","epoch 9  | loss: 0.37374 | val_0_accuracy: 0.56027 |  0:00:07s\n","epoch 10 | loss: 0.36623 | val_0_accuracy: 0.54447 |  0:00:07s\n","epoch 11 | loss: 0.36419 | val_0_accuracy: 0.56525 |  0:00:08s\n","epoch 12 | loss: 0.36529 | val_0_accuracy: 0.68495 |  0:00:09s\n","epoch 13 | loss: 0.35923 | val_0_accuracy: 0.65669 |  0:00:09s\n","epoch 14 | loss: 0.35441 | val_0_accuracy: 0.64505 |  0:00:10s\n","epoch 15 | loss: 0.35033 | val_0_accuracy: 0.6808  |  0:00:11s\n","epoch 16 | loss: 0.35015 | val_0_accuracy: 0.64339 |  0:00:11s\n","epoch 17 | loss: 0.34987 | val_0_accuracy: 0.6783  |  0:00:12s\n","epoch 18 | loss: 0.34696 | val_0_accuracy: 0.6941  |  0:00:13s\n","epoch 19 | loss: 0.34781 | val_0_accuracy: 0.71405 |  0:00:13s\n","epoch 20 | loss: 0.34415 | val_0_accuracy: 0.7207  |  0:00:14s\n","epoch 21 | loss: 0.3407  | val_0_accuracy: 0.71654 |  0:00:15s\n","epoch 22 | loss: 0.34662 | val_0_accuracy: 0.72569 |  0:00:15s\n","epoch 23 | loss: 0.34605 | val_0_accuracy: 0.75478 |  0:00:16s\n","epoch 24 | loss: 0.34072 | val_0_accuracy: 0.77722 |  0:00:17s\n","epoch 25 | loss: 0.34996 | val_0_accuracy: 0.77473 |  0:00:17s\n","epoch 26 | loss: 0.35464 | val_0_accuracy: 0.80964 |  0:00:18s\n","epoch 27 | loss: 0.34373 | val_0_accuracy: 0.7847  |  0:00:19s\n","epoch 28 | loss: 0.33816 | val_0_accuracy: 0.78886 |  0:00:19s\n","epoch 29 | loss: 0.33964 | val_0_accuracy: 0.79468 |  0:00:20s\n","epoch 30 | loss: 0.33029 | val_0_accuracy: 0.80299 |  0:00:21s\n","epoch 31 | loss: 0.34009 | val_0_accuracy: 0.82294 |  0:00:21s\n","epoch 32 | loss: 0.33006 | val_0_accuracy: 0.83624 |  0:00:22s\n","epoch 33 | loss: 0.33732 | val_0_accuracy: 0.83707 |  0:00:23s\n","epoch 34 | loss: 0.32961 | val_0_accuracy: 0.81796 |  0:00:24s\n","epoch 35 | loss: 0.32475 | val_0_accuracy: 0.85037 |  0:00:24s\n","epoch 36 | loss: 0.3257  | val_0_accuracy: 0.84871 |  0:00:25s\n","epoch 37 | loss: 0.32697 | val_0_accuracy: 0.84622 |  0:00:26s\n","epoch 38 | loss: 0.32731 | val_0_accuracy: 0.84705 |  0:00:26s\n","epoch 39 | loss: 0.32503 | val_0_accuracy: 0.85453 |  0:00:27s\n","epoch 40 | loss: 0.32412 | val_0_accuracy: 0.85287 |  0:00:28s\n","epoch 41 | loss: 0.32497 | val_0_accuracy: 0.85869 |  0:00:28s\n","epoch 42 | loss: 0.32477 | val_0_accuracy: 0.86451 |  0:00:29s\n","epoch 43 | loss: 0.32159 | val_0_accuracy: 0.85037 |  0:00:30s\n","epoch 44 | loss: 0.33601 | val_0_accuracy: 0.85037 |  0:00:30s\n","epoch 45 | loss: 0.33774 | val_0_accuracy: 0.85287 |  0:00:31s\n","epoch 46 | loss: 0.33424 | val_0_accuracy: 0.85952 |  0:00:32s\n","epoch 47 | loss: 0.32593 | val_0_accuracy: 0.84539 |  0:00:32s\n","epoch 48 | loss: 0.32625 | val_0_accuracy: 0.85121 |  0:00:33s\n","epoch 49 | loss: 0.32754 | val_0_accuracy: 0.85619 |  0:00:34s\n","epoch 50 | loss: 0.3257  | val_0_accuracy: 0.84871 |  0:00:34s\n","epoch 51 | loss: 0.32138 | val_0_accuracy: 0.85453 |  0:00:35s\n","epoch 52 | loss: 0.31932 | val_0_accuracy: 0.85702 |  0:00:36s\n","\n","Early stopping occurred at epoch 52 with best_epoch = 42 and best_val_0_accuracy = 0.86451\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-07-06 05:48:04,498] Trial 13 finished with value: 0.8645054031587698 and parameters: {'n_d': 47, 'n_steps': 3, 'gamma': 1.1622871579708312, 'n_independent': 5, 'n_shared': 4, 'momentum': 0.0900281531773117}. Best is trial 3 with value: 0.8694929343308395.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 1.09062 | val_0_accuracy: 0.51787 |  0:00:01s\n","epoch 1  | loss: 0.60037 | val_0_accuracy: 0.52369 |  0:00:02s\n","epoch 2  | loss: 0.52376 | val_0_accuracy: 0.51953 |  0:00:03s\n","epoch 3  | loss: 0.46795 | val_0_accuracy: 0.55943 |  0:00:04s\n","epoch 4  | loss: 0.45742 | val_0_accuracy: 0.52618 |  0:00:05s\n","epoch 5  | loss: 0.42768 | val_0_accuracy: 0.6409  |  0:00:06s\n","epoch 6  | loss: 0.41799 | val_0_accuracy: 0.64672 |  0:00:07s\n","epoch 7  | loss: 0.42834 | val_0_accuracy: 0.60432 |  0:00:08s\n","epoch 8  | loss: 0.41368 | val_0_accuracy: 0.55278 |  0:00:09s\n","epoch 9  | loss: 0.41935 | val_0_accuracy: 0.66334 |  0:00:10s\n","epoch 10 | loss: 0.40227 | val_0_accuracy: 0.6409  |  0:00:11s\n","epoch 11 | loss: 0.39336 | val_0_accuracy: 0.66168 |  0:00:12s\n","epoch 12 | loss: 0.39028 | val_0_accuracy: 0.67581 |  0:00:13s\n","epoch 13 | loss: 0.3995  | val_0_accuracy: 0.66999 |  0:00:14s\n","epoch 14 | loss: 0.39657 | val_0_accuracy: 0.66999 |  0:00:15s\n","epoch 15 | loss: 0.40299 | val_0_accuracy: 0.74065 |  0:00:16s\n","epoch 16 | loss: 0.40733 | val_0_accuracy: 0.75977 |  0:00:17s\n","epoch 17 | loss: 0.40571 | val_0_accuracy: 0.7473  |  0:00:18s\n","epoch 18 | loss: 0.39662 | val_0_accuracy: 0.69992 |  0:00:19s\n","epoch 19 | loss: 0.39168 | val_0_accuracy: 0.76808 |  0:00:20s\n","epoch 20 | loss: 0.3953  | val_0_accuracy: 0.75561 |  0:00:21s\n","epoch 21 | loss: 0.38686 | val_0_accuracy: 0.74813 |  0:00:22s\n","epoch 22 | loss: 0.38181 | val_0_accuracy: 0.76475 |  0:00:23s\n","epoch 23 | loss: 0.37746 | val_0_accuracy: 0.78055 |  0:00:24s\n","epoch 24 | loss: 0.37186 | val_0_accuracy: 0.75894 |  0:00:25s\n","epoch 25 | loss: 0.3655  | val_0_accuracy: 0.75312 |  0:00:26s\n","epoch 26 | loss: 0.36033 | val_0_accuracy: 0.76891 |  0:00:27s\n","epoch 27 | loss: 0.37149 | val_0_accuracy: 0.75062 |  0:00:28s\n","epoch 28 | loss: 0.3692  | val_0_accuracy: 0.78803 |  0:00:29s\n","epoch 29 | loss: 0.36964 | val_0_accuracy: 0.79135 |  0:00:30s\n","epoch 30 | loss: 0.36404 | val_0_accuracy: 0.79135 |  0:00:31s\n","epoch 31 | loss: 0.37035 | val_0_accuracy: 0.80466 |  0:00:32s\n","epoch 32 | loss: 0.36592 | val_0_accuracy: 0.79219 |  0:00:33s\n","epoch 33 | loss: 0.37156 | val_0_accuracy: 0.82045 |  0:00:34s\n","epoch 34 | loss: 0.36916 | val_0_accuracy: 0.82045 |  0:00:35s\n","epoch 35 | loss: 0.35891 | val_0_accuracy: 0.82793 |  0:00:36s\n","epoch 36 | loss: 0.36099 | val_0_accuracy: 0.82211 |  0:00:37s\n","epoch 37 | loss: 0.35812 | val_0_accuracy: 0.83375 |  0:00:38s\n","epoch 38 | loss: 0.3515  | val_0_accuracy: 0.82793 |  0:00:39s\n","epoch 39 | loss: 0.35145 | val_0_accuracy: 0.83458 |  0:00:40s\n","epoch 40 | loss: 0.35732 | val_0_accuracy: 0.82128 |  0:00:41s\n","epoch 41 | loss: 0.35648 | val_0_accuracy: 0.81796 |  0:00:42s\n","epoch 42 | loss: 0.35351 | val_0_accuracy: 0.83874 |  0:00:43s\n","epoch 43 | loss: 0.35062 | val_0_accuracy: 0.83624 |  0:00:44s\n","epoch 44 | loss: 0.35187 | val_0_accuracy: 0.84123 |  0:00:45s\n","epoch 45 | loss: 0.34414 | val_0_accuracy: 0.85037 |  0:00:46s\n","epoch 46 | loss: 0.34891 | val_0_accuracy: 0.84871 |  0:00:47s\n","epoch 47 | loss: 0.34535 | val_0_accuracy: 0.84539 |  0:00:48s\n","epoch 48 | loss: 0.34207 | val_0_accuracy: 0.83707 |  0:00:49s\n","epoch 49 | loss: 0.34188 | val_0_accuracy: 0.84539 |  0:00:50s\n","epoch 50 | loss: 0.34324 | val_0_accuracy: 0.83042 |  0:00:51s\n","epoch 51 | loss: 0.34801 | val_0_accuracy: 0.8404  |  0:00:52s\n","epoch 52 | loss: 0.35276 | val_0_accuracy: 0.84289 |  0:00:53s\n","epoch 53 | loss: 0.35294 | val_0_accuracy: 0.84539 |  0:00:54s\n","epoch 54 | loss: 0.34389 | val_0_accuracy: 0.83957 |  0:00:55s\n","epoch 55 | loss: 0.34509 | val_0_accuracy: 0.8404  |  0:00:56s\n","\n","Early stopping occurred at epoch 55 with best_epoch = 45 and best_val_0_accuracy = 0.85037\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-07-06 05:49:01,407] Trial 14 finished with value: 0.8503740648379052 and parameters: {'n_d': 52, 'n_steps': 5, 'gamma': 1.404111948428225, 'n_independent': 4, 'n_shared': 5, 'momentum': 0.0124281154536459}. Best is trial 3 with value: 0.8694929343308395.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 0.63519 | val_0_accuracy: 0.51704 |  0:00:00s\n","epoch 1  | loss: 0.50119 | val_0_accuracy: 0.51538 |  0:00:01s\n","epoch 2  | loss: 0.44938 | val_0_accuracy: 0.6143  |  0:00:02s\n","epoch 3  | loss: 0.42357 | val_0_accuracy: 0.52286 |  0:00:02s\n","epoch 4  | loss: 0.4072  | val_0_accuracy: 0.66584 |  0:00:03s\n","epoch 5  | loss: 0.39899 | val_0_accuracy: 0.65835 |  0:00:04s\n","epoch 6  | loss: 0.38598 | val_0_accuracy: 0.61845 |  0:00:04s\n","epoch 7  | loss: 0.38552 | val_0_accuracy: 0.56193 |  0:00:05s\n","epoch 8  | loss: 0.38272 | val_0_accuracy: 0.6517  |  0:00:06s\n","epoch 9  | loss: 0.38057 | val_0_accuracy: 0.6783  |  0:00:06s\n","epoch 10 | loss: 0.37092 | val_0_accuracy: 0.67332 |  0:00:07s\n","epoch 11 | loss: 0.36969 | val_0_accuracy: 0.63259 |  0:00:08s\n","epoch 12 | loss: 0.36453 | val_0_accuracy: 0.70823 |  0:00:08s\n","epoch 13 | loss: 0.36012 | val_0_accuracy: 0.67165 |  0:00:09s\n","epoch 14 | loss: 0.36152 | val_0_accuracy: 0.68495 |  0:00:10s\n","epoch 15 | loss: 0.35896 | val_0_accuracy: 0.70989 |  0:00:10s\n","epoch 16 | loss: 0.35264 | val_0_accuracy: 0.70075 |  0:00:11s\n","epoch 17 | loss: 0.35594 | val_0_accuracy: 0.7049  |  0:00:12s\n","epoch 18 | loss: 0.34665 | val_0_accuracy: 0.72818 |  0:00:12s\n","epoch 19 | loss: 0.34204 | val_0_accuracy: 0.74231 |  0:00:13s\n","epoch 20 | loss: 0.34786 | val_0_accuracy: 0.75977 |  0:00:14s\n","epoch 21 | loss: 0.34071 | val_0_accuracy: 0.75229 |  0:00:14s\n","epoch 22 | loss: 0.34361 | val_0_accuracy: 0.7315  |  0:00:15s\n","epoch 23 | loss: 0.33492 | val_0_accuracy: 0.74813 |  0:00:16s\n","epoch 24 | loss: 0.33257 | val_0_accuracy: 0.7581  |  0:00:16s\n","epoch 25 | loss: 0.33852 | val_0_accuracy: 0.7581  |  0:00:17s\n","epoch 26 | loss: 0.33043 | val_0_accuracy: 0.76891 |  0:00:18s\n","epoch 27 | loss: 0.33827 | val_0_accuracy: 0.80216 |  0:00:18s\n","epoch 28 | loss: 0.33286 | val_0_accuracy: 0.80964 |  0:00:19s\n","epoch 29 | loss: 0.32535 | val_0_accuracy: 0.80632 |  0:00:20s\n","epoch 30 | loss: 0.33049 | val_0_accuracy: 0.81712 |  0:00:21s\n","epoch 31 | loss: 0.32217 | val_0_accuracy: 0.82461 |  0:00:21s\n","epoch 32 | loss: 0.32471 | val_0_accuracy: 0.82959 |  0:00:22s\n","epoch 33 | loss: 0.32345 | val_0_accuracy: 0.83957 |  0:00:23s\n","epoch 34 | loss: 0.32236 | val_0_accuracy: 0.83292 |  0:00:23s\n","epoch 35 | loss: 0.32044 | val_0_accuracy: 0.83791 |  0:00:24s\n","epoch 36 | loss: 0.32057 | val_0_accuracy: 0.82876 |  0:00:25s\n","epoch 37 | loss: 0.32271 | val_0_accuracy: 0.83375 |  0:00:25s\n","epoch 38 | loss: 0.3264  | val_0_accuracy: 0.84705 |  0:00:26s\n","epoch 39 | loss: 0.3229  | val_0_accuracy: 0.85287 |  0:00:27s\n","epoch 40 | loss: 0.32391 | val_0_accuracy: 0.84123 |  0:00:27s\n","epoch 41 | loss: 0.32576 | val_0_accuracy: 0.84954 |  0:00:28s\n","epoch 42 | loss: 0.32617 | val_0_accuracy: 0.85287 |  0:00:29s\n","epoch 43 | loss: 0.32657 | val_0_accuracy: 0.84954 |  0:00:29s\n","epoch 44 | loss: 0.32071 | val_0_accuracy: 0.85287 |  0:00:30s\n","epoch 45 | loss: 0.31905 | val_0_accuracy: 0.85121 |  0:00:31s\n","epoch 46 | loss: 0.31619 | val_0_accuracy: 0.84954 |  0:00:31s\n","epoch 47 | loss: 0.31296 | val_0_accuracy: 0.84705 |  0:00:32s\n","epoch 48 | loss: 0.32185 | val_0_accuracy: 0.84622 |  0:00:33s\n","epoch 49 | loss: 0.32097 | val_0_accuracy: 0.8537  |  0:00:34s\n","epoch 50 | loss: 0.32206 | val_0_accuracy: 0.84788 |  0:00:34s\n","epoch 51 | loss: 0.32681 | val_0_accuracy: 0.84622 |  0:00:35s\n","epoch 52 | loss: 0.32759 | val_0_accuracy: 0.85287 |  0:00:36s\n","epoch 53 | loss: 0.33641 | val_0_accuracy: 0.85702 |  0:00:36s\n","epoch 54 | loss: 0.32789 | val_0_accuracy: 0.84871 |  0:00:37s\n","epoch 55 | loss: 0.32553 | val_0_accuracy: 0.85952 |  0:00:38s\n","epoch 56 | loss: 0.32369 | val_0_accuracy: 0.85786 |  0:00:38s\n","epoch 57 | loss: 0.32528 | val_0_accuracy: 0.85619 |  0:00:39s\n","epoch 58 | loss: 0.32273 | val_0_accuracy: 0.85952 |  0:00:40s\n","epoch 59 | loss: 0.32259 | val_0_accuracy: 0.86201 |  0:00:40s\n","epoch 60 | loss: 0.32178 | val_0_accuracy: 0.85619 |  0:00:41s\n","epoch 61 | loss: 0.32171 | val_0_accuracy: 0.85453 |  0:00:42s\n","epoch 62 | loss: 0.31959 | val_0_accuracy: 0.86118 |  0:00:42s\n","epoch 63 | loss: 0.31958 | val_0_accuracy: 0.86284 |  0:00:43s\n","epoch 64 | loss: 0.31992 | val_0_accuracy: 0.86451 |  0:00:44s\n","epoch 65 | loss: 0.31661 | val_0_accuracy: 0.86367 |  0:00:44s\n","epoch 66 | loss: 0.31107 | val_0_accuracy: 0.86367 |  0:00:45s\n","epoch 67 | loss: 0.31303 | val_0_accuracy: 0.8537  |  0:00:46s\n","epoch 68 | loss: 0.30976 | val_0_accuracy: 0.85786 |  0:00:46s\n","epoch 69 | loss: 0.31095 | val_0_accuracy: 0.86617 |  0:00:47s\n","epoch 70 | loss: 0.30927 | val_0_accuracy: 0.86451 |  0:00:48s\n","epoch 71 | loss: 0.30661 | val_0_accuracy: 0.86949 |  0:00:48s\n","epoch 72 | loss: 0.31227 | val_0_accuracy: 0.85702 |  0:00:49s\n","epoch 73 | loss: 0.30966 | val_0_accuracy: 0.85287 |  0:00:50s\n","epoch 74 | loss: 0.3037  | val_0_accuracy: 0.86118 |  0:00:50s\n","epoch 75 | loss: 0.30983 | val_0_accuracy: 0.86201 |  0:00:51s\n","epoch 76 | loss: 0.32077 | val_0_accuracy: 0.85619 |  0:00:52s\n","epoch 77 | loss: 0.32546 | val_0_accuracy: 0.86949 |  0:00:52s\n","epoch 78 | loss: 0.31389 | val_0_accuracy: 0.86201 |  0:00:53s\n","epoch 79 | loss: 0.3167  | val_0_accuracy: 0.86284 |  0:00:54s\n","epoch 80 | loss: 0.31135 | val_0_accuracy: 0.85869 |  0:00:54s\n","epoch 81 | loss: 0.30953 | val_0_accuracy: 0.86118 |  0:00:55s\n","\n","Early stopping occurred at epoch 81 with best_epoch = 71 and best_val_0_accuracy = 0.86949\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-07-06 05:49:57,411] Trial 15 finished with value: 0.8694929343308395 and parameters: {'n_d': 24, 'n_steps': 3, 'gamma': 1.002285541167971, 'n_independent': 5, 'n_shared': 4, 'momentum': 0.09003930634848917}. Best is trial 3 with value: 0.8694929343308395.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 0.77095 | val_0_accuracy: 0.52286 |  0:00:01s\n","epoch 1  | loss: 0.60323 | val_0_accuracy: 0.51704 |  0:00:02s\n","epoch 2  | loss: 0.5062  | val_0_accuracy: 0.60848 |  0:00:03s\n","epoch 3  | loss: 0.456   | val_0_accuracy: 0.59352 |  0:00:04s\n","epoch 4  | loss: 0.43176 | val_0_accuracy: 0.68828 |  0:00:05s\n","epoch 5  | loss: 0.41208 | val_0_accuracy: 0.67581 |  0:00:06s\n","epoch 6  | loss: 0.41382 | val_0_accuracy: 0.69992 |  0:00:08s\n","epoch 7  | loss: 0.4011  | val_0_accuracy: 0.70158 |  0:00:09s\n","epoch 8  | loss: 0.39079 | val_0_accuracy: 0.66002 |  0:00:10s\n","epoch 9  | loss: 0.38932 | val_0_accuracy: 0.6783  |  0:00:11s\n","epoch 10 | loss: 0.38179 | val_0_accuracy: 0.69077 |  0:00:12s\n","epoch 11 | loss: 0.37657 | val_0_accuracy: 0.69493 |  0:00:14s\n","epoch 12 | loss: 0.37992 | val_0_accuracy: 0.71488 |  0:00:15s\n","epoch 13 | loss: 0.37143 | val_0_accuracy: 0.71987 |  0:00:16s\n","epoch 14 | loss: 0.36271 | val_0_accuracy: 0.7182  |  0:00:17s\n","epoch 15 | loss: 0.36311 | val_0_accuracy: 0.73483 |  0:00:18s\n","epoch 16 | loss: 0.3675  | val_0_accuracy: 0.734   |  0:00:19s\n","epoch 17 | loss: 0.35429 | val_0_accuracy: 0.74979 |  0:00:20s\n","epoch 18 | loss: 0.36587 | val_0_accuracy: 0.76143 |  0:00:22s\n","epoch 19 | loss: 0.36703 | val_0_accuracy: 0.76392 |  0:00:23s\n","epoch 20 | loss: 0.36368 | val_0_accuracy: 0.73649 |  0:00:24s\n","epoch 21 | loss: 0.37203 | val_0_accuracy: 0.74065 |  0:00:25s\n","epoch 22 | loss: 0.36185 | val_0_accuracy: 0.76226 |  0:00:26s\n","epoch 23 | loss: 0.35458 | val_0_accuracy: 0.77972 |  0:00:27s\n","epoch 24 | loss: 0.35845 | val_0_accuracy: 0.78055 |  0:00:29s\n","epoch 25 | loss: 0.34945 | val_0_accuracy: 0.78138 |  0:00:30s\n","epoch 26 | loss: 0.34852 | val_0_accuracy: 0.8005  |  0:00:31s\n","epoch 27 | loss: 0.3429  | val_0_accuracy: 0.79385 |  0:00:32s\n","epoch 28 | loss: 0.35082 | val_0_accuracy: 0.79717 |  0:00:33s\n","epoch 29 | loss: 0.34418 | val_0_accuracy: 0.78554 |  0:00:34s\n","epoch 30 | loss: 0.33995 | val_0_accuracy: 0.80549 |  0:00:36s\n","epoch 31 | loss: 0.34333 | val_0_accuracy: 0.79302 |  0:00:37s\n","epoch 32 | loss: 0.34176 | val_0_accuracy: 0.81131 |  0:00:38s\n","epoch 33 | loss: 0.34188 | val_0_accuracy: 0.80715 |  0:00:39s\n","epoch 34 | loss: 0.33727 | val_0_accuracy: 0.82377 |  0:00:40s\n","epoch 35 | loss: 0.3359  | val_0_accuracy: 0.82793 |  0:00:41s\n","epoch 36 | loss: 0.33788 | val_0_accuracy: 0.82876 |  0:00:43s\n","epoch 37 | loss: 0.3362  | val_0_accuracy: 0.83957 |  0:00:44s\n","epoch 38 | loss: 0.33263 | val_0_accuracy: 0.85121 |  0:00:45s\n","epoch 39 | loss: 0.33124 | val_0_accuracy: 0.84871 |  0:00:46s\n","epoch 40 | loss: 0.33313 | val_0_accuracy: 0.84954 |  0:00:47s\n","epoch 41 | loss: 0.32901 | val_0_accuracy: 0.84788 |  0:00:48s\n","epoch 42 | loss: 0.32814 | val_0_accuracy: 0.84954 |  0:00:49s\n","epoch 43 | loss: 0.34178 | val_0_accuracy: 0.84456 |  0:00:51s\n","epoch 44 | loss: 0.32768 | val_0_accuracy: 0.8404  |  0:00:52s\n","epoch 45 | loss: 0.33476 | val_0_accuracy: 0.84622 |  0:00:53s\n","epoch 46 | loss: 0.33195 | val_0_accuracy: 0.84871 |  0:00:54s\n","epoch 47 | loss: 0.33224 | val_0_accuracy: 0.85453 |  0:00:55s\n","epoch 48 | loss: 0.33342 | val_0_accuracy: 0.8537  |  0:00:56s\n","epoch 49 | loss: 0.33346 | val_0_accuracy: 0.8537  |  0:00:58s\n","epoch 50 | loss: 0.32206 | val_0_accuracy: 0.8404  |  0:00:59s\n","epoch 51 | loss: 0.3232  | val_0_accuracy: 0.84954 |  0:01:00s\n","epoch 52 | loss: 0.33127 | val_0_accuracy: 0.84705 |  0:01:01s\n","epoch 53 | loss: 0.32523 | val_0_accuracy: 0.85536 |  0:01:02s\n","epoch 54 | loss: 0.32578 | val_0_accuracy: 0.86201 |  0:01:03s\n","epoch 55 | loss: 0.32327 | val_0_accuracy: 0.85121 |  0:01:04s\n","epoch 56 | loss: 0.32809 | val_0_accuracy: 0.85287 |  0:01:06s\n","epoch 57 | loss: 0.31998 | val_0_accuracy: 0.85204 |  0:01:07s\n","epoch 58 | loss: 0.32118 | val_0_accuracy: 0.84206 |  0:01:08s\n","epoch 59 | loss: 0.32648 | val_0_accuracy: 0.85453 |  0:01:09s\n","epoch 60 | loss: 0.32945 | val_0_accuracy: 0.86035 |  0:01:10s\n","epoch 61 | loss: 0.32397 | val_0_accuracy: 0.85121 |  0:01:11s\n","epoch 62 | loss: 0.3338  | val_0_accuracy: 0.85287 |  0:01:12s\n","epoch 63 | loss: 0.33661 | val_0_accuracy: 0.8537  |  0:01:14s\n","epoch 64 | loss: 0.33273 | val_0_accuracy: 0.84456 |  0:01:15s\n","\n","Early stopping occurred at epoch 64 with best_epoch = 54 and best_val_0_accuracy = 0.86201\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-07-06 05:51:13,306] Trial 16 finished with value: 0.8620116375727348 and parameters: {'n_d': 34, 'n_steps': 6, 'gamma': 1.151682098324207, 'n_independent': 4, 'n_shared': 5, 'momentum': 0.08346649459557415}. Best is trial 3 with value: 0.8694929343308395.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 0.61212 | val_0_accuracy: 0.52535 |  0:00:00s\n","epoch 1  | loss: 0.49892 | val_0_accuracy: 0.52702 |  0:00:01s\n","epoch 2  | loss: 0.47699 | val_0_accuracy: 0.55777 |  0:00:01s\n","epoch 3  | loss: 0.45053 | val_0_accuracy: 0.54198 |  0:00:02s\n","epoch 4  | loss: 0.44875 | val_0_accuracy: 0.57606 |  0:00:02s\n","epoch 5  | loss: 0.43302 | val_0_accuracy: 0.56276 |  0:00:03s\n","epoch 6  | loss: 0.42236 | val_0_accuracy: 0.60515 |  0:00:03s\n","epoch 7  | loss: 0.41739 | val_0_accuracy: 0.5985  |  0:00:04s\n","epoch 8  | loss: 0.42094 | val_0_accuracy: 0.57606 |  0:00:05s\n","epoch 9  | loss: 0.41812 | val_0_accuracy: 0.59684 |  0:00:05s\n","epoch 10 | loss: 0.40925 | val_0_accuracy: 0.62095 |  0:00:06s\n","epoch 11 | loss: 0.40808 | val_0_accuracy: 0.65337 |  0:00:06s\n","epoch 12 | loss: 0.40153 | val_0_accuracy: 0.61929 |  0:00:07s\n","epoch 13 | loss: 0.39207 | val_0_accuracy: 0.68495 |  0:00:07s\n","epoch 14 | loss: 0.39189 | val_0_accuracy: 0.70158 |  0:00:08s\n","epoch 15 | loss: 0.38178 | val_0_accuracy: 0.69327 |  0:00:08s\n","epoch 16 | loss: 0.38841 | val_0_accuracy: 0.71737 |  0:00:09s\n","epoch 17 | loss: 0.388   | val_0_accuracy: 0.72319 |  0:00:09s\n","epoch 18 | loss: 0.38764 | val_0_accuracy: 0.7207  |  0:00:10s\n","epoch 19 | loss: 0.38286 | val_0_accuracy: 0.74397 |  0:00:10s\n","epoch 20 | loss: 0.37776 | val_0_accuracy: 0.71904 |  0:00:11s\n","epoch 21 | loss: 0.37464 | val_0_accuracy: 0.72652 |  0:00:12s\n","epoch 22 | loss: 0.37038 | val_0_accuracy: 0.75561 |  0:00:12s\n","epoch 23 | loss: 0.37706 | val_0_accuracy: 0.76392 |  0:00:13s\n","epoch 24 | loss: 0.37654 | val_0_accuracy: 0.74564 |  0:00:13s\n","epoch 25 | loss: 0.37641 | val_0_accuracy: 0.77639 |  0:00:14s\n","epoch 26 | loss: 0.36536 | val_0_accuracy: 0.8005  |  0:00:14s\n","epoch 27 | loss: 0.36439 | val_0_accuracy: 0.78387 |  0:00:15s\n","epoch 28 | loss: 0.36246 | val_0_accuracy: 0.78969 |  0:00:15s\n","epoch 29 | loss: 0.37496 | val_0_accuracy: 0.80299 |  0:00:16s\n","epoch 30 | loss: 0.36224 | val_0_accuracy: 0.80466 |  0:00:17s\n","epoch 31 | loss: 0.36608 | val_0_accuracy: 0.8138  |  0:00:17s\n","epoch 32 | loss: 0.36671 | val_0_accuracy: 0.82211 |  0:00:18s\n","epoch 33 | loss: 0.3666  | val_0_accuracy: 0.82294 |  0:00:18s\n","epoch 34 | loss: 0.36535 | val_0_accuracy: 0.82377 |  0:00:19s\n","epoch 35 | loss: 0.3649  | val_0_accuracy: 0.82959 |  0:00:19s\n","epoch 36 | loss: 0.36051 | val_0_accuracy: 0.83957 |  0:00:20s\n","epoch 37 | loss: 0.36255 | val_0_accuracy: 0.84456 |  0:00:21s\n","epoch 38 | loss: 0.36554 | val_0_accuracy: 0.83791 |  0:00:21s\n","epoch 39 | loss: 0.35797 | val_0_accuracy: 0.84206 |  0:00:22s\n","epoch 40 | loss: 0.35088 | val_0_accuracy: 0.83874 |  0:00:22s\n","epoch 41 | loss: 0.34793 | val_0_accuracy: 0.84539 |  0:00:23s\n","epoch 42 | loss: 0.34689 | val_0_accuracy: 0.83791 |  0:00:23s\n","epoch 43 | loss: 0.34739 | val_0_accuracy: 0.83874 |  0:00:24s\n","epoch 44 | loss: 0.34457 | val_0_accuracy: 0.84954 |  0:00:24s\n","epoch 45 | loss: 0.33785 | val_0_accuracy: 0.85453 |  0:00:25s\n","epoch 46 | loss: 0.33978 | val_0_accuracy: 0.84372 |  0:00:25s\n","epoch 47 | loss: 0.33617 | val_0_accuracy: 0.85204 |  0:00:26s\n","epoch 48 | loss: 0.33627 | val_0_accuracy: 0.84954 |  0:00:26s\n","epoch 49 | loss: 0.33195 | val_0_accuracy: 0.85121 |  0:00:27s\n","epoch 50 | loss: 0.33321 | val_0_accuracy: 0.8537  |  0:00:28s\n","epoch 51 | loss: 0.33398 | val_0_accuracy: 0.84871 |  0:00:28s\n","epoch 52 | loss: 0.33168 | val_0_accuracy: 0.85204 |  0:00:29s\n","epoch 53 | loss: 0.33454 | val_0_accuracy: 0.85869 |  0:00:29s\n","epoch 54 | loss: 0.33305 | val_0_accuracy: 0.85204 |  0:00:30s\n","epoch 55 | loss: 0.33335 | val_0_accuracy: 0.85121 |  0:00:30s\n","epoch 56 | loss: 0.332   | val_0_accuracy: 0.84539 |  0:00:31s\n","epoch 57 | loss: 0.33361 | val_0_accuracy: 0.85952 |  0:00:31s\n","epoch 58 | loss: 0.32895 | val_0_accuracy: 0.84871 |  0:00:32s\n","epoch 59 | loss: 0.33668 | val_0_accuracy: 0.84622 |  0:00:32s\n","epoch 60 | loss: 0.33283 | val_0_accuracy: 0.85702 |  0:00:33s\n","epoch 61 | loss: 0.33241 | val_0_accuracy: 0.8537  |  0:00:33s\n","epoch 62 | loss: 0.3314  | val_0_accuracy: 0.85287 |  0:00:34s\n","epoch 63 | loss: 0.33348 | val_0_accuracy: 0.84539 |  0:00:35s\n","epoch 64 | loss: 0.3415  | val_0_accuracy: 0.85037 |  0:00:35s\n","epoch 65 | loss: 0.34037 | val_0_accuracy: 0.85121 |  0:00:36s\n","epoch 66 | loss: 0.34326 | val_0_accuracy: 0.85619 |  0:00:36s\n","epoch 67 | loss: 0.34375 | val_0_accuracy: 0.84206 |  0:00:37s\n","\n","Early stopping occurred at epoch 67 with best_epoch = 57 and best_val_0_accuracy = 0.85952\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-07-06 05:51:50,811] Trial 17 finished with value: 0.8595178719866999 and parameters: {'n_d': 17, 'n_steps': 4, 'gamma': 1.4195274794104864, 'n_independent': 2, 'n_shared': 3, 'momentum': 0.1916212552830067}. Best is trial 3 with value: 0.8694929343308395.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 0.76741 | val_0_accuracy: 0.5187  |  0:00:01s\n","epoch 1  | loss: 0.56657 | val_0_accuracy: 0.51621 |  0:00:02s\n","epoch 2  | loss: 0.50284 | val_0_accuracy: 0.53948 |  0:00:03s\n","epoch 3  | loss: 0.49862 | val_0_accuracy: 0.54115 |  0:00:04s\n","epoch 4  | loss: 0.48924 | val_0_accuracy: 0.55445 |  0:00:05s\n","epoch 5  | loss: 0.49323 | val_0_accuracy: 0.57107 |  0:00:06s\n","epoch 6  | loss: 0.48686 | val_0_accuracy: 0.56608 |  0:00:07s\n","epoch 7  | loss: 0.48951 | val_0_accuracy: 0.61513 |  0:00:07s\n","epoch 8  | loss: 0.48065 | val_0_accuracy: 0.60515 |  0:00:08s\n","epoch 9  | loss: 0.48806 | val_0_accuracy: 0.61762 |  0:00:09s\n","epoch 10 | loss: 0.47104 | val_0_accuracy: 0.6409  |  0:00:10s\n","epoch 11 | loss: 0.45894 | val_0_accuracy: 0.64339 |  0:00:11s\n","epoch 12 | loss: 0.46083 | val_0_accuracy: 0.69576 |  0:00:13s\n","epoch 13 | loss: 0.45476 | val_0_accuracy: 0.72569 |  0:00:14s\n","epoch 14 | loss: 0.44306 | val_0_accuracy: 0.72984 |  0:00:15s\n","epoch 15 | loss: 0.43599 | val_0_accuracy: 0.73566 |  0:00:16s\n","epoch 16 | loss: 0.44882 | val_0_accuracy: 0.7448  |  0:00:17s\n","epoch 17 | loss: 0.44738 | val_0_accuracy: 0.76642 |  0:00:18s\n","epoch 18 | loss: 0.43593 | val_0_accuracy: 0.76143 |  0:00:19s\n","epoch 19 | loss: 0.4516  | val_0_accuracy: 0.75561 |  0:00:20s\n","epoch 20 | loss: 0.47714 | val_0_accuracy: 0.75727 |  0:00:21s\n","epoch 21 | loss: 0.473   | val_0_accuracy: 0.75229 |  0:00:22s\n","epoch 22 | loss: 0.45604 | val_0_accuracy: 0.75145 |  0:00:23s\n","epoch 23 | loss: 0.44188 | val_0_accuracy: 0.7581  |  0:00:24s\n","epoch 24 | loss: 0.44803 | val_0_accuracy: 0.75478 |  0:00:25s\n","epoch 25 | loss: 0.4447  | val_0_accuracy: 0.7714  |  0:00:26s\n","epoch 26 | loss: 0.4413  | val_0_accuracy: 0.77556 |  0:00:27s\n","epoch 27 | loss: 0.43376 | val_0_accuracy: 0.77224 |  0:00:28s\n","epoch 28 | loss: 0.43474 | val_0_accuracy: 0.75644 |  0:00:29s\n","epoch 29 | loss: 0.45214 | val_0_accuracy: 0.76642 |  0:00:30s\n","epoch 30 | loss: 0.44039 | val_0_accuracy: 0.75644 |  0:00:30s\n","epoch 31 | loss: 0.43687 | val_0_accuracy: 0.7714  |  0:00:31s\n","epoch 32 | loss: 0.43992 | val_0_accuracy: 0.77639 |  0:00:32s\n","epoch 33 | loss: 0.4309  | val_0_accuracy: 0.78803 |  0:00:33s\n","epoch 34 | loss: 0.41984 | val_0_accuracy: 0.77972 |  0:00:35s\n","epoch 35 | loss: 0.4227  | val_0_accuracy: 0.80715 |  0:00:36s\n","epoch 36 | loss: 0.41812 | val_0_accuracy: 0.79634 |  0:00:37s\n","epoch 37 | loss: 0.4164  | val_0_accuracy: 0.7847  |  0:00:38s\n","epoch 38 | loss: 0.42317 | val_0_accuracy: 0.78969 |  0:00:39s\n","epoch 39 | loss: 0.41956 | val_0_accuracy: 0.81463 |  0:00:40s\n","epoch 40 | loss: 0.41299 | val_0_accuracy: 0.81047 |  0:00:41s\n","epoch 41 | loss: 0.4077  | val_0_accuracy: 0.81131 |  0:00:41s\n","epoch 42 | loss: 0.40346 | val_0_accuracy: 0.81297 |  0:00:42s\n","epoch 43 | loss: 0.40196 | val_0_accuracy: 0.80382 |  0:00:43s\n","epoch 44 | loss: 0.39776 | val_0_accuracy: 0.8271  |  0:00:44s\n","epoch 45 | loss: 0.3942  | val_0_accuracy: 0.82294 |  0:00:45s\n","epoch 46 | loss: 0.40067 | val_0_accuracy: 0.82045 |  0:00:46s\n","epoch 47 | loss: 0.40237 | val_0_accuracy: 0.82211 |  0:00:47s\n","epoch 48 | loss: 0.39728 | val_0_accuracy: 0.81962 |  0:00:48s\n","epoch 49 | loss: 0.39684 | val_0_accuracy: 0.83209 |  0:00:49s\n","epoch 50 | loss: 0.39148 | val_0_accuracy: 0.82377 |  0:00:50s\n","epoch 51 | loss: 0.38542 | val_0_accuracy: 0.82128 |  0:00:51s\n","epoch 52 | loss: 0.39178 | val_0_accuracy: 0.82128 |  0:00:52s\n","epoch 53 | loss: 0.39664 | val_0_accuracy: 0.81047 |  0:00:53s\n","epoch 54 | loss: 0.42017 | val_0_accuracy: 0.79634 |  0:00:54s\n","epoch 55 | loss: 0.43536 | val_0_accuracy: 0.81962 |  0:00:55s\n","epoch 56 | loss: 0.41324 | val_0_accuracy: 0.83042 |  0:00:56s\n","epoch 57 | loss: 0.40116 | val_0_accuracy: 0.82793 |  0:00:57s\n","epoch 58 | loss: 0.41037 | val_0_accuracy: 0.83042 |  0:00:58s\n","epoch 59 | loss: 0.40161 | val_0_accuracy: 0.83126 |  0:00:59s\n","\n","Early stopping occurred at epoch 59 with best_epoch = 49 and best_val_0_accuracy = 0.83209\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-07-06 05:52:51,204] Trial 18 finished with value: 0.8320864505403158 and parameters: {'n_d': 29, 'n_steps': 5, 'gamma': 1.8071054223210226, 'n_independent': 5, 'n_shared': 4, 'momentum': 0.2433319597179364}. Best is trial 3 with value: 0.8694929343308395.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 0.79436 | val_0_accuracy: 0.52203 |  0:00:01s\n","epoch 1  | loss: 0.55416 | val_0_accuracy: 0.59102 |  0:00:02s\n","epoch 2  | loss: 0.53376 | val_0_accuracy: 0.61014 |  0:00:03s\n","epoch 3  | loss: 0.4931  | val_0_accuracy: 0.51205 |  0:00:04s\n","epoch 4  | loss: 0.49734 | val_0_accuracy: 0.55195 |  0:00:05s\n","epoch 5  | loss: 0.45148 | val_0_accuracy: 0.64339 |  0:00:06s\n","epoch 6  | loss: 0.45021 | val_0_accuracy: 0.63591 |  0:00:07s\n","epoch 7  | loss: 0.44033 | val_0_accuracy: 0.69077 |  0:00:08s\n","epoch 8  | loss: 0.43061 | val_0_accuracy: 0.67747 |  0:00:09s\n","epoch 9  | loss: 0.41559 | val_0_accuracy: 0.70574 |  0:00:10s\n","epoch 10 | loss: 0.40468 | val_0_accuracy: 0.72402 |  0:00:11s\n","epoch 11 | loss: 0.39668 | val_0_accuracy: 0.72319 |  0:00:12s\n","epoch 12 | loss: 0.3928  | val_0_accuracy: 0.70158 |  0:00:14s\n","epoch 13 | loss: 0.38856 | val_0_accuracy: 0.71322 |  0:00:15s\n","epoch 14 | loss: 0.38445 | val_0_accuracy: 0.73067 |  0:00:16s\n","epoch 15 | loss: 0.38575 | val_0_accuracy: 0.72485 |  0:00:17s\n","epoch 16 | loss: 0.39059 | val_0_accuracy: 0.72735 |  0:00:18s\n","epoch 17 | loss: 0.38767 | val_0_accuracy: 0.74896 |  0:00:19s\n","epoch 18 | loss: 0.38167 | val_0_accuracy: 0.72153 |  0:00:20s\n","epoch 19 | loss: 0.37957 | val_0_accuracy: 0.74397 |  0:00:21s\n","epoch 20 | loss: 0.38192 | val_0_accuracy: 0.76642 |  0:00:22s\n","epoch 21 | loss: 0.38349 | val_0_accuracy: 0.75395 |  0:00:23s\n","epoch 22 | loss: 0.3831  | val_0_accuracy: 0.74148 |  0:00:24s\n","epoch 23 | loss: 0.39155 | val_0_accuracy: 0.76226 |  0:00:25s\n","epoch 24 | loss: 0.37705 | val_0_accuracy: 0.75894 |  0:00:26s\n","epoch 25 | loss: 0.37896 | val_0_accuracy: 0.7581  |  0:00:27s\n","epoch 26 | loss: 0.37976 | val_0_accuracy: 0.77972 |  0:00:29s\n","epoch 27 | loss: 0.38287 | val_0_accuracy: 0.79551 |  0:00:30s\n","epoch 28 | loss: 0.37767 | val_0_accuracy: 0.80299 |  0:00:31s\n","epoch 29 | loss: 0.37365 | val_0_accuracy: 0.80216 |  0:00:32s\n","epoch 30 | loss: 0.3726  | val_0_accuracy: 0.81546 |  0:00:33s\n","epoch 31 | loss: 0.3809  | val_0_accuracy: 0.80964 |  0:00:34s\n","epoch 32 | loss: 0.3705  | val_0_accuracy: 0.81463 |  0:00:35s\n","epoch 33 | loss: 0.37634 | val_0_accuracy: 0.81712 |  0:00:36s\n","epoch 34 | loss: 0.37012 | val_0_accuracy: 0.82876 |  0:00:37s\n","epoch 35 | loss: 0.36469 | val_0_accuracy: 0.82461 |  0:00:38s\n","epoch 36 | loss: 0.35816 | val_0_accuracy: 0.81712 |  0:00:40s\n","epoch 37 | loss: 0.36398 | val_0_accuracy: 0.84705 |  0:00:41s\n","epoch 38 | loss: 0.35939 | val_0_accuracy: 0.84123 |  0:00:42s\n","epoch 39 | loss: 0.36337 | val_0_accuracy: 0.84871 |  0:00:43s\n","epoch 40 | loss: 0.36221 | val_0_accuracy: 0.84539 |  0:00:44s\n","epoch 41 | loss: 0.35496 | val_0_accuracy: 0.84123 |  0:00:45s\n","epoch 42 | loss: 0.35416 | val_0_accuracy: 0.83957 |  0:00:46s\n","epoch 43 | loss: 0.34939 | val_0_accuracy: 0.84705 |  0:00:47s\n","epoch 44 | loss: 0.35793 | val_0_accuracy: 0.83209 |  0:00:48s\n","epoch 45 | loss: 0.36236 | val_0_accuracy: 0.85536 |  0:00:49s\n","epoch 46 | loss: 0.35767 | val_0_accuracy: 0.84954 |  0:00:50s\n","epoch 47 | loss: 0.3488  | val_0_accuracy: 0.86118 |  0:00:52s\n","epoch 48 | loss: 0.35086 | val_0_accuracy: 0.85453 |  0:00:53s\n","epoch 49 | loss: 0.348   | val_0_accuracy: 0.85453 |  0:00:54s\n","epoch 50 | loss: 0.34224 | val_0_accuracy: 0.85869 |  0:00:55s\n","epoch 51 | loss: 0.34053 | val_0_accuracy: 0.85536 |  0:00:56s\n","epoch 52 | loss: 0.33824 | val_0_accuracy: 0.86118 |  0:00:57s\n","epoch 53 | loss: 0.33238 | val_0_accuracy: 0.85952 |  0:00:58s\n","epoch 54 | loss: 0.33201 | val_0_accuracy: 0.85702 |  0:00:59s\n","epoch 55 | loss: 0.32786 | val_0_accuracy: 0.85536 |  0:01:00s\n","epoch 56 | loss: 0.33009 | val_0_accuracy: 0.85287 |  0:01:01s\n","epoch 57 | loss: 0.33348 | val_0_accuracy: 0.85453 |  0:01:02s\n","\n","Early stopping occurred at epoch 57 with best_epoch = 47 and best_val_0_accuracy = 0.86118\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-07-06 05:53:54,583] Trial 19 finished with value: 0.8611803823773898 and parameters: {'n_d': 50, 'n_steps': 7, 'gamma': 1.2229949916412213, 'n_independent': 2, 'n_shared': 5, 'momentum': 0.05782220579205963}. Best is trial 3 with value: 0.8694929343308395.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 0.70379 | val_0_accuracy: 0.52452 |  0:00:00s\n","epoch 1  | loss: 0.50025 | val_0_accuracy: 0.5212  |  0:00:01s\n","epoch 2  | loss: 0.44949 | val_0_accuracy: 0.55362 |  0:00:02s\n","epoch 3  | loss: 0.41983 | val_0_accuracy: 0.56359 |  0:00:03s\n","epoch 4  | loss: 0.39172 | val_0_accuracy: 0.54281 |  0:00:03s\n","epoch 5  | loss: 0.37804 | val_0_accuracy: 0.54364 |  0:00:04s\n","epoch 6  | loss: 0.37329 | val_0_accuracy: 0.58687 |  0:00:05s\n","epoch 7  | loss: 0.3713  | val_0_accuracy: 0.59518 |  0:00:06s\n","epoch 8  | loss: 0.36374 | val_0_accuracy: 0.61347 |  0:00:06s\n","epoch 9  | loss: 0.3606  | val_0_accuracy: 0.63924 |  0:00:07s\n","epoch 10 | loss: 0.36207 | val_0_accuracy: 0.63674 |  0:00:08s\n","epoch 11 | loss: 0.35798 | val_0_accuracy: 0.62926 |  0:00:09s\n","epoch 12 | loss: 0.35856 | val_0_accuracy: 0.69825 |  0:00:10s\n","epoch 13 | loss: 0.35708 | val_0_accuracy: 0.68745 |  0:00:10s\n","epoch 14 | loss: 0.36028 | val_0_accuracy: 0.69576 |  0:00:11s\n","epoch 15 | loss: 0.35616 | val_0_accuracy: 0.71155 |  0:00:12s\n","epoch 16 | loss: 0.36324 | val_0_accuracy: 0.73815 |  0:00:13s\n","epoch 17 | loss: 0.35874 | val_0_accuracy: 0.73483 |  0:00:13s\n","epoch 18 | loss: 0.35268 | val_0_accuracy: 0.76808 |  0:00:14s\n","epoch 19 | loss: 0.34667 | val_0_accuracy: 0.77556 |  0:00:15s\n","epoch 20 | loss: 0.34239 | val_0_accuracy: 0.77057 |  0:00:16s\n","epoch 21 | loss: 0.34104 | val_0_accuracy: 0.75894 |  0:00:16s\n","epoch 22 | loss: 0.33069 | val_0_accuracy: 0.76808 |  0:00:17s\n","epoch 23 | loss: 0.33382 | val_0_accuracy: 0.79219 |  0:00:18s\n","epoch 24 | loss: 0.33413 | val_0_accuracy: 0.79052 |  0:00:19s\n","epoch 25 | loss: 0.33122 | val_0_accuracy: 0.7847  |  0:00:20s\n","epoch 26 | loss: 0.32569 | val_0_accuracy: 0.79967 |  0:00:20s\n","epoch 27 | loss: 0.33386 | val_0_accuracy: 0.80964 |  0:00:21s\n","epoch 28 | loss: 0.32993 | val_0_accuracy: 0.8138  |  0:00:22s\n","epoch 29 | loss: 0.32683 | val_0_accuracy: 0.80798 |  0:00:23s\n","epoch 30 | loss: 0.33205 | val_0_accuracy: 0.81297 |  0:00:24s\n","epoch 31 | loss: 0.33093 | val_0_accuracy: 0.81214 |  0:00:24s\n","epoch 32 | loss: 0.33096 | val_0_accuracy: 0.84123 |  0:00:25s\n","epoch 33 | loss: 0.33119 | val_0_accuracy: 0.83624 |  0:00:26s\n","epoch 34 | loss: 0.32854 | val_0_accuracy: 0.83624 |  0:00:27s\n","epoch 35 | loss: 0.33297 | val_0_accuracy: 0.83957 |  0:00:27s\n","epoch 36 | loss: 0.32906 | val_0_accuracy: 0.84788 |  0:00:28s\n","epoch 37 | loss: 0.32806 | val_0_accuracy: 0.84539 |  0:00:29s\n","epoch 38 | loss: 0.32323 | val_0_accuracy: 0.85453 |  0:00:30s\n","epoch 39 | loss: 0.32196 | val_0_accuracy: 0.85287 |  0:00:30s\n","epoch 40 | loss: 0.31484 | val_0_accuracy: 0.84539 |  0:00:31s\n","epoch 41 | loss: 0.3167  | val_0_accuracy: 0.85204 |  0:00:32s\n","epoch 42 | loss: 0.31533 | val_0_accuracy: 0.84622 |  0:00:33s\n","epoch 43 | loss: 0.31334 | val_0_accuracy: 0.84372 |  0:00:33s\n","epoch 44 | loss: 0.30676 | val_0_accuracy: 0.86284 |  0:00:34s\n","epoch 45 | loss: 0.31103 | val_0_accuracy: 0.85287 |  0:00:35s\n","epoch 46 | loss: 0.31537 | val_0_accuracy: 0.8537  |  0:00:36s\n","epoch 47 | loss: 0.31882 | val_0_accuracy: 0.85619 |  0:00:37s\n","epoch 48 | loss: 0.31513 | val_0_accuracy: 0.85453 |  0:00:37s\n","epoch 49 | loss: 0.31319 | val_0_accuracy: 0.85536 |  0:00:38s\n","epoch 50 | loss: 0.30881 | val_0_accuracy: 0.85619 |  0:00:39s\n","epoch 51 | loss: 0.31472 | val_0_accuracy: 0.84456 |  0:00:40s\n","epoch 52 | loss: 0.31413 | val_0_accuracy: 0.86118 |  0:00:40s\n","epoch 53 | loss: 0.31767 | val_0_accuracy: 0.85619 |  0:00:41s\n","epoch 54 | loss: 0.31203 | val_0_accuracy: 0.84622 |  0:00:42s\n","\n","Early stopping occurred at epoch 54 with best_epoch = 44 and best_val_0_accuracy = 0.86284\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-07-06 05:54:37,377] Trial 20 finished with value: 0.8628428927680798 and parameters: {'n_d': 39, 'n_steps': 4, 'gamma': 1.0982639115403645, 'n_independent': 4, 'n_shared': 4, 'momentum': 0.11468565882575951}. Best is trial 3 with value: 0.8694929343308395.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 0.63652 | val_0_accuracy: 0.54198 |  0:00:00s\n","epoch 1  | loss: 0.49159 | val_0_accuracy: 0.50042 |  0:00:01s\n","epoch 2  | loss: 0.4451  | val_0_accuracy: 0.48296 |  0:00:02s\n","epoch 3  | loss: 0.41999 | val_0_accuracy: 0.532   |  0:00:02s\n","epoch 4  | loss: 0.4058  | val_0_accuracy: 0.58022 |  0:00:03s\n","epoch 5  | loss: 0.39327 | val_0_accuracy: 0.59185 |  0:00:04s\n","epoch 6  | loss: 0.38621 | val_0_accuracy: 0.63508 |  0:00:04s\n","epoch 7  | loss: 0.37798 | val_0_accuracy: 0.62843 |  0:00:05s\n","epoch 8  | loss: 0.37202 | val_0_accuracy: 0.68662 |  0:00:06s\n","epoch 9  | loss: 0.36988 | val_0_accuracy: 0.7074  |  0:00:06s\n","epoch 10 | loss: 0.3636  | val_0_accuracy: 0.69659 |  0:00:07s\n","epoch 11 | loss: 0.35441 | val_0_accuracy: 0.70324 |  0:00:08s\n","epoch 12 | loss: 0.35233 | val_0_accuracy: 0.70075 |  0:00:08s\n","epoch 13 | loss: 0.3484  | val_0_accuracy: 0.71571 |  0:00:09s\n","epoch 14 | loss: 0.35142 | val_0_accuracy: 0.70407 |  0:00:10s\n","epoch 15 | loss: 0.35472 | val_0_accuracy: 0.7182  |  0:00:10s\n","epoch 16 | loss: 0.34443 | val_0_accuracy: 0.70989 |  0:00:11s\n","epoch 17 | loss: 0.34475 | val_0_accuracy: 0.72735 |  0:00:12s\n","epoch 18 | loss: 0.34323 | val_0_accuracy: 0.72485 |  0:00:12s\n","epoch 19 | loss: 0.34337 | val_0_accuracy: 0.73483 |  0:00:13s\n","epoch 20 | loss: 0.34872 | val_0_accuracy: 0.74231 |  0:00:14s\n","epoch 21 | loss: 0.34212 | val_0_accuracy: 0.76226 |  0:00:14s\n","epoch 22 | loss: 0.34203 | val_0_accuracy: 0.76309 |  0:00:15s\n","epoch 23 | loss: 0.34414 | val_0_accuracy: 0.7606  |  0:00:16s\n","epoch 24 | loss: 0.33782 | val_0_accuracy: 0.74813 |  0:00:16s\n","epoch 25 | loss: 0.3416  | val_0_accuracy: 0.78969 |  0:00:17s\n","epoch 26 | loss: 0.33761 | val_0_accuracy: 0.79551 |  0:00:18s\n","epoch 27 | loss: 0.33411 | val_0_accuracy: 0.8005  |  0:00:19s\n","epoch 28 | loss: 0.33106 | val_0_accuracy: 0.79468 |  0:00:19s\n","epoch 29 | loss: 0.3326  | val_0_accuracy: 0.80632 |  0:00:20s\n","epoch 30 | loss: 0.33014 | val_0_accuracy: 0.83126 |  0:00:21s\n","epoch 31 | loss: 0.32402 | val_0_accuracy: 0.81629 |  0:00:21s\n","epoch 32 | loss: 0.32752 | val_0_accuracy: 0.81546 |  0:00:22s\n","epoch 33 | loss: 0.32198 | val_0_accuracy: 0.83042 |  0:00:23s\n","epoch 34 | loss: 0.32361 | val_0_accuracy: 0.83707 |  0:00:23s\n","epoch 35 | loss: 0.32133 | val_0_accuracy: 0.82959 |  0:00:24s\n","epoch 36 | loss: 0.32191 | val_0_accuracy: 0.83126 |  0:00:25s\n","epoch 37 | loss: 0.31729 | val_0_accuracy: 0.83541 |  0:00:25s\n","epoch 38 | loss: 0.32101 | val_0_accuracy: 0.83791 |  0:00:26s\n","epoch 39 | loss: 0.31706 | val_0_accuracy: 0.83375 |  0:00:27s\n","epoch 40 | loss: 0.31898 | val_0_accuracy: 0.83624 |  0:00:27s\n","epoch 41 | loss: 0.31007 | val_0_accuracy: 0.84456 |  0:00:28s\n","epoch 42 | loss: 0.31812 | val_0_accuracy: 0.8537  |  0:00:29s\n","epoch 43 | loss: 0.32125 | val_0_accuracy: 0.85536 |  0:00:29s\n","epoch 44 | loss: 0.31214 | val_0_accuracy: 0.84622 |  0:00:30s\n","epoch 45 | loss: 0.31557 | val_0_accuracy: 0.84705 |  0:00:31s\n","epoch 46 | loss: 0.31336 | val_0_accuracy: 0.85453 |  0:00:31s\n","epoch 47 | loss: 0.31152 | val_0_accuracy: 0.84871 |  0:00:32s\n","epoch 48 | loss: 0.31865 | val_0_accuracy: 0.85536 |  0:00:33s\n","epoch 49 | loss: 0.3187  | val_0_accuracy: 0.85453 |  0:00:33s\n","epoch 50 | loss: 0.3146  | val_0_accuracy: 0.84954 |  0:00:34s\n","epoch 51 | loss: 0.31208 | val_0_accuracy: 0.86201 |  0:00:35s\n","epoch 52 | loss: 0.31154 | val_0_accuracy: 0.84954 |  0:00:36s\n","epoch 53 | loss: 0.30905 | val_0_accuracy: 0.85536 |  0:00:36s\n","epoch 54 | loss: 0.30756 | val_0_accuracy: 0.84705 |  0:00:37s\n","epoch 55 | loss: 0.31072 | val_0_accuracy: 0.85952 |  0:00:37s\n","epoch 56 | loss: 0.31046 | val_0_accuracy: 0.85869 |  0:00:38s\n","epoch 57 | loss: 0.30505 | val_0_accuracy: 0.85786 |  0:00:39s\n","epoch 58 | loss: 0.30517 | val_0_accuracy: 0.85121 |  0:00:40s\n","epoch 59 | loss: 0.30806 | val_0_accuracy: 0.85869 |  0:00:40s\n","epoch 60 | loss: 0.30169 | val_0_accuracy: 0.86534 |  0:00:41s\n","epoch 61 | loss: 0.30275 | val_0_accuracy: 0.85869 |  0:00:42s\n","epoch 62 | loss: 0.30383 | val_0_accuracy: 0.85786 |  0:00:42s\n","epoch 63 | loss: 0.3051  | val_0_accuracy: 0.86617 |  0:00:43s\n","epoch 64 | loss: 0.30539 | val_0_accuracy: 0.86201 |  0:00:44s\n","epoch 65 | loss: 0.30571 | val_0_accuracy: 0.86284 |  0:00:44s\n","epoch 66 | loss: 0.30294 | val_0_accuracy: 0.85952 |  0:00:45s\n","epoch 67 | loss: 0.30659 | val_0_accuracy: 0.86367 |  0:00:46s\n","epoch 68 | loss: 0.30446 | val_0_accuracy: 0.8537  |  0:00:46s\n","epoch 69 | loss: 0.30178 | val_0_accuracy: 0.86035 |  0:00:47s\n","epoch 70 | loss: 0.29989 | val_0_accuracy: 0.86118 |  0:00:48s\n","epoch 71 | loss: 0.30174 | val_0_accuracy: 0.86451 |  0:00:48s\n","epoch 72 | loss: 0.30346 | val_0_accuracy: 0.86367 |  0:00:49s\n","epoch 73 | loss: 0.29923 | val_0_accuracy: 0.86035 |  0:00:50s\n","\n","Early stopping occurred at epoch 73 with best_epoch = 63 and best_val_0_accuracy = 0.86617\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-07-06 05:55:27,899] Trial 21 finished with value: 0.8661679135494597 and parameters: {'n_d': 18, 'n_steps': 3, 'gamma': 1.0199958425015498, 'n_independent': 5, 'n_shared': 4, 'momentum': 0.08987363742382055}. Best is trial 3 with value: 0.8694929343308395.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 0.62726 | val_0_accuracy: 0.51538 |  0:00:00s\n","epoch 1  | loss: 0.47247 | val_0_accuracy: 0.50374 |  0:00:01s\n","epoch 2  | loss: 0.41896 | val_0_accuracy: 0.51704 |  0:00:02s\n","epoch 3  | loss: 0.39994 | val_0_accuracy: 0.51787 |  0:00:02s\n","epoch 4  | loss: 0.39054 | val_0_accuracy: 0.51621 |  0:00:03s\n","epoch 5  | loss: 0.38246 | val_0_accuracy: 0.51704 |  0:00:04s\n","epoch 6  | loss: 0.37859 | val_0_accuracy: 0.52452 |  0:00:04s\n","epoch 7  | loss: 0.37736 | val_0_accuracy: 0.57606 |  0:00:05s\n","epoch 8  | loss: 0.37309 | val_0_accuracy: 0.55445 |  0:00:06s\n","epoch 9  | loss: 0.36705 | val_0_accuracy: 0.59268 |  0:00:06s\n","epoch 10 | loss: 0.35985 | val_0_accuracy: 0.601   |  0:00:07s\n","epoch 11 | loss: 0.35588 | val_0_accuracy: 0.63342 |  0:00:08s\n","epoch 12 | loss: 0.3547  | val_0_accuracy: 0.60183 |  0:00:08s\n","epoch 13 | loss: 0.35456 | val_0_accuracy: 0.66085 |  0:00:09s\n","epoch 14 | loss: 0.34688 | val_0_accuracy: 0.66334 |  0:00:10s\n","epoch 15 | loss: 0.35179 | val_0_accuracy: 0.71737 |  0:00:11s\n","epoch 16 | loss: 0.34908 | val_0_accuracy: 0.71405 |  0:00:11s\n","epoch 17 | loss: 0.34815 | val_0_accuracy: 0.68662 |  0:00:12s\n","epoch 18 | loss: 0.35611 | val_0_accuracy: 0.65919 |  0:00:13s\n","epoch 19 | loss: 0.34505 | val_0_accuracy: 0.72984 |  0:00:13s\n","epoch 20 | loss: 0.34061 | val_0_accuracy: 0.74314 |  0:00:14s\n","epoch 21 | loss: 0.33602 | val_0_accuracy: 0.74647 |  0:00:15s\n","epoch 22 | loss: 0.32766 | val_0_accuracy: 0.74231 |  0:00:15s\n","epoch 23 | loss: 0.33313 | val_0_accuracy: 0.73732 |  0:00:16s\n","epoch 24 | loss: 0.33124 | val_0_accuracy: 0.7473  |  0:00:17s\n","epoch 25 | loss: 0.32722 | val_0_accuracy: 0.78969 |  0:00:17s\n","epoch 26 | loss: 0.32988 | val_0_accuracy: 0.79884 |  0:00:18s\n","epoch 27 | loss: 0.33027 | val_0_accuracy: 0.77805 |  0:00:19s\n","epoch 28 | loss: 0.32363 | val_0_accuracy: 0.76392 |  0:00:19s\n","epoch 29 | loss: 0.32244 | val_0_accuracy: 0.82544 |  0:00:20s\n","epoch 30 | loss: 0.32191 | val_0_accuracy: 0.8271  |  0:00:21s\n","epoch 31 | loss: 0.31697 | val_0_accuracy: 0.80881 |  0:00:21s\n","epoch 32 | loss: 0.32003 | val_0_accuracy: 0.83126 |  0:00:22s\n","epoch 33 | loss: 0.31793 | val_0_accuracy: 0.82627 |  0:00:23s\n","epoch 34 | loss: 0.3238  | val_0_accuracy: 0.83126 |  0:00:24s\n","epoch 35 | loss: 0.3127  | val_0_accuracy: 0.83042 |  0:00:24s\n","epoch 36 | loss: 0.31413 | val_0_accuracy: 0.83707 |  0:00:25s\n","epoch 37 | loss: 0.30997 | val_0_accuracy: 0.84871 |  0:00:26s\n","epoch 38 | loss: 0.30434 | val_0_accuracy: 0.85536 |  0:00:26s\n","epoch 39 | loss: 0.30561 | val_0_accuracy: 0.8537  |  0:00:27s\n","epoch 40 | loss: 0.30831 | val_0_accuracy: 0.85453 |  0:00:28s\n","epoch 41 | loss: 0.30838 | val_0_accuracy: 0.85453 |  0:00:28s\n","epoch 42 | loss: 0.30883 | val_0_accuracy: 0.8537  |  0:00:29s\n","epoch 43 | loss: 0.30847 | val_0_accuracy: 0.86118 |  0:00:30s\n","epoch 44 | loss: 0.30893 | val_0_accuracy: 0.85952 |  0:00:30s\n","epoch 45 | loss: 0.30666 | val_0_accuracy: 0.84705 |  0:00:31s\n","epoch 46 | loss: 0.31107 | val_0_accuracy: 0.85952 |  0:00:32s\n","epoch 47 | loss: 0.30446 | val_0_accuracy: 0.85952 |  0:00:32s\n","epoch 48 | loss: 0.3053  | val_0_accuracy: 0.85453 |  0:00:33s\n","epoch 49 | loss: 0.3092  | val_0_accuracy: 0.85952 |  0:00:34s\n","epoch 50 | loss: 0.30412 | val_0_accuracy: 0.86035 |  0:00:34s\n","epoch 51 | loss: 0.30188 | val_0_accuracy: 0.85121 |  0:00:35s\n","epoch 52 | loss: 0.2991  | val_0_accuracy: 0.86201 |  0:00:36s\n","epoch 53 | loss: 0.29583 | val_0_accuracy: 0.86866 |  0:00:36s\n","epoch 54 | loss: 0.29555 | val_0_accuracy: 0.85702 |  0:00:37s\n","epoch 55 | loss: 0.30513 | val_0_accuracy: 0.86367 |  0:00:38s\n","epoch 56 | loss: 0.30147 | val_0_accuracy: 0.86451 |  0:00:38s\n","epoch 57 | loss: 0.29839 | val_0_accuracy: 0.85204 |  0:00:39s\n","epoch 58 | loss: 0.30095 | val_0_accuracy: 0.86949 |  0:00:40s\n","epoch 59 | loss: 0.30059 | val_0_accuracy: 0.85037 |  0:00:40s\n","epoch 60 | loss: 0.29555 | val_0_accuracy: 0.86118 |  0:00:41s\n","epoch 61 | loss: 0.29856 | val_0_accuracy: 0.86451 |  0:00:42s\n","epoch 62 | loss: 0.29289 | val_0_accuracy: 0.86035 |  0:00:42s\n","epoch 63 | loss: 0.29355 | val_0_accuracy: 0.86284 |  0:00:43s\n","epoch 64 | loss: 0.29664 | val_0_accuracy: 0.85619 |  0:00:44s\n","epoch 65 | loss: 0.29406 | val_0_accuracy: 0.8537  |  0:00:44s\n","epoch 66 | loss: 0.29861 | val_0_accuracy: 0.86284 |  0:00:45s\n","epoch 67 | loss: 0.29505 | val_0_accuracy: 0.86284 |  0:00:46s\n","epoch 68 | loss: 0.29762 | val_0_accuracy: 0.85952 |  0:00:46s\n","\n","Early stopping occurred at epoch 68 with best_epoch = 58 and best_val_0_accuracy = 0.86949\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-07-06 05:56:15,187] Trial 22 finished with value: 0.8694929343308395 and parameters: {'n_d': 27, 'n_steps': 3, 'gamma': 1.01898874361898, 'n_independent': 5, 'n_shared': 4, 'momentum': 0.016498364283712152}. Best is trial 3 with value: 0.8694929343308395.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 0.75029 | val_0_accuracy: 0.51455 |  0:00:00s\n","epoch 1  | loss: 0.50936 | val_0_accuracy: 0.51288 |  0:00:01s\n","epoch 2  | loss: 0.4529  | val_0_accuracy: 0.51704 |  0:00:02s\n","epoch 3  | loss: 0.44306 | val_0_accuracy: 0.51455 |  0:00:03s\n","epoch 4  | loss: 0.42142 | val_0_accuracy: 0.53367 |  0:00:03s\n","epoch 5  | loss: 0.41372 | val_0_accuracy: 0.51704 |  0:00:04s\n","epoch 6  | loss: 0.39325 | val_0_accuracy: 0.53865 |  0:00:05s\n","epoch 7  | loss: 0.38869 | val_0_accuracy: 0.52785 |  0:00:05s\n","epoch 8  | loss: 0.37645 | val_0_accuracy: 0.55777 |  0:00:06s\n","epoch 9  | loss: 0.36718 | val_0_accuracy: 0.60515 |  0:00:07s\n","epoch 10 | loss: 0.36754 | val_0_accuracy: 0.66833 |  0:00:08s\n","epoch 11 | loss: 0.36683 | val_0_accuracy: 0.65669 |  0:00:08s\n","epoch 12 | loss: 0.35933 | val_0_accuracy: 0.70823 |  0:00:09s\n","epoch 13 | loss: 0.36084 | val_0_accuracy: 0.72901 |  0:00:10s\n","epoch 14 | loss: 0.3535  | val_0_accuracy: 0.71488 |  0:00:11s\n","epoch 15 | loss: 0.35218 | val_0_accuracy: 0.72735 |  0:00:11s\n","epoch 16 | loss: 0.34743 | val_0_accuracy: 0.73067 |  0:00:12s\n","epoch 17 | loss: 0.35188 | val_0_accuracy: 0.74647 |  0:00:13s\n","epoch 18 | loss: 0.35033 | val_0_accuracy: 0.74397 |  0:00:14s\n","epoch 19 | loss: 0.35246 | val_0_accuracy: 0.74564 |  0:00:14s\n","epoch 20 | loss: 0.35573 | val_0_accuracy: 0.76974 |  0:00:15s\n","epoch 21 | loss: 0.35676 | val_0_accuracy: 0.76808 |  0:00:16s\n","epoch 22 | loss: 0.35614 | val_0_accuracy: 0.76475 |  0:00:17s\n","epoch 23 | loss: 0.35256 | val_0_accuracy: 0.77972 |  0:00:17s\n","epoch 24 | loss: 0.35413 | val_0_accuracy: 0.78387 |  0:00:18s\n","epoch 25 | loss: 0.35816 | val_0_accuracy: 0.80881 |  0:00:19s\n","epoch 26 | loss: 0.35592 | val_0_accuracy: 0.81712 |  0:00:19s\n","epoch 27 | loss: 0.35094 | val_0_accuracy: 0.83042 |  0:00:20s\n","epoch 28 | loss: 0.35252 | val_0_accuracy: 0.78803 |  0:00:21s\n","epoch 29 | loss: 0.34471 | val_0_accuracy: 0.82045 |  0:00:22s\n","epoch 30 | loss: 0.3464  | val_0_accuracy: 0.84456 |  0:00:23s\n","epoch 31 | loss: 0.34187 | val_0_accuracy: 0.81796 |  0:00:23s\n","epoch 32 | loss: 0.33843 | val_0_accuracy: 0.84289 |  0:00:24s\n","epoch 33 | loss: 0.34082 | val_0_accuracy: 0.83126 |  0:00:25s\n","epoch 34 | loss: 0.34636 | val_0_accuracy: 0.84206 |  0:00:25s\n","epoch 35 | loss: 0.33841 | val_0_accuracy: 0.82377 |  0:00:26s\n","epoch 36 | loss: 0.33901 | val_0_accuracy: 0.85121 |  0:00:27s\n","epoch 37 | loss: 0.33997 | val_0_accuracy: 0.85702 |  0:00:28s\n","epoch 38 | loss: 0.33831 | val_0_accuracy: 0.85453 |  0:00:28s\n","epoch 39 | loss: 0.33602 | val_0_accuracy: 0.83375 |  0:00:29s\n","epoch 40 | loss: 0.33406 | val_0_accuracy: 0.85204 |  0:00:30s\n","epoch 41 | loss: 0.33227 | val_0_accuracy: 0.86617 |  0:00:30s\n","epoch 42 | loss: 0.33355 | val_0_accuracy: 0.85453 |  0:00:31s\n","epoch 43 | loss: 0.33284 | val_0_accuracy: 0.84372 |  0:00:32s\n","epoch 44 | loss: 0.33285 | val_0_accuracy: 0.85952 |  0:00:33s\n","epoch 45 | loss: 0.33248 | val_0_accuracy: 0.85869 |  0:00:33s\n","epoch 46 | loss: 0.33248 | val_0_accuracy: 0.85786 |  0:00:34s\n","epoch 47 | loss: 0.33084 | val_0_accuracy: 0.85287 |  0:00:35s\n","epoch 48 | loss: 0.3268  | val_0_accuracy: 0.85619 |  0:00:36s\n","epoch 49 | loss: 0.32342 | val_0_accuracy: 0.85453 |  0:00:36s\n","epoch 50 | loss: 0.32559 | val_0_accuracy: 0.85869 |  0:00:37s\n","epoch 51 | loss: 0.32734 | val_0_accuracy: 0.85786 |  0:00:38s\n","\n","Early stopping occurred at epoch 51 with best_epoch = 41 and best_val_0_accuracy = 0.86617\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-07-06 05:56:53,889] Trial 23 finished with value: 0.8661679135494597 and parameters: {'n_d': 21, 'n_steps': 3, 'gamma': 1.1868149110713497, 'n_independent': 5, 'n_shared': 5, 'momentum': 0.06822953870196186}. Best is trial 3 with value: 0.8694929343308395.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 0.84667 | val_0_accuracy: 0.50291 |  0:00:00s\n","epoch 1  | loss: 0.52379 | val_0_accuracy: 0.50042 |  0:00:01s\n","epoch 2  | loss: 0.48265 | val_0_accuracy: 0.5611  |  0:00:02s\n","epoch 3  | loss: 0.4512  | val_0_accuracy: 0.5719  |  0:00:02s\n","epoch 4  | loss: 0.43052 | val_0_accuracy: 0.62012 |  0:00:03s\n","epoch 5  | loss: 0.41976 | val_0_accuracy: 0.62178 |  0:00:04s\n","epoch 6  | loss: 0.40839 | val_0_accuracy: 0.65669 |  0:00:05s\n","epoch 7  | loss: 0.41038 | val_0_accuracy: 0.66251 |  0:00:05s\n","epoch 8  | loss: 0.39849 | val_0_accuracy: 0.68911 |  0:00:06s\n","epoch 9  | loss: 0.39415 | val_0_accuracy: 0.71405 |  0:00:07s\n","epoch 10 | loss: 0.39154 | val_0_accuracy: 0.7049  |  0:00:07s\n","epoch 11 | loss: 0.3861  | val_0_accuracy: 0.68163 |  0:00:08s\n","epoch 12 | loss: 0.37508 | val_0_accuracy: 0.66002 |  0:00:09s\n","epoch 13 | loss: 0.36874 | val_0_accuracy: 0.65835 |  0:00:09s\n","epoch 14 | loss: 0.36615 | val_0_accuracy: 0.68579 |  0:00:10s\n","epoch 15 | loss: 0.35745 | val_0_accuracy: 0.70989 |  0:00:11s\n","epoch 16 | loss: 0.36306 | val_0_accuracy: 0.73317 |  0:00:11s\n","epoch 17 | loss: 0.36067 | val_0_accuracy: 0.72901 |  0:00:12s\n","epoch 18 | loss: 0.3547  | val_0_accuracy: 0.75145 |  0:00:13s\n","epoch 19 | loss: 0.35564 | val_0_accuracy: 0.75062 |  0:00:14s\n","epoch 20 | loss: 0.35797 | val_0_accuracy: 0.73483 |  0:00:14s\n","epoch 21 | loss: 0.35507 | val_0_accuracy: 0.75644 |  0:00:15s\n","epoch 22 | loss: 0.34964 | val_0_accuracy: 0.77889 |  0:00:16s\n","epoch 23 | loss: 0.34999 | val_0_accuracy: 0.76642 |  0:00:16s\n","epoch 24 | loss: 0.34644 | val_0_accuracy: 0.76725 |  0:00:17s\n","epoch 25 | loss: 0.3465  | val_0_accuracy: 0.7739  |  0:00:18s\n","epoch 26 | loss: 0.34394 | val_0_accuracy: 0.7872  |  0:00:18s\n","epoch 27 | loss: 0.34037 | val_0_accuracy: 0.78886 |  0:00:19s\n","epoch 28 | loss: 0.35178 | val_0_accuracy: 0.80299 |  0:00:20s\n","epoch 29 | loss: 0.35231 | val_0_accuracy: 0.8005  |  0:00:21s\n","epoch 30 | loss: 0.35409 | val_0_accuracy: 0.79468 |  0:00:21s\n","epoch 31 | loss: 0.3524  | val_0_accuracy: 0.82627 |  0:00:22s\n","epoch 32 | loss: 0.34935 | val_0_accuracy: 0.8271  |  0:00:23s\n","epoch 33 | loss: 0.34855 | val_0_accuracy: 0.81214 |  0:00:23s\n","epoch 34 | loss: 0.35715 | val_0_accuracy: 0.83957 |  0:00:24s\n","epoch 35 | loss: 0.34809 | val_0_accuracy: 0.8404  |  0:00:25s\n","epoch 36 | loss: 0.34377 | val_0_accuracy: 0.83541 |  0:00:25s\n","epoch 37 | loss: 0.3463  | val_0_accuracy: 0.82461 |  0:00:26s\n","epoch 38 | loss: 0.34799 | val_0_accuracy: 0.83874 |  0:00:27s\n","epoch 39 | loss: 0.34016 | val_0_accuracy: 0.84954 |  0:00:27s\n","epoch 40 | loss: 0.33784 | val_0_accuracy: 0.85037 |  0:00:28s\n","epoch 41 | loss: 0.33878 | val_0_accuracy: 0.85121 |  0:00:29s\n","epoch 42 | loss: 0.33725 | val_0_accuracy: 0.85204 |  0:00:30s\n","epoch 43 | loss: 0.33807 | val_0_accuracy: 0.8537  |  0:00:30s\n","epoch 44 | loss: 0.3345  | val_0_accuracy: 0.84622 |  0:00:31s\n","epoch 45 | loss: 0.3316  | val_0_accuracy: 0.84539 |  0:00:32s\n","epoch 46 | loss: 0.33002 | val_0_accuracy: 0.84622 |  0:00:32s\n","epoch 47 | loss: 0.3276  | val_0_accuracy: 0.85869 |  0:00:33s\n","epoch 48 | loss: 0.32439 | val_0_accuracy: 0.85952 |  0:00:34s\n","epoch 49 | loss: 0.32516 | val_0_accuracy: 0.85619 |  0:00:34s\n","epoch 50 | loss: 0.32368 | val_0_accuracy: 0.85453 |  0:00:35s\n","epoch 51 | loss: 0.3247  | val_0_accuracy: 0.86201 |  0:00:36s\n","epoch 52 | loss: 0.32555 | val_0_accuracy: 0.85952 |  0:00:37s\n","epoch 53 | loss: 0.32375 | val_0_accuracy: 0.85453 |  0:00:37s\n","epoch 54 | loss: 0.32244 | val_0_accuracy: 0.85786 |  0:00:38s\n","epoch 55 | loss: 0.31887 | val_0_accuracy: 0.86367 |  0:00:39s\n","epoch 56 | loss: 0.32057 | val_0_accuracy: 0.84954 |  0:00:39s\n","epoch 57 | loss: 0.32168 | val_0_accuracy: 0.85453 |  0:00:40s\n","epoch 58 | loss: 0.31499 | val_0_accuracy: 0.86284 |  0:00:41s\n","epoch 59 | loss: 0.31744 | val_0_accuracy: 0.86617 |  0:00:41s\n","epoch 60 | loss: 0.31554 | val_0_accuracy: 0.86284 |  0:00:42s\n","epoch 61 | loss: 0.32047 | val_0_accuracy: 0.86367 |  0:00:43s\n","epoch 62 | loss: 0.31783 | val_0_accuracy: 0.85869 |  0:00:44s\n","epoch 63 | loss: 0.31384 | val_0_accuracy: 0.86451 |  0:00:44s\n","epoch 64 | loss: 0.30921 | val_0_accuracy: 0.867   |  0:00:45s\n","epoch 65 | loss: 0.31312 | val_0_accuracy: 0.86284 |  0:00:46s\n","epoch 66 | loss: 0.31272 | val_0_accuracy: 0.86201 |  0:00:46s\n","epoch 67 | loss: 0.31183 | val_0_accuracy: 0.86118 |  0:00:47s\n","epoch 68 | loss: 0.31281 | val_0_accuracy: 0.86284 |  0:00:48s\n","epoch 69 | loss: 0.30801 | val_0_accuracy: 0.86201 |  0:00:48s\n","epoch 70 | loss: 0.31234 | val_0_accuracy: 0.86949 |  0:00:49s\n","epoch 71 | loss: 0.31299 | val_0_accuracy: 0.86451 |  0:00:50s\n","epoch 72 | loss: 0.31701 | val_0_accuracy: 0.86035 |  0:00:50s\n","epoch 73 | loss: 0.31628 | val_0_accuracy: 0.85619 |  0:00:51s\n","epoch 74 | loss: 0.30975 | val_0_accuracy: 0.87199 |  0:00:52s\n","epoch 75 | loss: 0.30782 | val_0_accuracy: 0.86617 |  0:00:53s\n","epoch 76 | loss: 0.31319 | val_0_accuracy: 0.85952 |  0:00:53s\n","epoch 77 | loss: 0.30979 | val_0_accuracy: 0.85952 |  0:00:54s\n","epoch 78 | loss: 0.31792 | val_0_accuracy: 0.8537  |  0:00:55s\n","epoch 79 | loss: 0.31373 | val_0_accuracy: 0.86035 |  0:00:55s\n","epoch 80 | loss: 0.32438 | val_0_accuracy: 0.85619 |  0:00:56s\n","epoch 81 | loss: 0.33645 | val_0_accuracy: 0.84954 |  0:00:57s\n","epoch 82 | loss: 0.33535 | val_0_accuracy: 0.85702 |  0:00:57s\n","epoch 83 | loss: 0.32325 | val_0_accuracy: 0.86201 |  0:00:58s\n","epoch 84 | loss: 0.3207  | val_0_accuracy: 0.85037 |  0:00:59s\n","\n","Early stopping occurred at epoch 84 with best_epoch = 74 and best_val_0_accuracy = 0.87199\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-07-06 05:57:53,440] Trial 24 finished with value: 0.8719866999168745 and parameters: {'n_d': 30, 'n_steps': 4, 'gamma': 1.3873724331661097, 'n_independent': 4, 'n_shared': 3, 'momentum': 0.17168963165489434}. Best is trial 24 with value: 0.8719866999168745.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 0.89267 | val_0_accuracy: 0.55195 |  0:00:00s\n","epoch 1  | loss: 0.53361 | val_0_accuracy: 0.51787 |  0:00:01s\n","epoch 2  | loss: 0.51068 | val_0_accuracy: 0.6251  |  0:00:02s\n","epoch 3  | loss: 0.48727 | val_0_accuracy: 0.56442 |  0:00:03s\n","epoch 4  | loss: 0.45238 | val_0_accuracy: 0.56858 |  0:00:04s\n","epoch 5  | loss: 0.45681 | val_0_accuracy: 0.58853 |  0:00:04s\n","epoch 6  | loss: 0.42963 | val_0_accuracy: 0.58105 |  0:00:05s\n","epoch 7  | loss: 0.41645 | val_0_accuracy: 0.58853 |  0:00:06s\n","epoch 8  | loss: 0.40338 | val_0_accuracy: 0.6251  |  0:00:07s\n","epoch 9  | loss: 0.3995  | val_0_accuracy: 0.6276  |  0:00:08s\n","epoch 10 | loss: 0.38809 | val_0_accuracy: 0.64755 |  0:00:08s\n","epoch 11 | loss: 0.38793 | val_0_accuracy: 0.65004 |  0:00:09s\n","epoch 12 | loss: 0.3835  | val_0_accuracy: 0.63092 |  0:00:10s\n","epoch 13 | loss: 0.38056 | val_0_accuracy: 0.66002 |  0:00:11s\n","epoch 14 | loss: 0.37968 | val_0_accuracy: 0.66999 |  0:00:12s\n","epoch 15 | loss: 0.37631 | val_0_accuracy: 0.7049  |  0:00:13s\n","epoch 16 | loss: 0.37147 | val_0_accuracy: 0.69077 |  0:00:13s\n","epoch 17 | loss: 0.36851 | val_0_accuracy: 0.71239 |  0:00:14s\n","epoch 18 | loss: 0.36834 | val_0_accuracy: 0.67082 |  0:00:15s\n","epoch 19 | loss: 0.36446 | val_0_accuracy: 0.75145 |  0:00:16s\n","epoch 20 | loss: 0.36933 | val_0_accuracy: 0.72984 |  0:00:17s\n","epoch 21 | loss: 0.3754  | val_0_accuracy: 0.73317 |  0:00:18s\n","epoch 22 | loss: 0.37184 | val_0_accuracy: 0.75977 |  0:00:18s\n","epoch 23 | loss: 0.37004 | val_0_accuracy: 0.7714  |  0:00:19s\n","epoch 24 | loss: 0.36817 | val_0_accuracy: 0.77556 |  0:00:20s\n","epoch 25 | loss: 0.36312 | val_0_accuracy: 0.77556 |  0:00:21s\n","epoch 26 | loss: 0.36187 | val_0_accuracy: 0.79468 |  0:00:22s\n","epoch 27 | loss: 0.36296 | val_0_accuracy: 0.79634 |  0:00:22s\n","epoch 28 | loss: 0.35548 | val_0_accuracy: 0.81297 |  0:00:23s\n","epoch 29 | loss: 0.35762 | val_0_accuracy: 0.80133 |  0:00:24s\n","epoch 30 | loss: 0.35609 | val_0_accuracy: 0.8005  |  0:00:25s\n","epoch 31 | loss: 0.35225 | val_0_accuracy: 0.81796 |  0:00:26s\n","epoch 32 | loss: 0.3509  | val_0_accuracy: 0.82211 |  0:00:27s\n","epoch 33 | loss: 0.35216 | val_0_accuracy: 0.83292 |  0:00:28s\n","epoch 34 | loss: 0.35135 | val_0_accuracy: 0.8138  |  0:00:28s\n","epoch 35 | loss: 0.3478  | val_0_accuracy: 0.84705 |  0:00:29s\n","epoch 36 | loss: 0.35546 | val_0_accuracy: 0.84123 |  0:00:30s\n","epoch 37 | loss: 0.35709 | val_0_accuracy: 0.84539 |  0:00:31s\n","epoch 38 | loss: 0.35914 | val_0_accuracy: 0.84705 |  0:00:32s\n","epoch 39 | loss: 0.35242 | val_0_accuracy: 0.85287 |  0:00:32s\n","epoch 40 | loss: 0.35342 | val_0_accuracy: 0.84206 |  0:00:33s\n","epoch 41 | loss: 0.36217 | val_0_accuracy: 0.84622 |  0:00:34s\n","epoch 42 | loss: 0.37716 | val_0_accuracy: 0.82377 |  0:00:35s\n","epoch 43 | loss: 0.38633 | val_0_accuracy: 0.81712 |  0:00:36s\n","epoch 44 | loss: 0.38159 | val_0_accuracy: 0.8271  |  0:00:37s\n","epoch 45 | loss: 0.37728 | val_0_accuracy: 0.84622 |  0:00:37s\n","epoch 46 | loss: 0.37307 | val_0_accuracy: 0.83375 |  0:00:38s\n","epoch 47 | loss: 0.36824 | val_0_accuracy: 0.83375 |  0:00:39s\n","epoch 48 | loss: 0.36412 | val_0_accuracy: 0.83957 |  0:00:40s\n","epoch 49 | loss: 0.36135 | val_0_accuracy: 0.84871 |  0:00:41s\n","\n","Early stopping occurred at epoch 49 with best_epoch = 39 and best_val_0_accuracy = 0.85287\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-07-06 05:58:35,026] Trial 25 finished with value: 0.8528678304239401 and parameters: {'n_d': 31, 'n_steps': 5, 'gamma': 1.427048351214876, 'n_independent': 4, 'n_shared': 3, 'momentum': 0.1586330675410263}. Best is trial 24 with value: 0.8719866999168745.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 1.10649 | val_0_accuracy: 0.52369 |  0:00:00s\n","epoch 1  | loss: 0.54635 | val_0_accuracy: 0.52369 |  0:00:01s\n","epoch 2  | loss: 0.47159 | val_0_accuracy: 0.53117 |  0:00:02s\n","epoch 3  | loss: 0.44191 | val_0_accuracy: 0.51122 |  0:00:02s\n","epoch 4  | loss: 0.42313 | val_0_accuracy: 0.51787 |  0:00:03s\n","epoch 5  | loss: 0.41356 | val_0_accuracy: 0.52037 |  0:00:04s\n","epoch 6  | loss: 0.40589 | val_0_accuracy: 0.57689 |  0:00:04s\n","epoch 7  | loss: 0.39788 | val_0_accuracy: 0.58437 |  0:00:05s\n","epoch 8  | loss: 0.40009 | val_0_accuracy: 0.68246 |  0:00:06s\n","epoch 9  | loss: 0.39848 | val_0_accuracy: 0.63924 |  0:00:06s\n","epoch 10 | loss: 0.39028 | val_0_accuracy: 0.59933 |  0:00:07s\n","epoch 11 | loss: 0.38842 | val_0_accuracy: 0.64589 |  0:00:08s\n","epoch 12 | loss: 0.38123 | val_0_accuracy: 0.6675  |  0:00:09s\n","epoch 13 | loss: 0.37787 | val_0_accuracy: 0.70989 |  0:00:09s\n","epoch 14 | loss: 0.37079 | val_0_accuracy: 0.72818 |  0:00:10s\n","epoch 15 | loss: 0.36717 | val_0_accuracy: 0.72319 |  0:00:11s\n","epoch 16 | loss: 0.35976 | val_0_accuracy: 0.73067 |  0:00:11s\n","epoch 17 | loss: 0.35199 | val_0_accuracy: 0.72402 |  0:00:12s\n","epoch 18 | loss: 0.34132 | val_0_accuracy: 0.71405 |  0:00:13s\n","epoch 19 | loss: 0.34147 | val_0_accuracy: 0.74647 |  0:00:13s\n","epoch 20 | loss: 0.33505 | val_0_accuracy: 0.75062 |  0:00:14s\n","epoch 21 | loss: 0.34124 | val_0_accuracy: 0.74065 |  0:00:15s\n","epoch 22 | loss: 0.33776 | val_0_accuracy: 0.7182  |  0:00:16s\n","epoch 23 | loss: 0.34045 | val_0_accuracy: 0.73982 |  0:00:16s\n","epoch 24 | loss: 0.33755 | val_0_accuracy: 0.75977 |  0:00:17s\n","epoch 25 | loss: 0.33572 | val_0_accuracy: 0.77722 |  0:00:18s\n","epoch 26 | loss: 0.3342  | val_0_accuracy: 0.79385 |  0:00:18s\n","epoch 27 | loss: 0.33341 | val_0_accuracy: 0.82128 |  0:00:19s\n","epoch 28 | loss: 0.32861 | val_0_accuracy: 0.81879 |  0:00:20s\n","epoch 29 | loss: 0.32397 | val_0_accuracy: 0.82294 |  0:00:20s\n","epoch 30 | loss: 0.32777 | val_0_accuracy: 0.81796 |  0:00:21s\n","epoch 31 | loss: 0.3223  | val_0_accuracy: 0.83707 |  0:00:22s\n","epoch 32 | loss: 0.32618 | val_0_accuracy: 0.84289 |  0:00:23s\n","epoch 33 | loss: 0.32754 | val_0_accuracy: 0.81796 |  0:00:23s\n","epoch 34 | loss: 0.32401 | val_0_accuracy: 0.83791 |  0:00:24s\n","epoch 35 | loss: 0.32593 | val_0_accuracy: 0.84871 |  0:00:25s\n","epoch 36 | loss: 0.32197 | val_0_accuracy: 0.83707 |  0:00:25s\n","epoch 37 | loss: 0.32657 | val_0_accuracy: 0.85037 |  0:00:26s\n","epoch 38 | loss: 0.32332 | val_0_accuracy: 0.85121 |  0:00:27s\n","epoch 39 | loss: 0.31977 | val_0_accuracy: 0.84871 |  0:00:28s\n","epoch 40 | loss: 0.32866 | val_0_accuracy: 0.85952 |  0:00:28s\n","epoch 41 | loss: 0.32837 | val_0_accuracy: 0.85869 |  0:00:29s\n","epoch 42 | loss: 0.32152 | val_0_accuracy: 0.86035 |  0:00:30s\n","epoch 43 | loss: 0.33873 | val_0_accuracy: 0.86035 |  0:00:30s\n","epoch 44 | loss: 0.34269 | val_0_accuracy: 0.86118 |  0:00:31s\n","epoch 45 | loss: 0.33986 | val_0_accuracy: 0.84539 |  0:00:32s\n","epoch 46 | loss: 0.33775 | val_0_accuracy: 0.84372 |  0:00:32s\n","epoch 47 | loss: 0.33141 | val_0_accuracy: 0.85204 |  0:00:33s\n","epoch 48 | loss: 0.33324 | val_0_accuracy: 0.85619 |  0:00:34s\n","epoch 49 | loss: 0.33307 | val_0_accuracy: 0.86534 |  0:00:34s\n","epoch 50 | loss: 0.33303 | val_0_accuracy: 0.86118 |  0:00:35s\n","epoch 51 | loss: 0.33033 | val_0_accuracy: 0.86284 |  0:00:36s\n","epoch 52 | loss: 0.31755 | val_0_accuracy: 0.86367 |  0:00:37s\n","epoch 53 | loss: 0.32276 | val_0_accuracy: 0.85952 |  0:00:37s\n","epoch 54 | loss: 0.32044 | val_0_accuracy: 0.86866 |  0:00:38s\n","epoch 55 | loss: 0.31807 | val_0_accuracy: 0.86783 |  0:00:39s\n","epoch 56 | loss: 0.31222 | val_0_accuracy: 0.86035 |  0:00:39s\n","epoch 57 | loss: 0.31835 | val_0_accuracy: 0.86451 |  0:00:40s\n","epoch 58 | loss: 0.31474 | val_0_accuracy: 0.85786 |  0:00:41s\n","epoch 59 | loss: 0.31312 | val_0_accuracy: 0.86118 |  0:00:41s\n","epoch 60 | loss: 0.31607 | val_0_accuracy: 0.86451 |  0:00:42s\n","epoch 61 | loss: 0.31822 | val_0_accuracy: 0.85121 |  0:00:43s\n","epoch 62 | loss: 0.31908 | val_0_accuracy: 0.87032 |  0:00:43s\n","epoch 63 | loss: 0.32383 | val_0_accuracy: 0.86534 |  0:00:44s\n","epoch 64 | loss: 0.32346 | val_0_accuracy: 0.85702 |  0:00:45s\n","epoch 65 | loss: 0.32006 | val_0_accuracy: 0.86284 |  0:00:46s\n","epoch 66 | loss: 0.31642 | val_0_accuracy: 0.86118 |  0:00:46s\n","epoch 67 | loss: 0.31916 | val_0_accuracy: 0.86949 |  0:00:47s\n","epoch 68 | loss: 0.31099 | val_0_accuracy: 0.85952 |  0:00:48s\n","epoch 69 | loss: 0.31353 | val_0_accuracy: 0.85786 |  0:00:48s\n","epoch 70 | loss: 0.31219 | val_0_accuracy: 0.85952 |  0:00:49s\n","epoch 71 | loss: 0.3126  | val_0_accuracy: 0.86783 |  0:00:50s\n","epoch 72 | loss: 0.31036 | val_0_accuracy: 0.85536 |  0:00:50s\n","\n","Early stopping occurred at epoch 72 with best_epoch = 62 and best_val_0_accuracy = 0.87032\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-07-06 05:59:26,327] Trial 26 finished with value: 0.8703241895261845 and parameters: {'n_d': 55, 'n_steps': 4, 'gamma': 1.3754382051045377, 'n_independent': 4, 'n_shared': 3, 'momentum': 0.21917827191344427}. Best is trial 24 with value: 0.8719866999168745.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 0.88315 | val_0_accuracy: 0.57772 |  0:00:00s\n","epoch 1  | loss: 0.62138 | val_0_accuracy: 0.51122 |  0:00:01s\n","epoch 2  | loss: 0.55155 | val_0_accuracy: 0.53865 |  0:00:02s\n","epoch 3  | loss: 0.50156 | val_0_accuracy: 0.56941 |  0:00:03s\n","epoch 4  | loss: 0.45632 | val_0_accuracy: 0.58022 |  0:00:04s\n","epoch 5  | loss: 0.45493 | val_0_accuracy: 0.58188 |  0:00:05s\n","epoch 6  | loss: 0.45108 | val_0_accuracy: 0.64256 |  0:00:06s\n","epoch 7  | loss: 0.44337 | val_0_accuracy: 0.66168 |  0:00:07s\n","epoch 8  | loss: 0.42916 | val_0_accuracy: 0.65835 |  0:00:08s\n","epoch 9  | loss: 0.42692 | val_0_accuracy: 0.6675  |  0:00:09s\n","epoch 10 | loss: 0.41572 | val_0_accuracy: 0.68745 |  0:00:10s\n","epoch 11 | loss: 0.40669 | val_0_accuracy: 0.70906 |  0:00:11s\n","epoch 12 | loss: 0.40083 | val_0_accuracy: 0.67997 |  0:00:12s\n","epoch 13 | loss: 0.40108 | val_0_accuracy: 0.69493 |  0:00:13s\n","epoch 14 | loss: 0.40033 | val_0_accuracy: 0.69825 |  0:00:14s\n","epoch 15 | loss: 0.4028  | val_0_accuracy: 0.73649 |  0:00:15s\n","epoch 16 | loss: 0.40284 | val_0_accuracy: 0.71654 |  0:00:16s\n","epoch 17 | loss: 0.38408 | val_0_accuracy: 0.71405 |  0:00:17s\n","epoch 18 | loss: 0.37846 | val_0_accuracy: 0.73732 |  0:00:18s\n","epoch 19 | loss: 0.38445 | val_0_accuracy: 0.74647 |  0:00:19s\n","epoch 20 | loss: 0.39015 | val_0_accuracy: 0.76475 |  0:00:20s\n","epoch 21 | loss: 0.38214 | val_0_accuracy: 0.7473  |  0:00:21s\n","epoch 22 | loss: 0.37609 | val_0_accuracy: 0.72818 |  0:00:22s\n","epoch 23 | loss: 0.36906 | val_0_accuracy: 0.75561 |  0:00:23s\n","epoch 24 | loss: 0.3639  | val_0_accuracy: 0.78803 |  0:00:24s\n","epoch 25 | loss: 0.36403 | val_0_accuracy: 0.7872  |  0:00:25s\n","epoch 26 | loss: 0.36632 | val_0_accuracy: 0.75977 |  0:00:25s\n","epoch 27 | loss: 0.3601  | val_0_accuracy: 0.79468 |  0:00:26s\n","epoch 28 | loss: 0.36262 | val_0_accuracy: 0.79717 |  0:00:27s\n","epoch 29 | loss: 0.36837 | val_0_accuracy: 0.81297 |  0:00:28s\n","epoch 30 | loss: 0.36939 | val_0_accuracy: 0.82544 |  0:00:29s\n","epoch 31 | loss: 0.37625 | val_0_accuracy: 0.83375 |  0:00:30s\n","epoch 32 | loss: 0.38879 | val_0_accuracy: 0.81629 |  0:00:31s\n","epoch 33 | loss: 0.38102 | val_0_accuracy: 0.81463 |  0:00:32s\n","epoch 34 | loss: 0.37199 | val_0_accuracy: 0.82461 |  0:00:33s\n","epoch 35 | loss: 0.36933 | val_0_accuracy: 0.8271  |  0:00:34s\n","epoch 36 | loss: 0.37022 | val_0_accuracy: 0.80964 |  0:00:35s\n","epoch 37 | loss: 0.36056 | val_0_accuracy: 0.83126 |  0:00:36s\n","epoch 38 | loss: 0.36543 | val_0_accuracy: 0.83707 |  0:00:37s\n","epoch 39 | loss: 0.36219 | val_0_accuracy: 0.84456 |  0:00:38s\n","epoch 40 | loss: 0.35811 | val_0_accuracy: 0.83458 |  0:00:39s\n","epoch 41 | loss: 0.35804 | val_0_accuracy: 0.84123 |  0:00:40s\n","epoch 42 | loss: 0.35646 | val_0_accuracy: 0.84206 |  0:00:41s\n","epoch 43 | loss: 0.34699 | val_0_accuracy: 0.84123 |  0:00:42s\n","epoch 44 | loss: 0.35418 | val_0_accuracy: 0.82876 |  0:00:43s\n","epoch 45 | loss: 0.35994 | val_0_accuracy: 0.84705 |  0:00:43s\n","epoch 46 | loss: 0.35257 | val_0_accuracy: 0.82959 |  0:00:44s\n","epoch 47 | loss: 0.34863 | val_0_accuracy: 0.85204 |  0:00:45s\n","epoch 48 | loss: 0.35146 | val_0_accuracy: 0.85536 |  0:00:46s\n","epoch 49 | loss: 0.34956 | val_0_accuracy: 0.84705 |  0:00:47s\n","epoch 50 | loss: 0.34324 | val_0_accuracy: 0.84954 |  0:00:48s\n","epoch 51 | loss: 0.33656 | val_0_accuracy: 0.8537  |  0:00:49s\n","epoch 52 | loss: 0.33812 | val_0_accuracy: 0.85204 |  0:00:50s\n","epoch 53 | loss: 0.34002 | val_0_accuracy: 0.84705 |  0:00:51s\n","epoch 54 | loss: 0.33549 | val_0_accuracy: 0.85702 |  0:00:52s\n","epoch 55 | loss: 0.34361 | val_0_accuracy: 0.85037 |  0:00:53s\n","epoch 56 | loss: 0.35282 | val_0_accuracy: 0.83791 |  0:00:54s\n","epoch 57 | loss: 0.35688 | val_0_accuracy: 0.84954 |  0:00:55s\n","epoch 58 | loss: 0.354   | val_0_accuracy: 0.84871 |  0:00:56s\n","epoch 59 | loss: 0.34785 | val_0_accuracy: 0.84954 |  0:00:57s\n","epoch 60 | loss: 0.34739 | val_0_accuracy: 0.85453 |  0:00:58s\n","epoch 61 | loss: 0.34269 | val_0_accuracy: 0.85952 |  0:00:59s\n","epoch 62 | loss: 0.33902 | val_0_accuracy: 0.84622 |  0:01:00s\n","epoch 63 | loss: 0.34295 | val_0_accuracy: 0.83957 |  0:01:01s\n","epoch 64 | loss: 0.33866 | val_0_accuracy: 0.86118 |  0:01:02s\n","epoch 65 | loss: 0.33699 | val_0_accuracy: 0.85869 |  0:01:03s\n","epoch 66 | loss: 0.33436 | val_0_accuracy: 0.85869 |  0:01:04s\n","epoch 67 | loss: 0.33262 | val_0_accuracy: 0.85952 |  0:01:05s\n","epoch 68 | loss: 0.33085 | val_0_accuracy: 0.86284 |  0:01:05s\n","epoch 69 | loss: 0.32927 | val_0_accuracy: 0.86367 |  0:01:06s\n","epoch 70 | loss: 0.32876 | val_0_accuracy: 0.86367 |  0:01:07s\n","epoch 71 | loss: 0.33078 | val_0_accuracy: 0.86201 |  0:01:08s\n","epoch 72 | loss: 0.33064 | val_0_accuracy: 0.85952 |  0:01:09s\n","epoch 73 | loss: 0.33215 | val_0_accuracy: 0.85287 |  0:01:10s\n","epoch 74 | loss: 0.32691 | val_0_accuracy: 0.86783 |  0:01:11s\n","epoch 75 | loss: 0.32381 | val_0_accuracy: 0.86284 |  0:01:12s\n","epoch 76 | loss: 0.32805 | val_0_accuracy: 0.86118 |  0:01:13s\n","epoch 77 | loss: 0.32245 | val_0_accuracy: 0.86949 |  0:01:14s\n","epoch 78 | loss: 0.32534 | val_0_accuracy: 0.8537  |  0:01:15s\n","epoch 79 | loss: 0.32954 | val_0_accuracy: 0.85869 |  0:01:16s\n","epoch 80 | loss: 0.32945 | val_0_accuracy: 0.85037 |  0:01:17s\n","epoch 81 | loss: 0.32876 | val_0_accuracy: 0.85786 |  0:01:18s\n","epoch 82 | loss: 0.32663 | val_0_accuracy: 0.85619 |  0:01:19s\n","epoch 83 | loss: 0.32661 | val_0_accuracy: 0.86284 |  0:01:20s\n","epoch 84 | loss: 0.33086 | val_0_accuracy: 0.8537  |  0:01:21s\n","epoch 85 | loss: 0.32281 | val_0_accuracy: 0.85204 |  0:01:22s\n","epoch 86 | loss: 0.33091 | val_0_accuracy: 0.85786 |  0:01:23s\n","epoch 87 | loss: 0.33584 | val_0_accuracy: 0.85619 |  0:01:24s\n","\n","Early stopping occurred at epoch 87 with best_epoch = 77 and best_val_0_accuracy = 0.86949\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-07-06 06:00:50,950] Trial 27 finished with value: 0.8694929343308395 and parameters: {'n_d': 55, 'n_steps': 6, 'gamma': 1.3567412018353053, 'n_independent': 4, 'n_shared': 3, 'momentum': 0.22771162402890183}. Best is trial 24 with value: 0.8719866999168745.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 0.70872 | val_0_accuracy: 0.51372 |  0:00:00s\n","epoch 1  | loss: 0.50748 | val_0_accuracy: 0.52203 |  0:00:01s\n","epoch 2  | loss: 0.45921 | val_0_accuracy: 0.59933 |  0:00:02s\n","epoch 3  | loss: 0.43761 | val_0_accuracy: 0.52785 |  0:00:02s\n","epoch 4  | loss: 0.4148  | val_0_accuracy: 0.62843 |  0:00:03s\n","epoch 5  | loss: 0.41064 | val_0_accuracy: 0.56692 |  0:00:04s\n","epoch 6  | loss: 0.40611 | val_0_accuracy: 0.6542  |  0:00:04s\n","epoch 7  | loss: 0.39789 | val_0_accuracy: 0.69825 |  0:00:05s\n","epoch 8  | loss: 0.39604 | val_0_accuracy: 0.72153 |  0:00:06s\n","epoch 9  | loss: 0.39227 | val_0_accuracy: 0.69077 |  0:00:07s\n","epoch 10 | loss: 0.38085 | val_0_accuracy: 0.66916 |  0:00:07s\n","epoch 11 | loss: 0.37996 | val_0_accuracy: 0.60432 |  0:00:08s\n","epoch 12 | loss: 0.37414 | val_0_accuracy: 0.67082 |  0:00:09s\n","epoch 13 | loss: 0.37509 | val_0_accuracy: 0.67249 |  0:00:09s\n","epoch 14 | loss: 0.37434 | val_0_accuracy: 0.66916 |  0:00:10s\n","epoch 15 | loss: 0.36786 | val_0_accuracy: 0.73566 |  0:00:11s\n","epoch 16 | loss: 0.36502 | val_0_accuracy: 0.6808  |  0:00:11s\n","epoch 17 | loss: 0.36421 | val_0_accuracy: 0.70989 |  0:00:12s\n","epoch 18 | loss: 0.36365 | val_0_accuracy: 0.7182  |  0:00:13s\n","epoch 19 | loss: 0.3668  | val_0_accuracy: 0.74314 |  0:00:14s\n","epoch 20 | loss: 0.35893 | val_0_accuracy: 0.72735 |  0:00:14s\n","epoch 21 | loss: 0.36015 | val_0_accuracy: 0.73566 |  0:00:15s\n","epoch 22 | loss: 0.3561  | val_0_accuracy: 0.74813 |  0:00:16s\n","epoch 23 | loss: 0.36049 | val_0_accuracy: 0.76891 |  0:00:16s\n","epoch 24 | loss: 0.35935 | val_0_accuracy: 0.78886 |  0:00:17s\n","epoch 25 | loss: 0.35781 | val_0_accuracy: 0.79135 |  0:00:18s\n","epoch 26 | loss: 0.36565 | val_0_accuracy: 0.7847  |  0:00:18s\n","epoch 27 | loss: 0.36184 | val_0_accuracy: 0.77057 |  0:00:19s\n","epoch 28 | loss: 0.36922 | val_0_accuracy: 0.79551 |  0:00:20s\n","epoch 29 | loss: 0.36212 | val_0_accuracy: 0.76725 |  0:00:21s\n","epoch 30 | loss: 0.35777 | val_0_accuracy: 0.78637 |  0:00:21s\n","epoch 31 | loss: 0.35437 | val_0_accuracy: 0.81214 |  0:00:22s\n","epoch 32 | loss: 0.35035 | val_0_accuracy: 0.81629 |  0:00:23s\n","epoch 33 | loss: 0.35237 | val_0_accuracy: 0.82544 |  0:00:23s\n","epoch 34 | loss: 0.35837 | val_0_accuracy: 0.82377 |  0:00:24s\n","epoch 35 | loss: 0.35104 | val_0_accuracy: 0.83707 |  0:00:25s\n","epoch 36 | loss: 0.36383 | val_0_accuracy: 0.83624 |  0:00:25s\n","epoch 37 | loss: 0.36577 | val_0_accuracy: 0.8404  |  0:00:26s\n","epoch 38 | loss: 0.35919 | val_0_accuracy: 0.8404  |  0:00:27s\n","epoch 39 | loss: 0.34962 | val_0_accuracy: 0.83707 |  0:00:27s\n","epoch 40 | loss: 0.35594 | val_0_accuracy: 0.83707 |  0:00:28s\n","epoch 41 | loss: 0.35131 | val_0_accuracy: 0.84622 |  0:00:29s\n","epoch 42 | loss: 0.35397 | val_0_accuracy: 0.83624 |  0:00:30s\n","epoch 43 | loss: 0.34774 | val_0_accuracy: 0.82959 |  0:00:30s\n","epoch 44 | loss: 0.34507 | val_0_accuracy: 0.83375 |  0:00:31s\n","epoch 45 | loss: 0.34909 | val_0_accuracy: 0.83624 |  0:00:32s\n","epoch 46 | loss: 0.36238 | val_0_accuracy: 0.8404  |  0:00:32s\n","epoch 47 | loss: 0.35502 | val_0_accuracy: 0.83707 |  0:00:33s\n","epoch 48 | loss: 0.34917 | val_0_accuracy: 0.85619 |  0:00:34s\n","epoch 49 | loss: 0.34663 | val_0_accuracy: 0.84622 |  0:00:34s\n","epoch 50 | loss: 0.33966 | val_0_accuracy: 0.84871 |  0:00:35s\n","epoch 51 | loss: 0.33895 | val_0_accuracy: 0.85287 |  0:00:36s\n","epoch 52 | loss: 0.33485 | val_0_accuracy: 0.85453 |  0:00:36s\n","epoch 53 | loss: 0.33763 | val_0_accuracy: 0.86035 |  0:00:37s\n","epoch 54 | loss: 0.33375 | val_0_accuracy: 0.85536 |  0:00:38s\n","epoch 55 | loss: 0.32967 | val_0_accuracy: 0.85869 |  0:00:39s\n","epoch 56 | loss: 0.33185 | val_0_accuracy: 0.85952 |  0:00:39s\n","epoch 57 | loss: 0.32642 | val_0_accuracy: 0.85786 |  0:00:40s\n","epoch 58 | loss: 0.32864 | val_0_accuracy: 0.86451 |  0:00:41s\n","epoch 59 | loss: 0.32702 | val_0_accuracy: 0.86451 |  0:00:41s\n","epoch 60 | loss: 0.32714 | val_0_accuracy: 0.85536 |  0:00:42s\n","epoch 61 | loss: 0.3249  | val_0_accuracy: 0.85869 |  0:00:43s\n","epoch 62 | loss: 0.32026 | val_0_accuracy: 0.85619 |  0:00:43s\n","epoch 63 | loss: 0.32506 | val_0_accuracy: 0.86201 |  0:00:44s\n","epoch 64 | loss: 0.31856 | val_0_accuracy: 0.86534 |  0:00:45s\n","epoch 65 | loss: 0.32354 | val_0_accuracy: 0.86367 |  0:00:45s\n","epoch 66 | loss: 0.31872 | val_0_accuracy: 0.85869 |  0:00:46s\n","epoch 67 | loss: 0.32056 | val_0_accuracy: 0.85869 |  0:00:47s\n","epoch 68 | loss: 0.32262 | val_0_accuracy: 0.85536 |  0:00:47s\n","epoch 69 | loss: 0.32023 | val_0_accuracy: 0.86035 |  0:00:48s\n","epoch 70 | loss: 0.32586 | val_0_accuracy: 0.86118 |  0:00:49s\n","epoch 71 | loss: 0.32176 | val_0_accuracy: 0.85869 |  0:00:50s\n","epoch 72 | loss: 0.32492 | val_0_accuracy: 0.85204 |  0:00:50s\n","epoch 73 | loss: 0.32376 | val_0_accuracy: 0.85287 |  0:00:51s\n","epoch 74 | loss: 0.32238 | val_0_accuracy: 0.85869 |  0:00:52s\n","\n","Early stopping occurred at epoch 74 with best_epoch = 64 and best_val_0_accuracy = 0.86534\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-07-06 06:01:43,669] Trial 28 finished with value: 0.8653366583541147 and parameters: {'n_d': 58, 'n_steps': 4, 'gamma': 1.4226593566801449, 'n_independent': 4, 'n_shared': 3, 'momentum': 0.28869031252023986}. Best is trial 24 with value: 0.8719866999168745.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 1.08651 | val_0_accuracy: 0.57357 |  0:00:00s\n","epoch 1  | loss: 0.61933 | val_0_accuracy: 0.52618 |  0:00:01s\n","epoch 2  | loss: 0.53051 | val_0_accuracy: 0.57855 |  0:00:02s\n","epoch 3  | loss: 0.47726 | val_0_accuracy: 0.53616 |  0:00:02s\n","epoch 4  | loss: 0.46565 | val_0_accuracy: 0.52785 |  0:00:03s\n","epoch 5  | loss: 0.45185 | val_0_accuracy: 0.53117 |  0:00:04s\n","epoch 6  | loss: 0.42904 | val_0_accuracy: 0.64256 |  0:00:05s\n","epoch 7  | loss: 0.41364 | val_0_accuracy: 0.57523 |  0:00:05s\n","epoch 8  | loss: 0.41261 | val_0_accuracy: 0.60515 |  0:00:06s\n","epoch 9  | loss: 0.40968 | val_0_accuracy: 0.63425 |  0:00:07s\n","epoch 10 | loss: 0.41398 | val_0_accuracy: 0.64672 |  0:00:08s\n","epoch 11 | loss: 0.40307 | val_0_accuracy: 0.69077 |  0:00:08s\n","epoch 12 | loss: 0.39553 | val_0_accuracy: 0.69327 |  0:00:09s\n","epoch 13 | loss: 0.40207 | val_0_accuracy: 0.70407 |  0:00:10s\n","epoch 14 | loss: 0.40169 | val_0_accuracy: 0.74896 |  0:00:11s\n","epoch 15 | loss: 0.40038 | val_0_accuracy: 0.74896 |  0:00:11s\n","epoch 16 | loss: 0.39403 | val_0_accuracy: 0.75145 |  0:00:12s\n","epoch 17 | loss: 0.39272 | val_0_accuracy: 0.76392 |  0:00:13s\n","epoch 18 | loss: 0.38946 | val_0_accuracy: 0.74397 |  0:00:13s\n","epoch 19 | loss: 0.40144 | val_0_accuracy: 0.7581  |  0:00:14s\n","epoch 20 | loss: 0.41346 | val_0_accuracy: 0.76392 |  0:00:15s\n","epoch 21 | loss: 0.40365 | val_0_accuracy: 0.7606  |  0:00:16s\n","epoch 22 | loss: 0.39952 | val_0_accuracy: 0.75977 |  0:00:16s\n","epoch 23 | loss: 0.39291 | val_0_accuracy: 0.76642 |  0:00:17s\n","epoch 24 | loss: 0.40805 | val_0_accuracy: 0.74979 |  0:00:18s\n","epoch 25 | loss: 0.41507 | val_0_accuracy: 0.71987 |  0:00:19s\n","epoch 26 | loss: 0.422   | val_0_accuracy: 0.78055 |  0:00:19s\n","epoch 27 | loss: 0.40243 | val_0_accuracy: 0.7714  |  0:00:20s\n","epoch 28 | loss: 0.39204 | val_0_accuracy: 0.7847  |  0:00:21s\n","epoch 29 | loss: 0.38667 | val_0_accuracy: 0.79884 |  0:00:22s\n","epoch 30 | loss: 0.3771  | val_0_accuracy: 0.80881 |  0:00:22s\n","epoch 31 | loss: 0.38415 | val_0_accuracy: 0.81629 |  0:00:23s\n","epoch 32 | loss: 0.377   | val_0_accuracy: 0.80964 |  0:00:24s\n","epoch 33 | loss: 0.38135 | val_0_accuracy: 0.81214 |  0:00:24s\n","epoch 34 | loss: 0.37899 | val_0_accuracy: 0.81796 |  0:00:25s\n","epoch 35 | loss: 0.37915 | val_0_accuracy: 0.81131 |  0:00:26s\n","epoch 36 | loss: 0.38487 | val_0_accuracy: 0.83292 |  0:00:27s\n","epoch 37 | loss: 0.37039 | val_0_accuracy: 0.81796 |  0:00:27s\n","epoch 38 | loss: 0.38276 | val_0_accuracy: 0.82128 |  0:00:28s\n","epoch 39 | loss: 0.38562 | val_0_accuracy: 0.82876 |  0:00:29s\n","epoch 40 | loss: 0.38959 | val_0_accuracy: 0.82793 |  0:00:30s\n","epoch 41 | loss: 0.38708 | val_0_accuracy: 0.82627 |  0:00:30s\n","epoch 42 | loss: 0.37953 | val_0_accuracy: 0.83375 |  0:00:31s\n","epoch 43 | loss: 0.37654 | val_0_accuracy: 0.84123 |  0:00:32s\n","epoch 44 | loss: 0.37645 | val_0_accuracy: 0.83209 |  0:00:32s\n","epoch 45 | loss: 0.37217 | val_0_accuracy: 0.84622 |  0:00:33s\n","epoch 46 | loss: 0.37364 | val_0_accuracy: 0.83209 |  0:00:34s\n","epoch 47 | loss: 0.37259 | val_0_accuracy: 0.84788 |  0:00:35s\n","epoch 48 | loss: 0.36514 | val_0_accuracy: 0.84539 |  0:00:35s\n","epoch 49 | loss: 0.36525 | val_0_accuracy: 0.83624 |  0:00:36s\n","epoch 50 | loss: 0.36615 | val_0_accuracy: 0.84206 |  0:00:37s\n","epoch 51 | loss: 0.37208 | val_0_accuracy: 0.84788 |  0:00:38s\n","epoch 52 | loss: 0.37381 | val_0_accuracy: 0.84871 |  0:00:38s\n","epoch 53 | loss: 0.37437 | val_0_accuracy: 0.84123 |  0:00:39s\n","epoch 54 | loss: 0.36428 | val_0_accuracy: 0.83292 |  0:00:40s\n","epoch 55 | loss: 0.36551 | val_0_accuracy: 0.83707 |  0:00:41s\n","epoch 56 | loss: 0.36954 | val_0_accuracy: 0.83126 |  0:00:41s\n","epoch 57 | loss: 0.36667 | val_0_accuracy: 0.84123 |  0:00:42s\n","epoch 58 | loss: 0.36155 | val_0_accuracy: 0.85121 |  0:00:43s\n","epoch 59 | loss: 0.3637  | val_0_accuracy: 0.84788 |  0:00:44s\n","epoch 60 | loss: 0.35456 | val_0_accuracy: 0.83874 |  0:00:44s\n","epoch 61 | loss: 0.35916 | val_0_accuracy: 0.83541 |  0:00:45s\n","epoch 62 | loss: 0.37091 | val_0_accuracy: 0.84123 |  0:00:46s\n","epoch 63 | loss: 0.36875 | val_0_accuracy: 0.8404  |  0:00:47s\n","epoch 64 | loss: 0.36802 | val_0_accuracy: 0.84954 |  0:00:47s\n","epoch 65 | loss: 0.36643 | val_0_accuracy: 0.84705 |  0:00:48s\n","epoch 66 | loss: 0.36149 | val_0_accuracy: 0.83957 |  0:00:49s\n","epoch 67 | loss: 0.36071 | val_0_accuracy: 0.83541 |  0:00:49s\n","epoch 68 | loss: 0.35778 | val_0_accuracy: 0.84289 |  0:00:50s\n","\n","Early stopping occurred at epoch 68 with best_epoch = 58 and best_val_0_accuracy = 0.85121\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-07-06 06:02:34,783] Trial 29 finished with value: 0.8512053200332502 and parameters: {'n_d': 45, 'n_steps': 7, 'gamma': 1.3475344175434862, 'n_independent': 3, 'n_shared': 1, 'momentum': 0.17522614275765816}. Best is trial 24 with value: 0.8719866999168745.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 0.72562 | val_0_accuracy: 0.51039 |  0:00:00s\n","epoch 1  | loss: 0.51609 | val_0_accuracy: 0.51372 |  0:00:01s\n","epoch 2  | loss: 0.48461 | val_0_accuracy: 0.58936 |  0:00:02s\n","epoch 3  | loss: 0.45801 | val_0_accuracy: 0.53034 |  0:00:02s\n","epoch 4  | loss: 0.44944 | val_0_accuracy: 0.57772 |  0:00:03s\n","epoch 5  | loss: 0.44727 | val_0_accuracy: 0.63259 |  0:00:04s\n","epoch 6  | loss: 0.43258 | val_0_accuracy: 0.7182  |  0:00:05s\n","epoch 7  | loss: 0.42306 | val_0_accuracy: 0.62843 |  0:00:05s\n","epoch 8  | loss: 0.41622 | val_0_accuracy: 0.61762 |  0:00:06s\n","epoch 9  | loss: 0.43929 | val_0_accuracy: 0.65337 |  0:00:07s\n","epoch 10 | loss: 0.42191 | val_0_accuracy: 0.67082 |  0:00:08s\n","epoch 11 | loss: 0.41278 | val_0_accuracy: 0.69825 |  0:00:08s\n","epoch 12 | loss: 0.39804 | val_0_accuracy: 0.68662 |  0:00:09s\n","epoch 13 | loss: 0.39121 | val_0_accuracy: 0.6941  |  0:00:10s\n","epoch 14 | loss: 0.38916 | val_0_accuracy: 0.73899 |  0:00:11s\n","epoch 15 | loss: 0.38737 | val_0_accuracy: 0.73899 |  0:00:11s\n","epoch 16 | loss: 0.38241 | val_0_accuracy: 0.72652 |  0:00:12s\n","epoch 17 | loss: 0.38507 | val_0_accuracy: 0.73483 |  0:00:13s\n","epoch 18 | loss: 0.38256 | val_0_accuracy: 0.74148 |  0:00:14s\n","epoch 19 | loss: 0.38847 | val_0_accuracy: 0.76392 |  0:00:14s\n","epoch 20 | loss: 0.39019 | val_0_accuracy: 0.76392 |  0:00:15s\n","epoch 21 | loss: 0.38154 | val_0_accuracy: 0.77307 |  0:00:16s\n","epoch 22 | loss: 0.37359 | val_0_accuracy: 0.77057 |  0:00:17s\n","epoch 23 | loss: 0.37325 | val_0_accuracy: 0.77722 |  0:00:17s\n","epoch 24 | loss: 0.37206 | val_0_accuracy: 0.7714  |  0:00:18s\n","epoch 25 | loss: 0.37166 | val_0_accuracy: 0.7872  |  0:00:19s\n","epoch 26 | loss: 0.36425 | val_0_accuracy: 0.78886 |  0:00:20s\n","epoch 27 | loss: 0.37002 | val_0_accuracy: 0.798   |  0:00:20s\n","epoch 28 | loss: 0.36488 | val_0_accuracy: 0.81463 |  0:00:21s\n","epoch 29 | loss: 0.36668 | val_0_accuracy: 0.81297 |  0:00:22s\n","epoch 30 | loss: 0.36593 | val_0_accuracy: 0.80715 |  0:00:22s\n","epoch 31 | loss: 0.36964 | val_0_accuracy: 0.80632 |  0:00:23s\n","epoch 32 | loss: 0.3629  | val_0_accuracy: 0.81879 |  0:00:24s\n","epoch 33 | loss: 0.36685 | val_0_accuracy: 0.83624 |  0:00:25s\n","epoch 34 | loss: 0.3641  | val_0_accuracy: 0.82294 |  0:00:25s\n","epoch 35 | loss: 0.36042 | val_0_accuracy: 0.8271  |  0:00:26s\n","epoch 36 | loss: 0.35655 | val_0_accuracy: 0.83209 |  0:00:27s\n","epoch 37 | loss: 0.35901 | val_0_accuracy: 0.83791 |  0:00:28s\n","epoch 38 | loss: 0.35679 | val_0_accuracy: 0.83791 |  0:00:28s\n","epoch 39 | loss: 0.3537  | val_0_accuracy: 0.84289 |  0:00:29s\n","epoch 40 | loss: 0.35641 | val_0_accuracy: 0.83791 |  0:00:30s\n","epoch 41 | loss: 0.36315 | val_0_accuracy: 0.83375 |  0:00:31s\n","epoch 42 | loss: 0.37181 | val_0_accuracy: 0.84206 |  0:00:31s\n","epoch 43 | loss: 0.35532 | val_0_accuracy: 0.84954 |  0:00:32s\n","epoch 44 | loss: 0.35388 | val_0_accuracy: 0.83957 |  0:00:33s\n","epoch 45 | loss: 0.35571 | val_0_accuracy: 0.85121 |  0:00:34s\n","epoch 46 | loss: 0.36183 | val_0_accuracy: 0.84123 |  0:00:34s\n","epoch 47 | loss: 0.36274 | val_0_accuracy: 0.84123 |  0:00:35s\n","epoch 48 | loss: 0.35735 | val_0_accuracy: 0.84539 |  0:00:36s\n","epoch 49 | loss: 0.35216 | val_0_accuracy: 0.84206 |  0:00:37s\n","epoch 50 | loss: 0.35687 | val_0_accuracy: 0.8404  |  0:00:37s\n","epoch 51 | loss: 0.34914 | val_0_accuracy: 0.84206 |  0:00:38s\n","epoch 52 | loss: 0.34709 | val_0_accuracy: 0.84788 |  0:00:39s\n","epoch 53 | loss: 0.35073 | val_0_accuracy: 0.84871 |  0:00:40s\n","epoch 54 | loss: 0.35793 | val_0_accuracy: 0.84539 |  0:00:40s\n","epoch 55 | loss: 0.36256 | val_0_accuracy: 0.84289 |  0:00:41s\n","\n","Early stopping occurred at epoch 55 with best_epoch = 45 and best_val_0_accuracy = 0.85121\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-07-06 06:03:16,795] Trial 30 finished with value: 0.8512053200332502 and parameters: {'n_d': 41, 'n_steps': 5, 'gamma': 1.4674392796494247, 'n_independent': 3, 'n_shared': 3, 'momentum': 0.21523096672037315}. Best is trial 24 with value: 0.8719866999168745.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 0.71031 | val_0_accuracy: 0.53283 |  0:00:00s\n","epoch 1  | loss: 0.57064 | val_0_accuracy: 0.4946  |  0:00:01s\n","epoch 2  | loss: 0.48862 | val_0_accuracy: 0.5079  |  0:00:02s\n","epoch 3  | loss: 0.44802 | val_0_accuracy: 0.51787 |  0:00:03s\n","epoch 4  | loss: 0.41988 | val_0_accuracy: 0.54946 |  0:00:03s\n","epoch 5  | loss: 0.39809 | val_0_accuracy: 0.57357 |  0:00:04s\n","epoch 6  | loss: 0.38132 | val_0_accuracy: 0.57273 |  0:00:05s\n","epoch 7  | loss: 0.37187 | val_0_accuracy: 0.6384  |  0:00:06s\n","epoch 8  | loss: 0.37797 | val_0_accuracy: 0.57938 |  0:00:06s\n","epoch 9  | loss: 0.38399 | val_0_accuracy: 0.54198 |  0:00:07s\n","epoch 10 | loss: 0.37309 | val_0_accuracy: 0.52785 |  0:00:08s\n","epoch 11 | loss: 0.37401 | val_0_accuracy: 0.53533 |  0:00:09s\n","epoch 12 | loss: 0.36165 | val_0_accuracy: 0.5345  |  0:00:10s\n","epoch 13 | loss: 0.35606 | val_0_accuracy: 0.58022 |  0:00:10s\n","epoch 14 | loss: 0.35544 | val_0_accuracy: 0.57606 |  0:00:11s\n","epoch 15 | loss: 0.35162 | val_0_accuracy: 0.66085 |  0:00:12s\n","epoch 16 | loss: 0.35012 | val_0_accuracy: 0.71322 |  0:00:13s\n","epoch 17 | loss: 0.35035 | val_0_accuracy: 0.69327 |  0:00:13s\n","epoch 18 | loss: 0.34925 | val_0_accuracy: 0.74397 |  0:00:14s\n","epoch 19 | loss: 0.34807 | val_0_accuracy: 0.72153 |  0:00:15s\n","epoch 20 | loss: 0.35504 | val_0_accuracy: 0.74564 |  0:00:16s\n","epoch 21 | loss: 0.35368 | val_0_accuracy: 0.73815 |  0:00:16s\n","epoch 22 | loss: 0.3436  | val_0_accuracy: 0.75395 |  0:00:17s\n","epoch 23 | loss: 0.34287 | val_0_accuracy: 0.77889 |  0:00:18s\n","epoch 24 | loss: 0.35025 | val_0_accuracy: 0.79967 |  0:00:19s\n","epoch 25 | loss: 0.33947 | val_0_accuracy: 0.78554 |  0:00:20s\n","epoch 26 | loss: 0.33868 | val_0_accuracy: 0.78387 |  0:00:20s\n","epoch 27 | loss: 0.3488  | val_0_accuracy: 0.7872  |  0:00:21s\n","epoch 28 | loss: 0.33613 | val_0_accuracy: 0.77722 |  0:00:22s\n","epoch 29 | loss: 0.34356 | val_0_accuracy: 0.79052 |  0:00:23s\n","epoch 30 | loss: 0.34028 | val_0_accuracy: 0.83292 |  0:00:23s\n","epoch 31 | loss: 0.33787 | val_0_accuracy: 0.83541 |  0:00:24s\n","epoch 32 | loss: 0.33614 | val_0_accuracy: 0.82793 |  0:00:25s\n","epoch 33 | loss: 0.33726 | val_0_accuracy: 0.83957 |  0:00:26s\n","epoch 34 | loss: 0.33032 | val_0_accuracy: 0.82211 |  0:00:26s\n","epoch 35 | loss: 0.33078 | val_0_accuracy: 0.83624 |  0:00:27s\n","epoch 36 | loss: 0.33915 | val_0_accuracy: 0.85204 |  0:00:28s\n","epoch 37 | loss: 0.33832 | val_0_accuracy: 0.83791 |  0:00:29s\n","epoch 38 | loss: 0.32707 | val_0_accuracy: 0.84705 |  0:00:29s\n","epoch 39 | loss: 0.33446 | val_0_accuracy: 0.84622 |  0:00:30s\n","epoch 40 | loss: 0.33054 | val_0_accuracy: 0.85204 |  0:00:31s\n","epoch 41 | loss: 0.33647 | val_0_accuracy: 0.84954 |  0:00:32s\n","epoch 42 | loss: 0.33202 | val_0_accuracy: 0.85121 |  0:00:33s\n","epoch 43 | loss: 0.32897 | val_0_accuracy: 0.8404  |  0:00:33s\n","epoch 44 | loss: 0.32843 | val_0_accuracy: 0.85619 |  0:00:34s\n","epoch 45 | loss: 0.32916 | val_0_accuracy: 0.85453 |  0:00:35s\n","epoch 46 | loss: 0.32886 | val_0_accuracy: 0.85287 |  0:00:36s\n","epoch 47 | loss: 0.32681 | val_0_accuracy: 0.85702 |  0:00:37s\n","epoch 48 | loss: 0.32076 | val_0_accuracy: 0.85952 |  0:00:37s\n","epoch 49 | loss: 0.32373 | val_0_accuracy: 0.85453 |  0:00:38s\n","epoch 50 | loss: 0.32516 | val_0_accuracy: 0.85619 |  0:00:39s\n","epoch 51 | loss: 0.32068 | val_0_accuracy: 0.85869 |  0:00:40s\n","epoch 52 | loss: 0.32581 | val_0_accuracy: 0.85786 |  0:00:40s\n","epoch 53 | loss: 0.32097 | val_0_accuracy: 0.85952 |  0:00:41s\n","epoch 54 | loss: 0.32505 | val_0_accuracy: 0.85121 |  0:00:42s\n","epoch 55 | loss: 0.32684 | val_0_accuracy: 0.84622 |  0:00:43s\n","epoch 56 | loss: 0.32055 | val_0_accuracy: 0.85786 |  0:00:44s\n","epoch 57 | loss: 0.32588 | val_0_accuracy: 0.86534 |  0:00:44s\n","epoch 58 | loss: 0.32808 | val_0_accuracy: 0.85786 |  0:00:45s\n","epoch 59 | loss: 0.32131 | val_0_accuracy: 0.8537  |  0:00:46s\n","epoch 60 | loss: 0.3198  | val_0_accuracy: 0.85702 |  0:00:47s\n","epoch 61 | loss: 0.31715 | val_0_accuracy: 0.8537  |  0:00:47s\n","epoch 62 | loss: 0.31711 | val_0_accuracy: 0.85786 |  0:00:48s\n","epoch 63 | loss: 0.31569 | val_0_accuracy: 0.85619 |  0:00:49s\n","epoch 64 | loss: 0.31216 | val_0_accuracy: 0.8537  |  0:00:50s\n","epoch 65 | loss: 0.31301 | val_0_accuracy: 0.85204 |  0:00:50s\n","epoch 66 | loss: 0.31702 | val_0_accuracy: 0.85037 |  0:00:51s\n","epoch 67 | loss: 0.31924 | val_0_accuracy: 0.86201 |  0:00:52s\n","\n","Early stopping occurred at epoch 67 with best_epoch = 57 and best_val_0_accuracy = 0.86534\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-07-06 06:04:09,605] Trial 31 finished with value: 0.8653366583541147 and parameters: {'n_d': 38, 'n_steps': 4, 'gamma': 1.2896219346791313, 'n_independent': 5, 'n_shared': 3, 'momentum': 0.30170062631211714}. Best is trial 24 with value: 0.8719866999168745.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 0.88505 | val_0_accuracy: 0.5453  |  0:00:00s\n","epoch 1  | loss: 0.59837 | val_0_accuracy: 0.49543 |  0:00:01s\n","epoch 2  | loss: 0.50662 | val_0_accuracy: 0.53948 |  0:00:01s\n","epoch 3  | loss: 0.4486  | val_0_accuracy: 0.52203 |  0:00:02s\n","epoch 4  | loss: 0.43142 | val_0_accuracy: 0.50457 |  0:00:03s\n","epoch 5  | loss: 0.41227 | val_0_accuracy: 0.61264 |  0:00:03s\n","epoch 6  | loss: 0.40496 | val_0_accuracy: 0.69576 |  0:00:04s\n","epoch 7  | loss: 0.39259 | val_0_accuracy: 0.64256 |  0:00:05s\n","epoch 8  | loss: 0.38676 | val_0_accuracy: 0.55528 |  0:00:05s\n","epoch 9  | loss: 0.38237 | val_0_accuracy: 0.55694 |  0:00:06s\n","epoch 10 | loss: 0.37967 | val_0_accuracy: 0.66251 |  0:00:06s\n","epoch 11 | loss: 0.37914 | val_0_accuracy: 0.59352 |  0:00:07s\n","epoch 12 | loss: 0.37078 | val_0_accuracy: 0.56442 |  0:00:08s\n","epoch 13 | loss: 0.37549 | val_0_accuracy: 0.69077 |  0:00:08s\n","epoch 14 | loss: 0.3733  | val_0_accuracy: 0.72735 |  0:00:09s\n","epoch 15 | loss: 0.36953 | val_0_accuracy: 0.70823 |  0:00:09s\n","epoch 16 | loss: 0.36827 | val_0_accuracy: 0.73234 |  0:00:10s\n","epoch 17 | loss: 0.36436 | val_0_accuracy: 0.71987 |  0:00:11s\n","epoch 18 | loss: 0.36539 | val_0_accuracy: 0.70241 |  0:00:11s\n","epoch 19 | loss: 0.36998 | val_0_accuracy: 0.73234 |  0:00:12s\n","epoch 20 | loss: 0.36431 | val_0_accuracy: 0.73649 |  0:00:13s\n","epoch 21 | loss: 0.36395 | val_0_accuracy: 0.73732 |  0:00:13s\n","epoch 22 | loss: 0.36038 | val_0_accuracy: 0.75977 |  0:00:14s\n","epoch 23 | loss: 0.36129 | val_0_accuracy: 0.74065 |  0:00:14s\n","epoch 24 | loss: 0.36433 | val_0_accuracy: 0.7714  |  0:00:15s\n","epoch 25 | loss: 0.35375 | val_0_accuracy: 0.76309 |  0:00:16s\n","epoch 26 | loss: 0.35279 | val_0_accuracy: 0.74813 |  0:00:16s\n","epoch 27 | loss: 0.35136 | val_0_accuracy: 0.80715 |  0:00:17s\n","epoch 28 | loss: 0.35396 | val_0_accuracy: 0.81629 |  0:00:18s\n","epoch 29 | loss: 0.35092 | val_0_accuracy: 0.80881 |  0:00:18s\n","epoch 30 | loss: 0.35267 | val_0_accuracy: 0.82544 |  0:00:19s\n","epoch 31 | loss: 0.35129 | val_0_accuracy: 0.80715 |  0:00:19s\n","epoch 32 | loss: 0.35135 | val_0_accuracy: 0.81962 |  0:00:20s\n","epoch 33 | loss: 0.34917 | val_0_accuracy: 0.81463 |  0:00:21s\n","epoch 34 | loss: 0.34882 | val_0_accuracy: 0.83209 |  0:00:21s\n","epoch 35 | loss: 0.34374 | val_0_accuracy: 0.83126 |  0:00:22s\n","epoch 36 | loss: 0.33805 | val_0_accuracy: 0.83375 |  0:00:22s\n","epoch 37 | loss: 0.34106 | val_0_accuracy: 0.83707 |  0:00:23s\n","epoch 38 | loss: 0.34692 | val_0_accuracy: 0.84622 |  0:00:24s\n","epoch 39 | loss: 0.34157 | val_0_accuracy: 0.84456 |  0:00:24s\n","epoch 40 | loss: 0.33521 | val_0_accuracy: 0.84788 |  0:00:25s\n","epoch 41 | loss: 0.33842 | val_0_accuracy: 0.8537  |  0:00:26s\n","epoch 42 | loss: 0.34384 | val_0_accuracy: 0.85121 |  0:00:26s\n","epoch 43 | loss: 0.33602 | val_0_accuracy: 0.84372 |  0:00:27s\n","epoch 44 | loss: 0.33829 | val_0_accuracy: 0.84705 |  0:00:28s\n","epoch 45 | loss: 0.33589 | val_0_accuracy: 0.84456 |  0:00:28s\n","epoch 46 | loss: 0.33442 | val_0_accuracy: 0.83957 |  0:00:29s\n","epoch 47 | loss: 0.34289 | val_0_accuracy: 0.84372 |  0:00:30s\n","epoch 48 | loss: 0.34351 | val_0_accuracy: 0.84788 |  0:00:30s\n","epoch 49 | loss: 0.33758 | val_0_accuracy: 0.85287 |  0:00:31s\n","epoch 50 | loss: 0.3384  | val_0_accuracy: 0.85786 |  0:00:31s\n","epoch 51 | loss: 0.33752 | val_0_accuracy: 0.84871 |  0:00:32s\n","epoch 52 | loss: 0.3384  | val_0_accuracy: 0.85453 |  0:00:33s\n","epoch 53 | loss: 0.33324 | val_0_accuracy: 0.85536 |  0:00:33s\n","epoch 54 | loss: 0.33889 | val_0_accuracy: 0.85786 |  0:00:34s\n","epoch 55 | loss: 0.33433 | val_0_accuracy: 0.85121 |  0:00:35s\n","epoch 56 | loss: 0.33803 | val_0_accuracy: 0.84788 |  0:00:35s\n","epoch 57 | loss: 0.33303 | val_0_accuracy: 0.85037 |  0:00:36s\n","epoch 58 | loss: 0.33274 | val_0_accuracy: 0.85869 |  0:00:36s\n","epoch 59 | loss: 0.33311 | val_0_accuracy: 0.86284 |  0:00:37s\n","epoch 60 | loss: 0.33189 | val_0_accuracy: 0.85619 |  0:00:38s\n","epoch 61 | loss: 0.32732 | val_0_accuracy: 0.8537  |  0:00:38s\n","epoch 62 | loss: 0.32643 | val_0_accuracy: 0.85453 |  0:00:39s\n","epoch 63 | loss: 0.32624 | val_0_accuracy: 0.85786 |  0:00:39s\n","epoch 64 | loss: 0.32872 | val_0_accuracy: 0.85869 |  0:00:40s\n","epoch 65 | loss: 0.32287 | val_0_accuracy: 0.85453 |  0:00:41s\n","epoch 66 | loss: 0.32303 | val_0_accuracy: 0.85453 |  0:00:41s\n","epoch 67 | loss: 0.32347 | val_0_accuracy: 0.85204 |  0:00:42s\n","epoch 68 | loss: 0.33455 | val_0_accuracy: 0.84871 |  0:00:42s\n","epoch 69 | loss: 0.33087 | val_0_accuracy: 0.85287 |  0:00:43s\n","\n","Early stopping occurred at epoch 69 with best_epoch = 59 and best_val_0_accuracy = 0.86284\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-07-06 06:04:53,567] Trial 32 finished with value: 0.8628428927680798 and parameters: {'n_d': 48, 'n_steps': 4, 'gamma': 1.5248946984992449, 'n_independent': 4, 'n_shared': 2, 'momentum': 0.1189001688578865}. Best is trial 24 with value: 0.8719866999168745.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 0.714   | val_0_accuracy: 0.5719  |  0:00:00s\n","epoch 1  | loss: 0.47747 | val_0_accuracy: 0.51039 |  0:00:01s\n","epoch 2  | loss: 0.42551 | val_0_accuracy: 0.51787 |  0:00:02s\n","epoch 3  | loss: 0.39856 | val_0_accuracy: 0.5453  |  0:00:03s\n","epoch 4  | loss: 0.38562 | val_0_accuracy: 0.532   |  0:00:03s\n","epoch 5  | loss: 0.38667 | val_0_accuracy: 0.54281 |  0:00:04s\n","epoch 6  | loss: 0.37856 | val_0_accuracy: 0.52286 |  0:00:05s\n","epoch 7  | loss: 0.36498 | val_0_accuracy: 0.53948 |  0:00:05s\n","epoch 8  | loss: 0.36319 | val_0_accuracy: 0.57107 |  0:00:06s\n","epoch 9  | loss: 0.36437 | val_0_accuracy: 0.56941 |  0:00:07s\n","epoch 10 | loss: 0.36177 | val_0_accuracy: 0.58853 |  0:00:08s\n","epoch 11 | loss: 0.35374 | val_0_accuracy: 0.60515 |  0:00:08s\n","epoch 12 | loss: 0.35688 | val_0_accuracy: 0.68662 |  0:00:09s\n","epoch 13 | loss: 0.35791 | val_0_accuracy: 0.66584 |  0:00:10s\n","epoch 14 | loss: 0.34831 | val_0_accuracy: 0.6675  |  0:00:11s\n","epoch 15 | loss: 0.34831 | val_0_accuracy: 0.71072 |  0:00:11s\n","epoch 16 | loss: 0.34749 | val_0_accuracy: 0.71322 |  0:00:12s\n","epoch 17 | loss: 0.34144 | val_0_accuracy: 0.69825 |  0:00:13s\n","epoch 18 | loss: 0.33801 | val_0_accuracy: 0.67914 |  0:00:14s\n","epoch 19 | loss: 0.34187 | val_0_accuracy: 0.69825 |  0:00:14s\n","epoch 20 | loss: 0.33667 | val_0_accuracy: 0.71322 |  0:00:15s\n","epoch 21 | loss: 0.33833 | val_0_accuracy: 0.74813 |  0:00:16s\n","epoch 22 | loss: 0.33642 | val_0_accuracy: 0.7581  |  0:00:16s\n","epoch 23 | loss: 0.33179 | val_0_accuracy: 0.76891 |  0:00:17s\n","epoch 24 | loss: 0.33274 | val_0_accuracy: 0.75644 |  0:00:18s\n","epoch 25 | loss: 0.33151 | val_0_accuracy: 0.80299 |  0:00:19s\n","epoch 26 | loss: 0.33037 | val_0_accuracy: 0.79717 |  0:00:19s\n","epoch 27 | loss: 0.32524 | val_0_accuracy: 0.80632 |  0:00:20s\n","epoch 28 | loss: 0.3307  | val_0_accuracy: 0.81131 |  0:00:21s\n","epoch 29 | loss: 0.33082 | val_0_accuracy: 0.77972 |  0:00:22s\n","epoch 30 | loss: 0.33628 | val_0_accuracy: 0.82211 |  0:00:23s\n","epoch 31 | loss: 0.32629 | val_0_accuracy: 0.84123 |  0:00:23s\n","epoch 32 | loss: 0.32533 | val_0_accuracy: 0.83624 |  0:00:24s\n","epoch 33 | loss: 0.32657 | val_0_accuracy: 0.82627 |  0:00:25s\n","epoch 34 | loss: 0.32572 | val_0_accuracy: 0.83791 |  0:00:26s\n","epoch 35 | loss: 0.33118 | val_0_accuracy: 0.84456 |  0:00:26s\n","epoch 36 | loss: 0.32282 | val_0_accuracy: 0.85287 |  0:00:27s\n","epoch 37 | loss: 0.31426 | val_0_accuracy: 0.85287 |  0:00:28s\n","epoch 38 | loss: 0.31755 | val_0_accuracy: 0.85204 |  0:00:28s\n","epoch 39 | loss: 0.32187 | val_0_accuracy: 0.84289 |  0:00:29s\n","epoch 40 | loss: 0.32317 | val_0_accuracy: 0.83791 |  0:00:30s\n","epoch 41 | loss: 0.32018 | val_0_accuracy: 0.84705 |  0:00:31s\n","epoch 42 | loss: 0.31893 | val_0_accuracy: 0.84622 |  0:00:31s\n","epoch 43 | loss: 0.31832 | val_0_accuracy: 0.85121 |  0:00:32s\n","epoch 44 | loss: 0.3132  | val_0_accuracy: 0.85869 |  0:00:33s\n","epoch 45 | loss: 0.31061 | val_0_accuracy: 0.86201 |  0:00:34s\n","epoch 46 | loss: 0.31284 | val_0_accuracy: 0.85287 |  0:00:34s\n","epoch 47 | loss: 0.31224 | val_0_accuracy: 0.84788 |  0:00:35s\n","epoch 48 | loss: 0.30486 | val_0_accuracy: 0.85619 |  0:00:36s\n","epoch 49 | loss: 0.3065  | val_0_accuracy: 0.85536 |  0:00:37s\n","epoch 50 | loss: 0.30822 | val_0_accuracy: 0.84705 |  0:00:37s\n","epoch 51 | loss: 0.31675 | val_0_accuracy: 0.86118 |  0:00:38s\n","epoch 52 | loss: 0.31148 | val_0_accuracy: 0.86367 |  0:00:39s\n","epoch 53 | loss: 0.30928 | val_0_accuracy: 0.84954 |  0:00:39s\n","epoch 54 | loss: 0.30765 | val_0_accuracy: 0.85619 |  0:00:40s\n","epoch 55 | loss: 0.30385 | val_0_accuracy: 0.86866 |  0:00:41s\n","epoch 56 | loss: 0.30461 | val_0_accuracy: 0.85287 |  0:00:42s\n","epoch 57 | loss: 0.30578 | val_0_accuracy: 0.86284 |  0:00:42s\n","epoch 58 | loss: 0.30459 | val_0_accuracy: 0.86284 |  0:00:43s\n","epoch 59 | loss: 0.30581 | val_0_accuracy: 0.85453 |  0:00:44s\n","epoch 60 | loss: 0.30449 | val_0_accuracy: 0.85702 |  0:00:45s\n","epoch 61 | loss: 0.30464 | val_0_accuracy: 0.83874 |  0:00:45s\n","epoch 62 | loss: 0.30428 | val_0_accuracy: 0.85453 |  0:00:46s\n","epoch 63 | loss: 0.30262 | val_0_accuracy: 0.86284 |  0:00:47s\n","epoch 64 | loss: 0.30157 | val_0_accuracy: 0.86284 |  0:00:47s\n","epoch 65 | loss: 0.29979 | val_0_accuracy: 0.86201 |  0:00:48s\n","\n","Early stopping occurred at epoch 65 with best_epoch = 55 and best_val_0_accuracy = 0.86866\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-07-06 06:05:42,663] Trial 33 finished with value: 0.8686616791354946 and parameters: {'n_d': 54, 'n_steps': 3, 'gamma': 1.2394910758689823, 'n_independent': 5, 'n_shared': 5, 'momentum': 0.26260186076069114}. Best is trial 24 with value: 0.8719866999168745.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 0.66317 | val_0_accuracy: 0.52535 |  0:00:00s\n","epoch 1  | loss: 0.60326 | val_0_accuracy: 0.51039 |  0:00:01s\n","epoch 2  | loss: 0.54041 | val_0_accuracy: 0.56359 |  0:00:02s\n","epoch 3  | loss: 0.5234  | val_0_accuracy: 0.5744  |  0:00:03s\n","epoch 4  | loss: 0.50832 | val_0_accuracy: 0.57357 |  0:00:04s\n","epoch 5  | loss: 0.47999 | val_0_accuracy: 0.60931 |  0:00:05s\n","epoch 6  | loss: 0.47858 | val_0_accuracy: 0.62843 |  0:00:06s\n","epoch 7  | loss: 0.47006 | val_0_accuracy: 0.58853 |  0:00:07s\n","epoch 8  | loss: 0.46121 | val_0_accuracy: 0.64505 |  0:00:08s\n","epoch 9  | loss: 0.44722 | val_0_accuracy: 0.69077 |  0:00:08s\n","epoch 10 | loss: 0.44683 | val_0_accuracy: 0.69659 |  0:00:10s\n","epoch 11 | loss: 0.43471 | val_0_accuracy: 0.68828 |  0:00:11s\n","epoch 12 | loss: 0.43217 | val_0_accuracy: 0.71904 |  0:00:11s\n","epoch 13 | loss: 0.42969 | val_0_accuracy: 0.7207  |  0:00:12s\n","epoch 14 | loss: 0.42869 | val_0_accuracy: 0.71987 |  0:00:13s\n","epoch 15 | loss: 0.42635 | val_0_accuracy: 0.72984 |  0:00:14s\n","epoch 16 | loss: 0.4176  | val_0_accuracy: 0.72153 |  0:00:15s\n","epoch 17 | loss: 0.40592 | val_0_accuracy: 0.73815 |  0:00:16s\n","epoch 18 | loss: 0.39372 | val_0_accuracy: 0.73234 |  0:00:17s\n","epoch 19 | loss: 0.3987  | val_0_accuracy: 0.75145 |  0:00:18s\n","epoch 20 | loss: 0.3869  | val_0_accuracy: 0.74813 |  0:00:19s\n","epoch 21 | loss: 0.38447 | val_0_accuracy: 0.7581  |  0:00:20s\n","epoch 22 | loss: 0.38198 | val_0_accuracy: 0.75312 |  0:00:20s\n","epoch 23 | loss: 0.38353 | val_0_accuracy: 0.76143 |  0:00:21s\n","epoch 24 | loss: 0.37985 | val_0_accuracy: 0.77639 |  0:00:22s\n","epoch 25 | loss: 0.37955 | val_0_accuracy: 0.78055 |  0:00:23s\n","epoch 26 | loss: 0.37085 | val_0_accuracy: 0.77889 |  0:00:24s\n","epoch 27 | loss: 0.36798 | val_0_accuracy: 0.79468 |  0:00:25s\n","epoch 28 | loss: 0.36806 | val_0_accuracy: 0.78637 |  0:00:26s\n","epoch 29 | loss: 0.36656 | val_0_accuracy: 0.79717 |  0:00:27s\n","epoch 30 | loss: 0.36632 | val_0_accuracy: 0.81629 |  0:00:28s\n","epoch 31 | loss: 0.36911 | val_0_accuracy: 0.80715 |  0:00:29s\n","epoch 32 | loss: 0.36886 | val_0_accuracy: 0.81962 |  0:00:30s\n","epoch 33 | loss: 0.36352 | val_0_accuracy: 0.81546 |  0:00:30s\n","epoch 34 | loss: 0.3575  | val_0_accuracy: 0.82876 |  0:00:31s\n","epoch 35 | loss: 0.35419 | val_0_accuracy: 0.82128 |  0:00:32s\n","epoch 36 | loss: 0.35535 | val_0_accuracy: 0.83707 |  0:00:33s\n","epoch 37 | loss: 0.35195 | val_0_accuracy: 0.83707 |  0:00:34s\n","epoch 38 | loss: 0.35497 | val_0_accuracy: 0.81463 |  0:00:35s\n","epoch 39 | loss: 0.35303 | val_0_accuracy: 0.84456 |  0:00:36s\n","epoch 40 | loss: 0.36092 | val_0_accuracy: 0.83791 |  0:00:37s\n","epoch 41 | loss: 0.35652 | val_0_accuracy: 0.83209 |  0:00:38s\n","epoch 42 | loss: 0.35696 | val_0_accuracy: 0.84456 |  0:00:39s\n","epoch 43 | loss: 0.35649 | val_0_accuracy: 0.83209 |  0:00:39s\n","epoch 44 | loss: 0.35328 | val_0_accuracy: 0.84622 |  0:00:40s\n","epoch 45 | loss: 0.35485 | val_0_accuracy: 0.84123 |  0:00:41s\n","epoch 46 | loss: 0.36777 | val_0_accuracy: 0.84871 |  0:00:42s\n","epoch 47 | loss: 0.36975 | val_0_accuracy: 0.84788 |  0:00:43s\n","epoch 48 | loss: 0.36771 | val_0_accuracy: 0.85287 |  0:00:44s\n","epoch 49 | loss: 0.35762 | val_0_accuracy: 0.84372 |  0:00:45s\n","epoch 50 | loss: 0.35744 | val_0_accuracy: 0.84871 |  0:00:46s\n","epoch 51 | loss: 0.35672 | val_0_accuracy: 0.83957 |  0:00:47s\n","epoch 52 | loss: 0.35748 | val_0_accuracy: 0.84788 |  0:00:48s\n","epoch 53 | loss: 0.35837 | val_0_accuracy: 0.84456 |  0:00:49s\n","epoch 54 | loss: 0.36362 | val_0_accuracy: 0.84705 |  0:00:50s\n","epoch 55 | loss: 0.36483 | val_0_accuracy: 0.85204 |  0:00:50s\n","epoch 56 | loss: 0.35698 | val_0_accuracy: 0.85037 |  0:00:51s\n","epoch 57 | loss: 0.35583 | val_0_accuracy: 0.8537  |  0:00:52s\n","epoch 58 | loss: 0.35026 | val_0_accuracy: 0.84705 |  0:00:53s\n","epoch 59 | loss: 0.34755 | val_0_accuracy: 0.84954 |  0:00:54s\n","epoch 60 | loss: 0.35069 | val_0_accuracy: 0.85536 |  0:00:55s\n","epoch 61 | loss: 0.3458  | val_0_accuracy: 0.85619 |  0:00:56s\n","epoch 62 | loss: 0.34801 | val_0_accuracy: 0.84622 |  0:00:57s\n","epoch 63 | loss: 0.347   | val_0_accuracy: 0.8537  |  0:00:58s\n","epoch 64 | loss: 0.34598 | val_0_accuracy: 0.85536 |  0:00:59s\n","epoch 65 | loss: 0.34336 | val_0_accuracy: 0.84871 |  0:01:00s\n","epoch 66 | loss: 0.34278 | val_0_accuracy: 0.85702 |  0:01:00s\n","epoch 67 | loss: 0.33774 | val_0_accuracy: 0.85453 |  0:01:01s\n","epoch 68 | loss: 0.34325 | val_0_accuracy: 0.86035 |  0:01:02s\n","epoch 69 | loss: 0.34158 | val_0_accuracy: 0.85204 |  0:01:03s\n","epoch 70 | loss: 0.3407  | val_0_accuracy: 0.84954 |  0:01:04s\n","epoch 71 | loss: 0.35059 | val_0_accuracy: 0.84539 |  0:01:05s\n","epoch 72 | loss: 0.34653 | val_0_accuracy: 0.86201 |  0:01:06s\n","epoch 73 | loss: 0.34722 | val_0_accuracy: 0.84289 |  0:01:07s\n","epoch 74 | loss: 0.35388 | val_0_accuracy: 0.84372 |  0:01:08s\n","epoch 75 | loss: 0.34281 | val_0_accuracy: 0.85204 |  0:01:08s\n","epoch 76 | loss: 0.34125 | val_0_accuracy: 0.85702 |  0:01:09s\n","epoch 77 | loss: 0.34061 | val_0_accuracy: 0.85121 |  0:01:10s\n","epoch 78 | loss: 0.33995 | val_0_accuracy: 0.84622 |  0:01:11s\n","epoch 79 | loss: 0.341   | val_0_accuracy: 0.85204 |  0:01:12s\n","epoch 80 | loss: 0.34537 | val_0_accuracy: 0.84705 |  0:01:13s\n","epoch 81 | loss: 0.34669 | val_0_accuracy: 0.84705 |  0:01:14s\n","epoch 82 | loss: 0.34827 | val_0_accuracy: 0.84705 |  0:01:15s\n","\n","Early stopping occurred at epoch 82 with best_epoch = 72 and best_val_0_accuracy = 0.86201\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-07-06 06:06:58,336] Trial 34 finished with value: 0.8620116375727348 and parameters: {'n_d': 13, 'n_steps': 5, 'gamma': 1.3447601070998305, 'n_independent': 4, 'n_shared': 4, 'momentum': 0.03522365169051526}. Best is trial 24 with value: 0.8719866999168745.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 0.73296 | val_0_accuracy: 0.53034 |  0:00:00s\n","epoch 1  | loss: 0.48863 | val_0_accuracy: 0.51787 |  0:00:01s\n","epoch 2  | loss: 0.44613 | val_0_accuracy: 0.52452 |  0:00:01s\n","epoch 3  | loss: 0.41697 | val_0_accuracy: 0.51621 |  0:00:02s\n","epoch 4  | loss: 0.42    | val_0_accuracy: 0.53533 |  0:00:02s\n","epoch 5  | loss: 0.39991 | val_0_accuracy: 0.54032 |  0:00:03s\n","epoch 6  | loss: 0.39402 | val_0_accuracy: 0.54364 |  0:00:03s\n","epoch 7  | loss: 0.38704 | val_0_accuracy: 0.5478  |  0:00:04s\n","epoch 8  | loss: 0.3901  | val_0_accuracy: 0.5453  |  0:00:05s\n","epoch 9  | loss: 0.38421 | val_0_accuracy: 0.52868 |  0:00:05s\n","epoch 10 | loss: 0.37596 | val_0_accuracy: 0.52618 |  0:00:06s\n","epoch 11 | loss: 0.38058 | val_0_accuracy: 0.51953 |  0:00:06s\n","epoch 12 | loss: 0.36958 | val_0_accuracy: 0.51704 |  0:00:07s\n","epoch 13 | loss: 0.36858 | val_0_accuracy: 0.52452 |  0:00:07s\n","epoch 14 | loss: 0.36891 | val_0_accuracy: 0.59435 |  0:00:08s\n","epoch 15 | loss: 0.37943 | val_0_accuracy: 0.53948 |  0:00:08s\n","epoch 16 | loss: 0.37714 | val_0_accuracy: 0.55362 |  0:00:09s\n","epoch 17 | loss: 0.38342 | val_0_accuracy: 0.58936 |  0:00:10s\n","epoch 18 | loss: 0.37105 | val_0_accuracy: 0.62427 |  0:00:10s\n","epoch 19 | loss: 0.37513 | val_0_accuracy: 0.71488 |  0:00:11s\n","epoch 20 | loss: 0.37562 | val_0_accuracy: 0.70324 |  0:00:11s\n","epoch 21 | loss: 0.37091 | val_0_accuracy: 0.73483 |  0:00:12s\n","epoch 22 | loss: 0.38376 | val_0_accuracy: 0.73234 |  0:00:12s\n","epoch 23 | loss: 0.37679 | val_0_accuracy: 0.76808 |  0:00:13s\n","epoch 24 | loss: 0.36971 | val_0_accuracy: 0.77805 |  0:00:13s\n","epoch 25 | loss: 0.36388 | val_0_accuracy: 0.75894 |  0:00:14s\n","epoch 26 | loss: 0.35867 | val_0_accuracy: 0.78055 |  0:00:15s\n","epoch 27 | loss: 0.35361 | val_0_accuracy: 0.7847  |  0:00:15s\n","epoch 28 | loss: 0.34797 | val_0_accuracy: 0.79884 |  0:00:16s\n","epoch 29 | loss: 0.34605 | val_0_accuracy: 0.798   |  0:00:16s\n","epoch 30 | loss: 0.34417 | val_0_accuracy: 0.80798 |  0:00:17s\n","epoch 31 | loss: 0.34282 | val_0_accuracy: 0.81214 |  0:00:17s\n","epoch 32 | loss: 0.33735 | val_0_accuracy: 0.83707 |  0:00:18s\n","epoch 33 | loss: 0.34111 | val_0_accuracy: 0.83874 |  0:00:18s\n","epoch 34 | loss: 0.33866 | val_0_accuracy: 0.83707 |  0:00:19s\n","epoch 35 | loss: 0.34155 | val_0_accuracy: 0.83957 |  0:00:19s\n","epoch 36 | loss: 0.3413  | val_0_accuracy: 0.84539 |  0:00:20s\n","epoch 37 | loss: 0.33847 | val_0_accuracy: 0.85619 |  0:00:21s\n","epoch 38 | loss: 0.34053 | val_0_accuracy: 0.86284 |  0:00:21s\n","epoch 39 | loss: 0.34248 | val_0_accuracy: 0.84206 |  0:00:22s\n","epoch 40 | loss: 0.34602 | val_0_accuracy: 0.8537  |  0:00:22s\n","epoch 41 | loss: 0.33686 | val_0_accuracy: 0.86617 |  0:00:23s\n","epoch 42 | loss: 0.34033 | val_0_accuracy: 0.86284 |  0:00:23s\n","epoch 43 | loss: 0.33888 | val_0_accuracy: 0.85619 |  0:00:24s\n","epoch 44 | loss: 0.34216 | val_0_accuracy: 0.83874 |  0:00:24s\n","epoch 45 | loss: 0.33708 | val_0_accuracy: 0.84705 |  0:00:25s\n","epoch 46 | loss: 0.33518 | val_0_accuracy: 0.86035 |  0:00:26s\n","epoch 47 | loss: 0.33204 | val_0_accuracy: 0.86451 |  0:00:26s\n","epoch 48 | loss: 0.33112 | val_0_accuracy: 0.86284 |  0:00:27s\n","epoch 49 | loss: 0.33261 | val_0_accuracy: 0.86035 |  0:00:27s\n","epoch 50 | loss: 0.33465 | val_0_accuracy: 0.85453 |  0:00:28s\n","epoch 51 | loss: 0.34642 | val_0_accuracy: 0.84206 |  0:00:28s\n","\n","Early stopping occurred at epoch 51 with best_epoch = 41 and best_val_0_accuracy = 0.86617\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-07-06 06:07:27,498] Trial 35 finished with value: 0.8661679135494597 and parameters: {'n_d': 57, 'n_steps': 4, 'gamma': 1.7584247399595379, 'n_independent': 2, 'n_shared': 3, 'momentum': 0.33199467992770626}. Best is trial 24 with value: 0.8719866999168745.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 0.70853 | val_0_accuracy: 0.50291 |  0:00:00s\n","epoch 1  | loss: 0.5334  | val_0_accuracy: 0.54697 |  0:00:01s\n","epoch 2  | loss: 0.45936 | val_0_accuracy: 0.53616 |  0:00:01s\n","epoch 3  | loss: 0.45226 | val_0_accuracy: 0.55112 |  0:00:02s\n","epoch 4  | loss: 0.42138 | val_0_accuracy: 0.59268 |  0:00:03s\n","epoch 5  | loss: 0.41476 | val_0_accuracy: 0.59102 |  0:00:03s\n","epoch 6  | loss: 0.41785 | val_0_accuracy: 0.61845 |  0:00:04s\n","epoch 7  | loss: 0.3962  | val_0_accuracy: 0.62843 |  0:00:04s\n","epoch 8  | loss: 0.3927  | val_0_accuracy: 0.62344 |  0:00:05s\n","epoch 9  | loss: 0.38754 | val_0_accuracy: 0.66002 |  0:00:06s\n","epoch 10 | loss: 0.38314 | val_0_accuracy: 0.66168 |  0:00:06s\n","epoch 11 | loss: 0.38551 | val_0_accuracy: 0.70574 |  0:00:07s\n","epoch 12 | loss: 0.37795 | val_0_accuracy: 0.70407 |  0:00:08s\n","epoch 13 | loss: 0.37549 | val_0_accuracy: 0.72735 |  0:00:08s\n","epoch 14 | loss: 0.3671  | val_0_accuracy: 0.6916  |  0:00:09s\n","epoch 15 | loss: 0.36293 | val_0_accuracy: 0.69909 |  0:00:10s\n","epoch 16 | loss: 0.36838 | val_0_accuracy: 0.72818 |  0:00:10s\n","epoch 17 | loss: 0.36517 | val_0_accuracy: 0.75395 |  0:00:11s\n","epoch 18 | loss: 0.36017 | val_0_accuracy: 0.7074  |  0:00:12s\n","epoch 19 | loss: 0.35313 | val_0_accuracy: 0.74231 |  0:00:12s\n","epoch 20 | loss: 0.35522 | val_0_accuracy: 0.77224 |  0:00:13s\n","epoch 21 | loss: 0.35852 | val_0_accuracy: 0.76475 |  0:00:13s\n","epoch 22 | loss: 0.35396 | val_0_accuracy: 0.76559 |  0:00:14s\n","epoch 23 | loss: 0.35579 | val_0_accuracy: 0.7606  |  0:00:15s\n","epoch 24 | loss: 0.34824 | val_0_accuracy: 0.74979 |  0:00:15s\n","epoch 25 | loss: 0.34407 | val_0_accuracy: 0.80382 |  0:00:16s\n","epoch 26 | loss: 0.34628 | val_0_accuracy: 0.78803 |  0:00:16s\n","epoch 27 | loss: 0.3438  | val_0_accuracy: 0.78969 |  0:00:17s\n","epoch 28 | loss: 0.34251 | val_0_accuracy: 0.79468 |  0:00:18s\n","epoch 29 | loss: 0.34509 | val_0_accuracy: 0.80632 |  0:00:18s\n","epoch 30 | loss: 0.33951 | val_0_accuracy: 0.83126 |  0:00:19s\n","epoch 31 | loss: 0.33646 | val_0_accuracy: 0.82627 |  0:00:20s\n","epoch 32 | loss: 0.33541 | val_0_accuracy: 0.83791 |  0:00:20s\n","epoch 33 | loss: 0.33892 | val_0_accuracy: 0.81796 |  0:00:21s\n","epoch 34 | loss: 0.33296 | val_0_accuracy: 0.83042 |  0:00:21s\n","epoch 35 | loss: 0.33886 | val_0_accuracy: 0.83458 |  0:00:22s\n","epoch 36 | loss: 0.33168 | val_0_accuracy: 0.84622 |  0:00:23s\n","epoch 37 | loss: 0.33637 | val_0_accuracy: 0.85786 |  0:00:23s\n","epoch 38 | loss: 0.333   | val_0_accuracy: 0.85952 |  0:00:24s\n","epoch 39 | loss: 0.33901 | val_0_accuracy: 0.83874 |  0:00:25s\n","epoch 40 | loss: 0.33496 | val_0_accuracy: 0.83957 |  0:00:25s\n","epoch 41 | loss: 0.33486 | val_0_accuracy: 0.8404  |  0:00:26s\n","epoch 42 | loss: 0.32868 | val_0_accuracy: 0.84622 |  0:00:26s\n","epoch 43 | loss: 0.33399 | val_0_accuracy: 0.84456 |  0:00:27s\n","epoch 44 | loss: 0.33573 | val_0_accuracy: 0.85037 |  0:00:28s\n","epoch 45 | loss: 0.33085 | val_0_accuracy: 0.85121 |  0:00:28s\n","epoch 46 | loss: 0.3297  | val_0_accuracy: 0.85453 |  0:00:29s\n","epoch 47 | loss: 0.32424 | val_0_accuracy: 0.86118 |  0:00:29s\n","epoch 48 | loss: 0.32343 | val_0_accuracy: 0.85869 |  0:00:30s\n","epoch 49 | loss: 0.32183 | val_0_accuracy: 0.85869 |  0:00:31s\n","epoch 50 | loss: 0.32523 | val_0_accuracy: 0.87116 |  0:00:31s\n","epoch 51 | loss: 0.31902 | val_0_accuracy: 0.86866 |  0:00:32s\n","epoch 52 | loss: 0.32815 | val_0_accuracy: 0.85121 |  0:00:33s\n","epoch 53 | loss: 0.32267 | val_0_accuracy: 0.85037 |  0:00:33s\n","epoch 54 | loss: 0.32036 | val_0_accuracy: 0.86367 |  0:00:34s\n","epoch 55 | loss: 0.32127 | val_0_accuracy: 0.85287 |  0:00:34s\n","epoch 56 | loss: 0.31734 | val_0_accuracy: 0.85619 |  0:00:35s\n","epoch 57 | loss: 0.31452 | val_0_accuracy: 0.86035 |  0:00:36s\n","epoch 58 | loss: 0.31439 | val_0_accuracy: 0.86201 |  0:00:36s\n","epoch 59 | loss: 0.31421 | val_0_accuracy: 0.86118 |  0:00:37s\n","epoch 60 | loss: 0.31435 | val_0_accuracy: 0.87116 |  0:00:37s\n","\n","Early stopping occurred at epoch 60 with best_epoch = 50 and best_val_0_accuracy = 0.87116\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-07-06 06:08:05,840] Trial 36 finished with value: 0.8711554447215295 and parameters: {'n_d': 43, 'n_steps': 4, 'gamma': 1.9036597485609557, 'n_independent': 4, 'n_shared': 2, 'momentum': 0.16106061937134608}. Best is trial 24 with value: 0.8719866999168745.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 0.91118 | val_0_accuracy: 0.52702 |  0:00:00s\n","epoch 1  | loss: 0.56626 | val_0_accuracy: 0.54613 |  0:00:01s\n","epoch 2  | loss: 0.49376 | val_0_accuracy: 0.63092 |  0:00:01s\n","epoch 3  | loss: 0.46232 | val_0_accuracy: 0.56775 |  0:00:02s\n","epoch 4  | loss: 0.43911 | val_0_accuracy: 0.55278 |  0:00:02s\n","epoch 5  | loss: 0.43488 | val_0_accuracy: 0.54447 |  0:00:03s\n","epoch 6  | loss: 0.4239  | val_0_accuracy: 0.58105 |  0:00:03s\n","epoch 7  | loss: 0.42031 | val_0_accuracy: 0.58271 |  0:00:04s\n","epoch 8  | loss: 0.40792 | val_0_accuracy: 0.59102 |  0:00:04s\n","epoch 9  | loss: 0.40538 | val_0_accuracy: 0.61347 |  0:00:05s\n","epoch 10 | loss: 0.39867 | val_0_accuracy: 0.5985  |  0:00:05s\n","epoch 11 | loss: 0.40232 | val_0_accuracy: 0.56775 |  0:00:06s\n","epoch 12 | loss: 0.39905 | val_0_accuracy: 0.65919 |  0:00:07s\n","epoch 13 | loss: 0.39678 | val_0_accuracy: 0.63259 |  0:00:07s\n","epoch 14 | loss: 0.38881 | val_0_accuracy: 0.65586 |  0:00:08s\n","epoch 15 | loss: 0.3868  | val_0_accuracy: 0.66916 |  0:00:08s\n","epoch 16 | loss: 0.38847 | val_0_accuracy: 0.71488 |  0:00:09s\n","epoch 17 | loss: 0.39039 | val_0_accuracy: 0.72984 |  0:00:09s\n","epoch 18 | loss: 0.38378 | val_0_accuracy: 0.7207  |  0:00:10s\n","epoch 19 | loss: 0.39561 | val_0_accuracy: 0.73067 |  0:00:10s\n","epoch 20 | loss: 0.39015 | val_0_accuracy: 0.76808 |  0:00:11s\n","epoch 21 | loss: 0.38562 | val_0_accuracy: 0.78221 |  0:00:12s\n","epoch 22 | loss: 0.38184 | val_0_accuracy: 0.76392 |  0:00:12s\n","epoch 23 | loss: 0.38602 | val_0_accuracy: 0.75478 |  0:00:13s\n","epoch 24 | loss: 0.3874  | val_0_accuracy: 0.75894 |  0:00:13s\n","epoch 25 | loss: 0.3904  | val_0_accuracy: 0.77722 |  0:00:14s\n","epoch 26 | loss: 0.37713 | val_0_accuracy: 0.78221 |  0:00:15s\n","epoch 27 | loss: 0.36768 | val_0_accuracy: 0.76559 |  0:00:15s\n","epoch 28 | loss: 0.37344 | val_0_accuracy: 0.77805 |  0:00:16s\n","epoch 29 | loss: 0.37134 | val_0_accuracy: 0.78803 |  0:00:16s\n","epoch 30 | loss: 0.37344 | val_0_accuracy: 0.7714  |  0:00:17s\n","epoch 31 | loss: 0.36846 | val_0_accuracy: 0.81297 |  0:00:17s\n","epoch 32 | loss: 0.37587 | val_0_accuracy: 0.81546 |  0:00:18s\n","epoch 33 | loss: 0.37507 | val_0_accuracy: 0.81712 |  0:00:18s\n","epoch 34 | loss: 0.38207 | val_0_accuracy: 0.82377 |  0:00:19s\n","epoch 35 | loss: 0.37179 | val_0_accuracy: 0.82128 |  0:00:19s\n","epoch 36 | loss: 0.36387 | val_0_accuracy: 0.83042 |  0:00:20s\n","epoch 37 | loss: 0.36144 | val_0_accuracy: 0.84372 |  0:00:21s\n","epoch 38 | loss: 0.35804 | val_0_accuracy: 0.84871 |  0:00:21s\n","epoch 39 | loss: 0.35509 | val_0_accuracy: 0.84289 |  0:00:22s\n","epoch 40 | loss: 0.35589 | val_0_accuracy: 0.82128 |  0:00:22s\n","epoch 41 | loss: 0.36115 | val_0_accuracy: 0.84206 |  0:00:23s\n","epoch 42 | loss: 0.35847 | val_0_accuracy: 0.82959 |  0:00:23s\n","epoch 43 | loss: 0.35973 | val_0_accuracy: 0.83791 |  0:00:24s\n","epoch 44 | loss: 0.35766 | val_0_accuracy: 0.83874 |  0:00:24s\n","epoch 45 | loss: 0.36133 | val_0_accuracy: 0.83126 |  0:00:25s\n","epoch 46 | loss: 0.3566  | val_0_accuracy: 0.84123 |  0:00:25s\n","epoch 47 | loss: 0.35131 | val_0_accuracy: 0.84622 |  0:00:26s\n","epoch 48 | loss: 0.35987 | val_0_accuracy: 0.84456 |  0:00:27s\n","\n","Early stopping occurred at epoch 48 with best_epoch = 38 and best_val_0_accuracy = 0.84871\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-07-06 06:08:33,234] Trial 37 finished with value: 0.8487115544472152 and parameters: {'n_d': 43, 'n_steps': 4, 'gamma': 1.9551929343139263, 'n_independent': 4, 'n_shared': 1, 'momentum': 0.16304002448768087}. Best is trial 24 with value: 0.8719866999168745.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 0.96638 | val_0_accuracy: 0.5187  |  0:00:00s\n","epoch 1  | loss: 0.72492 | val_0_accuracy: 0.51621 |  0:00:01s\n","epoch 2  | loss: 0.67184 | val_0_accuracy: 0.49044 |  0:00:02s\n","epoch 3  | loss: 0.54405 | val_0_accuracy: 0.5212  |  0:00:02s\n","epoch 4  | loss: 0.49129 | val_0_accuracy: 0.51288 |  0:00:03s\n","epoch 5  | loss: 0.4604  | val_0_accuracy: 0.61014 |  0:00:04s\n","epoch 6  | loss: 0.43995 | val_0_accuracy: 0.6251  |  0:00:05s\n","epoch 7  | loss: 0.43723 | val_0_accuracy: 0.65919 |  0:00:05s\n","epoch 8  | loss: 0.45782 | val_0_accuracy: 0.58603 |  0:00:06s\n","epoch 9  | loss: 0.45716 | val_0_accuracy: 0.67914 |  0:00:07s\n","epoch 10 | loss: 0.45329 | val_0_accuracy: 0.71571 |  0:00:08s\n","epoch 11 | loss: 0.46492 | val_0_accuracy: 0.67332 |  0:00:08s\n","epoch 12 | loss: 0.44893 | val_0_accuracy: 0.68994 |  0:00:09s\n","epoch 13 | loss: 0.43906 | val_0_accuracy: 0.67664 |  0:00:10s\n","epoch 14 | loss: 0.43207 | val_0_accuracy: 0.67997 |  0:00:11s\n","epoch 15 | loss: 0.42889 | val_0_accuracy: 0.69742 |  0:00:11s\n","epoch 16 | loss: 0.42233 | val_0_accuracy: 0.7207  |  0:00:12s\n","epoch 17 | loss: 0.41022 | val_0_accuracy: 0.70906 |  0:00:13s\n","epoch 18 | loss: 0.41702 | val_0_accuracy: 0.73649 |  0:00:14s\n","epoch 19 | loss: 0.40979 | val_0_accuracy: 0.73982 |  0:00:14s\n","epoch 20 | loss: 0.40917 | val_0_accuracy: 0.74314 |  0:00:15s\n","epoch 21 | loss: 0.40537 | val_0_accuracy: 0.76642 |  0:00:16s\n","epoch 22 | loss: 0.40601 | val_0_accuracy: 0.74314 |  0:00:17s\n","epoch 23 | loss: 0.41125 | val_0_accuracy: 0.77057 |  0:00:17s\n","epoch 24 | loss: 0.40987 | val_0_accuracy: 0.7473  |  0:00:18s\n","epoch 25 | loss: 0.41235 | val_0_accuracy: 0.77889 |  0:00:19s\n","epoch 26 | loss: 0.40099 | val_0_accuracy: 0.77722 |  0:00:20s\n","epoch 27 | loss: 0.39591 | val_0_accuracy: 0.75312 |  0:00:20s\n","epoch 28 | loss: 0.39958 | val_0_accuracy: 0.75062 |  0:00:21s\n","epoch 29 | loss: 0.39749 | val_0_accuracy: 0.75644 |  0:00:22s\n","epoch 30 | loss: 0.39691 | val_0_accuracy: 0.77473 |  0:00:23s\n","epoch 31 | loss: 0.39197 | val_0_accuracy: 0.79884 |  0:00:23s\n","epoch 32 | loss: 0.38306 | val_0_accuracy: 0.79468 |  0:00:24s\n","epoch 33 | loss: 0.38356 | val_0_accuracy: 0.81297 |  0:00:25s\n","epoch 34 | loss: 0.37961 | val_0_accuracy: 0.8138  |  0:00:26s\n","epoch 35 | loss: 0.37684 | val_0_accuracy: 0.82959 |  0:00:26s\n","epoch 36 | loss: 0.3744  | val_0_accuracy: 0.8271  |  0:00:27s\n","epoch 37 | loss: 0.36889 | val_0_accuracy: 0.83042 |  0:00:28s\n","epoch 38 | loss: 0.37597 | val_0_accuracy: 0.80299 |  0:00:29s\n","epoch 39 | loss: 0.37604 | val_0_accuracy: 0.82377 |  0:00:29s\n","epoch 40 | loss: 0.36754 | val_0_accuracy: 0.83957 |  0:00:30s\n","epoch 41 | loss: 0.36468 | val_0_accuracy: 0.83541 |  0:00:31s\n","epoch 42 | loss: 0.36456 | val_0_accuracy: 0.83957 |  0:00:32s\n","epoch 43 | loss: 0.36025 | val_0_accuracy: 0.84539 |  0:00:32s\n","epoch 44 | loss: 0.35982 | val_0_accuracy: 0.84206 |  0:00:33s\n","epoch 45 | loss: 0.35507 | val_0_accuracy: 0.84372 |  0:00:34s\n","epoch 46 | loss: 0.35566 | val_0_accuracy: 0.84622 |  0:00:35s\n","epoch 47 | loss: 0.35775 | val_0_accuracy: 0.83957 |  0:00:35s\n","epoch 48 | loss: 0.35955 | val_0_accuracy: 0.83874 |  0:00:36s\n","epoch 49 | loss: 0.3578  | val_0_accuracy: 0.83874 |  0:00:37s\n","epoch 50 | loss: 0.36042 | val_0_accuracy: 0.83791 |  0:00:38s\n","epoch 51 | loss: 0.35795 | val_0_accuracy: 0.83874 |  0:00:38s\n","epoch 52 | loss: 0.35532 | val_0_accuracy: 0.84123 |  0:00:39s\n","epoch 53 | loss: 0.35273 | val_0_accuracy: 0.83874 |  0:00:40s\n","epoch 54 | loss: 0.34882 | val_0_accuracy: 0.84372 |  0:00:41s\n","epoch 55 | loss: 0.34499 | val_0_accuracy: 0.84123 |  0:00:41s\n","epoch 56 | loss: 0.34409 | val_0_accuracy: 0.84289 |  0:00:42s\n","\n","Early stopping occurred at epoch 56 with best_epoch = 46 and best_val_0_accuracy = 0.84622\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-07-06 06:09:16,293] Trial 38 finished with value: 0.8462177888611804 and parameters: {'n_d': 64, 'n_steps': 6, 'gamma': 1.900224848191331, 'n_independent': 3, 'n_shared': 2, 'momentum': 0.2023276316190312}. Best is trial 24 with value: 0.8719866999168745.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 0.99051 | val_0_accuracy: 0.52203 |  0:00:01s\n","epoch 1  | loss: 0.67626 | val_0_accuracy: 0.52369 |  0:00:02s\n","epoch 2  | loss: 0.61624 | val_0_accuracy: 0.56525 |  0:00:03s\n","epoch 3  | loss: 0.54881 | val_0_accuracy: 0.61264 |  0:00:04s\n","epoch 4  | loss: 0.56254 | val_0_accuracy: 0.67914 |  0:00:05s\n","epoch 5  | loss: 0.55234 | val_0_accuracy: 0.67664 |  0:00:06s\n","epoch 6  | loss: 0.55982 | val_0_accuracy: 0.60682 |  0:00:07s\n","epoch 7  | loss: 0.4898  | val_0_accuracy: 0.601   |  0:00:08s\n","epoch 8  | loss: 0.47696 | val_0_accuracy: 0.62344 |  0:00:09s\n","epoch 9  | loss: 0.47117 | val_0_accuracy: 0.69327 |  0:00:10s\n","epoch 10 | loss: 0.46846 | val_0_accuracy: 0.60432 |  0:00:11s\n","epoch 11 | loss: 0.46939 | val_0_accuracy: 0.64755 |  0:00:13s\n","epoch 12 | loss: 0.48594 | val_0_accuracy: 0.72984 |  0:00:14s\n","epoch 13 | loss: 0.50478 | val_0_accuracy: 0.71488 |  0:00:15s\n","epoch 14 | loss: 0.47737 | val_0_accuracy: 0.72901 |  0:00:16s\n","epoch 15 | loss: 0.46828 | val_0_accuracy: 0.75395 |  0:00:17s\n","epoch 16 | loss: 0.45992 | val_0_accuracy: 0.74896 |  0:00:18s\n","epoch 17 | loss: 0.45604 | val_0_accuracy: 0.74397 |  0:00:19s\n","epoch 18 | loss: 0.46034 | val_0_accuracy: 0.72984 |  0:00:20s\n","epoch 19 | loss: 0.43979 | val_0_accuracy: 0.75229 |  0:00:21s\n","epoch 20 | loss: 0.43117 | val_0_accuracy: 0.74231 |  0:00:22s\n","epoch 21 | loss: 0.43583 | val_0_accuracy: 0.6517  |  0:00:23s\n","epoch 22 | loss: 0.43504 | val_0_accuracy: 0.71322 |  0:00:25s\n","epoch 23 | loss: 0.4443  | val_0_accuracy: 0.7448  |  0:00:26s\n","epoch 24 | loss: 0.43706 | val_0_accuracy: 0.75977 |  0:00:27s\n","epoch 25 | loss: 0.42807 | val_0_accuracy: 0.7606  |  0:00:28s\n","epoch 26 | loss: 0.42098 | val_0_accuracy: 0.77224 |  0:00:29s\n","epoch 27 | loss: 0.42898 | val_0_accuracy: 0.7581  |  0:00:30s\n","epoch 28 | loss: 0.4241  | val_0_accuracy: 0.7739  |  0:00:31s\n","epoch 29 | loss: 0.42676 | val_0_accuracy: 0.78637 |  0:00:32s\n","epoch 30 | loss: 0.41938 | val_0_accuracy: 0.77639 |  0:00:33s\n","epoch 31 | loss: 0.42465 | val_0_accuracy: 0.80466 |  0:00:34s\n","epoch 32 | loss: 0.41757 | val_0_accuracy: 0.7872  |  0:00:35s\n","epoch 33 | loss: 0.43207 | val_0_accuracy: 0.75561 |  0:00:36s\n","epoch 34 | loss: 0.44744 | val_0_accuracy: 0.77224 |  0:00:38s\n","epoch 35 | loss: 0.42741 | val_0_accuracy: 0.80549 |  0:00:39s\n","epoch 36 | loss: 0.41458 | val_0_accuracy: 0.80299 |  0:00:40s\n","epoch 37 | loss: 0.41579 | val_0_accuracy: 0.79634 |  0:00:41s\n","epoch 38 | loss: 0.40702 | val_0_accuracy: 0.7872  |  0:00:42s\n","epoch 39 | loss: 0.4154  | val_0_accuracy: 0.81131 |  0:00:43s\n","epoch 40 | loss: 0.41879 | val_0_accuracy: 0.80299 |  0:00:44s\n","epoch 41 | loss: 0.42699 | val_0_accuracy: 0.80133 |  0:00:45s\n","epoch 42 | loss: 0.42899 | val_0_accuracy: 0.77972 |  0:00:46s\n","epoch 43 | loss: 0.43814 | val_0_accuracy: 0.79052 |  0:00:47s\n","epoch 44 | loss: 0.43304 | val_0_accuracy: 0.79717 |  0:00:48s\n","epoch 45 | loss: 0.4314  | val_0_accuracy: 0.79717 |  0:00:49s\n","epoch 46 | loss: 0.44259 | val_0_accuracy: 0.79551 |  0:00:51s\n","epoch 47 | loss: 0.44818 | val_0_accuracy: 0.78637 |  0:00:52s\n","epoch 48 | loss: 0.44232 | val_0_accuracy: 0.79468 |  0:00:53s\n","epoch 49 | loss: 0.43462 | val_0_accuracy: 0.79967 |  0:00:54s\n","\n","Early stopping occurred at epoch 49 with best_epoch = 39 and best_val_0_accuracy = 0.81131\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-07-06 06:10:11,168] Trial 39 finished with value: 0.8113050706566916 and parameters: {'n_d': 36, 'n_steps': 8, 'gamma': 1.6313301395548332, 'n_independent': 4, 'n_shared': 2, 'momentum': 0.2509083557988841}. Best is trial 24 with value: 0.8719866999168745.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 0.94125 | val_0_accuracy: 0.51787 |  0:00:00s\n","epoch 1  | loss: 0.5428  | val_0_accuracy: 0.5187  |  0:00:01s\n","epoch 2  | loss: 0.46588 | val_0_accuracy: 0.53533 |  0:00:01s\n","epoch 3  | loss: 0.45755 | val_0_accuracy: 0.54198 |  0:00:02s\n","epoch 4  | loss: 0.43041 | val_0_accuracy: 0.55445 |  0:00:02s\n","epoch 5  | loss: 0.41494 | val_0_accuracy: 0.59019 |  0:00:03s\n","epoch 6  | loss: 0.40698 | val_0_accuracy: 0.601   |  0:00:04s\n","epoch 7  | loss: 0.40504 | val_0_accuracy: 0.58853 |  0:00:04s\n","epoch 8  | loss: 0.40332 | val_0_accuracy: 0.65669 |  0:00:05s\n","epoch 9  | loss: 0.40039 | val_0_accuracy: 0.66251 |  0:00:05s\n","epoch 10 | loss: 0.41224 | val_0_accuracy: 0.68495 |  0:00:06s\n","epoch 11 | loss: 0.40023 | val_0_accuracy: 0.64256 |  0:00:06s\n","epoch 12 | loss: 0.40524 | val_0_accuracy: 0.6118  |  0:00:07s\n","epoch 13 | loss: 0.40926 | val_0_accuracy: 0.65919 |  0:00:08s\n","epoch 14 | loss: 0.39571 | val_0_accuracy: 0.67415 |  0:00:08s\n","epoch 15 | loss: 0.39207 | val_0_accuracy: 0.73649 |  0:00:09s\n","epoch 16 | loss: 0.38947 | val_0_accuracy: 0.73067 |  0:00:09s\n","epoch 17 | loss: 0.38753 | val_0_accuracy: 0.73649 |  0:00:10s\n","epoch 18 | loss: 0.37862 | val_0_accuracy: 0.74564 |  0:00:10s\n","epoch 19 | loss: 0.37123 | val_0_accuracy: 0.76392 |  0:00:11s\n","epoch 20 | loss: 0.36958 | val_0_accuracy: 0.7473  |  0:00:12s\n","epoch 21 | loss: 0.37426 | val_0_accuracy: 0.75395 |  0:00:12s\n","epoch 22 | loss: 0.37229 | val_0_accuracy: 0.76725 |  0:00:13s\n","epoch 23 | loss: 0.37373 | val_0_accuracy: 0.75312 |  0:00:13s\n","epoch 24 | loss: 0.37906 | val_0_accuracy: 0.76808 |  0:00:14s\n","epoch 25 | loss: 0.36687 | val_0_accuracy: 0.75894 |  0:00:14s\n","epoch 26 | loss: 0.36205 | val_0_accuracy: 0.78304 |  0:00:15s\n","epoch 27 | loss: 0.36222 | val_0_accuracy: 0.79717 |  0:00:16s\n","epoch 28 | loss: 0.35505 | val_0_accuracy: 0.80881 |  0:00:16s\n","epoch 29 | loss: 0.35458 | val_0_accuracy: 0.80216 |  0:00:17s\n","epoch 30 | loss: 0.3492  | val_0_accuracy: 0.82128 |  0:00:17s\n","epoch 31 | loss: 0.34571 | val_0_accuracy: 0.82128 |  0:00:18s\n","epoch 32 | loss: 0.34657 | val_0_accuracy: 0.80549 |  0:00:18s\n","epoch 33 | loss: 0.3421  | val_0_accuracy: 0.83126 |  0:00:19s\n","epoch 34 | loss: 0.34633 | val_0_accuracy: 0.83126 |  0:00:19s\n","epoch 35 | loss: 0.34078 | val_0_accuracy: 0.84622 |  0:00:20s\n","epoch 36 | loss: 0.34084 | val_0_accuracy: 0.83541 |  0:00:21s\n","epoch 37 | loss: 0.34178 | val_0_accuracy: 0.83791 |  0:00:21s\n","epoch 38 | loss: 0.34248 | val_0_accuracy: 0.83375 |  0:00:22s\n","epoch 39 | loss: 0.34069 | val_0_accuracy: 0.83292 |  0:00:22s\n","epoch 40 | loss: 0.33347 | val_0_accuracy: 0.84372 |  0:00:23s\n","epoch 41 | loss: 0.33599 | val_0_accuracy: 0.84622 |  0:00:23s\n","epoch 42 | loss: 0.33401 | val_0_accuracy: 0.83957 |  0:00:24s\n","epoch 43 | loss: 0.33121 | val_0_accuracy: 0.84622 |  0:00:24s\n","epoch 44 | loss: 0.33314 | val_0_accuracy: 0.84539 |  0:00:25s\n","epoch 45 | loss: 0.33126 | val_0_accuracy: 0.85204 |  0:00:26s\n","epoch 46 | loss: 0.32998 | val_0_accuracy: 0.85702 |  0:00:26s\n","epoch 47 | loss: 0.32864 | val_0_accuracy: 0.84871 |  0:00:27s\n","epoch 48 | loss: 0.32675 | val_0_accuracy: 0.84622 |  0:00:27s\n","epoch 49 | loss: 0.3274  | val_0_accuracy: 0.85121 |  0:00:28s\n","epoch 50 | loss: 0.3322  | val_0_accuracy: 0.85287 |  0:00:28s\n","epoch 51 | loss: 0.32695 | val_0_accuracy: 0.84954 |  0:00:29s\n","epoch 52 | loss: 0.32923 | val_0_accuracy: 0.84372 |  0:00:30s\n","epoch 53 | loss: 0.32369 | val_0_accuracy: 0.84871 |  0:00:30s\n","epoch 54 | loss: 0.32288 | val_0_accuracy: 0.84788 |  0:00:31s\n","epoch 55 | loss: 0.31785 | val_0_accuracy: 0.84705 |  0:00:31s\n","epoch 56 | loss: 0.32457 | val_0_accuracy: 0.85287 |  0:00:32s\n","\n","Early stopping occurred at epoch 56 with best_epoch = 46 and best_val_0_accuracy = 0.85702\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-07-06 06:10:43,807] Trial 40 finished with value: 0.857024106400665 and parameters: {'n_d': 46, 'n_steps': 5, 'gamma': 1.4872904370628381, 'n_independent': 3, 'n_shared': 1, 'momentum': 0.14830795751115028}. Best is trial 24 with value: 0.8719866999168745.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 0.86672 | val_0_accuracy: 0.50956 |  0:00:00s\n","epoch 1  | loss: 0.51637 | val_0_accuracy: 0.53034 |  0:00:01s\n","epoch 2  | loss: 0.47432 | val_0_accuracy: 0.52452 |  0:00:02s\n","epoch 3  | loss: 0.44111 | val_0_accuracy: 0.58271 |  0:00:02s\n","epoch 4  | loss: 0.42303 | val_0_accuracy: 0.67664 |  0:00:03s\n","epoch 5  | loss: 0.39865 | val_0_accuracy: 0.63259 |  0:00:04s\n","epoch 6  | loss: 0.38555 | val_0_accuracy: 0.62926 |  0:00:04s\n","epoch 7  | loss: 0.36999 | val_0_accuracy: 0.63508 |  0:00:05s\n","epoch 8  | loss: 0.36976 | val_0_accuracy: 0.65586 |  0:00:06s\n","epoch 9  | loss: 0.35968 | val_0_accuracy: 0.6675  |  0:00:06s\n","epoch 10 | loss: 0.36569 | val_0_accuracy: 0.67997 |  0:00:07s\n","epoch 11 | loss: 0.36667 | val_0_accuracy: 0.62344 |  0:00:08s\n","epoch 12 | loss: 0.35807 | val_0_accuracy: 0.71072 |  0:00:08s\n","epoch 13 | loss: 0.35305 | val_0_accuracy: 0.68911 |  0:00:09s\n","epoch 14 | loss: 0.35178 | val_0_accuracy: 0.68745 |  0:00:10s\n","epoch 15 | loss: 0.35405 | val_0_accuracy: 0.68163 |  0:00:11s\n","epoch 16 | loss: 0.35701 | val_0_accuracy: 0.72485 |  0:00:11s\n","epoch 17 | loss: 0.35306 | val_0_accuracy: 0.70906 |  0:00:12s\n","epoch 18 | loss: 0.34965 | val_0_accuracy: 0.70823 |  0:00:13s\n","epoch 19 | loss: 0.34576 | val_0_accuracy: 0.75145 |  0:00:13s\n","epoch 20 | loss: 0.34753 | val_0_accuracy: 0.7606  |  0:00:14s\n","epoch 21 | loss: 0.34662 | val_0_accuracy: 0.74065 |  0:00:15s\n","epoch 22 | loss: 0.34667 | val_0_accuracy: 0.77805 |  0:00:16s\n","epoch 23 | loss: 0.34383 | val_0_accuracy: 0.76475 |  0:00:16s\n","epoch 24 | loss: 0.34882 | val_0_accuracy: 0.7714  |  0:00:17s\n","epoch 25 | loss: 0.33899 | val_0_accuracy: 0.79135 |  0:00:18s\n","epoch 26 | loss: 0.34241 | val_0_accuracy: 0.76808 |  0:00:18s\n","epoch 27 | loss: 0.34087 | val_0_accuracy: 0.80632 |  0:00:19s\n","epoch 28 | loss: 0.33861 | val_0_accuracy: 0.81796 |  0:00:20s\n","epoch 29 | loss: 0.33223 | val_0_accuracy: 0.82461 |  0:00:21s\n","epoch 30 | loss: 0.33492 | val_0_accuracy: 0.83292 |  0:00:21s\n","epoch 31 | loss: 0.33596 | val_0_accuracy: 0.83375 |  0:00:22s\n","epoch 32 | loss: 0.34221 | val_0_accuracy: 0.84788 |  0:00:23s\n","epoch 33 | loss: 0.33962 | val_0_accuracy: 0.83957 |  0:00:23s\n","epoch 34 | loss: 0.33867 | val_0_accuracy: 0.83541 |  0:00:24s\n","epoch 35 | loss: 0.33467 | val_0_accuracy: 0.82876 |  0:00:25s\n","epoch 36 | loss: 0.33223 | val_0_accuracy: 0.84206 |  0:00:25s\n","epoch 37 | loss: 0.33771 | val_0_accuracy: 0.84871 |  0:00:26s\n","epoch 38 | loss: 0.33718 | val_0_accuracy: 0.84289 |  0:00:27s\n","epoch 39 | loss: 0.33291 | val_0_accuracy: 0.84871 |  0:00:28s\n","epoch 40 | loss: 0.33043 | val_0_accuracy: 0.85287 |  0:00:28s\n","epoch 41 | loss: 0.33389 | val_0_accuracy: 0.85869 |  0:00:29s\n","epoch 42 | loss: 0.33442 | val_0_accuracy: 0.84954 |  0:00:30s\n","epoch 43 | loss: 0.33409 | val_0_accuracy: 0.85204 |  0:00:30s\n","epoch 44 | loss: 0.33736 | val_0_accuracy: 0.85786 |  0:00:31s\n","epoch 45 | loss: 0.33188 | val_0_accuracy: 0.85702 |  0:00:32s\n","epoch 46 | loss: 0.33054 | val_0_accuracy: 0.85536 |  0:00:32s\n","epoch 47 | loss: 0.33086 | val_0_accuracy: 0.8537  |  0:00:33s\n","epoch 48 | loss: 0.32747 | val_0_accuracy: 0.85204 |  0:00:34s\n","epoch 49 | loss: 0.33624 | val_0_accuracy: 0.85536 |  0:00:34s\n","epoch 50 | loss: 0.3304  | val_0_accuracy: 0.85121 |  0:00:35s\n","epoch 51 | loss: 0.33448 | val_0_accuracy: 0.84206 |  0:00:36s\n","\n","Early stopping occurred at epoch 51 with best_epoch = 41 and best_val_0_accuracy = 0.85869\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-07-06 06:11:20,552] Trial 41 finished with value: 0.8586866167913549 and parameters: {'n_d': 34, 'n_steps': 4, 'gamma': 1.6732560524320281, 'n_independent': 5, 'n_shared': 2, 'momentum': 0.22030810996240657}. Best is trial 24 with value: 0.8719866999168745.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 0.64681 | val_0_accuracy: 0.54364 |  0:00:00s\n","epoch 1  | loss: 0.465   | val_0_accuracy: 0.53034 |  0:00:01s\n","epoch 2  | loss: 0.44595 | val_0_accuracy: 0.52702 |  0:00:01s\n","epoch 3  | loss: 0.43079 | val_0_accuracy: 0.53283 |  0:00:02s\n","epoch 4  | loss: 0.41392 | val_0_accuracy: 0.54032 |  0:00:02s\n","epoch 5  | loss: 0.4079  | val_0_accuracy: 0.58271 |  0:00:03s\n","epoch 6  | loss: 0.39792 | val_0_accuracy: 0.55943 |  0:00:03s\n","epoch 7  | loss: 0.38519 | val_0_accuracy: 0.54115 |  0:00:04s\n","epoch 8  | loss: 0.37923 | val_0_accuracy: 0.54697 |  0:00:04s\n","epoch 9  | loss: 0.37574 | val_0_accuracy: 0.55278 |  0:00:05s\n","epoch 10 | loss: 0.37151 | val_0_accuracy: 0.55611 |  0:00:05s\n","epoch 11 | loss: 0.36857 | val_0_accuracy: 0.57606 |  0:00:06s\n","epoch 12 | loss: 0.36598 | val_0_accuracy: 0.62095 |  0:00:06s\n","epoch 13 | loss: 0.36067 | val_0_accuracy: 0.57107 |  0:00:07s\n","epoch 14 | loss: 0.3641  | val_0_accuracy: 0.64339 |  0:00:07s\n","epoch 15 | loss: 0.36066 | val_0_accuracy: 0.68163 |  0:00:08s\n","epoch 16 | loss: 0.35512 | val_0_accuracy: 0.6808  |  0:00:08s\n","epoch 17 | loss: 0.35223 | val_0_accuracy: 0.71405 |  0:00:09s\n","epoch 18 | loss: 0.34695 | val_0_accuracy: 0.70823 |  0:00:09s\n","epoch 19 | loss: 0.33981 | val_0_accuracy: 0.71987 |  0:00:10s\n","epoch 20 | loss: 0.34003 | val_0_accuracy: 0.75478 |  0:00:10s\n","epoch 21 | loss: 0.34369 | val_0_accuracy: 0.74397 |  0:00:11s\n","epoch 22 | loss: 0.33822 | val_0_accuracy: 0.72153 |  0:00:11s\n","epoch 23 | loss: 0.33798 | val_0_accuracy: 0.74979 |  0:00:12s\n","epoch 24 | loss: 0.34093 | val_0_accuracy: 0.76642 |  0:00:12s\n","epoch 25 | loss: 0.33791 | val_0_accuracy: 0.78387 |  0:00:13s\n","epoch 26 | loss: 0.33377 | val_0_accuracy: 0.77722 |  0:00:13s\n","epoch 27 | loss: 0.33382 | val_0_accuracy: 0.77473 |  0:00:14s\n","epoch 28 | loss: 0.33621 | val_0_accuracy: 0.79219 |  0:00:14s\n","epoch 29 | loss: 0.33468 | val_0_accuracy: 0.78803 |  0:00:15s\n","epoch 30 | loss: 0.3331  | val_0_accuracy: 0.78304 |  0:00:15s\n","epoch 31 | loss: 0.33245 | val_0_accuracy: 0.79967 |  0:00:16s\n","epoch 32 | loss: 0.3265  | val_0_accuracy: 0.80964 |  0:00:16s\n","epoch 33 | loss: 0.33019 | val_0_accuracy: 0.82627 |  0:00:17s\n","epoch 34 | loss: 0.32398 | val_0_accuracy: 0.84289 |  0:00:17s\n","epoch 35 | loss: 0.32141 | val_0_accuracy: 0.85037 |  0:00:18s\n","epoch 36 | loss: 0.32149 | val_0_accuracy: 0.8537  |  0:00:18s\n","epoch 37 | loss: 0.31667 | val_0_accuracy: 0.84871 |  0:00:19s\n","epoch 38 | loss: 0.31317 | val_0_accuracy: 0.85786 |  0:00:19s\n","epoch 39 | loss: 0.31714 | val_0_accuracy: 0.86367 |  0:00:20s\n","epoch 40 | loss: 0.31862 | val_0_accuracy: 0.85204 |  0:00:20s\n","epoch 41 | loss: 0.31598 | val_0_accuracy: 0.85702 |  0:00:21s\n","epoch 42 | loss: 0.31286 | val_0_accuracy: 0.85121 |  0:00:21s\n","epoch 43 | loss: 0.31804 | val_0_accuracy: 0.86617 |  0:00:22s\n","epoch 44 | loss: 0.31469 | val_0_accuracy: 0.86201 |  0:00:22s\n","epoch 45 | loss: 0.31285 | val_0_accuracy: 0.83042 |  0:00:23s\n","epoch 46 | loss: 0.32054 | val_0_accuracy: 0.85453 |  0:00:23s\n","epoch 47 | loss: 0.31194 | val_0_accuracy: 0.86284 |  0:00:24s\n","epoch 48 | loss: 0.31169 | val_0_accuracy: 0.85869 |  0:00:25s\n","epoch 49 | loss: 0.31881 | val_0_accuracy: 0.85702 |  0:00:25s\n","epoch 50 | loss: 0.32722 | val_0_accuracy: 0.85869 |  0:00:26s\n","epoch 51 | loss: 0.31699 | val_0_accuracy: 0.86118 |  0:00:26s\n","epoch 52 | loss: 0.3118  | val_0_accuracy: 0.86617 |  0:00:26s\n","epoch 53 | loss: 0.31027 | val_0_accuracy: 0.86783 |  0:00:27s\n","epoch 54 | loss: 0.3064  | val_0_accuracy: 0.86783 |  0:00:28s\n","epoch 55 | loss: 0.30758 | val_0_accuracy: 0.86866 |  0:00:28s\n","epoch 56 | loss: 0.30627 | val_0_accuracy: 0.86783 |  0:00:29s\n","epoch 57 | loss: 0.30388 | val_0_accuracy: 0.86118 |  0:00:29s\n","epoch 58 | loss: 0.30459 | val_0_accuracy: 0.85204 |  0:00:30s\n","epoch 59 | loss: 0.31018 | val_0_accuracy: 0.86866 |  0:00:30s\n","epoch 60 | loss: 0.30017 | val_0_accuracy: 0.86949 |  0:00:31s\n","epoch 61 | loss: 0.30537 | val_0_accuracy: 0.86783 |  0:00:31s\n","epoch 62 | loss: 0.30538 | val_0_accuracy: 0.86118 |  0:00:32s\n","epoch 63 | loss: 0.30007 | val_0_accuracy: 0.86617 |  0:00:32s\n","epoch 64 | loss: 0.29755 | val_0_accuracy: 0.87282 |  0:00:33s\n","epoch 65 | loss: 0.30363 | val_0_accuracy: 0.85536 |  0:00:33s\n","epoch 66 | loss: 0.30349 | val_0_accuracy: 0.85702 |  0:00:34s\n","epoch 67 | loss: 0.30061 | val_0_accuracy: 0.86534 |  0:00:34s\n","epoch 68 | loss: 0.30162 | val_0_accuracy: 0.86866 |  0:00:35s\n","epoch 69 | loss: 0.30186 | val_0_accuracy: 0.86617 |  0:00:35s\n","epoch 70 | loss: 0.30038 | val_0_accuracy: 0.867   |  0:00:36s\n","epoch 71 | loss: 0.29643 | val_0_accuracy: 0.86783 |  0:00:36s\n","epoch 72 | loss: 0.29695 | val_0_accuracy: 0.86201 |  0:00:37s\n","epoch 73 | loss: 0.29491 | val_0_accuracy: 0.86284 |  0:00:37s\n","epoch 74 | loss: 0.28816 | val_0_accuracy: 0.86783 |  0:00:38s\n","\n","Early stopping occurred at epoch 74 with best_epoch = 64 and best_val_0_accuracy = 0.87282\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-07-06 06:11:58,882] Trial 42 finished with value: 0.8728179551122195 and parameters: {'n_d': 30, 'n_steps': 3, 'gamma': 1.5673834303925407, 'n_independent': 4, 'n_shared': 2, 'momentum': 0.10956480194746604}. Best is trial 42 with value: 0.8728179551122195.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 0.78921 | val_0_accuracy: 0.5054  |  0:00:00s\n","epoch 1  | loss: 0.56181 | val_0_accuracy: 0.52037 |  0:00:01s\n","epoch 2  | loss: 0.49332 | val_0_accuracy: 0.51704 |  0:00:01s\n","epoch 3  | loss: 0.46797 | val_0_accuracy: 0.52868 |  0:00:02s\n","epoch 4  | loss: 0.44483 | val_0_accuracy: 0.53367 |  0:00:03s\n","epoch 5  | loss: 0.44662 | val_0_accuracy: 0.5345  |  0:00:03s\n","epoch 6  | loss: 0.44349 | val_0_accuracy: 0.52951 |  0:00:04s\n","epoch 7  | loss: 0.43407 | val_0_accuracy: 0.56027 |  0:00:04s\n","epoch 8  | loss: 0.41879 | val_0_accuracy: 0.56442 |  0:00:05s\n","epoch 9  | loss: 0.40209 | val_0_accuracy: 0.6409  |  0:00:06s\n","epoch 10 | loss: 0.38687 | val_0_accuracy: 0.6542  |  0:00:06s\n","epoch 11 | loss: 0.39235 | val_0_accuracy: 0.67165 |  0:00:07s\n","epoch 12 | loss: 0.38198 | val_0_accuracy: 0.68828 |  0:00:08s\n","epoch 13 | loss: 0.37568 | val_0_accuracy: 0.7207  |  0:00:08s\n","epoch 14 | loss: 0.37383 | val_0_accuracy: 0.68994 |  0:00:09s\n","epoch 15 | loss: 0.37064 | val_0_accuracy: 0.70574 |  0:00:10s\n","epoch 16 | loss: 0.37029 | val_0_accuracy: 0.72984 |  0:00:10s\n","epoch 17 | loss: 0.37002 | val_0_accuracy: 0.71072 |  0:00:11s\n","epoch 18 | loss: 0.36646 | val_0_accuracy: 0.74231 |  0:00:11s\n","epoch 19 | loss: 0.37293 | val_0_accuracy: 0.74564 |  0:00:12s\n","epoch 20 | loss: 0.36709 | val_0_accuracy: 0.74564 |  0:00:13s\n","epoch 21 | loss: 0.36722 | val_0_accuracy: 0.74979 |  0:00:13s\n","epoch 22 | loss: 0.36466 | val_0_accuracy: 0.76559 |  0:00:14s\n","epoch 23 | loss: 0.36116 | val_0_accuracy: 0.76642 |  0:00:15s\n","epoch 24 | loss: 0.36388 | val_0_accuracy: 0.7714  |  0:00:15s\n","epoch 25 | loss: 0.36337 | val_0_accuracy: 0.78969 |  0:00:16s\n","epoch 26 | loss: 0.35638 | val_0_accuracy: 0.798   |  0:00:17s\n","epoch 27 | loss: 0.35538 | val_0_accuracy: 0.78304 |  0:00:17s\n","epoch 28 | loss: 0.36256 | val_0_accuracy: 0.81047 |  0:00:18s\n","epoch 29 | loss: 0.36042 | val_0_accuracy: 0.80715 |  0:00:18s\n","epoch 30 | loss: 0.35637 | val_0_accuracy: 0.81796 |  0:00:19s\n","epoch 31 | loss: 0.35301 | val_0_accuracy: 0.81546 |  0:00:20s\n","epoch 32 | loss: 0.35596 | val_0_accuracy: 0.83375 |  0:00:20s\n","epoch 33 | loss: 0.35189 | val_0_accuracy: 0.83375 |  0:00:21s\n","epoch 34 | loss: 0.34627 | val_0_accuracy: 0.82876 |  0:00:21s\n","epoch 35 | loss: 0.33807 | val_0_accuracy: 0.83874 |  0:00:22s\n","epoch 36 | loss: 0.34122 | val_0_accuracy: 0.84206 |  0:00:23s\n","epoch 37 | loss: 0.34108 | val_0_accuracy: 0.83624 |  0:00:23s\n","epoch 38 | loss: 0.34353 | val_0_accuracy: 0.83375 |  0:00:24s\n","epoch 39 | loss: 0.3424  | val_0_accuracy: 0.84123 |  0:00:25s\n","epoch 40 | loss: 0.34231 | val_0_accuracy: 0.84622 |  0:00:25s\n","epoch 41 | loss: 0.33718 | val_0_accuracy: 0.8404  |  0:00:26s\n","epoch 42 | loss: 0.33949 | val_0_accuracy: 0.8404  |  0:00:26s\n","epoch 43 | loss: 0.32964 | val_0_accuracy: 0.84622 |  0:00:27s\n","epoch 44 | loss: 0.3294  | val_0_accuracy: 0.84954 |  0:00:28s\n","epoch 45 | loss: 0.33896 | val_0_accuracy: 0.85037 |  0:00:28s\n","epoch 46 | loss: 0.33797 | val_0_accuracy: 0.84622 |  0:00:29s\n","epoch 47 | loss: 0.33256 | val_0_accuracy: 0.84456 |  0:00:30s\n","epoch 48 | loss: 0.33231 | val_0_accuracy: 0.84954 |  0:00:30s\n","epoch 49 | loss: 0.3303  | val_0_accuracy: 0.84788 |  0:00:31s\n","epoch 50 | loss: 0.32659 | val_0_accuracy: 0.85037 |  0:00:31s\n","epoch 51 | loss: 0.32681 | val_0_accuracy: 0.84539 |  0:00:32s\n","epoch 52 | loss: 0.32949 | val_0_accuracy: 0.84123 |  0:00:33s\n","epoch 53 | loss: 0.32822 | val_0_accuracy: 0.85121 |  0:00:33s\n","epoch 54 | loss: 0.32763 | val_0_accuracy: 0.85536 |  0:00:34s\n","epoch 55 | loss: 0.33133 | val_0_accuracy: 0.86118 |  0:00:34s\n","epoch 56 | loss: 0.33826 | val_0_accuracy: 0.83957 |  0:00:35s\n","epoch 57 | loss: 0.33816 | val_0_accuracy: 0.85786 |  0:00:36s\n","epoch 58 | loss: 0.33109 | val_0_accuracy: 0.85453 |  0:00:36s\n","epoch 59 | loss: 0.33301 | val_0_accuracy: 0.84954 |  0:00:37s\n","epoch 60 | loss: 0.334   | val_0_accuracy: 0.85037 |  0:00:38s\n","epoch 61 | loss: 0.3359  | val_0_accuracy: 0.85869 |  0:00:38s\n","epoch 62 | loss: 0.32607 | val_0_accuracy: 0.85702 |  0:00:39s\n","epoch 63 | loss: 0.32918 | val_0_accuracy: 0.84456 |  0:00:39s\n","epoch 64 | loss: 0.33429 | val_0_accuracy: 0.84289 |  0:00:40s\n","epoch 65 | loss: 0.33394 | val_0_accuracy: 0.84705 |  0:00:41s\n","\n","Early stopping occurred at epoch 65 with best_epoch = 55 and best_val_0_accuracy = 0.86118\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-07-06 06:12:40,367] Trial 43 finished with value: 0.8611803823773898 and parameters: {'n_d': 41, 'n_steps': 4, 'gamma': 1.5552165126344422, 'n_independent': 4, 'n_shared': 2, 'momentum': 0.10711149372828642}. Best is trial 42 with value: 0.8728179551122195.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 0.58326 | val_0_accuracy: 0.53948 |  0:00:00s\n","epoch 1  | loss: 0.47248 | val_0_accuracy: 0.51787 |  0:00:00s\n","epoch 2  | loss: 0.43429 | val_0_accuracy: 0.5187  |  0:00:01s\n","epoch 3  | loss: 0.41682 | val_0_accuracy: 0.52369 |  0:00:01s\n","epoch 4  | loss: 0.39566 | val_0_accuracy: 0.52868 |  0:00:02s\n","epoch 5  | loss: 0.38097 | val_0_accuracy: 0.52785 |  0:00:02s\n","epoch 6  | loss: 0.36892 | val_0_accuracy: 0.56027 |  0:00:03s\n","epoch 7  | loss: 0.36409 | val_0_accuracy: 0.57689 |  0:00:03s\n","epoch 8  | loss: 0.3595  | val_0_accuracy: 0.54613 |  0:00:04s\n","epoch 9  | loss: 0.35468 | val_0_accuracy: 0.57273 |  0:00:04s\n","epoch 10 | loss: 0.34691 | val_0_accuracy: 0.55528 |  0:00:05s\n","epoch 11 | loss: 0.34916 | val_0_accuracy: 0.57357 |  0:00:05s\n","epoch 12 | loss: 0.35147 | val_0_accuracy: 0.58853 |  0:00:05s\n","epoch 13 | loss: 0.34735 | val_0_accuracy: 0.60682 |  0:00:06s\n","epoch 14 | loss: 0.34701 | val_0_accuracy: 0.67581 |  0:00:06s\n","epoch 15 | loss: 0.35732 | val_0_accuracy: 0.62344 |  0:00:07s\n","epoch 16 | loss: 0.33918 | val_0_accuracy: 0.68246 |  0:00:07s\n","epoch 17 | loss: 0.33416 | val_0_accuracy: 0.68412 |  0:00:08s\n","epoch 18 | loss: 0.33456 | val_0_accuracy: 0.69244 |  0:00:08s\n","epoch 19 | loss: 0.33533 | val_0_accuracy: 0.73566 |  0:00:09s\n","epoch 20 | loss: 0.33247 | val_0_accuracy: 0.7473  |  0:00:09s\n","epoch 21 | loss: 0.32883 | val_0_accuracy: 0.75727 |  0:00:09s\n","epoch 22 | loss: 0.33534 | val_0_accuracy: 0.76891 |  0:00:10s\n","epoch 23 | loss: 0.338   | val_0_accuracy: 0.77972 |  0:00:10s\n","epoch 24 | loss: 0.33466 | val_0_accuracy: 0.7847  |  0:00:11s\n","epoch 25 | loss: 0.33283 | val_0_accuracy: 0.78221 |  0:00:11s\n","epoch 26 | loss: 0.32516 | val_0_accuracy: 0.78803 |  0:00:12s\n","epoch 27 | loss: 0.32508 | val_0_accuracy: 0.81047 |  0:00:12s\n","epoch 28 | loss: 0.33132 | val_0_accuracy: 0.84123 |  0:00:13s\n","epoch 29 | loss: 0.32797 | val_0_accuracy: 0.81214 |  0:00:13s\n","epoch 30 | loss: 0.32542 | val_0_accuracy: 0.8138  |  0:00:14s\n","epoch 31 | loss: 0.32432 | val_0_accuracy: 0.83874 |  0:00:14s\n","epoch 32 | loss: 0.32389 | val_0_accuracy: 0.82793 |  0:00:14s\n","epoch 33 | loss: 0.32052 | val_0_accuracy: 0.8404  |  0:00:15s\n","epoch 34 | loss: 0.32005 | val_0_accuracy: 0.84206 |  0:00:15s\n","epoch 35 | loss: 0.31719 | val_0_accuracy: 0.85204 |  0:00:16s\n","epoch 36 | loss: 0.32203 | val_0_accuracy: 0.84123 |  0:00:16s\n","epoch 37 | loss: 0.33119 | val_0_accuracy: 0.85204 |  0:00:17s\n","epoch 38 | loss: 0.32459 | val_0_accuracy: 0.84788 |  0:00:17s\n","epoch 39 | loss: 0.32496 | val_0_accuracy: 0.85869 |  0:00:17s\n","epoch 40 | loss: 0.3206  | val_0_accuracy: 0.84539 |  0:00:18s\n","epoch 41 | loss: 0.31139 | val_0_accuracy: 0.84871 |  0:00:18s\n","epoch 42 | loss: 0.31689 | val_0_accuracy: 0.8537  |  0:00:19s\n","epoch 43 | loss: 0.31327 | val_0_accuracy: 0.85619 |  0:00:19s\n","epoch 44 | loss: 0.3134  | val_0_accuracy: 0.85702 |  0:00:20s\n","epoch 45 | loss: 0.3099  | val_0_accuracy: 0.85952 |  0:00:20s\n","epoch 46 | loss: 0.3123  | val_0_accuracy: 0.85204 |  0:00:21s\n","epoch 47 | loss: 0.31228 | val_0_accuracy: 0.85952 |  0:00:21s\n","epoch 48 | loss: 0.31167 | val_0_accuracy: 0.85952 |  0:00:21s\n","epoch 49 | loss: 0.31002 | val_0_accuracy: 0.867   |  0:00:22s\n","epoch 50 | loss: 0.30629 | val_0_accuracy: 0.86451 |  0:00:22s\n","epoch 51 | loss: 0.30857 | val_0_accuracy: 0.86534 |  0:00:23s\n","epoch 52 | loss: 0.3031  | val_0_accuracy: 0.86534 |  0:00:23s\n","epoch 53 | loss: 0.30304 | val_0_accuracy: 0.86201 |  0:00:24s\n","epoch 54 | loss: 0.29987 | val_0_accuracy: 0.85619 |  0:00:24s\n","epoch 55 | loss: 0.30527 | val_0_accuracy: 0.86284 |  0:00:25s\n","epoch 56 | loss: 0.30023 | val_0_accuracy: 0.87199 |  0:00:25s\n","epoch 57 | loss: 0.30008 | val_0_accuracy: 0.86367 |  0:00:25s\n","epoch 58 | loss: 0.29918 | val_0_accuracy: 0.85037 |  0:00:26s\n","epoch 59 | loss: 0.29227 | val_0_accuracy: 0.86617 |  0:00:26s\n","epoch 60 | loss: 0.30221 | val_0_accuracy: 0.86284 |  0:00:27s\n","epoch 61 | loss: 0.29234 | val_0_accuracy: 0.86118 |  0:00:27s\n","epoch 62 | loss: 0.29673 | val_0_accuracy: 0.86284 |  0:00:28s\n","epoch 63 | loss: 0.29047 | val_0_accuracy: 0.86617 |  0:00:28s\n","epoch 64 | loss: 0.29106 | val_0_accuracy: 0.85786 |  0:00:29s\n","epoch 65 | loss: 0.29315 | val_0_accuracy: 0.86118 |  0:00:29s\n","epoch 66 | loss: 0.28845 | val_0_accuracy: 0.85037 |  0:00:29s\n","\n","Early stopping occurred at epoch 66 with best_epoch = 56 and best_val_0_accuracy = 0.87199\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-07-06 06:13:10,574] Trial 44 finished with value: 0.8719866999168745 and parameters: {'n_d': 32, 'n_steps': 3, 'gamma': 1.8073734093522194, 'n_independent': 3, 'n_shared': 2, 'momentum': 0.1353648514517179}. Best is trial 42 with value: 0.8728179551122195.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 0.6326  | val_0_accuracy: 0.55777 |  0:00:00s\n","epoch 1  | loss: 0.50539 | val_0_accuracy: 0.53533 |  0:00:01s\n","epoch 2  | loss: 0.46756 | val_0_accuracy: 0.52203 |  0:00:01s\n","epoch 3  | loss: 0.45271 | val_0_accuracy: 0.52037 |  0:00:01s\n","epoch 4  | loss: 0.43395 | val_0_accuracy: 0.53367 |  0:00:02s\n","epoch 5  | loss: 0.42313 | val_0_accuracy: 0.56608 |  0:00:02s\n","epoch 6  | loss: 0.41273 | val_0_accuracy: 0.65254 |  0:00:03s\n","epoch 7  | loss: 0.39454 | val_0_accuracy: 0.63009 |  0:00:03s\n","epoch 8  | loss: 0.38744 | val_0_accuracy: 0.63924 |  0:00:04s\n","epoch 9  | loss: 0.38053 | val_0_accuracy: 0.66251 |  0:00:04s\n","epoch 10 | loss: 0.3711  | val_0_accuracy: 0.64007 |  0:00:05s\n","epoch 11 | loss: 0.3716  | val_0_accuracy: 0.68246 |  0:00:05s\n","epoch 12 | loss: 0.36072 | val_0_accuracy: 0.69077 |  0:00:05s\n","epoch 13 | loss: 0.3587  | val_0_accuracy: 0.7074  |  0:00:06s\n","epoch 14 | loss: 0.35341 | val_0_accuracy: 0.66584 |  0:00:06s\n","epoch 15 | loss: 0.35898 | val_0_accuracy: 0.69742 |  0:00:07s\n","epoch 16 | loss: 0.34784 | val_0_accuracy: 0.67997 |  0:00:07s\n","epoch 17 | loss: 0.3522  | val_0_accuracy: 0.73067 |  0:00:08s\n","epoch 18 | loss: 0.34309 | val_0_accuracy: 0.72569 |  0:00:08s\n","epoch 19 | loss: 0.3407  | val_0_accuracy: 0.73732 |  0:00:09s\n","epoch 20 | loss: 0.34082 | val_0_accuracy: 0.74647 |  0:00:09s\n","epoch 21 | loss: 0.33898 | val_0_accuracy: 0.74231 |  0:00:09s\n","epoch 22 | loss: 0.33888 | val_0_accuracy: 0.75062 |  0:00:10s\n","epoch 23 | loss: 0.33422 | val_0_accuracy: 0.77224 |  0:00:10s\n","epoch 24 | loss: 0.33053 | val_0_accuracy: 0.75977 |  0:00:11s\n","epoch 25 | loss: 0.33054 | val_0_accuracy: 0.77722 |  0:00:11s\n","epoch 26 | loss: 0.3313  | val_0_accuracy: 0.7872  |  0:00:12s\n","epoch 27 | loss: 0.32724 | val_0_accuracy: 0.82461 |  0:00:12s\n","epoch 28 | loss: 0.32692 | val_0_accuracy: 0.82128 |  0:00:13s\n","epoch 29 | loss: 0.32198 | val_0_accuracy: 0.82627 |  0:00:13s\n","epoch 30 | loss: 0.32171 | val_0_accuracy: 0.82959 |  0:00:13s\n","epoch 31 | loss: 0.3282  | val_0_accuracy: 0.84539 |  0:00:14s\n","epoch 32 | loss: 0.3264  | val_0_accuracy: 0.83209 |  0:00:14s\n","epoch 33 | loss: 0.32678 | val_0_accuracy: 0.83541 |  0:00:15s\n","epoch 34 | loss: 0.32588 | val_0_accuracy: 0.84289 |  0:00:15s\n","epoch 35 | loss: 0.32544 | val_0_accuracy: 0.84788 |  0:00:16s\n","epoch 36 | loss: 0.32339 | val_0_accuracy: 0.84372 |  0:00:16s\n","epoch 37 | loss: 0.32146 | val_0_accuracy: 0.85287 |  0:00:17s\n","epoch 38 | loss: 0.32654 | val_0_accuracy: 0.85037 |  0:00:17s\n","epoch 39 | loss: 0.32709 | val_0_accuracy: 0.84705 |  0:00:17s\n","epoch 40 | loss: 0.32183 | val_0_accuracy: 0.83791 |  0:00:18s\n","epoch 41 | loss: 0.32702 | val_0_accuracy: 0.85121 |  0:00:18s\n","epoch 42 | loss: 0.3192  | val_0_accuracy: 0.85204 |  0:00:19s\n","epoch 43 | loss: 0.31619 | val_0_accuracy: 0.85536 |  0:00:19s\n","epoch 44 | loss: 0.31604 | val_0_accuracy: 0.85952 |  0:00:20s\n","epoch 45 | loss: 0.3189  | val_0_accuracy: 0.85536 |  0:00:20s\n","epoch 46 | loss: 0.31792 | val_0_accuracy: 0.85952 |  0:00:21s\n","epoch 47 | loss: 0.31186 | val_0_accuracy: 0.85702 |  0:00:21s\n","epoch 48 | loss: 0.31843 | val_0_accuracy: 0.84539 |  0:00:21s\n","epoch 49 | loss: 0.31642 | val_0_accuracy: 0.8537  |  0:00:22s\n","epoch 50 | loss: 0.3129  | val_0_accuracy: 0.85536 |  0:00:22s\n","epoch 51 | loss: 0.31732 | val_0_accuracy: 0.85121 |  0:00:23s\n","epoch 52 | loss: 0.3112  | val_0_accuracy: 0.85786 |  0:00:23s\n","epoch 53 | loss: 0.31182 | val_0_accuracy: 0.85702 |  0:00:24s\n","epoch 54 | loss: 0.30645 | val_0_accuracy: 0.86035 |  0:00:24s\n","epoch 55 | loss: 0.31898 | val_0_accuracy: 0.85204 |  0:00:25s\n","epoch 56 | loss: 0.31231 | val_0_accuracy: 0.85619 |  0:00:25s\n","epoch 57 | loss: 0.30814 | val_0_accuracy: 0.85037 |  0:00:25s\n","epoch 58 | loss: 0.3088  | val_0_accuracy: 0.85287 |  0:00:26s\n","epoch 59 | loss: 0.30796 | val_0_accuracy: 0.85786 |  0:00:26s\n","epoch 60 | loss: 0.31337 | val_0_accuracy: 0.85702 |  0:00:27s\n","epoch 61 | loss: 0.30536 | val_0_accuracy: 0.85786 |  0:00:27s\n","epoch 62 | loss: 0.3019  | val_0_accuracy: 0.85453 |  0:00:28s\n","epoch 63 | loss: 0.30231 | val_0_accuracy: 0.86118 |  0:00:28s\n","epoch 64 | loss: 0.30415 | val_0_accuracy: 0.84622 |  0:00:29s\n","epoch 65 | loss: 0.30222 | val_0_accuracy: 0.84788 |  0:00:29s\n","epoch 66 | loss: 0.30164 | val_0_accuracy: 0.86367 |  0:00:29s\n","epoch 67 | loss: 0.2985  | val_0_accuracy: 0.85453 |  0:00:30s\n","epoch 68 | loss: 0.29719 | val_0_accuracy: 0.85952 |  0:00:30s\n","epoch 69 | loss: 0.30375 | val_0_accuracy: 0.86118 |  0:00:31s\n","epoch 70 | loss: 0.29517 | val_0_accuracy: 0.85453 |  0:00:31s\n","epoch 71 | loss: 0.30352 | val_0_accuracy: 0.84954 |  0:00:32s\n","epoch 72 | loss: 0.30232 | val_0_accuracy: 0.85536 |  0:00:32s\n","epoch 73 | loss: 0.30325 | val_0_accuracy: 0.85536 |  0:00:33s\n","epoch 74 | loss: 0.29824 | val_0_accuracy: 0.84788 |  0:00:33s\n","epoch 75 | loss: 0.29894 | val_0_accuracy: 0.84289 |  0:00:34s\n","epoch 76 | loss: 0.3031  | val_0_accuracy: 0.85121 |  0:00:34s\n","\n","Early stopping occurred at epoch 76 with best_epoch = 66 and best_val_0_accuracy = 0.86367\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-07-06 06:13:45,318] Trial 45 finished with value: 0.8636741479634248 and parameters: {'n_d': 30, 'n_steps': 3, 'gamma': 1.8468948934641403, 'n_independent': 3, 'n_shared': 2, 'momentum': 0.13369163429143355}. Best is trial 42 with value: 0.8728179551122195.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 0.70577 | val_0_accuracy: 0.51787 |  0:00:00s\n","epoch 1  | loss: 0.48095 | val_0_accuracy: 0.52037 |  0:00:00s\n","epoch 2  | loss: 0.46559 | val_0_accuracy: 0.51787 |  0:00:00s\n","epoch 3  | loss: 0.4485  | val_0_accuracy: 0.52203 |  0:00:01s\n","epoch 4  | loss: 0.43259 | val_0_accuracy: 0.52868 |  0:00:01s\n","epoch 5  | loss: 0.42283 | val_0_accuracy: 0.52535 |  0:00:01s\n","epoch 6  | loss: 0.42402 | val_0_accuracy: 0.52618 |  0:00:02s\n","epoch 7  | loss: 0.40389 | val_0_accuracy: 0.5586  |  0:00:02s\n","epoch 8  | loss: 0.39265 | val_0_accuracy: 0.57107 |  0:00:02s\n","epoch 9  | loss: 0.38901 | val_0_accuracy: 0.56692 |  0:00:03s\n","epoch 10 | loss: 0.38644 | val_0_accuracy: 0.65087 |  0:00:03s\n","epoch 11 | loss: 0.37832 | val_0_accuracy: 0.67581 |  0:00:03s\n","epoch 12 | loss: 0.37281 | val_0_accuracy: 0.68994 |  0:00:04s\n","epoch 13 | loss: 0.3717  | val_0_accuracy: 0.69244 |  0:00:04s\n","epoch 14 | loss: 0.36724 | val_0_accuracy: 0.69493 |  0:00:04s\n","epoch 15 | loss: 0.36626 | val_0_accuracy: 0.72153 |  0:00:05s\n","epoch 16 | loss: 0.35852 | val_0_accuracy: 0.734   |  0:00:05s\n","epoch 17 | loss: 0.35352 | val_0_accuracy: 0.74397 |  0:00:05s\n","epoch 18 | loss: 0.35431 | val_0_accuracy: 0.74231 |  0:00:06s\n","epoch 19 | loss: 0.35739 | val_0_accuracy: 0.71987 |  0:00:06s\n","epoch 20 | loss: 0.3508  | val_0_accuracy: 0.74065 |  0:00:06s\n","epoch 21 | loss: 0.34629 | val_0_accuracy: 0.76226 |  0:00:07s\n","epoch 22 | loss: 0.34247 | val_0_accuracy: 0.73566 |  0:00:07s\n","epoch 23 | loss: 0.34555 | val_0_accuracy: 0.75561 |  0:00:07s\n","epoch 24 | loss: 0.34006 | val_0_accuracy: 0.75894 |  0:00:08s\n","epoch 25 | loss: 0.34169 | val_0_accuracy: 0.79634 |  0:00:08s\n","epoch 26 | loss: 0.33971 | val_0_accuracy: 0.77889 |  0:00:08s\n","epoch 27 | loss: 0.33206 | val_0_accuracy: 0.78554 |  0:00:09s\n","epoch 28 | loss: 0.33657 | val_0_accuracy: 0.79219 |  0:00:09s\n","epoch 29 | loss: 0.33313 | val_0_accuracy: 0.81879 |  0:00:09s\n","epoch 30 | loss: 0.33396 | val_0_accuracy: 0.82627 |  0:00:10s\n","epoch 31 | loss: 0.33452 | val_0_accuracy: 0.82793 |  0:00:10s\n","epoch 32 | loss: 0.33494 | val_0_accuracy: 0.80549 |  0:00:10s\n","epoch 33 | loss: 0.3385  | val_0_accuracy: 0.83957 |  0:00:11s\n","epoch 34 | loss: 0.33566 | val_0_accuracy: 0.83707 |  0:00:11s\n","epoch 35 | loss: 0.33606 | val_0_accuracy: 0.83957 |  0:00:11s\n","epoch 36 | loss: 0.33558 | val_0_accuracy: 0.84206 |  0:00:12s\n","epoch 37 | loss: 0.32858 | val_0_accuracy: 0.84954 |  0:00:12s\n","epoch 38 | loss: 0.3247  | val_0_accuracy: 0.85121 |  0:00:12s\n","epoch 39 | loss: 0.32619 | val_0_accuracy: 0.84788 |  0:00:13s\n","epoch 40 | loss: 0.32894 | val_0_accuracy: 0.84705 |  0:00:13s\n","epoch 41 | loss: 0.32624 | val_0_accuracy: 0.84372 |  0:00:13s\n","epoch 42 | loss: 0.32438 | val_0_accuracy: 0.84622 |  0:00:14s\n","epoch 43 | loss: 0.32608 | val_0_accuracy: 0.85536 |  0:00:14s\n","epoch 44 | loss: 0.3175  | val_0_accuracy: 0.84622 |  0:00:14s\n","epoch 45 | loss: 0.32338 | val_0_accuracy: 0.84456 |  0:00:15s\n","epoch 46 | loss: 0.3238  | val_0_accuracy: 0.84705 |  0:00:15s\n","epoch 47 | loss: 0.32317 | val_0_accuracy: 0.85037 |  0:00:15s\n","epoch 48 | loss: 0.3263  | val_0_accuracy: 0.84539 |  0:00:16s\n","epoch 49 | loss: 0.31972 | val_0_accuracy: 0.85204 |  0:00:16s\n","epoch 50 | loss: 0.31926 | val_0_accuracy: 0.85037 |  0:00:16s\n","epoch 51 | loss: 0.31443 | val_0_accuracy: 0.85037 |  0:00:17s\n","epoch 52 | loss: 0.32211 | val_0_accuracy: 0.85204 |  0:00:17s\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-07-06 06:14:03,222] Trial 46 finished with value: 0.8553615960099751 and parameters: {'n_d': 27, 'n_steps': 3, 'gamma': 1.9371600751982898, 'n_independent': 2, 'n_shared': 1, 'momentum': 0.17181295652186718}. Best is trial 42 with value: 0.8728179551122195.\n"]},{"output_type":"stream","name":"stdout","text":["epoch 53 | loss: 0.31794 | val_0_accuracy: 0.84788 |  0:00:17s\n","\n","Early stopping occurred at epoch 53 with best_epoch = 43 and best_val_0_accuracy = 0.85536\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 0.61725 | val_0_accuracy: 0.52785 |  0:00:00s\n","epoch 1  | loss: 0.47479 | val_0_accuracy: 0.51704 |  0:00:00s\n","epoch 2  | loss: 0.43829 | val_0_accuracy: 0.51372 |  0:00:01s\n","epoch 3  | loss: 0.40403 | val_0_accuracy: 0.52535 |  0:00:01s\n","epoch 4  | loss: 0.38414 | val_0_accuracy: 0.55112 |  0:00:02s\n","epoch 5  | loss: 0.38021 | val_0_accuracy: 0.55195 |  0:00:02s\n","epoch 6  | loss: 0.37181 | val_0_accuracy: 0.54946 |  0:00:03s\n","epoch 7  | loss: 0.36423 | val_0_accuracy: 0.53533 |  0:00:03s\n","epoch 8  | loss: 0.36067 | val_0_accuracy: 0.55445 |  0:00:04s\n","epoch 9  | loss: 0.3521  | val_0_accuracy: 0.56692 |  0:00:04s\n","epoch 10 | loss: 0.34548 | val_0_accuracy: 0.57273 |  0:00:05s\n","epoch 11 | loss: 0.34377 | val_0_accuracy: 0.58105 |  0:00:05s\n","epoch 12 | loss: 0.34224 | val_0_accuracy: 0.6808  |  0:00:05s\n","epoch 13 | loss: 0.33857 | val_0_accuracy: 0.61679 |  0:00:06s\n","epoch 14 | loss: 0.33862 | val_0_accuracy: 0.60349 |  0:00:06s\n","epoch 15 | loss: 0.34377 | val_0_accuracy: 0.65669 |  0:00:07s\n","epoch 16 | loss: 0.33893 | val_0_accuracy: 0.7049  |  0:00:07s\n","epoch 17 | loss: 0.3309  | val_0_accuracy: 0.66833 |  0:00:08s\n","epoch 18 | loss: 0.33531 | val_0_accuracy: 0.70158 |  0:00:08s\n","epoch 19 | loss: 0.33214 | val_0_accuracy: 0.73899 |  0:00:09s\n","epoch 20 | loss: 0.33095 | val_0_accuracy: 0.73899 |  0:00:09s\n","epoch 21 | loss: 0.33344 | val_0_accuracy: 0.76309 |  0:00:09s\n","epoch 22 | loss: 0.33541 | val_0_accuracy: 0.73483 |  0:00:10s\n","epoch 23 | loss: 0.32933 | val_0_accuracy: 0.78221 |  0:00:10s\n","epoch 24 | loss: 0.3359  | val_0_accuracy: 0.77224 |  0:00:11s\n","epoch 25 | loss: 0.33152 | val_0_accuracy: 0.78221 |  0:00:11s\n","epoch 26 | loss: 0.31642 | val_0_accuracy: 0.79302 |  0:00:12s\n","epoch 27 | loss: 0.32181 | val_0_accuracy: 0.80798 |  0:00:12s\n","epoch 28 | loss: 0.32876 | val_0_accuracy: 0.82627 |  0:00:13s\n","epoch 29 | loss: 0.32595 | val_0_accuracy: 0.81047 |  0:00:13s\n","epoch 30 | loss: 0.32627 | val_0_accuracy: 0.81214 |  0:00:14s\n","epoch 31 | loss: 0.31766 | val_0_accuracy: 0.81131 |  0:00:14s\n","epoch 32 | loss: 0.31858 | val_0_accuracy: 0.83042 |  0:00:14s\n","epoch 33 | loss: 0.31495 | val_0_accuracy: 0.82876 |  0:00:15s\n","epoch 34 | loss: 0.31994 | val_0_accuracy: 0.83624 |  0:00:15s\n","epoch 35 | loss: 0.31613 | val_0_accuracy: 0.84622 |  0:00:16s\n","epoch 36 | loss: 0.31596 | val_0_accuracy: 0.84788 |  0:00:16s\n","epoch 37 | loss: 0.31902 | val_0_accuracy: 0.84788 |  0:00:17s\n","epoch 38 | loss: 0.31915 | val_0_accuracy: 0.84456 |  0:00:17s\n","epoch 39 | loss: 0.31789 | val_0_accuracy: 0.84871 |  0:00:18s\n","epoch 40 | loss: 0.31504 | val_0_accuracy: 0.8537  |  0:00:18s\n","epoch 41 | loss: 0.3066  | val_0_accuracy: 0.84539 |  0:00:18s\n","epoch 42 | loss: 0.30986 | val_0_accuracy: 0.84954 |  0:00:19s\n","epoch 43 | loss: 0.30627 | val_0_accuracy: 0.86118 |  0:00:19s\n","epoch 44 | loss: 0.30379 | val_0_accuracy: 0.86118 |  0:00:20s\n","epoch 45 | loss: 0.30502 | val_0_accuracy: 0.86534 |  0:00:20s\n","epoch 46 | loss: 0.30303 | val_0_accuracy: 0.84788 |  0:00:21s\n","epoch 47 | loss: 0.30553 | val_0_accuracy: 0.86783 |  0:00:21s\n","epoch 48 | loss: 0.30474 | val_0_accuracy: 0.86284 |  0:00:22s\n","epoch 49 | loss: 0.30203 | val_0_accuracy: 0.86284 |  0:00:22s\n","epoch 50 | loss: 0.29745 | val_0_accuracy: 0.85453 |  0:00:22s\n","epoch 51 | loss: 0.29595 | val_0_accuracy: 0.86451 |  0:00:23s\n","epoch 52 | loss: 0.29287 | val_0_accuracy: 0.867   |  0:00:23s\n","epoch 53 | loss: 0.295   | val_0_accuracy: 0.85952 |  0:00:24s\n","epoch 54 | loss: 0.29264 | val_0_accuracy: 0.867   |  0:00:24s\n","epoch 55 | loss: 0.29281 | val_0_accuracy: 0.85952 |  0:00:25s\n","epoch 56 | loss: 0.29949 | val_0_accuracy: 0.86783 |  0:00:25s\n","epoch 57 | loss: 0.29632 | val_0_accuracy: 0.86617 |  0:00:25s\n","\n","Early stopping occurred at epoch 57 with best_epoch = 47 and best_val_0_accuracy = 0.86783\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-07-06 06:14:29,461] Trial 47 finished with value: 0.8678304239401496 and parameters: {'n_d': 32, 'n_steps': 3, 'gamma': 1.7432585589279628, 'n_independent': 3, 'n_shared': 2, 'momentum': 0.15004323592622526}. Best is trial 42 with value: 0.8728179551122195.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 0.93763 | val_0_accuracy: 0.51455 |  0:00:00s\n","epoch 1  | loss: 0.57751 | val_0_accuracy: 0.52452 |  0:00:01s\n","epoch 2  | loss: 0.48278 | val_0_accuracy: 0.57938 |  0:00:01s\n","epoch 3  | loss: 0.46952 | val_0_accuracy: 0.58022 |  0:00:02s\n","epoch 4  | loss: 0.46032 | val_0_accuracy: 0.63259 |  0:00:03s\n","epoch 5  | loss: 0.44873 | val_0_accuracy: 0.60349 |  0:00:03s\n","epoch 6  | loss: 0.4372  | val_0_accuracy: 0.65586 |  0:00:04s\n","epoch 7  | loss: 0.42161 | val_0_accuracy: 0.65835 |  0:00:04s\n","epoch 8  | loss: 0.41465 | val_0_accuracy: 0.6941  |  0:00:05s\n","epoch 9  | loss: 0.40147 | val_0_accuracy: 0.6783  |  0:00:06s\n","epoch 10 | loss: 0.40799 | val_0_accuracy: 0.66916 |  0:00:07s\n","epoch 11 | loss: 0.40179 | val_0_accuracy: 0.69327 |  0:00:07s\n","epoch 12 | loss: 0.39242 | val_0_accuracy: 0.69992 |  0:00:08s\n","epoch 13 | loss: 0.38526 | val_0_accuracy: 0.70158 |  0:00:08s\n","epoch 14 | loss: 0.38358 | val_0_accuracy: 0.72735 |  0:00:09s\n","epoch 15 | loss: 0.38544 | val_0_accuracy: 0.70241 |  0:00:10s\n","epoch 16 | loss: 0.38662 | val_0_accuracy: 0.74397 |  0:00:10s\n","epoch 17 | loss: 0.38325 | val_0_accuracy: 0.73815 |  0:00:11s\n","epoch 18 | loss: 0.37851 | val_0_accuracy: 0.74148 |  0:00:11s\n","epoch 19 | loss: 0.37093 | val_0_accuracy: 0.7581  |  0:00:12s\n","epoch 20 | loss: 0.37223 | val_0_accuracy: 0.75229 |  0:00:13s\n","epoch 21 | loss: 0.36775 | val_0_accuracy: 0.73649 |  0:00:13s\n","epoch 22 | loss: 0.37675 | val_0_accuracy: 0.78304 |  0:00:14s\n","epoch 23 | loss: 0.37237 | val_0_accuracy: 0.76974 |  0:00:15s\n","epoch 24 | loss: 0.37341 | val_0_accuracy: 0.78055 |  0:00:15s\n","epoch 25 | loss: 0.37173 | val_0_accuracy: 0.77473 |  0:00:16s\n","epoch 26 | loss: 0.36887 | val_0_accuracy: 0.79468 |  0:00:16s\n","epoch 27 | loss: 0.36698 | val_0_accuracy: 0.78554 |  0:00:17s\n","epoch 28 | loss: 0.35482 | val_0_accuracy: 0.80466 |  0:00:18s\n","epoch 29 | loss: 0.35191 | val_0_accuracy: 0.79717 |  0:00:18s\n","epoch 30 | loss: 0.35303 | val_0_accuracy: 0.79884 |  0:00:19s\n","epoch 31 | loss: 0.35791 | val_0_accuracy: 0.81297 |  0:00:20s\n","epoch 32 | loss: 0.35989 | val_0_accuracy: 0.82793 |  0:00:20s\n","epoch 33 | loss: 0.3539  | val_0_accuracy: 0.82377 |  0:00:21s\n","epoch 34 | loss: 0.35848 | val_0_accuracy: 0.83209 |  0:00:21s\n","epoch 35 | loss: 0.35492 | val_0_accuracy: 0.83624 |  0:00:22s\n","epoch 36 | loss: 0.35276 | val_0_accuracy: 0.83126 |  0:00:23s\n","epoch 37 | loss: 0.35041 | val_0_accuracy: 0.83126 |  0:00:23s\n","epoch 38 | loss: 0.35081 | val_0_accuracy: 0.84456 |  0:00:24s\n","epoch 39 | loss: 0.35476 | val_0_accuracy: 0.83458 |  0:00:24s\n","epoch 40 | loss: 0.35028 | val_0_accuracy: 0.84539 |  0:00:25s\n","epoch 41 | loss: 0.34319 | val_0_accuracy: 0.84123 |  0:00:26s\n","epoch 42 | loss: 0.34966 | val_0_accuracy: 0.83624 |  0:00:26s\n","epoch 43 | loss: 0.34612 | val_0_accuracy: 0.8271  |  0:00:27s\n","epoch 44 | loss: 0.34979 | val_0_accuracy: 0.84705 |  0:00:28s\n","epoch 45 | loss: 0.34946 | val_0_accuracy: 0.84539 |  0:00:28s\n","epoch 46 | loss: 0.34732 | val_0_accuracy: 0.85121 |  0:00:29s\n","epoch 47 | loss: 0.35722 | val_0_accuracy: 0.84871 |  0:00:30s\n","epoch 48 | loss: 0.35342 | val_0_accuracy: 0.85453 |  0:00:30s\n","epoch 49 | loss: 0.35217 | val_0_accuracy: 0.8537  |  0:00:31s\n","epoch 50 | loss: 0.35615 | val_0_accuracy: 0.84705 |  0:00:31s\n","epoch 51 | loss: 0.35095 | val_0_accuracy: 0.84206 |  0:00:32s\n","epoch 52 | loss: 0.34963 | val_0_accuracy: 0.84622 |  0:00:33s\n","epoch 53 | loss: 0.34385 | val_0_accuracy: 0.84622 |  0:00:33s\n","epoch 54 | loss: 0.34397 | val_0_accuracy: 0.85952 |  0:00:34s\n","epoch 55 | loss: 0.34001 | val_0_accuracy: 0.85786 |  0:00:34s\n","epoch 56 | loss: 0.33921 | val_0_accuracy: 0.86534 |  0:00:35s\n","epoch 57 | loss: 0.33749 | val_0_accuracy: 0.85453 |  0:00:36s\n","epoch 58 | loss: 0.33963 | val_0_accuracy: 0.84954 |  0:00:36s\n","epoch 59 | loss: 0.33827 | val_0_accuracy: 0.85121 |  0:00:37s\n","epoch 60 | loss: 0.33905 | val_0_accuracy: 0.85287 |  0:00:37s\n","epoch 61 | loss: 0.34425 | val_0_accuracy: 0.84622 |  0:00:38s\n","epoch 62 | loss: 0.33665 | val_0_accuracy: 0.84705 |  0:00:39s\n","epoch 63 | loss: 0.33194 | val_0_accuracy: 0.85287 |  0:00:39s\n","epoch 64 | loss: 0.33734 | val_0_accuracy: 0.85786 |  0:00:40s\n","epoch 65 | loss: 0.33271 | val_0_accuracy: 0.85702 |  0:00:41s\n","epoch 66 | loss: 0.33532 | val_0_accuracy: 0.85952 |  0:00:41s\n","\n","Early stopping occurred at epoch 66 with best_epoch = 56 and best_val_0_accuracy = 0.86534\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-07-06 06:15:11,500] Trial 48 finished with value: 0.8653366583541147 and parameters: {'n_d': 36, 'n_steps': 4, 'gamma': 1.8706300619731293, 'n_independent': 4, 'n_shared': 2, 'momentum': 0.1954102830953775}. Best is trial 42 with value: 0.8728179551122195.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 0.65736 | val_0_accuracy: 0.51288 |  0:00:00s\n","epoch 1  | loss: 0.48013 | val_0_accuracy: 0.51787 |  0:00:00s\n","epoch 2  | loss: 0.44549 | val_0_accuracy: 0.51787 |  0:00:01s\n","epoch 3  | loss: 0.43804 | val_0_accuracy: 0.51787 |  0:00:01s\n","epoch 4  | loss: 0.42508 | val_0_accuracy: 0.51704 |  0:00:01s\n","epoch 5  | loss: 0.41866 | val_0_accuracy: 0.51704 |  0:00:02s\n","epoch 6  | loss: 0.40971 | val_0_accuracy: 0.5187  |  0:00:02s\n","epoch 7  | loss: 0.40397 | val_0_accuracy: 0.52452 |  0:00:03s\n","epoch 8  | loss: 0.39441 | val_0_accuracy: 0.55777 |  0:00:03s\n","epoch 9  | loss: 0.38911 | val_0_accuracy: 0.55278 |  0:00:03s\n","epoch 10 | loss: 0.38569 | val_0_accuracy: 0.57024 |  0:00:04s\n","epoch 11 | loss: 0.3736  | val_0_accuracy: 0.55943 |  0:00:04s\n","epoch 12 | loss: 0.36799 | val_0_accuracy: 0.56692 |  0:00:05s\n","epoch 13 | loss: 0.35988 | val_0_accuracy: 0.60599 |  0:00:05s\n","epoch 14 | loss: 0.35858 | val_0_accuracy: 0.65669 |  0:00:05s\n","epoch 15 | loss: 0.35922 | val_0_accuracy: 0.66667 |  0:00:06s\n","epoch 16 | loss: 0.35254 | val_0_accuracy: 0.67581 |  0:00:06s\n","epoch 17 | loss: 0.35548 | val_0_accuracy: 0.74314 |  0:00:07s\n","epoch 18 | loss: 0.34882 | val_0_accuracy: 0.72901 |  0:00:07s\n","epoch 19 | loss: 0.35485 | val_0_accuracy: 0.73067 |  0:00:07s\n","epoch 20 | loss: 0.35009 | val_0_accuracy: 0.71737 |  0:00:08s\n","epoch 21 | loss: 0.34555 | val_0_accuracy: 0.72569 |  0:00:08s\n","epoch 22 | loss: 0.34284 | val_0_accuracy: 0.75312 |  0:00:09s\n","epoch 23 | loss: 0.34758 | val_0_accuracy: 0.77473 |  0:00:09s\n","epoch 24 | loss: 0.34797 | val_0_accuracy: 0.78221 |  0:00:09s\n","epoch 25 | loss: 0.33955 | val_0_accuracy: 0.7872  |  0:00:10s\n","epoch 26 | loss: 0.33673 | val_0_accuracy: 0.81214 |  0:00:10s\n","epoch 27 | loss: 0.33816 | val_0_accuracy: 0.79967 |  0:00:11s\n","epoch 28 | loss: 0.33513 | val_0_accuracy: 0.79468 |  0:00:11s\n","epoch 29 | loss: 0.32862 | val_0_accuracy: 0.81047 |  0:00:11s\n","epoch 30 | loss: 0.33283 | val_0_accuracy: 0.80216 |  0:00:12s\n","epoch 31 | loss: 0.33319 | val_0_accuracy: 0.81546 |  0:00:12s\n","epoch 32 | loss: 0.34168 | val_0_accuracy: 0.82544 |  0:00:12s\n","epoch 33 | loss: 0.3337  | val_0_accuracy: 0.83375 |  0:00:13s\n","epoch 34 | loss: 0.33998 | val_0_accuracy: 0.82876 |  0:00:13s\n","epoch 35 | loss: 0.33707 | val_0_accuracy: 0.84456 |  0:00:14s\n","epoch 36 | loss: 0.33526 | val_0_accuracy: 0.83375 |  0:00:14s\n","epoch 37 | loss: 0.33676 | val_0_accuracy: 0.84954 |  0:00:14s\n","epoch 38 | loss: 0.3325  | val_0_accuracy: 0.83707 |  0:00:15s\n","epoch 39 | loss: 0.33189 | val_0_accuracy: 0.84539 |  0:00:15s\n","epoch 40 | loss: 0.32904 | val_0_accuracy: 0.8537  |  0:00:16s\n","epoch 41 | loss: 0.33128 | val_0_accuracy: 0.84705 |  0:00:16s\n","epoch 42 | loss: 0.3343  | val_0_accuracy: 0.8537  |  0:00:16s\n","epoch 43 | loss: 0.33589 | val_0_accuracy: 0.84954 |  0:00:17s\n","epoch 44 | loss: 0.33325 | val_0_accuracy: 0.85287 |  0:00:17s\n","epoch 45 | loss: 0.32837 | val_0_accuracy: 0.85453 |  0:00:17s\n","epoch 46 | loss: 0.33176 | val_0_accuracy: 0.8537  |  0:00:18s\n","epoch 47 | loss: 0.32381 | val_0_accuracy: 0.85702 |  0:00:18s\n","epoch 48 | loss: 0.32749 | val_0_accuracy: 0.86035 |  0:00:19s\n","epoch 49 | loss: 0.3248  | val_0_accuracy: 0.85786 |  0:00:19s\n","epoch 50 | loss: 0.32564 | val_0_accuracy: 0.85453 |  0:00:19s\n","epoch 51 | loss: 0.32176 | val_0_accuracy: 0.85952 |  0:00:20s\n","epoch 52 | loss: 0.33625 | val_0_accuracy: 0.83624 |  0:00:20s\n","epoch 53 | loss: 0.34693 | val_0_accuracy: 0.85702 |  0:00:21s\n","epoch 54 | loss: 0.33512 | val_0_accuracy: 0.85121 |  0:00:21s\n","epoch 55 | loss: 0.32583 | val_0_accuracy: 0.8537  |  0:00:21s\n","epoch 56 | loss: 0.3359  | val_0_accuracy: 0.84954 |  0:00:22s\n","epoch 57 | loss: 0.33266 | val_0_accuracy: 0.84622 |  0:00:22s\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-07-06 06:15:34,730] Trial 49 finished with value: 0.8603491271820449 and parameters: {'n_d': 27, 'n_steps': 3, 'gamma': 1.9984551564675725, 'n_independent': 3, 'n_shared': 1, 'momentum': 0.1780822234225706}. Best is trial 42 with value: 0.8728179551122195.\n"]},{"output_type":"stream","name":"stdout","text":["epoch 58 | loss: 0.33771 | val_0_accuracy: 0.8537  |  0:00:22s\n","\n","Early stopping occurred at epoch 58 with best_epoch = 48 and best_val_0_accuracy = 0.86035\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 0.75613 | val_0_accuracy: 0.49543 |  0:00:00s\n","epoch 1  | loss: 0.53264 | val_0_accuracy: 0.53117 |  0:00:01s\n","epoch 2  | loss: 0.47875 | val_0_accuracy: 0.61679 |  0:00:02s\n","epoch 3  | loss: 0.4667  | val_0_accuracy: 0.58853 |  0:00:02s\n","epoch 4  | loss: 0.45156 | val_0_accuracy: 0.60848 |  0:00:03s\n","epoch 5  | loss: 0.43235 | val_0_accuracy: 0.6276  |  0:00:04s\n","epoch 6  | loss: 0.42984 | val_0_accuracy: 0.62095 |  0:00:04s\n","epoch 7  | loss: 0.41991 | val_0_accuracy: 0.66334 |  0:00:05s\n","epoch 8  | loss: 0.41374 | val_0_accuracy: 0.53117 |  0:00:06s\n","epoch 9  | loss: 0.40777 | val_0_accuracy: 0.54613 |  0:00:06s\n","epoch 10 | loss: 0.39798 | val_0_accuracy: 0.5985  |  0:00:07s\n","epoch 11 | loss: 0.38767 | val_0_accuracy: 0.57606 |  0:00:08s\n","epoch 12 | loss: 0.38593 | val_0_accuracy: 0.56359 |  0:00:09s\n","epoch 13 | loss: 0.38515 | val_0_accuracy: 0.53367 |  0:00:09s\n","epoch 14 | loss: 0.3761  | val_0_accuracy: 0.61845 |  0:00:10s\n","epoch 15 | loss: 0.37606 | val_0_accuracy: 0.61513 |  0:00:11s\n","epoch 16 | loss: 0.37301 | val_0_accuracy: 0.62594 |  0:00:11s\n","epoch 17 | loss: 0.36475 | val_0_accuracy: 0.64921 |  0:00:12s\n","\n","Early stopping occurred at epoch 17 with best_epoch = 7 and best_val_0_accuracy = 0.66334\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-07-06 06:15:47,703] Trial 50 finished with value: 0.6633416458852868 and parameters: {'n_d': 38, 'n_steps': 4, 'gamma': 1.603997024780408, 'n_independent': 4, 'n_shared': 3, 'momentum': 0.1319507312483605}. Best is trial 42 with value: 0.8728179551122195.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 1.43303 | val_0_accuracy: 0.55362 |  0:00:01s\n","epoch 1  | loss: 0.79591 | val_0_accuracy: 0.52868 |  0:00:02s\n","epoch 2  | loss: 0.83591 | val_0_accuracy: 0.60017 |  0:00:03s\n","epoch 3  | loss: 0.58879 | val_0_accuracy: 0.5345  |  0:00:05s\n","epoch 4  | loss: 0.54774 | val_0_accuracy: 0.68579 |  0:00:06s\n","epoch 5  | loss: 0.54716 | val_0_accuracy: 0.66168 |  0:00:07s\n","epoch 6  | loss: 0.45519 | val_0_accuracy: 0.57938 |  0:00:09s\n","epoch 7  | loss: 0.44613 | val_0_accuracy: 0.61347 |  0:00:10s\n","epoch 8  | loss: 0.46138 | val_0_accuracy: 0.61929 |  0:00:11s\n","epoch 9  | loss: 0.46018 | val_0_accuracy: 0.67581 |  0:00:13s\n","epoch 10 | loss: 0.45379 | val_0_accuracy: 0.66334 |  0:00:14s\n","epoch 11 | loss: 0.42669 | val_0_accuracy: 0.71155 |  0:00:15s\n","epoch 12 | loss: 0.4368  | val_0_accuracy: 0.73982 |  0:00:16s\n","epoch 13 | loss: 0.43483 | val_0_accuracy: 0.72153 |  0:00:18s\n","epoch 14 | loss: 0.4273  | val_0_accuracy: 0.73566 |  0:00:19s\n","epoch 15 | loss: 0.42997 | val_0_accuracy: 0.74979 |  0:00:20s\n","epoch 16 | loss: 0.436   | val_0_accuracy: 0.74647 |  0:00:22s\n","epoch 17 | loss: 0.41581 | val_0_accuracy: 0.71987 |  0:00:23s\n","epoch 18 | loss: 0.43346 | val_0_accuracy: 0.75894 |  0:00:24s\n","epoch 19 | loss: 0.42423 | val_0_accuracy: 0.71488 |  0:00:26s\n","epoch 20 | loss: 0.40837 | val_0_accuracy: 0.75478 |  0:00:27s\n","epoch 21 | loss: 0.40859 | val_0_accuracy: 0.72984 |  0:00:28s\n","epoch 22 | loss: 0.40912 | val_0_accuracy: 0.7448  |  0:00:29s\n","epoch 23 | loss: 0.40205 | val_0_accuracy: 0.76974 |  0:00:31s\n","epoch 24 | loss: 0.40366 | val_0_accuracy: 0.74647 |  0:00:32s\n","epoch 25 | loss: 0.40401 | val_0_accuracy: 0.75977 |  0:00:33s\n","epoch 26 | loss: 0.39681 | val_0_accuracy: 0.79967 |  0:00:35s\n","epoch 27 | loss: 0.39874 | val_0_accuracy: 0.79634 |  0:00:36s\n","epoch 28 | loss: 0.39768 | val_0_accuracy: 0.79219 |  0:00:37s\n","epoch 29 | loss: 0.40289 | val_0_accuracy: 0.77972 |  0:00:38s\n","epoch 30 | loss: 0.40506 | val_0_accuracy: 0.79634 |  0:00:40s\n","epoch 31 | loss: 0.40785 | val_0_accuracy: 0.83126 |  0:00:41s\n","epoch 32 | loss: 0.42715 | val_0_accuracy: 0.81297 |  0:00:43s\n","epoch 33 | loss: 0.45374 | val_0_accuracy: 0.81629 |  0:00:44s\n","epoch 34 | loss: 0.41526 | val_0_accuracy: 0.81796 |  0:00:45s\n","epoch 35 | loss: 0.39888 | val_0_accuracy: 0.79967 |  0:00:46s\n","epoch 36 | loss: 0.39408 | val_0_accuracy: 0.80715 |  0:00:48s\n","epoch 37 | loss: 0.38986 | val_0_accuracy: 0.81546 |  0:00:49s\n","epoch 38 | loss: 0.39572 | val_0_accuracy: 0.82876 |  0:00:50s\n","epoch 39 | loss: 0.40243 | val_0_accuracy: 0.82627 |  0:00:52s\n","epoch 40 | loss: 0.39644 | val_0_accuracy: 0.83624 |  0:00:53s\n","epoch 41 | loss: 0.39401 | val_0_accuracy: 0.83209 |  0:00:54s\n","epoch 42 | loss: 0.38188 | val_0_accuracy: 0.81879 |  0:00:56s\n","epoch 43 | loss: 0.38498 | val_0_accuracy: 0.81629 |  0:00:57s\n","epoch 44 | loss: 0.3962  | val_0_accuracy: 0.81131 |  0:00:58s\n","epoch 45 | loss: 0.3963  | val_0_accuracy: 0.82544 |  0:00:59s\n","epoch 46 | loss: 0.39607 | val_0_accuracy: 0.83209 |  0:01:01s\n","epoch 47 | loss: 0.39196 | val_0_accuracy: 0.83042 |  0:01:02s\n","epoch 48 | loss: 0.37562 | val_0_accuracy: 0.82793 |  0:01:03s\n","epoch 49 | loss: 0.3809  | val_0_accuracy: 0.83209 |  0:01:05s\n","epoch 50 | loss: 0.37283 | val_0_accuracy: 0.82876 |  0:01:06s\n","\n","Early stopping occurred at epoch 50 with best_epoch = 40 and best_val_0_accuracy = 0.83624\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-07-06 06:16:54,854] Trial 51 finished with value: 0.8362427265170407 and parameters: {'n_d': 52, 'n_steps': 10, 'gamma': 1.2921322828257322, 'n_independent': 4, 'n_shared': 2, 'momentum': 0.10114114103534072}. Best is trial 42 with value: 0.8728179551122195.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 0.6771  | val_0_accuracy: 0.58603 |  0:00:00s\n","epoch 1  | loss: 0.46459 | val_0_accuracy: 0.5985  |  0:00:00s\n","epoch 2  | loss: 0.43573 | val_0_accuracy: 0.55362 |  0:00:00s\n","epoch 3  | loss: 0.42175 | val_0_accuracy: 0.53117 |  0:00:01s\n","epoch 4  | loss: 0.40609 | val_0_accuracy: 0.52618 |  0:00:01s\n","epoch 5  | loss: 0.4022  | val_0_accuracy: 0.53699 |  0:00:01s\n","epoch 6  | loss: 0.39878 | val_0_accuracy: 0.56608 |  0:00:02s\n","epoch 7  | loss: 0.3932  | val_0_accuracy: 0.60432 |  0:00:02s\n","epoch 8  | loss: 0.38922 | val_0_accuracy: 0.5852  |  0:00:02s\n","epoch 9  | loss: 0.38812 | val_0_accuracy: 0.63259 |  0:00:03s\n","epoch 10 | loss: 0.38059 | val_0_accuracy: 0.62594 |  0:00:03s\n","epoch 11 | loss: 0.3815  | val_0_accuracy: 0.58936 |  0:00:03s\n","epoch 12 | loss: 0.38217 | val_0_accuracy: 0.62012 |  0:00:04s\n","epoch 13 | loss: 0.3778  | val_0_accuracy: 0.63674 |  0:00:04s\n","epoch 14 | loss: 0.37296 | val_0_accuracy: 0.66334 |  0:00:04s\n","epoch 15 | loss: 0.3677  | val_0_accuracy: 0.6384  |  0:00:05s\n","epoch 16 | loss: 0.36584 | val_0_accuracy: 0.66334 |  0:00:05s\n","epoch 17 | loss: 0.36672 | val_0_accuracy: 0.73899 |  0:00:05s\n","epoch 18 | loss: 0.36537 | val_0_accuracy: 0.75062 |  0:00:06s\n","epoch 19 | loss: 0.36461 | val_0_accuracy: 0.69742 |  0:00:06s\n","epoch 20 | loss: 0.3587  | val_0_accuracy: 0.75644 |  0:00:06s\n","epoch 21 | loss: 0.35879 | val_0_accuracy: 0.72153 |  0:00:07s\n","epoch 22 | loss: 0.35116 | val_0_accuracy: 0.76725 |  0:00:07s\n","epoch 23 | loss: 0.34219 | val_0_accuracy: 0.7473  |  0:00:07s\n","epoch 24 | loss: 0.34663 | val_0_accuracy: 0.76725 |  0:00:08s\n","epoch 25 | loss: 0.35653 | val_0_accuracy: 0.77307 |  0:00:08s\n","epoch 26 | loss: 0.34788 | val_0_accuracy: 0.77722 |  0:00:08s\n","epoch 27 | loss: 0.34486 | val_0_accuracy: 0.81047 |  0:00:09s\n","epoch 28 | loss: 0.34456 | val_0_accuracy: 0.79967 |  0:00:09s\n","epoch 29 | loss: 0.34083 | val_0_accuracy: 0.76891 |  0:00:09s\n","epoch 30 | loss: 0.34444 | val_0_accuracy: 0.80466 |  0:00:10s\n","epoch 31 | loss: 0.33755 | val_0_accuracy: 0.83209 |  0:00:10s\n","epoch 32 | loss: 0.33459 | val_0_accuracy: 0.82876 |  0:00:10s\n","epoch 33 | loss: 0.3334  | val_0_accuracy: 0.83209 |  0:00:11s\n","epoch 34 | loss: 0.33266 | val_0_accuracy: 0.83541 |  0:00:11s\n","epoch 35 | loss: 0.33877 | val_0_accuracy: 0.8404  |  0:00:11s\n","epoch 36 | loss: 0.33223 | val_0_accuracy: 0.84622 |  0:00:12s\n","epoch 37 | loss: 0.33568 | val_0_accuracy: 0.84206 |  0:00:12s\n","epoch 38 | loss: 0.33084 | val_0_accuracy: 0.84788 |  0:00:12s\n","epoch 39 | loss: 0.3371  | val_0_accuracy: 0.84289 |  0:00:13s\n","epoch 40 | loss: 0.33185 | val_0_accuracy: 0.84954 |  0:00:13s\n","epoch 41 | loss: 0.33264 | val_0_accuracy: 0.84539 |  0:00:13s\n","epoch 42 | loss: 0.32841 | val_0_accuracy: 0.85453 |  0:00:14s\n","epoch 43 | loss: 0.32602 | val_0_accuracy: 0.85619 |  0:00:14s\n","epoch 44 | loss: 0.32594 | val_0_accuracy: 0.85204 |  0:00:14s\n","epoch 45 | loss: 0.32194 | val_0_accuracy: 0.85536 |  0:00:15s\n","epoch 46 | loss: 0.32205 | val_0_accuracy: 0.84788 |  0:00:15s\n","epoch 47 | loss: 0.32    | val_0_accuracy: 0.86284 |  0:00:15s\n","epoch 48 | loss: 0.32208 | val_0_accuracy: 0.85121 |  0:00:16s\n","epoch 49 | loss: 0.31856 | val_0_accuracy: 0.85453 |  0:00:16s\n","epoch 50 | loss: 0.32903 | val_0_accuracy: 0.85536 |  0:00:16s\n","epoch 51 | loss: 0.32021 | val_0_accuracy: 0.85536 |  0:00:17s\n","epoch 52 | loss: 0.31744 | val_0_accuracy: 0.85702 |  0:00:17s\n","epoch 53 | loss: 0.31627 | val_0_accuracy: 0.85287 |  0:00:17s\n","epoch 54 | loss: 0.31394 | val_0_accuracy: 0.85786 |  0:00:18s\n","epoch 55 | loss: 0.31417 | val_0_accuracy: 0.85453 |  0:00:18s\n","epoch 56 | loss: 0.31516 | val_0_accuracy: 0.86118 |  0:00:18s\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-07-06 06:17:14,266] Trial 52 finished with value: 0.8628428927680798 and parameters: {'n_d': 34, 'n_steps': 3, 'gamma': 1.8004395410347045, 'n_independent': 1, 'n_shared': 2, 'momentum': 0.07247588797740151}. Best is trial 42 with value: 0.8728179551122195.\n"]},{"output_type":"stream","name":"stdout","text":["epoch 57 | loss: 0.31313 | val_0_accuracy: 0.85702 |  0:00:19s\n","\n","Early stopping occurred at epoch 57 with best_epoch = 47 and best_val_0_accuracy = 0.86284\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 0.8601  | val_0_accuracy: 0.61596 |  0:00:00s\n","epoch 1  | loss: 0.58408 | val_0_accuracy: 0.53616 |  0:00:01s\n","epoch 2  | loss: 0.48745 | val_0_accuracy: 0.54613 |  0:00:02s\n","epoch 3  | loss: 0.45247 | val_0_accuracy: 0.6409  |  0:00:02s\n","epoch 4  | loss: 0.43955 | val_0_accuracy: 0.56027 |  0:00:03s\n","epoch 5  | loss: 0.42959 | val_0_accuracy: 0.57855 |  0:00:04s\n","epoch 6  | loss: 0.41915 | val_0_accuracy: 0.60183 |  0:00:05s\n","epoch 7  | loss: 0.40852 | val_0_accuracy: 0.6517  |  0:00:05s\n","epoch 8  | loss: 0.40078 | val_0_accuracy: 0.65337 |  0:00:06s\n","epoch 9  | loss: 0.3997  | val_0_accuracy: 0.62926 |  0:00:07s\n","epoch 10 | loss: 0.3968  | val_0_accuracy: 0.66334 |  0:00:08s\n","epoch 11 | loss: 0.39564 | val_0_accuracy: 0.70075 |  0:00:08s\n","epoch 12 | loss: 0.38264 | val_0_accuracy: 0.71654 |  0:00:09s\n","epoch 13 | loss: 0.38075 | val_0_accuracy: 0.7074  |  0:00:10s\n","epoch 14 | loss: 0.38118 | val_0_accuracy: 0.68329 |  0:00:10s\n","epoch 15 | loss: 0.39245 | val_0_accuracy: 0.73067 |  0:00:11s\n","epoch 16 | loss: 0.38221 | val_0_accuracy: 0.70906 |  0:00:12s\n","epoch 17 | loss: 0.37777 | val_0_accuracy: 0.68329 |  0:00:13s\n","epoch 18 | loss: 0.38197 | val_0_accuracy: 0.75062 |  0:00:13s\n","epoch 19 | loss: 0.38706 | val_0_accuracy: 0.70324 |  0:00:14s\n","epoch 20 | loss: 0.37392 | val_0_accuracy: 0.71571 |  0:00:15s\n","epoch 21 | loss: 0.36504 | val_0_accuracy: 0.67498 |  0:00:16s\n","epoch 22 | loss: 0.36491 | val_0_accuracy: 0.75561 |  0:00:16s\n","epoch 23 | loss: 0.36918 | val_0_accuracy: 0.72236 |  0:00:17s\n","epoch 24 | loss: 0.3751  | val_0_accuracy: 0.7581  |  0:00:18s\n","epoch 25 | loss: 0.36692 | val_0_accuracy: 0.76475 |  0:00:19s\n","epoch 26 | loss: 0.3647  | val_0_accuracy: 0.79135 |  0:00:19s\n","epoch 27 | loss: 0.35606 | val_0_accuracy: 0.81214 |  0:00:20s\n","epoch 28 | loss: 0.36024 | val_0_accuracy: 0.7739  |  0:00:21s\n","epoch 29 | loss: 0.35777 | val_0_accuracy: 0.8005  |  0:00:21s\n","epoch 30 | loss: 0.35519 | val_0_accuracy: 0.80466 |  0:00:22s\n","epoch 31 | loss: 0.35679 | val_0_accuracy: 0.81047 |  0:00:23s\n","epoch 32 | loss: 0.36058 | val_0_accuracy: 0.81629 |  0:00:24s\n","epoch 33 | loss: 0.35375 | val_0_accuracy: 0.8271  |  0:00:24s\n","epoch 34 | loss: 0.35358 | val_0_accuracy: 0.83624 |  0:00:25s\n","epoch 35 | loss: 0.35578 | val_0_accuracy: 0.83042 |  0:00:26s\n","epoch 36 | loss: 0.35676 | val_0_accuracy: 0.83209 |  0:00:27s\n","epoch 37 | loss: 0.34985 | val_0_accuracy: 0.8404  |  0:00:27s\n","epoch 38 | loss: 0.35378 | val_0_accuracy: 0.83874 |  0:00:28s\n","epoch 39 | loss: 0.35115 | val_0_accuracy: 0.8404  |  0:00:29s\n","epoch 40 | loss: 0.35641 | val_0_accuracy: 0.83624 |  0:00:30s\n","epoch 41 | loss: 0.3525  | val_0_accuracy: 0.84289 |  0:00:30s\n","epoch 42 | loss: 0.35508 | val_0_accuracy: 0.83791 |  0:00:31s\n","epoch 43 | loss: 0.35334 | val_0_accuracy: 0.83707 |  0:00:32s\n","epoch 44 | loss: 0.35789 | val_0_accuracy: 0.83624 |  0:00:33s\n","epoch 45 | loss: 0.35192 | val_0_accuracy: 0.83209 |  0:00:33s\n","epoch 46 | loss: 0.35061 | val_0_accuracy: 0.84539 |  0:00:34s\n","epoch 47 | loss: 0.34982 | val_0_accuracy: 0.83874 |  0:00:35s\n","epoch 48 | loss: 0.35171 | val_0_accuracy: 0.84954 |  0:00:36s\n","epoch 49 | loss: 0.34704 | val_0_accuracy: 0.85287 |  0:00:36s\n","epoch 50 | loss: 0.34858 | val_0_accuracy: 0.84954 |  0:00:37s\n","epoch 51 | loss: 0.34602 | val_0_accuracy: 0.84456 |  0:00:38s\n","epoch 52 | loss: 0.34882 | val_0_accuracy: 0.8537  |  0:00:38s\n","epoch 53 | loss: 0.34335 | val_0_accuracy: 0.85702 |  0:00:39s\n","epoch 54 | loss: 0.33984 | val_0_accuracy: 0.85287 |  0:00:40s\n","epoch 55 | loss: 0.33562 | val_0_accuracy: 0.84954 |  0:00:41s\n","epoch 56 | loss: 0.34263 | val_0_accuracy: 0.84871 |  0:00:41s\n","epoch 57 | loss: 0.3377  | val_0_accuracy: 0.84456 |  0:00:42s\n","epoch 58 | loss: 0.34057 | val_0_accuracy: 0.85037 |  0:00:43s\n","epoch 59 | loss: 0.33862 | val_0_accuracy: 0.85619 |  0:00:43s\n","epoch 60 | loss: 0.33946 | val_0_accuracy: 0.85037 |  0:00:44s\n","epoch 61 | loss: 0.33807 | val_0_accuracy: 0.85536 |  0:00:45s\n","epoch 62 | loss: 0.33897 | val_0_accuracy: 0.84954 |  0:00:46s\n","epoch 63 | loss: 0.33786 | val_0_accuracy: 0.85121 |  0:00:46s\n","\n","Early stopping occurred at epoch 63 with best_epoch = 53 and best_val_0_accuracy = 0.85702\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-07-06 06:18:01,542] Trial 53 finished with value: 0.857024106400665 and parameters: {'n_d': 49, 'n_steps': 5, 'gamma': 1.3867931493136785, 'n_independent': 4, 'n_shared': 2, 'momentum': 0.12532036015525838}. Best is trial 42 with value: 0.8728179551122195.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 0.66457 | val_0_accuracy: 0.51455 |  0:00:00s\n","epoch 1  | loss: 0.50719 | val_0_accuracy: 0.51455 |  0:00:01s\n","epoch 2  | loss: 0.46673 | val_0_accuracy: 0.53948 |  0:00:01s\n","epoch 3  | loss: 0.44214 | val_0_accuracy: 0.53865 |  0:00:02s\n","epoch 4  | loss: 0.42091 | val_0_accuracy: 0.53616 |  0:00:02s\n","epoch 5  | loss: 0.41844 | val_0_accuracy: 0.5852  |  0:00:03s\n","epoch 6  | loss: 0.40613 | val_0_accuracy: 0.56442 |  0:00:03s\n","epoch 7  | loss: 0.39844 | val_0_accuracy: 0.61762 |  0:00:04s\n","epoch 8  | loss: 0.39391 | val_0_accuracy: 0.6542  |  0:00:04s\n","epoch 9  | loss: 0.38401 | val_0_accuracy: 0.67249 |  0:00:05s\n","epoch 10 | loss: 0.40147 | val_0_accuracy: 0.65337 |  0:00:06s\n","epoch 11 | loss: 0.39065 | val_0_accuracy: 0.66833 |  0:00:06s\n","epoch 12 | loss: 0.39348 | val_0_accuracy: 0.67415 |  0:00:07s\n","epoch 13 | loss: 0.38157 | val_0_accuracy: 0.6941  |  0:00:07s\n","epoch 14 | loss: 0.37214 | val_0_accuracy: 0.734   |  0:00:08s\n","epoch 15 | loss: 0.36307 | val_0_accuracy: 0.71654 |  0:00:08s\n","epoch 16 | loss: 0.36217 | val_0_accuracy: 0.68828 |  0:00:09s\n","epoch 17 | loss: 0.36159 | val_0_accuracy: 0.71155 |  0:00:10s\n","epoch 18 | loss: 0.36487 | val_0_accuracy: 0.73067 |  0:00:10s\n","epoch 19 | loss: 0.36187 | val_0_accuracy: 0.69909 |  0:00:11s\n","epoch 20 | loss: 0.36313 | val_0_accuracy: 0.72153 |  0:00:11s\n","epoch 21 | loss: 0.35714 | val_0_accuracy: 0.7606  |  0:00:12s\n","epoch 22 | loss: 0.35291 | val_0_accuracy: 0.76725 |  0:00:12s\n","epoch 23 | loss: 0.35061 | val_0_accuracy: 0.74979 |  0:00:13s\n","epoch 24 | loss: 0.34726 | val_0_accuracy: 0.76808 |  0:00:13s\n","epoch 25 | loss: 0.34549 | val_0_accuracy: 0.77722 |  0:00:14s\n","epoch 26 | loss: 0.34265 | val_0_accuracy: 0.8005  |  0:00:15s\n","epoch 27 | loss: 0.34295 | val_0_accuracy: 0.76475 |  0:00:15s\n","epoch 28 | loss: 0.33856 | val_0_accuracy: 0.79884 |  0:00:16s\n","epoch 29 | loss: 0.33654 | val_0_accuracy: 0.80798 |  0:00:16s\n","epoch 30 | loss: 0.3311  | val_0_accuracy: 0.81712 |  0:00:17s\n","epoch 31 | loss: 0.33044 | val_0_accuracy: 0.81297 |  0:00:17s\n","epoch 32 | loss: 0.33146 | val_0_accuracy: 0.81131 |  0:00:18s\n","epoch 33 | loss: 0.33759 | val_0_accuracy: 0.84289 |  0:00:18s\n","epoch 34 | loss: 0.32917 | val_0_accuracy: 0.84372 |  0:00:19s\n","epoch 35 | loss: 0.32359 | val_0_accuracy: 0.83957 |  0:00:20s\n","epoch 36 | loss: 0.32064 | val_0_accuracy: 0.84206 |  0:00:20s\n","epoch 37 | loss: 0.31992 | val_0_accuracy: 0.84705 |  0:00:21s\n","epoch 38 | loss: 0.32172 | val_0_accuracy: 0.83707 |  0:00:21s\n","epoch 39 | loss: 0.3198  | val_0_accuracy: 0.85121 |  0:00:22s\n","epoch 40 | loss: 0.31819 | val_0_accuracy: 0.84705 |  0:00:22s\n","epoch 41 | loss: 0.31274 | val_0_accuracy: 0.84456 |  0:00:23s\n","epoch 42 | loss: 0.31739 | val_0_accuracy: 0.85037 |  0:00:24s\n","epoch 43 | loss: 0.32034 | val_0_accuracy: 0.85287 |  0:00:24s\n","epoch 44 | loss: 0.31497 | val_0_accuracy: 0.84622 |  0:00:25s\n","epoch 45 | loss: 0.31492 | val_0_accuracy: 0.86035 |  0:00:25s\n","epoch 46 | loss: 0.31338 | val_0_accuracy: 0.86451 |  0:00:26s\n","epoch 47 | loss: 0.31238 | val_0_accuracy: 0.85204 |  0:00:26s\n","epoch 48 | loss: 0.31399 | val_0_accuracy: 0.85287 |  0:00:27s\n","epoch 49 | loss: 0.31232 | val_0_accuracy: 0.86617 |  0:00:27s\n","epoch 50 | loss: 0.30607 | val_0_accuracy: 0.85453 |  0:00:28s\n","epoch 51 | loss: 0.31203 | val_0_accuracy: 0.85037 |  0:00:29s\n","epoch 52 | loss: 0.3159  | val_0_accuracy: 0.85702 |  0:00:29s\n","epoch 53 | loss: 0.30867 | val_0_accuracy: 0.85037 |  0:00:30s\n","epoch 54 | loss: 0.30319 | val_0_accuracy: 0.85786 |  0:00:30s\n","epoch 55 | loss: 0.30726 | val_0_accuracy: 0.85619 |  0:00:31s\n","epoch 56 | loss: 0.3029  | val_0_accuracy: 0.85952 |  0:00:31s\n","epoch 57 | loss: 0.30228 | val_0_accuracy: 0.85952 |  0:00:32s\n","epoch 58 | loss: 0.30543 | val_0_accuracy: 0.86783 |  0:00:32s\n","epoch 59 | loss: 0.307   | val_0_accuracy: 0.86451 |  0:00:33s\n","epoch 60 | loss: 0.30448 | val_0_accuracy: 0.85952 |  0:00:34s\n","epoch 61 | loss: 0.30815 | val_0_accuracy: 0.85702 |  0:00:34s\n","epoch 62 | loss: 0.30785 | val_0_accuracy: 0.8537  |  0:00:35s\n","epoch 63 | loss: 0.31764 | val_0_accuracy: 0.86118 |  0:00:35s\n","epoch 64 | loss: 0.30834 | val_0_accuracy: 0.85786 |  0:00:36s\n","epoch 65 | loss: 0.30388 | val_0_accuracy: 0.85619 |  0:00:36s\n","epoch 66 | loss: 0.30343 | val_0_accuracy: 0.86617 |  0:00:37s\n","epoch 67 | loss: 0.30485 | val_0_accuracy: 0.85786 |  0:00:37s\n","epoch 68 | loss: 0.30669 | val_0_accuracy: 0.86118 |  0:00:38s\n","\n","Early stopping occurred at epoch 68 with best_epoch = 58 and best_val_0_accuracy = 0.86783\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-07-06 06:18:40,337] Trial 54 finished with value: 0.8678304239401496 and parameters: {'n_d': 29, 'n_steps': 3, 'gamma': 1.7186201714707114, 'n_independent': 4, 'n_shared': 3, 'momentum': 0.18691989045426105}. Best is trial 42 with value: 0.8728179551122195.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 0.75293 | val_0_accuracy: 0.52452 |  0:00:00s\n","epoch 1  | loss: 0.54259 | val_0_accuracy: 0.54697 |  0:00:01s\n","epoch 2  | loss: 0.49476 | val_0_accuracy: 0.52452 |  0:00:01s\n","epoch 3  | loss: 0.46765 | val_0_accuracy: 0.54863 |  0:00:02s\n","epoch 4  | loss: 0.45335 | val_0_accuracy: 0.55611 |  0:00:03s\n","epoch 5  | loss: 0.44492 | val_0_accuracy: 0.5478  |  0:00:03s\n","epoch 6  | loss: 0.43271 | val_0_accuracy: 0.54364 |  0:00:04s\n","epoch 7  | loss: 0.43942 | val_0_accuracy: 0.5586  |  0:00:04s\n","epoch 8  | loss: 0.42438 | val_0_accuracy: 0.56193 |  0:00:05s\n","epoch 9  | loss: 0.4155  | val_0_accuracy: 0.5852  |  0:00:06s\n","epoch 10 | loss: 0.40712 | val_0_accuracy: 0.63259 |  0:00:06s\n","epoch 11 | loss: 0.40524 | val_0_accuracy: 0.65337 |  0:00:07s\n","epoch 12 | loss: 0.40214 | val_0_accuracy: 0.6808  |  0:00:08s\n","epoch 13 | loss: 0.3971  | val_0_accuracy: 0.67664 |  0:00:08s\n","epoch 14 | loss: 0.39285 | val_0_accuracy: 0.64921 |  0:00:09s\n","epoch 15 | loss: 0.39944 | val_0_accuracy: 0.62261 |  0:00:09s\n","epoch 16 | loss: 0.39474 | val_0_accuracy: 0.71488 |  0:00:10s\n","epoch 17 | loss: 0.38958 | val_0_accuracy: 0.72652 |  0:00:11s\n","epoch 18 | loss: 0.3861  | val_0_accuracy: 0.6808  |  0:00:11s\n","epoch 19 | loss: 0.38189 | val_0_accuracy: 0.70574 |  0:00:12s\n","epoch 20 | loss: 0.38873 | val_0_accuracy: 0.75977 |  0:00:12s\n","epoch 21 | loss: 0.38786 | val_0_accuracy: 0.7473  |  0:00:13s\n","epoch 22 | loss: 0.38499 | val_0_accuracy: 0.75312 |  0:00:14s\n","epoch 23 | loss: 0.37626 | val_0_accuracy: 0.75145 |  0:00:14s\n","epoch 24 | loss: 0.37091 | val_0_accuracy: 0.78387 |  0:00:15s\n","epoch 25 | loss: 0.37111 | val_0_accuracy: 0.79135 |  0:00:16s\n","epoch 26 | loss: 0.37362 | val_0_accuracy: 0.78803 |  0:00:16s\n","epoch 27 | loss: 0.37226 | val_0_accuracy: 0.80715 |  0:00:17s\n","epoch 28 | loss: 0.36722 | val_0_accuracy: 0.78886 |  0:00:18s\n","epoch 29 | loss: 0.36604 | val_0_accuracy: 0.80216 |  0:00:18s\n","epoch 30 | loss: 0.36147 | val_0_accuracy: 0.81214 |  0:00:19s\n","epoch 31 | loss: 0.36148 | val_0_accuracy: 0.81962 |  0:00:19s\n","epoch 32 | loss: 0.35734 | val_0_accuracy: 0.83126 |  0:00:20s\n","epoch 33 | loss: 0.35708 | val_0_accuracy: 0.82627 |  0:00:21s\n","epoch 34 | loss: 0.36153 | val_0_accuracy: 0.84206 |  0:00:21s\n","epoch 35 | loss: 0.35743 | val_0_accuracy: 0.82128 |  0:00:22s\n","epoch 36 | loss: 0.356   | val_0_accuracy: 0.82959 |  0:00:22s\n","epoch 37 | loss: 0.35435 | val_0_accuracy: 0.84372 |  0:00:23s\n","epoch 38 | loss: 0.35031 | val_0_accuracy: 0.85204 |  0:00:24s\n","epoch 39 | loss: 0.35142 | val_0_accuracy: 0.84871 |  0:00:24s\n","epoch 40 | loss: 0.35588 | val_0_accuracy: 0.84954 |  0:00:25s\n","epoch 41 | loss: 0.35185 | val_0_accuracy: 0.84206 |  0:00:25s\n","epoch 42 | loss: 0.34759 | val_0_accuracy: 0.84539 |  0:00:26s\n","epoch 43 | loss: 0.34954 | val_0_accuracy: 0.8537  |  0:00:27s\n","epoch 44 | loss: 0.3473  | val_0_accuracy: 0.84788 |  0:00:27s\n","epoch 45 | loss: 0.35158 | val_0_accuracy: 0.84788 |  0:00:28s\n","epoch 46 | loss: 0.3538  | val_0_accuracy: 0.84123 |  0:00:29s\n","epoch 47 | loss: 0.34833 | val_0_accuracy: 0.84705 |  0:00:29s\n","epoch 48 | loss: 0.34719 | val_0_accuracy: 0.85453 |  0:00:30s\n","epoch 49 | loss: 0.34393 | val_0_accuracy: 0.85536 |  0:00:30s\n","epoch 50 | loss: 0.3436  | val_0_accuracy: 0.83791 |  0:00:31s\n","epoch 51 | loss: 0.33903 | val_0_accuracy: 0.84372 |  0:00:32s\n","epoch 52 | loss: 0.33661 | val_0_accuracy: 0.84622 |  0:00:32s\n","epoch 53 | loss: 0.34124 | val_0_accuracy: 0.84539 |  0:00:33s\n","epoch 54 | loss: 0.34    | val_0_accuracy: 0.84123 |  0:00:33s\n","epoch 55 | loss: 0.33003 | val_0_accuracy: 0.85619 |  0:00:34s\n","epoch 56 | loss: 0.33387 | val_0_accuracy: 0.85619 |  0:00:35s\n","epoch 57 | loss: 0.33362 | val_0_accuracy: 0.85204 |  0:00:35s\n","epoch 58 | loss: 0.33622 | val_0_accuracy: 0.84788 |  0:00:36s\n","epoch 59 | loss: 0.33564 | val_0_accuracy: 0.84788 |  0:00:37s\n","epoch 60 | loss: 0.33057 | val_0_accuracy: 0.85702 |  0:00:37s\n","epoch 61 | loss: 0.32957 | val_0_accuracy: 0.85536 |  0:00:38s\n","epoch 62 | loss: 0.32943 | val_0_accuracy: 0.85786 |  0:00:38s\n","epoch 63 | loss: 0.32723 | val_0_accuracy: 0.84539 |  0:00:39s\n","epoch 64 | loss: 0.32729 | val_0_accuracy: 0.84788 |  0:00:40s\n","epoch 65 | loss: 0.33302 | val_0_accuracy: 0.84206 |  0:00:40s\n","epoch 66 | loss: 0.33463 | val_0_accuracy: 0.83957 |  0:00:41s\n","epoch 67 | loss: 0.32829 | val_0_accuracy: 0.84289 |  0:00:42s\n","epoch 68 | loss: 0.32745 | val_0_accuracy: 0.85619 |  0:00:42s\n","epoch 69 | loss: 0.32952 | val_0_accuracy: 0.86367 |  0:00:43s\n","epoch 70 | loss: 0.32324 | val_0_accuracy: 0.85204 |  0:00:43s\n","epoch 71 | loss: 0.32646 | val_0_accuracy: 0.8537  |  0:00:44s\n","epoch 72 | loss: 0.33095 | val_0_accuracy: 0.84622 |  0:00:45s\n","epoch 73 | loss: 0.32934 | val_0_accuracy: 0.85287 |  0:00:45s\n","epoch 74 | loss: 0.32689 | val_0_accuracy: 0.8404  |  0:00:46s\n","epoch 75 | loss: 0.3311  | val_0_accuracy: 0.84622 |  0:00:46s\n","epoch 76 | loss: 0.33319 | val_0_accuracy: 0.8537  |  0:00:47s\n","epoch 77 | loss: 0.32788 | val_0_accuracy: 0.85536 |  0:00:48s\n","epoch 78 | loss: 0.33197 | val_0_accuracy: 0.8537  |  0:00:48s\n","epoch 79 | loss: 0.32976 | val_0_accuracy: 0.86284 |  0:00:49s\n","\n","Early stopping occurred at epoch 79 with best_epoch = 69 and best_val_0_accuracy = 0.86367\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-07-06 06:19:30,139] Trial 55 finished with value: 0.8636741479634248 and parameters: {'n_d': 22, 'n_steps': 4, 'gamma': 1.465268526621802, 'n_independent': 3, 'n_shared': 3, 'momentum': 0.10543187518634244}. Best is trial 42 with value: 0.8728179551122195.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 0.83151 | val_0_accuracy: 0.49127 |  0:00:00s\n","epoch 1  | loss: 0.53327 | val_0_accuracy: 0.51122 |  0:00:01s\n","epoch 2  | loss: 0.45963 | val_0_accuracy: 0.53782 |  0:00:02s\n","epoch 3  | loss: 0.44023 | val_0_accuracy: 0.54115 |  0:00:03s\n","epoch 4  | loss: 0.42248 | val_0_accuracy: 0.56941 |  0:00:03s\n","epoch 5  | loss: 0.42129 | val_0_accuracy: 0.58354 |  0:00:04s\n","epoch 6  | loss: 0.40125 | val_0_accuracy: 0.69077 |  0:00:05s\n","epoch 7  | loss: 0.39812 | val_0_accuracy: 0.65919 |  0:00:06s\n","epoch 8  | loss: 0.3983  | val_0_accuracy: 0.73649 |  0:00:07s\n","epoch 9  | loss: 0.38799 | val_0_accuracy: 0.66417 |  0:00:07s\n","epoch 10 | loss: 0.37844 | val_0_accuracy: 0.64505 |  0:00:08s\n","epoch 11 | loss: 0.37671 | val_0_accuracy: 0.67914 |  0:00:09s\n","epoch 12 | loss: 0.38145 | val_0_accuracy: 0.66916 |  0:00:10s\n","epoch 13 | loss: 0.37851 | val_0_accuracy: 0.6143  |  0:00:10s\n","epoch 14 | loss: 0.37103 | val_0_accuracy: 0.6409  |  0:00:11s\n","epoch 15 | loss: 0.36614 | val_0_accuracy: 0.66584 |  0:00:12s\n","epoch 16 | loss: 0.35927 | val_0_accuracy: 0.67747 |  0:00:13s\n","epoch 17 | loss: 0.35892 | val_0_accuracy: 0.69825 |  0:00:13s\n","epoch 18 | loss: 0.36468 | val_0_accuracy: 0.734   |  0:00:14s\n","\n","Early stopping occurred at epoch 18 with best_epoch = 8 and best_val_0_accuracy = 0.73649\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-07-06 06:19:45,193] Trial 56 finished with value: 0.7364921030756443 and parameters: {'n_d': 61, 'n_steps': 4, 'gamma': 1.6629802786624241, 'n_independent': 5, 'n_shared': 3, 'momentum': 0.159500483487155}. Best is trial 42 with value: 0.8728179551122195.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 0.78786 | val_0_accuracy: 0.52369 |  0:00:00s\n","epoch 1  | loss: 0.62376 | val_0_accuracy: 0.5611  |  0:00:01s\n","epoch 2  | loss: 0.50042 | val_0_accuracy: 0.6916  |  0:00:02s\n","epoch 3  | loss: 0.48566 | val_0_accuracy: 0.5852  |  0:00:03s\n","epoch 4  | loss: 0.44241 | val_0_accuracy: 0.59518 |  0:00:04s\n","epoch 5  | loss: 0.43332 | val_0_accuracy: 0.67082 |  0:00:05s\n","epoch 6  | loss: 0.4227  | val_0_accuracy: 0.5611  |  0:00:06s\n","epoch 7  | loss: 0.41805 | val_0_accuracy: 0.59684 |  0:00:07s\n","epoch 8  | loss: 0.40602 | val_0_accuracy: 0.58354 |  0:00:08s\n","epoch 9  | loss: 0.39561 | val_0_accuracy: 0.62677 |  0:00:09s\n","epoch 10 | loss: 0.39219 | val_0_accuracy: 0.66916 |  0:00:09s\n","epoch 11 | loss: 0.38769 | val_0_accuracy: 0.66085 |  0:00:10s\n","epoch 12 | loss: 0.38849 | val_0_accuracy: 0.65752 |  0:00:11s\n","\n","Early stopping occurred at epoch 12 with best_epoch = 2 and best_val_0_accuracy = 0.6916\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-07-06 06:19:57,412] Trial 57 finished with value: 0.6916043225270158 and parameters: {'n_d': 40, 'n_steps': 5, 'gamma': 1.3124163270408193, 'n_independent': 4, 'n_shared': 4, 'momentum': 0.14189559914939753}. Best is trial 42 with value: 0.8728179551122195.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 0.65742 | val_0_accuracy: 0.55195 |  0:00:00s\n","epoch 1  | loss: 0.45369 | val_0_accuracy: 0.59518 |  0:00:00s\n","epoch 2  | loss: 0.41716 | val_0_accuracy: 0.53948 |  0:00:01s\n","epoch 3  | loss: 0.40219 | val_0_accuracy: 0.5187  |  0:00:01s\n","epoch 4  | loss: 0.39085 | val_0_accuracy: 0.54946 |  0:00:02s\n","epoch 5  | loss: 0.38762 | val_0_accuracy: 0.5187  |  0:00:02s\n","epoch 6  | loss: 0.37742 | val_0_accuracy: 0.53283 |  0:00:03s\n","epoch 7  | loss: 0.36662 | val_0_accuracy: 0.53948 |  0:00:03s\n","epoch 8  | loss: 0.36672 | val_0_accuracy: 0.53283 |  0:00:03s\n","epoch 9  | loss: 0.36528 | val_0_accuracy: 0.54863 |  0:00:04s\n","epoch 10 | loss: 0.35889 | val_0_accuracy: 0.62344 |  0:00:04s\n","epoch 11 | loss: 0.35722 | val_0_accuracy: 0.63259 |  0:00:05s\n","epoch 12 | loss: 0.35705 | val_0_accuracy: 0.60515 |  0:00:05s\n","epoch 13 | loss: 0.35539 | val_0_accuracy: 0.61014 |  0:00:06s\n","epoch 14 | loss: 0.34258 | val_0_accuracy: 0.60183 |  0:00:06s\n","epoch 15 | loss: 0.34467 | val_0_accuracy: 0.66667 |  0:00:07s\n","epoch 16 | loss: 0.34265 | val_0_accuracy: 0.70906 |  0:00:07s\n","epoch 17 | loss: 0.33654 | val_0_accuracy: 0.71571 |  0:00:07s\n","epoch 18 | loss: 0.34172 | val_0_accuracy: 0.7049  |  0:00:08s\n","epoch 19 | loss: 0.32975 | val_0_accuracy: 0.71322 |  0:00:08s\n","epoch 20 | loss: 0.3381  | val_0_accuracy: 0.68994 |  0:00:09s\n","epoch 21 | loss: 0.33505 | val_0_accuracy: 0.71904 |  0:00:09s\n","epoch 22 | loss: 0.32787 | val_0_accuracy: 0.72485 |  0:00:10s\n","epoch 23 | loss: 0.33163 | val_0_accuracy: 0.76309 |  0:00:10s\n","epoch 24 | loss: 0.33758 | val_0_accuracy: 0.75977 |  0:00:11s\n","epoch 25 | loss: 0.34191 | val_0_accuracy: 0.78387 |  0:00:11s\n","epoch 26 | loss: 0.3324  | val_0_accuracy: 0.78304 |  0:00:12s\n","epoch 27 | loss: 0.33355 | val_0_accuracy: 0.79385 |  0:00:12s\n","epoch 28 | loss: 0.32551 | val_0_accuracy: 0.78803 |  0:00:13s\n","epoch 29 | loss: 0.32262 | val_0_accuracy: 0.80466 |  0:00:13s\n","epoch 30 | loss: 0.32262 | val_0_accuracy: 0.81546 |  0:00:13s\n","epoch 31 | loss: 0.32554 | val_0_accuracy: 0.8138  |  0:00:14s\n","epoch 32 | loss: 0.32568 | val_0_accuracy: 0.83375 |  0:00:14s\n","epoch 33 | loss: 0.32152 | val_0_accuracy: 0.81879 |  0:00:15s\n","epoch 34 | loss: 0.32111 | val_0_accuracy: 0.8138  |  0:00:15s\n","epoch 35 | loss: 0.31598 | val_0_accuracy: 0.83707 |  0:00:16s\n","epoch 36 | loss: 0.31867 | val_0_accuracy: 0.85121 |  0:00:16s\n","epoch 37 | loss: 0.31515 | val_0_accuracy: 0.86201 |  0:00:17s\n","epoch 38 | loss: 0.3158  | val_0_accuracy: 0.83707 |  0:00:17s\n","epoch 39 | loss: 0.31302 | val_0_accuracy: 0.85702 |  0:00:17s\n","epoch 40 | loss: 0.31478 | val_0_accuracy: 0.86035 |  0:00:18s\n","epoch 41 | loss: 0.3092  | val_0_accuracy: 0.86534 |  0:00:18s\n","epoch 42 | loss: 0.31498 | val_0_accuracy: 0.85702 |  0:00:19s\n","epoch 43 | loss: 0.31116 | val_0_accuracy: 0.86284 |  0:00:19s\n","epoch 44 | loss: 0.30652 | val_0_accuracy: 0.86534 |  0:00:20s\n","epoch 45 | loss: 0.30998 | val_0_accuracy: 0.867   |  0:00:20s\n","epoch 46 | loss: 0.30896 | val_0_accuracy: 0.85121 |  0:00:21s\n","epoch 47 | loss: 0.31154 | val_0_accuracy: 0.85786 |  0:00:21s\n","epoch 48 | loss: 0.30469 | val_0_accuracy: 0.86451 |  0:00:21s\n","epoch 49 | loss: 0.3047  | val_0_accuracy: 0.86201 |  0:00:22s\n","epoch 50 | loss: 0.31145 | val_0_accuracy: 0.85619 |  0:00:22s\n","epoch 51 | loss: 0.30973 | val_0_accuracy: 0.86783 |  0:00:23s\n","epoch 52 | loss: 0.30733 | val_0_accuracy: 0.86201 |  0:00:23s\n","epoch 53 | loss: 0.3008  | val_0_accuracy: 0.85453 |  0:00:24s\n","epoch 54 | loss: 0.30552 | val_0_accuracy: 0.86866 |  0:00:24s\n","epoch 55 | loss: 0.30323 | val_0_accuracy: 0.86367 |  0:00:25s\n","epoch 56 | loss: 0.30414 | val_0_accuracy: 0.86201 |  0:00:25s\n","epoch 57 | loss: 0.29546 | val_0_accuracy: 0.87032 |  0:00:25s\n","epoch 58 | loss: 0.29779 | val_0_accuracy: 0.85952 |  0:00:26s\n","epoch 59 | loss: 0.29386 | val_0_accuracy: 0.86783 |  0:00:26s\n","epoch 60 | loss: 0.29974 | val_0_accuracy: 0.85952 |  0:00:27s\n","epoch 61 | loss: 0.30889 | val_0_accuracy: 0.85619 |  0:00:27s\n","epoch 62 | loss: 0.30221 | val_0_accuracy: 0.85952 |  0:00:28s\n","epoch 63 | loss: 0.2934  | val_0_accuracy: 0.86783 |  0:00:28s\n","epoch 64 | loss: 0.29587 | val_0_accuracy: 0.86201 |  0:00:28s\n","epoch 65 | loss: 0.29713 | val_0_accuracy: 0.87032 |  0:00:29s\n","epoch 66 | loss: 0.29326 | val_0_accuracy: 0.86367 |  0:00:29s\n","epoch 67 | loss: 0.29464 | val_0_accuracy: 0.86534 |  0:00:30s\n","\n","Early stopping occurred at epoch 67 with best_epoch = 57 and best_val_0_accuracy = 0.87032\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-07-06 06:20:28,039] Trial 58 finished with value: 0.8703241895261845 and parameters: {'n_d': 44, 'n_steps': 3, 'gamma': 1.3819290693144248, 'n_independent': 3, 'n_shared': 2, 'momentum': 0.04883099705695135}. Best is trial 42 with value: 0.8728179551122195.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 0.57831 | val_0_accuracy: 0.55112 |  0:00:00s\n","epoch 1  | loss: 0.46362 | val_0_accuracy: 0.52452 |  0:00:00s\n","epoch 2  | loss: 0.43155 | val_0_accuracy: 0.51953 |  0:00:01s\n","epoch 3  | loss: 0.40322 | val_0_accuracy: 0.52203 |  0:00:01s\n","epoch 4  | loss: 0.39713 | val_0_accuracy: 0.532   |  0:00:02s\n","epoch 5  | loss: 0.38229 | val_0_accuracy: 0.54863 |  0:00:02s\n","epoch 6  | loss: 0.37849 | val_0_accuracy: 0.59767 |  0:00:03s\n","epoch 7  | loss: 0.36711 | val_0_accuracy: 0.58271 |  0:00:03s\n","epoch 8  | loss: 0.37025 | val_0_accuracy: 0.55611 |  0:00:03s\n","epoch 9  | loss: 0.36222 | val_0_accuracy: 0.58354 |  0:00:04s\n","epoch 10 | loss: 0.35764 | val_0_accuracy: 0.58105 |  0:00:04s\n","epoch 11 | loss: 0.35267 | val_0_accuracy: 0.59601 |  0:00:05s\n","epoch 12 | loss: 0.35322 | val_0_accuracy: 0.65337 |  0:00:05s\n","epoch 13 | loss: 0.35073 | val_0_accuracy: 0.64921 |  0:00:06s\n","epoch 14 | loss: 0.3488  | val_0_accuracy: 0.66916 |  0:00:06s\n","epoch 15 | loss: 0.35897 | val_0_accuracy: 0.64755 |  0:00:07s\n","epoch 16 | loss: 0.34926 | val_0_accuracy: 0.6675  |  0:00:07s\n","epoch 17 | loss: 0.34461 | val_0_accuracy: 0.69659 |  0:00:07s\n","epoch 18 | loss: 0.34014 | val_0_accuracy: 0.70407 |  0:00:08s\n","epoch 19 | loss: 0.33894 | val_0_accuracy: 0.70407 |  0:00:08s\n","epoch 20 | loss: 0.33842 | val_0_accuracy: 0.71322 |  0:00:09s\n","epoch 21 | loss: 0.33832 | val_0_accuracy: 0.7581  |  0:00:09s\n","epoch 22 | loss: 0.35351 | val_0_accuracy: 0.7606  |  0:00:10s\n","epoch 23 | loss: 0.34763 | val_0_accuracy: 0.77307 |  0:00:10s\n","epoch 24 | loss: 0.34548 | val_0_accuracy: 0.78803 |  0:00:11s\n","epoch 25 | loss: 0.34452 | val_0_accuracy: 0.77224 |  0:00:11s\n","epoch 26 | loss: 0.33359 | val_0_accuracy: 0.7714  |  0:00:12s\n","epoch 27 | loss: 0.33072 | val_0_accuracy: 0.80632 |  0:00:12s\n","epoch 28 | loss: 0.33433 | val_0_accuracy: 0.83375 |  0:00:12s\n","epoch 29 | loss: 0.33784 | val_0_accuracy: 0.82045 |  0:00:13s\n","epoch 30 | loss: 0.33554 | val_0_accuracy: 0.81629 |  0:00:13s\n","epoch 31 | loss: 0.33525 | val_0_accuracy: 0.83375 |  0:00:14s\n","epoch 32 | loss: 0.33019 | val_0_accuracy: 0.82377 |  0:00:14s\n","epoch 33 | loss: 0.32631 | val_0_accuracy: 0.84372 |  0:00:15s\n","epoch 34 | loss: 0.32833 | val_0_accuracy: 0.85037 |  0:00:15s\n","epoch 35 | loss: 0.32627 | val_0_accuracy: 0.85121 |  0:00:16s\n","epoch 36 | loss: 0.32195 | val_0_accuracy: 0.84206 |  0:00:16s\n","epoch 37 | loss: 0.32156 | val_0_accuracy: 0.85619 |  0:00:16s\n","epoch 38 | loss: 0.32063 | val_0_accuracy: 0.85037 |  0:00:17s\n","epoch 39 | loss: 0.32259 | val_0_accuracy: 0.84705 |  0:00:17s\n","epoch 40 | loss: 0.32887 | val_0_accuracy: 0.85786 |  0:00:18s\n","epoch 41 | loss: 0.32837 | val_0_accuracy: 0.85786 |  0:00:18s\n","epoch 42 | loss: 0.331   | val_0_accuracy: 0.85619 |  0:00:19s\n","epoch 43 | loss: 0.32999 | val_0_accuracy: 0.85536 |  0:00:19s\n","epoch 44 | loss: 0.32523 | val_0_accuracy: 0.85702 |  0:00:19s\n","epoch 45 | loss: 0.32236 | val_0_accuracy: 0.85287 |  0:00:20s\n","epoch 46 | loss: 0.31886 | val_0_accuracy: 0.83541 |  0:00:20s\n","epoch 47 | loss: 0.32131 | val_0_accuracy: 0.85619 |  0:00:21s\n","epoch 48 | loss: 0.3212  | val_0_accuracy: 0.85952 |  0:00:21s\n","epoch 49 | loss: 0.31897 | val_0_accuracy: 0.86201 |  0:00:22s\n","epoch 50 | loss: 0.31599 | val_0_accuracy: 0.85453 |  0:00:22s\n","epoch 51 | loss: 0.31192 | val_0_accuracy: 0.86284 |  0:00:23s\n","epoch 52 | loss: 0.30891 | val_0_accuracy: 0.85619 |  0:00:23s\n","epoch 53 | loss: 0.31354 | val_0_accuracy: 0.85204 |  0:00:24s\n","epoch 54 | loss: 0.31039 | val_0_accuracy: 0.85786 |  0:00:24s\n","epoch 55 | loss: 0.31439 | val_0_accuracy: 0.85453 |  0:00:24s\n","epoch 56 | loss: 0.31323 | val_0_accuracy: 0.86035 |  0:00:25s\n","epoch 57 | loss: 0.30632 | val_0_accuracy: 0.84871 |  0:00:25s\n","epoch 58 | loss: 0.305   | val_0_accuracy: 0.86035 |  0:00:26s\n","epoch 59 | loss: 0.3001  | val_0_accuracy: 0.86201 |  0:00:26s\n","epoch 60 | loss: 0.30935 | val_0_accuracy: 0.85536 |  0:00:27s\n","epoch 61 | loss: 0.30168 | val_0_accuracy: 0.86367 |  0:00:27s\n","epoch 62 | loss: 0.29851 | val_0_accuracy: 0.86534 |  0:00:27s\n","epoch 63 | loss: 0.29196 | val_0_accuracy: 0.85786 |  0:00:28s\n","epoch 64 | loss: 0.29246 | val_0_accuracy: 0.86783 |  0:00:28s\n","epoch 65 | loss: 0.2966  | val_0_accuracy: 0.86451 |  0:00:29s\n","epoch 66 | loss: 0.29887 | val_0_accuracy: 0.86118 |  0:00:29s\n","epoch 67 | loss: 0.2951  | val_0_accuracy: 0.86118 |  0:00:30s\n","epoch 68 | loss: 0.29811 | val_0_accuracy: 0.86118 |  0:00:30s\n","epoch 69 | loss: 0.29244 | val_0_accuracy: 0.86534 |  0:00:31s\n","epoch 70 | loss: 0.29085 | val_0_accuracy: 0.85702 |  0:00:31s\n","epoch 71 | loss: 0.2897  | val_0_accuracy: 0.85869 |  0:00:31s\n","epoch 72 | loss: 0.29743 | val_0_accuracy: 0.86534 |  0:00:32s\n","epoch 73 | loss: 0.29289 | val_0_accuracy: 0.86201 |  0:00:32s\n","epoch 74 | loss: 0.29806 | val_0_accuracy: 0.86367 |  0:00:33s\n","\n","Early stopping occurred at epoch 74 with best_epoch = 64 and best_val_0_accuracy = 0.86783\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-07-06 06:21:01,531] Trial 59 finished with value: 0.8678304239401496 and parameters: {'n_d': 32, 'n_steps': 3, 'gamma': 1.5301118845440476, 'n_independent': 3, 'n_shared': 2, 'momentum': 0.03981824193012244}. Best is trial 42 with value: 0.8728179551122195.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 0.66488 | val_0_accuracy: 0.52452 |  0:00:00s\n","epoch 1  | loss: 0.45132 | val_0_accuracy: 0.51621 |  0:00:00s\n","epoch 2  | loss: 0.41442 | val_0_accuracy: 0.53283 |  0:00:01s\n","epoch 3  | loss: 0.39473 | val_0_accuracy: 0.58437 |  0:00:01s\n","epoch 4  | loss: 0.38703 | val_0_accuracy: 0.57689 |  0:00:01s\n","epoch 5  | loss: 0.37755 | val_0_accuracy: 0.56608 |  0:00:02s\n","epoch 6  | loss: 0.37256 | val_0_accuracy: 0.56359 |  0:00:02s\n","epoch 7  | loss: 0.36945 | val_0_accuracy: 0.57273 |  0:00:03s\n","epoch 8  | loss: 0.36602 | val_0_accuracy: 0.60931 |  0:00:03s\n","epoch 9  | loss: 0.35749 | val_0_accuracy: 0.59268 |  0:00:03s\n","epoch 10 | loss: 0.35335 | val_0_accuracy: 0.62178 |  0:00:04s\n","epoch 11 | loss: 0.35478 | val_0_accuracy: 0.6409  |  0:00:04s\n","epoch 12 | loss: 0.35003 | val_0_accuracy: 0.64256 |  0:00:05s\n","epoch 13 | loss: 0.35957 | val_0_accuracy: 0.65586 |  0:00:05s\n","epoch 14 | loss: 0.34983 | val_0_accuracy: 0.66334 |  0:00:05s\n","epoch 15 | loss: 0.34514 | val_0_accuracy: 0.68246 |  0:00:06s\n","epoch 16 | loss: 0.34712 | val_0_accuracy: 0.71322 |  0:00:06s\n","epoch 17 | loss: 0.34123 | val_0_accuracy: 0.68163 |  0:00:07s\n","epoch 18 | loss: 0.33739 | val_0_accuracy: 0.71737 |  0:00:07s\n","epoch 19 | loss: 0.33895 | val_0_accuracy: 0.67165 |  0:00:07s\n","epoch 20 | loss: 0.34297 | val_0_accuracy: 0.68745 |  0:00:08s\n","epoch 21 | loss: 0.34003 | val_0_accuracy: 0.69077 |  0:00:08s\n","epoch 22 | loss: 0.33407 | val_0_accuracy: 0.71904 |  0:00:08s\n","epoch 23 | loss: 0.33304 | val_0_accuracy: 0.7473  |  0:00:09s\n","epoch 24 | loss: 0.32979 | val_0_accuracy: 0.77057 |  0:00:09s\n","epoch 25 | loss: 0.3245  | val_0_accuracy: 0.77639 |  0:00:10s\n","epoch 26 | loss: 0.32947 | val_0_accuracy: 0.73566 |  0:00:10s\n","epoch 27 | loss: 0.33104 | val_0_accuracy: 0.79468 |  0:00:10s\n","epoch 28 | loss: 0.33049 | val_0_accuracy: 0.80798 |  0:00:11s\n","epoch 29 | loss: 0.33187 | val_0_accuracy: 0.81214 |  0:00:11s\n","epoch 30 | loss: 0.32526 | val_0_accuracy: 0.77057 |  0:00:12s\n","epoch 31 | loss: 0.32359 | val_0_accuracy: 0.80466 |  0:00:12s\n","epoch 32 | loss: 0.3237  | val_0_accuracy: 0.82461 |  0:00:12s\n","epoch 33 | loss: 0.31755 | val_0_accuracy: 0.82294 |  0:00:13s\n","epoch 34 | loss: 0.31659 | val_0_accuracy: 0.82959 |  0:00:13s\n","epoch 35 | loss: 0.31752 | val_0_accuracy: 0.83126 |  0:00:14s\n","epoch 36 | loss: 0.31613 | val_0_accuracy: 0.84456 |  0:00:14s\n","epoch 37 | loss: 0.3151  | val_0_accuracy: 0.85037 |  0:00:14s\n","epoch 38 | loss: 0.31264 | val_0_accuracy: 0.85121 |  0:00:15s\n","epoch 39 | loss: 0.31378 | val_0_accuracy: 0.85786 |  0:00:15s\n","epoch 40 | loss: 0.31744 | val_0_accuracy: 0.85287 |  0:00:16s\n","epoch 41 | loss: 0.3088  | val_0_accuracy: 0.85204 |  0:00:16s\n","epoch 42 | loss: 0.31209 | val_0_accuracy: 0.84705 |  0:00:16s\n","epoch 43 | loss: 0.30266 | val_0_accuracy: 0.85287 |  0:00:17s\n","epoch 44 | loss: 0.30522 | val_0_accuracy: 0.8537  |  0:00:17s\n","epoch 45 | loss: 0.30475 | val_0_accuracy: 0.8537  |  0:00:17s\n","epoch 46 | loss: 0.30131 | val_0_accuracy: 0.8537  |  0:00:18s\n","epoch 47 | loss: 0.3075  | val_0_accuracy: 0.86617 |  0:00:18s\n","epoch 48 | loss: 0.30118 | val_0_accuracy: 0.86118 |  0:00:19s\n","epoch 49 | loss: 0.30165 | val_0_accuracy: 0.86367 |  0:00:19s\n","epoch 50 | loss: 0.30388 | val_0_accuracy: 0.86367 |  0:00:19s\n","epoch 51 | loss: 0.30098 | val_0_accuracy: 0.85952 |  0:00:20s\n","epoch 52 | loss: 0.29948 | val_0_accuracy: 0.86367 |  0:00:20s\n","epoch 53 | loss: 0.30047 | val_0_accuracy: 0.85121 |  0:00:20s\n","epoch 54 | loss: 0.29701 | val_0_accuracy: 0.85619 |  0:00:21s\n","epoch 55 | loss: 0.30365 | val_0_accuracy: 0.85204 |  0:00:21s\n","epoch 56 | loss: 0.30457 | val_0_accuracy: 0.85204 |  0:00:22s\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-07-06 06:21:24,311] Trial 60 finished with value: 0.8661679135494597 and parameters: {'n_d': 44, 'n_steps': 3, 'gamma': 1.3667457727799146, 'n_independent': 3, 'n_shared': 1, 'momentum': 0.3904871985890165}. Best is trial 42 with value: 0.8728179551122195.\n"]},{"output_type":"stream","name":"stdout","text":["epoch 57 | loss: 0.30845 | val_0_accuracy: 0.85453 |  0:00:22s\n","\n","Early stopping occurred at epoch 57 with best_epoch = 47 and best_val_0_accuracy = 0.86617\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 0.97273 | val_0_accuracy: 0.48712 |  0:00:00s\n","epoch 1  | loss: 0.51471 | val_0_accuracy: 0.52037 |  0:00:00s\n","epoch 2  | loss: 0.46126 | val_0_accuracy: 0.54281 |  0:00:01s\n","epoch 3  | loss: 0.43883 | val_0_accuracy: 0.56608 |  0:00:01s\n","epoch 4  | loss: 0.41717 | val_0_accuracy: 0.57357 |  0:00:02s\n","epoch 5  | loss: 0.4056  | val_0_accuracy: 0.53533 |  0:00:02s\n","epoch 6  | loss: 0.39605 | val_0_accuracy: 0.56193 |  0:00:03s\n","epoch 7  | loss: 0.40056 | val_0_accuracy: 0.56775 |  0:00:03s\n","epoch 8  | loss: 0.3993  | val_0_accuracy: 0.58354 |  0:00:04s\n","epoch 9  | loss: 0.38828 | val_0_accuracy: 0.59102 |  0:00:04s\n","epoch 10 | loss: 0.38124 | val_0_accuracy: 0.5478  |  0:00:05s\n","epoch 11 | loss: 0.37186 | val_0_accuracy: 0.64256 |  0:00:05s\n","epoch 12 | loss: 0.37413 | val_0_accuracy: 0.63259 |  0:00:06s\n","epoch 13 | loss: 0.36975 | val_0_accuracy: 0.62344 |  0:00:06s\n","epoch 14 | loss: 0.36705 | val_0_accuracy: 0.60183 |  0:00:07s\n","epoch 15 | loss: 0.36213 | val_0_accuracy: 0.65087 |  0:00:07s\n","epoch 16 | loss: 0.36345 | val_0_accuracy: 0.65919 |  0:00:08s\n","epoch 17 | loss: 0.36509 | val_0_accuracy: 0.69742 |  0:00:08s\n","epoch 18 | loss: 0.36561 | val_0_accuracy: 0.6251  |  0:00:09s\n","epoch 19 | loss: 0.36004 | val_0_accuracy: 0.63259 |  0:00:09s\n","epoch 20 | loss: 0.35678 | val_0_accuracy: 0.69992 |  0:00:10s\n","epoch 21 | loss: 0.37077 | val_0_accuracy: 0.70075 |  0:00:10s\n","epoch 22 | loss: 0.36442 | val_0_accuracy: 0.6916  |  0:00:10s\n","epoch 23 | loss: 0.35122 | val_0_accuracy: 0.74231 |  0:00:11s\n","epoch 24 | loss: 0.35763 | val_0_accuracy: 0.74647 |  0:00:11s\n","epoch 25 | loss: 0.35997 | val_0_accuracy: 0.76226 |  0:00:12s\n","epoch 26 | loss: 0.35746 | val_0_accuracy: 0.76642 |  0:00:12s\n","epoch 27 | loss: 0.36087 | val_0_accuracy: 0.77473 |  0:00:13s\n","epoch 28 | loss: 0.3599  | val_0_accuracy: 0.79219 |  0:00:13s\n","epoch 29 | loss: 0.35054 | val_0_accuracy: 0.8138  |  0:00:14s\n","epoch 30 | loss: 0.35032 | val_0_accuracy: 0.82377 |  0:00:14s\n","epoch 31 | loss: 0.35325 | val_0_accuracy: 0.83209 |  0:00:15s\n","epoch 32 | loss: 0.34674 | val_0_accuracy: 0.83541 |  0:00:15s\n","epoch 33 | loss: 0.34275 | val_0_accuracy: 0.84705 |  0:00:16s\n","epoch 34 | loss: 0.34339 | val_0_accuracy: 0.82294 |  0:00:16s\n","epoch 35 | loss: 0.34166 | val_0_accuracy: 0.85287 |  0:00:17s\n","epoch 36 | loss: 0.34445 | val_0_accuracy: 0.83874 |  0:00:17s\n","epoch 37 | loss: 0.34522 | val_0_accuracy: 0.84372 |  0:00:18s\n","epoch 38 | loss: 0.33839 | val_0_accuracy: 0.84539 |  0:00:18s\n","epoch 39 | loss: 0.33934 | val_0_accuracy: 0.84788 |  0:00:19s\n","epoch 40 | loss: 0.33583 | val_0_accuracy: 0.85702 |  0:00:19s\n","epoch 41 | loss: 0.33803 | val_0_accuracy: 0.84456 |  0:00:19s\n","epoch 42 | loss: 0.34027 | val_0_accuracy: 0.84539 |  0:00:20s\n","epoch 43 | loss: 0.33337 | val_0_accuracy: 0.85037 |  0:00:20s\n","epoch 44 | loss: 0.33531 | val_0_accuracy: 0.85453 |  0:00:21s\n","epoch 45 | loss: 0.32991 | val_0_accuracy: 0.85702 |  0:00:21s\n","epoch 46 | loss: 0.32892 | val_0_accuracy: 0.85536 |  0:00:22s\n","epoch 47 | loss: 0.32662 | val_0_accuracy: 0.86118 |  0:00:22s\n","epoch 48 | loss: 0.32792 | val_0_accuracy: 0.85037 |  0:00:23s\n","epoch 49 | loss: 0.33041 | val_0_accuracy: 0.85869 |  0:00:23s\n","epoch 50 | loss: 0.3273  | val_0_accuracy: 0.85287 |  0:00:24s\n","epoch 51 | loss: 0.32499 | val_0_accuracy: 0.86035 |  0:00:24s\n","epoch 52 | loss: 0.3218  | val_0_accuracy: 0.84456 |  0:00:25s\n","epoch 53 | loss: 0.32424 | val_0_accuracy: 0.85287 |  0:00:25s\n","epoch 54 | loss: 0.32125 | val_0_accuracy: 0.85287 |  0:00:26s\n","epoch 55 | loss: 0.32303 | val_0_accuracy: 0.85287 |  0:00:26s\n","epoch 56 | loss: 0.32195 | val_0_accuracy: 0.84871 |  0:00:26s\n","epoch 57 | loss: 0.32638 | val_0_accuracy: 0.84871 |  0:00:27s\n","\n","Early stopping occurred at epoch 57 with best_epoch = 47 and best_val_0_accuracy = 0.86118\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-07-06 06:21:52,071] Trial 61 finished with value: 0.8611803823773898 and parameters: {'n_d': 50, 'n_steps': 4, 'gamma': 1.2540851676504752, 'n_independent': 2, 'n_shared': 2, 'momentum': 0.0726537305586935}. Best is trial 42 with value: 0.8728179551122195.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 0.62586 | val_0_accuracy: 0.5187  |  0:00:00s\n","epoch 1  | loss: 0.45791 | val_0_accuracy: 0.52369 |  0:00:00s\n","epoch 2  | loss: 0.40984 | val_0_accuracy: 0.52951 |  0:00:01s\n","epoch 3  | loss: 0.39002 | val_0_accuracy: 0.52369 |  0:00:02s\n","epoch 4  | loss: 0.37843 | val_0_accuracy: 0.5187  |  0:00:02s\n","epoch 5  | loss: 0.36737 | val_0_accuracy: 0.55029 |  0:00:02s\n","epoch 6  | loss: 0.36632 | val_0_accuracy: 0.60017 |  0:00:03s\n","epoch 7  | loss: 0.35426 | val_0_accuracy: 0.56442 |  0:00:03s\n","epoch 8  | loss: 0.35383 | val_0_accuracy: 0.59435 |  0:00:04s\n","epoch 9  | loss: 0.35235 | val_0_accuracy: 0.61513 |  0:00:04s\n","epoch 10 | loss: 0.3507  | val_0_accuracy: 0.61513 |  0:00:05s\n","epoch 11 | loss: 0.34567 | val_0_accuracy: 0.59684 |  0:00:06s\n","epoch 12 | loss: 0.33974 | val_0_accuracy: 0.66002 |  0:00:06s\n","epoch 13 | loss: 0.3385  | val_0_accuracy: 0.64007 |  0:00:07s\n","epoch 14 | loss: 0.33599 | val_0_accuracy: 0.68662 |  0:00:07s\n","epoch 15 | loss: 0.32936 | val_0_accuracy: 0.72236 |  0:00:08s\n","epoch 16 | loss: 0.32926 | val_0_accuracy: 0.72569 |  0:00:08s\n","epoch 17 | loss: 0.33186 | val_0_accuracy: 0.74979 |  0:00:09s\n","epoch 18 | loss: 0.33202 | val_0_accuracy: 0.73483 |  0:00:09s\n","epoch 19 | loss: 0.32242 | val_0_accuracy: 0.71654 |  0:00:10s\n","epoch 20 | loss: 0.32755 | val_0_accuracy: 0.70407 |  0:00:10s\n","epoch 21 | loss: 0.3252  | val_0_accuracy: 0.75894 |  0:00:11s\n","epoch 22 | loss: 0.3194  | val_0_accuracy: 0.74314 |  0:00:11s\n","epoch 23 | loss: 0.32741 | val_0_accuracy: 0.75395 |  0:00:12s\n","epoch 24 | loss: 0.33457 | val_0_accuracy: 0.76392 |  0:00:12s\n","epoch 25 | loss: 0.3272  | val_0_accuracy: 0.75229 |  0:00:13s\n","epoch 26 | loss: 0.32286 | val_0_accuracy: 0.78055 |  0:00:13s\n","epoch 27 | loss: 0.31546 | val_0_accuracy: 0.81546 |  0:00:14s\n","epoch 28 | loss: 0.32121 | val_0_accuracy: 0.81214 |  0:00:14s\n","epoch 29 | loss: 0.31494 | val_0_accuracy: 0.82959 |  0:00:15s\n","epoch 30 | loss: 0.31174 | val_0_accuracy: 0.82211 |  0:00:15s\n","epoch 31 | loss: 0.30763 | val_0_accuracy: 0.83624 |  0:00:16s\n","epoch 32 | loss: 0.31447 | val_0_accuracy: 0.83541 |  0:00:16s\n","epoch 33 | loss: 0.30771 | val_0_accuracy: 0.84372 |  0:00:17s\n","epoch 34 | loss: 0.3147  | val_0_accuracy: 0.85287 |  0:00:18s\n","epoch 35 | loss: 0.31402 | val_0_accuracy: 0.86534 |  0:00:18s\n","epoch 36 | loss: 0.31487 | val_0_accuracy: 0.85702 |  0:00:19s\n","epoch 37 | loss: 0.31499 | val_0_accuracy: 0.85204 |  0:00:19s\n","epoch 38 | loss: 0.30818 | val_0_accuracy: 0.86118 |  0:00:20s\n","epoch 39 | loss: 0.30821 | val_0_accuracy: 0.85952 |  0:00:20s\n","epoch 40 | loss: 0.3046  | val_0_accuracy: 0.85952 |  0:00:21s\n","epoch 41 | loss: 0.3034  | val_0_accuracy: 0.86035 |  0:00:21s\n","epoch 42 | loss: 0.30054 | val_0_accuracy: 0.86451 |  0:00:22s\n","epoch 43 | loss: 0.30264 | val_0_accuracy: 0.86617 |  0:00:22s\n","epoch 44 | loss: 0.30246 | val_0_accuracy: 0.86035 |  0:00:23s\n","epoch 45 | loss: 0.3024  | val_0_accuracy: 0.85619 |  0:00:23s\n","epoch 46 | loss: 0.3089  | val_0_accuracy: 0.86201 |  0:00:24s\n","epoch 47 | loss: 0.31144 | val_0_accuracy: 0.85786 |  0:00:24s\n","epoch 48 | loss: 0.30553 | val_0_accuracy: 0.87116 |  0:00:25s\n","epoch 49 | loss: 0.299   | val_0_accuracy: 0.86035 |  0:00:25s\n","epoch 50 | loss: 0.29856 | val_0_accuracy: 0.87032 |  0:00:26s\n","epoch 51 | loss: 0.29907 | val_0_accuracy: 0.86866 |  0:00:26s\n","epoch 52 | loss: 0.2927  | val_0_accuracy: 0.86617 |  0:00:27s\n","epoch 53 | loss: 0.2942  | val_0_accuracy: 0.86866 |  0:00:27s\n","epoch 54 | loss: 0.29067 | val_0_accuracy: 0.86118 |  0:00:28s\n","epoch 55 | loss: 0.28723 | val_0_accuracy: 0.85287 |  0:00:28s\n","epoch 56 | loss: 0.29376 | val_0_accuracy: 0.85619 |  0:00:29s\n","epoch 57 | loss: 0.29039 | val_0_accuracy: 0.86367 |  0:00:29s\n","epoch 58 | loss: 0.29194 | val_0_accuracy: 0.86118 |  0:00:30s\n","\n","Early stopping occurred at epoch 58 with best_epoch = 48 and best_val_0_accuracy = 0.87116\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-07-06 06:22:22,886] Trial 62 finished with value: 0.8711554447215295 and parameters: {'n_d': 43, 'n_steps': 3, 'gamma': 1.1969400619792323, 'n_independent': 3, 'n_shared': 3, 'momentum': 0.05093000580977663}. Best is trial 42 with value: 0.8728179551122195.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 0.6378  | val_0_accuracy: 0.51953 |  0:00:00s\n","epoch 1  | loss: 0.48187 | val_0_accuracy: 0.5187  |  0:00:01s\n","epoch 2  | loss: 0.4416  | val_0_accuracy: 0.51704 |  0:00:01s\n","epoch 3  | loss: 0.41766 | val_0_accuracy: 0.51704 |  0:00:02s\n","epoch 4  | loss: 0.40372 | val_0_accuracy: 0.53367 |  0:00:02s\n","epoch 5  | loss: 0.3814  | val_0_accuracy: 0.53948 |  0:00:03s\n","epoch 6  | loss: 0.37035 | val_0_accuracy: 0.52785 |  0:00:03s\n","epoch 7  | loss: 0.36877 | val_0_accuracy: 0.55445 |  0:00:04s\n","epoch 8  | loss: 0.35771 | val_0_accuracy: 0.54281 |  0:00:04s\n","epoch 9  | loss: 0.35221 | val_0_accuracy: 0.52369 |  0:00:05s\n","epoch 10 | loss: 0.35131 | val_0_accuracy: 0.52702 |  0:00:05s\n","epoch 11 | loss: 0.35007 | val_0_accuracy: 0.54115 |  0:00:06s\n","epoch 12 | loss: 0.34474 | val_0_accuracy: 0.57606 |  0:00:06s\n","epoch 13 | loss: 0.34732 | val_0_accuracy: 0.57024 |  0:00:07s\n","epoch 14 | loss: 0.33728 | val_0_accuracy: 0.6118  |  0:00:07s\n","epoch 15 | loss: 0.33684 | val_0_accuracy: 0.64256 |  0:00:08s\n","epoch 16 | loss: 0.33812 | val_0_accuracy: 0.65752 |  0:00:08s\n","epoch 17 | loss: 0.33966 | val_0_accuracy: 0.68579 |  0:00:09s\n","epoch 18 | loss: 0.33854 | val_0_accuracy: 0.6517  |  0:00:09s\n","epoch 19 | loss: 0.32608 | val_0_accuracy: 0.6542  |  0:00:10s\n","epoch 20 | loss: 0.3316  | val_0_accuracy: 0.63092 |  0:00:10s\n","epoch 21 | loss: 0.32789 | val_0_accuracy: 0.7207  |  0:00:11s\n","epoch 22 | loss: 0.32708 | val_0_accuracy: 0.72984 |  0:00:11s\n","epoch 23 | loss: 0.32806 | val_0_accuracy: 0.73317 |  0:00:12s\n","epoch 24 | loss: 0.33047 | val_0_accuracy: 0.70989 |  0:00:12s\n","epoch 25 | loss: 0.32598 | val_0_accuracy: 0.75395 |  0:00:13s\n","epoch 26 | loss: 0.32661 | val_0_accuracy: 0.79219 |  0:00:13s\n","epoch 27 | loss: 0.32391 | val_0_accuracy: 0.81546 |  0:00:14s\n","epoch 28 | loss: 0.32674 | val_0_accuracy: 0.82045 |  0:00:14s\n","epoch 29 | loss: 0.32386 | val_0_accuracy: 0.82876 |  0:00:15s\n","epoch 30 | loss: 0.32188 | val_0_accuracy: 0.81546 |  0:00:15s\n","epoch 31 | loss: 0.32095 | val_0_accuracy: 0.80549 |  0:00:16s\n","epoch 32 | loss: 0.32248 | val_0_accuracy: 0.81629 |  0:00:16s\n","epoch 33 | loss: 0.31589 | val_0_accuracy: 0.83458 |  0:00:17s\n","epoch 34 | loss: 0.32109 | val_0_accuracy: 0.85287 |  0:00:17s\n","epoch 35 | loss: 0.31646 | val_0_accuracy: 0.85121 |  0:00:18s\n","epoch 36 | loss: 0.31871 | val_0_accuracy: 0.84123 |  0:00:19s\n","epoch 37 | loss: 0.31898 | val_0_accuracy: 0.84456 |  0:00:19s\n","epoch 38 | loss: 0.322   | val_0_accuracy: 0.84622 |  0:00:20s\n","epoch 39 | loss: 0.31886 | val_0_accuracy: 0.85453 |  0:00:20s\n","epoch 40 | loss: 0.3179  | val_0_accuracy: 0.8537  |  0:00:21s\n","epoch 41 | loss: 0.31271 | val_0_accuracy: 0.85536 |  0:00:21s\n","epoch 42 | loss: 0.30938 | val_0_accuracy: 0.84206 |  0:00:22s\n","epoch 43 | loss: 0.31866 | val_0_accuracy: 0.84788 |  0:00:22s\n","epoch 44 | loss: 0.31308 | val_0_accuracy: 0.84372 |  0:00:23s\n","epoch 45 | loss: 0.3145  | val_0_accuracy: 0.85869 |  0:00:23s\n","epoch 46 | loss: 0.31549 | val_0_accuracy: 0.84954 |  0:00:24s\n","epoch 47 | loss: 0.31664 | val_0_accuracy: 0.85453 |  0:00:24s\n","epoch 48 | loss: 0.31294 | val_0_accuracy: 0.84954 |  0:00:25s\n","epoch 49 | loss: 0.31257 | val_0_accuracy: 0.84206 |  0:00:25s\n","epoch 50 | loss: 0.31289 | val_0_accuracy: 0.86201 |  0:00:26s\n","epoch 51 | loss: 0.31611 | val_0_accuracy: 0.85952 |  0:00:26s\n","epoch 52 | loss: 0.30708 | val_0_accuracy: 0.85037 |  0:00:27s\n","epoch 53 | loss: 0.31092 | val_0_accuracy: 0.85121 |  0:00:27s\n","epoch 54 | loss: 0.30776 | val_0_accuracy: 0.86118 |  0:00:28s\n","epoch 55 | loss: 0.30286 | val_0_accuracy: 0.85952 |  0:00:28s\n","epoch 56 | loss: 0.30598 | val_0_accuracy: 0.85952 |  0:00:29s\n","epoch 57 | loss: 0.29828 | val_0_accuracy: 0.85536 |  0:00:29s\n","epoch 58 | loss: 0.3084  | val_0_accuracy: 0.84539 |  0:00:30s\n","epoch 59 | loss: 0.31024 | val_0_accuracy: 0.85204 |  0:00:30s\n","epoch 60 | loss: 0.30964 | val_0_accuracy: 0.84871 |  0:00:31s\n","\n","Early stopping occurred at epoch 60 with best_epoch = 50 and best_val_0_accuracy = 0.86201\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-07-06 06:22:54,272] Trial 63 finished with value: 0.8620116375727348 and parameters: {'n_d': 43, 'n_steps': 3, 'gamma': 1.2077256554778546, 'n_independent': 3, 'n_shared': 3, 'momentum': 0.06194901975422565}. Best is trial 42 with value: 0.8728179551122195.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 0.59635 | val_0_accuracy: 0.5212  |  0:00:00s\n","epoch 1  | loss: 0.44932 | val_0_accuracy: 0.51704 |  0:00:01s\n","epoch 2  | loss: 0.42532 | val_0_accuracy: 0.57606 |  0:00:01s\n","epoch 3  | loss: 0.40382 | val_0_accuracy: 0.54613 |  0:00:02s\n","epoch 4  | loss: 0.39119 | val_0_accuracy: 0.57606 |  0:00:02s\n","epoch 5  | loss: 0.38804 | val_0_accuracy: 0.59601 |  0:00:03s\n","epoch 6  | loss: 0.3936  | val_0_accuracy: 0.6941  |  0:00:03s\n","epoch 7  | loss: 0.37949 | val_0_accuracy: 0.69493 |  0:00:04s\n","epoch 8  | loss: 0.36698 | val_0_accuracy: 0.66667 |  0:00:04s\n","epoch 9  | loss: 0.3714  | val_0_accuracy: 0.6808  |  0:00:05s\n","epoch 10 | loss: 0.37546 | val_0_accuracy: 0.75312 |  0:00:05s\n","epoch 11 | loss: 0.36426 | val_0_accuracy: 0.70906 |  0:00:06s\n","epoch 12 | loss: 0.36051 | val_0_accuracy: 0.7473  |  0:00:06s\n","epoch 13 | loss: 0.3523  | val_0_accuracy: 0.74397 |  0:00:07s\n","epoch 14 | loss: 0.3526  | val_0_accuracy: 0.74979 |  0:00:07s\n","epoch 15 | loss: 0.35383 | val_0_accuracy: 0.76143 |  0:00:08s\n","epoch 16 | loss: 0.35887 | val_0_accuracy: 0.77639 |  0:00:08s\n","epoch 17 | loss: 0.35753 | val_0_accuracy: 0.7581  |  0:00:09s\n","epoch 18 | loss: 0.35295 | val_0_accuracy: 0.7473  |  0:00:09s\n","epoch 19 | loss: 0.35154 | val_0_accuracy: 0.75229 |  0:00:10s\n","epoch 20 | loss: 0.34904 | val_0_accuracy: 0.75977 |  0:00:10s\n","epoch 21 | loss: 0.35213 | val_0_accuracy: 0.78554 |  0:00:11s\n","epoch 22 | loss: 0.34428 | val_0_accuracy: 0.76891 |  0:00:11s\n","epoch 23 | loss: 0.3434  | val_0_accuracy: 0.78554 |  0:00:12s\n","epoch 24 | loss: 0.33717 | val_0_accuracy: 0.78221 |  0:00:12s\n","epoch 25 | loss: 0.34296 | val_0_accuracy: 0.77805 |  0:00:13s\n","epoch 26 | loss: 0.33985 | val_0_accuracy: 0.76808 |  0:00:13s\n","epoch 27 | loss: 0.33385 | val_0_accuracy: 0.79302 |  0:00:14s\n","epoch 28 | loss: 0.336   | val_0_accuracy: 0.83458 |  0:00:14s\n","epoch 29 | loss: 0.33774 | val_0_accuracy: 0.82045 |  0:00:15s\n","epoch 30 | loss: 0.33767 | val_0_accuracy: 0.81546 |  0:00:15s\n","epoch 31 | loss: 0.33858 | val_0_accuracy: 0.82128 |  0:00:16s\n","epoch 32 | loss: 0.34156 | val_0_accuracy: 0.81214 |  0:00:16s\n","epoch 33 | loss: 0.3376  | val_0_accuracy: 0.83209 |  0:00:17s\n","epoch 34 | loss: 0.3333  | val_0_accuracy: 0.82876 |  0:00:17s\n","epoch 35 | loss: 0.33048 | val_0_accuracy: 0.84206 |  0:00:18s\n","epoch 36 | loss: 0.33446 | val_0_accuracy: 0.83375 |  0:00:18s\n","epoch 37 | loss: 0.32595 | val_0_accuracy: 0.82959 |  0:00:19s\n","epoch 38 | loss: 0.3298  | val_0_accuracy: 0.83541 |  0:00:19s\n","epoch 39 | loss: 0.32494 | val_0_accuracy: 0.83541 |  0:00:20s\n","epoch 40 | loss: 0.32482 | val_0_accuracy: 0.84705 |  0:00:20s\n","epoch 41 | loss: 0.32137 | val_0_accuracy: 0.83957 |  0:00:21s\n","epoch 42 | loss: 0.32057 | val_0_accuracy: 0.83874 |  0:00:21s\n","epoch 43 | loss: 0.32244 | val_0_accuracy: 0.84456 |  0:00:22s\n","epoch 44 | loss: 0.32373 | val_0_accuracy: 0.83375 |  0:00:22s\n","epoch 45 | loss: 0.31726 | val_0_accuracy: 0.84206 |  0:00:23s\n","epoch 46 | loss: 0.31726 | val_0_accuracy: 0.85702 |  0:00:23s\n","epoch 47 | loss: 0.31136 | val_0_accuracy: 0.83624 |  0:00:24s\n","epoch 48 | loss: 0.31916 | val_0_accuracy: 0.85204 |  0:00:24s\n","epoch 49 | loss: 0.31331 | val_0_accuracy: 0.84705 |  0:00:25s\n","epoch 50 | loss: 0.30786 | val_0_accuracy: 0.84871 |  0:00:25s\n","epoch 51 | loss: 0.31455 | val_0_accuracy: 0.84622 |  0:00:26s\n","epoch 52 | loss: 0.31462 | val_0_accuracy: 0.84123 |  0:00:26s\n","epoch 53 | loss: 0.31905 | val_0_accuracy: 0.85287 |  0:00:27s\n","epoch 54 | loss: 0.31062 | val_0_accuracy: 0.84206 |  0:00:27s\n","epoch 55 | loss: 0.30637 | val_0_accuracy: 0.85204 |  0:00:28s\n","epoch 56 | loss: 0.3067  | val_0_accuracy: 0.8537  |  0:00:28s\n","\n","Early stopping occurred at epoch 56 with best_epoch = 46 and best_val_0_accuracy = 0.85702\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-07-06 06:23:23,461] Trial 64 finished with value: 0.857024106400665 and parameters: {'n_d': 38, 'n_steps': 3, 'gamma': 1.463732173430068, 'n_independent': 3, 'n_shared': 3, 'momentum': 0.047671196393782936}. Best is trial 42 with value: 0.8728179551122195.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 0.59852 | val_0_accuracy: 0.51787 |  0:00:00s\n","epoch 1  | loss: 0.44457 | val_0_accuracy: 0.52203 |  0:00:00s\n","epoch 2  | loss: 0.40045 | val_0_accuracy: 0.57523 |  0:00:01s\n","epoch 3  | loss: 0.38489 | val_0_accuracy: 0.5478  |  0:00:01s\n","epoch 4  | loss: 0.37909 | val_0_accuracy: 0.58687 |  0:00:02s\n","epoch 5  | loss: 0.37648 | val_0_accuracy: 0.56442 |  0:00:02s\n","epoch 6  | loss: 0.36791 | val_0_accuracy: 0.59352 |  0:00:03s\n","epoch 7  | loss: 0.363   | val_0_accuracy: 0.63092 |  0:00:03s\n","epoch 8  | loss: 0.36443 | val_0_accuracy: 0.66584 |  0:00:04s\n","epoch 9  | loss: 0.35823 | val_0_accuracy: 0.62677 |  0:00:04s\n","epoch 10 | loss: 0.35331 | val_0_accuracy: 0.65835 |  0:00:04s\n","epoch 11 | loss: 0.3492  | val_0_accuracy: 0.68329 |  0:00:05s\n","epoch 12 | loss: 0.34921 | val_0_accuracy: 0.63342 |  0:00:05s\n","epoch 13 | loss: 0.33967 | val_0_accuracy: 0.67581 |  0:00:06s\n","epoch 14 | loss: 0.34438 | val_0_accuracy: 0.72319 |  0:00:06s\n","epoch 15 | loss: 0.33629 | val_0_accuracy: 0.73649 |  0:00:07s\n","epoch 16 | loss: 0.3374  | val_0_accuracy: 0.66417 |  0:00:07s\n","epoch 17 | loss: 0.33564 | val_0_accuracy: 0.72735 |  0:00:08s\n","epoch 18 | loss: 0.33376 | val_0_accuracy: 0.70574 |  0:00:08s\n","epoch 19 | loss: 0.33057 | val_0_accuracy: 0.73982 |  0:00:09s\n","epoch 20 | loss: 0.32733 | val_0_accuracy: 0.74647 |  0:00:09s\n","epoch 21 | loss: 0.32386 | val_0_accuracy: 0.74896 |  0:00:09s\n","epoch 22 | loss: 0.33015 | val_0_accuracy: 0.7315  |  0:00:10s\n","epoch 23 | loss: 0.32725 | val_0_accuracy: 0.75561 |  0:00:10s\n","epoch 24 | loss: 0.32275 | val_0_accuracy: 0.76642 |  0:00:11s\n","epoch 25 | loss: 0.32813 | val_0_accuracy: 0.7739  |  0:00:11s\n","epoch 26 | loss: 0.31971 | val_0_accuracy: 0.78637 |  0:00:12s\n","epoch 27 | loss: 0.32145 | val_0_accuracy: 0.77057 |  0:00:12s\n","epoch 28 | loss: 0.31887 | val_0_accuracy: 0.78138 |  0:00:13s\n","epoch 29 | loss: 0.32262 | val_0_accuracy: 0.80299 |  0:00:13s\n","epoch 30 | loss: 0.31884 | val_0_accuracy: 0.79717 |  0:00:13s\n","epoch 31 | loss: 0.32323 | val_0_accuracy: 0.81879 |  0:00:14s\n","epoch 32 | loss: 0.32601 | val_0_accuracy: 0.81546 |  0:00:14s\n","epoch 33 | loss: 0.32596 | val_0_accuracy: 0.80466 |  0:00:15s\n","epoch 34 | loss: 0.32043 | val_0_accuracy: 0.84622 |  0:00:15s\n","epoch 35 | loss: 0.31519 | val_0_accuracy: 0.8404  |  0:00:16s\n","epoch 36 | loss: 0.32136 | val_0_accuracy: 0.84456 |  0:00:16s\n","epoch 37 | loss: 0.31888 | val_0_accuracy: 0.84954 |  0:00:17s\n","epoch 38 | loss: 0.31399 | val_0_accuracy: 0.84289 |  0:00:17s\n","epoch 39 | loss: 0.31252 | val_0_accuracy: 0.84871 |  0:00:18s\n","epoch 40 | loss: 0.31225 | val_0_accuracy: 0.85619 |  0:00:18s\n","epoch 41 | loss: 0.31254 | val_0_accuracy: 0.85121 |  0:00:19s\n","epoch 42 | loss: 0.31711 | val_0_accuracy: 0.85786 |  0:00:19s\n","epoch 43 | loss: 0.31424 | val_0_accuracy: 0.84456 |  0:00:20s\n","epoch 44 | loss: 0.309   | val_0_accuracy: 0.84456 |  0:00:20s\n","epoch 45 | loss: 0.30887 | val_0_accuracy: 0.85037 |  0:00:21s\n","epoch 46 | loss: 0.3083  | val_0_accuracy: 0.85619 |  0:00:21s\n","epoch 47 | loss: 0.30886 | val_0_accuracy: 0.85204 |  0:00:21s\n","epoch 48 | loss: 0.30592 | val_0_accuracy: 0.85536 |  0:00:22s\n","epoch 49 | loss: 0.30383 | val_0_accuracy: 0.85121 |  0:00:22s\n","epoch 50 | loss: 0.30498 | val_0_accuracy: 0.85453 |  0:00:23s\n","epoch 51 | loss: 0.30075 | val_0_accuracy: 0.86118 |  0:00:23s\n","epoch 52 | loss: 0.30034 | val_0_accuracy: 0.84206 |  0:00:24s\n","epoch 53 | loss: 0.30171 | val_0_accuracy: 0.8537  |  0:00:24s\n","epoch 54 | loss: 0.30086 | val_0_accuracy: 0.85786 |  0:00:25s\n","epoch 55 | loss: 0.30273 | val_0_accuracy: 0.85453 |  0:00:25s\n","epoch 56 | loss: 0.30721 | val_0_accuracy: 0.85121 |  0:00:25s\n","epoch 57 | loss: 0.31083 | val_0_accuracy: 0.85786 |  0:00:26s\n","epoch 58 | loss: 0.30123 | val_0_accuracy: 0.85204 |  0:00:26s\n","epoch 59 | loss: 0.2976  | val_0_accuracy: 0.85869 |  0:00:27s\n","epoch 60 | loss: 0.29674 | val_0_accuracy: 0.86035 |  0:00:27s\n","epoch 61 | loss: 0.29623 | val_0_accuracy: 0.85204 |  0:00:28s\n","\n","Early stopping occurred at epoch 61 with best_epoch = 51 and best_val_0_accuracy = 0.86118\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-07-06 06:23:51,911] Trial 65 finished with value: 0.8611803823773898 and parameters: {'n_d': 46, 'n_steps': 3, 'gamma': 1.077303987165111, 'n_independent': 3, 'n_shared': 2, 'momentum': 0.03465731655197906}. Best is trial 42 with value: 0.8728179551122195.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 0.64324 | val_0_accuracy: 0.51205 |  0:00:00s\n","epoch 1  | loss: 0.48843 | val_0_accuracy: 0.51122 |  0:00:01s\n","epoch 2  | loss: 0.47407 | val_0_accuracy: 0.51953 |  0:00:01s\n","epoch 3  | loss: 0.45141 | val_0_accuracy: 0.52203 |  0:00:02s\n","epoch 4  | loss: 0.4342  | val_0_accuracy: 0.52868 |  0:00:02s\n","epoch 5  | loss: 0.41746 | val_0_accuracy: 0.52702 |  0:00:03s\n","epoch 6  | loss: 0.42963 | val_0_accuracy: 0.5611  |  0:00:03s\n","epoch 7  | loss: 0.4235  | val_0_accuracy: 0.59435 |  0:00:04s\n","epoch 8  | loss: 0.41452 | val_0_accuracy: 0.59601 |  0:00:05s\n","epoch 9  | loss: 0.41442 | val_0_accuracy: 0.62926 |  0:00:05s\n","epoch 10 | loss: 0.41232 | val_0_accuracy: 0.61679 |  0:00:06s\n","epoch 11 | loss: 0.41528 | val_0_accuracy: 0.62012 |  0:00:06s\n","epoch 12 | loss: 0.42269 | val_0_accuracy: 0.59684 |  0:00:07s\n","epoch 13 | loss: 0.41618 | val_0_accuracy: 0.70574 |  0:00:07s\n","epoch 14 | loss: 0.40938 | val_0_accuracy: 0.64589 |  0:00:08s\n","epoch 15 | loss: 0.40912 | val_0_accuracy: 0.6384  |  0:00:08s\n","epoch 16 | loss: 0.40679 | val_0_accuracy: 0.67581 |  0:00:09s\n","epoch 17 | loss: 0.40328 | val_0_accuracy: 0.68911 |  0:00:09s\n","epoch 18 | loss: 0.40076 | val_0_accuracy: 0.68412 |  0:00:10s\n","epoch 19 | loss: 0.39284 | val_0_accuracy: 0.70574 |  0:00:10s\n","epoch 20 | loss: 0.3902  | val_0_accuracy: 0.71488 |  0:00:11s\n","epoch 21 | loss: 0.3944  | val_0_accuracy: 0.69909 |  0:00:12s\n","epoch 22 | loss: 0.38436 | val_0_accuracy: 0.74065 |  0:00:12s\n","epoch 23 | loss: 0.38973 | val_0_accuracy: 0.72901 |  0:00:13s\n","epoch 24 | loss: 0.38918 | val_0_accuracy: 0.72485 |  0:00:13s\n","epoch 25 | loss: 0.38392 | val_0_accuracy: 0.69825 |  0:00:14s\n","epoch 26 | loss: 0.37981 | val_0_accuracy: 0.74397 |  0:00:14s\n","epoch 27 | loss: 0.37541 | val_0_accuracy: 0.74896 |  0:00:15s\n","epoch 28 | loss: 0.37174 | val_0_accuracy: 0.79385 |  0:00:15s\n","epoch 29 | loss: 0.37289 | val_0_accuracy: 0.81047 |  0:00:16s\n","epoch 30 | loss: 0.36844 | val_0_accuracy: 0.7847  |  0:00:17s\n","epoch 31 | loss: 0.36161 | val_0_accuracy: 0.80299 |  0:00:17s\n","epoch 32 | loss: 0.35448 | val_0_accuracy: 0.81463 |  0:00:18s\n","epoch 33 | loss: 0.35107 | val_0_accuracy: 0.8138  |  0:00:18s\n","epoch 34 | loss: 0.35232 | val_0_accuracy: 0.83209 |  0:00:19s\n","epoch 35 | loss: 0.34881 | val_0_accuracy: 0.81879 |  0:00:19s\n","epoch 36 | loss: 0.34948 | val_0_accuracy: 0.8404  |  0:00:20s\n","epoch 37 | loss: 0.34623 | val_0_accuracy: 0.83791 |  0:00:20s\n","epoch 38 | loss: 0.3458  | val_0_accuracy: 0.83209 |  0:00:21s\n","epoch 39 | loss: 0.34532 | val_0_accuracy: 0.84622 |  0:00:22s\n","epoch 40 | loss: 0.34232 | val_0_accuracy: 0.84705 |  0:00:22s\n","epoch 41 | loss: 0.33753 | val_0_accuracy: 0.84206 |  0:00:23s\n","epoch 42 | loss: 0.33972 | val_0_accuracy: 0.84954 |  0:00:23s\n","epoch 43 | loss: 0.33685 | val_0_accuracy: 0.85037 |  0:00:24s\n","epoch 44 | loss: 0.33108 | val_0_accuracy: 0.85121 |  0:00:24s\n","epoch 45 | loss: 0.33299 | val_0_accuracy: 0.84871 |  0:00:25s\n","epoch 46 | loss: 0.33556 | val_0_accuracy: 0.84954 |  0:00:25s\n","epoch 47 | loss: 0.33086 | val_0_accuracy: 0.84372 |  0:00:26s\n","epoch 48 | loss: 0.32846 | val_0_accuracy: 0.84871 |  0:00:26s\n","epoch 49 | loss: 0.33187 | val_0_accuracy: 0.86284 |  0:00:27s\n","epoch 50 | loss: 0.32781 | val_0_accuracy: 0.85619 |  0:00:28s\n","epoch 51 | loss: 0.3283  | val_0_accuracy: 0.86201 |  0:00:28s\n","epoch 52 | loss: 0.3248  | val_0_accuracy: 0.85619 |  0:00:29s\n","epoch 53 | loss: 0.32225 | val_0_accuracy: 0.85536 |  0:00:29s\n","epoch 54 | loss: 0.3242  | val_0_accuracy: 0.85619 |  0:00:30s\n","epoch 55 | loss: 0.32566 | val_0_accuracy: 0.8537  |  0:00:30s\n","epoch 56 | loss: 0.32421 | val_0_accuracy: 0.84788 |  0:00:31s\n","epoch 57 | loss: 0.33354 | val_0_accuracy: 0.85952 |  0:00:31s\n","epoch 58 | loss: 0.33221 | val_0_accuracy: 0.85287 |  0:00:32s\n","epoch 59 | loss: 0.32665 | val_0_accuracy: 0.85619 |  0:00:32s\n","\n","Early stopping occurred at epoch 59 with best_epoch = 49 and best_val_0_accuracy = 0.86284\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-07-06 06:24:25,161] Trial 66 finished with value: 0.8628428927680798 and parameters: {'n_d': 25, 'n_steps': 4, 'gamma': 1.947527828062569, 'n_independent': 2, 'n_shared': 3, 'momentum': 0.07768605501791695}. Best is trial 42 with value: 0.8728179551122195.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 0.61366 | val_0_accuracy: 0.54198 |  0:00:00s\n","epoch 1  | loss: 0.44972 | val_0_accuracy: 0.5212  |  0:00:01s\n","epoch 2  | loss: 0.41115 | val_0_accuracy: 0.52203 |  0:00:01s\n","epoch 3  | loss: 0.39968 | val_0_accuracy: 0.51704 |  0:00:02s\n","epoch 4  | loss: 0.38495 | val_0_accuracy: 0.51538 |  0:00:02s\n","epoch 5  | loss: 0.37488 | val_0_accuracy: 0.54447 |  0:00:03s\n","epoch 6  | loss: 0.3823  | val_0_accuracy: 0.52868 |  0:00:04s\n","epoch 7  | loss: 0.37105 | val_0_accuracy: 0.54447 |  0:00:04s\n","epoch 8  | loss: 0.36224 | val_0_accuracy: 0.59933 |  0:00:05s\n","epoch 9  | loss: 0.3599  | val_0_accuracy: 0.61596 |  0:00:05s\n","epoch 10 | loss: 0.3579  | val_0_accuracy: 0.6409  |  0:00:06s\n","epoch 11 | loss: 0.35237 | val_0_accuracy: 0.6542  |  0:00:06s\n","epoch 12 | loss: 0.35278 | val_0_accuracy: 0.7049  |  0:00:07s\n","epoch 13 | loss: 0.34863 | val_0_accuracy: 0.66417 |  0:00:08s\n","epoch 14 | loss: 0.3538  | val_0_accuracy: 0.68246 |  0:00:08s\n","epoch 15 | loss: 0.34553 | val_0_accuracy: 0.70574 |  0:00:09s\n","epoch 16 | loss: 0.36034 | val_0_accuracy: 0.72735 |  0:00:09s\n","epoch 17 | loss: 0.36995 | val_0_accuracy: 0.71405 |  0:00:10s\n","epoch 18 | loss: 0.36239 | val_0_accuracy: 0.72901 |  0:00:10s\n","epoch 19 | loss: 0.35723 | val_0_accuracy: 0.75561 |  0:00:11s\n","epoch 20 | loss: 0.35773 | val_0_accuracy: 0.76226 |  0:00:12s\n","epoch 21 | loss: 0.34537 | val_0_accuracy: 0.76475 |  0:00:12s\n","epoch 22 | loss: 0.3413  | val_0_accuracy: 0.76725 |  0:00:13s\n","epoch 23 | loss: 0.34466 | val_0_accuracy: 0.77722 |  0:00:13s\n","epoch 24 | loss: 0.33943 | val_0_accuracy: 0.78138 |  0:00:14s\n","epoch 25 | loss: 0.33657 | val_0_accuracy: 0.7739  |  0:00:15s\n","epoch 26 | loss: 0.33781 | val_0_accuracy: 0.80466 |  0:00:15s\n","epoch 27 | loss: 0.33783 | val_0_accuracy: 0.82045 |  0:00:16s\n","epoch 28 | loss: 0.33259 | val_0_accuracy: 0.80632 |  0:00:16s\n","epoch 29 | loss: 0.33335 | val_0_accuracy: 0.81962 |  0:00:17s\n","epoch 30 | loss: 0.32604 | val_0_accuracy: 0.82377 |  0:00:17s\n","epoch 31 | loss: 0.32902 | val_0_accuracy: 0.83292 |  0:00:18s\n","epoch 32 | loss: 0.32842 | val_0_accuracy: 0.83458 |  0:00:19s\n","epoch 33 | loss: 0.32954 | val_0_accuracy: 0.85287 |  0:00:19s\n","epoch 34 | loss: 0.32689 | val_0_accuracy: 0.84705 |  0:00:20s\n","epoch 35 | loss: 0.32301 | val_0_accuracy: 0.84539 |  0:00:20s\n","epoch 36 | loss: 0.32107 | val_0_accuracy: 0.8537  |  0:00:21s\n","epoch 37 | loss: 0.31861 | val_0_accuracy: 0.85786 |  0:00:21s\n","epoch 38 | loss: 0.32236 | val_0_accuracy: 0.86617 |  0:00:22s\n","epoch 39 | loss: 0.3206  | val_0_accuracy: 0.84622 |  0:00:23s\n","epoch 40 | loss: 0.3181  | val_0_accuracy: 0.86617 |  0:00:23s\n","epoch 41 | loss: 0.31339 | val_0_accuracy: 0.86201 |  0:00:24s\n","epoch 42 | loss: 0.31699 | val_0_accuracy: 0.85121 |  0:00:24s\n","epoch 43 | loss: 0.31551 | val_0_accuracy: 0.85536 |  0:00:25s\n","epoch 44 | loss: 0.31345 | val_0_accuracy: 0.86118 |  0:00:25s\n","epoch 45 | loss: 0.3194  | val_0_accuracy: 0.86534 |  0:00:26s\n","epoch 46 | loss: 0.31056 | val_0_accuracy: 0.85702 |  0:00:27s\n","epoch 47 | loss: 0.31502 | val_0_accuracy: 0.85869 |  0:00:27s\n","epoch 48 | loss: 0.30591 | val_0_accuracy: 0.86118 |  0:00:28s\n","\n","Early stopping occurred at epoch 48 with best_epoch = 38 and best_val_0_accuracy = 0.86617\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-07-06 06:24:53,686] Trial 67 finished with value: 0.8661679135494597 and parameters: {'n_d': 28, 'n_steps': 3, 'gamma': 1.3951759483991668, 'n_independent': 4, 'n_shared': 3, 'momentum': 0.09227778031548235}. Best is trial 42 with value: 0.8728179551122195.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 0.66605 | val_0_accuracy: 0.5611  |  0:00:00s\n","epoch 1  | loss: 0.47588 | val_0_accuracy: 0.50623 |  0:00:01s\n","epoch 2  | loss: 0.43471 | val_0_accuracy: 0.52203 |  0:00:01s\n","epoch 3  | loss: 0.41432 | val_0_accuracy: 0.51621 |  0:00:02s\n","epoch 4  | loss: 0.39381 | val_0_accuracy: 0.51621 |  0:00:02s\n","epoch 5  | loss: 0.38519 | val_0_accuracy: 0.51704 |  0:00:03s\n","epoch 6  | loss: 0.38145 | val_0_accuracy: 0.51621 |  0:00:03s\n","epoch 7  | loss: 0.37255 | val_0_accuracy: 0.51953 |  0:00:04s\n","epoch 8  | loss: 0.3684  | val_0_accuracy: 0.55777 |  0:00:04s\n","epoch 9  | loss: 0.36868 | val_0_accuracy: 0.55445 |  0:00:05s\n","epoch 10 | loss: 0.36808 | val_0_accuracy: 0.53283 |  0:00:05s\n","\n","Early stopping occurred at epoch 10 with best_epoch = 0 and best_val_0_accuracy = 0.5611\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-07-06 06:24:59,560] Trial 68 finished with value: 0.5610972568578554 and parameters: {'n_d': 36, 'n_steps': 3, 'gamma': 1.5689765035008256, 'n_independent': 4, 'n_shared': 2, 'momentum': 0.21001276940958055}. Best is trial 42 with value: 0.8728179551122195.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 1.61507 | val_0_accuracy: 0.532   |  0:00:01s\n","epoch 1  | loss: 0.7277  | val_0_accuracy: 0.6251  |  0:00:02s\n","epoch 2  | loss: 0.62976 | val_0_accuracy: 0.55278 |  0:00:04s\n","epoch 3  | loss: 0.56822 | val_0_accuracy: 0.63259 |  0:00:05s\n","epoch 4  | loss: 0.59633 | val_0_accuracy: 0.58188 |  0:00:06s\n","epoch 5  | loss: 0.53872 | val_0_accuracy: 0.54946 |  0:00:08s\n","epoch 6  | loss: 0.47522 | val_0_accuracy: 0.70407 |  0:00:09s\n","epoch 7  | loss: 0.4729  | val_0_accuracy: 0.54613 |  0:00:10s\n","epoch 8  | loss: 0.48551 | val_0_accuracy: 0.64505 |  0:00:12s\n","epoch 9  | loss: 0.45049 | val_0_accuracy: 0.63175 |  0:00:13s\n","epoch 10 | loss: 0.46763 | val_0_accuracy: 0.70989 |  0:00:14s\n","epoch 11 | loss: 0.46054 | val_0_accuracy: 0.72901 |  0:00:16s\n","epoch 12 | loss: 0.45176 | val_0_accuracy: 0.6783  |  0:00:17s\n","epoch 13 | loss: 0.44236 | val_0_accuracy: 0.65503 |  0:00:19s\n","epoch 14 | loss: 0.43079 | val_0_accuracy: 0.734   |  0:00:20s\n","epoch 15 | loss: 0.42823 | val_0_accuracy: 0.70906 |  0:00:21s\n","epoch 16 | loss: 0.41473 | val_0_accuracy: 0.7074  |  0:00:23s\n","epoch 17 | loss: 0.4265  | val_0_accuracy: 0.67747 |  0:00:24s\n","epoch 18 | loss: 0.4158  | val_0_accuracy: 0.70989 |  0:00:25s\n","epoch 19 | loss: 0.42813 | val_0_accuracy: 0.63342 |  0:00:27s\n","epoch 20 | loss: 0.42038 | val_0_accuracy: 0.70158 |  0:00:28s\n","epoch 21 | loss: 0.398   | val_0_accuracy: 0.71322 |  0:00:29s\n","epoch 22 | loss: 0.38929 | val_0_accuracy: 0.63009 |  0:00:31s\n","epoch 23 | loss: 0.39724 | val_0_accuracy: 0.66916 |  0:00:32s\n","epoch 24 | loss: 0.40419 | val_0_accuracy: 0.65337 |  0:00:33s\n","\n","Early stopping occurred at epoch 24 with best_epoch = 14 and best_val_0_accuracy = 0.734\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-07-06 06:25:34,225] Trial 69 finished with value: 0.7339983374896093 and parameters: {'n_d': 52, 'n_steps': 9, 'gamma': 1.3226314526070844, 'n_independent': 4, 'n_shared': 3, 'momentum': 0.1180669636578225}. Best is trial 42 with value: 0.8728179551122195.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 0.81929 | val_0_accuracy: 0.51122 |  0:00:00s\n","epoch 1  | loss: 0.48537 | val_0_accuracy: 0.57024 |  0:00:01s\n","epoch 2  | loss: 0.44809 | val_0_accuracy: 0.55694 |  0:00:01s\n","epoch 3  | loss: 0.41802 | val_0_accuracy: 0.53533 |  0:00:02s\n","epoch 4  | loss: 0.39566 | val_0_accuracy: 0.63924 |  0:00:02s\n","epoch 5  | loss: 0.37963 | val_0_accuracy: 0.62012 |  0:00:03s\n","epoch 6  | loss: 0.37146 | val_0_accuracy: 0.5586  |  0:00:03s\n","epoch 7  | loss: 0.36509 | val_0_accuracy: 0.54946 |  0:00:04s\n","epoch 8  | loss: 0.36713 | val_0_accuracy: 0.59102 |  0:00:04s\n","epoch 9  | loss: 0.35816 | val_0_accuracy: 0.6276  |  0:00:05s\n","epoch 10 | loss: 0.36098 | val_0_accuracy: 0.6276  |  0:00:06s\n","epoch 11 | loss: 0.35722 | val_0_accuracy: 0.6409  |  0:00:06s\n","epoch 12 | loss: 0.35268 | val_0_accuracy: 0.65254 |  0:00:07s\n","epoch 13 | loss: 0.36096 | val_0_accuracy: 0.68329 |  0:00:07s\n","epoch 14 | loss: 0.35288 | val_0_accuracy: 0.69493 |  0:00:08s\n","epoch 15 | loss: 0.34624 | val_0_accuracy: 0.70241 |  0:00:08s\n","epoch 16 | loss: 0.35017 | val_0_accuracy: 0.66584 |  0:00:09s\n","epoch 17 | loss: 0.34756 | val_0_accuracy: 0.66417 |  0:00:09s\n","epoch 18 | loss: 0.34607 | val_0_accuracy: 0.7049  |  0:00:10s\n","epoch 19 | loss: 0.34725 | val_0_accuracy: 0.74231 |  0:00:11s\n","epoch 20 | loss: 0.34748 | val_0_accuracy: 0.73566 |  0:00:11s\n","epoch 21 | loss: 0.34265 | val_0_accuracy: 0.73317 |  0:00:12s\n","epoch 22 | loss: 0.3408  | val_0_accuracy: 0.7581  |  0:00:12s\n","epoch 23 | loss: 0.33918 | val_0_accuracy: 0.75894 |  0:00:13s\n","epoch 24 | loss: 0.33349 | val_0_accuracy: 0.76143 |  0:00:13s\n","epoch 25 | loss: 0.34044 | val_0_accuracy: 0.79717 |  0:00:14s\n","epoch 26 | loss: 0.33849 | val_0_accuracy: 0.798   |  0:00:14s\n","epoch 27 | loss: 0.34288 | val_0_accuracy: 0.79052 |  0:00:15s\n","epoch 28 | loss: 0.33407 | val_0_accuracy: 0.7847  |  0:00:16s\n","epoch 29 | loss: 0.33306 | val_0_accuracy: 0.81879 |  0:00:16s\n","epoch 30 | loss: 0.33063 | val_0_accuracy: 0.83541 |  0:00:17s\n","epoch 31 | loss: 0.32564 | val_0_accuracy: 0.82544 |  0:00:17s\n","epoch 32 | loss: 0.33271 | val_0_accuracy: 0.84123 |  0:00:18s\n","epoch 33 | loss: 0.33129 | val_0_accuracy: 0.84456 |  0:00:18s\n","epoch 34 | loss: 0.32265 | val_0_accuracy: 0.83624 |  0:00:19s\n","epoch 35 | loss: 0.32745 | val_0_accuracy: 0.82461 |  0:00:19s\n","epoch 36 | loss: 0.32341 | val_0_accuracy: 0.84705 |  0:00:20s\n","epoch 37 | loss: 0.32116 | val_0_accuracy: 0.84456 |  0:00:20s\n","epoch 38 | loss: 0.32575 | val_0_accuracy: 0.84871 |  0:00:21s\n","epoch 39 | loss: 0.31891 | val_0_accuracy: 0.84788 |  0:00:22s\n","epoch 40 | loss: 0.32062 | val_0_accuracy: 0.84123 |  0:00:22s\n","epoch 41 | loss: 0.32513 | val_0_accuracy: 0.84622 |  0:00:23s\n","epoch 42 | loss: 0.32066 | val_0_accuracy: 0.85536 |  0:00:23s\n","epoch 43 | loss: 0.3248  | val_0_accuracy: 0.85536 |  0:00:24s\n","epoch 44 | loss: 0.31613 | val_0_accuracy: 0.84206 |  0:00:24s\n","epoch 45 | loss: 0.31961 | val_0_accuracy: 0.84622 |  0:00:25s\n","epoch 46 | loss: 0.32059 | val_0_accuracy: 0.85121 |  0:00:25s\n","epoch 47 | loss: 0.31344 | val_0_accuracy: 0.85121 |  0:00:26s\n","epoch 48 | loss: 0.31404 | val_0_accuracy: 0.85619 |  0:00:27s\n","epoch 49 | loss: 0.31928 | val_0_accuracy: 0.85536 |  0:00:27s\n","epoch 50 | loss: 0.32193 | val_0_accuracy: 0.86201 |  0:00:28s\n","epoch 51 | loss: 0.32398 | val_0_accuracy: 0.84788 |  0:00:28s\n","epoch 52 | loss: 0.32003 | val_0_accuracy: 0.85204 |  0:00:29s\n","epoch 53 | loss: 0.31498 | val_0_accuracy: 0.85869 |  0:00:29s\n","epoch 54 | loss: 0.31112 | val_0_accuracy: 0.85287 |  0:00:30s\n","epoch 55 | loss: 0.30873 | val_0_accuracy: 0.85536 |  0:00:31s\n","epoch 56 | loss: 0.30779 | val_0_accuracy: 0.85453 |  0:00:31s\n","epoch 57 | loss: 0.30809 | val_0_accuracy: 0.85786 |  0:00:32s\n","epoch 58 | loss: 0.3099  | val_0_accuracy: 0.86035 |  0:00:32s\n","epoch 59 | loss: 0.31111 | val_0_accuracy: 0.86035 |  0:00:33s\n","epoch 60 | loss: 0.31085 | val_0_accuracy: 0.86284 |  0:00:33s\n","epoch 61 | loss: 0.30497 | val_0_accuracy: 0.84705 |  0:00:34s\n","epoch 62 | loss: 0.30896 | val_0_accuracy: 0.85453 |  0:00:34s\n","epoch 63 | loss: 0.30875 | val_0_accuracy: 0.84871 |  0:00:35s\n","epoch 64 | loss: 0.30502 | val_0_accuracy: 0.85037 |  0:00:35s\n","epoch 65 | loss: 0.30874 | val_0_accuracy: 0.84871 |  0:00:36s\n","epoch 66 | loss: 0.3064  | val_0_accuracy: 0.85536 |  0:00:37s\n","epoch 67 | loss: 0.30824 | val_0_accuracy: 0.85952 |  0:00:37s\n","epoch 68 | loss: 0.30711 | val_0_accuracy: 0.85702 |  0:00:38s\n","epoch 69 | loss: 0.30195 | val_0_accuracy: 0.85869 |  0:00:38s\n","epoch 70 | loss: 0.30173 | val_0_accuracy: 0.84871 |  0:00:39s\n","\n","Early stopping occurred at epoch 70 with best_epoch = 60 and best_val_0_accuracy = 0.86284\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-07-06 06:26:13,763] Trial 70 finished with value: 0.8628428927680798 and parameters: {'n_d': 58, 'n_steps': 4, 'gamma': 1.1465493782675997, 'n_independent': 3, 'n_shared': 2, 'momentum': 0.23035670108496567}. Best is trial 42 with value: 0.8728179551122195.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 0.76096 | val_0_accuracy: 0.50208 |  0:00:00s\n","epoch 1  | loss: 0.50075 | val_0_accuracy: 0.48795 |  0:00:01s\n","epoch 2  | loss: 0.44745 | val_0_accuracy: 0.54281 |  0:00:02s\n","epoch 3  | loss: 0.42506 | val_0_accuracy: 0.53948 |  0:00:02s\n","epoch 4  | loss: 0.40078 | val_0_accuracy: 0.53533 |  0:00:03s\n","epoch 5  | loss: 0.39638 | val_0_accuracy: 0.5453  |  0:00:04s\n","epoch 6  | loss: 0.38683 | val_0_accuracy: 0.56858 |  0:00:04s\n","epoch 7  | loss: 0.38157 | val_0_accuracy: 0.55611 |  0:00:05s\n","epoch 8  | loss: 0.38012 | val_0_accuracy: 0.59601 |  0:00:06s\n","epoch 9  | loss: 0.3806  | val_0_accuracy: 0.61097 |  0:00:06s\n","epoch 10 | loss: 0.37568 | val_0_accuracy: 0.6384  |  0:00:07s\n","epoch 11 | loss: 0.36886 | val_0_accuracy: 0.67332 |  0:00:08s\n","epoch 12 | loss: 0.36355 | val_0_accuracy: 0.65004 |  0:00:09s\n","epoch 13 | loss: 0.36046 | val_0_accuracy: 0.66002 |  0:00:09s\n","epoch 14 | loss: 0.35465 | val_0_accuracy: 0.6675  |  0:00:10s\n","epoch 15 | loss: 0.35389 | val_0_accuracy: 0.69327 |  0:00:11s\n","epoch 16 | loss: 0.35795 | val_0_accuracy: 0.74314 |  0:00:11s\n","epoch 17 | loss: 0.3572  | val_0_accuracy: 0.73566 |  0:00:12s\n","epoch 18 | loss: 0.35476 | val_0_accuracy: 0.71904 |  0:00:13s\n","epoch 19 | loss: 0.34501 | val_0_accuracy: 0.7473  |  0:00:13s\n","epoch 20 | loss: 0.34739 | val_0_accuracy: 0.70989 |  0:00:14s\n","epoch 21 | loss: 0.3468  | val_0_accuracy: 0.72901 |  0:00:15s\n","epoch 22 | loss: 0.34641 | val_0_accuracy: 0.73483 |  0:00:15s\n","epoch 23 | loss: 0.34422 | val_0_accuracy: 0.73067 |  0:00:16s\n","epoch 24 | loss: 0.34372 | val_0_accuracy: 0.74979 |  0:00:17s\n","epoch 25 | loss: 0.33806 | val_0_accuracy: 0.77556 |  0:00:18s\n","epoch 26 | loss: 0.33922 | val_0_accuracy: 0.79052 |  0:00:18s\n","epoch 27 | loss: 0.3333  | val_0_accuracy: 0.79135 |  0:00:19s\n","epoch 28 | loss: 0.33502 | val_0_accuracy: 0.79884 |  0:00:20s\n","epoch 29 | loss: 0.33332 | val_0_accuracy: 0.80632 |  0:00:20s\n","epoch 30 | loss: 0.33327 | val_0_accuracy: 0.83624 |  0:00:21s\n","epoch 31 | loss: 0.33529 | val_0_accuracy: 0.82461 |  0:00:22s\n","epoch 32 | loss: 0.33244 | val_0_accuracy: 0.8404  |  0:00:22s\n","epoch 33 | loss: 0.33536 | val_0_accuracy: 0.84372 |  0:00:23s\n","epoch 34 | loss: 0.33578 | val_0_accuracy: 0.84289 |  0:00:24s\n","epoch 35 | loss: 0.34224 | val_0_accuracy: 0.83375 |  0:00:24s\n","epoch 36 | loss: 0.33656 | val_0_accuracy: 0.84871 |  0:00:25s\n","epoch 37 | loss: 0.33305 | val_0_accuracy: 0.83624 |  0:00:26s\n","epoch 38 | loss: 0.32905 | val_0_accuracy: 0.84539 |  0:00:27s\n","epoch 39 | loss: 0.32948 | val_0_accuracy: 0.84871 |  0:00:27s\n","epoch 40 | loss: 0.32601 | val_0_accuracy: 0.85952 |  0:00:28s\n","epoch 41 | loss: 0.32995 | val_0_accuracy: 0.8537  |  0:00:29s\n","epoch 42 | loss: 0.3264  | val_0_accuracy: 0.85287 |  0:00:29s\n","epoch 43 | loss: 0.32906 | val_0_accuracy: 0.85453 |  0:00:30s\n","epoch 44 | loss: 0.32673 | val_0_accuracy: 0.85204 |  0:00:31s\n","epoch 45 | loss: 0.32813 | val_0_accuracy: 0.84954 |  0:00:31s\n","epoch 46 | loss: 0.32457 | val_0_accuracy: 0.85786 |  0:00:32s\n","epoch 47 | loss: 0.31907 | val_0_accuracy: 0.8537  |  0:00:33s\n","epoch 48 | loss: 0.31667 | val_0_accuracy: 0.85453 |  0:00:34s\n","epoch 49 | loss: 0.32071 | val_0_accuracy: 0.82959 |  0:00:34s\n","epoch 50 | loss: 0.32155 | val_0_accuracy: 0.86035 |  0:00:35s\n","epoch 51 | loss: 0.3192  | val_0_accuracy: 0.85204 |  0:00:36s\n","epoch 52 | loss: 0.31368 | val_0_accuracy: 0.86367 |  0:00:36s\n","epoch 53 | loss: 0.31505 | val_0_accuracy: 0.86035 |  0:00:37s\n","epoch 54 | loss: 0.31412 | val_0_accuracy: 0.85952 |  0:00:38s\n","epoch 55 | loss: 0.31113 | val_0_accuracy: 0.84954 |  0:00:38s\n","epoch 56 | loss: 0.31668 | val_0_accuracy: 0.85702 |  0:00:39s\n","epoch 57 | loss: 0.31286 | val_0_accuracy: 0.85869 |  0:00:40s\n","epoch 58 | loss: 0.30844 | val_0_accuracy: 0.84456 |  0:00:40s\n","epoch 59 | loss: 0.30718 | val_0_accuracy: 0.85952 |  0:00:41s\n","epoch 60 | loss: 0.31162 | val_0_accuracy: 0.85952 |  0:00:42s\n","epoch 61 | loss: 0.30772 | val_0_accuracy: 0.86534 |  0:00:42s\n","epoch 62 | loss: 0.30967 | val_0_accuracy: 0.85287 |  0:00:43s\n","epoch 63 | loss: 0.30739 | val_0_accuracy: 0.86035 |  0:00:44s\n","epoch 64 | loss: 0.30856 | val_0_accuracy: 0.87199 |  0:00:45s\n","epoch 65 | loss: 0.30586 | val_0_accuracy: 0.85702 |  0:00:45s\n","epoch 66 | loss: 0.31087 | val_0_accuracy: 0.86451 |  0:00:46s\n","epoch 67 | loss: 0.30451 | val_0_accuracy: 0.85869 |  0:00:47s\n","epoch 68 | loss: 0.30356 | val_0_accuracy: 0.86035 |  0:00:47s\n","epoch 69 | loss: 0.30048 | val_0_accuracy: 0.85287 |  0:00:48s\n","epoch 70 | loss: 0.30621 | val_0_accuracy: 0.8537  |  0:00:49s\n","epoch 71 | loss: 0.30589 | val_0_accuracy: 0.85702 |  0:00:49s\n","epoch 72 | loss: 0.30302 | val_0_accuracy: 0.85702 |  0:00:50s\n","epoch 73 | loss: 0.30411 | val_0_accuracy: 0.85619 |  0:00:51s\n","epoch 74 | loss: 0.30519 | val_0_accuracy: 0.85702 |  0:00:52s\n","\n","Early stopping occurred at epoch 74 with best_epoch = 64 and best_val_0_accuracy = 0.87199\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-07-06 06:27:06,170] Trial 71 finished with value: 0.8719866999168745 and parameters: {'n_d': 41, 'n_steps': 4, 'gamma': 1.1809943887495624, 'n_independent': 3, 'n_shared': 4, 'momentum': 0.05848393731104244}. Best is trial 42 with value: 0.8728179551122195.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 1.12758 | val_0_accuracy: 0.532   |  0:00:00s\n","epoch 1  | loss: 0.63979 | val_0_accuracy: 0.5586  |  0:00:01s\n","epoch 2  | loss: 0.49033 | val_0_accuracy: 0.54697 |  0:00:02s\n","epoch 3  | loss: 0.45118 | val_0_accuracy: 0.52702 |  0:00:03s\n","epoch 4  | loss: 0.43695 | val_0_accuracy: 0.53865 |  0:00:04s\n","epoch 5  | loss: 0.42433 | val_0_accuracy: 0.53533 |  0:00:05s\n","epoch 6  | loss: 0.42675 | val_0_accuracy: 0.5611  |  0:00:06s\n","epoch 7  | loss: 0.42832 | val_0_accuracy: 0.56775 |  0:00:07s\n","epoch 8  | loss: 0.39958 | val_0_accuracy: 0.53533 |  0:00:08s\n","epoch 9  | loss: 0.39978 | val_0_accuracy: 0.5611  |  0:00:09s\n","epoch 10 | loss: 0.39244 | val_0_accuracy: 0.65004 |  0:00:10s\n","epoch 11 | loss: 0.38872 | val_0_accuracy: 0.64339 |  0:00:11s\n","epoch 12 | loss: 0.3785  | val_0_accuracy: 0.6542  |  0:00:12s\n","epoch 13 | loss: 0.37528 | val_0_accuracy: 0.71654 |  0:00:13s\n","epoch 14 | loss: 0.39321 | val_0_accuracy: 0.6143  |  0:00:14s\n","epoch 15 | loss: 0.37713 | val_0_accuracy: 0.6409  |  0:00:15s\n","epoch 16 | loss: 0.39253 | val_0_accuracy: 0.74148 |  0:00:16s\n","epoch 17 | loss: 0.3743  | val_0_accuracy: 0.72735 |  0:00:17s\n","epoch 18 | loss: 0.37104 | val_0_accuracy: 0.7448  |  0:00:18s\n","epoch 19 | loss: 0.37131 | val_0_accuracy: 0.7473  |  0:00:19s\n","epoch 20 | loss: 0.3653  | val_0_accuracy: 0.75395 |  0:00:20s\n","epoch 21 | loss: 0.35182 | val_0_accuracy: 0.76309 |  0:00:21s\n","epoch 22 | loss: 0.35527 | val_0_accuracy: 0.76808 |  0:00:22s\n","epoch 23 | loss: 0.35278 | val_0_accuracy: 0.74065 |  0:00:23s\n","epoch 24 | loss: 0.34511 | val_0_accuracy: 0.7207  |  0:00:24s\n","epoch 25 | loss: 0.34274 | val_0_accuracy: 0.76808 |  0:00:25s\n","epoch 26 | loss: 0.34061 | val_0_accuracy: 0.78387 |  0:00:26s\n","epoch 27 | loss: 0.33877 | val_0_accuracy: 0.77556 |  0:00:27s\n","epoch 28 | loss: 0.34249 | val_0_accuracy: 0.76974 |  0:00:28s\n","epoch 29 | loss: 0.33491 | val_0_accuracy: 0.79551 |  0:00:29s\n","epoch 30 | loss: 0.3369  | val_0_accuracy: 0.81629 |  0:00:30s\n","epoch 31 | loss: 0.33653 | val_0_accuracy: 0.82377 |  0:00:31s\n","epoch 32 | loss: 0.3367  | val_0_accuracy: 0.83126 |  0:00:32s\n","epoch 33 | loss: 0.33762 | val_0_accuracy: 0.81796 |  0:00:33s\n","epoch 34 | loss: 0.34073 | val_0_accuracy: 0.84123 |  0:00:34s\n","epoch 35 | loss: 0.33823 | val_0_accuracy: 0.83624 |  0:00:35s\n","epoch 36 | loss: 0.33569 | val_0_accuracy: 0.84289 |  0:00:36s\n","epoch 37 | loss: 0.33623 | val_0_accuracy: 0.83707 |  0:00:37s\n","epoch 38 | loss: 0.33474 | val_0_accuracy: 0.84456 |  0:00:38s\n","epoch 39 | loss: 0.33622 | val_0_accuracy: 0.84539 |  0:00:39s\n","epoch 40 | loss: 0.33061 | val_0_accuracy: 0.84622 |  0:00:40s\n","epoch 41 | loss: 0.33331 | val_0_accuracy: 0.84622 |  0:00:41s\n","epoch 42 | loss: 0.33331 | val_0_accuracy: 0.8537  |  0:00:42s\n","epoch 43 | loss: 0.32912 | val_0_accuracy: 0.85453 |  0:00:43s\n","epoch 44 | loss: 0.32392 | val_0_accuracy: 0.85786 |  0:00:44s\n","epoch 45 | loss: 0.32816 | val_0_accuracy: 0.84788 |  0:00:45s\n","epoch 46 | loss: 0.32284 | val_0_accuracy: 0.84871 |  0:00:46s\n","epoch 47 | loss: 0.32683 | val_0_accuracy: 0.85287 |  0:00:46s\n","epoch 48 | loss: 0.32346 | val_0_accuracy: 0.84954 |  0:00:47s\n","epoch 49 | loss: 0.32172 | val_0_accuracy: 0.83541 |  0:00:48s\n","epoch 50 | loss: 0.33218 | val_0_accuracy: 0.84788 |  0:00:49s\n","epoch 51 | loss: 0.32422 | val_0_accuracy: 0.86118 |  0:00:50s\n","epoch 52 | loss: 0.32394 | val_0_accuracy: 0.84622 |  0:00:51s\n","epoch 53 | loss: 0.32531 | val_0_accuracy: 0.85037 |  0:00:52s\n","epoch 54 | loss: 0.32622 | val_0_accuracy: 0.85619 |  0:00:53s\n","epoch 55 | loss: 0.32117 | val_0_accuracy: 0.85453 |  0:00:54s\n","epoch 56 | loss: 0.31736 | val_0_accuracy: 0.85536 |  0:00:55s\n","epoch 57 | loss: 0.32121 | val_0_accuracy: 0.84456 |  0:00:56s\n","epoch 58 | loss: 0.33684 | val_0_accuracy: 0.84123 |  0:00:57s\n","epoch 59 | loss: 0.34079 | val_0_accuracy: 0.84705 |  0:00:58s\n","epoch 60 | loss: 0.32784 | val_0_accuracy: 0.84622 |  0:00:59s\n","epoch 61 | loss: 0.3262  | val_0_accuracy: 0.867   |  0:01:00s\n","epoch 62 | loss: 0.31649 | val_0_accuracy: 0.86284 |  0:01:01s\n","epoch 63 | loss: 0.3204  | val_0_accuracy: 0.87199 |  0:01:02s\n","epoch 64 | loss: 0.31531 | val_0_accuracy: 0.87199 |  0:01:03s\n","epoch 65 | loss: 0.31342 | val_0_accuracy: 0.85952 |  0:01:04s\n","epoch 66 | loss: 0.31722 | val_0_accuracy: 0.86118 |  0:01:05s\n","epoch 67 | loss: 0.30835 | val_0_accuracy: 0.85037 |  0:01:06s\n","epoch 68 | loss: 0.30831 | val_0_accuracy: 0.86534 |  0:01:07s\n","epoch 69 | loss: 0.31314 | val_0_accuracy: 0.86367 |  0:01:08s\n","epoch 70 | loss: 0.31061 | val_0_accuracy: 0.86118 |  0:01:09s\n","epoch 71 | loss: 0.30615 | val_0_accuracy: 0.82461 |  0:01:10s\n","epoch 72 | loss: 0.31364 | val_0_accuracy: 0.86534 |  0:01:10s\n","epoch 73 | loss: 0.3164  | val_0_accuracy: 0.85786 |  0:01:11s\n","\n","Early stopping occurred at epoch 73 with best_epoch = 63 and best_val_0_accuracy = 0.87199\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-07-06 06:28:18,632] Trial 72 finished with value: 0.8719866999168745 and parameters: {'n_d': 42, 'n_steps': 7, 'gamma': 1.179009772783236, 'n_independent': 3, 'n_shared': 3, 'momentum': 0.05814532793469426}. Best is trial 42 with value: 0.8728179551122195.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 0.9898  | val_0_accuracy: 0.55029 |  0:00:00s\n","epoch 1  | loss: 0.5645  | val_0_accuracy: 0.55694 |  0:00:01s\n","epoch 2  | loss: 0.50531 | val_0_accuracy: 0.53367 |  0:00:02s\n","epoch 3  | loss: 0.46308 | val_0_accuracy: 0.51953 |  0:00:03s\n","epoch 4  | loss: 0.43651 | val_0_accuracy: 0.56359 |  0:00:04s\n","epoch 5  | loss: 0.41971 | val_0_accuracy: 0.53367 |  0:00:05s\n","epoch 6  | loss: 0.40221 | val_0_accuracy: 0.64838 |  0:00:06s\n","epoch 7  | loss: 0.39345 | val_0_accuracy: 0.56525 |  0:00:07s\n","epoch 8  | loss: 0.39518 | val_0_accuracy: 0.60266 |  0:00:08s\n","epoch 9  | loss: 0.39347 | val_0_accuracy: 0.62012 |  0:00:09s\n","epoch 10 | loss: 0.38629 | val_0_accuracy: 0.66002 |  0:00:10s\n","epoch 11 | loss: 0.38108 | val_0_accuracy: 0.68828 |  0:00:11s\n","epoch 12 | loss: 0.38404 | val_0_accuracy: 0.67415 |  0:00:12s\n","epoch 13 | loss: 0.37908 | val_0_accuracy: 0.67664 |  0:00:13s\n","epoch 14 | loss: 0.3725  | val_0_accuracy: 0.6783  |  0:00:14s\n","epoch 15 | loss: 0.36676 | val_0_accuracy: 0.71239 |  0:00:15s\n","epoch 16 | loss: 0.36225 | val_0_accuracy: 0.69493 |  0:00:16s\n","epoch 17 | loss: 0.35866 | val_0_accuracy: 0.73317 |  0:00:17s\n","epoch 18 | loss: 0.36552 | val_0_accuracy: 0.72901 |  0:00:18s\n","epoch 19 | loss: 0.35599 | val_0_accuracy: 0.73982 |  0:00:19s\n","epoch 20 | loss: 0.35544 | val_0_accuracy: 0.73067 |  0:00:20s\n","epoch 21 | loss: 0.35772 | val_0_accuracy: 0.75229 |  0:00:21s\n","epoch 22 | loss: 0.36188 | val_0_accuracy: 0.69576 |  0:00:22s\n","epoch 23 | loss: 0.35766 | val_0_accuracy: 0.75727 |  0:00:23s\n","epoch 24 | loss: 0.35263 | val_0_accuracy: 0.78138 |  0:00:24s\n","epoch 25 | loss: 0.35852 | val_0_accuracy: 0.79135 |  0:00:25s\n","epoch 26 | loss: 0.35312 | val_0_accuracy: 0.79219 |  0:00:26s\n","epoch 27 | loss: 0.35417 | val_0_accuracy: 0.81047 |  0:00:27s\n","epoch 28 | loss: 0.36035 | val_0_accuracy: 0.81047 |  0:00:28s\n","epoch 29 | loss: 0.35895 | val_0_accuracy: 0.81712 |  0:00:29s\n","epoch 30 | loss: 0.35428 | val_0_accuracy: 0.8271  |  0:00:30s\n","epoch 31 | loss: 0.35377 | val_0_accuracy: 0.80549 |  0:00:31s\n","epoch 32 | loss: 0.35698 | val_0_accuracy: 0.82377 |  0:00:31s\n","epoch 33 | loss: 0.35728 | val_0_accuracy: 0.83126 |  0:00:32s\n","epoch 34 | loss: 0.35923 | val_0_accuracy: 0.8271  |  0:00:33s\n","epoch 35 | loss: 0.34992 | val_0_accuracy: 0.82959 |  0:00:34s\n","epoch 36 | loss: 0.35071 | val_0_accuracy: 0.83458 |  0:00:35s\n","epoch 37 | loss: 0.3512  | val_0_accuracy: 0.83541 |  0:00:36s\n","epoch 38 | loss: 0.35001 | val_0_accuracy: 0.83375 |  0:00:37s\n","epoch 39 | loss: 0.34431 | val_0_accuracy: 0.84456 |  0:00:38s\n","epoch 40 | loss: 0.34723 | val_0_accuracy: 0.83292 |  0:00:39s\n","epoch 41 | loss: 0.34485 | val_0_accuracy: 0.84622 |  0:00:40s\n","epoch 42 | loss: 0.3476  | val_0_accuracy: 0.83874 |  0:00:41s\n","epoch 43 | loss: 0.33961 | val_0_accuracy: 0.84372 |  0:00:42s\n","epoch 44 | loss: 0.33015 | val_0_accuracy: 0.85204 |  0:00:43s\n","epoch 45 | loss: 0.32776 | val_0_accuracy: 0.85037 |  0:00:44s\n","epoch 46 | loss: 0.33233 | val_0_accuracy: 0.85121 |  0:00:45s\n","epoch 47 | loss: 0.33256 | val_0_accuracy: 0.85453 |  0:00:46s\n","epoch 48 | loss: 0.33349 | val_0_accuracy: 0.86118 |  0:00:47s\n","epoch 49 | loss: 0.33476 | val_0_accuracy: 0.8537  |  0:00:48s\n","epoch 50 | loss: 0.33361 | val_0_accuracy: 0.85204 |  0:00:49s\n","epoch 51 | loss: 0.32545 | val_0_accuracy: 0.85869 |  0:00:50s\n","epoch 52 | loss: 0.32628 | val_0_accuracy: 0.85619 |  0:00:51s\n","epoch 53 | loss: 0.31704 | val_0_accuracy: 0.85952 |  0:00:52s\n","epoch 54 | loss: 0.32526 | val_0_accuracy: 0.85453 |  0:00:53s\n","epoch 55 | loss: 0.32152 | val_0_accuracy: 0.85869 |  0:00:54s\n","epoch 56 | loss: 0.31716 | val_0_accuracy: 0.84705 |  0:00:55s\n","epoch 57 | loss: 0.31847 | val_0_accuracy: 0.86367 |  0:00:56s\n","epoch 58 | loss: 0.31655 | val_0_accuracy: 0.86617 |  0:00:56s\n","epoch 59 | loss: 0.31851 | val_0_accuracy: 0.85702 |  0:00:57s\n","epoch 60 | loss: 0.32556 | val_0_accuracy: 0.85702 |  0:00:58s\n","epoch 61 | loss: 0.32652 | val_0_accuracy: 0.85536 |  0:00:59s\n","epoch 62 | loss: 0.314   | val_0_accuracy: 0.86035 |  0:01:00s\n","epoch 63 | loss: 0.31832 | val_0_accuracy: 0.85952 |  0:01:01s\n","epoch 64 | loss: 0.31214 | val_0_accuracy: 0.85869 |  0:01:02s\n","epoch 65 | loss: 0.31312 | val_0_accuracy: 0.86949 |  0:01:03s\n","epoch 66 | loss: 0.31131 | val_0_accuracy: 0.86866 |  0:01:04s\n","epoch 67 | loss: 0.30997 | val_0_accuracy: 0.85952 |  0:01:05s\n","epoch 68 | loss: 0.31327 | val_0_accuracy: 0.85453 |  0:01:06s\n","epoch 69 | loss: 0.31378 | val_0_accuracy: 0.86284 |  0:01:07s\n","epoch 70 | loss: 0.30768 | val_0_accuracy: 0.86949 |  0:01:08s\n","epoch 71 | loss: 0.30539 | val_0_accuracy: 0.86284 |  0:01:09s\n","epoch 72 | loss: 0.30398 | val_0_accuracy: 0.85952 |  0:01:10s\n","epoch 73 | loss: 0.30252 | val_0_accuracy: 0.85869 |  0:01:11s\n","epoch 74 | loss: 0.30816 | val_0_accuracy: 0.83874 |  0:01:12s\n","epoch 75 | loss: 0.30749 | val_0_accuracy: 0.86617 |  0:01:13s\n","\n","Early stopping occurred at epoch 75 with best_epoch = 65 and best_val_0_accuracy = 0.86949\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-07-06 06:29:32,610] Trial 73 finished with value: 0.8694929343308395 and parameters: {'n_d': 40, 'n_steps': 7, 'gamma': 1.123543738611057, 'n_independent': 3, 'n_shared': 3, 'momentum': 0.026978892614830857}. Best is trial 42 with value: 0.8728179551122195.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 1.17317 | val_0_accuracy: 0.52037 |  0:00:01s\n","epoch 1  | loss: 0.57366 | val_0_accuracy: 0.55362 |  0:00:02s\n","epoch 2  | loss: 0.56216 | val_0_accuracy: 0.52535 |  0:00:03s\n","epoch 3  | loss: 0.51794 | val_0_accuracy: 0.59684 |  0:00:04s\n","epoch 4  | loss: 0.46463 | val_0_accuracy: 0.532   |  0:00:05s\n","epoch 5  | loss: 0.45029 | val_0_accuracy: 0.52785 |  0:00:06s\n","epoch 6  | loss: 0.47641 | val_0_accuracy: 0.53117 |  0:00:07s\n","epoch 7  | loss: 0.45845 | val_0_accuracy: 0.55528 |  0:00:08s\n","epoch 8  | loss: 0.43388 | val_0_accuracy: 0.56941 |  0:00:09s\n","epoch 9  | loss: 0.41161 | val_0_accuracy: 0.57107 |  0:00:10s\n","epoch 10 | loss: 0.41204 | val_0_accuracy: 0.57273 |  0:00:11s\n","epoch 11 | loss: 0.4086  | val_0_accuracy: 0.66251 |  0:00:12s\n","epoch 12 | loss: 0.40875 | val_0_accuracy: 0.58603 |  0:00:13s\n","epoch 13 | loss: 0.40553 | val_0_accuracy: 0.60848 |  0:00:15s\n","epoch 14 | loss: 0.39889 | val_0_accuracy: 0.7207  |  0:00:16s\n","epoch 15 | loss: 0.38868 | val_0_accuracy: 0.69825 |  0:00:17s\n","epoch 16 | loss: 0.39    | val_0_accuracy: 0.66833 |  0:00:18s\n","epoch 17 | loss: 0.385   | val_0_accuracy: 0.7049  |  0:00:19s\n","epoch 18 | loss: 0.38067 | val_0_accuracy: 0.71571 |  0:00:20s\n","epoch 19 | loss: 0.37891 | val_0_accuracy: 0.71239 |  0:00:21s\n","epoch 20 | loss: 0.3734  | val_0_accuracy: 0.71571 |  0:00:22s\n","epoch 21 | loss: 0.3776  | val_0_accuracy: 0.73815 |  0:00:23s\n","epoch 22 | loss: 0.3743  | val_0_accuracy: 0.75977 |  0:00:24s\n","epoch 23 | loss: 0.3738  | val_0_accuracy: 0.75312 |  0:00:25s\n","epoch 24 | loss: 0.37209 | val_0_accuracy: 0.76392 |  0:00:26s\n","epoch 25 | loss: 0.37513 | val_0_accuracy: 0.7714  |  0:00:28s\n","epoch 26 | loss: 0.38061 | val_0_accuracy: 0.76808 |  0:00:29s\n","epoch 27 | loss: 0.3896  | val_0_accuracy: 0.76725 |  0:00:30s\n","epoch 28 | loss: 0.37615 | val_0_accuracy: 0.76974 |  0:00:31s\n","epoch 29 | loss: 0.36931 | val_0_accuracy: 0.79219 |  0:00:32s\n","epoch 30 | loss: 0.37451 | val_0_accuracy: 0.81712 |  0:00:33s\n","epoch 31 | loss: 0.37048 | val_0_accuracy: 0.81131 |  0:00:34s\n","epoch 32 | loss: 0.37347 | val_0_accuracy: 0.81879 |  0:00:35s\n","epoch 33 | loss: 0.36965 | val_0_accuracy: 0.82627 |  0:00:36s\n","epoch 34 | loss: 0.36839 | val_0_accuracy: 0.83791 |  0:00:37s\n","epoch 35 | loss: 0.36422 | val_0_accuracy: 0.82294 |  0:00:38s\n","epoch 36 | loss: 0.36229 | val_0_accuracy: 0.8138  |  0:00:39s\n","epoch 37 | loss: 0.35753 | val_0_accuracy: 0.8138  |  0:00:41s\n","epoch 38 | loss: 0.35593 | val_0_accuracy: 0.83126 |  0:00:42s\n","epoch 39 | loss: 0.35231 | val_0_accuracy: 0.83292 |  0:00:43s\n","epoch 40 | loss: 0.35109 | val_0_accuracy: 0.83624 |  0:00:44s\n","epoch 41 | loss: 0.34637 | val_0_accuracy: 0.84788 |  0:00:45s\n","epoch 42 | loss: 0.34992 | val_0_accuracy: 0.84871 |  0:00:46s\n","epoch 43 | loss: 0.34905 | val_0_accuracy: 0.84456 |  0:00:47s\n","epoch 44 | loss: 0.34636 | val_0_accuracy: 0.84206 |  0:00:48s\n","epoch 45 | loss: 0.34485 | val_0_accuracy: 0.85121 |  0:00:49s\n","epoch 46 | loss: 0.3382  | val_0_accuracy: 0.84622 |  0:00:50s\n","epoch 47 | loss: 0.34229 | val_0_accuracy: 0.85536 |  0:00:51s\n","epoch 48 | loss: 0.34329 | val_0_accuracy: 0.85287 |  0:00:52s\n","epoch 49 | loss: 0.33989 | val_0_accuracy: 0.85121 |  0:00:53s\n","epoch 50 | loss: 0.33452 | val_0_accuracy: 0.84954 |  0:00:54s\n","epoch 51 | loss: 0.33185 | val_0_accuracy: 0.8537  |  0:00:55s\n","epoch 52 | loss: 0.33244 | val_0_accuracy: 0.84954 |  0:00:57s\n","epoch 53 | loss: 0.32967 | val_0_accuracy: 0.8537  |  0:00:58s\n","epoch 54 | loss: 0.33041 | val_0_accuracy: 0.85536 |  0:00:59s\n","epoch 55 | loss: 0.32914 | val_0_accuracy: 0.84372 |  0:01:00s\n","epoch 56 | loss: 0.32582 | val_0_accuracy: 0.85453 |  0:01:01s\n","epoch 57 | loss: 0.32468 | val_0_accuracy: 0.84954 |  0:01:02s\n","\n","Early stopping occurred at epoch 57 with best_epoch = 47 and best_val_0_accuracy = 0.85536\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-07-06 06:30:35,696] Trial 74 finished with value: 0.8553615960099751 and parameters: {'n_d': 33, 'n_steps': 7, 'gamma': 1.1691794471533479, 'n_independent': 3, 'n_shared': 4, 'momentum': 0.05963486479449567}. Best is trial 42 with value: 0.8728179551122195.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 0.97101 | val_0_accuracy: 0.59767 |  0:00:01s\n","epoch 1  | loss: 0.6269  | val_0_accuracy: 0.60848 |  0:00:02s\n","epoch 2  | loss: 0.64703 | val_0_accuracy: 0.50707 |  0:00:03s\n","epoch 3  | loss: 0.59036 | val_0_accuracy: 0.61679 |  0:00:04s\n","epoch 4  | loss: 0.47637 | val_0_accuracy: 0.56608 |  0:00:05s\n","epoch 5  | loss: 0.44903 | val_0_accuracy: 0.6143  |  0:00:06s\n","epoch 6  | loss: 0.44835 | val_0_accuracy: 0.53117 |  0:00:07s\n","epoch 7  | loss: 0.43132 | val_0_accuracy: 0.64173 |  0:00:08s\n","epoch 8  | loss: 0.41996 | val_0_accuracy: 0.5744  |  0:00:09s\n","epoch 9  | loss: 0.42774 | val_0_accuracy: 0.6384  |  0:00:10s\n","epoch 10 | loss: 0.42727 | val_0_accuracy: 0.70407 |  0:00:11s\n","epoch 11 | loss: 0.40915 | val_0_accuracy: 0.68911 |  0:00:13s\n","epoch 12 | loss: 0.42174 | val_0_accuracy: 0.62926 |  0:00:14s\n","epoch 13 | loss: 0.40503 | val_0_accuracy: 0.66085 |  0:00:15s\n","epoch 14 | loss: 0.39158 | val_0_accuracy: 0.68412 |  0:00:16s\n","epoch 15 | loss: 0.39426 | val_0_accuracy: 0.71155 |  0:00:17s\n","epoch 16 | loss: 0.39073 | val_0_accuracy: 0.70158 |  0:00:18s\n","epoch 17 | loss: 0.39375 | val_0_accuracy: 0.75478 |  0:00:19s\n","epoch 18 | loss: 0.39383 | val_0_accuracy: 0.76226 |  0:00:20s\n","epoch 19 | loss: 0.39587 | val_0_accuracy: 0.76642 |  0:00:21s\n","epoch 20 | loss: 0.39424 | val_0_accuracy: 0.73317 |  0:00:22s\n","epoch 21 | loss: 0.38672 | val_0_accuracy: 0.7448  |  0:00:23s\n","epoch 22 | loss: 0.39357 | val_0_accuracy: 0.74647 |  0:00:24s\n","epoch 23 | loss: 0.38603 | val_0_accuracy: 0.76226 |  0:00:25s\n","epoch 24 | loss: 0.38323 | val_0_accuracy: 0.76309 |  0:00:26s\n","epoch 25 | loss: 0.3907  | val_0_accuracy: 0.74647 |  0:00:28s\n","epoch 26 | loss: 0.3921  | val_0_accuracy: 0.76808 |  0:00:29s\n","epoch 27 | loss: 0.41021 | val_0_accuracy: 0.80216 |  0:00:30s\n","epoch 28 | loss: 0.42117 | val_0_accuracy: 0.80964 |  0:00:31s\n","epoch 29 | loss: 0.39912 | val_0_accuracy: 0.81879 |  0:00:32s\n","epoch 30 | loss: 0.39268 | val_0_accuracy: 0.81629 |  0:00:33s\n","epoch 31 | loss: 0.3924  | val_0_accuracy: 0.81796 |  0:00:34s\n","epoch 32 | loss: 0.38506 | val_0_accuracy: 0.83292 |  0:00:35s\n","epoch 33 | loss: 0.3791  | val_0_accuracy: 0.80881 |  0:00:36s\n","epoch 34 | loss: 0.3831  | val_0_accuracy: 0.80216 |  0:00:37s\n","epoch 35 | loss: 0.3747  | val_0_accuracy: 0.82544 |  0:00:38s\n","epoch 36 | loss: 0.37405 | val_0_accuracy: 0.81879 |  0:00:39s\n","epoch 37 | loss: 0.38413 | val_0_accuracy: 0.83707 |  0:00:40s\n","epoch 38 | loss: 0.37372 | val_0_accuracy: 0.83292 |  0:00:42s\n","epoch 39 | loss: 0.37266 | val_0_accuracy: 0.83126 |  0:00:43s\n","epoch 40 | loss: 0.37305 | val_0_accuracy: 0.84705 |  0:00:44s\n","epoch 41 | loss: 0.37634 | val_0_accuracy: 0.82959 |  0:00:45s\n","epoch 42 | loss: 0.38183 | val_0_accuracy: 0.83042 |  0:00:46s\n","epoch 43 | loss: 0.38456 | val_0_accuracy: 0.83458 |  0:00:47s\n","epoch 44 | loss: 0.37809 | val_0_accuracy: 0.8271  |  0:00:48s\n","epoch 45 | loss: 0.37671 | val_0_accuracy: 0.8271  |  0:00:49s\n","epoch 46 | loss: 0.37369 | val_0_accuracy: 0.84289 |  0:00:50s\n","epoch 47 | loss: 0.37244 | val_0_accuracy: 0.83042 |  0:00:51s\n","epoch 48 | loss: 0.36773 | val_0_accuracy: 0.83791 |  0:00:52s\n","epoch 49 | loss: 0.37131 | val_0_accuracy: 0.82211 |  0:00:53s\n","epoch 50 | loss: 0.37176 | val_0_accuracy: 0.83707 |  0:00:55s\n","\n","Early stopping occurred at epoch 50 with best_epoch = 40 and best_val_0_accuracy = 0.84705\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-07-06 06:31:31,365] Trial 75 finished with value: 0.8470490440565254 and parameters: {'n_d': 47, 'n_steps': 8, 'gamma': 1.212011844570951, 'n_independent': 3, 'n_shared': 3, 'momentum': 0.1673862020836624}. Best is trial 42 with value: 0.8728179551122195.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 0.75146 | val_0_accuracy: 0.5212  |  0:00:00s\n","epoch 1  | loss: 0.55762 | val_0_accuracy: 0.57024 |  0:00:01s\n","epoch 2  | loss: 0.5208  | val_0_accuracy: 0.52868 |  0:00:02s\n","epoch 3  | loss: 0.52681 | val_0_accuracy: 0.58271 |  0:00:03s\n","epoch 4  | loss: 0.46052 | val_0_accuracy: 0.56359 |  0:00:04s\n","epoch 5  | loss: 0.44579 | val_0_accuracy: 0.63674 |  0:00:05s\n","epoch 6  | loss: 0.43066 | val_0_accuracy: 0.67165 |  0:00:06s\n","epoch 7  | loss: 0.40799 | val_0_accuracy: 0.62178 |  0:00:07s\n","epoch 8  | loss: 0.41432 | val_0_accuracy: 0.63259 |  0:00:08s\n","epoch 9  | loss: 0.40737 | val_0_accuracy: 0.65752 |  0:00:09s\n","epoch 10 | loss: 0.39715 | val_0_accuracy: 0.59102 |  0:00:10s\n","epoch 11 | loss: 0.38857 | val_0_accuracy: 0.61513 |  0:00:11s\n","epoch 12 | loss: 0.37964 | val_0_accuracy: 0.61762 |  0:00:12s\n","epoch 13 | loss: 0.37808 | val_0_accuracy: 0.65004 |  0:00:13s\n","epoch 14 | loss: 0.37053 | val_0_accuracy: 0.70407 |  0:00:14s\n","epoch 15 | loss: 0.36966 | val_0_accuracy: 0.7074  |  0:00:15s\n","epoch 16 | loss: 0.36703 | val_0_accuracy: 0.71904 |  0:00:16s\n","epoch 17 | loss: 0.36455 | val_0_accuracy: 0.71488 |  0:00:16s\n","epoch 18 | loss: 0.35215 | val_0_accuracy: 0.73317 |  0:00:17s\n","epoch 19 | loss: 0.35242 | val_0_accuracy: 0.75977 |  0:00:18s\n","epoch 20 | loss: 0.34552 | val_0_accuracy: 0.74896 |  0:00:19s\n","epoch 21 | loss: 0.34872 | val_0_accuracy: 0.75062 |  0:00:20s\n","epoch 22 | loss: 0.34151 | val_0_accuracy: 0.75894 |  0:00:21s\n","epoch 23 | loss: 0.35947 | val_0_accuracy: 0.75894 |  0:00:22s\n","epoch 24 | loss: 0.3584  | val_0_accuracy: 0.78221 |  0:00:23s\n","epoch 25 | loss: 0.35691 | val_0_accuracy: 0.79551 |  0:00:24s\n","epoch 26 | loss: 0.35491 | val_0_accuracy: 0.78637 |  0:00:25s\n","epoch 27 | loss: 0.34816 | val_0_accuracy: 0.80549 |  0:00:26s\n","epoch 28 | loss: 0.34485 | val_0_accuracy: 0.82128 |  0:00:27s\n","epoch 29 | loss: 0.34112 | val_0_accuracy: 0.80632 |  0:00:28s\n","epoch 30 | loss: 0.34216 | val_0_accuracy: 0.80382 |  0:00:29s\n","epoch 31 | loss: 0.34202 | val_0_accuracy: 0.8138  |  0:00:30s\n","epoch 32 | loss: 0.33866 | val_0_accuracy: 0.80715 |  0:00:31s\n","epoch 33 | loss: 0.34359 | val_0_accuracy: 0.83541 |  0:00:32s\n","epoch 34 | loss: 0.3416  | val_0_accuracy: 0.83624 |  0:00:33s\n","epoch 35 | loss: 0.3414  | val_0_accuracy: 0.83874 |  0:00:34s\n","epoch 36 | loss: 0.33525 | val_0_accuracy: 0.83292 |  0:00:35s\n","epoch 37 | loss: 0.33203 | val_0_accuracy: 0.8537  |  0:00:36s\n","epoch 38 | loss: 0.32824 | val_0_accuracy: 0.85204 |  0:00:36s\n","epoch 39 | loss: 0.32621 | val_0_accuracy: 0.85453 |  0:00:37s\n","epoch 40 | loss: 0.32139 | val_0_accuracy: 0.8537  |  0:00:38s\n","epoch 41 | loss: 0.31852 | val_0_accuracy: 0.85952 |  0:00:39s\n","epoch 42 | loss: 0.31956 | val_0_accuracy: 0.85952 |  0:00:40s\n","epoch 43 | loss: 0.31691 | val_0_accuracy: 0.84788 |  0:00:41s\n","epoch 44 | loss: 0.31344 | val_0_accuracy: 0.85536 |  0:00:42s\n","epoch 45 | loss: 0.32243 | val_0_accuracy: 0.86201 |  0:00:43s\n","epoch 46 | loss: 0.31428 | val_0_accuracy: 0.86617 |  0:00:44s\n","epoch 47 | loss: 0.31017 | val_0_accuracy: 0.85619 |  0:00:45s\n","epoch 48 | loss: 0.31416 | val_0_accuracy: 0.8537  |  0:00:46s\n","epoch 49 | loss: 0.31479 | val_0_accuracy: 0.84622 |  0:00:47s\n","epoch 50 | loss: 0.32317 | val_0_accuracy: 0.86534 |  0:00:48s\n","epoch 51 | loss: 0.32263 | val_0_accuracy: 0.86284 |  0:00:49s\n","epoch 52 | loss: 0.318   | val_0_accuracy: 0.85037 |  0:00:50s\n","epoch 53 | loss: 0.31999 | val_0_accuracy: 0.86534 |  0:00:51s\n","epoch 54 | loss: 0.31297 | val_0_accuracy: 0.86035 |  0:00:52s\n","epoch 55 | loss: 0.31342 | val_0_accuracy: 0.85869 |  0:00:52s\n","epoch 56 | loss: 0.31045 | val_0_accuracy: 0.86035 |  0:00:53s\n","\n","Early stopping occurred at epoch 56 with best_epoch = 46 and best_val_0_accuracy = 0.86617\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-07-06 06:32:25,819] Trial 76 finished with value: 0.8661679135494597 and parameters: {'n_d': 30, 'n_steps': 6, 'gamma': 1.108768371550898, 'n_independent': 3, 'n_shared': 4, 'momentum': 0.09538422303109761}. Best is trial 42 with value: 0.8728179551122195.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 0.70387 | val_0_accuracy: 0.51122 |  0:00:00s\n","epoch 1  | loss: 0.54039 | val_0_accuracy: 0.53034 |  0:00:01s\n","epoch 2  | loss: 0.48959 | val_0_accuracy: 0.56608 |  0:00:02s\n","epoch 3  | loss: 0.46212 | val_0_accuracy: 0.53283 |  0:00:03s\n","epoch 4  | loss: 0.45574 | val_0_accuracy: 0.56442 |  0:00:04s\n","epoch 5  | loss: 0.45375 | val_0_accuracy: 0.57938 |  0:00:05s\n","epoch 6  | loss: 0.44118 | val_0_accuracy: 0.62012 |  0:00:05s\n","epoch 7  | loss: 0.42315 | val_0_accuracy: 0.59185 |  0:00:06s\n","epoch 8  | loss: 0.421   | val_0_accuracy: 0.59352 |  0:00:07s\n","epoch 9  | loss: 0.42051 | val_0_accuracy: 0.63259 |  0:00:08s\n","epoch 10 | loss: 0.43074 | val_0_accuracy: 0.62427 |  0:00:09s\n","epoch 11 | loss: 0.42884 | val_0_accuracy: 0.68662 |  0:00:10s\n","epoch 12 | loss: 0.41046 | val_0_accuracy: 0.6783  |  0:00:11s\n","epoch 13 | loss: 0.40409 | val_0_accuracy: 0.68911 |  0:00:11s\n","epoch 14 | loss: 0.39802 | val_0_accuracy: 0.70407 |  0:00:12s\n","epoch 15 | loss: 0.39343 | val_0_accuracy: 0.72569 |  0:00:13s\n","epoch 16 | loss: 0.39443 | val_0_accuracy: 0.70823 |  0:00:14s\n","epoch 17 | loss: 0.38434 | val_0_accuracy: 0.75561 |  0:00:15s\n","epoch 18 | loss: 0.38335 | val_0_accuracy: 0.75977 |  0:00:16s\n","epoch 19 | loss: 0.37854 | val_0_accuracy: 0.76143 |  0:00:17s\n","epoch 20 | loss: 0.38024 | val_0_accuracy: 0.77556 |  0:00:17s\n","epoch 21 | loss: 0.37488 | val_0_accuracy: 0.7739  |  0:00:18s\n","epoch 22 | loss: 0.37192 | val_0_accuracy: 0.76309 |  0:00:19s\n","epoch 23 | loss: 0.38097 | val_0_accuracy: 0.75478 |  0:00:20s\n","epoch 24 | loss: 0.38359 | val_0_accuracy: 0.77556 |  0:00:21s\n","epoch 25 | loss: 0.37235 | val_0_accuracy: 0.77722 |  0:00:22s\n","epoch 26 | loss: 0.37511 | val_0_accuracy: 0.77473 |  0:00:23s\n","epoch 27 | loss: 0.37658 | val_0_accuracy: 0.78387 |  0:00:24s\n","epoch 28 | loss: 0.38007 | val_0_accuracy: 0.798   |  0:00:25s\n","epoch 29 | loss: 0.38091 | val_0_accuracy: 0.81214 |  0:00:25s\n","epoch 30 | loss: 0.37603 | val_0_accuracy: 0.81297 |  0:00:26s\n","epoch 31 | loss: 0.37847 | val_0_accuracy: 0.80216 |  0:00:27s\n","epoch 32 | loss: 0.37265 | val_0_accuracy: 0.81463 |  0:00:28s\n","epoch 33 | loss: 0.36931 | val_0_accuracy: 0.82128 |  0:00:29s\n","epoch 34 | loss: 0.37616 | val_0_accuracy: 0.82793 |  0:00:30s\n","epoch 35 | loss: 0.37739 | val_0_accuracy: 0.83458 |  0:00:31s\n","epoch 36 | loss: 0.37616 | val_0_accuracy: 0.83292 |  0:00:32s\n","epoch 37 | loss: 0.37067 | val_0_accuracy: 0.83458 |  0:00:33s\n","epoch 38 | loss: 0.37128 | val_0_accuracy: 0.8404  |  0:00:34s\n","epoch 39 | loss: 0.36837 | val_0_accuracy: 0.84954 |  0:00:35s\n","epoch 40 | loss: 0.36482 | val_0_accuracy: 0.84206 |  0:00:35s\n","epoch 41 | loss: 0.36483 | val_0_accuracy: 0.83458 |  0:00:36s\n","epoch 42 | loss: 0.36672 | val_0_accuracy: 0.84788 |  0:00:37s\n","epoch 43 | loss: 0.36188 | val_0_accuracy: 0.84456 |  0:00:38s\n","epoch 44 | loss: 0.36279 | val_0_accuracy: 0.83791 |  0:00:39s\n","epoch 45 | loss: 0.35765 | val_0_accuracy: 0.85536 |  0:00:40s\n","epoch 46 | loss: 0.35399 | val_0_accuracy: 0.84372 |  0:00:41s\n","epoch 47 | loss: 0.35843 | val_0_accuracy: 0.83707 |  0:00:41s\n","epoch 48 | loss: 0.35711 | val_0_accuracy: 0.83707 |  0:00:42s\n","epoch 49 | loss: 0.3542  | val_0_accuracy: 0.85037 |  0:00:43s\n","epoch 50 | loss: 0.35518 | val_0_accuracy: 0.84539 |  0:00:44s\n","epoch 51 | loss: 0.35237 | val_0_accuracy: 0.83874 |  0:00:45s\n","epoch 52 | loss: 0.35214 | val_0_accuracy: 0.8537  |  0:00:46s\n","epoch 53 | loss: 0.34273 | val_0_accuracy: 0.85037 |  0:00:47s\n","epoch 54 | loss: 0.34475 | val_0_accuracy: 0.84622 |  0:00:48s\n","epoch 55 | loss: 0.35039 | val_0_accuracy: 0.84954 |  0:00:48s\n","\n","Early stopping occurred at epoch 55 with best_epoch = 45 and best_val_0_accuracy = 0.85536\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-07-06 06:33:15,247] Trial 77 finished with value: 0.8553615960099751 and parameters: {'n_d': 35, 'n_steps': 7, 'gamma': 1.2511560124991956, 'n_independent': 2, 'n_shared': 3, 'momentum': 0.19878236342320227}. Best is trial 42 with value: 0.8728179551122195.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 0.79314 | val_0_accuracy: 0.56775 |  0:00:00s\n","epoch 1  | loss: 0.52477 | val_0_accuracy: 0.53034 |  0:00:01s\n","epoch 2  | loss: 0.4546  | val_0_accuracy: 0.59933 |  0:00:02s\n","epoch 3  | loss: 0.42043 | val_0_accuracy: 0.63757 |  0:00:03s\n","epoch 4  | loss: 0.40206 | val_0_accuracy: 0.59601 |  0:00:04s\n","epoch 5  | loss: 0.38816 | val_0_accuracy: 0.56359 |  0:00:05s\n","epoch 6  | loss: 0.38538 | val_0_accuracy: 0.65337 |  0:00:06s\n","epoch 7  | loss: 0.38135 | val_0_accuracy: 0.66584 |  0:00:06s\n","epoch 8  | loss: 0.37438 | val_0_accuracy: 0.64007 |  0:00:07s\n","epoch 9  | loss: 0.37184 | val_0_accuracy: 0.60848 |  0:00:08s\n","epoch 10 | loss: 0.36788 | val_0_accuracy: 0.66916 |  0:00:09s\n","epoch 11 | loss: 0.36321 | val_0_accuracy: 0.69244 |  0:00:10s\n","epoch 12 | loss: 0.35857 | val_0_accuracy: 0.69576 |  0:00:11s\n","epoch 13 | loss: 0.35048 | val_0_accuracy: 0.68579 |  0:00:11s\n","epoch 14 | loss: 0.35265 | val_0_accuracy: 0.7049  |  0:00:12s\n","epoch 15 | loss: 0.34799 | val_0_accuracy: 0.68828 |  0:00:13s\n","epoch 16 | loss: 0.34359 | val_0_accuracy: 0.66085 |  0:00:14s\n","epoch 17 | loss: 0.34462 | val_0_accuracy: 0.68828 |  0:00:15s\n","epoch 18 | loss: 0.3409  | val_0_accuracy: 0.71239 |  0:00:16s\n","epoch 19 | loss: 0.33944 | val_0_accuracy: 0.7207  |  0:00:16s\n","epoch 20 | loss: 0.33655 | val_0_accuracy: 0.72901 |  0:00:17s\n","epoch 21 | loss: 0.33601 | val_0_accuracy: 0.76475 |  0:00:18s\n","epoch 22 | loss: 0.33233 | val_0_accuracy: 0.76725 |  0:00:19s\n","epoch 23 | loss: 0.32533 | val_0_accuracy: 0.77889 |  0:00:20s\n","epoch 24 | loss: 0.32305 | val_0_accuracy: 0.76725 |  0:00:21s\n","epoch 25 | loss: 0.32333 | val_0_accuracy: 0.79884 |  0:00:21s\n","epoch 26 | loss: 0.32726 | val_0_accuracy: 0.79884 |  0:00:22s\n","epoch 27 | loss: 0.31774 | val_0_accuracy: 0.80299 |  0:00:23s\n","epoch 28 | loss: 0.32075 | val_0_accuracy: 0.80964 |  0:00:24s\n","epoch 29 | loss: 0.32123 | val_0_accuracy: 0.81297 |  0:00:25s\n","epoch 30 | loss: 0.32238 | val_0_accuracy: 0.81962 |  0:00:26s\n","epoch 31 | loss: 0.33435 | val_0_accuracy: 0.82045 |  0:00:26s\n","epoch 32 | loss: 0.33893 | val_0_accuracy: 0.81796 |  0:00:27s\n","epoch 33 | loss: 0.33518 | val_0_accuracy: 0.83458 |  0:00:28s\n","epoch 34 | loss: 0.33143 | val_0_accuracy: 0.80964 |  0:00:29s\n","epoch 35 | loss: 0.34115 | val_0_accuracy: 0.84456 |  0:00:30s\n","epoch 36 | loss: 0.33924 | val_0_accuracy: 0.84622 |  0:00:31s\n","epoch 37 | loss: 0.32824 | val_0_accuracy: 0.85453 |  0:00:32s\n","epoch 38 | loss: 0.32138 | val_0_accuracy: 0.83957 |  0:00:32s\n","epoch 39 | loss: 0.31987 | val_0_accuracy: 0.84622 |  0:00:33s\n","epoch 40 | loss: 0.31593 | val_0_accuracy: 0.85453 |  0:00:34s\n","epoch 41 | loss: 0.31765 | val_0_accuracy: 0.84539 |  0:00:35s\n","epoch 42 | loss: 0.31475 | val_0_accuracy: 0.85204 |  0:00:36s\n","epoch 43 | loss: 0.31348 | val_0_accuracy: 0.8537  |  0:00:36s\n","epoch 44 | loss: 0.31608 | val_0_accuracy: 0.85869 |  0:00:37s\n","epoch 45 | loss: 0.31298 | val_0_accuracy: 0.85453 |  0:00:38s\n","epoch 46 | loss: 0.31278 | val_0_accuracy: 0.85619 |  0:00:39s\n","epoch 47 | loss: 0.30797 | val_0_accuracy: 0.85204 |  0:00:40s\n","epoch 48 | loss: 0.30857 | val_0_accuracy: 0.86201 |  0:00:41s\n","epoch 49 | loss: 0.3095  | val_0_accuracy: 0.8537  |  0:00:41s\n","epoch 50 | loss: 0.30761 | val_0_accuracy: 0.86118 |  0:00:42s\n","epoch 51 | loss: 0.30969 | val_0_accuracy: 0.84123 |  0:00:43s\n","epoch 52 | loss: 0.31006 | val_0_accuracy: 0.85121 |  0:00:44s\n","epoch 53 | loss: 0.30361 | val_0_accuracy: 0.85536 |  0:00:45s\n","epoch 54 | loss: 0.30146 | val_0_accuracy: 0.85702 |  0:00:46s\n","epoch 55 | loss: 0.307   | val_0_accuracy: 0.85536 |  0:00:46s\n","epoch 56 | loss: 0.3026  | val_0_accuracy: 0.86284 |  0:00:47s\n","epoch 57 | loss: 0.2979  | val_0_accuracy: 0.85702 |  0:00:48s\n","epoch 58 | loss: 0.30317 | val_0_accuracy: 0.84871 |  0:00:49s\n","epoch 59 | loss: 0.30369 | val_0_accuracy: 0.85619 |  0:00:50s\n","epoch 60 | loss: 0.29432 | val_0_accuracy: 0.86451 |  0:00:51s\n","epoch 61 | loss: 0.29619 | val_0_accuracy: 0.85869 |  0:00:52s\n","epoch 62 | loss: 0.29413 | val_0_accuracy: 0.86284 |  0:00:52s\n","epoch 63 | loss: 0.29592 | val_0_accuracy: 0.86035 |  0:00:53s\n","epoch 64 | loss: 0.28969 | val_0_accuracy: 0.86866 |  0:00:54s\n","epoch 65 | loss: 0.29973 | val_0_accuracy: 0.86035 |  0:00:55s\n","epoch 66 | loss: 0.30326 | val_0_accuracy: 0.82544 |  0:00:56s\n","epoch 67 | loss: 0.29837 | val_0_accuracy: 0.85952 |  0:00:56s\n","epoch 68 | loss: 0.29764 | val_0_accuracy: 0.86035 |  0:00:57s\n","epoch 69 | loss: 0.30325 | val_0_accuracy: 0.86534 |  0:00:58s\n","epoch 70 | loss: 0.30381 | val_0_accuracy: 0.85453 |  0:00:59s\n","epoch 71 | loss: 0.30422 | val_0_accuracy: 0.8537  |  0:01:00s\n","epoch 72 | loss: 0.30972 | val_0_accuracy: 0.86035 |  0:01:01s\n","epoch 73 | loss: 0.31152 | val_0_accuracy: 0.85952 |  0:01:02s\n","epoch 74 | loss: 0.3029  | val_0_accuracy: 0.86367 |  0:01:02s\n","\n","Early stopping occurred at epoch 74 with best_epoch = 64 and best_val_0_accuracy = 0.86866\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-07-06 06:34:18,702] Trial 78 finished with value: 0.8686616791354946 and parameters: {'n_d': 42, 'n_steps': 5, 'gamma': 1.0621982853895136, 'n_independent': 4, 'n_shared': 3, 'momentum': 0.08123218734868286}. Best is trial 42 with value: 0.8728179551122195.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 0.76296 | val_0_accuracy: 0.52037 |  0:00:00s\n","epoch 1  | loss: 0.49437 | val_0_accuracy: 0.51538 |  0:00:01s\n","epoch 2  | loss: 0.4544  | val_0_accuracy: 0.52535 |  0:00:02s\n","epoch 3  | loss: 0.43546 | val_0_accuracy: 0.52286 |  0:00:03s\n","epoch 4  | loss: 0.43175 | val_0_accuracy: 0.53865 |  0:00:03s\n","epoch 5  | loss: 0.40076 | val_0_accuracy: 0.57772 |  0:00:04s\n","epoch 6  | loss: 0.38823 | val_0_accuracy: 0.57523 |  0:00:05s\n","epoch 7  | loss: 0.38121 | val_0_accuracy: 0.57523 |  0:00:06s\n","epoch 8  | loss: 0.36944 | val_0_accuracy: 0.56027 |  0:00:07s\n","epoch 9  | loss: 0.37064 | val_0_accuracy: 0.60848 |  0:00:07s\n","epoch 10 | loss: 0.37092 | val_0_accuracy: 0.60432 |  0:00:08s\n","epoch 11 | loss: 0.36067 | val_0_accuracy: 0.61929 |  0:00:09s\n","epoch 12 | loss: 0.35585 | val_0_accuracy: 0.68246 |  0:00:10s\n","epoch 13 | loss: 0.3493  | val_0_accuracy: 0.65835 |  0:00:11s\n","epoch 14 | loss: 0.34992 | val_0_accuracy: 0.64838 |  0:00:11s\n","epoch 15 | loss: 0.33991 | val_0_accuracy: 0.68911 |  0:00:12s\n","epoch 16 | loss: 0.34688 | val_0_accuracy: 0.71155 |  0:00:13s\n","epoch 17 | loss: 0.34368 | val_0_accuracy: 0.74564 |  0:00:14s\n","epoch 18 | loss: 0.34375 | val_0_accuracy: 0.73234 |  0:00:14s\n","epoch 19 | loss: 0.34148 | val_0_accuracy: 0.70407 |  0:00:15s\n","epoch 20 | loss: 0.34079 | val_0_accuracy: 0.734   |  0:00:16s\n","epoch 21 | loss: 0.34172 | val_0_accuracy: 0.75894 |  0:00:17s\n","epoch 22 | loss: 0.33802 | val_0_accuracy: 0.75727 |  0:00:18s\n","epoch 23 | loss: 0.33805 | val_0_accuracy: 0.76808 |  0:00:18s\n","epoch 24 | loss: 0.33353 | val_0_accuracy: 0.76559 |  0:00:19s\n","epoch 25 | loss: 0.33414 | val_0_accuracy: 0.7739  |  0:00:20s\n","epoch 26 | loss: 0.33373 | val_0_accuracy: 0.7872  |  0:00:21s\n","epoch 27 | loss: 0.33425 | val_0_accuracy: 0.78387 |  0:00:22s\n","epoch 28 | loss: 0.33457 | val_0_accuracy: 0.79468 |  0:00:22s\n","epoch 29 | loss: 0.33336 | val_0_accuracy: 0.80964 |  0:00:23s\n","epoch 30 | loss: 0.33494 | val_0_accuracy: 0.81463 |  0:00:24s\n","epoch 31 | loss: 0.33217 | val_0_accuracy: 0.8138  |  0:00:25s\n","epoch 32 | loss: 0.33531 | val_0_accuracy: 0.82793 |  0:00:26s\n","epoch 33 | loss: 0.32644 | val_0_accuracy: 0.83707 |  0:00:26s\n","epoch 34 | loss: 0.32962 | val_0_accuracy: 0.83458 |  0:00:27s\n","epoch 35 | loss: 0.33193 | val_0_accuracy: 0.83874 |  0:00:28s\n","epoch 36 | loss: 0.33043 | val_0_accuracy: 0.83624 |  0:00:29s\n","epoch 37 | loss: 0.32606 | val_0_accuracy: 0.83957 |  0:00:29s\n","epoch 38 | loss: 0.3248  | val_0_accuracy: 0.84871 |  0:00:30s\n","epoch 39 | loss: 0.32166 | val_0_accuracy: 0.84954 |  0:00:31s\n","epoch 40 | loss: 0.32117 | val_0_accuracy: 0.83957 |  0:00:32s\n","epoch 41 | loss: 0.32342 | val_0_accuracy: 0.82876 |  0:00:33s\n","epoch 42 | loss: 0.31867 | val_0_accuracy: 0.84289 |  0:00:33s\n","epoch 43 | loss: 0.31343 | val_0_accuracy: 0.85453 |  0:00:34s\n","epoch 44 | loss: 0.31854 | val_0_accuracy: 0.84539 |  0:00:35s\n","epoch 45 | loss: 0.32718 | val_0_accuracy: 0.85287 |  0:00:36s\n","epoch 46 | loss: 0.32243 | val_0_accuracy: 0.85786 |  0:00:36s\n","epoch 47 | loss: 0.32421 | val_0_accuracy: 0.84705 |  0:00:37s\n","epoch 48 | loss: 0.32522 | val_0_accuracy: 0.85702 |  0:00:38s\n","epoch 49 | loss: 0.32029 | val_0_accuracy: 0.85121 |  0:00:39s\n","epoch 50 | loss: 0.31733 | val_0_accuracy: 0.86201 |  0:00:40s\n","epoch 51 | loss: 0.31723 | val_0_accuracy: 0.85952 |  0:00:40s\n","epoch 52 | loss: 0.31336 | val_0_accuracy: 0.85702 |  0:00:41s\n","epoch 53 | loss: 0.30894 | val_0_accuracy: 0.86534 |  0:00:42s\n","epoch 54 | loss: 0.308   | val_0_accuracy: 0.86534 |  0:00:43s\n","epoch 55 | loss: 0.30831 | val_0_accuracy: 0.85702 |  0:00:43s\n","epoch 56 | loss: 0.30512 | val_0_accuracy: 0.85619 |  0:00:44s\n","epoch 57 | loss: 0.31264 | val_0_accuracy: 0.85702 |  0:00:45s\n","epoch 58 | loss: 0.31268 | val_0_accuracy: 0.8537  |  0:00:46s\n","epoch 59 | loss: 0.31386 | val_0_accuracy: 0.86035 |  0:00:47s\n","epoch 60 | loss: 0.30809 | val_0_accuracy: 0.85702 |  0:00:47s\n","epoch 61 | loss: 0.30919 | val_0_accuracy: 0.85869 |  0:00:48s\n","epoch 62 | loss: 0.30688 | val_0_accuracy: 0.84788 |  0:00:49s\n","epoch 63 | loss: 0.30973 | val_0_accuracy: 0.85037 |  0:00:50s\n","\n","Early stopping occurred at epoch 63 with best_epoch = 53 and best_val_0_accuracy = 0.86534\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-07-06 06:35:09,254] Trial 79 finished with value: 0.8653366583541147 and parameters: {'n_d': 37, 'n_steps': 4, 'gamma': 1.0452349075789593, 'n_independent': 4, 'n_shared': 4, 'momentum': 0.02458130228370411}. Best is trial 42 with value: 0.8728179551122195.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 0.86144 | val_0_accuracy: 0.49792 |  0:00:00s\n","epoch 1  | loss: 0.64148 | val_0_accuracy: 0.51787 |  0:00:01s\n","epoch 2  | loss: 1.0203  | val_0_accuracy: 0.60515 |  0:00:02s\n","epoch 3  | loss: 0.6593  | val_0_accuracy: 0.5852  |  0:00:03s\n","epoch 4  | loss: 0.51819 | val_0_accuracy: 0.60515 |  0:00:04s\n","epoch 5  | loss: 0.49362 | val_0_accuracy: 0.54863 |  0:00:05s\n","epoch 6  | loss: 0.47724 | val_0_accuracy: 0.61596 |  0:00:05s\n","epoch 7  | loss: 0.47474 | val_0_accuracy: 0.62261 |  0:00:06s\n","epoch 8  | loss: 0.47824 | val_0_accuracy: 0.60349 |  0:00:07s\n","epoch 9  | loss: 0.46977 | val_0_accuracy: 0.60765 |  0:00:08s\n","epoch 10 | loss: 0.47977 | val_0_accuracy: 0.65586 |  0:00:09s\n","epoch 11 | loss: 0.47126 | val_0_accuracy: 0.67664 |  0:00:10s\n","epoch 12 | loss: 0.4583  | val_0_accuracy: 0.69909 |  0:00:11s\n","epoch 13 | loss: 0.47298 | val_0_accuracy: 0.74647 |  0:00:11s\n","epoch 14 | loss: 0.45536 | val_0_accuracy: 0.72485 |  0:00:12s\n","epoch 15 | loss: 0.43627 | val_0_accuracy: 0.68246 |  0:00:13s\n","epoch 16 | loss: 0.44598 | val_0_accuracy: 0.73234 |  0:00:14s\n","epoch 17 | loss: 0.4449  | val_0_accuracy: 0.73234 |  0:00:15s\n","epoch 18 | loss: 0.42912 | val_0_accuracy: 0.73483 |  0:00:16s\n","epoch 19 | loss: 0.43355 | val_0_accuracy: 0.74564 |  0:00:17s\n","epoch 20 | loss: 0.43173 | val_0_accuracy: 0.76226 |  0:00:18s\n","epoch 21 | loss: 0.4383  | val_0_accuracy: 0.76559 |  0:00:18s\n","epoch 22 | loss: 0.4297  | val_0_accuracy: 0.76392 |  0:00:19s\n","epoch 23 | loss: 0.4223  | val_0_accuracy: 0.76392 |  0:00:20s\n","epoch 24 | loss: 0.41996 | val_0_accuracy: 0.76392 |  0:00:21s\n","epoch 25 | loss: 0.42683 | val_0_accuracy: 0.77057 |  0:00:22s\n","epoch 26 | loss: 0.41737 | val_0_accuracy: 0.77057 |  0:00:23s\n","epoch 27 | loss: 0.42451 | val_0_accuracy: 0.77722 |  0:00:23s\n","epoch 28 | loss: 0.43686 | val_0_accuracy: 0.77722 |  0:00:24s\n","epoch 29 | loss: 0.43612 | val_0_accuracy: 0.77057 |  0:00:25s\n","epoch 30 | loss: 0.43942 | val_0_accuracy: 0.77972 |  0:00:26s\n","epoch 31 | loss: 0.43551 | val_0_accuracy: 0.7847  |  0:00:27s\n","epoch 32 | loss: 0.44076 | val_0_accuracy: 0.78138 |  0:00:28s\n","epoch 33 | loss: 0.45613 | val_0_accuracy: 0.78055 |  0:00:29s\n","epoch 34 | loss: 0.4447  | val_0_accuracy: 0.79634 |  0:00:30s\n","epoch 35 | loss: 0.43039 | val_0_accuracy: 0.77722 |  0:00:30s\n","epoch 36 | loss: 0.4363  | val_0_accuracy: 0.79468 |  0:00:31s\n","epoch 37 | loss: 0.42988 | val_0_accuracy: 0.81047 |  0:00:32s\n","epoch 38 | loss: 0.43047 | val_0_accuracy: 0.78969 |  0:00:33s\n","epoch 39 | loss: 0.43514 | val_0_accuracy: 0.8005  |  0:00:34s\n","epoch 40 | loss: 0.44057 | val_0_accuracy: 0.80964 |  0:00:35s\n","epoch 41 | loss: 0.44187 | val_0_accuracy: 0.80798 |  0:00:35s\n","epoch 42 | loss: 0.43569 | val_0_accuracy: 0.8005  |  0:00:36s\n","epoch 43 | loss: 0.42317 | val_0_accuracy: 0.79135 |  0:00:37s\n","epoch 44 | loss: 0.42184 | val_0_accuracy: 0.80299 |  0:00:38s\n","epoch 45 | loss: 0.42541 | val_0_accuracy: 0.80216 |  0:00:39s\n","epoch 46 | loss: 0.42155 | val_0_accuracy: 0.80632 |  0:00:40s\n","epoch 47 | loss: 0.42179 | val_0_accuracy: 0.81297 |  0:00:41s\n","epoch 48 | loss: 0.41729 | val_0_accuracy: 0.79717 |  0:00:41s\n","epoch 49 | loss: 0.41436 | val_0_accuracy: 0.81214 |  0:00:42s\n","epoch 50 | loss: 0.41264 | val_0_accuracy: 0.81712 |  0:00:43s\n","epoch 51 | loss: 0.40911 | val_0_accuracy: 0.8138  |  0:00:44s\n","epoch 52 | loss: 0.40989 | val_0_accuracy: 0.82461 |  0:00:45s\n","epoch 53 | loss: 0.40596 | val_0_accuracy: 0.82294 |  0:00:46s\n","epoch 54 | loss: 0.40221 | val_0_accuracy: 0.81879 |  0:00:46s\n","epoch 55 | loss: 0.40175 | val_0_accuracy: 0.80466 |  0:00:47s\n","epoch 56 | loss: 0.40684 | val_0_accuracy: 0.81297 |  0:00:48s\n","epoch 57 | loss: 0.41004 | val_0_accuracy: 0.82128 |  0:00:49s\n","epoch 58 | loss: 0.40916 | val_0_accuracy: 0.81297 |  0:00:50s\n","epoch 59 | loss: 0.40765 | val_0_accuracy: 0.82377 |  0:00:51s\n","epoch 60 | loss: 0.40643 | val_0_accuracy: 0.81879 |  0:00:52s\n","epoch 61 | loss: 0.39993 | val_0_accuracy: 0.8271  |  0:00:52s\n","epoch 62 | loss: 0.4011  | val_0_accuracy: 0.82128 |  0:00:53s\n","epoch 63 | loss: 0.40405 | val_0_accuracy: 0.82544 |  0:00:54s\n","epoch 64 | loss: 0.41151 | val_0_accuracy: 0.82211 |  0:00:55s\n","epoch 65 | loss: 0.40614 | val_0_accuracy: 0.81629 |  0:00:56s\n","epoch 66 | loss: 0.39869 | val_0_accuracy: 0.82377 |  0:00:57s\n","epoch 67 | loss: 0.39856 | val_0_accuracy: 0.82294 |  0:00:57s\n","epoch 68 | loss: 0.39484 | val_0_accuracy: 0.83292 |  0:00:58s\n","epoch 69 | loss: 0.395   | val_0_accuracy: 0.82128 |  0:00:59s\n","epoch 70 | loss: 0.39664 | val_0_accuracy: 0.82461 |  0:01:00s\n","epoch 71 | loss: 0.39657 | val_0_accuracy: 0.8271  |  0:01:01s\n","epoch 72 | loss: 0.39562 | val_0_accuracy: 0.83042 |  0:01:02s\n","epoch 73 | loss: 0.39246 | val_0_accuracy: 0.82627 |  0:01:03s\n","epoch 74 | loss: 0.39431 | val_0_accuracy: 0.82959 |  0:01:03s\n","epoch 75 | loss: 0.39611 | val_0_accuracy: 0.8271  |  0:01:04s\n","epoch 76 | loss: 0.39858 | val_0_accuracy: 0.82876 |  0:01:05s\n","epoch 77 | loss: 0.39476 | val_0_accuracy: 0.8271  |  0:01:06s\n","epoch 78 | loss: 0.39478 | val_0_accuracy: 0.83042 |  0:01:07s\n","\n","Early stopping occurred at epoch 78 with best_epoch = 68 and best_val_0_accuracy = 0.83292\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-07-06 06:36:17,046] Trial 80 finished with value: 0.8329177057356608 and parameters: {'n_d': 41, 'n_steps': 6, 'gamma': 1.815457732935449, 'n_independent': 3, 'n_shared': 3, 'momentum': 0.14989865760672796}. Best is trial 42 with value: 0.8728179551122195.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 0.66894 | val_0_accuracy: 0.52203 |  0:00:00s\n","epoch 1  | loss: 0.47993 | val_0_accuracy: 0.60432 |  0:00:00s\n","epoch 2  | loss: 0.42729 | val_0_accuracy: 0.53782 |  0:00:01s\n","epoch 3  | loss: 0.39644 | val_0_accuracy: 0.51787 |  0:00:01s\n","epoch 4  | loss: 0.38744 | val_0_accuracy: 0.57523 |  0:00:02s\n","epoch 5  | loss: 0.3864  | val_0_accuracy: 0.60349 |  0:00:02s\n","epoch 6  | loss: 0.36743 | val_0_accuracy: 0.57938 |  0:00:03s\n","epoch 7  | loss: 0.35636 | val_0_accuracy: 0.57107 |  0:00:03s\n","epoch 8  | loss: 0.3554  | val_0_accuracy: 0.5453  |  0:00:03s\n","epoch 9  | loss: 0.35314 | val_0_accuracy: 0.5611  |  0:00:04s\n","epoch 10 | loss: 0.34483 | val_0_accuracy: 0.62427 |  0:00:04s\n","epoch 11 | loss: 0.34397 | val_0_accuracy: 0.665   |  0:00:05s\n","epoch 12 | loss: 0.35123 | val_0_accuracy: 0.64422 |  0:00:05s\n","epoch 13 | loss: 0.34429 | val_0_accuracy: 0.62261 |  0:00:06s\n","epoch 14 | loss: 0.33591 | val_0_accuracy: 0.61513 |  0:00:06s\n","epoch 15 | loss: 0.34575 | val_0_accuracy: 0.69493 |  0:00:07s\n","epoch 16 | loss: 0.33885 | val_0_accuracy: 0.70574 |  0:00:07s\n","epoch 17 | loss: 0.3309  | val_0_accuracy: 0.70158 |  0:00:08s\n","epoch 18 | loss: 0.33611 | val_0_accuracy: 0.72319 |  0:00:08s\n","epoch 19 | loss: 0.32904 | val_0_accuracy: 0.73732 |  0:00:08s\n","epoch 20 | loss: 0.33552 | val_0_accuracy: 0.74564 |  0:00:09s\n","epoch 21 | loss: 0.34237 | val_0_accuracy: 0.74979 |  0:00:09s\n","epoch 22 | loss: 0.33215 | val_0_accuracy: 0.7473  |  0:00:10s\n","epoch 23 | loss: 0.33185 | val_0_accuracy: 0.7581  |  0:00:10s\n","epoch 24 | loss: 0.32952 | val_0_accuracy: 0.7581  |  0:00:11s\n","epoch 25 | loss: 0.32706 | val_0_accuracy: 0.78969 |  0:00:11s\n","epoch 26 | loss: 0.32466 | val_0_accuracy: 0.78221 |  0:00:11s\n","epoch 27 | loss: 0.32836 | val_0_accuracy: 0.79634 |  0:00:12s\n","epoch 28 | loss: 0.32689 | val_0_accuracy: 0.79468 |  0:00:12s\n","epoch 29 | loss: 0.32422 | val_0_accuracy: 0.79551 |  0:00:13s\n","epoch 30 | loss: 0.31916 | val_0_accuracy: 0.82294 |  0:00:13s\n","epoch 31 | loss: 0.3175  | val_0_accuracy: 0.81962 |  0:00:14s\n","epoch 32 | loss: 0.31953 | val_0_accuracy: 0.84622 |  0:00:14s\n","epoch 33 | loss: 0.31477 | val_0_accuracy: 0.83874 |  0:00:15s\n","epoch 34 | loss: 0.32092 | val_0_accuracy: 0.84954 |  0:00:15s\n","epoch 35 | loss: 0.31672 | val_0_accuracy: 0.84539 |  0:00:16s\n","epoch 36 | loss: 0.31635 | val_0_accuracy: 0.84456 |  0:00:16s\n","epoch 37 | loss: 0.31608 | val_0_accuracy: 0.84456 |  0:00:17s\n","epoch 38 | loss: 0.31761 | val_0_accuracy: 0.85037 |  0:00:17s\n","epoch 39 | loss: 0.3149  | val_0_accuracy: 0.85536 |  0:00:17s\n","epoch 40 | loss: 0.31553 | val_0_accuracy: 0.84622 |  0:00:18s\n","epoch 41 | loss: 0.3214  | val_0_accuracy: 0.85037 |  0:00:18s\n","epoch 42 | loss: 0.3215  | val_0_accuracy: 0.84954 |  0:00:19s\n","epoch 43 | loss: 0.31891 | val_0_accuracy: 0.86035 |  0:00:19s\n","epoch 44 | loss: 0.31909 | val_0_accuracy: 0.85619 |  0:00:20s\n","epoch 45 | loss: 0.31433 | val_0_accuracy: 0.85453 |  0:00:20s\n","epoch 46 | loss: 0.30639 | val_0_accuracy: 0.86035 |  0:00:21s\n","epoch 47 | loss: 0.30998 | val_0_accuracy: 0.85204 |  0:00:21s\n","epoch 48 | loss: 0.31181 | val_0_accuracy: 0.86201 |  0:00:21s\n","epoch 49 | loss: 0.30905 | val_0_accuracy: 0.85536 |  0:00:22s\n","epoch 50 | loss: 0.30804 | val_0_accuracy: 0.84788 |  0:00:22s\n","epoch 51 | loss: 0.30975 | val_0_accuracy: 0.86617 |  0:00:23s\n","epoch 52 | loss: 0.30508 | val_0_accuracy: 0.85204 |  0:00:23s\n","epoch 53 | loss: 0.30593 | val_0_accuracy: 0.85702 |  0:00:24s\n","epoch 54 | loss: 0.30809 | val_0_accuracy: 0.86534 |  0:00:24s\n","epoch 55 | loss: 0.3012  | val_0_accuracy: 0.85204 |  0:00:25s\n","epoch 56 | loss: 0.30411 | val_0_accuracy: 0.85869 |  0:00:25s\n","epoch 57 | loss: 0.3016  | val_0_accuracy: 0.85702 |  0:00:25s\n","epoch 58 | loss: 0.29608 | val_0_accuracy: 0.86451 |  0:00:26s\n","epoch 59 | loss: 0.29321 | val_0_accuracy: 0.85869 |  0:00:26s\n","epoch 60 | loss: 0.30125 | val_0_accuracy: 0.86534 |  0:00:27s\n","epoch 61 | loss: 0.30413 | val_0_accuracy: 0.8537  |  0:00:27s\n","\n","Early stopping occurred at epoch 61 with best_epoch = 51 and best_val_0_accuracy = 0.86617\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-07-06 06:36:45,093] Trial 81 finished with value: 0.8661679135494597 and parameters: {'n_d': 44, 'n_steps': 3, 'gamma': 1.1849994836301139, 'n_independent': 3, 'n_shared': 2, 'momentum': 0.04957089722938676}. Best is trial 42 with value: 0.8728179551122195.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 0.95564 | val_0_accuracy: 0.56276 |  0:00:00s\n","epoch 1  | loss: 0.76921 | val_0_accuracy: 0.61929 |  0:00:01s\n","epoch 2  | loss: 0.92215 | val_0_accuracy: 0.57357 |  0:00:02s\n","epoch 3  | loss: 0.79031 | val_0_accuracy: 0.62427 |  0:00:03s\n","epoch 4  | loss: 0.54691 | val_0_accuracy: 0.63009 |  0:00:04s\n","epoch 5  | loss: 0.49501 | val_0_accuracy: 0.53034 |  0:00:05s\n","epoch 6  | loss: 0.46643 | val_0_accuracy: 0.54032 |  0:00:06s\n","epoch 7  | loss: 0.46673 | val_0_accuracy: 0.58354 |  0:00:07s\n","epoch 8  | loss: 0.44113 | val_0_accuracy: 0.56941 |  0:00:08s\n","epoch 9  | loss: 0.43402 | val_0_accuracy: 0.57606 |  0:00:09s\n","epoch 10 | loss: 0.4243  | val_0_accuracy: 0.63674 |  0:00:10s\n","epoch 11 | loss: 0.42296 | val_0_accuracy: 0.6118  |  0:00:11s\n","epoch 12 | loss: 0.4186  | val_0_accuracy: 0.70906 |  0:00:12s\n","epoch 13 | loss: 0.41708 | val_0_accuracy: 0.71405 |  0:00:13s\n","epoch 14 | loss: 0.41668 | val_0_accuracy: 0.69825 |  0:00:14s\n","epoch 15 | loss: 0.4202  | val_0_accuracy: 0.73234 |  0:00:15s\n","epoch 16 | loss: 0.41891 | val_0_accuracy: 0.72319 |  0:00:16s\n","epoch 17 | loss: 0.42631 | val_0_accuracy: 0.70407 |  0:00:17s\n","epoch 18 | loss: 0.4235  | val_0_accuracy: 0.70906 |  0:00:17s\n","epoch 19 | loss: 0.43524 | val_0_accuracy: 0.73982 |  0:00:18s\n","epoch 20 | loss: 0.4396  | val_0_accuracy: 0.76226 |  0:00:19s\n","epoch 21 | loss: 0.43086 | val_0_accuracy: 0.76392 |  0:00:20s\n","epoch 22 | loss: 0.44071 | val_0_accuracy: 0.75727 |  0:00:21s\n","epoch 23 | loss: 0.42794 | val_0_accuracy: 0.75894 |  0:00:22s\n","epoch 24 | loss: 0.43998 | val_0_accuracy: 0.76226 |  0:00:23s\n","epoch 25 | loss: 0.43661 | val_0_accuracy: 0.75561 |  0:00:24s\n","epoch 26 | loss: 0.42475 | val_0_accuracy: 0.79052 |  0:00:25s\n","epoch 27 | loss: 0.42142 | val_0_accuracy: 0.78637 |  0:00:26s\n","epoch 28 | loss: 0.42282 | val_0_accuracy: 0.76891 |  0:00:27s\n","epoch 29 | loss: 0.42243 | val_0_accuracy: 0.76475 |  0:00:28s\n","epoch 30 | loss: 0.43879 | val_0_accuracy: 0.77805 |  0:00:29s\n","epoch 31 | loss: 0.42462 | val_0_accuracy: 0.78803 |  0:00:30s\n","epoch 32 | loss: 0.41338 | val_0_accuracy: 0.7847  |  0:00:31s\n","epoch 33 | loss: 0.41292 | val_0_accuracy: 0.79135 |  0:00:32s\n","epoch 34 | loss: 0.41601 | val_0_accuracy: 0.80964 |  0:00:33s\n","epoch 35 | loss: 0.41203 | val_0_accuracy: 0.82793 |  0:00:34s\n","epoch 36 | loss: 0.41172 | val_0_accuracy: 0.81047 |  0:00:35s\n","epoch 37 | loss: 0.41589 | val_0_accuracy: 0.80881 |  0:00:36s\n","epoch 38 | loss: 0.40821 | val_0_accuracy: 0.81796 |  0:00:37s\n","epoch 39 | loss: 0.40247 | val_0_accuracy: 0.81962 |  0:00:38s\n","epoch 40 | loss: 0.40046 | val_0_accuracy: 0.82211 |  0:00:38s\n","epoch 41 | loss: 0.40581 | val_0_accuracy: 0.8138  |  0:00:39s\n","epoch 42 | loss: 0.41162 | val_0_accuracy: 0.81214 |  0:00:40s\n","epoch 43 | loss: 0.40552 | val_0_accuracy: 0.79884 |  0:00:41s\n","epoch 44 | loss: 0.41235 | val_0_accuracy: 0.80881 |  0:00:42s\n","epoch 45 | loss: 0.40631 | val_0_accuracy: 0.82627 |  0:00:43s\n","\n","Early stopping occurred at epoch 45 with best_epoch = 35 and best_val_0_accuracy = 0.82793\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-07-06 06:37:29,246] Trial 82 finished with value: 0.827930174563591 and parameters: {'n_d': 39, 'n_steps': 8, 'gamma': 1.2766462735715634, 'n_independent': 3, 'n_shared': 2, 'momentum': 0.05200679411909247}. Best is trial 42 with value: 0.8728179551122195.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 0.71853 | val_0_accuracy: 0.49792 |  0:00:00s\n","epoch 1  | loss: 0.53482 | val_0_accuracy: 0.52369 |  0:00:01s\n","epoch 2  | loss: 0.45065 | val_0_accuracy: 0.51372 |  0:00:01s\n","epoch 3  | loss: 0.43238 | val_0_accuracy: 0.5079  |  0:00:02s\n","epoch 4  | loss: 0.41775 | val_0_accuracy: 0.52452 |  0:00:03s\n","epoch 5  | loss: 0.4069  | val_0_accuracy: 0.56276 |  0:00:03s\n","epoch 6  | loss: 0.39935 | val_0_accuracy: 0.58603 |  0:00:04s\n","epoch 7  | loss: 0.39307 | val_0_accuracy: 0.63259 |  0:00:05s\n","epoch 8  | loss: 0.39684 | val_0_accuracy: 0.65004 |  0:00:05s\n","epoch 9  | loss: 0.39736 | val_0_accuracy: 0.62926 |  0:00:06s\n","epoch 10 | loss: 0.40905 | val_0_accuracy: 0.69576 |  0:00:06s\n","epoch 11 | loss: 0.41029 | val_0_accuracy: 0.7182  |  0:00:07s\n","epoch 12 | loss: 0.40221 | val_0_accuracy: 0.72652 |  0:00:08s\n","epoch 13 | loss: 0.39482 | val_0_accuracy: 0.72735 |  0:00:08s\n","epoch 14 | loss: 0.38801 | val_0_accuracy: 0.71654 |  0:00:09s\n","epoch 15 | loss: 0.38339 | val_0_accuracy: 0.72569 |  0:00:10s\n","epoch 16 | loss: 0.38152 | val_0_accuracy: 0.71405 |  0:00:10s\n","epoch 17 | loss: 0.38172 | val_0_accuracy: 0.6941  |  0:00:11s\n","epoch 18 | loss: 0.3883  | val_0_accuracy: 0.71737 |  0:00:11s\n","epoch 19 | loss: 0.3886  | val_0_accuracy: 0.73732 |  0:00:12s\n","epoch 20 | loss: 0.3873  | val_0_accuracy: 0.74148 |  0:00:13s\n","epoch 21 | loss: 0.39485 | val_0_accuracy: 0.71737 |  0:00:13s\n","epoch 22 | loss: 0.38667 | val_0_accuracy: 0.73566 |  0:00:14s\n","epoch 23 | loss: 0.38478 | val_0_accuracy: 0.71904 |  0:00:14s\n","epoch 24 | loss: 0.38393 | val_0_accuracy: 0.72153 |  0:00:15s\n","epoch 25 | loss: 0.37994 | val_0_accuracy: 0.76475 |  0:00:16s\n","epoch 26 | loss: 0.37399 | val_0_accuracy: 0.77473 |  0:00:16s\n","epoch 27 | loss: 0.37858 | val_0_accuracy: 0.7714  |  0:00:17s\n","epoch 28 | loss: 0.37534 | val_0_accuracy: 0.7872  |  0:00:18s\n","epoch 29 | loss: 0.37757 | val_0_accuracy: 0.78304 |  0:00:18s\n","epoch 30 | loss: 0.37178 | val_0_accuracy: 0.79717 |  0:00:19s\n","epoch 31 | loss: 0.37466 | val_0_accuracy: 0.81214 |  0:00:20s\n","epoch 32 | loss: 0.37168 | val_0_accuracy: 0.77972 |  0:00:20s\n","epoch 33 | loss: 0.37903 | val_0_accuracy: 0.79551 |  0:00:21s\n","epoch 34 | loss: 0.37419 | val_0_accuracy: 0.80382 |  0:00:21s\n","epoch 35 | loss: 0.37211 | val_0_accuracy: 0.80466 |  0:00:22s\n","epoch 36 | loss: 0.37122 | val_0_accuracy: 0.80216 |  0:00:23s\n","epoch 37 | loss: 0.37727 | val_0_accuracy: 0.81629 |  0:00:23s\n","epoch 38 | loss: 0.37843 | val_0_accuracy: 0.81463 |  0:00:24s\n","epoch 39 | loss: 0.39857 | val_0_accuracy: 0.8271  |  0:00:24s\n","epoch 40 | loss: 0.40769 | val_0_accuracy: 0.82128 |  0:00:25s\n","epoch 41 | loss: 0.39032 | val_0_accuracy: 0.83042 |  0:00:26s\n","epoch 42 | loss: 0.38913 | val_0_accuracy: 0.82627 |  0:00:26s\n","epoch 43 | loss: 0.38191 | val_0_accuracy: 0.83624 |  0:00:27s\n","epoch 44 | loss: 0.37662 | val_0_accuracy: 0.83624 |  0:00:28s\n","epoch 45 | loss: 0.37413 | val_0_accuracy: 0.84123 |  0:00:28s\n","epoch 46 | loss: 0.37496 | val_0_accuracy: 0.83874 |  0:00:29s\n","epoch 47 | loss: 0.37748 | val_0_accuracy: 0.82294 |  0:00:29s\n","epoch 48 | loss: 0.37972 | val_0_accuracy: 0.82544 |  0:00:30s\n","epoch 49 | loss: 0.37396 | val_0_accuracy: 0.83624 |  0:00:31s\n","epoch 50 | loss: 0.37674 | val_0_accuracy: 0.82793 |  0:00:31s\n","epoch 51 | loss: 0.38339 | val_0_accuracy: 0.8404  |  0:00:32s\n","epoch 52 | loss: 0.37966 | val_0_accuracy: 0.84622 |  0:00:32s\n","epoch 53 | loss: 0.36743 | val_0_accuracy: 0.84206 |  0:00:33s\n","epoch 54 | loss: 0.37089 | val_0_accuracy: 0.83292 |  0:00:34s\n","epoch 55 | loss: 0.36543 | val_0_accuracy: 0.83624 |  0:00:34s\n","epoch 56 | loss: 0.36298 | val_0_accuracy: 0.84456 |  0:00:35s\n","epoch 57 | loss: 0.35637 | val_0_accuracy: 0.83624 |  0:00:36s\n","epoch 58 | loss: 0.35249 | val_0_accuracy: 0.84206 |  0:00:36s\n","epoch 59 | loss: 0.35531 | val_0_accuracy: 0.83874 |  0:00:37s\n","epoch 60 | loss: 0.35326 | val_0_accuracy: 0.83791 |  0:00:37s\n","epoch 61 | loss: 0.3518  | val_0_accuracy: 0.84123 |  0:00:38s\n","epoch 62 | loss: 0.35299 | val_0_accuracy: 0.83042 |  0:00:39s\n","\n","Early stopping occurred at epoch 62 with best_epoch = 52 and best_val_0_accuracy = 0.84622\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-07-06 06:38:08,747] Trial 83 finished with value: 0.8462177888611804 and parameters: {'n_d': 42, 'n_steps': 4, 'gamma': 1.903406887878643, 'n_independent': 3, 'n_shared': 3, 'momentum': 0.06214723648597918}. Best is trial 42 with value: 0.8728179551122195.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 1.00381 | val_0_accuracy: 0.53034 |  0:00:00s\n","epoch 1  | loss: 0.64182 | val_0_accuracy: 0.52702 |  0:00:01s\n","epoch 2  | loss: 0.52559 | val_0_accuracy: 0.53948 |  0:00:02s\n","epoch 3  | loss: 0.50039 | val_0_accuracy: 0.54946 |  0:00:02s\n","epoch 4  | loss: 0.47983 | val_0_accuracy: 0.5719  |  0:00:03s\n","epoch 5  | loss: 0.47848 | val_0_accuracy: 0.55112 |  0:00:04s\n","epoch 6  | loss: 0.4649  | val_0_accuracy: 0.6783  |  0:00:05s\n","epoch 7  | loss: 0.46667 | val_0_accuracy: 0.69576 |  0:00:05s\n","epoch 8  | loss: 0.44165 | val_0_accuracy: 0.67332 |  0:00:06s\n","epoch 9  | loss: 0.43617 | val_0_accuracy: 0.66417 |  0:00:07s\n","epoch 10 | loss: 0.41975 | val_0_accuracy: 0.67165 |  0:00:08s\n","epoch 11 | loss: 0.42339 | val_0_accuracy: 0.71322 |  0:00:08s\n","epoch 12 | loss: 0.41114 | val_0_accuracy: 0.68579 |  0:00:09s\n","epoch 13 | loss: 0.41325 | val_0_accuracy: 0.66584 |  0:00:10s\n","epoch 14 | loss: 0.41415 | val_0_accuracy: 0.65254 |  0:00:10s\n","epoch 15 | loss: 0.42558 | val_0_accuracy: 0.63342 |  0:00:11s\n","epoch 16 | loss: 0.42015 | val_0_accuracy: 0.71904 |  0:00:12s\n","epoch 17 | loss: 0.41629 | val_0_accuracy: 0.70989 |  0:00:13s\n","epoch 18 | loss: 0.40973 | val_0_accuracy: 0.72402 |  0:00:13s\n","epoch 19 | loss: 0.40573 | val_0_accuracy: 0.734   |  0:00:14s\n","epoch 20 | loss: 0.40074 | val_0_accuracy: 0.71322 |  0:00:15s\n","epoch 21 | loss: 0.40208 | val_0_accuracy: 0.71488 |  0:00:16s\n","epoch 22 | loss: 0.40023 | val_0_accuracy: 0.71571 |  0:00:16s\n","epoch 23 | loss: 0.38998 | val_0_accuracy: 0.71488 |  0:00:17s\n","epoch 24 | loss: 0.39113 | val_0_accuracy: 0.7606  |  0:00:18s\n","epoch 25 | loss: 0.39523 | val_0_accuracy: 0.77889 |  0:00:19s\n","epoch 26 | loss: 0.38767 | val_0_accuracy: 0.76725 |  0:00:19s\n","epoch 27 | loss: 0.38658 | val_0_accuracy: 0.78886 |  0:00:20s\n","epoch 28 | loss: 0.37783 | val_0_accuracy: 0.76642 |  0:00:21s\n","epoch 29 | loss: 0.37465 | val_0_accuracy: 0.77972 |  0:00:22s\n","epoch 30 | loss: 0.37274 | val_0_accuracy: 0.79302 |  0:00:22s\n","epoch 31 | loss: 0.37992 | val_0_accuracy: 0.79385 |  0:00:23s\n","epoch 32 | loss: 0.37815 | val_0_accuracy: 0.80133 |  0:00:24s\n","epoch 33 | loss: 0.38054 | val_0_accuracy: 0.80216 |  0:00:24s\n","epoch 34 | loss: 0.3837  | val_0_accuracy: 0.80632 |  0:00:25s\n","epoch 35 | loss: 0.37718 | val_0_accuracy: 0.81214 |  0:00:26s\n","epoch 36 | loss: 0.37653 | val_0_accuracy: 0.80466 |  0:00:27s\n","epoch 37 | loss: 0.37736 | val_0_accuracy: 0.83126 |  0:00:27s\n","epoch 38 | loss: 0.37921 | val_0_accuracy: 0.82959 |  0:00:28s\n","epoch 39 | loss: 0.37053 | val_0_accuracy: 0.84871 |  0:00:29s\n","epoch 40 | loss: 0.37439 | val_0_accuracy: 0.83707 |  0:00:30s\n","epoch 41 | loss: 0.37111 | val_0_accuracy: 0.83957 |  0:00:30s\n","epoch 42 | loss: 0.37219 | val_0_accuracy: 0.83707 |  0:00:31s\n","epoch 43 | loss: 0.3749  | val_0_accuracy: 0.83791 |  0:00:32s\n","epoch 44 | loss: 0.36958 | val_0_accuracy: 0.84123 |  0:00:32s\n","epoch 45 | loss: 0.37237 | val_0_accuracy: 0.83957 |  0:00:33s\n","epoch 46 | loss: 0.3731  | val_0_accuracy: 0.84456 |  0:00:34s\n","epoch 47 | loss: 0.37027 | val_0_accuracy: 0.83791 |  0:00:35s\n","epoch 48 | loss: 0.37173 | val_0_accuracy: 0.83126 |  0:00:35s\n","epoch 49 | loss: 0.37643 | val_0_accuracy: 0.83624 |  0:00:36s\n","\n","Early stopping occurred at epoch 49 with best_epoch = 39 and best_val_0_accuracy = 0.84871\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-07-06 06:38:45,777] Trial 84 finished with value: 0.8487115544472152 and parameters: {'n_d': 45, 'n_steps': 7, 'gamma': 1.4367355286796748, 'n_independent': 2, 'n_shared': 2, 'momentum': 0.039278750247438314}. Best is trial 42 with value: 0.8728179551122195.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 0.81604 | val_0_accuracy: 0.51372 |  0:00:00s\n","epoch 1  | loss: 0.50183 | val_0_accuracy: 0.51122 |  0:00:01s\n","epoch 2  | loss: 0.4613  | val_0_accuracy: 0.51704 |  0:00:01s\n","epoch 3  | loss: 0.41784 | val_0_accuracy: 0.51372 |  0:00:02s\n","epoch 4  | loss: 0.3981  | val_0_accuracy: 0.50125 |  0:00:03s\n","epoch 5  | loss: 0.39051 | val_0_accuracy: 0.51205 |  0:00:03s\n","epoch 6  | loss: 0.39241 | val_0_accuracy: 0.51704 |  0:00:04s\n","epoch 7  | loss: 0.37813 | val_0_accuracy: 0.5212  |  0:00:04s\n","epoch 8  | loss: 0.37138 | val_0_accuracy: 0.54946 |  0:00:05s\n","epoch 9  | loss: 0.37071 | val_0_accuracy: 0.52286 |  0:00:06s\n","epoch 10 | loss: 0.36782 | val_0_accuracy: 0.5611  |  0:00:06s\n","epoch 11 | loss: 0.356   | val_0_accuracy: 0.54863 |  0:00:07s\n","epoch 12 | loss: 0.35488 | val_0_accuracy: 0.58936 |  0:00:08s\n","epoch 13 | loss: 0.35277 | val_0_accuracy: 0.64256 |  0:00:08s\n","epoch 14 | loss: 0.3571  | val_0_accuracy: 0.69327 |  0:00:09s\n","epoch 15 | loss: 0.3597  | val_0_accuracy: 0.69077 |  0:00:09s\n","epoch 16 | loss: 0.36212 | val_0_accuracy: 0.71239 |  0:00:10s\n","epoch 17 | loss: 0.36763 | val_0_accuracy: 0.6941  |  0:00:11s\n","epoch 18 | loss: 0.3623  | val_0_accuracy: 0.71571 |  0:00:11s\n","epoch 19 | loss: 0.3563  | val_0_accuracy: 0.7448  |  0:00:12s\n","epoch 20 | loss: 0.35762 | val_0_accuracy: 0.7448  |  0:00:13s\n","epoch 21 | loss: 0.35654 | val_0_accuracy: 0.72153 |  0:00:13s\n","epoch 22 | loss: 0.34985 | val_0_accuracy: 0.77224 |  0:00:14s\n","epoch 23 | loss: 0.34685 | val_0_accuracy: 0.77224 |  0:00:14s\n","epoch 24 | loss: 0.3513  | val_0_accuracy: 0.78803 |  0:00:15s\n","epoch 25 | loss: 0.34597 | val_0_accuracy: 0.78803 |  0:00:16s\n","epoch 26 | loss: 0.33848 | val_0_accuracy: 0.77722 |  0:00:16s\n","epoch 27 | loss: 0.33735 | val_0_accuracy: 0.81463 |  0:00:17s\n","epoch 28 | loss: 0.33705 | val_0_accuracy: 0.81712 |  0:00:18s\n","epoch 29 | loss: 0.33603 | val_0_accuracy: 0.82377 |  0:00:18s\n","epoch 30 | loss: 0.33887 | val_0_accuracy: 0.83541 |  0:00:19s\n","epoch 31 | loss: 0.33357 | val_0_accuracy: 0.8271  |  0:00:20s\n","epoch 32 | loss: 0.33233 | val_0_accuracy: 0.82959 |  0:00:20s\n","epoch 33 | loss: 0.32554 | val_0_accuracy: 0.83209 |  0:00:21s\n","epoch 34 | loss: 0.33356 | val_0_accuracy: 0.84289 |  0:00:21s\n","epoch 35 | loss: 0.33145 | val_0_accuracy: 0.84372 |  0:00:22s\n","epoch 36 | loss: 0.32175 | val_0_accuracy: 0.84539 |  0:00:23s\n","epoch 37 | loss: 0.31966 | val_0_accuracy: 0.83707 |  0:00:23s\n","epoch 38 | loss: 0.32197 | val_0_accuracy: 0.85869 |  0:00:24s\n","epoch 39 | loss: 0.32304 | val_0_accuracy: 0.84871 |  0:00:25s\n","epoch 40 | loss: 0.32194 | val_0_accuracy: 0.84954 |  0:00:25s\n","epoch 41 | loss: 0.31969 | val_0_accuracy: 0.85702 |  0:00:26s\n","epoch 42 | loss: 0.31238 | val_0_accuracy: 0.85952 |  0:00:27s\n","epoch 43 | loss: 0.31422 | val_0_accuracy: 0.8537  |  0:00:27s\n","epoch 44 | loss: 0.3167  | val_0_accuracy: 0.85453 |  0:00:28s\n","epoch 45 | loss: 0.31274 | val_0_accuracy: 0.84705 |  0:00:28s\n","epoch 46 | loss: 0.31073 | val_0_accuracy: 0.84788 |  0:00:29s\n","epoch 47 | loss: 0.31152 | val_0_accuracy: 0.85287 |  0:00:30s\n","epoch 48 | loss: 0.30783 | val_0_accuracy: 0.85869 |  0:00:30s\n","epoch 49 | loss: 0.31069 | val_0_accuracy: 0.8537  |  0:00:31s\n","epoch 50 | loss: 0.30073 | val_0_accuracy: 0.86284 |  0:00:31s\n","epoch 51 | loss: 0.30188 | val_0_accuracy: 0.84539 |  0:00:32s\n","epoch 52 | loss: 0.30413 | val_0_accuracy: 0.85952 |  0:00:33s\n","epoch 53 | loss: 0.30303 | val_0_accuracy: 0.85869 |  0:00:33s\n","epoch 54 | loss: 0.30331 | val_0_accuracy: 0.8537  |  0:00:34s\n","epoch 55 | loss: 0.3046  | val_0_accuracy: 0.85287 |  0:00:35s\n","epoch 56 | loss: 0.29763 | val_0_accuracy: 0.86201 |  0:00:35s\n","epoch 57 | loss: 0.2952  | val_0_accuracy: 0.86866 |  0:00:36s\n","epoch 58 | loss: 0.29388 | val_0_accuracy: 0.85453 |  0:00:36s\n","epoch 59 | loss: 0.29521 | val_0_accuracy: 0.8537  |  0:00:37s\n","epoch 60 | loss: 0.29515 | val_0_accuracy: 0.84788 |  0:00:38s\n","epoch 61 | loss: 0.29613 | val_0_accuracy: 0.84539 |  0:00:38s\n","epoch 62 | loss: 0.29674 | val_0_accuracy: 0.85952 |  0:00:39s\n","epoch 63 | loss: 0.29281 | val_0_accuracy: 0.8537  |  0:00:40s\n","epoch 64 | loss: 0.29619 | val_0_accuracy: 0.84289 |  0:00:40s\n","epoch 65 | loss: 0.28707 | val_0_accuracy: 0.86367 |  0:00:41s\n","epoch 66 | loss: 0.2889  | val_0_accuracy: 0.85536 |  0:00:41s\n","epoch 67 | loss: 0.29211 | val_0_accuracy: 0.85536 |  0:00:42s\n","\n","Early stopping occurred at epoch 67 with best_epoch = 57 and best_val_0_accuracy = 0.86866\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-07-06 06:39:28,618] Trial 85 finished with value: 0.8686616791354946 and parameters: {'n_d': 48, 'n_steps': 4, 'gamma': 1.1387690207337018, 'n_independent': 4, 'n_shared': 2, 'momentum': 0.18412498808351746}. Best is trial 42 with value: 0.8728179551122195.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 0.65908 | val_0_accuracy: 0.5345  |  0:00:00s\n","epoch 1  | loss: 0.49885 | val_0_accuracy: 0.51704 |  0:00:01s\n","epoch 2  | loss: 0.46064 | val_0_accuracy: 0.52618 |  0:00:01s\n","epoch 3  | loss: 0.42586 | val_0_accuracy: 0.52868 |  0:00:02s\n","epoch 4  | loss: 0.39896 | val_0_accuracy: 0.52286 |  0:00:02s\n","epoch 5  | loss: 0.39425 | val_0_accuracy: 0.53616 |  0:00:02s\n","epoch 6  | loss: 0.38329 | val_0_accuracy: 0.5586  |  0:00:03s\n","epoch 7  | loss: 0.37517 | val_0_accuracy: 0.5611  |  0:00:04s\n","epoch 8  | loss: 0.36871 | val_0_accuracy: 0.59019 |  0:00:04s\n","epoch 9  | loss: 0.36491 | val_0_accuracy: 0.64672 |  0:00:05s\n","epoch 10 | loss: 0.36238 | val_0_accuracy: 0.59352 |  0:00:05s\n","epoch 11 | loss: 0.35793 | val_0_accuracy: 0.62594 |  0:00:06s\n","epoch 12 | loss: 0.367   | val_0_accuracy: 0.68495 |  0:00:06s\n","epoch 13 | loss: 0.35893 | val_0_accuracy: 0.70407 |  0:00:07s\n","epoch 14 | loss: 0.35478 | val_0_accuracy: 0.69244 |  0:00:07s\n","epoch 15 | loss: 0.36008 | val_0_accuracy: 0.72984 |  0:00:08s\n","epoch 16 | loss: 0.34825 | val_0_accuracy: 0.71654 |  0:00:08s\n","epoch 17 | loss: 0.35307 | val_0_accuracy: 0.72984 |  0:00:09s\n","epoch 18 | loss: 0.34948 | val_0_accuracy: 0.74564 |  0:00:09s\n","epoch 19 | loss: 0.35101 | val_0_accuracy: 0.75478 |  0:00:10s\n","epoch 20 | loss: 0.34999 | val_0_accuracy: 0.7739  |  0:00:10s\n","epoch 21 | loss: 0.34906 | val_0_accuracy: 0.76392 |  0:00:11s\n","epoch 22 | loss: 0.35446 | val_0_accuracy: 0.76725 |  0:00:11s\n","epoch 23 | loss: 0.34107 | val_0_accuracy: 0.7739  |  0:00:12s\n","epoch 24 | loss: 0.33847 | val_0_accuracy: 0.76891 |  0:00:12s\n","epoch 25 | loss: 0.34135 | val_0_accuracy: 0.77307 |  0:00:13s\n","epoch 26 | loss: 0.34218 | val_0_accuracy: 0.79302 |  0:00:13s\n","epoch 27 | loss: 0.34027 | val_0_accuracy: 0.81546 |  0:00:14s\n","epoch 28 | loss: 0.33426 | val_0_accuracy: 0.81047 |  0:00:14s\n","epoch 29 | loss: 0.33551 | val_0_accuracy: 0.81214 |  0:00:15s\n","epoch 30 | loss: 0.33349 | val_0_accuracy: 0.82461 |  0:00:15s\n","epoch 31 | loss: 0.33287 | val_0_accuracy: 0.82461 |  0:00:16s\n","epoch 32 | loss: 0.34079 | val_0_accuracy: 0.83957 |  0:00:16s\n","epoch 33 | loss: 0.33695 | val_0_accuracy: 0.83957 |  0:00:17s\n","epoch 34 | loss: 0.32622 | val_0_accuracy: 0.83375 |  0:00:17s\n","epoch 35 | loss: 0.3311  | val_0_accuracy: 0.83375 |  0:00:18s\n","epoch 36 | loss: 0.32786 | val_0_accuracy: 0.83957 |  0:00:18s\n","epoch 37 | loss: 0.32607 | val_0_accuracy: 0.85037 |  0:00:19s\n","epoch 38 | loss: 0.33074 | val_0_accuracy: 0.84123 |  0:00:19s\n","epoch 39 | loss: 0.33377 | val_0_accuracy: 0.85702 |  0:00:20s\n","epoch 40 | loss: 0.33038 | val_0_accuracy: 0.85702 |  0:00:20s\n","epoch 41 | loss: 0.32535 | val_0_accuracy: 0.85287 |  0:00:21s\n","epoch 42 | loss: 0.32004 | val_0_accuracy: 0.85536 |  0:00:21s\n","epoch 43 | loss: 0.3159  | val_0_accuracy: 0.85287 |  0:00:22s\n","epoch 44 | loss: 0.32281 | val_0_accuracy: 0.85536 |  0:00:22s\n","epoch 45 | loss: 0.31906 | val_0_accuracy: 0.85536 |  0:00:23s\n","epoch 46 | loss: 0.31658 | val_0_accuracy: 0.8537  |  0:00:23s\n","epoch 47 | loss: 0.31663 | val_0_accuracy: 0.85786 |  0:00:24s\n","epoch 48 | loss: 0.31693 | val_0_accuracy: 0.85204 |  0:00:24s\n","epoch 49 | loss: 0.31399 | val_0_accuracy: 0.86284 |  0:00:25s\n","epoch 50 | loss: 0.31031 | val_0_accuracy: 0.85121 |  0:00:25s\n","epoch 51 | loss: 0.31565 | val_0_accuracy: 0.85702 |  0:00:26s\n","epoch 52 | loss: 0.31329 | val_0_accuracy: 0.85287 |  0:00:26s\n","epoch 53 | loss: 0.32014 | val_0_accuracy: 0.85952 |  0:00:27s\n","epoch 54 | loss: 0.32456 | val_0_accuracy: 0.83791 |  0:00:27s\n","epoch 55 | loss: 0.31582 | val_0_accuracy: 0.85869 |  0:00:28s\n","epoch 56 | loss: 0.31322 | val_0_accuracy: 0.86118 |  0:00:28s\n","epoch 57 | loss: 0.3129  | val_0_accuracy: 0.84871 |  0:00:29s\n","epoch 58 | loss: 0.30893 | val_0_accuracy: 0.86451 |  0:00:29s\n","epoch 59 | loss: 0.31438 | val_0_accuracy: 0.84123 |  0:00:30s\n","epoch 60 | loss: 0.31339 | val_0_accuracy: 0.85619 |  0:00:30s\n","epoch 61 | loss: 0.3093  | val_0_accuracy: 0.85702 |  0:00:31s\n","epoch 62 | loss: 0.31197 | val_0_accuracy: 0.85702 |  0:00:31s\n","epoch 63 | loss: 0.31147 | val_0_accuracy: 0.85619 |  0:00:32s\n","epoch 64 | loss: 0.30948 | val_0_accuracy: 0.85702 |  0:00:32s\n","epoch 65 | loss: 0.30781 | val_0_accuracy: 0.84954 |  0:00:33s\n","epoch 66 | loss: 0.30836 | val_0_accuracy: 0.8537  |  0:00:33s\n","epoch 67 | loss: 0.30503 | val_0_accuracy: 0.85952 |  0:00:34s\n","epoch 68 | loss: 0.30918 | val_0_accuracy: 0.87282 |  0:00:34s\n","epoch 69 | loss: 0.30363 | val_0_accuracy: 0.85869 |  0:00:35s\n","epoch 70 | loss: 0.30705 | val_0_accuracy: 0.85702 |  0:00:35s\n","epoch 71 | loss: 0.31338 | val_0_accuracy: 0.85619 |  0:00:36s\n","epoch 72 | loss: 0.30682 | val_0_accuracy: 0.85453 |  0:00:36s\n","epoch 73 | loss: 0.30967 | val_0_accuracy: 0.85952 |  0:00:37s\n","epoch 74 | loss: 0.30304 | val_0_accuracy: 0.86451 |  0:00:37s\n","epoch 75 | loss: 0.3003  | val_0_accuracy: 0.8537  |  0:00:38s\n","epoch 76 | loss: 0.29658 | val_0_accuracy: 0.85952 |  0:00:38s\n","epoch 77 | loss: 0.29681 | val_0_accuracy: 0.85453 |  0:00:39s\n","epoch 78 | loss: 0.29633 | val_0_accuracy: 0.85619 |  0:00:39s\n","\n","Early stopping occurred at epoch 78 with best_epoch = 68 and best_val_0_accuracy = 0.87282\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-07-06 06:40:08,786] Trial 86 finished with value: 0.8728179551122195 and parameters: {'n_d': 31, 'n_steps': 3, 'gamma': 1.3153265173469344, 'n_independent': 3, 'n_shared': 3, 'momentum': 0.13539441924061005}. Best is trial 42 with value: 0.8728179551122195.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 0.62448 | val_0_accuracy: 0.52535 |  0:00:00s\n","epoch 1  | loss: 0.4808  | val_0_accuracy: 0.55611 |  0:00:01s\n","epoch 2  | loss: 0.43595 | val_0_accuracy: 0.51704 |  0:00:01s\n","epoch 3  | loss: 0.42116 | val_0_accuracy: 0.52535 |  0:00:02s\n","epoch 4  | loss: 0.41609 | val_0_accuracy: 0.51704 |  0:00:02s\n","epoch 5  | loss: 0.40413 | val_0_accuracy: 0.51538 |  0:00:03s\n","epoch 6  | loss: 0.40085 | val_0_accuracy: 0.5187  |  0:00:03s\n","epoch 7  | loss: 0.38777 | val_0_accuracy: 0.52037 |  0:00:04s\n","epoch 8  | loss: 0.38179 | val_0_accuracy: 0.53034 |  0:00:05s\n","epoch 9  | loss: 0.38077 | val_0_accuracy: 0.53782 |  0:00:05s\n","epoch 10 | loss: 0.37743 | val_0_accuracy: 0.55694 |  0:00:06s\n","epoch 11 | loss: 0.37696 | val_0_accuracy: 0.54281 |  0:00:06s\n","epoch 12 | loss: 0.36877 | val_0_accuracy: 0.53616 |  0:00:07s\n","epoch 13 | loss: 0.36835 | val_0_accuracy: 0.58687 |  0:00:08s\n","epoch 14 | loss: 0.36792 | val_0_accuracy: 0.53948 |  0:00:08s\n","epoch 15 | loss: 0.36698 | val_0_accuracy: 0.61097 |  0:00:09s\n","epoch 16 | loss: 0.36477 | val_0_accuracy: 0.55029 |  0:00:09s\n","epoch 17 | loss: 0.35892 | val_0_accuracy: 0.5877  |  0:00:10s\n","epoch 18 | loss: 0.35902 | val_0_accuracy: 0.58687 |  0:00:10s\n","epoch 19 | loss: 0.3547  | val_0_accuracy: 0.66334 |  0:00:11s\n","epoch 20 | loss: 0.35946 | val_0_accuracy: 0.58188 |  0:00:11s\n","epoch 21 | loss: 0.35319 | val_0_accuracy: 0.58271 |  0:00:12s\n","epoch 22 | loss: 0.35096 | val_0_accuracy: 0.70657 |  0:00:13s\n","epoch 23 | loss: 0.34819 | val_0_accuracy: 0.72652 |  0:00:13s\n","epoch 24 | loss: 0.34717 | val_0_accuracy: 0.7448  |  0:00:14s\n","epoch 25 | loss: 0.33919 | val_0_accuracy: 0.76309 |  0:00:14s\n","epoch 26 | loss: 0.3378  | val_0_accuracy: 0.78304 |  0:00:15s\n","epoch 27 | loss: 0.33553 | val_0_accuracy: 0.81879 |  0:00:15s\n","epoch 28 | loss: 0.33589 | val_0_accuracy: 0.7872  |  0:00:16s\n","epoch 29 | loss: 0.33597 | val_0_accuracy: 0.8138  |  0:00:16s\n","epoch 30 | loss: 0.3337  | val_0_accuracy: 0.78886 |  0:00:17s\n","epoch 31 | loss: 0.3329  | val_0_accuracy: 0.81214 |  0:00:18s\n","epoch 32 | loss: 0.32819 | val_0_accuracy: 0.82876 |  0:00:18s\n","epoch 33 | loss: 0.32539 | val_0_accuracy: 0.81879 |  0:00:19s\n","epoch 34 | loss: 0.33351 | val_0_accuracy: 0.82627 |  0:00:19s\n","epoch 35 | loss: 0.33844 | val_0_accuracy: 0.84206 |  0:00:20s\n","epoch 36 | loss: 0.32793 | val_0_accuracy: 0.84372 |  0:00:20s\n","epoch 37 | loss: 0.32777 | val_0_accuracy: 0.84871 |  0:00:21s\n","epoch 38 | loss: 0.33019 | val_0_accuracy: 0.85619 |  0:00:22s\n","epoch 39 | loss: 0.3272  | val_0_accuracy: 0.85952 |  0:00:22s\n","epoch 40 | loss: 0.32478 | val_0_accuracy: 0.84539 |  0:00:23s\n","epoch 41 | loss: 0.32636 | val_0_accuracy: 0.85952 |  0:00:23s\n","epoch 42 | loss: 0.32327 | val_0_accuracy: 0.8537  |  0:00:24s\n","epoch 43 | loss: 0.32143 | val_0_accuracy: 0.85952 |  0:00:24s\n","epoch 44 | loss: 0.32071 | val_0_accuracy: 0.85453 |  0:00:25s\n","epoch 45 | loss: 0.3207  | val_0_accuracy: 0.85786 |  0:00:26s\n","epoch 46 | loss: 0.32339 | val_0_accuracy: 0.84871 |  0:00:26s\n","epoch 47 | loss: 0.31963 | val_0_accuracy: 0.85037 |  0:00:27s\n","epoch 48 | loss: 0.31644 | val_0_accuracy: 0.86451 |  0:00:27s\n","epoch 49 | loss: 0.3205  | val_0_accuracy: 0.84372 |  0:00:28s\n","epoch 50 | loss: 0.32089 | val_0_accuracy: 0.86451 |  0:00:28s\n","epoch 51 | loss: 0.3104  | val_0_accuracy: 0.85869 |  0:00:29s\n","epoch 52 | loss: 0.30588 | val_0_accuracy: 0.86201 |  0:00:29s\n","epoch 53 | loss: 0.30893 | val_0_accuracy: 0.85121 |  0:00:30s\n","epoch 54 | loss: 0.31281 | val_0_accuracy: 0.85287 |  0:00:31s\n","epoch 55 | loss: 0.30809 | val_0_accuracy: 0.85869 |  0:00:31s\n","epoch 56 | loss: 0.30619 | val_0_accuracy: 0.85702 |  0:00:32s\n","epoch 57 | loss: 0.3109  | val_0_accuracy: 0.86035 |  0:00:32s\n","epoch 58 | loss: 0.30778 | val_0_accuracy: 0.86201 |  0:00:33s\n","\n","Early stopping occurred at epoch 58 with best_epoch = 48 and best_val_0_accuracy = 0.86451\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-07-06 06:40:42,458] Trial 87 finished with value: 0.8645054031587698 and parameters: {'n_d': 31, 'n_steps': 3, 'gamma': 1.2287123287012764, 'n_independent': 4, 'n_shared': 3, 'momentum': 0.1383354547396837}. Best is trial 42 with value: 0.8728179551122195.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 0.67547 | val_0_accuracy: 0.52452 |  0:00:00s\n","epoch 1  | loss: 0.50572 | val_0_accuracy: 0.52618 |  0:00:01s\n","epoch 2  | loss: 0.47328 | val_0_accuracy: 0.52618 |  0:00:02s\n","epoch 3  | loss: 0.43248 | val_0_accuracy: 0.52452 |  0:00:03s\n","epoch 4  | loss: 0.41613 | val_0_accuracy: 0.52702 |  0:00:03s\n","epoch 5  | loss: 0.42156 | val_0_accuracy: 0.52369 |  0:00:04s\n","epoch 6  | loss: 0.40981 | val_0_accuracy: 0.5877  |  0:00:05s\n","epoch 7  | loss: 0.40716 | val_0_accuracy: 0.61762 |  0:00:06s\n","epoch 8  | loss: 0.39354 | val_0_accuracy: 0.64921 |  0:00:07s\n","epoch 9  | loss: 0.38739 | val_0_accuracy: 0.67415 |  0:00:07s\n","epoch 10 | loss: 0.38756 | val_0_accuracy: 0.67747 |  0:00:08s\n","epoch 11 | loss: 0.37549 | val_0_accuracy: 0.64755 |  0:00:09s\n","epoch 12 | loss: 0.36929 | val_0_accuracy: 0.6542  |  0:00:10s\n","epoch 13 | loss: 0.37695 | val_0_accuracy: 0.69493 |  0:00:10s\n","epoch 14 | loss: 0.36644 | val_0_accuracy: 0.67498 |  0:00:11s\n","epoch 15 | loss: 0.36654 | val_0_accuracy: 0.67332 |  0:00:12s\n","epoch 16 | loss: 0.37016 | val_0_accuracy: 0.73317 |  0:00:13s\n","epoch 17 | loss: 0.36588 | val_0_accuracy: 0.72984 |  0:00:14s\n","epoch 18 | loss: 0.35727 | val_0_accuracy: 0.73234 |  0:00:14s\n","epoch 19 | loss: 0.3548  | val_0_accuracy: 0.74979 |  0:00:15s\n","epoch 20 | loss: 0.35531 | val_0_accuracy: 0.75229 |  0:00:16s\n","epoch 21 | loss: 0.35299 | val_0_accuracy: 0.76725 |  0:00:17s\n","epoch 22 | loss: 0.35351 | val_0_accuracy: 0.75727 |  0:00:17s\n","epoch 23 | loss: 0.34953 | val_0_accuracy: 0.75395 |  0:00:18s\n","epoch 24 | loss: 0.34366 | val_0_accuracy: 0.78138 |  0:00:19s\n","epoch 25 | loss: 0.34931 | val_0_accuracy: 0.80549 |  0:00:20s\n","epoch 26 | loss: 0.35218 | val_0_accuracy: 0.78886 |  0:00:20s\n","epoch 27 | loss: 0.34538 | val_0_accuracy: 0.8005  |  0:00:21s\n","epoch 28 | loss: 0.34042 | val_0_accuracy: 0.80133 |  0:00:22s\n","epoch 29 | loss: 0.34689 | val_0_accuracy: 0.82211 |  0:00:23s\n","epoch 30 | loss: 0.34345 | val_0_accuracy: 0.83791 |  0:00:23s\n","epoch 31 | loss: 0.34607 | val_0_accuracy: 0.81796 |  0:00:24s\n","epoch 32 | loss: 0.34514 | val_0_accuracy: 0.80299 |  0:00:25s\n","epoch 33 | loss: 0.34925 | val_0_accuracy: 0.81879 |  0:00:26s\n","epoch 34 | loss: 0.3555  | val_0_accuracy: 0.83209 |  0:00:26s\n","epoch 35 | loss: 0.35568 | val_0_accuracy: 0.83126 |  0:00:27s\n","epoch 36 | loss: 0.34811 | val_0_accuracy: 0.83624 |  0:00:28s\n","epoch 37 | loss: 0.3444  | val_0_accuracy: 0.84539 |  0:00:29s\n","epoch 38 | loss: 0.33931 | val_0_accuracy: 0.84206 |  0:00:29s\n","epoch 39 | loss: 0.34077 | val_0_accuracy: 0.84206 |  0:00:30s\n","epoch 40 | loss: 0.33755 | val_0_accuracy: 0.8537  |  0:00:31s\n","epoch 41 | loss: 0.33552 | val_0_accuracy: 0.83874 |  0:00:32s\n","epoch 42 | loss: 0.33939 | val_0_accuracy: 0.84539 |  0:00:32s\n","epoch 43 | loss: 0.33841 | val_0_accuracy: 0.85536 |  0:00:33s\n","epoch 44 | loss: 0.33451 | val_0_accuracy: 0.84705 |  0:00:34s\n","epoch 45 | loss: 0.32759 | val_0_accuracy: 0.84123 |  0:00:35s\n","epoch 46 | loss: 0.3306  | val_0_accuracy: 0.84539 |  0:00:36s\n","epoch 47 | loss: 0.33112 | val_0_accuracy: 0.85702 |  0:00:36s\n","epoch 48 | loss: 0.33248 | val_0_accuracy: 0.84788 |  0:00:37s\n","epoch 49 | loss: 0.33647 | val_0_accuracy: 0.84954 |  0:00:38s\n","epoch 50 | loss: 0.33661 | val_0_accuracy: 0.84539 |  0:00:39s\n","epoch 51 | loss: 0.33417 | val_0_accuracy: 0.84788 |  0:00:39s\n","epoch 52 | loss: 0.32757 | val_0_accuracy: 0.85037 |  0:00:40s\n","epoch 53 | loss: 0.3305  | val_0_accuracy: 0.84788 |  0:00:41s\n","epoch 54 | loss: 0.3275  | val_0_accuracy: 0.84954 |  0:00:42s\n","epoch 55 | loss: 0.32778 | val_0_accuracy: 0.85536 |  0:00:42s\n","epoch 56 | loss: 0.32276 | val_0_accuracy: 0.85287 |  0:00:43s\n","epoch 57 | loss: 0.32339 | val_0_accuracy: 0.85702 |  0:00:44s\n","\n","Early stopping occurred at epoch 57 with best_epoch = 47 and best_val_0_accuracy = 0.85702\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-07-06 06:41:27,147] Trial 88 finished with value: 0.857024106400665 and parameters: {'n_d': 26, 'n_steps': 4, 'gamma': 1.3061406844364973, 'n_independent': 4, 'n_shared': 4, 'momentum': 0.12569313410177924}. Best is trial 42 with value: 0.8728179551122195.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 0.63759 | val_0_accuracy: 0.50623 |  0:00:00s\n","epoch 1  | loss: 0.46795 | val_0_accuracy: 0.50374 |  0:00:01s\n","epoch 2  | loss: 0.42795 | val_0_accuracy: 0.51621 |  0:00:01s\n","epoch 3  | loss: 0.39872 | val_0_accuracy: 0.51704 |  0:00:02s\n","epoch 4  | loss: 0.39803 | val_0_accuracy: 0.53367 |  0:00:02s\n","epoch 5  | loss: 0.38246 | val_0_accuracy: 0.55029 |  0:00:03s\n","epoch 6  | loss: 0.38    | val_0_accuracy: 0.57107 |  0:00:04s\n","epoch 7  | loss: 0.37679 | val_0_accuracy: 0.59352 |  0:00:04s\n","epoch 8  | loss: 0.37171 | val_0_accuracy: 0.61347 |  0:00:05s\n","epoch 9  | loss: 0.36535 | val_0_accuracy: 0.59352 |  0:00:05s\n","epoch 10 | loss: 0.36552 | val_0_accuracy: 0.61596 |  0:00:06s\n","epoch 11 | loss: 0.36255 | val_0_accuracy: 0.63009 |  0:00:07s\n","epoch 12 | loss: 0.3578  | val_0_accuracy: 0.63259 |  0:00:07s\n","epoch 13 | loss: 0.35585 | val_0_accuracy: 0.63259 |  0:00:08s\n","epoch 14 | loss: 0.35342 | val_0_accuracy: 0.65586 |  0:00:08s\n","epoch 15 | loss: 0.35896 | val_0_accuracy: 0.71072 |  0:00:09s\n","epoch 16 | loss: 0.36098 | val_0_accuracy: 0.72569 |  0:00:09s\n","epoch 17 | loss: 0.36049 | val_0_accuracy: 0.70574 |  0:00:10s\n","epoch 18 | loss: 0.35151 | val_0_accuracy: 0.72319 |  0:00:10s\n","epoch 19 | loss: 0.35372 | val_0_accuracy: 0.73732 |  0:00:11s\n","epoch 20 | loss: 0.35067 | val_0_accuracy: 0.72901 |  0:00:12s\n","epoch 21 | loss: 0.34708 | val_0_accuracy: 0.75312 |  0:00:12s\n","epoch 22 | loss: 0.33924 | val_0_accuracy: 0.76725 |  0:00:13s\n","epoch 23 | loss: 0.34287 | val_0_accuracy: 0.75312 |  0:00:13s\n","epoch 24 | loss: 0.33976 | val_0_accuracy: 0.75644 |  0:00:14s\n","epoch 25 | loss: 0.33969 | val_0_accuracy: 0.80216 |  0:00:14s\n","epoch 26 | loss: 0.33497 | val_0_accuracy: 0.78304 |  0:00:15s\n","epoch 27 | loss: 0.33511 | val_0_accuracy: 0.79052 |  0:00:15s\n","epoch 28 | loss: 0.3375  | val_0_accuracy: 0.82377 |  0:00:16s\n","epoch 29 | loss: 0.33414 | val_0_accuracy: 0.80216 |  0:00:17s\n","epoch 30 | loss: 0.33187 | val_0_accuracy: 0.81962 |  0:00:17s\n","epoch 31 | loss: 0.33199 | val_0_accuracy: 0.80382 |  0:00:18s\n","epoch 32 | loss: 0.32905 | val_0_accuracy: 0.83957 |  0:00:18s\n","epoch 33 | loss: 0.32699 | val_0_accuracy: 0.84206 |  0:00:19s\n","epoch 34 | loss: 0.32615 | val_0_accuracy: 0.83874 |  0:00:19s\n","epoch 35 | loss: 0.31849 | val_0_accuracy: 0.81712 |  0:00:20s\n","epoch 36 | loss: 0.3207  | val_0_accuracy: 0.82959 |  0:00:20s\n","epoch 37 | loss: 0.32292 | val_0_accuracy: 0.84788 |  0:00:21s\n","epoch 38 | loss: 0.31904 | val_0_accuracy: 0.83624 |  0:00:22s\n","epoch 39 | loss: 0.31925 | val_0_accuracy: 0.84456 |  0:00:22s\n","epoch 40 | loss: 0.31637 | val_0_accuracy: 0.84954 |  0:00:23s\n","epoch 41 | loss: 0.31922 | val_0_accuracy: 0.84705 |  0:00:23s\n","epoch 42 | loss: 0.31683 | val_0_accuracy: 0.85037 |  0:00:24s\n","epoch 43 | loss: 0.31841 | val_0_accuracy: 0.84622 |  0:00:24s\n","epoch 44 | loss: 0.31299 | val_0_accuracy: 0.84788 |  0:00:25s\n","epoch 45 | loss: 0.31222 | val_0_accuracy: 0.85702 |  0:00:25s\n","epoch 46 | loss: 0.31523 | val_0_accuracy: 0.85037 |  0:00:26s\n","epoch 47 | loss: 0.31655 | val_0_accuracy: 0.84871 |  0:00:27s\n","epoch 48 | loss: 0.30741 | val_0_accuracy: 0.85536 |  0:00:27s\n","epoch 49 | loss: 0.30813 | val_0_accuracy: 0.84622 |  0:00:28s\n","epoch 50 | loss: 0.31027 | val_0_accuracy: 0.84871 |  0:00:28s\n","epoch 51 | loss: 0.31941 | val_0_accuracy: 0.84123 |  0:00:29s\n","epoch 52 | loss: 0.3117  | val_0_accuracy: 0.84788 |  0:00:29s\n","epoch 53 | loss: 0.31761 | val_0_accuracy: 0.85453 |  0:00:30s\n","epoch 54 | loss: 0.31119 | val_0_accuracy: 0.85204 |  0:00:30s\n","epoch 55 | loss: 0.31027 | val_0_accuracy: 0.85869 |  0:00:31s\n","epoch 56 | loss: 0.30597 | val_0_accuracy: 0.85204 |  0:00:32s\n","epoch 57 | loss: 0.31135 | val_0_accuracy: 0.85702 |  0:00:32s\n","epoch 58 | loss: 0.30696 | val_0_accuracy: 0.85702 |  0:00:33s\n","epoch 59 | loss: 0.30665 | val_0_accuracy: 0.86118 |  0:00:33s\n","epoch 60 | loss: 0.31176 | val_0_accuracy: 0.85702 |  0:00:34s\n","epoch 61 | loss: 0.30587 | val_0_accuracy: 0.8537  |  0:00:34s\n","epoch 62 | loss: 0.30548 | val_0_accuracy: 0.85453 |  0:00:35s\n","epoch 63 | loss: 0.29933 | val_0_accuracy: 0.84954 |  0:00:35s\n","epoch 64 | loss: 0.3     | val_0_accuracy: 0.85702 |  0:00:36s\n","epoch 65 | loss: 0.30258 | val_0_accuracy: 0.84539 |  0:00:37s\n","epoch 66 | loss: 0.29136 | val_0_accuracy: 0.84954 |  0:00:37s\n","epoch 67 | loss: 0.29944 | val_0_accuracy: 0.85287 |  0:00:38s\n","epoch 68 | loss: 0.29698 | val_0_accuracy: 0.85287 |  0:00:38s\n","epoch 69 | loss: 0.29668 | val_0_accuracy: 0.85121 |  0:00:39s\n","\n","Early stopping occurred at epoch 69 with best_epoch = 59 and best_val_0_accuracy = 0.86118\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-07-06 06:42:06,761] Trial 89 finished with value: 0.8611803823773898 and parameters: {'n_d': 23, 'n_steps': 3, 'gamma': 1.194066071992458, 'n_independent': 4, 'n_shared': 3, 'momentum': 0.11139193509028891}. Best is trial 42 with value: 0.8728179551122195.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 0.80756 | val_0_accuracy: 0.58105 |  0:00:00s\n","epoch 1  | loss: 0.57388 | val_0_accuracy: 0.53117 |  0:00:01s\n","epoch 2  | loss: 0.53341 | val_0_accuracy: 0.57273 |  0:00:02s\n","epoch 3  | loss: 0.49974 | val_0_accuracy: 0.60599 |  0:00:03s\n","epoch 4  | loss: 0.47062 | val_0_accuracy: 0.5611  |  0:00:03s\n","epoch 5  | loss: 0.45205 | val_0_accuracy: 0.6276  |  0:00:04s\n","epoch 6  | loss: 0.43985 | val_0_accuracy: 0.59601 |  0:00:05s\n","epoch 7  | loss: 0.44406 | val_0_accuracy: 0.55445 |  0:00:05s\n","epoch 8  | loss: 0.43593 | val_0_accuracy: 0.61347 |  0:00:06s\n","epoch 9  | loss: 0.43827 | val_0_accuracy: 0.63508 |  0:00:07s\n","epoch 10 | loss: 0.43679 | val_0_accuracy: 0.58188 |  0:00:08s\n","epoch 11 | loss: 0.43065 | val_0_accuracy: 0.58105 |  0:00:08s\n","epoch 12 | loss: 0.43869 | val_0_accuracy: 0.61596 |  0:00:09s\n","epoch 13 | loss: 0.43808 | val_0_accuracy: 0.62178 |  0:00:10s\n","epoch 14 | loss: 0.4357  | val_0_accuracy: 0.64007 |  0:00:10s\n","epoch 15 | loss: 0.43922 | val_0_accuracy: 0.64173 |  0:00:11s\n","epoch 16 | loss: 0.41989 | val_0_accuracy: 0.5985  |  0:00:12s\n","epoch 17 | loss: 0.40556 | val_0_accuracy: 0.66833 |  0:00:13s\n","epoch 18 | loss: 0.40337 | val_0_accuracy: 0.70574 |  0:00:13s\n","epoch 19 | loss: 0.39596 | val_0_accuracy: 0.7473  |  0:00:14s\n","epoch 20 | loss: 0.38783 | val_0_accuracy: 0.73317 |  0:00:15s\n","epoch 21 | loss: 0.38605 | val_0_accuracy: 0.75312 |  0:00:16s\n","epoch 22 | loss: 0.37789 | val_0_accuracy: 0.74647 |  0:00:16s\n","epoch 23 | loss: 0.38774 | val_0_accuracy: 0.74896 |  0:00:17s\n","epoch 24 | loss: 0.39801 | val_0_accuracy: 0.76891 |  0:00:18s\n","epoch 25 | loss: 0.40594 | val_0_accuracy: 0.79468 |  0:00:19s\n","epoch 26 | loss: 0.396   | val_0_accuracy: 0.78554 |  0:00:19s\n","epoch 27 | loss: 0.38567 | val_0_accuracy: 0.79219 |  0:00:20s\n","epoch 28 | loss: 0.38378 | val_0_accuracy: 0.8005  |  0:00:21s\n","epoch 29 | loss: 0.40106 | val_0_accuracy: 0.80798 |  0:00:21s\n","epoch 30 | loss: 0.39513 | val_0_accuracy: 0.80715 |  0:00:22s\n","epoch 31 | loss: 0.39574 | val_0_accuracy: 0.81047 |  0:00:23s\n","epoch 32 | loss: 0.39444 | val_0_accuracy: 0.8138  |  0:00:24s\n","epoch 33 | loss: 0.38247 | val_0_accuracy: 0.81131 |  0:00:24s\n","epoch 34 | loss: 0.37582 | val_0_accuracy: 0.82294 |  0:00:25s\n","epoch 35 | loss: 0.37801 | val_0_accuracy: 0.82211 |  0:00:26s\n","epoch 36 | loss: 0.39136 | val_0_accuracy: 0.80632 |  0:00:27s\n","epoch 37 | loss: 0.38666 | val_0_accuracy: 0.8271  |  0:00:27s\n","epoch 38 | loss: 0.38621 | val_0_accuracy: 0.83541 |  0:00:28s\n","epoch 39 | loss: 0.38553 | val_0_accuracy: 0.83126 |  0:00:29s\n","epoch 40 | loss: 0.38766 | val_0_accuracy: 0.84123 |  0:00:29s\n","epoch 41 | loss: 0.37721 | val_0_accuracy: 0.84372 |  0:00:30s\n","epoch 42 | loss: 0.37229 | val_0_accuracy: 0.84123 |  0:00:31s\n","epoch 43 | loss: 0.37006 | val_0_accuracy: 0.84954 |  0:00:32s\n","epoch 44 | loss: 0.36887 | val_0_accuracy: 0.83541 |  0:00:32s\n","epoch 45 | loss: 0.37753 | val_0_accuracy: 0.83458 |  0:00:33s\n","epoch 46 | loss: 0.36582 | val_0_accuracy: 0.84871 |  0:00:34s\n","epoch 47 | loss: 0.36247 | val_0_accuracy: 0.84705 |  0:00:35s\n","epoch 48 | loss: 0.35833 | val_0_accuracy: 0.85037 |  0:00:35s\n","epoch 49 | loss: 0.35592 | val_0_accuracy: 0.84871 |  0:00:36s\n","epoch 50 | loss: 0.35497 | val_0_accuracy: 0.85204 |  0:00:37s\n","epoch 51 | loss: 0.34827 | val_0_accuracy: 0.85287 |  0:00:37s\n","epoch 52 | loss: 0.34502 | val_0_accuracy: 0.85121 |  0:00:38s\n","epoch 53 | loss: 0.34093 | val_0_accuracy: 0.84788 |  0:00:39s\n","epoch 54 | loss: 0.34133 | val_0_accuracy: 0.85204 |  0:00:40s\n","epoch 55 | loss: 0.33877 | val_0_accuracy: 0.85453 |  0:00:40s\n","epoch 56 | loss: 0.34029 | val_0_accuracy: 0.85869 |  0:00:41s\n","epoch 57 | loss: 0.33597 | val_0_accuracy: 0.85536 |  0:00:42s\n","epoch 58 | loss: 0.33856 | val_0_accuracy: 0.85869 |  0:00:43s\n","epoch 59 | loss: 0.3351  | val_0_accuracy: 0.85619 |  0:00:43s\n","epoch 60 | loss: 0.33324 | val_0_accuracy: 0.85786 |  0:00:44s\n","epoch 61 | loss: 0.33669 | val_0_accuracy: 0.84456 |  0:00:45s\n","epoch 62 | loss: 0.34005 | val_0_accuracy: 0.84788 |  0:00:46s\n","epoch 63 | loss: 0.33547 | val_0_accuracy: 0.85037 |  0:00:46s\n","epoch 64 | loss: 0.33242 | val_0_accuracy: 0.86367 |  0:00:47s\n","epoch 65 | loss: 0.33363 | val_0_accuracy: 0.85702 |  0:00:48s\n","epoch 66 | loss: 0.32718 | val_0_accuracy: 0.86118 |  0:00:48s\n","epoch 67 | loss: 0.32796 | val_0_accuracy: 0.86201 |  0:00:49s\n","epoch 68 | loss: 0.33305 | val_0_accuracy: 0.85786 |  0:00:50s\n","epoch 69 | loss: 0.3277  | val_0_accuracy: 0.86118 |  0:00:51s\n","epoch 70 | loss: 0.32543 | val_0_accuracy: 0.86035 |  0:00:51s\n","epoch 71 | loss: 0.32328 | val_0_accuracy: 0.85869 |  0:00:52s\n","epoch 72 | loss: 0.3322  | val_0_accuracy: 0.85786 |  0:00:53s\n","epoch 73 | loss: 0.32485 | val_0_accuracy: 0.85952 |  0:00:54s\n","epoch 74 | loss: 0.32313 | val_0_accuracy: 0.86035 |  0:00:54s\n","\n","Early stopping occurred at epoch 74 with best_epoch = 64 and best_val_0_accuracy = 0.86367\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-07-06 06:43:01,912] Trial 90 finished with value: 0.8636741479634248 and parameters: {'n_d': 33, 'n_steps': 5, 'gamma': 1.9682950875424008, 'n_independent': 3, 'n_shared': 3, 'momentum': 0.18008212491269557}. Best is trial 42 with value: 0.8728179551122195.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 0.6788  | val_0_accuracy: 0.51122 |  0:00:00s\n","epoch 1  | loss: 0.44078 | val_0_accuracy: 0.52203 |  0:00:00s\n","epoch 2  | loss: 0.42674 | val_0_accuracy: 0.51704 |  0:00:01s\n","epoch 3  | loss: 0.40321 | val_0_accuracy: 0.51704 |  0:00:01s\n","epoch 4  | loss: 0.39206 | val_0_accuracy: 0.51704 |  0:00:02s\n","epoch 5  | loss: 0.389   | val_0_accuracy: 0.51704 |  0:00:02s\n","epoch 6  | loss: 0.38397 | val_0_accuracy: 0.51953 |  0:00:03s\n","epoch 7  | loss: 0.3802  | val_0_accuracy: 0.51953 |  0:00:03s\n","epoch 8  | loss: 0.37422 | val_0_accuracy: 0.5187  |  0:00:03s\n","epoch 9  | loss: 0.37369 | val_0_accuracy: 0.54364 |  0:00:04s\n","epoch 10 | loss: 0.37336 | val_0_accuracy: 0.55528 |  0:00:04s\n","epoch 11 | loss: 0.36565 | val_0_accuracy: 0.54115 |  0:00:05s\n","epoch 12 | loss: 0.36458 | val_0_accuracy: 0.57357 |  0:00:05s\n","epoch 13 | loss: 0.36219 | val_0_accuracy: 0.54115 |  0:00:06s\n","epoch 14 | loss: 0.36077 | val_0_accuracy: 0.67664 |  0:00:06s\n","epoch 15 | loss: 0.35957 | val_0_accuracy: 0.60266 |  0:00:07s\n","epoch 16 | loss: 0.35624 | val_0_accuracy: 0.60432 |  0:00:07s\n","epoch 17 | loss: 0.36123 | val_0_accuracy: 0.65586 |  0:00:07s\n","epoch 18 | loss: 0.35735 | val_0_accuracy: 0.65503 |  0:00:08s\n","epoch 19 | loss: 0.35884 | val_0_accuracy: 0.68994 |  0:00:08s\n","epoch 20 | loss: 0.36072 | val_0_accuracy: 0.65752 |  0:00:09s\n","epoch 21 | loss: 0.35055 | val_0_accuracy: 0.71239 |  0:00:09s\n","epoch 22 | loss: 0.34512 | val_0_accuracy: 0.72735 |  0:00:10s\n","epoch 23 | loss: 0.34609 | val_0_accuracy: 0.7739  |  0:00:10s\n","epoch 24 | loss: 0.34599 | val_0_accuracy: 0.74813 |  0:00:11s\n","epoch 25 | loss: 0.3428  | val_0_accuracy: 0.77639 |  0:00:11s\n","epoch 26 | loss: 0.33941 | val_0_accuracy: 0.77805 |  0:00:11s\n","epoch 27 | loss: 0.33615 | val_0_accuracy: 0.80632 |  0:00:12s\n","epoch 28 | loss: 0.3346  | val_0_accuracy: 0.82211 |  0:00:12s\n","epoch 29 | loss: 0.33078 | val_0_accuracy: 0.79219 |  0:00:13s\n","epoch 30 | loss: 0.33155 | val_0_accuracy: 0.82461 |  0:00:13s\n","epoch 31 | loss: 0.32876 | val_0_accuracy: 0.82128 |  0:00:14s\n","epoch 32 | loss: 0.32643 | val_0_accuracy: 0.81047 |  0:00:14s\n","epoch 33 | loss: 0.32678 | val_0_accuracy: 0.84456 |  0:00:15s\n","epoch 34 | loss: 0.32618 | val_0_accuracy: 0.83624 |  0:00:15s\n","epoch 35 | loss: 0.32386 | val_0_accuracy: 0.83126 |  0:00:15s\n","epoch 36 | loss: 0.32557 | val_0_accuracy: 0.83791 |  0:00:16s\n","epoch 37 | loss: 0.32666 | val_0_accuracy: 0.85619 |  0:00:16s\n","epoch 38 | loss: 0.324   | val_0_accuracy: 0.84206 |  0:00:17s\n","epoch 39 | loss: 0.32381 | val_0_accuracy: 0.84289 |  0:00:17s\n","epoch 40 | loss: 0.32018 | val_0_accuracy: 0.84954 |  0:00:18s\n","epoch 41 | loss: 0.31799 | val_0_accuracy: 0.85121 |  0:00:18s\n","epoch 42 | loss: 0.31573 | val_0_accuracy: 0.84871 |  0:00:18s\n","epoch 43 | loss: 0.31353 | val_0_accuracy: 0.85702 |  0:00:19s\n","epoch 44 | loss: 0.31554 | val_0_accuracy: 0.86284 |  0:00:19s\n","epoch 45 | loss: 0.31702 | val_0_accuracy: 0.85536 |  0:00:20s\n","epoch 46 | loss: 0.31269 | val_0_accuracy: 0.84622 |  0:00:20s\n","epoch 47 | loss: 0.31067 | val_0_accuracy: 0.85786 |  0:00:21s\n","epoch 48 | loss: 0.3073  | val_0_accuracy: 0.86035 |  0:00:21s\n","epoch 49 | loss: 0.30394 | val_0_accuracy: 0.86035 |  0:00:22s\n","epoch 50 | loss: 0.30978 | val_0_accuracy: 0.85536 |  0:00:22s\n","epoch 51 | loss: 0.30692 | val_0_accuracy: 0.85619 |  0:00:23s\n","epoch 52 | loss: 0.30237 | val_0_accuracy: 0.85619 |  0:00:23s\n","epoch 53 | loss: 0.30697 | val_0_accuracy: 0.85869 |  0:00:24s\n","epoch 54 | loss: 0.30578 | val_0_accuracy: 0.86617 |  0:00:24s\n","epoch 55 | loss: 0.29943 | val_0_accuracy: 0.86284 |  0:00:24s\n","epoch 56 | loss: 0.29929 | val_0_accuracy: 0.85786 |  0:00:25s\n","epoch 57 | loss: 0.30328 | val_0_accuracy: 0.86534 |  0:00:25s\n","epoch 58 | loss: 0.29942 | val_0_accuracy: 0.85453 |  0:00:26s\n","epoch 59 | loss: 0.30868 | val_0_accuracy: 0.85619 |  0:00:26s\n","epoch 60 | loss: 0.30123 | val_0_accuracy: 0.85869 |  0:00:27s\n","epoch 61 | loss: 0.29968 | val_0_accuracy: 0.84954 |  0:00:27s\n","epoch 62 | loss: 0.30414 | val_0_accuracy: 0.85702 |  0:00:27s\n","epoch 63 | loss: 0.30296 | val_0_accuracy: 0.86866 |  0:00:28s\n","epoch 64 | loss: 0.29221 | val_0_accuracy: 0.85869 |  0:00:28s\n","epoch 65 | loss: 0.29165 | val_0_accuracy: 0.86035 |  0:00:29s\n","epoch 66 | loss: 0.29073 | val_0_accuracy: 0.86949 |  0:00:29s\n","epoch 67 | loss: 0.28877 | val_0_accuracy: 0.85786 |  0:00:30s\n","epoch 68 | loss: 0.28664 | val_0_accuracy: 0.86201 |  0:00:30s\n","epoch 69 | loss: 0.29373 | val_0_accuracy: 0.84788 |  0:00:31s\n","epoch 70 | loss: 0.28576 | val_0_accuracy: 0.86284 |  0:00:31s\n","epoch 71 | loss: 0.28676 | val_0_accuracy: 0.86451 |  0:00:32s\n","epoch 72 | loss: 0.28596 | val_0_accuracy: 0.85536 |  0:00:32s\n","epoch 73 | loss: 0.29062 | val_0_accuracy: 0.86451 |  0:00:32s\n","epoch 74 | loss: 0.286   | val_0_accuracy: 0.867   |  0:00:33s\n","epoch 75 | loss: 0.28272 | val_0_accuracy: 0.86783 |  0:00:33s\n","epoch 76 | loss: 0.28484 | val_0_accuracy: 0.86451 |  0:00:34s\n","\n","Early stopping occurred at epoch 76 with best_epoch = 66 and best_val_0_accuracy = 0.86949\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-07-06 06:43:36,442] Trial 91 finished with value: 0.8694929343308395 and parameters: {'n_d': 29, 'n_steps': 3, 'gamma': 1.3317167425253316, 'n_independent': 3, 'n_shared': 2, 'momentum': 0.01810844204843782}. Best is trial 42 with value: 0.8728179551122195.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 0.83992 | val_0_accuracy: 0.56276 |  0:00:00s\n","epoch 1  | loss: 0.52054 | val_0_accuracy: 0.61845 |  0:00:01s\n","epoch 2  | loss: 0.47812 | val_0_accuracy: 0.72236 |  0:00:01s\n","epoch 3  | loss: 0.45015 | val_0_accuracy: 0.63425 |  0:00:02s\n","epoch 4  | loss: 0.44238 | val_0_accuracy: 0.66085 |  0:00:03s\n","epoch 5  | loss: 0.42451 | val_0_accuracy: 0.67082 |  0:00:03s\n","epoch 6  | loss: 0.40412 | val_0_accuracy: 0.70989 |  0:00:04s\n","epoch 7  | loss: 0.40427 | val_0_accuracy: 0.68911 |  0:00:04s\n","epoch 8  | loss: 0.40415 | val_0_accuracy: 0.68828 |  0:00:05s\n","epoch 9  | loss: 0.39818 | val_0_accuracy: 0.67914 |  0:00:06s\n","epoch 10 | loss: 0.39541 | val_0_accuracy: 0.71155 |  0:00:06s\n","epoch 11 | loss: 0.3763  | val_0_accuracy: 0.7315  |  0:00:07s\n","epoch 12 | loss: 0.3799  | val_0_accuracy: 0.7049  |  0:00:07s\n","epoch 13 | loss: 0.38249 | val_0_accuracy: 0.70574 |  0:00:08s\n","epoch 14 | loss: 0.3725  | val_0_accuracy: 0.71155 |  0:00:09s\n","epoch 15 | loss: 0.36776 | val_0_accuracy: 0.7207  |  0:00:09s\n","epoch 16 | loss: 0.36788 | val_0_accuracy: 0.71571 |  0:00:10s\n","epoch 17 | loss: 0.35883 | val_0_accuracy: 0.7049  |  0:00:11s\n","epoch 18 | loss: 0.36094 | val_0_accuracy: 0.68994 |  0:00:11s\n","epoch 19 | loss: 0.35622 | val_0_accuracy: 0.73234 |  0:00:12s\n","epoch 20 | loss: 0.35125 | val_0_accuracy: 0.75145 |  0:00:12s\n","epoch 21 | loss: 0.35068 | val_0_accuracy: 0.77473 |  0:00:13s\n","epoch 22 | loss: 0.34156 | val_0_accuracy: 0.74397 |  0:00:14s\n","epoch 23 | loss: 0.34012 | val_0_accuracy: 0.75229 |  0:00:14s\n","epoch 24 | loss: 0.33604 | val_0_accuracy: 0.76226 |  0:00:15s\n","epoch 25 | loss: 0.33977 | val_0_accuracy: 0.75395 |  0:00:15s\n","epoch 26 | loss: 0.33679 | val_0_accuracy: 0.77057 |  0:00:16s\n","epoch 27 | loss: 0.3416  | val_0_accuracy: 0.79468 |  0:00:17s\n","epoch 28 | loss: 0.33285 | val_0_accuracy: 0.78886 |  0:00:17s\n","epoch 29 | loss: 0.33494 | val_0_accuracy: 0.80964 |  0:00:18s\n","epoch 30 | loss: 0.3334  | val_0_accuracy: 0.81214 |  0:00:18s\n","epoch 31 | loss: 0.33369 | val_0_accuracy: 0.82128 |  0:00:19s\n","epoch 32 | loss: 0.32963 | val_0_accuracy: 0.82045 |  0:00:20s\n","epoch 33 | loss: 0.3299  | val_0_accuracy: 0.83042 |  0:00:20s\n","epoch 34 | loss: 0.32562 | val_0_accuracy: 0.83458 |  0:00:21s\n","epoch 35 | loss: 0.32893 | val_0_accuracy: 0.83375 |  0:00:22s\n","epoch 36 | loss: 0.32889 | val_0_accuracy: 0.83957 |  0:00:22s\n","epoch 37 | loss: 0.3285  | val_0_accuracy: 0.84456 |  0:00:23s\n","epoch 38 | loss: 0.32679 | val_0_accuracy: 0.83791 |  0:00:24s\n","epoch 39 | loss: 0.32241 | val_0_accuracy: 0.83126 |  0:00:24s\n","epoch 40 | loss: 0.32353 | val_0_accuracy: 0.85204 |  0:00:25s\n","epoch 41 | loss: 0.32122 | val_0_accuracy: 0.85536 |  0:00:25s\n","epoch 42 | loss: 0.31748 | val_0_accuracy: 0.85037 |  0:00:26s\n","epoch 43 | loss: 0.32039 | val_0_accuracy: 0.85619 |  0:00:27s\n","epoch 44 | loss: 0.31976 | val_0_accuracy: 0.8537  |  0:00:27s\n","epoch 45 | loss: 0.32484 | val_0_accuracy: 0.85869 |  0:00:28s\n","epoch 46 | loss: 0.32027 | val_0_accuracy: 0.85121 |  0:00:28s\n","epoch 47 | loss: 0.32199 | val_0_accuracy: 0.85619 |  0:00:29s\n","epoch 48 | loss: 0.32314 | val_0_accuracy: 0.8537  |  0:00:30s\n","epoch 49 | loss: 0.3194  | val_0_accuracy: 0.85702 |  0:00:30s\n","epoch 50 | loss: 0.31966 | val_0_accuracy: 0.85786 |  0:00:31s\n","epoch 51 | loss: 0.31933 | val_0_accuracy: 0.85121 |  0:00:32s\n","epoch 52 | loss: 0.31766 | val_0_accuracy: 0.85702 |  0:00:32s\n","epoch 53 | loss: 0.31684 | val_0_accuracy: 0.85204 |  0:00:33s\n","epoch 54 | loss: 0.31931 | val_0_accuracy: 0.85204 |  0:00:33s\n","epoch 55 | loss: 0.31964 | val_0_accuracy: 0.86035 |  0:00:34s\n","epoch 56 | loss: 0.32235 | val_0_accuracy: 0.8537  |  0:00:35s\n","epoch 57 | loss: 0.32743 | val_0_accuracy: 0.84954 |  0:00:35s\n","epoch 58 | loss: 0.32509 | val_0_accuracy: 0.8537  |  0:00:36s\n","epoch 59 | loss: 0.31795 | val_0_accuracy: 0.85952 |  0:00:36s\n","epoch 60 | loss: 0.31655 | val_0_accuracy: 0.85619 |  0:00:37s\n","epoch 61 | loss: 0.31562 | val_0_accuracy: 0.86118 |  0:00:38s\n","epoch 62 | loss: 0.31614 | val_0_accuracy: 0.86035 |  0:00:38s\n","epoch 63 | loss: 0.31999 | val_0_accuracy: 0.85786 |  0:00:39s\n","epoch 64 | loss: 0.31079 | val_0_accuracy: 0.85702 |  0:00:40s\n","epoch 65 | loss: 0.31287 | val_0_accuracy: 0.85037 |  0:00:40s\n","epoch 66 | loss: 0.31529 | val_0_accuracy: 0.84788 |  0:00:41s\n","epoch 67 | loss: 0.31164 | val_0_accuracy: 0.86035 |  0:00:41s\n","epoch 68 | loss: 0.31919 | val_0_accuracy: 0.85204 |  0:00:42s\n","epoch 69 | loss: 0.31476 | val_0_accuracy: 0.86201 |  0:00:43s\n","epoch 70 | loss: 0.30973 | val_0_accuracy: 0.84539 |  0:00:43s\n","epoch 71 | loss: 0.318   | val_0_accuracy: 0.85287 |  0:00:44s\n","epoch 72 | loss: 0.30988 | val_0_accuracy: 0.85037 |  0:00:44s\n","epoch 73 | loss: 0.30353 | val_0_accuracy: 0.85453 |  0:00:45s\n","epoch 74 | loss: 0.30774 | val_0_accuracy: 0.85453 |  0:00:46s\n","epoch 75 | loss: 0.30376 | val_0_accuracy: 0.85702 |  0:00:46s\n","epoch 76 | loss: 0.30217 | val_0_accuracy: 0.85121 |  0:00:47s\n","epoch 77 | loss: 0.29938 | val_0_accuracy: 0.86201 |  0:00:47s\n","epoch 78 | loss: 0.3021  | val_0_accuracy: 0.85453 |  0:00:48s\n","epoch 79 | loss: 0.29655 | val_0_accuracy: 0.86035 |  0:00:49s\n","\n","Early stopping occurred at epoch 79 with best_epoch = 69 and best_val_0_accuracy = 0.86201\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-07-06 06:44:26,006] Trial 92 finished with value: 0.8620116375727348 and parameters: {'n_d': 35, 'n_steps': 3, 'gamma': 1.3829830232925662, 'n_independent': 3, 'n_shared': 5, 'momentum': 0.15120879501192683}. Best is trial 42 with value: 0.8728179551122195.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 0.66912 | val_0_accuracy: 0.54613 |  0:00:00s\n","epoch 1  | loss: 0.47595 | val_0_accuracy: 0.51704 |  0:00:00s\n","epoch 2  | loss: 0.45475 | val_0_accuracy: 0.51704 |  0:00:01s\n","epoch 3  | loss: 0.43782 | val_0_accuracy: 0.51787 |  0:00:01s\n","epoch 4  | loss: 0.42246 | val_0_accuracy: 0.52702 |  0:00:02s\n","epoch 5  | loss: 0.40784 | val_0_accuracy: 0.53948 |  0:00:02s\n","epoch 6  | loss: 0.3986  | val_0_accuracy: 0.56858 |  0:00:03s\n","epoch 7  | loss: 0.3886  | val_0_accuracy: 0.60432 |  0:00:03s\n","epoch 8  | loss: 0.38703 | val_0_accuracy: 0.60432 |  0:00:03s\n","epoch 9  | loss: 0.37868 | val_0_accuracy: 0.64838 |  0:00:04s\n","epoch 10 | loss: 0.38177 | val_0_accuracy: 0.7315  |  0:00:04s\n","epoch 11 | loss: 0.37266 | val_0_accuracy: 0.65254 |  0:00:05s\n","epoch 12 | loss: 0.36654 | val_0_accuracy: 0.66916 |  0:00:05s\n","epoch 13 | loss: 0.36087 | val_0_accuracy: 0.69659 |  0:00:06s\n","epoch 14 | loss: 0.35428 | val_0_accuracy: 0.7049  |  0:00:06s\n","epoch 15 | loss: 0.35117 | val_0_accuracy: 0.71405 |  0:00:07s\n","epoch 16 | loss: 0.34874 | val_0_accuracy: 0.72818 |  0:00:07s\n","epoch 17 | loss: 0.34813 | val_0_accuracy: 0.76143 |  0:00:08s\n","epoch 18 | loss: 0.35028 | val_0_accuracy: 0.74564 |  0:00:08s\n","epoch 19 | loss: 0.33864 | val_0_accuracy: 0.72153 |  0:00:08s\n","epoch 20 | loss: 0.33845 | val_0_accuracy: 0.72569 |  0:00:09s\n","epoch 21 | loss: 0.33833 | val_0_accuracy: 0.74397 |  0:00:09s\n","epoch 22 | loss: 0.33863 | val_0_accuracy: 0.79135 |  0:00:10s\n","epoch 23 | loss: 0.3432  | val_0_accuracy: 0.7872  |  0:00:10s\n","epoch 24 | loss: 0.34167 | val_0_accuracy: 0.77639 |  0:00:11s\n","epoch 25 | loss: 0.33663 | val_0_accuracy: 0.78554 |  0:00:11s\n","epoch 26 | loss: 0.34168 | val_0_accuracy: 0.77889 |  0:00:12s\n","epoch 27 | loss: 0.33776 | val_0_accuracy: 0.80549 |  0:00:12s\n","epoch 28 | loss: 0.33114 | val_0_accuracy: 0.80549 |  0:00:12s\n","epoch 29 | loss: 0.33419 | val_0_accuracy: 0.8138  |  0:00:13s\n","epoch 30 | loss: 0.33157 | val_0_accuracy: 0.83375 |  0:00:13s\n","epoch 31 | loss: 0.32768 | val_0_accuracy: 0.83624 |  0:00:14s\n","epoch 32 | loss: 0.33533 | val_0_accuracy: 0.84206 |  0:00:14s\n","epoch 33 | loss: 0.33315 | val_0_accuracy: 0.82544 |  0:00:15s\n","epoch 34 | loss: 0.33365 | val_0_accuracy: 0.84705 |  0:00:15s\n","epoch 35 | loss: 0.33172 | val_0_accuracy: 0.84622 |  0:00:16s\n","epoch 36 | loss: 0.32951 | val_0_accuracy: 0.84456 |  0:00:16s\n","epoch 37 | loss: 0.33028 | val_0_accuracy: 0.83458 |  0:00:16s\n","epoch 38 | loss: 0.3313  | val_0_accuracy: 0.85037 |  0:00:17s\n","epoch 39 | loss: 0.32821 | val_0_accuracy: 0.84705 |  0:00:17s\n","epoch 40 | loss: 0.32944 | val_0_accuracy: 0.84622 |  0:00:18s\n","epoch 41 | loss: 0.33128 | val_0_accuracy: 0.84705 |  0:00:18s\n","epoch 42 | loss: 0.32439 | val_0_accuracy: 0.85287 |  0:00:19s\n","epoch 43 | loss: 0.3253  | val_0_accuracy: 0.84954 |  0:00:19s\n","epoch 44 | loss: 0.32258 | val_0_accuracy: 0.84788 |  0:00:20s\n","epoch 45 | loss: 0.32191 | val_0_accuracy: 0.84954 |  0:00:20s\n","epoch 46 | loss: 0.32163 | val_0_accuracy: 0.8537  |  0:00:20s\n","epoch 47 | loss: 0.31992 | val_0_accuracy: 0.85287 |  0:00:21s\n","epoch 48 | loss: 0.31586 | val_0_accuracy: 0.85536 |  0:00:21s\n","epoch 49 | loss: 0.323   | val_0_accuracy: 0.85287 |  0:00:22s\n","epoch 50 | loss: 0.31649 | val_0_accuracy: 0.85786 |  0:00:22s\n","epoch 51 | loss: 0.31984 | val_0_accuracy: 0.84954 |  0:00:23s\n","epoch 52 | loss: 0.31699 | val_0_accuracy: 0.85287 |  0:00:23s\n","epoch 53 | loss: 0.31767 | val_0_accuracy: 0.85204 |  0:00:24s\n","epoch 54 | loss: 0.30895 | val_0_accuracy: 0.85786 |  0:00:24s\n","epoch 55 | loss: 0.32017 | val_0_accuracy: 0.85204 |  0:00:24s\n","epoch 56 | loss: 0.3194  | val_0_accuracy: 0.85619 |  0:00:25s\n","epoch 57 | loss: 0.31653 | val_0_accuracy: 0.84788 |  0:00:25s\n","epoch 58 | loss: 0.3138  | val_0_accuracy: 0.84871 |  0:00:26s\n","epoch 59 | loss: 0.31643 | val_0_accuracy: 0.85121 |  0:00:26s\n","epoch 60 | loss: 0.31586 | val_0_accuracy: 0.85287 |  0:00:27s\n","\n","Early stopping occurred at epoch 60 with best_epoch = 50 and best_val_0_accuracy = 0.85786\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-07-06 06:44:53,556] Trial 93 finished with value: 0.85785536159601 and parameters: {'n_d': 31, 'n_steps': 3, 'gamma': 1.439201981469224, 'n_independent': 3, 'n_shared': 2, 'momentum': 0.1582902398826346}. Best is trial 42 with value: 0.8728179551122195.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 0.69934 | val_0_accuracy: 0.51122 |  0:00:00s\n","epoch 1  | loss: 0.49177 | val_0_accuracy: 0.51953 |  0:00:00s\n","epoch 2  | loss: 0.46847 | val_0_accuracy: 0.5852  |  0:00:01s\n","epoch 3  | loss: 0.44046 | val_0_accuracy: 0.58853 |  0:00:01s\n","epoch 4  | loss: 0.40291 | val_0_accuracy: 0.59684 |  0:00:02s\n","epoch 5  | loss: 0.38554 | val_0_accuracy: 0.57772 |  0:00:02s\n","epoch 6  | loss: 0.37737 | val_0_accuracy: 0.61596 |  0:00:03s\n","epoch 7  | loss: 0.37906 | val_0_accuracy: 0.62677 |  0:00:03s\n","epoch 8  | loss: 0.37226 | val_0_accuracy: 0.67747 |  0:00:04s\n","epoch 9  | loss: 0.36994 | val_0_accuracy: 0.66168 |  0:00:04s\n","epoch 10 | loss: 0.36258 | val_0_accuracy: 0.67332 |  0:00:05s\n","epoch 11 | loss: 0.35195 | val_0_accuracy: 0.72236 |  0:00:05s\n","epoch 12 | loss: 0.35693 | val_0_accuracy: 0.734   |  0:00:05s\n","epoch 13 | loss: 0.34815 | val_0_accuracy: 0.71737 |  0:00:06s\n","epoch 14 | loss: 0.34844 | val_0_accuracy: 0.75395 |  0:00:06s\n","epoch 15 | loss: 0.34725 | val_0_accuracy: 0.75894 |  0:00:07s\n","epoch 16 | loss: 0.34484 | val_0_accuracy: 0.74647 |  0:00:07s\n","epoch 17 | loss: 0.34435 | val_0_accuracy: 0.7448  |  0:00:08s\n","epoch 18 | loss: 0.34056 | val_0_accuracy: 0.76475 |  0:00:08s\n","epoch 19 | loss: 0.34331 | val_0_accuracy: 0.76808 |  0:00:09s\n","epoch 20 | loss: 0.33514 | val_0_accuracy: 0.73732 |  0:00:09s\n","epoch 21 | loss: 0.33474 | val_0_accuracy: 0.75727 |  0:00:10s\n","epoch 22 | loss: 0.33418 | val_0_accuracy: 0.76392 |  0:00:10s\n","epoch 23 | loss: 0.32939 | val_0_accuracy: 0.77307 |  0:00:11s\n","epoch 24 | loss: 0.33256 | val_0_accuracy: 0.79717 |  0:00:11s\n","epoch 25 | loss: 0.32542 | val_0_accuracy: 0.77889 |  0:00:12s\n","epoch 26 | loss: 0.32882 | val_0_accuracy: 0.78969 |  0:00:12s\n","epoch 27 | loss: 0.32393 | val_0_accuracy: 0.79302 |  0:00:13s\n","epoch 28 | loss: 0.32688 | val_0_accuracy: 0.81546 |  0:00:13s\n","epoch 29 | loss: 0.32799 | val_0_accuracy: 0.82627 |  0:00:14s\n","epoch 30 | loss: 0.32518 | val_0_accuracy: 0.82377 |  0:00:14s\n","epoch 31 | loss: 0.31611 | val_0_accuracy: 0.81879 |  0:00:15s\n","epoch 32 | loss: 0.31762 | val_0_accuracy: 0.81297 |  0:00:15s\n","epoch 33 | loss: 0.32024 | val_0_accuracy: 0.83541 |  0:00:15s\n","epoch 34 | loss: 0.31817 | val_0_accuracy: 0.85952 |  0:00:16s\n","epoch 35 | loss: 0.31591 | val_0_accuracy: 0.85869 |  0:00:16s\n","epoch 36 | loss: 0.31455 | val_0_accuracy: 0.85204 |  0:00:17s\n","epoch 37 | loss: 0.31575 | val_0_accuracy: 0.85869 |  0:00:17s\n","epoch 38 | loss: 0.31886 | val_0_accuracy: 0.85121 |  0:00:18s\n","epoch 39 | loss: 0.32709 | val_0_accuracy: 0.86035 |  0:00:18s\n","epoch 40 | loss: 0.32279 | val_0_accuracy: 0.85287 |  0:00:19s\n","epoch 41 | loss: 0.31344 | val_0_accuracy: 0.85952 |  0:00:19s\n","epoch 42 | loss: 0.31106 | val_0_accuracy: 0.85453 |  0:00:20s\n","epoch 43 | loss: 0.31311 | val_0_accuracy: 0.85287 |  0:00:20s\n","epoch 44 | loss: 0.31058 | val_0_accuracy: 0.867   |  0:00:20s\n","epoch 45 | loss: 0.30688 | val_0_accuracy: 0.85869 |  0:00:21s\n","epoch 46 | loss: 0.3023  | val_0_accuracy: 0.85952 |  0:00:21s\n","epoch 47 | loss: 0.3043  | val_0_accuracy: 0.86451 |  0:00:22s\n","epoch 48 | loss: 0.3074  | val_0_accuracy: 0.85702 |  0:00:22s\n","epoch 49 | loss: 0.29909 | val_0_accuracy: 0.85869 |  0:00:23s\n","epoch 50 | loss: 0.30409 | val_0_accuracy: 0.86367 |  0:00:23s\n","epoch 51 | loss: 0.31226 | val_0_accuracy: 0.85619 |  0:00:24s\n","epoch 52 | loss: 0.30521 | val_0_accuracy: 0.86035 |  0:00:24s\n","epoch 53 | loss: 0.30444 | val_0_accuracy: 0.86367 |  0:00:25s\n","epoch 54 | loss: 0.29937 | val_0_accuracy: 0.85786 |  0:00:25s\n","\n","Early stopping occurred at epoch 54 with best_epoch = 44 and best_val_0_accuracy = 0.867\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-07-06 06:45:19,369] Trial 94 finished with value: 0.8669991687448046 and parameters: {'n_d': 43, 'n_steps': 3, 'gamma': 1.502668668122552, 'n_independent': 3, 'n_shared': 2, 'momentum': 0.08254752288953018}. Best is trial 42 with value: 0.8728179551122195.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 0.68957 | val_0_accuracy: 0.56359 |  0:00:00s\n","epoch 1  | loss: 0.52789 | val_0_accuracy: 0.532   |  0:00:01s\n","epoch 2  | loss: 0.46168 | val_0_accuracy: 0.5187  |  0:00:01s\n","epoch 3  | loss: 0.44275 | val_0_accuracy: 0.52702 |  0:00:02s\n","epoch 4  | loss: 0.41771 | val_0_accuracy: 0.55528 |  0:00:03s\n","epoch 5  | loss: 0.40652 | val_0_accuracy: 0.59933 |  0:00:03s\n","epoch 6  | loss: 0.40261 | val_0_accuracy: 0.60349 |  0:00:04s\n","epoch 7  | loss: 0.3928  | val_0_accuracy: 0.65254 |  0:00:05s\n","epoch 8  | loss: 0.38471 | val_0_accuracy: 0.68495 |  0:00:05s\n","epoch 9  | loss: 0.37527 | val_0_accuracy: 0.70407 |  0:00:06s\n","epoch 10 | loss: 0.37136 | val_0_accuracy: 0.68662 |  0:00:06s\n","epoch 11 | loss: 0.38006 | val_0_accuracy: 0.73317 |  0:00:07s\n","epoch 12 | loss: 0.36918 | val_0_accuracy: 0.72901 |  0:00:08s\n","epoch 13 | loss: 0.36581 | val_0_accuracy: 0.69659 |  0:00:08s\n","epoch 14 | loss: 0.36812 | val_0_accuracy: 0.71155 |  0:00:09s\n","epoch 15 | loss: 0.36342 | val_0_accuracy: 0.71904 |  0:00:10s\n","epoch 16 | loss: 0.36297 | val_0_accuracy: 0.68329 |  0:00:10s\n","epoch 17 | loss: 0.36473 | val_0_accuracy: 0.7315  |  0:00:11s\n","epoch 18 | loss: 0.37652 | val_0_accuracy: 0.74813 |  0:00:12s\n","epoch 19 | loss: 0.36195 | val_0_accuracy: 0.70407 |  0:00:12s\n","epoch 20 | loss: 0.35708 | val_0_accuracy: 0.71155 |  0:00:13s\n","epoch 21 | loss: 0.34742 | val_0_accuracy: 0.75229 |  0:00:13s\n","epoch 22 | loss: 0.34924 | val_0_accuracy: 0.7581  |  0:00:14s\n","epoch 23 | loss: 0.3449  | val_0_accuracy: 0.76475 |  0:00:15s\n","epoch 24 | loss: 0.346   | val_0_accuracy: 0.77057 |  0:00:15s\n","epoch 25 | loss: 0.34239 | val_0_accuracy: 0.78387 |  0:00:16s\n","epoch 26 | loss: 0.34289 | val_0_accuracy: 0.80798 |  0:00:17s\n","epoch 27 | loss: 0.35117 | val_0_accuracy: 0.79135 |  0:00:17s\n","epoch 28 | loss: 0.34691 | val_0_accuracy: 0.81796 |  0:00:18s\n","epoch 29 | loss: 0.35132 | val_0_accuracy: 0.81879 |  0:00:19s\n","epoch 30 | loss: 0.34799 | val_0_accuracy: 0.82544 |  0:00:19s\n","epoch 31 | loss: 0.34975 | val_0_accuracy: 0.82377 |  0:00:20s\n","epoch 32 | loss: 0.33986 | val_0_accuracy: 0.82294 |  0:00:21s\n","epoch 33 | loss: 0.34497 | val_0_accuracy: 0.83209 |  0:00:21s\n","epoch 34 | loss: 0.34345 | val_0_accuracy: 0.83209 |  0:00:22s\n","epoch 35 | loss: 0.34657 | val_0_accuracy: 0.83791 |  0:00:23s\n","epoch 36 | loss: 0.34156 | val_0_accuracy: 0.83874 |  0:00:23s\n","epoch 37 | loss: 0.33757 | val_0_accuracy: 0.84289 |  0:00:24s\n","epoch 38 | loss: 0.33597 | val_0_accuracy: 0.83791 |  0:00:25s\n","epoch 39 | loss: 0.34512 | val_0_accuracy: 0.83624 |  0:00:25s\n","epoch 40 | loss: 0.33741 | val_0_accuracy: 0.85869 |  0:00:26s\n","epoch 41 | loss: 0.33302 | val_0_accuracy: 0.84456 |  0:00:26s\n","epoch 42 | loss: 0.33076 | val_0_accuracy: 0.85287 |  0:00:27s\n","epoch 43 | loss: 0.33161 | val_0_accuracy: 0.84705 |  0:00:28s\n","epoch 44 | loss: 0.33211 | val_0_accuracy: 0.85453 |  0:00:28s\n","epoch 45 | loss: 0.33584 | val_0_accuracy: 0.84705 |  0:00:29s\n","epoch 46 | loss: 0.32862 | val_0_accuracy: 0.85037 |  0:00:30s\n","epoch 47 | loss: 0.33342 | val_0_accuracy: 0.85037 |  0:00:30s\n","epoch 48 | loss: 0.32708 | val_0_accuracy: 0.85952 |  0:00:31s\n","epoch 49 | loss: 0.32406 | val_0_accuracy: 0.84871 |  0:00:32s\n","epoch 50 | loss: 0.32293 | val_0_accuracy: 0.85453 |  0:00:32s\n","epoch 51 | loss: 0.32911 | val_0_accuracy: 0.85453 |  0:00:33s\n","epoch 52 | loss: 0.32266 | val_0_accuracy: 0.85619 |  0:00:33s\n","epoch 53 | loss: 0.32529 | val_0_accuracy: 0.85952 |  0:00:34s\n","epoch 54 | loss: 0.32671 | val_0_accuracy: 0.85536 |  0:00:35s\n","epoch 55 | loss: 0.32251 | val_0_accuracy: 0.85121 |  0:00:35s\n","epoch 56 | loss: 0.3248  | val_0_accuracy: 0.84206 |  0:00:36s\n","epoch 57 | loss: 0.32677 | val_0_accuracy: 0.85204 |  0:00:37s\n","epoch 58 | loss: 0.32792 | val_0_accuracy: 0.8537  |  0:00:37s\n","\n","Early stopping occurred at epoch 58 with best_epoch = 48 and best_val_0_accuracy = 0.85952\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-07-06 06:45:57,481] Trial 95 finished with value: 0.8595178719866999 and parameters: {'n_d': 39, 'n_steps': 4, 'gamma': 1.3741291521264583, 'n_independent': 3, 'n_shared': 3, 'momentum': 0.09745923550797583}. Best is trial 42 with value: 0.8728179551122195.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 0.72961 | val_0_accuracy: 0.56276 |  0:00:00s\n","epoch 1  | loss: 0.4914  | val_0_accuracy: 0.54447 |  0:00:01s\n","epoch 2  | loss: 0.44474 | val_0_accuracy: 0.54281 |  0:00:01s\n","epoch 3  | loss: 0.4276  | val_0_accuracy: 0.56359 |  0:00:02s\n","epoch 4  | loss: 0.40924 | val_0_accuracy: 0.5453  |  0:00:02s\n","epoch 5  | loss: 0.39313 | val_0_accuracy: 0.52535 |  0:00:03s\n","epoch 6  | loss: 0.39231 | val_0_accuracy: 0.52535 |  0:00:03s\n","epoch 7  | loss: 0.38335 | val_0_accuracy: 0.52369 |  0:00:04s\n","epoch 8  | loss: 0.38264 | val_0_accuracy: 0.54281 |  0:00:05s\n","epoch 9  | loss: 0.38137 | val_0_accuracy: 0.53283 |  0:00:05s\n","epoch 10 | loss: 0.37445 | val_0_accuracy: 0.57523 |  0:00:06s\n","epoch 11 | loss: 0.37585 | val_0_accuracy: 0.65337 |  0:00:06s\n","epoch 12 | loss: 0.3707  | val_0_accuracy: 0.64339 |  0:00:07s\n","epoch 13 | loss: 0.37215 | val_0_accuracy: 0.69077 |  0:00:07s\n","epoch 14 | loss: 0.3691  | val_0_accuracy: 0.71571 |  0:00:08s\n","epoch 15 | loss: 0.36374 | val_0_accuracy: 0.72319 |  0:00:08s\n","epoch 16 | loss: 0.35923 | val_0_accuracy: 0.73317 |  0:00:09s\n","epoch 17 | loss: 0.34995 | val_0_accuracy: 0.71488 |  0:00:10s\n","epoch 18 | loss: 0.35072 | val_0_accuracy: 0.7207  |  0:00:10s\n","epoch 19 | loss: 0.3523  | val_0_accuracy: 0.73317 |  0:00:11s\n","epoch 20 | loss: 0.35734 | val_0_accuracy: 0.73483 |  0:00:11s\n","epoch 21 | loss: 0.34607 | val_0_accuracy: 0.75644 |  0:00:12s\n","epoch 22 | loss: 0.34066 | val_0_accuracy: 0.75062 |  0:00:12s\n","epoch 23 | loss: 0.34391 | val_0_accuracy: 0.77224 |  0:00:13s\n","epoch 24 | loss: 0.34309 | val_0_accuracy: 0.75478 |  0:00:13s\n","epoch 25 | loss: 0.34786 | val_0_accuracy: 0.74813 |  0:00:14s\n","epoch 26 | loss: 0.33896 | val_0_accuracy: 0.78055 |  0:00:15s\n","epoch 27 | loss: 0.33496 | val_0_accuracy: 0.78304 |  0:00:15s\n","epoch 28 | loss: 0.33186 | val_0_accuracy: 0.82128 |  0:00:16s\n","epoch 29 | loss: 0.3298  | val_0_accuracy: 0.82045 |  0:00:16s\n","epoch 30 | loss: 0.33066 | val_0_accuracy: 0.8271  |  0:00:17s\n","epoch 31 | loss: 0.32713 | val_0_accuracy: 0.82876 |  0:00:17s\n","epoch 32 | loss: 0.32637 | val_0_accuracy: 0.83042 |  0:00:18s\n","epoch 33 | loss: 0.32698 | val_0_accuracy: 0.82793 |  0:00:19s\n","epoch 34 | loss: 0.32892 | val_0_accuracy: 0.84954 |  0:00:19s\n","epoch 35 | loss: 0.33005 | val_0_accuracy: 0.85121 |  0:00:20s\n","epoch 36 | loss: 0.32705 | val_0_accuracy: 0.84788 |  0:00:20s\n","epoch 37 | loss: 0.32606 | val_0_accuracy: 0.84206 |  0:00:21s\n","epoch 38 | loss: 0.32686 | val_0_accuracy: 0.84705 |  0:00:21s\n","epoch 39 | loss: 0.3231  | val_0_accuracy: 0.85037 |  0:00:22s\n","epoch 40 | loss: 0.32358 | val_0_accuracy: 0.85037 |  0:00:23s\n","epoch 41 | loss: 0.32169 | val_0_accuracy: 0.85204 |  0:00:23s\n","epoch 42 | loss: 0.3228  | val_0_accuracy: 0.83791 |  0:00:24s\n","epoch 43 | loss: 0.32404 | val_0_accuracy: 0.85037 |  0:00:24s\n","epoch 44 | loss: 0.32193 | val_0_accuracy: 0.84954 |  0:00:25s\n","epoch 45 | loss: 0.31958 | val_0_accuracy: 0.85619 |  0:00:25s\n","epoch 46 | loss: 0.31391 | val_0_accuracy: 0.85536 |  0:00:26s\n","epoch 47 | loss: 0.31875 | val_0_accuracy: 0.85536 |  0:00:26s\n","epoch 48 | loss: 0.31915 | val_0_accuracy: 0.85121 |  0:00:27s\n","epoch 49 | loss: 0.31592 | val_0_accuracy: 0.85536 |  0:00:28s\n","epoch 50 | loss: 0.31379 | val_0_accuracy: 0.85619 |  0:00:28s\n","epoch 51 | loss: 0.31183 | val_0_accuracy: 0.85952 |  0:00:29s\n","epoch 52 | loss: 0.31332 | val_0_accuracy: 0.85869 |  0:00:29s\n","epoch 53 | loss: 0.30869 | val_0_accuracy: 0.85619 |  0:00:30s\n","epoch 54 | loss: 0.30902 | val_0_accuracy: 0.85619 |  0:00:30s\n","epoch 55 | loss: 0.31513 | val_0_accuracy: 0.85786 |  0:00:31s\n","epoch 56 | loss: 0.31812 | val_0_accuracy: 0.84456 |  0:00:31s\n","epoch 57 | loss: 0.30829 | val_0_accuracy: 0.84788 |  0:00:32s\n","epoch 58 | loss: 0.31571 | val_0_accuracy: 0.86201 |  0:00:33s\n","epoch 59 | loss: 0.30831 | val_0_accuracy: 0.85453 |  0:00:33s\n","epoch 60 | loss: 0.31895 | val_0_accuracy: 0.85536 |  0:00:34s\n","epoch 61 | loss: 0.313   | val_0_accuracy: 0.85619 |  0:00:34s\n","epoch 62 | loss: 0.31462 | val_0_accuracy: 0.85453 |  0:00:35s\n","epoch 63 | loss: 0.31143 | val_0_accuracy: 0.86201 |  0:00:35s\n","epoch 64 | loss: 0.31686 | val_0_accuracy: 0.86949 |  0:00:36s\n","epoch 65 | loss: 0.31611 | val_0_accuracy: 0.85453 |  0:00:36s\n","epoch 66 | loss: 0.32404 | val_0_accuracy: 0.85204 |  0:00:37s\n","epoch 67 | loss: 0.31485 | val_0_accuracy: 0.85619 |  0:00:38s\n","epoch 68 | loss: 0.31622 | val_0_accuracy: 0.85702 |  0:00:38s\n","epoch 69 | loss: 0.31029 | val_0_accuracy: 0.85952 |  0:00:39s\n","epoch 70 | loss: 0.31063 | val_0_accuracy: 0.86118 |  0:00:39s\n","epoch 71 | loss: 0.3072  | val_0_accuracy: 0.86534 |  0:00:40s\n","epoch 72 | loss: 0.3105  | val_0_accuracy: 0.85702 |  0:00:40s\n","epoch 73 | loss: 0.30508 | val_0_accuracy: 0.86367 |  0:00:41s\n","epoch 74 | loss: 0.3049  | val_0_accuracy: 0.86534 |  0:00:41s\n","\n","Early stopping occurred at epoch 74 with best_epoch = 64 and best_val_0_accuracy = 0.86949\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-07-06 06:46:39,823] Trial 96 finished with value: 0.8694929343308395 and parameters: {'n_d': 54, 'n_steps': 4, 'gamma': 1.4064169656579995, 'n_independent': 4, 'n_shared': 1, 'momentum': 0.25289671867511665}. Best is trial 42 with value: 0.8728179551122195.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 0.68697 | val_0_accuracy: 0.52702 |  0:00:00s\n","epoch 1  | loss: 0.46767 | val_0_accuracy: 0.52785 |  0:00:00s\n","epoch 2  | loss: 0.427   | val_0_accuracy: 0.58105 |  0:00:01s\n","epoch 3  | loss: 0.40267 | val_0_accuracy: 0.56027 |  0:00:01s\n","epoch 4  | loss: 0.38306 | val_0_accuracy: 0.58603 |  0:00:02s\n","epoch 5  | loss: 0.37083 | val_0_accuracy: 0.56442 |  0:00:02s\n","epoch 6  | loss: 0.35891 | val_0_accuracy: 0.57938 |  0:00:02s\n","epoch 7  | loss: 0.3562  | val_0_accuracy: 0.61679 |  0:00:03s\n","epoch 8  | loss: 0.3567  | val_0_accuracy: 0.58105 |  0:00:03s\n","epoch 9  | loss: 0.35642 | val_0_accuracy: 0.58603 |  0:00:04s\n","epoch 10 | loss: 0.35241 | val_0_accuracy: 0.62095 |  0:00:04s\n","epoch 11 | loss: 0.35177 | val_0_accuracy: 0.665   |  0:00:04s\n","epoch 12 | loss: 0.35064 | val_0_accuracy: 0.59268 |  0:00:05s\n","epoch 13 | loss: 0.34741 | val_0_accuracy: 0.68329 |  0:00:05s\n","epoch 14 | loss: 0.34469 | val_0_accuracy: 0.68163 |  0:00:06s\n","epoch 15 | loss: 0.33818 | val_0_accuracy: 0.67747 |  0:00:06s\n","epoch 16 | loss: 0.33898 | val_0_accuracy: 0.7049  |  0:00:06s\n","epoch 17 | loss: 0.33787 | val_0_accuracy: 0.71072 |  0:00:07s\n","epoch 18 | loss: 0.33785 | val_0_accuracy: 0.70574 |  0:00:07s\n","epoch 19 | loss: 0.33098 | val_0_accuracy: 0.71488 |  0:00:08s\n","epoch 20 | loss: 0.3315  | val_0_accuracy: 0.70324 |  0:00:08s\n","epoch 21 | loss: 0.32672 | val_0_accuracy: 0.74979 |  0:00:09s\n","epoch 22 | loss: 0.32914 | val_0_accuracy: 0.73982 |  0:00:09s\n","epoch 23 | loss: 0.32612 | val_0_accuracy: 0.7847  |  0:00:10s\n","epoch 24 | loss: 0.32138 | val_0_accuracy: 0.77473 |  0:00:10s\n","epoch 25 | loss: 0.32192 | val_0_accuracy: 0.79302 |  0:00:10s\n","epoch 26 | loss: 0.3234  | val_0_accuracy: 0.77889 |  0:00:11s\n","epoch 27 | loss: 0.32455 | val_0_accuracy: 0.81047 |  0:00:11s\n","epoch 28 | loss: 0.32082 | val_0_accuracy: 0.80133 |  0:00:12s\n","epoch 29 | loss: 0.32033 | val_0_accuracy: 0.81962 |  0:00:12s\n","epoch 30 | loss: 0.32534 | val_0_accuracy: 0.82377 |  0:00:13s\n","epoch 31 | loss: 0.3226  | val_0_accuracy: 0.8271  |  0:00:13s\n","epoch 32 | loss: 0.31897 | val_0_accuracy: 0.82627 |  0:00:13s\n","epoch 33 | loss: 0.31812 | val_0_accuracy: 0.83957 |  0:00:14s\n","epoch 34 | loss: 0.32112 | val_0_accuracy: 0.84788 |  0:00:14s\n","epoch 35 | loss: 0.3158  | val_0_accuracy: 0.83874 |  0:00:15s\n","epoch 36 | loss: 0.31659 | val_0_accuracy: 0.83541 |  0:00:15s\n","epoch 37 | loss: 0.32151 | val_0_accuracy: 0.84788 |  0:00:16s\n","epoch 38 | loss: 0.30948 | val_0_accuracy: 0.84123 |  0:00:16s\n","epoch 39 | loss: 0.32043 | val_0_accuracy: 0.84539 |  0:00:16s\n","epoch 40 | loss: 0.31036 | val_0_accuracy: 0.85121 |  0:00:17s\n","epoch 41 | loss: 0.3061  | val_0_accuracy: 0.85287 |  0:00:17s\n","epoch 42 | loss: 0.30643 | val_0_accuracy: 0.84622 |  0:00:18s\n","epoch 43 | loss: 0.31221 | val_0_accuracy: 0.85121 |  0:00:18s\n","epoch 44 | loss: 0.30621 | val_0_accuracy: 0.8537  |  0:00:19s\n","epoch 45 | loss: 0.30744 | val_0_accuracy: 0.84954 |  0:00:19s\n","epoch 46 | loss: 0.30069 | val_0_accuracy: 0.8537  |  0:00:20s\n","epoch 47 | loss: 0.2985  | val_0_accuracy: 0.85702 |  0:00:20s\n","epoch 48 | loss: 0.29452 | val_0_accuracy: 0.8537  |  0:00:21s\n","epoch 49 | loss: 0.30255 | val_0_accuracy: 0.85037 |  0:00:21s\n","epoch 50 | loss: 0.29971 | val_0_accuracy: 0.85121 |  0:00:21s\n","epoch 51 | loss: 0.30419 | val_0_accuracy: 0.84705 |  0:00:22s\n","epoch 52 | loss: 0.30043 | val_0_accuracy: 0.85536 |  0:00:22s\n","epoch 53 | loss: 0.30209 | val_0_accuracy: 0.85287 |  0:00:23s\n","epoch 54 | loss: 0.30116 | val_0_accuracy: 0.85536 |  0:00:23s\n","epoch 55 | loss: 0.29963 | val_0_accuracy: 0.85453 |  0:00:23s\n","epoch 56 | loss: 0.29411 | val_0_accuracy: 0.85037 |  0:00:24s\n","epoch 57 | loss: 0.29168 | val_0_accuracy: 0.85786 |  0:00:24s\n","epoch 58 | loss: 0.28855 | val_0_accuracy: 0.84372 |  0:00:25s\n","epoch 59 | loss: 0.29161 | val_0_accuracy: 0.83957 |  0:00:25s\n","epoch 60 | loss: 0.29064 | val_0_accuracy: 0.85619 |  0:00:26s\n","epoch 61 | loss: 0.28877 | val_0_accuracy: 0.84705 |  0:00:26s\n","epoch 62 | loss: 0.28553 | val_0_accuracy: 0.84456 |  0:00:26s\n","epoch 63 | loss: 0.28972 | val_0_accuracy: 0.85204 |  0:00:27s\n","epoch 64 | loss: 0.28004 | val_0_accuracy: 0.84206 |  0:00:27s\n","epoch 65 | loss: 0.28349 | val_0_accuracy: 0.85204 |  0:00:28s\n","epoch 66 | loss: 0.28476 | val_0_accuracy: 0.84705 |  0:00:28s\n","epoch 67 | loss: 0.28402 | val_0_accuracy: 0.85702 |  0:00:28s\n","\n","Early stopping occurred at epoch 67 with best_epoch = 57 and best_val_0_accuracy = 0.85786\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-07-06 06:47:09,010] Trial 97 finished with value: 0.85785536159601 and parameters: {'n_d': 50, 'n_steps': 3, 'gamma': 1.275098697558152, 'n_independent': 2, 'n_shared': 2, 'momentum': 0.0657935199341124}. Best is trial 42 with value: 0.8728179551122195.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 0.79065 | val_0_accuracy: 0.53533 |  0:00:00s\n","epoch 1  | loss: 0.54866 | val_0_accuracy: 0.56525 |  0:00:01s\n","epoch 2  | loss: 0.48886 | val_0_accuracy: 0.56692 |  0:00:01s\n","epoch 3  | loss: 0.46904 | val_0_accuracy: 0.58437 |  0:00:02s\n","epoch 4  | loss: 0.44355 | val_0_accuracy: 0.61679 |  0:00:03s\n","epoch 5  | loss: 0.42535 | val_0_accuracy: 0.60765 |  0:00:03s\n","epoch 6  | loss: 0.41856 | val_0_accuracy: 0.63924 |  0:00:04s\n","epoch 7  | loss: 0.41687 | val_0_accuracy: 0.67498 |  0:00:04s\n","epoch 8  | loss: 0.40435 | val_0_accuracy: 0.68246 |  0:00:05s\n","epoch 9  | loss: 0.39844 | val_0_accuracy: 0.6409  |  0:00:05s\n","epoch 10 | loss: 0.38984 | val_0_accuracy: 0.61264 |  0:00:06s\n","epoch 11 | loss: 0.38265 | val_0_accuracy: 0.58105 |  0:00:06s\n","epoch 12 | loss: 0.37807 | val_0_accuracy: 0.6143  |  0:00:07s\n","epoch 13 | loss: 0.37447 | val_0_accuracy: 0.68579 |  0:00:07s\n","epoch 14 | loss: 0.37997 | val_0_accuracy: 0.62178 |  0:00:08s\n","epoch 15 | loss: 0.37066 | val_0_accuracy: 0.63924 |  0:00:08s\n","epoch 16 | loss: 0.36797 | val_0_accuracy: 0.665   |  0:00:09s\n","epoch 17 | loss: 0.36166 | val_0_accuracy: 0.67332 |  0:00:09s\n","epoch 18 | loss: 0.35986 | val_0_accuracy: 0.65254 |  0:00:10s\n","epoch 19 | loss: 0.35721 | val_0_accuracy: 0.69244 |  0:00:11s\n","epoch 20 | loss: 0.35465 | val_0_accuracy: 0.67997 |  0:00:11s\n","epoch 21 | loss: 0.35333 | val_0_accuracy: 0.71322 |  0:00:12s\n","epoch 22 | loss: 0.35242 | val_0_accuracy: 0.73566 |  0:00:12s\n","epoch 23 | loss: 0.3453  | val_0_accuracy: 0.74231 |  0:00:13s\n","epoch 24 | loss: 0.34474 | val_0_accuracy: 0.74813 |  0:00:13s\n","epoch 25 | loss: 0.34424 | val_0_accuracy: 0.77889 |  0:00:14s\n","epoch 26 | loss: 0.34829 | val_0_accuracy: 0.79302 |  0:00:15s\n","epoch 27 | loss: 0.34641 | val_0_accuracy: 0.79219 |  0:00:15s\n","epoch 28 | loss: 0.34606 | val_0_accuracy: 0.79967 |  0:00:16s\n","epoch 29 | loss: 0.34519 | val_0_accuracy: 0.80881 |  0:00:16s\n","epoch 30 | loss: 0.33979 | val_0_accuracy: 0.82461 |  0:00:17s\n","epoch 31 | loss: 0.33781 | val_0_accuracy: 0.84206 |  0:00:17s\n","epoch 32 | loss: 0.33093 | val_0_accuracy: 0.83042 |  0:00:18s\n","epoch 33 | loss: 0.33282 | val_0_accuracy: 0.83707 |  0:00:18s\n","epoch 34 | loss: 0.33497 | val_0_accuracy: 0.83624 |  0:00:19s\n","epoch 35 | loss: 0.3359  | val_0_accuracy: 0.83292 |  0:00:19s\n","epoch 36 | loss: 0.35411 | val_0_accuracy: 0.84123 |  0:00:20s\n","epoch 37 | loss: 0.35212 | val_0_accuracy: 0.82876 |  0:00:20s\n","epoch 38 | loss: 0.34508 | val_0_accuracy: 0.83292 |  0:00:21s\n","epoch 39 | loss: 0.3402  | val_0_accuracy: 0.84705 |  0:00:21s\n","epoch 40 | loss: 0.33095 | val_0_accuracy: 0.84539 |  0:00:22s\n","epoch 41 | loss: 0.33018 | val_0_accuracy: 0.84539 |  0:00:23s\n","epoch 42 | loss: 0.33556 | val_0_accuracy: 0.84289 |  0:00:23s\n","epoch 43 | loss: 0.3507  | val_0_accuracy: 0.83874 |  0:00:24s\n","epoch 44 | loss: 0.35102 | val_0_accuracy: 0.84705 |  0:00:24s\n","epoch 45 | loss: 0.34597 | val_0_accuracy: 0.84622 |  0:00:25s\n","epoch 46 | loss: 0.34199 | val_0_accuracy: 0.84788 |  0:00:25s\n","epoch 47 | loss: 0.33985 | val_0_accuracy: 0.84871 |  0:00:26s\n","epoch 48 | loss: 0.33679 | val_0_accuracy: 0.84871 |  0:00:26s\n","epoch 49 | loss: 0.33909 | val_0_accuracy: 0.85287 |  0:00:27s\n","epoch 50 | loss: 0.33298 | val_0_accuracy: 0.85453 |  0:00:27s\n","epoch 51 | loss: 0.32816 | val_0_accuracy: 0.85121 |  0:00:28s\n","epoch 52 | loss: 0.3319  | val_0_accuracy: 0.84372 |  0:00:28s\n","epoch 53 | loss: 0.33073 | val_0_accuracy: 0.84954 |  0:00:29s\n","epoch 54 | loss: 0.33109 | val_0_accuracy: 0.84788 |  0:00:29s\n","epoch 55 | loss: 0.33075 | val_0_accuracy: 0.84788 |  0:00:30s\n","epoch 56 | loss: 0.32889 | val_0_accuracy: 0.85702 |  0:00:31s\n","epoch 57 | loss: 0.32337 | val_0_accuracy: 0.84622 |  0:00:31s\n","epoch 58 | loss: 0.32315 | val_0_accuracy: 0.85619 |  0:00:32s\n","epoch 59 | loss: 0.32153 | val_0_accuracy: 0.84871 |  0:00:32s\n","epoch 60 | loss: 0.32629 | val_0_accuracy: 0.85037 |  0:00:33s\n","epoch 61 | loss: 0.32495 | val_0_accuracy: 0.83957 |  0:00:33s\n","epoch 62 | loss: 0.32198 | val_0_accuracy: 0.85453 |  0:00:34s\n","epoch 63 | loss: 0.32196 | val_0_accuracy: 0.84622 |  0:00:34s\n","epoch 64 | loss: 0.3199  | val_0_accuracy: 0.85453 |  0:00:35s\n","epoch 65 | loss: 0.32289 | val_0_accuracy: 0.85037 |  0:00:35s\n","epoch 66 | loss: 0.31772 | val_0_accuracy: 0.84539 |  0:00:36s\n","\n","Early stopping occurred at epoch 66 with best_epoch = 56 and best_val_0_accuracy = 0.85702\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-07-06 06:47:45,728] Trial 98 finished with value: 0.857024106400665 and parameters: {'n_d': 18, 'n_steps': 3, 'gamma': 1.3530861290893004, 'n_independent': 3, 'n_shared': 3, 'momentum': 0.11950769444590167}. Best is trial 42 with value: 0.8728179551122195.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 0.7555  | val_0_accuracy: 0.4522  |  0:00:00s\n","epoch 1  | loss: 0.52489 | val_0_accuracy: 0.52868 |  0:00:01s\n","epoch 2  | loss: 0.50154 | val_0_accuracy: 0.51704 |  0:00:01s\n","epoch 3  | loss: 0.4695  | val_0_accuracy: 0.5478  |  0:00:02s\n","epoch 4  | loss: 0.43392 | val_0_accuracy: 0.51787 |  0:00:03s\n","epoch 5  | loss: 0.41625 | val_0_accuracy: 0.51621 |  0:00:03s\n","epoch 6  | loss: 0.42293 | val_0_accuracy: 0.5212  |  0:00:04s\n","epoch 7  | loss: 0.42955 | val_0_accuracy: 0.51787 |  0:00:05s\n","epoch 8  | loss: 0.42552 | val_0_accuracy: 0.5212  |  0:00:05s\n","epoch 9  | loss: 0.40821 | val_0_accuracy: 0.53699 |  0:00:06s\n","epoch 10 | loss: 0.40304 | val_0_accuracy: 0.56027 |  0:00:07s\n","epoch 11 | loss: 0.39378 | val_0_accuracy: 0.57606 |  0:00:07s\n","epoch 12 | loss: 0.38768 | val_0_accuracy: 0.56775 |  0:00:08s\n","epoch 13 | loss: 0.38454 | val_0_accuracy: 0.55195 |  0:00:09s\n","epoch 14 | loss: 0.38752 | val_0_accuracy: 0.5877  |  0:00:10s\n","epoch 15 | loss: 0.38257 | val_0_accuracy: 0.68495 |  0:00:10s\n","epoch 16 | loss: 0.37948 | val_0_accuracy: 0.6542  |  0:00:11s\n","epoch 17 | loss: 0.38637 | val_0_accuracy: 0.59435 |  0:00:12s\n","epoch 18 | loss: 0.38639 | val_0_accuracy: 0.68329 |  0:00:12s\n","epoch 19 | loss: 0.39763 | val_0_accuracy: 0.68246 |  0:00:13s\n","epoch 20 | loss: 0.39655 | val_0_accuracy: 0.68911 |  0:00:14s\n","epoch 21 | loss: 0.3877  | val_0_accuracy: 0.70906 |  0:00:14s\n","epoch 22 | loss: 0.3814  | val_0_accuracy: 0.7473  |  0:00:15s\n","epoch 23 | loss: 0.37913 | val_0_accuracy: 0.73982 |  0:00:16s\n","epoch 24 | loss: 0.37985 | val_0_accuracy: 0.74813 |  0:00:16s\n","epoch 25 | loss: 0.37767 | val_0_accuracy: 0.7315  |  0:00:17s\n","epoch 26 | loss: 0.37518 | val_0_accuracy: 0.76725 |  0:00:18s\n","epoch 27 | loss: 0.36666 | val_0_accuracy: 0.7606  |  0:00:18s\n","epoch 28 | loss: 0.36591 | val_0_accuracy: 0.78969 |  0:00:19s\n","epoch 29 | loss: 0.36439 | val_0_accuracy: 0.80466 |  0:00:20s\n","epoch 30 | loss: 0.36054 | val_0_accuracy: 0.80133 |  0:00:20s\n","epoch 31 | loss: 0.35512 | val_0_accuracy: 0.81463 |  0:00:21s\n","epoch 32 | loss: 0.36212 | val_0_accuracy: 0.83624 |  0:00:22s\n","epoch 33 | loss: 0.3665  | val_0_accuracy: 0.82627 |  0:00:23s\n","epoch 34 | loss: 0.36546 | val_0_accuracy: 0.83042 |  0:00:23s\n","epoch 35 | loss: 0.36337 | val_0_accuracy: 0.82211 |  0:00:24s\n","epoch 36 | loss: 0.36646 | val_0_accuracy: 0.8271  |  0:00:25s\n","epoch 37 | loss: 0.35899 | val_0_accuracy: 0.84705 |  0:00:25s\n","epoch 38 | loss: 0.36032 | val_0_accuracy: 0.8271  |  0:00:26s\n","epoch 39 | loss: 0.38302 | val_0_accuracy: 0.82627 |  0:00:27s\n","epoch 40 | loss: 0.42007 | val_0_accuracy: 0.80632 |  0:00:27s\n","epoch 41 | loss: 0.41554 | val_0_accuracy: 0.81546 |  0:00:28s\n","epoch 42 | loss: 0.41901 | val_0_accuracy: 0.82377 |  0:00:29s\n","epoch 43 | loss: 0.41726 | val_0_accuracy: 0.79219 |  0:00:29s\n","epoch 44 | loss: 0.40295 | val_0_accuracy: 0.82627 |  0:00:30s\n","epoch 45 | loss: 0.38794 | val_0_accuracy: 0.82461 |  0:00:31s\n","epoch 46 | loss: 0.39187 | val_0_accuracy: 0.84206 |  0:00:31s\n","epoch 47 | loss: 0.38566 | val_0_accuracy: 0.8271  |  0:00:32s\n","\n","Early stopping occurred at epoch 47 with best_epoch = 37 and best_val_0_accuracy = 0.84705\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-07-06 06:48:18,768] Trial 99 finished with value: 0.8470490440565254 and parameters: {'n_d': 37, 'n_steps': 4, 'gamma': 1.896765249264529, 'n_independent': 4, 'n_shared': 2, 'momentum': 0.1690083334652489}. Best is trial 42 with value: 0.8728179551122195.\n"]}]},{"cell_type":"code","source":["best_params"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sg7oYTivFBGe","executionInfo":{"status":"ok","timestamp":1720248875477,"user_tz":-420,"elapsed":564,"user":{"displayName":"Jonindo Pasaribu","userId":"10958990953097471082"}},"outputId":"b82496e6-1aab-4219-bf2c-b2446c4f37f1"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'n_d': 30,\n"," 'n_steps': 3,\n"," 'gamma': 1.5673834303925407,\n"," 'n_independent': 4,\n"," 'n_shared': 2,\n"," 'momentum': 0.10956480194746604}"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":["best_params = {'n_d': 30,\n"," 'n_steps': 3,\n"," 'gamma': 1.5673834303925407,\n"," 'n_independent': 4,\n"," 'n_shared': 2,\n"," 'momentum': 0.10956480194746604}"],"metadata":{"id":"CHnxOdrzcUoW","executionInfo":{"status":"ok","timestamp":1731760014951,"user_tz":-420,"elapsed":7,"user":{"displayName":"Jonindo Pasaribu","userId":"10958990953097471082"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["from pytorch_tabnet.callbacks import Callback\n","\n","def print_memory_usage():\n","    process = psutil.Process()\n","    mem_info = process.memory_info()\n","    print(f\"System RAM Usage: {mem_info.rss / (1024 ** 2):.2f} MB\")\n","    if torch.cuda.is_available():\n","      print(f\"Allocated GPU memory: {torch.cuda.memory_allocated() / (1024 ** 2):.2f} MB\")\n","      print(f\"Cached GPU memory: {torch.cuda.memory_reserved() / (1024 ** 2):.2f} MB\")\n","\n","class MemoryUsageCallback(Callback):\n","    def on_epoch_end(self, epoch, logs=None):\n","        print_memory_usage()"],"metadata":{"id":"CbT_rO_046Ev","executionInfo":{"status":"ok","timestamp":1731760014951,"user_tz":-420,"elapsed":7,"user":{"displayName":"Jonindo Pasaribu","userId":"10958990953097471082"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["# Train final model using best hyperparameters\n","best_model = TabNetClassifier(\n","    **best_params,\n","    n_a=best_params['n_d'],\n","    optimizer_fn=torch.optim.Adam,\n","    optimizer_params=dict(lr=2e-2)\n",")\n","\n","best_model.fit(\n","    X_train, y_train,\n","    eval_set=[(X_train, y_train), (X_valid, y_valid)],\n","    eval_name=['train', 'valid'],\n","    eval_metric=['accuracy'],\n","    patience=16,\n","    callbacks=[MemoryUsageCallback()]\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rLdfMkJXw_Xl","outputId":"3e7bb005-caa8-4857-f6f6-461236feeb42"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 0.64681 | train_accuracy: 0.5165  | valid_accuracy: 0.54364 |  0:00:02s\n","System RAM Usage: 1180.45 MB\n","Allocated GPU memory: 18.89 MB\n","Cached GPU memory: 60.00 MB\n","epoch 1  | loss: 0.47316 | train_accuracy: 0.55388 | valid_accuracy: 0.58105 |  0:00:03s\n","System RAM Usage: 1180.45 MB\n","Allocated GPU memory: 18.89 MB\n","Cached GPU memory: 60.00 MB\n","epoch 2  | loss: 0.44154 | train_accuracy: 0.49984 | valid_accuracy: 0.51787 |  0:00:04s\n","System RAM Usage: 1180.45 MB\n","Allocated GPU memory: 18.89 MB\n","Cached GPU memory: 60.00 MB\n","epoch 3  | loss: 0.41657 | train_accuracy: 0.49311 | valid_accuracy: 0.52203 |  0:00:05s\n","System RAM Usage: 1180.86 MB\n","Allocated GPU memory: 18.89 MB\n","Cached GPU memory: 60.00 MB\n","epoch 4  | loss: 0.41002 | train_accuracy: 0.50176 | valid_accuracy: 0.52535 |  0:00:05s\n","System RAM Usage: 1180.86 MB\n","Allocated GPU memory: 18.89 MB\n","Cached GPU memory: 60.00 MB\n","epoch 5  | loss: 0.39871 | train_accuracy: 0.50838 | valid_accuracy: 0.53034 |  0:00:06s\n","System RAM Usage: 1180.86 MB\n","Allocated GPU memory: 18.89 MB\n","Cached GPU memory: 60.00 MB\n","epoch 6  | loss: 0.39016 | train_accuracy: 0.4992  | valid_accuracy: 0.51787 |  0:00:07s\n","System RAM Usage: 1180.86 MB\n","Allocated GPU memory: 18.89 MB\n","Cached GPU memory: 60.00 MB\n","epoch 7  | loss: 0.38475 | train_accuracy: 0.50742 | valid_accuracy: 0.52868 |  0:00:08s\n","System RAM Usage: 1180.86 MB\n","Allocated GPU memory: 18.89 MB\n","Cached GPU memory: 60.00 MB\n","epoch 8  | loss: 0.38312 | train_accuracy: 0.50507 | valid_accuracy: 0.52535 |  0:00:08s\n","System RAM Usage: 1180.86 MB\n","Allocated GPU memory: 18.89 MB\n","Cached GPU memory: 60.00 MB\n","epoch 9  | loss: 0.37699 | train_accuracy: 0.52088 | valid_accuracy: 0.54364 |  0:00:09s\n","System RAM Usage: 1180.86 MB\n","Allocated GPU memory: 18.89 MB\n","Cached GPU memory: 60.00 MB\n","epoch 10 | loss: 0.3827  | train_accuracy: 0.52494 | valid_accuracy: 0.55611 |  0:00:10s\n","System RAM Usage: 1180.86 MB\n","Allocated GPU memory: 18.89 MB\n","Cached GPU memory: 60.00 MB\n","epoch 11 | loss: 0.37189 | train_accuracy: 0.54171 | valid_accuracy: 0.56193 |  0:00:11s\n","System RAM Usage: 1180.86 MB\n","Allocated GPU memory: 18.89 MB\n","Cached GPU memory: 60.00 MB\n","epoch 12 | loss: 0.36633 | train_accuracy: 0.52526 | valid_accuracy: 0.54613 |  0:00:12s\n","System RAM Usage: 1180.86 MB\n","Allocated GPU memory: 18.89 MB\n","Cached GPU memory: 60.00 MB\n","epoch 13 | loss: 0.36321 | train_accuracy: 0.5259  | valid_accuracy: 0.55029 |  0:00:13s\n","System RAM Usage: 1180.86 MB\n","Allocated GPU memory: 18.89 MB\n","Cached GPU memory: 60.00 MB\n","epoch 14 | loss: 0.35852 | train_accuracy: 0.57503 | valid_accuracy: 0.59933 |  0:00:14s\n","System RAM Usage: 1180.86 MB\n","Allocated GPU memory: 18.89 MB\n","Cached GPU memory: 60.00 MB\n","epoch 15 | loss: 0.35662 | train_accuracy: 0.66709 | valid_accuracy: 0.68495 |  0:00:14s\n","System RAM Usage: 1180.86 MB\n","Allocated GPU memory: 18.89 MB\n","Cached GPU memory: 60.00 MB\n","epoch 16 | loss: 0.35484 | train_accuracy: 0.61113 | valid_accuracy: 0.63591 |  0:00:15s\n","System RAM Usage: 1180.86 MB\n","Allocated GPU memory: 18.89 MB\n","Cached GPU memory: 60.00 MB\n","epoch 17 | loss: 0.35371 | train_accuracy: 0.66592 | valid_accuracy: 0.68495 |  0:00:16s\n","System RAM Usage: 1180.86 MB\n","Allocated GPU memory: 18.89 MB\n","Cached GPU memory: 60.00 MB\n","epoch 18 | loss: 0.34969 | train_accuracy: 0.68643 | valid_accuracy: 0.69742 |  0:00:16s\n","System RAM Usage: 1180.86 MB\n","Allocated GPU memory: 18.89 MB\n","Cached GPU memory: 60.00 MB\n","epoch 19 | loss: 0.34706 | train_accuracy: 0.72359 | valid_accuracy: 0.7315  |  0:00:17s\n","System RAM Usage: 1180.86 MB\n","Allocated GPU memory: 18.89 MB\n","Cached GPU memory: 60.00 MB\n","epoch 20 | loss: 0.34174 | train_accuracy: 0.73417 | valid_accuracy: 0.73732 |  0:00:18s\n","System RAM Usage: 1180.86 MB\n","Allocated GPU memory: 18.89 MB\n","Cached GPU memory: 60.00 MB\n","epoch 21 | loss: 0.34234 | train_accuracy: 0.70448 | valid_accuracy: 0.72569 |  0:00:19s\n","System RAM Usage: 1180.86 MB\n","Allocated GPU memory: 18.89 MB\n","Cached GPU memory: 60.00 MB\n","epoch 22 | loss: 0.34257 | train_accuracy: 0.71473 | valid_accuracy: 0.72236 |  0:00:19s\n","System RAM Usage: 1180.86 MB\n","Allocated GPU memory: 18.89 MB\n","Cached GPU memory: 60.00 MB\n","epoch 23 | loss: 0.34235 | train_accuracy: 0.74122 | valid_accuracy: 0.74148 |  0:00:20s\n","System RAM Usage: 1180.86 MB\n","Allocated GPU memory: 18.89 MB\n","Cached GPU memory: 60.00 MB\n","epoch 24 | loss: 0.3403  | train_accuracy: 0.79045 | valid_accuracy: 0.78221 |  0:00:21s\n","System RAM Usage: 1180.86 MB\n","Allocated GPU memory: 18.89 MB\n","Cached GPU memory: 60.00 MB\n","epoch 25 | loss: 0.34623 | train_accuracy: 0.78169 | valid_accuracy: 0.77057 |  0:00:22s\n","System RAM Usage: 1180.86 MB\n","Allocated GPU memory: 18.89 MB\n","Cached GPU memory: 60.00 MB\n","epoch 26 | loss: 0.33401 | train_accuracy: 0.7786  | valid_accuracy: 0.77722 |  0:00:23s\n","System RAM Usage: 1180.86 MB\n","Allocated GPU memory: 18.89 MB\n","Cached GPU memory: 60.00 MB\n","epoch 27 | loss: 0.34221 | train_accuracy: 0.79964 | valid_accuracy: 0.79302 |  0:00:24s\n","System RAM Usage: 1180.86 MB\n","Allocated GPU memory: 18.89 MB\n","Cached GPU memory: 60.00 MB\n","epoch 28 | loss: 0.33288 | train_accuracy: 0.80882 | valid_accuracy: 0.79717 |  0:00:25s\n","System RAM Usage: 1180.86 MB\n","Allocated GPU memory: 18.89 MB\n","Cached GPU memory: 60.00 MB\n","epoch 29 | loss: 0.33474 | train_accuracy: 0.81544 | valid_accuracy: 0.80466 |  0:00:26s\n","System RAM Usage: 1180.86 MB\n","Allocated GPU memory: 18.89 MB\n","Cached GPU memory: 60.00 MB\n","epoch 30 | loss: 0.33594 | train_accuracy: 0.81117 | valid_accuracy: 0.79385 |  0:00:26s\n","System RAM Usage: 1180.86 MB\n","Allocated GPU memory: 18.89 MB\n","Cached GPU memory: 60.00 MB\n","epoch 31 | loss: 0.33384 | train_accuracy: 0.83146 | valid_accuracy: 0.82959 |  0:00:27s\n","System RAM Usage: 1180.86 MB\n","Allocated GPU memory: 18.89 MB\n","Cached GPU memory: 60.00 MB\n","epoch 32 | loss: 0.32839 | train_accuracy: 0.81843 | valid_accuracy: 0.80549 |  0:00:28s\n","System RAM Usage: 1180.86 MB\n","Allocated GPU memory: 18.89 MB\n","Cached GPU memory: 60.00 MB\n","epoch 33 | loss: 0.32685 | train_accuracy: 0.84076 | valid_accuracy: 0.82959 |  0:00:28s\n","System RAM Usage: 1180.86 MB\n","Allocated GPU memory: 18.89 MB\n","Cached GPU memory: 60.00 MB\n","epoch 34 | loss: 0.32536 | train_accuracy: 0.83787 | valid_accuracy: 0.82793 |  0:00:29s\n","System RAM Usage: 1180.86 MB\n","Allocated GPU memory: 18.89 MB\n","Cached GPU memory: 60.00 MB\n","epoch 35 | loss: 0.32379 | train_accuracy: 0.84375 | valid_accuracy: 0.82627 |  0:00:30s\n","System RAM Usage: 1180.86 MB\n","Allocated GPU memory: 18.89 MB\n","Cached GPU memory: 60.00 MB\n","epoch 36 | loss: 0.32286 | train_accuracy: 0.84909 | valid_accuracy: 0.83624 |  0:00:31s\n","System RAM Usage: 1180.86 MB\n","Allocated GPU memory: 18.89 MB\n","Cached GPU memory: 60.00 MB\n","epoch 37 | loss: 0.3267  | train_accuracy: 0.85742 | valid_accuracy: 0.84705 |  0:00:31s\n","System RAM Usage: 1180.86 MB\n","Allocated GPU memory: 18.89 MB\n","Cached GPU memory: 60.00 MB\n","epoch 38 | loss: 0.32402 | train_accuracy: 0.84738 | valid_accuracy: 0.83209 |  0:00:32s\n","System RAM Usage: 1180.86 MB\n","Allocated GPU memory: 18.89 MB\n","Cached GPU memory: 60.00 MB\n","epoch 39 | loss: 0.32138 | train_accuracy: 0.85453 | valid_accuracy: 0.84289 |  0:00:33s\n","System RAM Usage: 1180.86 MB\n","Allocated GPU memory: 18.89 MB\n","Cached GPU memory: 60.00 MB\n","epoch 40 | loss: 0.32406 | train_accuracy: 0.85176 | valid_accuracy: 0.83209 |  0:00:34s\n","System RAM Usage: 1180.86 MB\n","Allocated GPU memory: 18.89 MB\n","Cached GPU memory: 60.00 MB\n","epoch 41 | loss: 0.32732 | train_accuracy: 0.8571  | valid_accuracy: 0.84954 |  0:00:35s\n","System RAM Usage: 1180.86 MB\n","Allocated GPU memory: 18.89 MB\n","Cached GPU memory: 60.00 MB\n","epoch 42 | loss: 0.32582 | train_accuracy: 0.86116 | valid_accuracy: 0.8537  |  0:00:36s\n","System RAM Usage: 1180.86 MB\n","Allocated GPU memory: 18.89 MB\n","Cached GPU memory: 60.00 MB\n","epoch 43 | loss: 0.32232 | train_accuracy: 0.85945 | valid_accuracy: 0.85786 |  0:00:37s\n","System RAM Usage: 1180.86 MB\n","Allocated GPU memory: 18.89 MB\n","Cached GPU memory: 60.00 MB\n","epoch 44 | loss: 0.32853 | train_accuracy: 0.86308 | valid_accuracy: 0.85121 |  0:00:38s\n","System RAM Usage: 1180.86 MB\n","Allocated GPU memory: 18.89 MB\n","Cached GPU memory: 60.00 MB\n","epoch 45 | loss: 0.3253  | train_accuracy: 0.85603 | valid_accuracy: 0.84622 |  0:00:38s\n","System RAM Usage: 1180.86 MB\n","Allocated GPU memory: 18.89 MB\n","Cached GPU memory: 60.00 MB\n","epoch 46 | loss: 0.32479 | train_accuracy: 0.8619  | valid_accuracy: 0.85619 |  0:00:39s\n","System RAM Usage: 1180.86 MB\n","Allocated GPU memory: 18.89 MB\n","Cached GPU memory: 60.00 MB\n","epoch 47 | loss: 0.326   | train_accuracy: 0.85688 | valid_accuracy: 0.85453 |  0:00:40s\n","System RAM Usage: 1180.86 MB\n","Allocated GPU memory: 18.89 MB\n","Cached GPU memory: 60.00 MB\n","epoch 48 | loss: 0.32697 | train_accuracy: 0.86158 | valid_accuracy: 0.85619 |  0:00:41s\n","System RAM Usage: 1180.86 MB\n","Allocated GPU memory: 18.89 MB\n","Cached GPU memory: 60.00 MB\n","epoch 49 | loss: 0.33407 | train_accuracy: 0.85998 | valid_accuracy: 0.84372 |  0:00:41s\n","System RAM Usage: 1180.86 MB\n","Allocated GPU memory: 18.89 MB\n","Cached GPU memory: 60.00 MB\n","epoch 50 | loss: 0.33283 | train_accuracy: 0.86276 | valid_accuracy: 0.85869 |  0:00:42s\n","System RAM Usage: 1180.86 MB\n","Allocated GPU memory: 18.89 MB\n","Cached GPU memory: 60.00 MB\n","epoch 51 | loss: 0.32481 | train_accuracy: 0.86062 | valid_accuracy: 0.84206 |  0:00:43s\n","System RAM Usage: 1180.86 MB\n","Allocated GPU memory: 18.89 MB\n","Cached GPU memory: 60.00 MB\n","epoch 52 | loss: 0.3214  | train_accuracy: 0.86201 | valid_accuracy: 0.85121 |  0:00:44s\n","System RAM Usage: 1180.86 MB\n","Allocated GPU memory: 18.89 MB\n","Cached GPU memory: 60.00 MB\n","epoch 53 | loss: 0.32183 | train_accuracy: 0.86532 | valid_accuracy: 0.8537  |  0:00:45s\n","System RAM Usage: 1180.86 MB\n","Allocated GPU memory: 18.89 MB\n","Cached GPU memory: 60.00 MB\n","epoch 54 | loss: 0.31791 | train_accuracy: 0.86479 | valid_accuracy: 0.85204 |  0:00:45s\n","System RAM Usage: 1180.86 MB\n","Allocated GPU memory: 18.89 MB\n","Cached GPU memory: 60.00 MB\n","epoch 55 | loss: 0.31464 | train_accuracy: 0.87066 | valid_accuracy: 0.8537  |  0:00:46s\n","System RAM Usage: 1180.86 MB\n","Allocated GPU memory: 18.89 MB\n","Cached GPU memory: 60.00 MB\n","epoch 56 | loss: 0.31813 | train_accuracy: 0.86703 | valid_accuracy: 0.86534 |  0:00:47s\n","System RAM Usage: 1180.86 MB\n","Allocated GPU memory: 18.89 MB\n","Cached GPU memory: 60.00 MB\n","epoch 57 | loss: 0.3078  | train_accuracy: 0.86863 | valid_accuracy: 0.867   |  0:00:48s\n","System RAM Usage: 1180.86 MB\n","Allocated GPU memory: 18.89 MB\n","Cached GPU memory: 60.00 MB\n","epoch 58 | loss: 0.31625 | train_accuracy: 0.86746 | valid_accuracy: 0.85619 |  0:00:49s\n","System RAM Usage: 1180.86 MB\n","Allocated GPU memory: 18.89 MB\n","Cached GPU memory: 60.00 MB\n","epoch 59 | loss: 0.31899 | train_accuracy: 0.86607 | valid_accuracy: 0.86035 |  0:00:50s\n","System RAM Usage: 1180.86 MB\n","Allocated GPU memory: 18.89 MB\n","Cached GPU memory: 60.00 MB\n","epoch 60 | loss: 0.31967 | train_accuracy: 0.86297 | valid_accuracy: 0.84954 |  0:00:51s\n","System RAM Usage: 1180.86 MB\n","Allocated GPU memory: 18.89 MB\n","Cached GPU memory: 60.00 MB\n","epoch 61 | loss: 0.32305 | train_accuracy: 0.86489 | valid_accuracy: 0.85037 |  0:00:51s\n","System RAM Usage: 1180.86 MB\n","Allocated GPU memory: 18.89 MB\n","Cached GPU memory: 60.00 MB\n","epoch 62 | loss: 0.3196  | train_accuracy: 0.8681  | valid_accuracy: 0.85536 |  0:00:52s\n","System RAM Usage: 1180.86 MB\n","Allocated GPU memory: 18.89 MB\n","Cached GPU memory: 60.00 MB\n","epoch 63 | loss: 0.31053 | train_accuracy: 0.86447 | valid_accuracy: 0.85786 |  0:00:53s\n","System RAM Usage: 1180.86 MB\n","Allocated GPU memory: 18.89 MB\n","Cached GPU memory: 60.00 MB\n","epoch 64 | loss: 0.31052 | train_accuracy: 0.86746 | valid_accuracy: 0.85453 |  0:00:54s\n","System RAM Usage: 1180.86 MB\n","Allocated GPU memory: 18.89 MB\n","Cached GPU memory: 60.00 MB\n","epoch 65 | loss: 0.30959 | train_accuracy: 0.87429 | valid_accuracy: 0.86035 |  0:00:54s\n","System RAM Usage: 1180.86 MB\n","Allocated GPU memory: 18.89 MB\n","Cached GPU memory: 60.00 MB\n","epoch 66 | loss: 0.30673 | train_accuracy: 0.87269 | valid_accuracy: 0.85786 |  0:00:55s\n","System RAM Usage: 1180.86 MB\n","Allocated GPU memory: 18.89 MB\n","Cached GPU memory: 60.00 MB\n","epoch 67 | loss: 0.30372 | train_accuracy: 0.87184 | valid_accuracy: 0.85204 |  0:00:56s\n","System RAM Usage: 1180.86 MB\n","Allocated GPU memory: 18.89 MB\n","Cached GPU memory: 60.00 MB\n","epoch 68 | loss: 0.30494 | train_accuracy: 0.87419 | valid_accuracy: 0.85786 |  0:00:57s\n","System RAM Usage: 1180.86 MB\n","Allocated GPU memory: 18.89 MB\n","Cached GPU memory: 60.00 MB\n","epoch 69 | loss: 0.30849 | train_accuracy: 0.87397 | valid_accuracy: 0.87032 |  0:00:57s\n","System RAM Usage: 1180.86 MB\n","Allocated GPU memory: 18.89 MB\n","Cached GPU memory: 60.00 MB\n","epoch 70 | loss: 0.30427 | train_accuracy: 0.86756 | valid_accuracy: 0.86118 |  0:00:58s\n","System RAM Usage: 1180.86 MB\n","Allocated GPU memory: 18.89 MB\n","Cached GPU memory: 60.00 MB\n","epoch 71 | loss: 0.30126 | train_accuracy: 0.87451 | valid_accuracy: 0.86783 |  0:00:59s\n","System RAM Usage: 1180.86 MB\n","Allocated GPU memory: 18.89 MB\n","Cached GPU memory: 60.00 MB\n","epoch 72 | loss: 0.29945 | train_accuracy: 0.87152 | valid_accuracy: 0.85786 |  0:01:00s\n","System RAM Usage: 1180.86 MB\n","Allocated GPU memory: 18.89 MB\n","Cached GPU memory: 60.00 MB\n","epoch 73 | loss: 0.30444 | train_accuracy: 0.8713  | valid_accuracy: 0.85952 |  0:01:01s\n","System RAM Usage: 1180.86 MB\n","Allocated GPU memory: 18.89 MB\n","Cached GPU memory: 60.00 MB\n","epoch 74 | loss: 0.29846 | train_accuracy: 0.87568 | valid_accuracy: 0.86118 |  0:01:02s\n","System RAM Usage: 1180.86 MB\n","Allocated GPU memory: 18.89 MB\n","Cached GPU memory: 60.00 MB\n","epoch 75 | loss: 0.29918 | train_accuracy: 0.87162 | valid_accuracy: 0.85536 |  0:01:03s\n","System RAM Usage: 1180.86 MB\n","Allocated GPU memory: 18.89 MB\n","Cached GPU memory: 60.00 MB\n","epoch 76 | loss: 0.30433 | train_accuracy: 0.87087 | valid_accuracy: 0.86201 |  0:01:03s\n","System RAM Usage: 1180.86 MB\n","Allocated GPU memory: 18.89 MB\n","Cached GPU memory: 60.00 MB\n"]}]},{"cell_type":"code","source":["from sklearn.metrics import classification_report, roc_auc_score\n","\n","y_proba = best_model.predict_proba(X_test)\n","test_auc = roc_auc_score(y_score=y_proba[:,1], y_true=y_test)\n","\n","y_proba_valid = best_model.predict_proba(X_valid)\n","valid_auc = roc_auc_score(y_score=y_proba_valid[:,1], y_true=y_valid)\n","\n","print(\"Best Valid Score:\", best_model.best_cost)\n","print(\"Test AUC:\", test_auc)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"o3TYXT_o_6oS","executionInfo":{"status":"ok","timestamp":1720249105273,"user_tz":-420,"elapsed":446,"user":{"displayName":"Jonindo Pasaribu","userId":"10958990953097471082"}},"outputId":"32f307ef-d4b0-4531-9ca0-01103fb89940"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Best Valid Score: 0.8703241895261845\n","Test AUC: 0.9170907466052919\n"]}]},{"cell_type":"code","source":["preds = best_model.predict(X_test)\n","\n","print(classification_report(y_true=y_test, y_pred=preds))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0vUcwomf3Z_Q","executionInfo":{"status":"ok","timestamp":1720249108757,"user_tz":-420,"elapsed":2,"user":{"displayName":"Jonindo Pasaribu","userId":"10958990953097471082"}},"outputId":"e378074c-06da-448b-cc1c-61c776b26200"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.83      0.85      0.84      1393\n","           1       0.85      0.83      0.84      1417\n","\n","    accuracy                           0.84      2810\n","   macro avg       0.84      0.84      0.84      2810\n","weighted avg       0.84      0.84      0.84      2810\n","\n"]}]},{"cell_type":"code","source":["from sklearn.metrics import classification_report, roc_auc_score, roc_curve\n","\n","y_proba = best_model.predict_proba(X_test)\n","test_auc = roc_auc_score(y_score=y_proba[:,1], y_true=y_test)\n","\n","y_proba_valid = best_model.predict_proba(X_valid)\n","valid_auc = roc_auc_score(y_score=y_proba_valid[:,1], y_true=y_valid)\n","\n","print(\"Best Valid Score:\", best_model.best_cost)\n","print(\"Test AUC:\", test_auc)"],"metadata":{"id":"gltO0pgucZtm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["fpr, tpr, thresholds = roc_curve(y_score=y_proba[:,1], y_true=y_test)\n","\n","roc_data = pd.DataFrame({\n","    'fpr': fpr,\n","    'tpr': tpr\n","})\n","\n","roc_data.to_csv('MagicTelescope-TabNet.csv', index=False)"],"metadata":{"id":"LlCRogPucb0M"},"execution_count":null,"outputs":[]}]}