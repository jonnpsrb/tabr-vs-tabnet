{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","machine_shape":"hm","authorship_tag":"ABX9TyOJBuoe2qQpdWqJIS8k5BwM"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["!wget https://huggingface.co/datasets/puhsu/tabular-benchmarks/resolve/main/data.tar -O tabular-dl-tabr.tar.gz\n","!tar -xvf tabular-dl-tabr.tar.gz"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pulqlCAgJDEt","executionInfo":{"status":"ok","timestamp":1728980957675,"user_tz":-480,"elapsed":146599,"user":{"displayName":"Jonindo Pasaribu","userId":"10958990953097471082"}},"outputId":"3fe0326c-513c-48a7-f421-622e436fffba"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["--2024-10-15 08:26:50--  https://huggingface.co/datasets/puhsu/tabular-benchmarks/resolve/main/data.tar\n","Resolving huggingface.co (huggingface.co)... 13.35.210.114, 13.35.210.66, 13.35.210.77, ...\n","Connecting to huggingface.co (huggingface.co)|13.35.210.114|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://cdn-lfs.hf.co/repos/1b/25/1b25d6e2556c827abfaf6ba9da6021338691cafc39fe9d77986955ae0a69243d/0d74e4b96febb48fbe4dd2d851f8638b5738354f82c3183f92adbd2abf2f256b?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27data.tar%3B+filename%3D%22data.tar%22%3B&response-content-type=application%2Fx-tar&Expires=1729240011&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcyOTI0MDAxMX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5oZi5jby9yZXBvcy8xYi8yNS8xYjI1ZDZlMjU1NmM4MjdhYmZhZjZiYTlkYTYwMjEzMzg2OTFjYWZjMzlmZTlkNzc5ODY5NTVhZTBhNjkyNDNkLzBkNzRlNGI5NmZlYmI0OGZiZTRkZDJkODUxZjg2MzhiNTczODM1NGY4MmMzMTgzZjkyYWRiZDJhYmYyZjI1NmI%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qJnJlc3BvbnNlLWNvbnRlbnQtdHlwZT0qIn1dfQ__&Signature=i%7EJHKgObPPClvZUozwBT6czX5dFV5wYJ7UBoZedVFhFC7xIj06SnE4I6K2W%7E5Vp3EFK4DYQAVoM6YngPFqlRBMh8ShwFBQI1h%7E--de-eKaIVhPmS9WgxomVTPvrO3PVQ7EdzNjxv879FVU1UoSzN58kVTuyv0ktsL3Xy0MYJ8AeDFWtt2nNT7osZJuA%7EdiLg-pYOvtviSvac1lY8S7qSkGBO0PXXU4IFYl8Rl4Razx%7EzdGolwRvqrFcFFyobZnPXw9exmDtt45Fjlgz4%7E30Qrb4MjViaKqMQpptBr36dvfSLYeGrXI8IOV6gW1GyZLYh5agZPGJ0nGln2wEMwp%7EJ1A__&Key-Pair-Id=K3RPWS32NSSJCE [following]\n","--2024-10-15 08:26:51--  https://cdn-lfs.hf.co/repos/1b/25/1b25d6e2556c827abfaf6ba9da6021338691cafc39fe9d77986955ae0a69243d/0d74e4b96febb48fbe4dd2d851f8638b5738354f82c3183f92adbd2abf2f256b?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27data.tar%3B+filename%3D%22data.tar%22%3B&response-content-type=application%2Fx-tar&Expires=1729240011&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcyOTI0MDAxMX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5oZi5jby9yZXBvcy8xYi8yNS8xYjI1ZDZlMjU1NmM4MjdhYmZhZjZiYTlkYTYwMjEzMzg2OTFjYWZjMzlmZTlkNzc5ODY5NTVhZTBhNjkyNDNkLzBkNzRlNGI5NmZlYmI0OGZiZTRkZDJkODUxZjg2MzhiNTczODM1NGY4MmMzMTgzZjkyYWRiZDJhYmYyZjI1NmI%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qJnJlc3BvbnNlLWNvbnRlbnQtdHlwZT0qIn1dfQ__&Signature=i%7EJHKgObPPClvZUozwBT6czX5dFV5wYJ7UBoZedVFhFC7xIj06SnE4I6K2W%7E5Vp3EFK4DYQAVoM6YngPFqlRBMh8ShwFBQI1h%7E--de-eKaIVhPmS9WgxomVTPvrO3PVQ7EdzNjxv879FVU1UoSzN58kVTuyv0ktsL3Xy0MYJ8AeDFWtt2nNT7osZJuA%7EdiLg-pYOvtviSvac1lY8S7qSkGBO0PXXU4IFYl8Rl4Razx%7EzdGolwRvqrFcFFyobZnPXw9exmDtt45Fjlgz4%7E30Qrb4MjViaKqMQpptBr36dvfSLYeGrXI8IOV6gW1GyZLYh5agZPGJ0nGln2wEMwp%7EJ1A__&Key-Pair-Id=K3RPWS32NSSJCE\n","Resolving cdn-lfs.hf.co (cdn-lfs.hf.co)... 18.155.68.85, 18.155.68.34, 18.155.68.37, ...\n","Connecting to cdn-lfs.hf.co (cdn-lfs.hf.co)|18.155.68.85|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 3094384640 (2.9G) [application/x-tar]\n","Saving to: ‘tabular-dl-tabr.tar.gz’\n","\n","tabular-dl-tabr.tar 100%[===================>]   2.88G  21.8MB/s    in 2m 18s  \n","\n","2024-10-15 08:29:09 (21.4 MB/s) - ‘tabular-dl-tabr.tar.gz’ saved [3094384640/3094384640]\n","\n","data/\n","data/regression-num-medium-0-Ailerons/\n","data/regression-num-medium-0-Ailerons/X_num_val.npy\n","data/regression-num-medium-0-Ailerons/Y_val.npy\n","data/regression-num-medium-0-Ailerons/X_num_train.npy\n","data/regression-num-medium-0-Ailerons/info.json\n","data/regression-num-medium-0-Ailerons/READY\n","data/regression-num-medium-0-Ailerons/X_num_test.npy\n","data/regression-num-medium-0-Ailerons/Y_test.npy\n","data/regression-num-medium-0-Ailerons/Y_train.npy\n","data/regression-cat-medium-0-house_sales/\n","data/regression-cat-medium-0-house_sales/X_num_val.npy\n","data/regression-cat-medium-0-house_sales/Y_val.npy\n","data/regression-cat-medium-0-house_sales/X_bin_val.npy\n","data/regression-cat-medium-0-house_sales/X_num_train.npy\n","data/regression-cat-medium-0-house_sales/X_bin_train.npy\n","data/regression-cat-medium-0-house_sales/info.json\n","data/regression-cat-medium-0-house_sales/READY\n","data/regression-cat-medium-0-house_sales/X_bin_test.npy\n","data/regression-cat-medium-0-house_sales/X_num_test.npy\n","data/regression-cat-medium-0-house_sales/Y_test.npy\n","data/regression-cat-medium-0-house_sales/Y_train.npy\n","data/classif-cat-medium-2-KDDCup09_upselling/\n","data/classif-cat-medium-2-KDDCup09_upselling/X_cat_val.npy\n","data/classif-cat-medium-2-KDDCup09_upselling/X_num_val.npy\n","data/classif-cat-medium-2-KDDCup09_upselling/Y_val.npy\n","data/classif-cat-medium-2-KDDCup09_upselling/X_bin_val.npy\n","data/classif-cat-medium-2-KDDCup09_upselling/X_num_train.npy\n","data/classif-cat-medium-2-KDDCup09_upselling/X_cat_test.npy\n","data/classif-cat-medium-2-KDDCup09_upselling/X_bin_train.npy\n","data/classif-cat-medium-2-KDDCup09_upselling/X_cat_train.npy\n","data/classif-cat-medium-2-KDDCup09_upselling/info.json\n","data/classif-cat-medium-2-KDDCup09_upselling/READY\n","data/classif-cat-medium-2-KDDCup09_upselling/X_bin_test.npy\n","data/classif-cat-medium-2-KDDCup09_upselling/X_num_test.npy\n","data/classif-cat-medium-2-KDDCup09_upselling/Y_test.npy\n","data/classif-cat-medium-2-KDDCup09_upselling/Y_train.npy\n","data/regression-num-medium-2-isolet/\n","data/regression-num-medium-2-isolet/X_num_val.npy\n","data/regression-num-medium-2-isolet/Y_val.npy\n","data/regression-num-medium-2-isolet/X_num_train.npy\n","data/regression-num-medium-2-isolet/info.json\n","data/regression-num-medium-2-isolet/READY\n","data/regression-num-medium-2-isolet/X_num_test.npy\n","data/regression-num-medium-2-isolet/Y_test.npy\n","data/regression-num-medium-2-isolet/Y_train.npy\n","data/regression-cat-medium-1-Brazilian_houses/\n","data/regression-cat-medium-1-Brazilian_houses/X_cat_val.npy\n","data/regression-cat-medium-1-Brazilian_houses/X_num_val.npy\n","data/regression-cat-medium-1-Brazilian_houses/Y_val.npy\n","data/regression-cat-medium-1-Brazilian_houses/X_bin_val.npy\n","data/regression-cat-medium-1-Brazilian_houses/X_num_train.npy\n","data/regression-cat-medium-1-Brazilian_houses/X_cat_test.npy\n","data/regression-cat-medium-1-Brazilian_houses/X_bin_train.npy\n","data/regression-cat-medium-1-Brazilian_houses/X_cat_train.npy\n","data/regression-cat-medium-1-Brazilian_houses/info.json\n","data/regression-cat-medium-1-Brazilian_houses/READY\n","data/regression-cat-medium-1-Brazilian_houses/X_bin_test.npy\n","data/regression-cat-medium-1-Brazilian_houses/X_num_test.npy\n","data/regression-cat-medium-1-Brazilian_houses/Y_test.npy\n","data/regression-cat-medium-1-Brazilian_houses/Y_train.npy\n","data/regression-num-medium-2-wine_quality/\n","data/regression-num-medium-2-wine_quality/X_num_val.npy\n","data/regression-num-medium-2-wine_quality/Y_val.npy\n","data/regression-num-medium-2-wine_quality/X_num_train.npy\n","data/regression-num-medium-2-wine_quality/info.json\n","data/regression-num-medium-2-wine_quality/READY\n","data/regression-num-medium-2-wine_quality/X_num_test.npy\n","data/regression-num-medium-2-wine_quality/Y_test.npy\n","data/regression-num-medium-2-wine_quality/Y_train.npy\n","data/regression-num-medium-0-california/\n","data/regression-num-medium-0-california/X_num_val.npy\n","data/regression-num-medium-0-california/Y_val.npy\n","data/regression-num-medium-0-california/X_num_train.npy\n","data/regression-num-medium-0-california/info.json\n","data/regression-num-medium-0-california/READY\n","data/regression-num-medium-0-california/X_num_test.npy\n","data/regression-num-medium-0-california/Y_test.npy\n","data/regression-num-medium-0-california/Y_train.npy\n","data/classif-num-medium-2-wine/\n","data/classif-num-medium-2-wine/X_num_val.npy\n","data/classif-num-medium-2-wine/Y_val.npy\n","data/classif-num-medium-2-wine/X_num_train.npy\n","data/classif-num-medium-2-wine/info.json\n","data/classif-num-medium-2-wine/READY\n","data/classif-num-medium-2-wine/X_num_test.npy\n","data/classif-num-medium-2-wine/Y_test.npy\n","data/classif-num-medium-2-wine/Y_train.npy\n","data/classif-num-medium-1-phoneme/\n","data/classif-num-medium-1-phoneme/X_num_val.npy\n","data/classif-num-medium-1-phoneme/Y_val.npy\n","data/classif-num-medium-1-phoneme/X_num_train.npy\n","data/classif-num-medium-1-phoneme/info.json\n","data/classif-num-medium-1-phoneme/READY\n","data/classif-num-medium-1-phoneme/X_num_test.npy\n","data/classif-num-medium-1-phoneme/Y_test.npy\n","data/classif-num-medium-1-phoneme/Y_train.npy\n","data/regression-num-medium-1-isolet/\n","data/regression-num-medium-1-isolet/X_num_val.npy\n","data/regression-num-medium-1-isolet/Y_val.npy\n","data/regression-num-medium-1-isolet/X_num_train.npy\n","data/regression-num-medium-1-isolet/info.json\n","data/regression-num-medium-1-isolet/READY\n","data/regression-num-medium-1-isolet/X_num_test.npy\n","data/regression-num-medium-1-isolet/Y_test.npy\n","data/regression-num-medium-1-isolet/Y_train.npy\n","data/churn/\n","data/churn/X_cat_val.npy\n","data/churn/X_num_val.npy\n","data/churn/Y_val.npy\n","data/churn/X_bin_val.npy\n","data/churn/X_num_train.npy\n","data/churn/X_cat_test.npy\n","data/churn/X_bin_train.npy\n","data/churn/X_cat_train.npy\n","data/churn/info.json\n","data/churn/READY\n","data/churn/X_bin_test.npy\n","data/churn/X_num_test.npy\n","data/churn/Y_test.npy\n","data/churn/Y_train.npy\n","data/regression-num-medium-2-sulfur/\n","data/regression-num-medium-2-sulfur/X_num_val.npy\n","data/regression-num-medium-2-sulfur/Y_val.npy\n","data/regression-num-medium-2-sulfur/X_num_train.npy\n","data/regression-num-medium-2-sulfur/info.json\n","data/regression-num-medium-2-sulfur/READY\n","data/regression-num-medium-2-sulfur/X_num_test.npy\n","data/regression-num-medium-2-sulfur/Y_test.npy\n","data/regression-num-medium-2-sulfur/Y_train.npy\n","data/regression-cat-large-0-diamonds/\n","data/regression-cat-large-0-diamonds/X_cat_val.npy\n","data/regression-cat-large-0-diamonds/X_num_val.npy\n","data/regression-cat-large-0-diamonds/Y_val.npy\n","data/regression-cat-large-0-diamonds/X_num_train.npy\n","data/regression-cat-large-0-diamonds/X_cat_test.npy\n","data/regression-cat-large-0-diamonds/X_cat_train.npy\n","data/regression-cat-large-0-diamonds/info.json\n","data/regression-cat-large-0-diamonds/READY\n","data/regression-cat-large-0-diamonds/X_num_test.npy\n","data/regression-cat-large-0-diamonds/Y_test.npy\n","data/regression-cat-large-0-diamonds/Y_train.npy\n","data/classif-cat-large-0-road-safety/\n","data/classif-cat-large-0-road-safety/X_cat_val.npy\n","data/classif-cat-large-0-road-safety/X_num_val.npy\n","data/classif-cat-large-0-road-safety/Y_val.npy\n","data/classif-cat-large-0-road-safety/X_num_train.npy\n","data/classif-cat-large-0-road-safety/X_cat_test.npy\n","data/classif-cat-large-0-road-safety/X_cat_train.npy\n","data/classif-cat-large-0-road-safety/info.json\n","data/classif-cat-large-0-road-safety/READY\n","data/classif-cat-large-0-road-safety/X_num_test.npy\n","data/classif-cat-large-0-road-safety/Y_test.npy\n","data/classif-cat-large-0-road-safety/Y_train.npy\n","data/classif-num-medium-1-MagicTelescope/\n","data/classif-num-medium-1-MagicTelescope/X_num_val.npy\n","data/classif-num-medium-1-MagicTelescope/Y_val.npy\n","data/classif-num-medium-1-MagicTelescope/X_num_train.npy\n","data/classif-num-medium-1-MagicTelescope/info.json\n","data/classif-num-medium-1-MagicTelescope/READY\n","data/classif-num-medium-1-MagicTelescope/X_num_test.npy\n","data/classif-num-medium-1-MagicTelescope/Y_test.npy\n","data/classif-num-medium-1-MagicTelescope/Y_train.npy\n","data/regression-num-medium-0-wine_quality/\n","data/regression-num-medium-0-wine_quality/X_num_val.npy\n","data/regression-num-medium-0-wine_quality/Y_val.npy\n","data/regression-num-medium-0-wine_quality/X_num_train.npy\n","data/regression-num-medium-0-wine_quality/info.json\n","data/regression-num-medium-0-wine_quality/READY\n","data/regression-num-medium-0-wine_quality/X_num_test.npy\n","data/regression-num-medium-0-wine_quality/Y_test.npy\n","data/regression-num-medium-0-wine_quality/Y_train.npy\n","data/adult/\n","data/adult/X_cat_val.npy\n","data/adult/X_num_val.npy\n","data/adult/Y_val.npy\n","data/adult/X_bin_val.npy\n","data/adult/X_num_train.npy\n","data/adult/X_cat_test.npy\n","data/adult/X_bin_train.npy\n","data/adult/X_cat_train.npy\n","data/adult/info.json\n","data/adult/READY\n","data/adult/X_bin_test.npy\n","data/adult/X_num_test.npy\n","data/adult/Y_test.npy\n","data/adult/Y_train.npy\n","data/classif-num-medium-1-kdd_ipums_la_97-small/\n","data/classif-num-medium-1-kdd_ipums_la_97-small/X_num_val.npy\n","data/classif-num-medium-1-kdd_ipums_la_97-small/Y_val.npy\n","data/classif-num-medium-1-kdd_ipums_la_97-small/X_num_train.npy\n","data/classif-num-medium-1-kdd_ipums_la_97-small/info.json\n","data/classif-num-medium-1-kdd_ipums_la_97-small/READY\n","data/classif-num-medium-1-kdd_ipums_la_97-small/X_num_test.npy\n","data/classif-num-medium-1-kdd_ipums_la_97-small/Y_test.npy\n","data/classif-num-medium-1-kdd_ipums_la_97-small/Y_train.npy\n","data/regression-num-medium-0-superconduct/\n","data/regression-num-medium-0-superconduct/X_num_val.npy\n","data/regression-num-medium-0-superconduct/Y_val.npy\n","data/regression-num-medium-0-superconduct/X_num_train.npy\n","data/regression-num-medium-0-superconduct/info.json\n","data/regression-num-medium-0-superconduct/READY\n","data/regression-num-medium-0-superconduct/X_num_test.npy\n","data/regression-num-medium-0-superconduct/Y_test.npy\n","data/regression-num-medium-0-superconduct/Y_train.npy\n","data/regression-num-medium-0-house_16H/\n","data/regression-num-medium-0-house_16H/X_num_val.npy\n","data/regression-num-medium-0-house_16H/Y_val.npy\n","data/regression-num-medium-0-house_16H/X_num_train.npy\n","data/regression-num-medium-0-house_16H/info.json\n","data/regression-num-medium-0-house_16H/READY\n","data/regression-num-medium-0-house_16H/X_num_test.npy\n","data/regression-num-medium-0-house_16H/Y_test.npy\n","data/regression-num-medium-0-house_16H/Y_train.npy\n","data/weather-big/\n","data/weather-big/X_num_val.npy\n","data/weather-big/Y_val.npy\n","data/weather-big/X_bin_val.npy\n","data/weather-big/X_num_train.npy\n","data/weather-big/X_bin_train.npy\n","data/weather-big/LICENSE.md\n","data/weather-big/info.json\n","data/weather-big/READY\n","data/weather-big/X_bin_test.npy\n","data/weather-big/X_num_test.npy\n","data/weather-big/Y_test.npy\n","data/weather-big/Y_train.npy\n","data/classif-num-large-0-Higgs/\n","data/classif-num-large-0-Higgs/X_num_val.npy\n","data/classif-num-large-0-Higgs/Y_val.npy\n","data/classif-num-large-0-Higgs/X_num_train.npy\n","data/classif-num-large-0-Higgs/info.json\n","data/classif-num-large-0-Higgs/READY\n","data/classif-num-large-0-Higgs/X_num_test.npy\n","data/classif-num-large-0-Higgs/Y_test.npy\n","data/classif-num-large-0-Higgs/Y_train.npy\n","data/regression-cat-medium-2-analcatdata_supreme/\n","data/regression-cat-medium-2-analcatdata_supreme/X_num_val.npy\n","data/regression-cat-medium-2-analcatdata_supreme/Y_val.npy\n","data/regression-cat-medium-2-analcatdata_supreme/X_bin_val.npy\n","data/regression-cat-medium-2-analcatdata_supreme/X_num_train.npy\n","data/regression-cat-medium-2-analcatdata_supreme/X_bin_train.npy\n","data/regression-cat-medium-2-analcatdata_supreme/info.json\n","data/regression-cat-medium-2-analcatdata_supreme/READY\n","data/regression-cat-medium-2-analcatdata_supreme/X_bin_test.npy\n","data/regression-cat-medium-2-analcatdata_supreme/X_num_test.npy\n","data/regression-cat-medium-2-analcatdata_supreme/Y_test.npy\n","data/regression-cat-medium-2-analcatdata_supreme/Y_train.npy\n","data/regression-cat-large-0-black_friday/\n","data/regression-cat-large-0-black_friday/X_cat_val.npy\n","data/regression-cat-large-0-black_friday/X_num_val.npy\n","data/regression-cat-large-0-black_friday/Y_val.npy\n","data/regression-cat-large-0-black_friday/X_bin_val.npy\n","data/regression-cat-large-0-black_friday/X_num_train.npy\n","data/regression-cat-large-0-black_friday/X_cat_test.npy\n","data/regression-cat-large-0-black_friday/X_bin_train.npy\n","data/regression-cat-large-0-black_friday/X_cat_train.npy\n","data/regression-cat-large-0-black_friday/info.json\n","data/regression-cat-large-0-black_friday/READY\n","data/regression-cat-large-0-black_friday/X_bin_test.npy\n","data/regression-cat-large-0-black_friday/X_num_test.npy\n","data/regression-cat-large-0-black_friday/Y_test.npy\n","data/regression-cat-large-0-black_friday/Y_train.npy\n","data/classif-num-medium-1-wine/\n","data/classif-num-medium-1-wine/X_num_val.npy\n","data/classif-num-medium-1-wine/Y_val.npy\n","data/classif-num-medium-1-wine/X_num_train.npy\n","data/classif-num-medium-1-wine/info.json\n","data/classif-num-medium-1-wine/READY\n","data/classif-num-medium-1-wine/X_num_test.npy\n","data/classif-num-medium-1-wine/Y_test.npy\n","data/classif-num-medium-1-wine/Y_train.npy\n","data/regression-cat-medium-0-visualizing_soil/\n","data/regression-cat-medium-0-visualizing_soil/X_num_val.npy\n","data/regression-cat-medium-0-visualizing_soil/Y_val.npy\n","data/regression-cat-medium-0-visualizing_soil/X_bin_val.npy\n","data/regression-cat-medium-0-visualizing_soil/X_num_train.npy\n","data/regression-cat-medium-0-visualizing_soil/X_bin_train.npy\n","data/regression-cat-medium-0-visualizing_soil/info.json\n","data/regression-cat-medium-0-visualizing_soil/READY\n","data/regression-cat-medium-0-visualizing_soil/X_bin_test.npy\n","data/regression-cat-medium-0-visualizing_soil/X_num_test.npy\n","data/regression-cat-medium-0-visualizing_soil/Y_test.npy\n","data/regression-cat-medium-0-visualizing_soil/Y_train.npy\n","data/regression-cat-medium-1-Mercedes_Benz_Greener_Manufacturing/\n","data/regression-cat-medium-1-Mercedes_Benz_Greener_Manufacturing/X_cat_val.npy\n","data/regression-cat-medium-1-Mercedes_Benz_Greener_Manufacturing/Y_val.npy\n","data/regression-cat-medium-1-Mercedes_Benz_Greener_Manufacturing/X_bin_val.npy\n","data/regression-cat-medium-1-Mercedes_Benz_Greener_Manufacturing/X_cat_test.npy\n","data/regression-cat-medium-1-Mercedes_Benz_Greener_Manufacturing/X_bin_train.npy\n","data/regression-cat-medium-1-Mercedes_Benz_Greener_Manufacturing/X_cat_train.npy\n","data/regression-cat-medium-1-Mercedes_Benz_Greener_Manufacturing/info.json\n","data/regression-cat-medium-1-Mercedes_Benz_Greener_Manufacturing/READY\n","data/regression-cat-medium-1-Mercedes_Benz_Greener_Manufacturing/X_bin_test.npy\n","data/regression-cat-medium-1-Mercedes_Benz_Greener_Manufacturing/Y_test.npy\n","data/regression-cat-medium-1-Mercedes_Benz_Greener_Manufacturing/Y_train.npy\n","data/classif-num-medium-0-kdd_ipums_la_97-small/\n","data/classif-num-medium-0-kdd_ipums_la_97-small/X_num_val.npy\n","data/classif-num-medium-0-kdd_ipums_la_97-small/Y_val.npy\n","data/classif-num-medium-0-kdd_ipums_la_97-small/X_num_train.npy\n","data/classif-num-medium-0-kdd_ipums_la_97-small/info.json\n","data/classif-num-medium-0-kdd_ipums_la_97-small/READY\n","data/classif-num-medium-0-kdd_ipums_la_97-small/X_num_test.npy\n","data/classif-num-medium-0-kdd_ipums_la_97-small/Y_test.npy\n","data/classif-num-medium-0-kdd_ipums_la_97-small/Y_train.npy\n","data/regression-num-medium-1-MiamiHousing2016/\n","data/regression-num-medium-1-MiamiHousing2016/X_num_val.npy\n","data/regression-num-medium-1-MiamiHousing2016/Y_val.npy\n","data/regression-num-medium-1-MiamiHousing2016/X_num_train.npy\n","data/regression-num-medium-1-MiamiHousing2016/info.json\n","data/regression-num-medium-1-MiamiHousing2016/READY\n","data/regression-num-medium-1-MiamiHousing2016/X_num_test.npy\n","data/regression-num-medium-1-MiamiHousing2016/Y_test.npy\n","data/regression-num-medium-1-MiamiHousing2016/Y_train.npy\n","data/regression-cat-medium-0-OnlineNewsPopularity/\n","data/regression-cat-medium-0-OnlineNewsPopularity/X_num_val.npy\n","data/regression-cat-medium-0-OnlineNewsPopularity/Y_val.npy\n","data/regression-cat-medium-0-OnlineNewsPopularity/X_bin_val.npy\n","data/regression-cat-medium-0-OnlineNewsPopularity/X_num_train.npy\n","data/regression-cat-medium-0-OnlineNewsPopularity/X_bin_train.npy\n","data/regression-cat-medium-0-OnlineNewsPopularity/info.json\n","data/regression-cat-medium-0-OnlineNewsPopularity/READY\n","data/regression-cat-medium-0-OnlineNewsPopularity/X_bin_test.npy\n","data/regression-cat-medium-0-OnlineNewsPopularity/X_num_test.npy\n","data/regression-cat-medium-0-OnlineNewsPopularity/Y_test.npy\n","data/regression-cat-medium-0-OnlineNewsPopularity/Y_train.npy\n","data/regression-num-medium-1-elevators/\n","data/regression-num-medium-1-elevators/X_num_val.npy\n","data/regression-num-medium-1-elevators/Y_val.npy\n","data/regression-num-medium-1-elevators/X_num_train.npy\n","data/regression-num-medium-1-elevators/info.json\n","data/regression-num-medium-1-elevators/READY\n","data/regression-num-medium-1-elevators/X_num_test.npy\n","data/regression-num-medium-1-elevators/Y_test.npy\n","data/regression-num-medium-1-elevators/Y_train.npy\n","data/regression-num-medium-0-pol/\n","data/regression-num-medium-0-pol/X_num_val.npy\n","data/regression-num-medium-0-pol/Y_val.npy\n","data/regression-num-medium-0-pol/X_num_train.npy\n","data/regression-num-medium-0-pol/info.json\n","data/regression-num-medium-0-pol/READY\n","data/regression-num-medium-0-pol/X_num_test.npy\n","data/regression-num-medium-0-pol/Y_test.npy\n","data/regression-num-medium-0-pol/Y_train.npy\n","data/classif-num-medium-2-kdd_ipums_la_97-small/\n","data/classif-num-medium-2-kdd_ipums_la_97-small/X_num_val.npy\n","data/classif-num-medium-2-kdd_ipums_la_97-small/Y_val.npy\n","data/classif-num-medium-2-kdd_ipums_la_97-small/X_num_train.npy\n","data/classif-num-medium-2-kdd_ipums_la_97-small/info.json\n","data/classif-num-medium-2-kdd_ipums_la_97-small/READY\n","data/classif-num-medium-2-kdd_ipums_la_97-small/X_num_test.npy\n","data/classif-num-medium-2-kdd_ipums_la_97-small/Y_test.npy\n","data/classif-num-medium-2-kdd_ipums_la_97-small/Y_train.npy\n","data/classif-num-medium-0-phoneme/\n","data/classif-num-medium-0-phoneme/X_num_val.npy\n","data/classif-num-medium-0-phoneme/Y_val.npy\n","data/classif-num-medium-0-phoneme/X_num_train.npy\n","data/classif-num-medium-0-phoneme/info.json\n","data/classif-num-medium-0-phoneme/READY\n","data/classif-num-medium-0-phoneme/X_num_test.npy\n","data/classif-num-medium-0-phoneme/Y_test.npy\n","data/classif-num-medium-0-phoneme/Y_train.npy\n","data/regression-num-medium-0-sulfur/\n","data/regression-num-medium-0-sulfur/X_num_val.npy\n","data/regression-num-medium-0-sulfur/Y_val.npy\n","data/regression-num-medium-0-sulfur/X_num_train.npy\n","data/regression-num-medium-0-sulfur/info.json\n","data/regression-num-medium-0-sulfur/READY\n","data/regression-num-medium-0-sulfur/X_num_test.npy\n","data/regression-num-medium-0-sulfur/Y_test.npy\n","data/regression-num-medium-0-sulfur/Y_train.npy\n","data/regression-cat-medium-0-analcatdata_supreme/\n","data/regression-cat-medium-0-analcatdata_supreme/X_num_val.npy\n","data/regression-cat-medium-0-analcatdata_supreme/Y_val.npy\n","data/regression-cat-medium-0-analcatdata_supreme/X_bin_val.npy\n","data/regression-cat-medium-0-analcatdata_supreme/X_num_train.npy\n","data/regression-cat-medium-0-analcatdata_supreme/X_bin_train.npy\n","data/regression-cat-medium-0-analcatdata_supreme/info.json\n","data/regression-cat-medium-0-analcatdata_supreme/READY\n","data/regression-cat-medium-0-analcatdata_supreme/X_bin_test.npy\n","data/regression-cat-medium-0-analcatdata_supreme/X_num_test.npy\n","data/regression-cat-medium-0-analcatdata_supreme/Y_test.npy\n","data/regression-cat-medium-0-analcatdata_supreme/Y_train.npy\n","data/classif-num-medium-2-phoneme/\n","data/classif-num-medium-2-phoneme/X_num_val.npy\n","data/classif-num-medium-2-phoneme/Y_val.npy\n","data/classif-num-medium-2-phoneme/X_num_train.npy\n","data/classif-num-medium-2-phoneme/info.json\n","data/classif-num-medium-2-phoneme/READY\n","data/classif-num-medium-2-phoneme/X_num_test.npy\n","data/classif-num-medium-2-phoneme/Y_test.npy\n","data/classif-num-medium-2-phoneme/Y_train.npy\n","data/regression-cat-large-0-SGEMM_GPU_kernel_performance/\n","data/regression-cat-large-0-SGEMM_GPU_kernel_performance/X_num_val.npy\n","data/regression-cat-large-0-SGEMM_GPU_kernel_performance/Y_val.npy\n","data/regression-cat-large-0-SGEMM_GPU_kernel_performance/X_bin_val.npy\n","data/regression-cat-large-0-SGEMM_GPU_kernel_performance/X_num_train.npy\n","data/regression-cat-large-0-SGEMM_GPU_kernel_performance/X_bin_train.npy\n","data/regression-cat-large-0-SGEMM_GPU_kernel_performance/info.json\n","data/regression-cat-large-0-SGEMM_GPU_kernel_performance/READY\n","data/regression-cat-large-0-SGEMM_GPU_kernel_performance/X_bin_test.npy\n","data/regression-cat-large-0-SGEMM_GPU_kernel_performance/X_num_test.npy\n","data/regression-cat-large-0-SGEMM_GPU_kernel_performance/Y_test.npy\n","data/regression-cat-large-0-SGEMM_GPU_kernel_performance/Y_train.npy\n","data/regression-num-medium-1-wine_quality/\n","data/regression-num-medium-1-wine_quality/X_num_val.npy\n","data/regression-num-medium-1-wine_quality/Y_val.npy\n","data/regression-num-medium-1-wine_quality/X_num_train.npy\n","data/regression-num-medium-1-wine_quality/info.json\n","data/regression-num-medium-1-wine_quality/READY\n","data/regression-num-medium-1-wine_quality/X_num_test.npy\n","data/regression-num-medium-1-wine_quality/Y_test.npy\n","data/regression-num-medium-1-wine_quality/Y_train.npy\n","data/regression-num-medium-0-cpu_act/\n","data/regression-num-medium-0-cpu_act/X_num_val.npy\n","data/regression-num-medium-0-cpu_act/Y_val.npy\n","data/regression-num-medium-0-cpu_act/X_num_train.npy\n","data/regression-num-medium-0-cpu_act/info.json\n","data/regression-num-medium-0-cpu_act/READY\n","data/regression-num-medium-0-cpu_act/X_num_test.npy\n","data/regression-num-medium-0-cpu_act/Y_test.npy\n","data/regression-num-medium-0-cpu_act/Y_train.npy\n","data/regression-cat-medium-0-Bike_Sharing_Demand/\n","data/regression-cat-medium-0-Bike_Sharing_Demand/X_cat_val.npy\n","data/regression-cat-medium-0-Bike_Sharing_Demand/X_num_val.npy\n","data/regression-cat-medium-0-Bike_Sharing_Demand/Y_val.npy\n","data/regression-cat-medium-0-Bike_Sharing_Demand/X_bin_val.npy\n","data/regression-cat-medium-0-Bike_Sharing_Demand/X_num_train.npy\n","data/regression-cat-medium-0-Bike_Sharing_Demand/X_cat_test.npy\n","data/regression-cat-medium-0-Bike_Sharing_Demand/X_bin_train.npy\n","data/regression-cat-medium-0-Bike_Sharing_Demand/X_cat_train.npy\n","data/regression-cat-medium-0-Bike_Sharing_Demand/info.json\n","data/regression-cat-medium-0-Bike_Sharing_Demand/READY\n","data/regression-cat-medium-0-Bike_Sharing_Demand/X_bin_test.npy\n","data/regression-cat-medium-0-Bike_Sharing_Demand/X_num_test.npy\n","data/regression-cat-medium-0-Bike_Sharing_Demand/Y_test.npy\n","data/regression-cat-medium-0-Bike_Sharing_Demand/Y_train.npy\n","data/regression-cat-medium-1-visualizing_soil/\n","data/regression-cat-medium-1-visualizing_soil/X_num_val.npy\n","data/regression-cat-medium-1-visualizing_soil/Y_val.npy\n","data/regression-cat-medium-1-visualizing_soil/X_bin_val.npy\n","data/regression-cat-medium-1-visualizing_soil/X_num_train.npy\n","data/regression-cat-medium-1-visualizing_soil/X_bin_train.npy\n","data/regression-cat-medium-1-visualizing_soil/info.json\n","data/regression-cat-medium-1-visualizing_soil/READY\n","data/regression-cat-medium-1-visualizing_soil/X_bin_test.npy\n","data/regression-cat-medium-1-visualizing_soil/X_num_test.npy\n","data/regression-cat-medium-1-visualizing_soil/Y_test.npy\n","data/regression-cat-medium-1-visualizing_soil/Y_train.npy\n","data/classif-num-medium-4-phoneme/\n","data/classif-num-medium-4-phoneme/X_num_val.npy\n","data/classif-num-medium-4-phoneme/Y_val.npy\n","data/classif-num-medium-4-phoneme/X_num_train.npy\n","data/classif-num-medium-4-phoneme/info.json\n","data/classif-num-medium-4-phoneme/READY\n","data/classif-num-medium-4-phoneme/X_num_test.npy\n","data/classif-num-medium-4-phoneme/Y_test.npy\n","data/classif-num-medium-4-phoneme/Y_train.npy\n","data/house/\n","data/house/X_num_val.npy\n","data/house/Y_val.npy\n","data/house/X_num_train.npy\n","data/house/info.json\n","data/house/READY\n","data/house/X_num_test.npy\n","data/house/Y_test.npy\n","data/house/Y_train.npy\n","data/regression-cat-medium-2-Brazilian_houses/\n","data/regression-cat-medium-2-Brazilian_houses/X_cat_val.npy\n","data/regression-cat-medium-2-Brazilian_houses/X_num_val.npy\n","data/regression-cat-medium-2-Brazilian_houses/Y_val.npy\n","data/regression-cat-medium-2-Brazilian_houses/X_bin_val.npy\n","data/regression-cat-medium-2-Brazilian_houses/X_num_train.npy\n","data/regression-cat-medium-2-Brazilian_houses/X_cat_test.npy\n","data/regression-cat-medium-2-Brazilian_houses/X_bin_train.npy\n","data/regression-cat-medium-2-Brazilian_houses/X_cat_train.npy\n","data/regression-cat-medium-2-Brazilian_houses/info.json\n","data/regression-cat-medium-2-Brazilian_houses/READY\n","data/regression-cat-medium-2-Brazilian_houses/X_bin_test.npy\n","data/regression-cat-medium-2-Brazilian_houses/X_num_test.npy\n","data/regression-cat-medium-2-Brazilian_houses/Y_test.npy\n","data/regression-cat-medium-2-Brazilian_houses/Y_train.npy\n","data/regression-cat-large-0-particulate-matter-ukair-2017/\n","data/regression-cat-large-0-particulate-matter-ukair-2017/X_cat_val.npy\n","data/regression-cat-large-0-particulate-matter-ukair-2017/X_num_val.npy\n","data/regression-cat-large-0-particulate-matter-ukair-2017/Y_val.npy\n","data/regression-cat-large-0-particulate-matter-ukair-2017/X_num_train.npy\n","data/regression-cat-large-0-particulate-matter-ukair-2017/X_cat_test.npy\n","data/regression-cat-large-0-particulate-matter-ukair-2017/X_cat_train.npy\n","data/regression-cat-large-0-particulate-matter-ukair-2017/info.json\n","data/regression-cat-large-0-particulate-matter-ukair-2017/READY\n","data/regression-cat-large-0-particulate-matter-ukair-2017/X_num_test.npy\n","data/regression-cat-large-0-particulate-matter-ukair-2017/Y_test.npy\n","data/regression-cat-large-0-particulate-matter-ukair-2017/Y_train.npy\n","data/regression-cat-medium-2-Mercedes_Benz_Greener_Manufacturing/\n","data/regression-cat-medium-2-Mercedes_Benz_Greener_Manufacturing/X_cat_val.npy\n","data/regression-cat-medium-2-Mercedes_Benz_Greener_Manufacturing/Y_val.npy\n","data/regression-cat-medium-2-Mercedes_Benz_Greener_Manufacturing/X_bin_val.npy\n","data/regression-cat-medium-2-Mercedes_Benz_Greener_Manufacturing/X_cat_test.npy\n","data/regression-cat-medium-2-Mercedes_Benz_Greener_Manufacturing/X_bin_train.npy\n","data/regression-cat-medium-2-Mercedes_Benz_Greener_Manufacturing/X_cat_train.npy\n","data/regression-cat-medium-2-Mercedes_Benz_Greener_Manufacturing/info.json\n","data/regression-cat-medium-2-Mercedes_Benz_Greener_Manufacturing/READY\n","data/regression-cat-medium-2-Mercedes_Benz_Greener_Manufacturing/X_bin_test.npy\n","data/regression-cat-medium-2-Mercedes_Benz_Greener_Manufacturing/Y_test.npy\n","data/regression-cat-medium-2-Mercedes_Benz_Greener_Manufacturing/Y_train.npy\n","data/black-friday/\n","data/black-friday/X_cat_val.npy\n","data/black-friday/X_num_val.npy\n","data/black-friday/Y_val.npy\n","data/black-friday/X_bin_val.npy\n","data/black-friday/X_num_train.npy\n","data/black-friday/X_cat_test.npy\n","data/black-friday/X_bin_train.npy\n","data/black-friday/X_cat_train.npy\n","data/black-friday/info.json\n","data/black-friday/X_bin_test.npy\n","data/black-friday/X_num_test.npy\n","data/black-friday/Y_test.npy\n","data/black-friday/Y_train.npy\n","data/regression-num-medium-1-sulfur/\n","data/regression-num-medium-1-sulfur/X_num_val.npy\n","data/regression-num-medium-1-sulfur/Y_val.npy\n","data/regression-num-medium-1-sulfur/X_num_train.npy\n","data/regression-num-medium-1-sulfur/info.json\n","data/regression-num-medium-1-sulfur/READY\n","data/regression-num-medium-1-sulfur/X_num_test.npy\n","data/regression-num-medium-1-sulfur/Y_test.npy\n","data/regression-num-medium-1-sulfur/Y_train.npy\n","data/classif-num-medium-0-wine/\n","data/classif-num-medium-0-wine/X_num_val.npy\n","data/classif-num-medium-0-wine/Y_val.npy\n","data/classif-num-medium-0-wine/X_num_train.npy\n","data/classif-num-medium-0-wine/info.json\n","data/classif-num-medium-0-wine/READY\n","data/classif-num-medium-0-wine/X_num_test.npy\n","data/classif-num-medium-0-wine/Y_test.npy\n","data/classif-num-medium-0-wine/Y_train.npy\n","data/covtype/\n","data/covtype/X_num_val.npy\n","data/covtype/Y_val.npy\n","data/covtype/X_bin_val.npy\n","data/covtype/X_num_train.npy\n","data/covtype/X_bin_train.npy\n","data/covtype/info.json\n","data/covtype/READY\n","data/covtype/X_bin_test.npy\n","data/covtype/X_num_test.npy\n","data/covtype/Y_test.npy\n","data/covtype/Y_train.npy\n","data/regression-cat-large-0-nyc-taxi-green-dec-2016/\n","data/regression-cat-large-0-nyc-taxi-green-dec-2016/X_cat_val.npy\n","data/regression-cat-large-0-nyc-taxi-green-dec-2016/X_num_val.npy\n","data/regression-cat-large-0-nyc-taxi-green-dec-2016/Y_val.npy\n","data/regression-cat-large-0-nyc-taxi-green-dec-2016/X_bin_val.npy\n","data/regression-cat-large-0-nyc-taxi-green-dec-2016/X_num_train.npy\n","data/regression-cat-large-0-nyc-taxi-green-dec-2016/X_cat_test.npy\n","data/regression-cat-large-0-nyc-taxi-green-dec-2016/X_bin_train.npy\n","data/regression-cat-large-0-nyc-taxi-green-dec-2016/X_cat_train.npy\n","data/regression-cat-large-0-nyc-taxi-green-dec-2016/info.json\n","data/regression-cat-large-0-nyc-taxi-green-dec-2016/READY\n","data/regression-cat-large-0-nyc-taxi-green-dec-2016/X_bin_test.npy\n","data/regression-cat-large-0-nyc-taxi-green-dec-2016/X_num_test.npy\n","data/regression-cat-large-0-nyc-taxi-green-dec-2016/Y_test.npy\n","data/regression-cat-large-0-nyc-taxi-green-dec-2016/Y_train.npy\n","data/classif-num-medium-0-MagicTelescope/\n","data/classif-num-medium-0-MagicTelescope/X_num_val.npy\n","data/classif-num-medium-0-MagicTelescope/Y_val.npy\n","data/classif-num-medium-0-MagicTelescope/X_num_train.npy\n","data/classif-num-medium-0-MagicTelescope/info.json\n","data/classif-num-medium-0-MagicTelescope/READY\n","data/classif-num-medium-0-MagicTelescope/X_num_test.npy\n","data/classif-num-medium-0-MagicTelescope/Y_test.npy\n","data/classif-num-medium-0-MagicTelescope/Y_train.npy\n","data/regression-cat-medium-3-analcatdata_supreme/\n","data/regression-cat-medium-3-analcatdata_supreme/X_num_val.npy\n","data/regression-cat-medium-3-analcatdata_supreme/Y_val.npy\n","data/regression-cat-medium-3-analcatdata_supreme/X_bin_val.npy\n","data/regression-cat-medium-3-analcatdata_supreme/X_num_train.npy\n","data/regression-cat-medium-3-analcatdata_supreme/X_bin_train.npy\n","data/regression-cat-medium-3-analcatdata_supreme/info.json\n","data/regression-cat-medium-3-analcatdata_supreme/READY\n","data/regression-cat-medium-3-analcatdata_supreme/X_bin_test.npy\n","data/regression-cat-medium-3-analcatdata_supreme/X_num_test.npy\n","data/regression-cat-medium-3-analcatdata_supreme/Y_test.npy\n","data/regression-cat-medium-3-analcatdata_supreme/Y_train.npy\n","data/regression-cat-medium-0-Mercedes_Benz_Greener_Manufacturing/\n","data/regression-cat-medium-0-Mercedes_Benz_Greener_Manufacturing/X_cat_val.npy\n","data/regression-cat-medium-0-Mercedes_Benz_Greener_Manufacturing/Y_val.npy\n","data/regression-cat-medium-0-Mercedes_Benz_Greener_Manufacturing/X_bin_val.npy\n","data/regression-cat-medium-0-Mercedes_Benz_Greener_Manufacturing/X_cat_test.npy\n","data/regression-cat-medium-0-Mercedes_Benz_Greener_Manufacturing/X_bin_train.npy\n","data/regression-cat-medium-0-Mercedes_Benz_Greener_Manufacturing/X_cat_train.npy\n","data/regression-cat-medium-0-Mercedes_Benz_Greener_Manufacturing/info.json\n","data/regression-cat-medium-0-Mercedes_Benz_Greener_Manufacturing/READY\n","data/regression-cat-medium-0-Mercedes_Benz_Greener_Manufacturing/X_bin_test.npy\n","data/regression-cat-medium-0-Mercedes_Benz_Greener_Manufacturing/Y_test.npy\n","data/regression-cat-medium-0-Mercedes_Benz_Greener_Manufacturing/Y_train.npy\n","data/microsoft/\n","data/microsoft/X_num_val.npy\n","data/microsoft/Y_val.npy\n","data/microsoft/X_bin_val.npy\n","data/microsoft/X_num_train.npy\n","data/microsoft/X_bin_train.npy\n","data/microsoft/info.json\n","data/microsoft/READY\n","data/microsoft/X_bin_test.npy\n","data/microsoft/X_num_test.npy\n","data/microsoft/Y_test.npy\n","data/microsoft/Y_train.npy\n","data/regression-cat-medium-4-analcatdata_supreme/\n","data/regression-cat-medium-4-analcatdata_supreme/X_num_val.npy\n","data/regression-cat-medium-4-analcatdata_supreme/Y_val.npy\n","data/regression-cat-medium-4-analcatdata_supreme/X_bin_val.npy\n","data/regression-cat-medium-4-analcatdata_supreme/X_num_train.npy\n","data/regression-cat-medium-4-analcatdata_supreme/X_bin_train.npy\n","data/regression-cat-medium-4-analcatdata_supreme/info.json\n","data/regression-cat-medium-4-analcatdata_supreme/READY\n","data/regression-cat-medium-4-analcatdata_supreme/X_bin_test.npy\n","data/regression-cat-medium-4-analcatdata_supreme/X_num_test.npy\n","data/regression-cat-medium-4-analcatdata_supreme/Y_test.npy\n","data/regression-cat-medium-4-analcatdata_supreme/Y_train.npy\n","data/regression-num-medium-1-fifa/\n","data/regression-num-medium-1-fifa/X_num_val.npy\n","data/regression-num-medium-1-fifa/Y_val.npy\n","data/regression-num-medium-1-fifa/X_num_train.npy\n","data/regression-num-medium-1-fifa/info.json\n","data/regression-num-medium-1-fifa/READY\n","data/regression-num-medium-1-fifa/X_num_test.npy\n","data/regression-num-medium-1-fifa/Y_test.npy\n","data/regression-num-medium-1-fifa/Y_train.npy\n","data/regression-num-medium-0-isolet/\n","data/regression-num-medium-0-isolet/X_num_val.npy\n","data/regression-num-medium-0-isolet/Y_val.npy\n","data/regression-num-medium-0-isolet/X_num_train.npy\n","data/regression-num-medium-0-isolet/info.json\n","data/regression-num-medium-0-isolet/READY\n","data/regression-num-medium-0-isolet/X_num_test.npy\n","data/regression-num-medium-0-isolet/Y_test.npy\n","data/regression-num-medium-0-isolet/Y_train.npy\n","data/classif-num-medium-3-phoneme/\n","data/classif-num-medium-3-phoneme/X_num_val.npy\n","data/classif-num-medium-3-phoneme/Y_val.npy\n","data/classif-num-medium-3-phoneme/X_num_train.npy\n","data/classif-num-medium-3-phoneme/info.json\n","data/classif-num-medium-3-phoneme/READY\n","data/classif-num-medium-3-phoneme/X_num_test.npy\n","data/classif-num-medium-3-phoneme/Y_test.npy\n","data/classif-num-medium-3-phoneme/Y_train.npy\n","data/regression-cat-medium-3-Mercedes_Benz_Greener_Manufacturing/\n","data/regression-cat-medium-3-Mercedes_Benz_Greener_Manufacturing/X_cat_val.npy\n","data/regression-cat-medium-3-Mercedes_Benz_Greener_Manufacturing/Y_val.npy\n","data/regression-cat-medium-3-Mercedes_Benz_Greener_Manufacturing/X_bin_val.npy\n","data/regression-cat-medium-3-Mercedes_Benz_Greener_Manufacturing/X_cat_test.npy\n","data/regression-cat-medium-3-Mercedes_Benz_Greener_Manufacturing/X_bin_train.npy\n","data/regression-cat-medium-3-Mercedes_Benz_Greener_Manufacturing/X_cat_train.npy\n","data/regression-cat-medium-3-Mercedes_Benz_Greener_Manufacturing/info.json\n","data/regression-cat-medium-3-Mercedes_Benz_Greener_Manufacturing/READY\n","data/regression-cat-medium-3-Mercedes_Benz_Greener_Manufacturing/X_bin_test.npy\n","data/regression-cat-medium-3-Mercedes_Benz_Greener_Manufacturing/Y_test.npy\n","data/regression-cat-medium-3-Mercedes_Benz_Greener_Manufacturing/Y_train.npy\n","data/california/\n","data/california/X_num_val.npy\n","data/california/Y_val.npy\n","data/california/X_num_train.npy\n","data/california/info.json\n","data/california/READY\n","data/california/X_num_test.npy\n","data/california/Y_test.npy\n","data/california/Y_train.npy\n","data/classif-cat-medium-2-rl/\n","data/classif-cat-medium-2-rl/X_cat_val.npy\n","data/classif-cat-medium-2-rl/X_num_val.npy\n","data/classif-cat-medium-2-rl/Y_val.npy\n","data/classif-cat-medium-2-rl/X_bin_val.npy\n","data/classif-cat-medium-2-rl/X_num_train.npy\n","data/classif-cat-medium-2-rl/X_cat_test.npy\n","data/classif-cat-medium-2-rl/X_bin_train.npy\n","data/classif-cat-medium-2-rl/X_cat_train.npy\n","data/classif-cat-medium-2-rl/info.json\n","data/classif-cat-medium-2-rl/READY\n","data/classif-cat-medium-2-rl/X_bin_test.npy\n","data/classif-cat-medium-2-rl/X_num_test.npy\n","data/classif-cat-medium-2-rl/Y_test.npy\n","data/classif-cat-medium-2-rl/Y_train.npy\n","data/regression-cat-medium-0-Brazilian_houses/\n","data/regression-cat-medium-0-Brazilian_houses/X_cat_val.npy\n","data/regression-cat-medium-0-Brazilian_houses/X_num_val.npy\n","data/regression-cat-medium-0-Brazilian_houses/Y_val.npy\n","data/regression-cat-medium-0-Brazilian_houses/X_bin_val.npy\n","data/regression-cat-medium-0-Brazilian_houses/X_num_train.npy\n","data/regression-cat-medium-0-Brazilian_houses/X_cat_test.npy\n","data/regression-cat-medium-0-Brazilian_houses/X_bin_train.npy\n","data/regression-cat-medium-0-Brazilian_houses/X_cat_train.npy\n","data/regression-cat-medium-0-Brazilian_houses/info.json\n","data/regression-cat-medium-0-Brazilian_houses/READY\n","data/regression-cat-medium-0-Brazilian_houses/X_bin_test.npy\n","data/regression-cat-medium-0-Brazilian_houses/X_num_test.npy\n","data/regression-cat-medium-0-Brazilian_houses/Y_test.npy\n","data/regression-cat-medium-0-Brazilian_houses/Y_train.npy\n","data/regression-cat-medium-1-analcatdata_supreme/\n","data/regression-cat-medium-1-analcatdata_supreme/X_num_val.npy\n","data/regression-cat-medium-1-analcatdata_supreme/Y_val.npy\n","data/regression-cat-medium-1-analcatdata_supreme/X_bin_val.npy\n","data/regression-cat-medium-1-analcatdata_supreme/X_num_train.npy\n","data/regression-cat-medium-1-analcatdata_supreme/X_bin_train.npy\n","data/regression-cat-medium-1-analcatdata_supreme/info.json\n","data/regression-cat-medium-1-analcatdata_supreme/READY\n","data/regression-cat-medium-1-analcatdata_supreme/X_bin_test.npy\n","data/regression-cat-medium-1-analcatdata_supreme/X_num_test.npy\n","data/regression-cat-medium-1-analcatdata_supreme/Y_test.npy\n","data/regression-cat-medium-1-analcatdata_supreme/Y_train.npy\n","data/classif-num-medium-2-MagicTelescope/\n","data/classif-num-medium-2-MagicTelescope/X_num_val.npy\n","data/classif-num-medium-2-MagicTelescope/Y_val.npy\n","data/classif-num-medium-2-MagicTelescope/X_num_train.npy\n","data/classif-num-medium-2-MagicTelescope/info.json\n","data/classif-num-medium-2-MagicTelescope/READY\n","data/classif-num-medium-2-MagicTelescope/X_num_test.npy\n","data/classif-num-medium-2-MagicTelescope/Y_test.npy\n","data/classif-num-medium-2-MagicTelescope/Y_train.npy\n","data/classif-cat-medium-1-rl/\n","data/classif-cat-medium-1-rl/X_cat_val.npy\n","data/classif-cat-medium-1-rl/X_num_val.npy\n","data/classif-cat-medium-1-rl/Y_val.npy\n","data/classif-cat-medium-1-rl/X_bin_val.npy\n","data/classif-cat-medium-1-rl/X_num_train.npy\n","data/classif-cat-medium-1-rl/X_cat_test.npy\n","data/classif-cat-medium-1-rl/X_bin_train.npy\n","data/classif-cat-medium-1-rl/X_cat_train.npy\n","data/classif-cat-medium-1-rl/info.json\n","data/classif-cat-medium-1-rl/READY\n","data/classif-cat-medium-1-rl/X_bin_test.npy\n","data/classif-cat-medium-1-rl/X_num_test.npy\n","data/classif-cat-medium-1-rl/Y_test.npy\n","data/classif-cat-medium-1-rl/Y_train.npy\n","data/classif-cat-medium-0-compass/\n","data/classif-cat-medium-0-compass/X_cat_val.npy\n","data/classif-cat-medium-0-compass/X_num_val.npy\n","data/classif-cat-medium-0-compass/Y_val.npy\n","data/classif-cat-medium-0-compass/X_bin_val.npy\n","data/classif-cat-medium-0-compass/X_num_train.npy\n","data/classif-cat-medium-0-compass/X_cat_test.npy\n","data/classif-cat-medium-0-compass/X_bin_train.npy\n","data/classif-cat-medium-0-compass/X_cat_train.npy\n","data/classif-cat-medium-0-compass/info.json\n","data/classif-cat-medium-0-compass/READY\n","data/classif-cat-medium-0-compass/X_bin_test.npy\n","data/classif-cat-medium-0-compass/X_num_test.npy\n","data/classif-cat-medium-0-compass/Y_test.npy\n","data/classif-cat-medium-0-compass/Y_train.npy\n","data/regression-cat-medium-2-yprop_4_1/\n","data/regression-cat-medium-2-yprop_4_1/X_num_val.npy\n","data/regression-cat-medium-2-yprop_4_1/Y_val.npy\n","data/regression-cat-medium-2-yprop_4_1/X_bin_val.npy\n","data/regression-cat-medium-2-yprop_4_1/X_num_train.npy\n","data/regression-cat-medium-2-yprop_4_1/X_bin_train.npy\n","data/regression-cat-medium-2-yprop_4_1/info.json\n","data/regression-cat-medium-2-yprop_4_1/READY\n","data/regression-cat-medium-2-yprop_4_1/X_bin_test.npy\n","data/regression-cat-medium-2-yprop_4_1/X_num_test.npy\n","data/regression-cat-medium-2-yprop_4_1/Y_test.npy\n","data/regression-cat-medium-2-yprop_4_1/Y_train.npy\n","data/weather-small/\n","data/weather-small/X_num_val.npy\n","data/weather-small/Y_val.npy\n","data/weather-small/X_bin_val.npy\n","data/weather-small/X_num_train.npy\n","data/weather-small/X_bin_train.npy\n","data/weather-small/info.json\n","data/weather-small/READY\n","data/weather-small/X_bin_test.npy\n","data/weather-small/X_num_test.npy\n","data/weather-small/Y_test.npy\n","data/weather-small/Y_train.npy\n","data/diamond/\n","data/diamond/X_cat_val.npy\n","data/diamond/X_num_val.npy\n","data/diamond/Y_val.npy\n","data/diamond/X_num_train.npy\n","data/diamond/X_cat_test.npy\n","data/diamond/X_cat_train.npy\n","data/diamond/info.json\n","data/diamond/X_num_test.npy\n","data/diamond/Y_test.npy\n","data/diamond/Y_train.npy\n","data/regression-num-medium-0-fifa/\n","data/regression-num-medium-0-fifa/X_num_val.npy\n","data/regression-num-medium-0-fifa/Y_val.npy\n","data/regression-num-medium-0-fifa/X_num_train.npy\n","data/regression-num-medium-0-fifa/info.json\n","data/regression-num-medium-0-fifa/READY\n","data/regression-num-medium-0-fifa/X_num_test.npy\n","data/regression-num-medium-0-fifa/Y_test.npy\n","data/regression-num-medium-0-fifa/Y_train.npy\n","data/regression-num-medium-1-cpu_act/\n","data/regression-num-medium-1-cpu_act/X_num_val.npy\n","data/regression-num-medium-1-cpu_act/Y_val.npy\n","data/regression-num-medium-1-cpu_act/X_num_train.npy\n","data/regression-num-medium-1-cpu_act/info.json\n","data/regression-num-medium-1-cpu_act/READY\n","data/regression-num-medium-1-cpu_act/X_num_test.npy\n","data/regression-num-medium-1-cpu_act/Y_test.npy\n","data/regression-num-medium-1-cpu_act/Y_train.npy\n","data/regression-num-medium-1-pol/\n","data/regression-num-medium-1-pol/X_num_val.npy\n","data/regression-num-medium-1-pol/Y_val.npy\n","data/regression-num-medium-1-pol/X_num_train.npy\n","data/regression-num-medium-1-pol/info.json\n","data/regression-num-medium-1-pol/READY\n","data/regression-num-medium-1-pol/X_num_test.npy\n","data/regression-num-medium-1-pol/Y_test.npy\n","data/regression-num-medium-1-pol/Y_train.npy\n","data/regression-num-medium-0-elevators/\n","data/regression-num-medium-0-elevators/X_num_val.npy\n","data/regression-num-medium-0-elevators/Y_val.npy\n","data/regression-num-medium-0-elevators/X_num_train.npy\n","data/regression-num-medium-0-elevators/info.json\n","data/regression-num-medium-0-elevators/READY\n","data/regression-num-medium-0-elevators/X_num_test.npy\n","data/regression-num-medium-0-elevators/Y_test.npy\n","data/regression-num-medium-0-elevators/Y_train.npy\n","data/regression-cat-medium-4-Mercedes_Benz_Greener_Manufacturing/\n","data/regression-cat-medium-4-Mercedes_Benz_Greener_Manufacturing/X_cat_val.npy\n","data/regression-cat-medium-4-Mercedes_Benz_Greener_Manufacturing/Y_val.npy\n","data/regression-cat-medium-4-Mercedes_Benz_Greener_Manufacturing/X_bin_val.npy\n","data/regression-cat-medium-4-Mercedes_Benz_Greener_Manufacturing/X_cat_test.npy\n","data/regression-cat-medium-4-Mercedes_Benz_Greener_Manufacturing/X_bin_train.npy\n","data/regression-cat-medium-4-Mercedes_Benz_Greener_Manufacturing/X_cat_train.npy\n","data/regression-cat-medium-4-Mercedes_Benz_Greener_Manufacturing/info.json\n","data/regression-cat-medium-4-Mercedes_Benz_Greener_Manufacturing/READY\n","data/regression-cat-medium-4-Mercedes_Benz_Greener_Manufacturing/X_bin_test.npy\n","data/regression-cat-medium-4-Mercedes_Benz_Greener_Manufacturing/Y_test.npy\n","data/regression-cat-medium-4-Mercedes_Benz_Greener_Manufacturing/Y_train.npy\n","data/regression-num-medium-2-MiamiHousing2016/\n","data/regression-num-medium-2-MiamiHousing2016/X_num_val.npy\n","data/regression-num-medium-2-MiamiHousing2016/Y_val.npy\n","data/regression-num-medium-2-MiamiHousing2016/X_num_train.npy\n","data/regression-num-medium-2-MiamiHousing2016/info.json\n","data/regression-num-medium-2-MiamiHousing2016/READY\n","data/regression-num-medium-2-MiamiHousing2016/X_num_test.npy\n","data/regression-num-medium-2-MiamiHousing2016/Y_test.npy\n","data/regression-num-medium-2-MiamiHousing2016/Y_train.npy\n","data/regression-num-medium-1-Ailerons/\n","data/regression-num-medium-1-Ailerons/X_num_val.npy\n","data/regression-num-medium-1-Ailerons/Y_val.npy\n","data/regression-num-medium-1-Ailerons/X_num_train.npy\n","data/regression-num-medium-1-Ailerons/info.json\n","data/regression-num-medium-1-Ailerons/READY\n","data/regression-num-medium-1-Ailerons/X_num_test.npy\n","data/regression-num-medium-1-Ailerons/Y_test.npy\n","data/regression-num-medium-1-Ailerons/Y_train.npy\n","data/regression-num-medium-0-medical_charges/\n","data/regression-num-medium-0-medical_charges/X_num_val.npy\n","data/regression-num-medium-0-medical_charges/Y_val.npy\n","data/regression-num-medium-0-medical_charges/X_num_train.npy\n","data/regression-num-medium-0-medical_charges/info.json\n","data/regression-num-medium-0-medical_charges/READY\n","data/regression-num-medium-0-medical_charges/X_num_test.npy\n","data/regression-num-medium-0-medical_charges/Y_test.npy\n","data/regression-num-medium-0-medical_charges/Y_train.npy\n","data/classif-num-medium-0-bank-marketing/\n","data/classif-num-medium-0-bank-marketing/X_num_val.npy\n","data/classif-num-medium-0-bank-marketing/Y_val.npy\n","data/classif-num-medium-0-bank-marketing/X_num_train.npy\n","data/classif-num-medium-0-bank-marketing/info.json\n","data/classif-num-medium-0-bank-marketing/READY\n","data/classif-num-medium-0-bank-marketing/X_num_test.npy\n","data/classif-num-medium-0-bank-marketing/Y_test.npy\n","data/classif-num-medium-0-bank-marketing/Y_train.npy\n","data/classif-num-medium-3-wine/\n","data/classif-num-medium-3-wine/X_num_val.npy\n","data/classif-num-medium-3-wine/Y_val.npy\n","data/classif-num-medium-3-wine/X_num_train.npy\n","data/classif-num-medium-3-wine/info.json\n","data/classif-num-medium-3-wine/READY\n","data/classif-num-medium-3-wine/X_num_test.npy\n","data/classif-num-medium-3-wine/Y_test.npy\n","data/classif-num-medium-3-wine/Y_train.npy\n","data/classif-num-medium-2-bank-marketing/\n","data/classif-num-medium-2-bank-marketing/X_num_val.npy\n","data/classif-num-medium-2-bank-marketing/Y_val.npy\n","data/classif-num-medium-2-bank-marketing/X_num_train.npy\n","data/classif-num-medium-2-bank-marketing/info.json\n","data/classif-num-medium-2-bank-marketing/READY\n","data/classif-num-medium-2-bank-marketing/X_num_test.npy\n","data/classif-num-medium-2-bank-marketing/Y_test.npy\n","data/classif-num-medium-2-bank-marketing/Y_train.npy\n","data/classif-num-large-0-jannis/\n","data/classif-num-large-0-jannis/X_num_val.npy\n","data/classif-num-large-0-jannis/Y_val.npy\n","data/classif-num-large-0-jannis/X_num_train.npy\n","data/classif-num-large-0-jannis/info.json\n","data/classif-num-large-0-jannis/READY\n","data/classif-num-large-0-jannis/X_num_test.npy\n","data/classif-num-large-0-jannis/Y_test.npy\n","data/classif-num-large-0-jannis/Y_train.npy\n","data/regression-num-medium-0-houses/\n","data/regression-num-medium-0-houses/X_num_val.npy\n","data/regression-num-medium-0-houses/Y_val.npy\n","data/regression-num-medium-0-houses/X_num_train.npy\n","data/regression-num-medium-0-houses/info.json\n","data/regression-num-medium-0-houses/READY\n","data/regression-num-medium-0-houses/X_num_test.npy\n","data/regression-num-medium-0-houses/Y_test.npy\n","data/regression-num-medium-0-houses/Y_train.npy\n","data/regression-num-large-0-year/\n","data/regression-num-large-0-year/X_num_val.npy\n","data/regression-num-large-0-year/Y_val.npy\n","data/regression-num-large-0-year/X_num_train.npy\n","data/regression-num-large-0-year/info.json\n","data/regression-num-large-0-year/READY\n","data/regression-num-large-0-year/X_num_test.npy\n","data/regression-num-large-0-year/Y_test.npy\n","data/regression-num-large-0-year/Y_train.npy\n","data/classif-cat-medium-1-KDDCup09_upselling/\n","data/classif-cat-medium-1-KDDCup09_upselling/X_cat_val.npy\n","data/classif-cat-medium-1-KDDCup09_upselling/X_num_val.npy\n","data/classif-cat-medium-1-KDDCup09_upselling/Y_val.npy\n","data/classif-cat-medium-1-KDDCup09_upselling/X_bin_val.npy\n","data/classif-cat-medium-1-KDDCup09_upselling/X_num_train.npy\n","data/classif-cat-medium-1-KDDCup09_upselling/X_cat_test.npy\n","data/classif-cat-medium-1-KDDCup09_upselling/X_bin_train.npy\n","data/classif-cat-medium-1-KDDCup09_upselling/X_cat_train.npy\n","data/classif-cat-medium-1-KDDCup09_upselling/info.json\n","data/classif-cat-medium-1-KDDCup09_upselling/READY\n","data/classif-cat-medium-1-KDDCup09_upselling/X_bin_test.npy\n","data/classif-cat-medium-1-KDDCup09_upselling/X_num_test.npy\n","data/classif-cat-medium-1-KDDCup09_upselling/Y_test.npy\n","data/classif-cat-medium-1-KDDCup09_upselling/Y_train.npy\n","data/classif-cat-medium-0-KDDCup09_upselling/\n","data/classif-cat-medium-0-KDDCup09_upselling/X_cat_val.npy\n","data/classif-cat-medium-0-KDDCup09_upselling/X_num_val.npy\n","data/classif-cat-medium-0-KDDCup09_upselling/Y_val.npy\n","data/classif-cat-medium-0-KDDCup09_upselling/X_bin_val.npy\n","data/classif-cat-medium-0-KDDCup09_upselling/X_num_train.npy\n","data/classif-cat-medium-0-KDDCup09_upselling/X_cat_test.npy\n","data/classif-cat-medium-0-KDDCup09_upselling/X_bin_train.npy\n","data/classif-cat-medium-0-KDDCup09_upselling/X_cat_train.npy\n","data/classif-cat-medium-0-KDDCup09_upselling/info.json\n","data/classif-cat-medium-0-KDDCup09_upselling/READY\n","data/classif-cat-medium-0-KDDCup09_upselling/X_bin_test.npy\n","data/classif-cat-medium-0-KDDCup09_upselling/X_num_test.npy\n","data/classif-cat-medium-0-KDDCup09_upselling/Y_test.npy\n","data/classif-cat-medium-0-KDDCup09_upselling/Y_train.npy\n","data/classif-num-large-0-MiniBooNE/\n","data/classif-num-large-0-MiniBooNE/X_num_val.npy\n","data/classif-num-large-0-MiniBooNE/Y_val.npy\n","data/classif-num-large-0-MiniBooNE/X_num_train.npy\n","data/classif-num-large-0-MiniBooNE/info.json\n","data/classif-num-large-0-MiniBooNE/READY\n","data/classif-num-large-0-MiniBooNE/X_num_test.npy\n","data/classif-num-large-0-MiniBooNE/Y_test.npy\n","data/classif-num-large-0-MiniBooNE/Y_train.npy\n","data/regression-num-medium-0-MiamiHousing2016/\n","data/regression-num-medium-0-MiamiHousing2016/X_num_val.npy\n","data/regression-num-medium-0-MiamiHousing2016/Y_val.npy\n","data/regression-num-medium-0-MiamiHousing2016/X_num_train.npy\n","data/regression-num-medium-0-MiamiHousing2016/info.json\n","data/regression-num-medium-0-MiamiHousing2016/READY\n","data/regression-num-medium-0-MiamiHousing2016/X_num_test.npy\n","data/regression-num-medium-0-MiamiHousing2016/Y_test.npy\n","data/regression-num-medium-0-MiamiHousing2016/Y_train.npy\n","data/regression-num-medium-2-Ailerons/\n","data/regression-num-medium-2-Ailerons/X_num_val.npy\n","data/regression-num-medium-2-Ailerons/Y_val.npy\n","data/regression-num-medium-2-Ailerons/X_num_train.npy\n","data/regression-num-medium-2-Ailerons/info.json\n","data/regression-num-medium-2-Ailerons/READY\n","data/regression-num-medium-2-Ailerons/X_num_test.npy\n","data/regression-num-medium-2-Ailerons/Y_test.npy\n","data/regression-num-medium-2-Ailerons/Y_train.npy\n","data/classif-num-medium-0-credit/\n","data/classif-num-medium-0-credit/X_num_val.npy\n","data/classif-num-medium-0-credit/Y_val.npy\n","data/classif-num-medium-0-credit/X_num_train.npy\n","data/classif-num-medium-0-credit/info.json\n","data/classif-num-medium-0-credit/READY\n","data/classif-num-medium-0-credit/X_num_test.npy\n","data/classif-num-medium-0-credit/Y_test.npy\n","data/classif-num-medium-0-credit/Y_train.npy\n","data/classif-num-medium-4-wine/\n","data/classif-num-medium-4-wine/X_num_val.npy\n","data/classif-num-medium-4-wine/Y_val.npy\n","data/classif-num-medium-4-wine/X_num_train.npy\n","data/classif-num-medium-4-wine/info.json\n","data/classif-num-medium-4-wine/READY\n","data/classif-num-medium-4-wine/X_num_test.npy\n","data/classif-num-medium-4-wine/Y_test.npy\n","data/classif-num-medium-4-wine/Y_train.npy\n","data/higgs-small/\n","data/higgs-small/X_num_val.npy\n","data/higgs-small/Y_val.npy\n","data/higgs-small/X_num_train.npy\n","data/higgs-small/info.json\n","data/higgs-small/READY\n","data/higgs-small/X_num_test.npy\n","data/higgs-small/Y_test.npy\n","data/higgs-small/Y_train.npy\n","data/classif-cat-medium-1-compass/\n","data/classif-cat-medium-1-compass/X_cat_val.npy\n","data/classif-cat-medium-1-compass/X_num_val.npy\n","data/classif-cat-medium-1-compass/Y_val.npy\n","data/classif-cat-medium-1-compass/X_bin_val.npy\n","data/classif-cat-medium-1-compass/X_num_train.npy\n","data/classif-cat-medium-1-compass/X_cat_test.npy\n","data/classif-cat-medium-1-compass/X_bin_train.npy\n","data/classif-cat-medium-1-compass/X_cat_train.npy\n","data/classif-cat-medium-1-compass/info.json\n","data/classif-cat-medium-1-compass/READY\n","data/classif-cat-medium-1-compass/X_bin_test.npy\n","data/classif-cat-medium-1-compass/X_num_test.npy\n","data/classif-cat-medium-1-compass/Y_test.npy\n","data/classif-cat-medium-1-compass/Y_train.npy\n","data/classif-cat-medium-0-rl/\n","data/classif-cat-medium-0-rl/X_cat_val.npy\n","data/classif-cat-medium-0-rl/X_num_val.npy\n","data/classif-cat-medium-0-rl/Y_val.npy\n","data/classif-cat-medium-0-rl/X_bin_val.npy\n","data/classif-cat-medium-0-rl/X_num_train.npy\n","data/classif-cat-medium-0-rl/X_cat_test.npy\n","data/classif-cat-medium-0-rl/X_bin_train.npy\n","data/classif-cat-medium-0-rl/X_cat_train.npy\n","data/classif-cat-medium-0-rl/info.json\n","data/classif-cat-medium-0-rl/READY\n","data/classif-cat-medium-0-rl/X_bin_test.npy\n","data/classif-cat-medium-0-rl/X_num_test.npy\n","data/classif-cat-medium-0-rl/Y_test.npy\n","data/classif-cat-medium-0-rl/Y_train.npy\n","data/regression-num-medium-2-cpu_act/\n","data/regression-num-medium-2-cpu_act/X_num_val.npy\n","data/regression-num-medium-2-cpu_act/Y_val.npy\n","data/regression-num-medium-2-cpu_act/X_num_train.npy\n","data/regression-num-medium-2-cpu_act/info.json\n","data/regression-num-medium-2-cpu_act/READY\n","data/regression-num-medium-2-cpu_act/X_num_test.npy\n","data/regression-num-medium-2-cpu_act/Y_test.npy\n","data/regression-num-medium-2-cpu_act/Y_train.npy\n","data/otto/\n","data/otto/X_num_val.npy\n","data/otto/Y_val.npy\n","data/otto/X_num_train.npy\n","data/otto/info.json\n","data/otto/READY\n","data/otto/X_num_test.npy\n","data/otto/Y_test.npy\n","data/otto/Y_train.npy\n","data/regression-cat-medium-0-yprop_4_1/\n","data/regression-cat-medium-0-yprop_4_1/X_num_val.npy\n","data/regression-cat-medium-0-yprop_4_1/Y_val.npy\n","data/regression-cat-medium-0-yprop_4_1/X_bin_val.npy\n","data/regression-cat-medium-0-yprop_4_1/X_num_train.npy\n","data/regression-cat-medium-0-yprop_4_1/X_bin_train.npy\n","data/regression-cat-medium-0-yprop_4_1/info.json\n","data/regression-cat-medium-0-yprop_4_1/READY\n","data/regression-cat-medium-0-yprop_4_1/X_bin_test.npy\n","data/regression-cat-medium-0-yprop_4_1/X_num_test.npy\n","data/regression-cat-medium-0-yprop_4_1/Y_test.npy\n","data/regression-cat-medium-0-yprop_4_1/Y_train.npy\n","data/classif-cat-large-0-covertype/\n","data/classif-cat-large-0-covertype/X_num_val.npy\n","data/classif-cat-large-0-covertype/Y_val.npy\n","data/classif-cat-large-0-covertype/X_bin_val.npy\n","data/classif-cat-large-0-covertype/X_num_train.npy\n","data/classif-cat-large-0-covertype/X_bin_train.npy\n","data/classif-cat-large-0-covertype/info.json\n","data/classif-cat-large-0-covertype/READY\n","data/classif-cat-large-0-covertype/X_bin_test.npy\n","data/classif-cat-large-0-covertype/X_num_test.npy\n","data/classif-cat-large-0-covertype/Y_test.npy\n","data/classif-cat-large-0-covertype/Y_train.npy\n","data/regression-cat-medium-1-Bike_Sharing_Demand/\n","data/regression-cat-medium-1-Bike_Sharing_Demand/X_cat_val.npy\n","data/regression-cat-medium-1-Bike_Sharing_Demand/X_num_val.npy\n","data/regression-cat-medium-1-Bike_Sharing_Demand/Y_val.npy\n","data/regression-cat-medium-1-Bike_Sharing_Demand/X_bin_val.npy\n","data/regression-cat-medium-1-Bike_Sharing_Demand/X_num_train.npy\n","data/regression-cat-medium-1-Bike_Sharing_Demand/X_cat_test.npy\n","data/regression-cat-medium-1-Bike_Sharing_Demand/X_bin_train.npy\n","data/regression-cat-medium-1-Bike_Sharing_Demand/X_cat_train.npy\n","data/regression-cat-medium-1-Bike_Sharing_Demand/info.json\n","data/regression-cat-medium-1-Bike_Sharing_Demand/READY\n","data/regression-cat-medium-1-Bike_Sharing_Demand/X_bin_test.npy\n","data/regression-cat-medium-1-Bike_Sharing_Demand/X_num_test.npy\n","data/regression-cat-medium-1-Bike_Sharing_Demand/Y_test.npy\n","data/regression-cat-medium-1-Bike_Sharing_Demand/Y_train.npy\n","data/classif-cat-medium-0-electricity/\n","data/classif-cat-medium-0-electricity/X_cat_val.npy\n","data/classif-cat-medium-0-electricity/X_num_val.npy\n","data/classif-cat-medium-0-electricity/Y_val.npy\n","data/classif-cat-medium-0-electricity/X_num_train.npy\n","data/classif-cat-medium-0-electricity/X_cat_test.npy\n","data/classif-cat-medium-0-electricity/X_cat_train.npy\n","data/classif-cat-medium-0-electricity/info.json\n","data/classif-cat-medium-0-electricity/READY\n","data/classif-cat-medium-0-electricity/X_num_test.npy\n","data/classif-cat-medium-0-electricity/Y_test.npy\n","data/classif-cat-medium-0-electricity/Y_train.npy\n","data/regression-cat-medium-2-visualizing_soil/\n","data/regression-cat-medium-2-visualizing_soil/X_num_val.npy\n","data/regression-cat-medium-2-visualizing_soil/Y_val.npy\n","data/regression-cat-medium-2-visualizing_soil/X_bin_val.npy\n","data/regression-cat-medium-2-visualizing_soil/X_num_train.npy\n","data/regression-cat-medium-2-visualizing_soil/X_bin_train.npy\n","data/regression-cat-medium-2-visualizing_soil/info.json\n","data/regression-cat-medium-2-visualizing_soil/READY\n","data/regression-cat-medium-2-visualizing_soil/X_bin_test.npy\n","data/regression-cat-medium-2-visualizing_soil/X_num_test.npy\n","data/regression-cat-medium-2-visualizing_soil/Y_test.npy\n","data/regression-cat-medium-2-visualizing_soil/Y_train.npy\n","data/regression-cat-medium-1-yprop_4_1/\n","data/regression-cat-medium-1-yprop_4_1/X_num_val.npy\n","data/regression-cat-medium-1-yprop_4_1/Y_val.npy\n","data/regression-cat-medium-1-yprop_4_1/X_bin_val.npy\n","data/regression-cat-medium-1-yprop_4_1/X_num_train.npy\n","data/regression-cat-medium-1-yprop_4_1/X_bin_train.npy\n","data/regression-cat-medium-1-yprop_4_1/info.json\n","data/regression-cat-medium-1-yprop_4_1/READY\n","data/regression-cat-medium-1-yprop_4_1/X_bin_test.npy\n","data/regression-cat-medium-1-yprop_4_1/X_num_test.npy\n","data/regression-cat-medium-1-yprop_4_1/Y_test.npy\n","data/regression-cat-medium-1-yprop_4_1/Y_train.npy\n","data/classif-num-medium-1-bank-marketing/\n","data/classif-num-medium-1-bank-marketing/X_num_val.npy\n","data/classif-num-medium-1-bank-marketing/Y_val.npy\n","data/classif-num-medium-1-bank-marketing/X_num_train.npy\n","data/classif-num-medium-1-bank-marketing/info.json\n","data/classif-num-medium-1-bank-marketing/READY\n","data/classif-num-medium-1-bank-marketing/X_num_test.npy\n","data/classif-num-medium-1-bank-marketing/Y_test.npy\n","data/classif-num-medium-1-bank-marketing/Y_train.npy\n","data/classif-num-medium-1-credit/\n","data/classif-num-medium-1-credit/X_num_val.npy\n","data/classif-num-medium-1-credit/Y_val.npy\n","data/classif-num-medium-1-credit/X_num_train.npy\n","data/classif-num-medium-1-credit/info.json\n","data/classif-num-medium-1-credit/READY\n","data/classif-num-medium-1-credit/X_num_test.npy\n","data/classif-num-medium-1-credit/Y_test.npy\n","data/classif-num-medium-1-credit/Y_train.npy\n"]}]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-glTe-NrxA3S","executionInfo":{"status":"ok","timestamp":1728980961924,"user_tz":-480,"elapsed":4252,"user":{"displayName":"Jonindo Pasaribu","userId":"10958990953097471082"}},"outputId":"8e45ddd3-b9b1-4ab3-ebca-ce7aeb9a98ef"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pytorch-tabnet\n","  Downloading pytorch_tabnet-4.1.0-py3-none-any.whl.metadata (15 kB)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from pytorch-tabnet) (1.26.4)\n","Requirement already satisfied: scikit_learn>0.21 in /usr/local/lib/python3.10/dist-packages (from pytorch-tabnet) (1.5.2)\n","Requirement already satisfied: scipy>1.4 in /usr/local/lib/python3.10/dist-packages (from pytorch-tabnet) (1.13.1)\n","Requirement already satisfied: torch>=1.3 in /usr/local/lib/python3.10/dist-packages (from pytorch-tabnet) (2.4.1+cu121)\n","Requirement already satisfied: tqdm>=4.36 in /usr/local/lib/python3.10/dist-packages (from pytorch-tabnet) (4.66.5)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit_learn>0.21->pytorch-tabnet) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit_learn>0.21->pytorch-tabnet) (3.5.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (3.16.1)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (1.13.3)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (3.4)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (2024.6.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.3->pytorch-tabnet) (3.0.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.3->pytorch-tabnet) (1.3.0)\n","Downloading pytorch_tabnet-4.1.0-py3-none-any.whl (44 kB)\n","\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/44.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.5/44.5 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: pytorch-tabnet\n","Successfully installed pytorch-tabnet-4.1.0\n"]}],"source":["!pip install pytorch-tabnet"]},{"cell_type":"code","source":["!pip install optuna"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T3kebgsowkp0","executionInfo":{"status":"ok","timestamp":1728980964366,"user_tz":-480,"elapsed":2447,"user":{"displayName":"Jonindo Pasaribu","userId":"10958990953097471082"}},"outputId":"798db65a-98bd-45be-a57a-e74208a83bac"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting optuna\n","  Downloading optuna-4.0.0-py3-none-any.whl.metadata (16 kB)\n","Collecting alembic>=1.5.0 (from optuna)\n","  Downloading alembic-1.13.3-py3-none-any.whl.metadata (7.4 kB)\n","Collecting colorlog (from optuna)\n","  Downloading colorlog-6.8.2-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (24.1)\n","Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.35)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.66.5)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0.2)\n","Collecting Mako (from alembic>=1.5.0->optuna)\n","  Downloading Mako-1.3.5-py3-none-any.whl.metadata (2.9 kB)\n","Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.12.2)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna) (3.1.1)\n","Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna) (3.0.1)\n","Downloading optuna-4.0.0-py3-none-any.whl (362 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m362.8/362.8 kB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading alembic-1.13.3-py3-none-any.whl (233 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.2/233.2 kB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading colorlog-6.8.2-py3-none-any.whl (11 kB)\n","Downloading Mako-1.3.5-py3-none-any.whl (78 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: Mako, colorlog, alembic, optuna\n","Successfully installed Mako-1.3.5 alembic-1.13.3 colorlog-6.8.2 optuna-4.0.0\n"]}]},{"cell_type":"code","source":["!pip install psutil"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1AlZ_9btlf9J","executionInfo":{"status":"ok","timestamp":1728980966949,"user_tz":-480,"elapsed":2584,"user":{"displayName":"Jonindo Pasaribu","userId":"10958990953097471082"}},"outputId":"19f433cf-a76a-4ef8-a251-b6e2d755ccab"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (5.9.5)\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import optuna\n","import torch.optim\n","import psutil\n","\n","from pytorch_tabnet.tab_model import TabNetRegressor\n","from sklearn.preprocessing import QuantileTransformer"],"metadata":{"id":"085aiY1dzlHG","executionInfo":{"status":"ok","timestamp":1728980971931,"user_tz":-480,"elapsed":4985,"user":{"displayName":"Jonindo Pasaribu","userId":"10958990953097471082"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["tnr = TabNetRegressor()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pr7k2hel51eb","executionInfo":{"status":"ok","timestamp":1728980971931,"user_tz":-480,"elapsed":7,"user":{"displayName":"Jonindo Pasaribu","userId":"10958990953097471082"}},"outputId":"364584c4-f058-4026-e516-dd9d3716d5bb"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]}]},{"cell_type":"code","source":["X_train = np.load('/content/data/regression-num-medium-0-Ailerons/X_num_train.npy')\n","y_train = np.load('/content/data/regression-num-medium-0-Ailerons/Y_train.npy').reshape(-1, 1)\n","\n","X_valid = np.load('/content/data/regression-num-medium-0-Ailerons/X_num_val.npy')\n","y_valid = np.load('/content/data/regression-num-medium-0-Ailerons/Y_val.npy').reshape(-1, 1)\n","\n","X_test = np.load('/content/data/regression-num-medium-0-Ailerons/X_num_test.npy')\n","y_test = np.load('/content/data/regression-num-medium-0-Ailerons/Y_test.npy').reshape(-1, 1)"],"metadata":{"id":"ml0RPc_76dZx","executionInfo":{"status":"ok","timestamp":1728980971931,"user_tz":-480,"elapsed":6,"user":{"displayName":"Jonindo Pasaribu","userId":"10958990953097471082"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["normalizer = QuantileTransformer(\n","            output_distribution='normal',\n","            n_quantiles=max(min(X_train.shape[0] // 30, 1000), 10),\n","            subsample=1_000_000_000,\n","            )\n","normalizer.fit_transform(X_train)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"19PUhYavmHsh","executionInfo":{"status":"ok","timestamp":1728980971931,"user_tz":-480,"elapsed":6,"user":{"displayName":"Jonindo Pasaribu","userId":"10958990953097471082"}},"outputId":"9d012cac-d7a0-42a0-cded-a30b5b5b8ba7"},"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[-1.6914173 ,  1.2977961 ,  0.6379428 , ...,  0.05503214,\n","         0.26635137, -0.24605119],\n","       [ 0.49931866,  0.7170322 ,  0.5998753 , ...,  0.05503214,\n","        -0.67695796, -1.0968035 ],\n","       [-0.31967288, -0.29906526,  1.2449065 , ...,  0.05503214,\n","         0.784747  ,  0.7375054 ],\n","       ...,\n","       [-0.9446696 ,  2.8350697 , -0.34041727, ...,  0.05503214,\n","         0.784747  ,  0.8282596 ],\n","       [ 0.7776394 ,  0.5262046 , -1.9667383 , ...,  0.05503214,\n","         1.5453691 ,  1.5855004 ],\n","       [ 0.82457423, -1.2887294 , -0.16178727, ...,  0.05503214,\n","         1.0685635 ,  0.90253806]], dtype=float32)"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["#Baseline\n","tnr.fit(\n","    X_train=X_train, y_train=y_train,\n","    eval_set=[(X_train, y_train), (X_valid, y_valid)],\n","    eval_name=['train', 'valid'],\n","    eval_metric=['mae', 'rmse'],\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dmadZ12j7CO_","executionInfo":{"status":"ok","timestamp":1728981000562,"user_tz":-480,"elapsed":28635,"user":{"displayName":"Jonindo Pasaribu","userId":"10958990953097471082"}},"outputId":"b25c91cd-0935-4b13-9da0-e22dbb23be69"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 0.21079 | train_mae: 0.1153699979186058| train_rmse: 0.19348999857902527| valid_mae: 0.11743000149726868| valid_rmse: 0.27685999870300293|  0:00:02s\n","epoch 1  | loss: 0.0235  | train_mae: 0.028759999200701714| train_rmse: 0.059700001031160355| valid_mae: 0.028289999812841415| valid_rmse: 0.05443999916315079|  0:00:03s\n","epoch 2  | loss: 0.00597 | train_mae: 0.02199999988079071| train_rmse: 0.07370000332593918| valid_mae: 0.02047000080347061| valid_rmse: 0.0767500028014183|  0:00:03s\n","epoch 3  | loss: 0.00262 | train_mae: 0.011909999884665012| train_rmse: 0.0771000012755394| valid_mae: 0.009739999659359455| valid_rmse: 0.06751000136137009|  0:00:04s\n","epoch 4  | loss: 0.00166 | train_mae: 0.0031300000846385956| train_rmse: 0.007000000216066837| valid_mae: 0.0028099999763071537| valid_rmse: 0.0055599999614059925|  0:00:04s\n","epoch 5  | loss: 0.00124 | train_mae: 0.0017099999822676182| train_rmse: 0.0038499999791383743| valid_mae: 0.0014400000218302011| valid_rmse: 0.0027099999133497477|  0:00:05s\n","epoch 6  | loss: 0.00103 | train_mae: 0.001820000004954636| train_rmse: 0.0040699997916817665| valid_mae: 0.0017099999822676182| valid_rmse: 0.003280000062659383|  0:00:06s\n","epoch 7  | loss: 0.00092 | train_mae: 0.0014700000174343586| train_rmse: 0.002899999963119626| valid_mae: 0.0013800000306218863| valid_rmse: 0.0026400000788271427|  0:00:07s\n","epoch 8  | loss: 0.00087 | train_mae: 0.001230000052601099| train_rmse: 0.0021299999207258224| valid_mae: 0.0011399999493733048| valid_rmse: 0.0018100000452250242|  0:00:07s\n","epoch 9  | loss: 0.00083 | train_mae: 0.0010600000387057662| train_rmse: 0.0017399999778717756| valid_mae: 0.0009899999713525176| valid_rmse: 0.001449999981559813|  0:00:08s\n","epoch 10 | loss: 0.00081 | train_mae: 0.0008500000112690032| train_rmse: 0.0012600000482052565| valid_mae: 0.0007999999797903001| valid_rmse: 0.0011399999493733048|  0:00:09s\n","epoch 11 | loss: 0.00079 | train_mae: 0.0006600000197067857| train_rmse: 0.001019999966956675| valid_mae: 0.0006099999882280827| valid_rmse: 0.0008900000248104334|  0:00:09s\n","epoch 12 | loss: 0.00077 | train_mae: 0.0006799999973736703| train_rmse: 0.001069999998435378| valid_mae: 0.0006399999838322401| valid_rmse: 0.0009399999980814755|  0:00:10s\n","epoch 13 | loss: 0.00075 | train_mae: 0.000699999975040555| train_rmse: 0.0010300000431016088| valid_mae: 0.0006699999794363976| valid_rmse: 0.0009399999980814755|  0:00:11s\n","epoch 14 | loss: 0.00074 | train_mae: 0.0006500000017695129| train_rmse: 0.0009299999801442027| valid_mae: 0.0006200000061653554| valid_rmse: 0.0008399999933317304|  0:00:11s\n","epoch 15 | loss: 0.00072 | train_mae: 0.0006799999973736703| train_rmse: 0.0009299999801442027| valid_mae: 0.0006399999838322401| valid_rmse: 0.000859999970998615|  0:00:12s\n","epoch 16 | loss: 0.00071 | train_mae: 0.0007099999929778278| train_rmse: 0.0009299999801442027| valid_mae: 0.0006799999973736703| valid_rmse: 0.0008500000112690032|  0:00:13s\n","epoch 17 | loss: 0.0007  | train_mae: 0.0007300000288523734| train_rmse: 0.0009200000204145908| valid_mae: 0.0007099999929778278| valid_rmse: 0.000859999970998615|  0:00:13s\n","epoch 18 | loss: 0.00069 | train_mae: 0.0006300000241026282| train_rmse: 0.0008399999933317304| valid_mae: 0.0006000000284984708| valid_rmse: 0.0007900000200606883|  0:00:14s\n","epoch 19 | loss: 0.00067 | train_mae: 0.0006500000017695129| train_rmse: 0.0008299999753944576| valid_mae: 0.0006200000061653554| valid_rmse: 0.0007900000200606883|  0:00:15s\n","epoch 20 | loss: 0.00066 | train_mae: 0.0007300000288523734| train_rmse: 0.0008699999889358878| valid_mae: 0.000699999975040555| valid_rmse: 0.0008299999753944576|  0:00:16s\n","epoch 21 | loss: 0.00065 | train_mae: 0.0006399999838322401| train_rmse: 0.0008200000156648457| valid_mae: 0.0006099999882280827| valid_rmse: 0.0007900000200606883|  0:00:16s\n","epoch 22 | loss: 0.00064 | train_mae: 0.0006500000017695129| train_rmse: 0.0008099999977275729| valid_mae: 0.0006200000061653554| valid_rmse: 0.0007800000021234155|  0:00:17s\n","epoch 23 | loss: 0.00063 | train_mae: 0.0007300000288523734| train_rmse: 0.000859999970998615| valid_mae: 0.0007099999929778278| valid_rmse: 0.0008299999753944576|  0:00:18s\n","epoch 24 | loss: 0.00062 | train_mae: 0.000699999975040555| train_rmse: 0.0008399999933317304| valid_mae: 0.0006799999973736703| valid_rmse: 0.0008099999977275729|  0:00:19s\n","epoch 25 | loss: 0.00061 | train_mae: 0.0006799999973736703| train_rmse: 0.0008299999753944576| valid_mae: 0.0006500000017695129| valid_rmse: 0.0007900000200606883|  0:00:20s\n","epoch 26 | loss: 0.00059 | train_mae: 0.0006900000153109431| train_rmse: 0.0008200000156648457| valid_mae: 0.0006699999794363976| valid_rmse: 0.0007900000200606883|  0:00:20s\n","epoch 27 | loss: 0.00059 | train_mae: 0.0006900000153109431| train_rmse: 0.0008500000112690032| valid_mae: 0.0006600000197067857| valid_rmse: 0.0008099999977275729|  0:00:21s\n","epoch 28 | loss: 0.00058 | train_mae: 0.0006699999794363976| train_rmse: 0.0008299999753944576| valid_mae: 0.0006500000017695129| valid_rmse: 0.0007900000200606883|  0:00:22s\n","epoch 29 | loss: 0.00057 | train_mae: 0.0006799999973736703| train_rmse: 0.0008299999753944576| valid_mae: 0.0006600000197067857| valid_rmse: 0.0007900000200606883|  0:00:22s\n","epoch 30 | loss: 0.00056 | train_mae: 0.0007099999929778278| train_rmse: 0.0008500000112690032| valid_mae: 0.0006900000153109431| valid_rmse: 0.0008099999977275729|  0:00:23s\n","epoch 31 | loss: 0.00055 | train_mae: 0.0006799999973736703| train_rmse: 0.0008299999753944576| valid_mae: 0.0006600000197067857| valid_rmse: 0.0007900000200606883|  0:00:24s\n","epoch 32 | loss: 0.00054 | train_mae: 0.0007099999929778278| train_rmse: 0.0008699999889358878| valid_mae: 0.0006799999973736703| valid_rmse: 0.0008299999753944576|  0:00:25s\n","\n","Early stopping occurred at epoch 32 with best_epoch = 22 and best_valid_rmse = 0.0007800000021234155\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n"]}]},{"cell_type":"code","source":["def objective(trial):\n","    params = {\n","        'n_d': trial.suggest_int('n_d', 8, 64),\n","        'n_steps': trial.suggest_int('n_steps', 3, 10),\n","        'gamma': trial.suggest_float('gamma', 1.0, 2.0),\n","        'n_independent': trial.suggest_int('n_independent', 1, 5),\n","        'n_shared': trial.suggest_int('n_shared', 1, 5),\n","        'momentum': trial.suggest_float('momentum', 0.01, 0.4),\n","    }\n","\n","    model = TabNetRegressor(**params, n_a=params['n_d'])\n","    model.fit(X_train, y_train, eval_set=[(X_valid, y_valid)], patience=10)\n","\n","    # Evaluate model performance\n","    score = model.best_cost  # or any other metric\n","\n","    return score\n","\n","study = optuna.create_study(direction='minimize')\n","study.optimize(objective, n_trials=100)\n","\n","best_params = study.best_params"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rKJAw0W-w7sc","executionInfo":{"status":"ok","timestamp":1728987116112,"user_tz":-480,"elapsed":6115558,"user":{"displayName":"Jonindo Pasaribu","userId":"10958990953097471082"}},"outputId":"1b7bbb1d-e718-4190-ca9e-e9625bb2421d"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stderr","text":["[I 2024-10-15 08:29:59,835] A new study created in memory with name: no-name-5460e492-9117-4c18-b92d-a3cac3984662\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 7.09352 | val_0_mse: 6.501930236816406|  0:00:01s\n","epoch 1  | loss: 4.34854 | val_0_mse: 8.90542984008789|  0:00:03s\n","epoch 2  | loss: 9.11763 | val_0_mse: 14.728400230407715|  0:00:04s\n","epoch 3  | loss: 2.97799 | val_0_mse: 0.38155001401901245|  0:00:06s\n","epoch 4  | loss: 1.11328 | val_0_mse: 0.5538700222969055|  0:00:07s\n","epoch 5  | loss: 1.83796 | val_0_mse: 0.24327999353408813|  0:00:09s\n","epoch 6  | loss: 1.52063 | val_0_mse: 0.015189999714493752|  0:00:11s\n","epoch 7  | loss: 0.24386 | val_0_mse: 0.011189999990165234|  0:00:12s\n","epoch 8  | loss: 0.04717 | val_0_mse: 0.01671000011265278|  0:00:14s\n","epoch 9  | loss: 0.03192 | val_0_mse: 0.015320000238716602|  0:00:15s\n","epoch 10 | loss: 0.01232 | val_0_mse: 0.0013699999544769526|  0:00:17s\n","epoch 11 | loss: 0.01024 | val_0_mse: 0.0010000000474974513|  0:00:19s\n","epoch 12 | loss: 0.00531 | val_0_mse: 0.001069999998435378|  0:00:20s\n","epoch 13 | loss: 0.00271 | val_0_mse: 0.00023999999393709004|  0:00:21s\n","epoch 14 | loss: 0.00182 | val_0_mse: 0.00014000000373926014|  0:00:23s\n","epoch 15 | loss: 0.00113 | val_0_mse: 0.00019999999494757503|  0:00:24s\n","epoch 16 | loss: 0.00086 | val_0_mse: 0.0002300000051036477|  0:00:26s\n","epoch 17 | loss: 0.00077 | val_0_mse: 0.00013000000035390258|  0:00:27s\n","epoch 18 | loss: 0.00063 | val_0_mse: 7.000000186963007e-05|  0:00:29s\n","epoch 19 | loss: 0.00054 | val_0_mse: 0.00011000000085914508|  0:00:30s\n","epoch 20 | loss: 0.00052 | val_0_mse: 5.999999848427251e-05|  0:00:32s\n","epoch 21 | loss: 0.00047 | val_0_mse: 3.9999998989515007e-05|  0:00:33s\n","epoch 22 | loss: 0.00045 | val_0_mse: 4.999999873689376e-05|  0:00:35s\n","epoch 23 | loss: 0.00047 | val_0_mse: 4.999999873689376e-05|  0:00:36s\n","epoch 24 | loss: 0.00047 | val_0_mse: 3.9999998989515007e-05|  0:00:38s\n","epoch 25 | loss: 0.00041 | val_0_mse: 3.9999998989515007e-05|  0:00:39s\n","epoch 26 | loss: 0.00038 | val_0_mse: 2.9999999242136255e-05|  0:00:40s\n","epoch 27 | loss: 0.00037 | val_0_mse: 4.999999873689376e-05|  0:00:42s\n","epoch 28 | loss: 0.00036 | val_0_mse: 2.9999999242136255e-05|  0:00:43s\n","epoch 29 | loss: 0.00035 | val_0_mse: 3.9999998989515007e-05|  0:00:45s\n","epoch 30 | loss: 0.00034 | val_0_mse: 3.9999998989515007e-05|  0:00:46s\n","epoch 31 | loss: 0.00034 | val_0_mse: 1.9999999494757503e-05|  0:00:48s\n","epoch 32 | loss: 0.00033 | val_0_mse: 2.9999999242136255e-05|  0:00:49s\n","epoch 33 | loss: 0.00033 | val_0_mse: 1.9999999494757503e-05|  0:00:51s\n","epoch 34 | loss: 0.00033 | val_0_mse: 1.9999999494757503e-05|  0:00:52s\n","epoch 35 | loss: 0.00031 | val_0_mse: 1.9999999494757503e-05|  0:00:54s\n","epoch 36 | loss: 0.00031 | val_0_mse: 1.9999999494757503e-05|  0:00:55s\n","epoch 37 | loss: 0.00031 | val_0_mse: 9.999999747378752e-06|  0:00:57s\n","epoch 38 | loss: 0.00031 | val_0_mse: 2.9999999242136255e-05|  0:00:58s\n","epoch 39 | loss: 0.00029 | val_0_mse: 1.9999999494757503e-05|  0:01:00s\n","epoch 40 | loss: 0.00031 | val_0_mse: 2.9999999242136255e-05|  0:01:01s\n","epoch 41 | loss: 0.00037 | val_0_mse: 9.999999747378752e-06|  0:01:02s\n","epoch 42 | loss: 0.00033 | val_0_mse: 1.9999999494757503e-05|  0:01:04s\n","epoch 43 | loss: 0.00031 | val_0_mse: 9.999999747378752e-06|  0:01:05s\n","epoch 44 | loss: 0.00028 | val_0_mse: 9.999999747378752e-06|  0:01:07s\n","epoch 45 | loss: 0.00027 | val_0_mse: 9.999999747378752e-06|  0:01:08s\n","epoch 46 | loss: 0.00027 | val_0_mse: 9.999999747378752e-06|  0:01:10s\n","epoch 47 | loss: 0.00027 | val_0_mse: 9.999999747378752e-06|  0:01:11s\n","epoch 48 | loss: 0.00026 | val_0_mse: 9.999999747378752e-06|  0:01:13s\n","epoch 49 | loss: 0.00026 | val_0_mse: 9.999999747378752e-06|  0:01:14s\n","epoch 50 | loss: 0.00026 | val_0_mse: 9.999999747378752e-06|  0:01:16s\n","epoch 51 | loss: 0.00027 | val_0_mse: 9.999999747378752e-06|  0:01:17s\n","epoch 52 | loss: 0.00025 | val_0_mse: 9.999999747378752e-06|  0:01:19s\n","epoch 53 | loss: 0.00025 | val_0_mse: 9.999999747378752e-06|  0:01:20s\n","epoch 54 | loss: 0.00026 | val_0_mse: 9.999999747378752e-06|  0:01:21s\n","epoch 55 | loss: 0.00025 | val_0_mse: 9.999999747378752e-06|  0:01:23s\n","epoch 56 | loss: 0.00024 | val_0_mse: 1.9999999494757503e-05|  0:01:24s\n","epoch 57 | loss: 0.00024 | val_0_mse: 9.999999747378752e-06|  0:01:26s\n","epoch 58 | loss: 0.00024 | val_0_mse: 0.0     |  0:01:27s\n","epoch 59 | loss: 0.00024 | val_0_mse: 9.999999747378752e-06|  0:01:29s\n","epoch 60 | loss: 0.00024 | val_0_mse: 9.999999747378752e-06|  0:01:30s\n","epoch 61 | loss: 0.00024 | val_0_mse: 9.999999747378752e-06|  0:01:31s\n","epoch 62 | loss: 0.00024 | val_0_mse: 9.999999747378752e-06|  0:01:33s\n","epoch 63 | loss: 0.00023 | val_0_mse: 0.0     |  0:01:34s\n","epoch 64 | loss: 0.00023 | val_0_mse: 9.999999747378752e-06|  0:01:36s\n","epoch 65 | loss: 0.00023 | val_0_mse: 9.999999747378752e-06|  0:01:37s\n","epoch 66 | loss: 0.00023 | val_0_mse: 9.999999747378752e-06|  0:01:39s\n","epoch 67 | loss: 0.00023 | val_0_mse: 9.999999747378752e-06|  0:01:40s\n","epoch 68 | loss: 0.00023 | val_0_mse: 0.0     |  0:01:42s\n","\n","Early stopping occurred at epoch 68 with best_epoch = 58 and best_val_0_mse = 0.0\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 08:31:42,692] Trial 0 finished with value: 4.379454367153812e-06 and parameters: {'n_d': 51, 'n_steps': 8, 'gamma': 1.4232258267650426, 'n_independent': 5, 'n_shared': 3, 'momentum': 0.22095787388539703}. Best is trial 0 with value: 4.379454367153812e-06.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 6.97577 | val_0_mse: 4.5311198234558105|  0:00:01s\n","epoch 1  | loss: 2.81298 | val_0_mse: 1.0567799806594849|  0:00:02s\n","epoch 2  | loss: 0.80108 | val_0_mse: 0.045049998909235|  0:00:03s\n","epoch 3  | loss: 0.68836 | val_0_mse: 0.20886999368667603|  0:00:04s\n","epoch 4  | loss: 0.73545 | val_0_mse: 0.17124000191688538|  0:00:05s\n","epoch 5  | loss: 0.29142 | val_0_mse: 0.0842600017786026|  0:00:06s\n","epoch 6  | loss: 0.18101 | val_0_mse: 0.07124999910593033|  0:00:07s\n","epoch 7  | loss: 0.57159 | val_0_mse: 1.0020999908447266|  0:00:08s\n","epoch 8  | loss: 0.13956 | val_0_mse: 0.06532999873161316|  0:00:09s\n","epoch 9  | loss: 0.01558 | val_0_mse: 0.006680000107735395|  0:00:10s\n","epoch 10 | loss: 0.0064  | val_0_mse: 0.0021100000012665987|  0:00:11s\n","epoch 11 | loss: 0.00548 | val_0_mse: 0.0010400000028312206|  0:00:12s\n","epoch 12 | loss: 0.00412 | val_0_mse: 0.0016700000269338489|  0:00:14s\n","epoch 13 | loss: 0.00324 | val_0_mse: 0.0012600000482052565|  0:00:15s\n","epoch 14 | loss: 0.00302 | val_0_mse: 0.0006399999838322401|  0:00:16s\n","epoch 15 | loss: 0.00207 | val_0_mse: 0.00044999999227002263|  0:00:17s\n","epoch 16 | loss: 0.00133 | val_0_mse: 0.0006799999973736703|  0:00:18s\n","epoch 17 | loss: 0.00107 | val_0_mse: 0.0004400000034365803|  0:00:19s\n","epoch 18 | loss: 0.00091 | val_0_mse: 0.0007600000244565308|  0:00:20s\n","epoch 19 | loss: 0.00074 | val_0_mse: 0.0009399999980814755|  0:00:21s\n","epoch 20 | loss: 0.00073 | val_0_mse: 0.0006000000284984708|  0:00:22s\n","epoch 21 | loss: 0.00066 | val_0_mse: 0.0007800000021234155|  0:00:23s\n","epoch 22 | loss: 0.0006  | val_0_mse: 0.0011099999537691474|  0:00:24s\n","epoch 23 | loss: 0.00061 | val_0_mse: 0.0006399999838322401|  0:00:25s\n","epoch 24 | loss: 0.00059 | val_0_mse: 0.0004900000058114529|  0:00:26s\n","epoch 25 | loss: 0.00054 | val_0_mse: 0.00044999999227002263|  0:00:27s\n","epoch 26 | loss: 0.00057 | val_0_mse: 0.0001900000061141327|  0:00:28s\n","epoch 27 | loss: 0.0005  | val_0_mse: 0.0005600000149570405|  0:00:29s\n","epoch 28 | loss: 0.00049 | val_0_mse: 0.00011999999696854502|  0:00:30s\n","epoch 29 | loss: 0.00047 | val_0_mse: 0.00022000000171829015|  0:00:31s\n","epoch 30 | loss: 0.00045 | val_0_mse: 0.0001500000071246177|  0:00:32s\n","epoch 31 | loss: 0.00043 | val_0_mse: 0.00023999999393709004|  0:00:33s\n","epoch 32 | loss: 0.00041 | val_0_mse: 0.00022000000171829015|  0:00:35s\n","epoch 33 | loss: 0.00041 | val_0_mse: 0.0003000000142492354|  0:00:36s\n","epoch 34 | loss: 0.0004  | val_0_mse: 0.0001500000071246177|  0:00:37s\n","epoch 35 | loss: 0.00039 | val_0_mse: 0.0001900000061141327|  0:00:38s\n","epoch 36 | loss: 0.0004  | val_0_mse: 0.0008900000248104334|  0:00:39s\n","epoch 37 | loss: 0.00037 | val_0_mse: 0.00015999999595806003|  0:00:40s\n","epoch 38 | loss: 0.00038 | val_0_mse: 0.0003499999875202775|  0:00:41s\n","\n","Early stopping occurred at epoch 38 with best_epoch = 28 and best_val_0_mse = 0.00011999999696854502\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 08:32:24,565] Trial 1 finished with value: 0.00011966858437517658 and parameters: {'n_d': 27, 'n_steps': 7, 'gamma': 1.3453073567903164, 'n_independent': 3, 'n_shared': 3, 'momentum': 0.231788841117413}. Best is trial 0 with value: 4.379454367153812e-06.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 5.65932 | val_0_mse: 354.0494384765625|  0:00:01s\n","epoch 1  | loss: 3.56691 | val_0_mse: 1.6294699907302856|  0:00:02s\n","epoch 2  | loss: 5.27951 | val_0_mse: 0.7482200264930725|  0:00:04s\n","epoch 3  | loss: 1.76685 | val_0_mse: 2.9644100666046143|  0:00:05s\n","epoch 4  | loss: 1.58538 | val_0_mse: 10.880069732666016|  0:00:06s\n","epoch 5  | loss: 0.49644 | val_0_mse: 0.002580000087618828|  0:00:07s\n","epoch 6  | loss: 0.34246 | val_0_mse: 0.0002500000118743628|  0:00:09s\n","epoch 7  | loss: 0.32293 | val_0_mse: 0.00418000016361475|  0:00:10s\n","epoch 8  | loss: 0.09662 | val_0_mse: 0.004029999952763319|  0:00:11s\n","epoch 9  | loss: 0.01407 | val_0_mse: 0.0006399999838322401|  0:00:12s\n","epoch 10 | loss: 0.00971 | val_0_mse: 0.0003600000054575503|  0:00:14s\n","epoch 11 | loss: 0.01166 | val_0_mse: 0.0036100000143051147|  0:00:15s\n","epoch 12 | loss: 0.01019 | val_0_mse: 0.00033999999868683517|  0:00:16s\n","epoch 13 | loss: 0.0058  | val_0_mse: 0.000859999970998615|  0:00:17s\n","epoch 14 | loss: 0.00555 | val_0_mse: 0.0005799999926239252|  0:00:19s\n","epoch 15 | loss: 0.00254 | val_0_mse: 0.0002500000118743628|  0:00:20s\n","epoch 16 | loss: 0.00177 | val_0_mse: 0.00041000000783242285|  0:00:21s\n","epoch 17 | loss: 0.00164 | val_0_mse: 0.0002899999963119626|  0:00:23s\n","epoch 18 | loss: 0.00151 | val_0_mse: 0.00011999999696854502|  0:00:24s\n","epoch 19 | loss: 0.00153 | val_0_mse: 0.00015999999595806003|  0:00:25s\n","epoch 20 | loss: 0.00167 | val_0_mse: 7.999999797903001e-05|  0:00:26s\n","epoch 21 | loss: 0.00136 | val_0_mse: 0.00014000000373926014|  0:00:28s\n","epoch 22 | loss: 0.00152 | val_0_mse: 0.0002899999963119626|  0:00:29s\n","epoch 23 | loss: 0.00091 | val_0_mse: 4.999999873689376e-05|  0:00:30s\n","epoch 24 | loss: 0.00074 | val_0_mse: 9.999999747378752e-05|  0:00:31s\n","epoch 25 | loss: 0.00072 | val_0_mse: 0.0001500000071246177|  0:00:33s\n","epoch 26 | loss: 0.00068 | val_0_mse: 7.000000186963007e-05|  0:00:34s\n","epoch 27 | loss: 0.00058 | val_0_mse: 5.999999848427251e-05|  0:00:35s\n","epoch 28 | loss: 0.00061 | val_0_mse: 9.999999747378752e-05|  0:00:36s\n","epoch 29 | loss: 0.00087 | val_0_mse: 0.0003100000030826777|  0:00:38s\n","epoch 30 | loss: 0.00122 | val_0_mse: 0.0005699999746866524|  0:00:39s\n","epoch 31 | loss: 0.00111 | val_0_mse: 9.999999747378752e-05|  0:00:40s\n","epoch 32 | loss: 0.00086 | val_0_mse: 9.999999747378752e-05|  0:00:42s\n","epoch 33 | loss: 0.0009  | val_0_mse: 7.999999797903001e-05|  0:00:43s\n","\n","Early stopping occurred at epoch 33 with best_epoch = 23 and best_val_0_mse = 4.999999873689376e-05\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 08:33:08,595] Trial 2 finished with value: 5.474952922668308e-05 and parameters: {'n_d': 57, 'n_steps': 6, 'gamma': 1.672319293797242, 'n_independent': 5, 'n_shared': 4, 'momentum': 0.3988460324893301}. Best is trial 0 with value: 4.379454367153812e-06.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 1.77677 | val_0_mse: 3.2821600437164307|  0:00:00s\n","epoch 1  | loss: 0.33957 | val_0_mse: 0.44437000155448914|  0:00:01s\n","epoch 2  | loss: 0.26439 | val_0_mse: 0.29201000928878784|  0:00:02s\n","epoch 3  | loss: 0.09569 | val_0_mse: 0.03061000071465969|  0:00:02s\n","epoch 4  | loss: 0.05338 | val_0_mse: 0.0038399999029934406|  0:00:03s\n","epoch 5  | loss: 0.0214  | val_0_mse: 0.0024999999441206455|  0:00:04s\n","epoch 6  | loss: 0.00639 | val_0_mse: 0.0012000000569969416|  0:00:05s\n","epoch 7  | loss: 0.00323 | val_0_mse: 0.0006799999973736703|  0:00:05s\n","epoch 8  | loss: 0.00218 | val_0_mse: 0.0006900000153109431|  0:00:06s\n","epoch 9  | loss: 0.00168 | val_0_mse: 0.0002800000074785203|  0:00:07s\n","epoch 10 | loss: 0.00137 | val_0_mse: 0.00014000000373926014|  0:00:08s\n","epoch 11 | loss: 0.00122 | val_0_mse: 0.00013000000035390258|  0:00:08s\n","epoch 12 | loss: 0.00103 | val_0_mse: 0.00015999999595806003|  0:00:09s\n","epoch 13 | loss: 0.0009  | val_0_mse: 9.000000136438757e-05|  0:00:10s\n","epoch 14 | loss: 0.00084 | val_0_mse: 0.00011999999696854502|  0:00:10s\n","epoch 15 | loss: 0.00084 | val_0_mse: 9.000000136438757e-05|  0:00:11s\n","epoch 16 | loss: 0.00079 | val_0_mse: 9.000000136438757e-05|  0:00:12s\n","epoch 17 | loss: 0.00073 | val_0_mse: 0.0001500000071246177|  0:00:13s\n","epoch 18 | loss: 0.00071 | val_0_mse: 5.999999848427251e-05|  0:00:13s\n","epoch 19 | loss: 0.00063 | val_0_mse: 5.999999848427251e-05|  0:00:14s\n","epoch 20 | loss: 0.00062 | val_0_mse: 3.9999998989515007e-05|  0:00:15s\n","epoch 21 | loss: 0.00059 | val_0_mse: 5.999999848427251e-05|  0:00:16s\n","epoch 22 | loss: 0.00064 | val_0_mse: 2.9999999242136255e-05|  0:00:16s\n","epoch 23 | loss: 0.00058 | val_0_mse: 3.9999998989515007e-05|  0:00:17s\n","epoch 24 | loss: 0.00058 | val_0_mse: 5.999999848427251e-05|  0:00:18s\n","epoch 25 | loss: 0.00054 | val_0_mse: 2.9999999242136255e-05|  0:00:18s\n","epoch 26 | loss: 0.0005  | val_0_mse: 9.000000136438757e-05|  0:00:19s\n","epoch 27 | loss: 0.00047 | val_0_mse: 2.9999999242136255e-05|  0:00:20s\n","epoch 28 | loss: 0.00048 | val_0_mse: 2.9999999242136255e-05|  0:00:21s\n","epoch 29 | loss: 0.00046 | val_0_mse: 4.999999873689376e-05|  0:00:21s\n","epoch 30 | loss: 0.00045 | val_0_mse: 3.9999998989515007e-05|  0:00:22s\n","epoch 31 | loss: 0.00043 | val_0_mse: 1.9999999494757503e-05|  0:00:23s\n","epoch 32 | loss: 0.00041 | val_0_mse: 1.9999999494757503e-05|  0:00:23s\n","epoch 33 | loss: 0.00041 | val_0_mse: 1.9999999494757503e-05|  0:00:24s\n","epoch 34 | loss: 0.00039 | val_0_mse: 3.9999998989515007e-05|  0:00:25s\n","epoch 35 | loss: 0.00038 | val_0_mse: 1.9999999494757503e-05|  0:00:26s\n","epoch 36 | loss: 0.00037 | val_0_mse: 1.9999999494757503e-05|  0:00:27s\n","epoch 37 | loss: 0.00036 | val_0_mse: 1.9999999494757503e-05|  0:00:27s\n","epoch 38 | loss: 0.00035 | val_0_mse: 1.9999999494757503e-05|  0:00:28s\n","epoch 39 | loss: 0.00034 | val_0_mse: 1.9999999494757503e-05|  0:00:29s\n","epoch 40 | loss: 0.00035 | val_0_mse: 1.9999999494757503e-05|  0:00:29s\n","epoch 41 | loss: 0.00034 | val_0_mse: 9.999999747378752e-06|  0:00:30s\n","epoch 42 | loss: 0.00033 | val_0_mse: 2.9999999242136255e-05|  0:00:31s\n","epoch 43 | loss: 0.00033 | val_0_mse: 9.999999747378752e-06|  0:00:32s\n","epoch 44 | loss: 0.00032 | val_0_mse: 1.9999999494757503e-05|  0:00:32s\n","epoch 45 | loss: 0.00031 | val_0_mse: 1.9999999494757503e-05|  0:00:33s\n","epoch 46 | loss: 0.00031 | val_0_mse: 9.999999747378752e-06|  0:00:34s\n","epoch 47 | loss: 0.0003  | val_0_mse: 9.999999747378752e-06|  0:00:34s\n","epoch 48 | loss: 0.00029 | val_0_mse: 1.9999999494757503e-05|  0:00:35s\n","epoch 49 | loss: 0.00029 | val_0_mse: 9.999999747378752e-06|  0:00:36s\n","epoch 50 | loss: 0.00028 | val_0_mse: 9.999999747378752e-06|  0:00:37s\n","epoch 51 | loss: 0.00028 | val_0_mse: 9.999999747378752e-06|  0:00:37s\n","epoch 52 | loss: 0.00027 | val_0_mse: 9.999999747378752e-06|  0:00:38s\n","epoch 53 | loss: 0.00027 | val_0_mse: 9.999999747378752e-06|  0:00:39s\n","epoch 54 | loss: 0.00026 | val_0_mse: 9.999999747378752e-06|  0:00:39s\n","epoch 55 | loss: 0.00026 | val_0_mse: 9.999999747378752e-06|  0:00:40s\n","epoch 56 | loss: 0.00026 | val_0_mse: 9.999999747378752e-06|  0:00:41s\n","epoch 57 | loss: 0.00026 | val_0_mse: 9.999999747378752e-06|  0:00:42s\n","epoch 58 | loss: 0.00025 | val_0_mse: 9.999999747378752e-06|  0:00:42s\n","epoch 59 | loss: 0.00025 | val_0_mse: 9.999999747378752e-06|  0:00:43s\n","epoch 60 | loss: 0.00025 | val_0_mse: 9.999999747378752e-06|  0:00:44s\n","epoch 61 | loss: 0.00025 | val_0_mse: 9.999999747378752e-06|  0:00:45s\n","epoch 62 | loss: 0.00025 | val_0_mse: 9.999999747378752e-06|  0:00:45s\n","epoch 63 | loss: 0.00024 | val_0_mse: 9.999999747378752e-06|  0:00:46s\n","epoch 64 | loss: 0.00024 | val_0_mse: 9.999999747378752e-06|  0:00:47s\n","epoch 65 | loss: 0.00024 | val_0_mse: 9.999999747378752e-06|  0:00:47s\n","epoch 66 | loss: 0.00024 | val_0_mse: 9.999999747378752e-06|  0:00:48s\n","epoch 67 | loss: 0.00023 | val_0_mse: 9.999999747378752e-06|  0:00:49s\n","epoch 68 | loss: 0.00023 | val_0_mse: 9.999999747378752e-06|  0:00:50s\n","epoch 69 | loss: 0.00023 | val_0_mse: 0.0     |  0:00:50s\n","epoch 70 | loss: 0.00022 | val_0_mse: 9.999999747378752e-06|  0:00:51s\n","epoch 71 | loss: 0.00022 | val_0_mse: 9.999999747378752e-06|  0:00:52s\n","epoch 72 | loss: 0.00022 | val_0_mse: 9.999999747378752e-06|  0:00:52s\n","epoch 73 | loss: 0.00021 | val_0_mse: 0.0     |  0:00:53s\n","epoch 74 | loss: 0.00022 | val_0_mse: 0.0     |  0:00:54s\n","epoch 75 | loss: 0.00021 | val_0_mse: 9.999999747378752e-06|  0:00:55s\n","epoch 76 | loss: 0.00021 | val_0_mse: 0.0     |  0:00:55s\n","epoch 77 | loss: 0.00021 | val_0_mse: 0.0     |  0:00:56s\n","epoch 78 | loss: 0.00021 | val_0_mse: 0.0     |  0:00:57s\n","epoch 79 | loss: 0.00021 | val_0_mse: 0.0     |  0:00:58s\n","epoch 80 | loss: 0.0002  | val_0_mse: 9.999999747378752e-06|  0:00:58s\n","epoch 81 | loss: 0.0002  | val_0_mse: 0.0     |  0:00:59s\n","epoch 82 | loss: 0.0002  | val_0_mse: 9.999999747378752e-06|  0:01:00s\n","epoch 83 | loss: 0.0002  | val_0_mse: 0.0     |  0:01:00s\n","epoch 84 | loss: 0.0002  | val_0_mse: 9.999999747378752e-06|  0:01:01s\n","epoch 85 | loss: 0.0002  | val_0_mse: 0.0     |  0:01:02s\n","epoch 86 | loss: 0.00019 | val_0_mse: 0.0     |  0:01:03s\n","epoch 87 | loss: 0.0002  | val_0_mse: 0.0     |  0:01:03s\n","epoch 88 | loss: 0.00019 | val_0_mse: 0.0     |  0:01:04s\n","epoch 89 | loss: 0.00019 | val_0_mse: 0.0     |  0:01:05s\n","epoch 90 | loss: 0.00019 | val_0_mse: 0.0     |  0:01:05s\n","epoch 91 | loss: 0.00018 | val_0_mse: 0.0     |  0:01:06s\n","epoch 92 | loss: 0.00018 | val_0_mse: 0.0     |  0:01:07s\n","epoch 93 | loss: 0.00018 | val_0_mse: 0.0     |  0:01:08s\n","epoch 94 | loss: 0.00018 | val_0_mse: 0.0     |  0:01:08s\n","epoch 95 | loss: 0.00018 | val_0_mse: 0.0     |  0:01:09s\n","\n","Early stopping occurred at epoch 95 with best_epoch = 85 and best_val_0_mse = 0.0\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 08:34:18,476] Trial 3 finished with value: 2.308088824065635e-06 and parameters: {'n_d': 26, 'n_steps': 5, 'gamma': 1.253406983672397, 'n_independent': 2, 'n_shared': 3, 'momentum': 0.29255930537974156}. Best is trial 3 with value: 2.308088824065635e-06.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 0.83443 | val_0_mse: 2.4874300956726074|  0:00:01s\n","epoch 1  | loss: 0.25488 | val_0_mse: 0.18963000178337097|  0:00:02s\n","epoch 2  | loss: 0.09533 | val_0_mse: 0.03754999861121178|  0:00:03s\n","epoch 3  | loss: 0.03621 | val_0_mse: 0.01785000041127205|  0:00:04s\n","epoch 4  | loss: 0.01619 | val_0_mse: 0.0016799999866634607|  0:00:05s\n","epoch 5  | loss: 0.00258 | val_0_mse: 0.00022000000171829015|  0:00:06s\n","epoch 6  | loss: 0.00065 | val_0_mse: 0.00014000000373926014|  0:00:08s\n","epoch 7  | loss: 0.00068 | val_0_mse: 4.999999873689376e-05|  0:00:09s\n","epoch 8  | loss: 0.00058 | val_0_mse: 7.999999797903001e-05|  0:00:10s\n","epoch 9  | loss: 0.00048 | val_0_mse: 9.999999747378752e-06|  0:00:11s\n","epoch 10 | loss: 0.00044 | val_0_mse: 9.999999747378752e-06|  0:00:12s\n","epoch 11 | loss: 0.00039 | val_0_mse: 0.0     |  0:00:13s\n","epoch 12 | loss: 0.00039 | val_0_mse: 0.0     |  0:00:15s\n","epoch 13 | loss: 0.00037 | val_0_mse: 0.0     |  0:00:16s\n","epoch 14 | loss: 0.00038 | val_0_mse: 0.0     |  0:00:17s\n","epoch 15 | loss: 0.00038 | val_0_mse: 0.0     |  0:00:18s\n","epoch 16 | loss: 0.00036 | val_0_mse: 0.0     |  0:00:19s\n","epoch 17 | loss: 0.00036 | val_0_mse: 0.0     |  0:00:21s\n","epoch 18 | loss: 0.00037 | val_0_mse: 0.0     |  0:00:22s\n","epoch 19 | loss: 0.00037 | val_0_mse: 0.0     |  0:00:23s\n","epoch 20 | loss: 0.00036 | val_0_mse: 0.0     |  0:00:24s\n","epoch 21 | loss: 0.00035 | val_0_mse: 0.0     |  0:00:25s\n","epoch 22 | loss: 0.00035 | val_0_mse: 0.0     |  0:00:26s\n","epoch 23 | loss: 0.00035 | val_0_mse: 0.0     |  0:00:27s\n","epoch 24 | loss: 0.00034 | val_0_mse: 0.0     |  0:00:29s\n","epoch 25 | loss: 0.00034 | val_0_mse: 0.0     |  0:00:30s\n","\n","Early stopping occurred at epoch 25 with best_epoch = 15 and best_val_0_mse = 0.0\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 08:34:49,354] Trial 4 finished with value: 1.9699176334597723e-07 and parameters: {'n_d': 10, 'n_steps': 6, 'gamma': 1.7672459740836413, 'n_independent': 5, 'n_shared': 3, 'momentum': 0.3684296146983064}. Best is trial 4 with value: 1.9699176334597723e-07.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 2.03176 | val_0_mse: 0.8730300068855286|  0:00:00s\n","epoch 1  | loss: 0.44197 | val_0_mse: 2.8412299156188965|  0:00:01s\n","epoch 2  | loss: 0.20606 | val_0_mse: 0.33803999423980713|  0:00:01s\n","epoch 3  | loss: 0.0706  | val_0_mse: 1.7032300233840942|  0:00:02s\n","epoch 4  | loss: 0.02544 | val_0_mse: 0.018400000408291817|  0:00:03s\n","epoch 5  | loss: 0.0101  | val_0_mse: 0.004449999891221523|  0:00:03s\n","epoch 6  | loss: 0.00584 | val_0_mse: 0.0026000000070780516|  0:00:04s\n","epoch 7  | loss: 0.00369 | val_0_mse: 0.0012000000569969416|  0:00:05s\n","epoch 8  | loss: 0.0022  | val_0_mse: 0.000590000010561198|  0:00:05s\n","epoch 9  | loss: 0.00173 | val_0_mse: 0.0006200000061653554|  0:00:06s\n","epoch 10 | loss: 0.00133 | val_0_mse: 0.00039000000106170774|  0:00:06s\n","epoch 11 | loss: 0.00126 | val_0_mse: 0.00039000000106170774|  0:00:07s\n","epoch 12 | loss: 0.00108 | val_0_mse: 0.00026000000070780516|  0:00:08s\n","epoch 13 | loss: 0.00103 | val_0_mse: 0.00041000000783242285|  0:00:08s\n","epoch 14 | loss: 0.00096 | val_0_mse: 0.00033999999868683517|  0:00:09s\n","epoch 15 | loss: 0.00095 | val_0_mse: 0.00019999999494757503|  0:00:09s\n","epoch 16 | loss: 0.00091 | val_0_mse: 0.0002500000118743628|  0:00:10s\n","epoch 17 | loss: 0.00098 | val_0_mse: 0.0001900000061141327|  0:00:11s\n","epoch 18 | loss: 0.00095 | val_0_mse: 0.00011000000085914508|  0:00:11s\n","epoch 19 | loss: 0.00078 | val_0_mse: 0.00011000000085914508|  0:00:12s\n","epoch 20 | loss: 0.00073 | val_0_mse: 9.000000136438757e-05|  0:00:13s\n","epoch 21 | loss: 0.00075 | val_0_mse: 0.00016999999934341758|  0:00:13s\n","epoch 22 | loss: 0.00078 | val_0_mse: 0.00018000000272877514|  0:00:14s\n","epoch 23 | loss: 0.00072 | val_0_mse: 0.0002500000118743628|  0:00:14s\n","epoch 24 | loss: 0.00077 | val_0_mse: 4.999999873689376e-05|  0:00:15s\n","epoch 25 | loss: 0.00076 | val_0_mse: 7.000000186963007e-05|  0:00:16s\n","epoch 26 | loss: 0.0008  | val_0_mse: 0.00018000000272877514|  0:00:17s\n","epoch 27 | loss: 0.00069 | val_0_mse: 7.999999797903001e-05|  0:00:17s\n","epoch 28 | loss: 0.0006  | val_0_mse: 7.000000186963007e-05|  0:00:18s\n","epoch 29 | loss: 0.00065 | val_0_mse: 9.999999747378752e-05|  0:00:18s\n","epoch 30 | loss: 0.00068 | val_0_mse: 0.00013000000035390258|  0:00:19s\n","epoch 31 | loss: 0.00077 | val_0_mse: 0.00016999999934341758|  0:00:20s\n","epoch 32 | loss: 0.00075 | val_0_mse: 0.00013000000035390258|  0:00:20s\n","epoch 33 | loss: 0.00068 | val_0_mse: 0.00011000000085914508|  0:00:21s\n","epoch 34 | loss: 0.0006  | val_0_mse: 9.999999747378752e-05|  0:00:21s\n","\n","Early stopping occurred at epoch 34 with best_epoch = 24 and best_val_0_mse = 4.999999873689376e-05\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 08:35:11,649] Trial 5 finished with value: 5.44622125744354e-05 and parameters: {'n_d': 44, 'n_steps': 4, 'gamma': 1.6745489591924398, 'n_independent': 3, 'n_shared': 2, 'momentum': 0.06091122178922228}. Best is trial 4 with value: 1.9699176334597723e-07.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 2.54004 | val_0_mse: 14.966480255126953|  0:00:00s\n","epoch 1  | loss: 0.41036 | val_0_mse: 0.5138900279998779|  0:00:01s\n","epoch 2  | loss: 0.29052 | val_0_mse: 0.036720000207424164|  0:00:02s\n","epoch 3  | loss: 0.07782 | val_0_mse: 0.10469000041484833|  0:00:02s\n","epoch 4  | loss: 0.04246 | val_0_mse: 0.00937000010162592|  0:00:03s\n","epoch 5  | loss: 0.01558 | val_0_mse: 0.0040699997916817665|  0:00:04s\n","epoch 6  | loss: 0.00635 | val_0_mse: 0.0011599999852478504|  0:00:04s\n","epoch 7  | loss: 0.00326 | val_0_mse: 0.0014900000533089042|  0:00:05s\n","epoch 8  | loss: 0.00191 | val_0_mse: 0.0003600000054575503|  0:00:06s\n","epoch 9  | loss: 0.00139 | val_0_mse: 0.0002899999963119626|  0:00:06s\n","epoch 10 | loss: 0.00112 | val_0_mse: 0.00015999999595806003|  0:00:07s\n","epoch 11 | loss: 0.00102 | val_0_mse: 0.0001500000071246177|  0:00:08s\n","epoch 12 | loss: 0.00086 | val_0_mse: 9.000000136438757e-05|  0:00:09s\n","epoch 13 | loss: 0.00078 | val_0_mse: 9.000000136438757e-05|  0:00:09s\n","epoch 14 | loss: 0.00076 | val_0_mse: 5.999999848427251e-05|  0:00:10s\n","epoch 15 | loss: 0.00068 | val_0_mse: 5.999999848427251e-05|  0:00:11s\n","epoch 16 | loss: 0.00066 | val_0_mse: 4.999999873689376e-05|  0:00:11s\n","epoch 17 | loss: 0.00063 | val_0_mse: 3.9999998989515007e-05|  0:00:12s\n","epoch 18 | loss: 0.00061 | val_0_mse: 3.9999998989515007e-05|  0:00:13s\n","epoch 19 | loss: 0.00059 | val_0_mse: 4.999999873689376e-05|  0:00:13s\n","epoch 20 | loss: 0.00057 | val_0_mse: 4.999999873689376e-05|  0:00:14s\n","epoch 21 | loss: 0.00054 | val_0_mse: 3.9999998989515007e-05|  0:00:15s\n","epoch 22 | loss: 0.00052 | val_0_mse: 2.9999999242136255e-05|  0:00:16s\n","epoch 23 | loss: 0.00051 | val_0_mse: 2.9999999242136255e-05|  0:00:16s\n","epoch 24 | loss: 0.00051 | val_0_mse: 1.9999999494757503e-05|  0:00:17s\n","epoch 25 | loss: 0.00049 | val_0_mse: 1.9999999494757503e-05|  0:00:18s\n","epoch 26 | loss: 0.00049 | val_0_mse: 2.9999999242136255e-05|  0:00:18s\n","epoch 27 | loss: 0.00047 | val_0_mse: 2.9999999242136255e-05|  0:00:19s\n","epoch 28 | loss: 0.00047 | val_0_mse: 2.9999999242136255e-05|  0:00:20s\n","epoch 29 | loss: 0.00046 | val_0_mse: 2.9999999242136255e-05|  0:00:20s\n","epoch 30 | loss: 0.00044 | val_0_mse: 1.9999999494757503e-05|  0:00:21s\n","epoch 31 | loss: 0.00044 | val_0_mse: 2.9999999242136255e-05|  0:00:22s\n","epoch 32 | loss: 0.00044 | val_0_mse: 1.9999999494757503e-05|  0:00:23s\n","epoch 33 | loss: 0.00041 | val_0_mse: 1.9999999494757503e-05|  0:00:23s\n","epoch 34 | loss: 0.00041 | val_0_mse: 1.9999999494757503e-05|  0:00:24s\n","epoch 35 | loss: 0.0004  | val_0_mse: 1.9999999494757503e-05|  0:00:25s\n","epoch 36 | loss: 0.00039 | val_0_mse: 1.9999999494757503e-05|  0:00:25s\n","epoch 37 | loss: 0.0004  | val_0_mse: 1.9999999494757503e-05|  0:00:26s\n","epoch 38 | loss: 0.00039 | val_0_mse: 1.9999999494757503e-05|  0:00:27s\n","epoch 39 | loss: 0.00038 | val_0_mse: 1.9999999494757503e-05|  0:00:27s\n","epoch 40 | loss: 0.00037 | val_0_mse: 1.9999999494757503e-05|  0:00:28s\n","epoch 41 | loss: 0.00036 | val_0_mse: 1.9999999494757503e-05|  0:00:29s\n","epoch 42 | loss: 0.00036 | val_0_mse: 9.999999747378752e-06|  0:00:30s\n","epoch 43 | loss: 0.00035 | val_0_mse: 9.999999747378752e-06|  0:00:30s\n","epoch 44 | loss: 0.00034 | val_0_mse: 9.999999747378752e-06|  0:00:31s\n","epoch 45 | loss: 0.00033 | val_0_mse: 1.9999999494757503e-05|  0:00:32s\n","epoch 46 | loss: 0.00034 | val_0_mse: 9.999999747378752e-06|  0:00:32s\n","epoch 47 | loss: 0.00032 | val_0_mse: 9.999999747378752e-06|  0:00:33s\n","epoch 48 | loss: 0.00032 | val_0_mse: 9.999999747378752e-06|  0:00:34s\n","epoch 49 | loss: 0.00032 | val_0_mse: 9.999999747378752e-06|  0:00:34s\n","epoch 50 | loss: 0.00032 | val_0_mse: 1.9999999494757503e-05|  0:00:35s\n","epoch 51 | loss: 0.00032 | val_0_mse: 9.999999747378752e-06|  0:00:36s\n","epoch 52 | loss: 0.00032 | val_0_mse: 9.999999747378752e-06|  0:00:36s\n","epoch 53 | loss: 0.0003  | val_0_mse: 9.999999747378752e-06|  0:00:37s\n","epoch 54 | loss: 0.00029 | val_0_mse: 9.999999747378752e-06|  0:00:38s\n","epoch 55 | loss: 0.00028 | val_0_mse: 9.999999747378752e-06|  0:00:39s\n","epoch 56 | loss: 0.00028 | val_0_mse: 9.999999747378752e-06|  0:00:39s\n","epoch 57 | loss: 0.00028 | val_0_mse: 9.999999747378752e-06|  0:00:40s\n","epoch 58 | loss: 0.00027 | val_0_mse: 9.999999747378752e-06|  0:00:41s\n","epoch 59 | loss: 0.00027 | val_0_mse: 9.999999747378752e-06|  0:00:41s\n","epoch 60 | loss: 0.00026 | val_0_mse: 9.999999747378752e-06|  0:00:42s\n","epoch 61 | loss: 0.00027 | val_0_mse: 9.999999747378752e-06|  0:00:43s\n","epoch 62 | loss: 0.00026 | val_0_mse: 0.0     |  0:00:43s\n","epoch 63 | loss: 0.00026 | val_0_mse: 0.0     |  0:00:44s\n","epoch 64 | loss: 0.00026 | val_0_mse: 9.999999747378752e-06|  0:00:45s\n","epoch 65 | loss: 0.00026 | val_0_mse: 9.999999747378752e-06|  0:00:45s\n","epoch 66 | loss: 0.00026 | val_0_mse: 9.999999747378752e-06|  0:00:46s\n","epoch 67 | loss: 0.00026 | val_0_mse: 9.999999747378752e-06|  0:00:47s\n","epoch 68 | loss: 0.00026 | val_0_mse: 9.999999747378752e-06|  0:00:47s\n","epoch 69 | loss: 0.00025 | val_0_mse: 9.999999747378752e-06|  0:00:48s\n","epoch 70 | loss: 0.00025 | val_0_mse: 9.999999747378752e-06|  0:00:49s\n","epoch 71 | loss: 0.00024 | val_0_mse: 9.999999747378752e-06|  0:00:49s\n","epoch 72 | loss: 0.00023 | val_0_mse: 0.0     |  0:00:50s\n","epoch 73 | loss: 0.00023 | val_0_mse: 0.0     |  0:00:51s\n","epoch 74 | loss: 0.00023 | val_0_mse: 0.0     |  0:00:52s\n","epoch 75 | loss: 0.00023 | val_0_mse: 0.0     |  0:00:52s\n","epoch 76 | loss: 0.00023 | val_0_mse: 0.0     |  0:00:53s\n","epoch 77 | loss: 0.00022 | val_0_mse: 0.0     |  0:00:54s\n","epoch 78 | loss: 0.00022 | val_0_mse: 9.999999747378752e-06|  0:00:54s\n","epoch 79 | loss: 0.00022 | val_0_mse: 0.0     |  0:00:55s\n","epoch 80 | loss: 0.00021 | val_0_mse: 0.0     |  0:00:56s\n","epoch 81 | loss: 0.00021 | val_0_mse: 0.0     |  0:00:56s\n","epoch 82 | loss: 0.0002  | val_0_mse: 0.0     |  0:00:57s\n","epoch 83 | loss: 0.00022 | val_0_mse: 1.9999999494757503e-05|  0:00:58s\n","epoch 84 | loss: 0.00027 | val_0_mse: 9.999999747378752e-06|  0:00:58s\n","epoch 85 | loss: 0.00028 | val_0_mse: 9.999999747378752e-06|  0:00:59s\n","epoch 86 | loss: 0.00029 | val_0_mse: 9.999999747378752e-06|  0:01:00s\n","epoch 87 | loss: 0.00029 | val_0_mse: 9.999999747378752e-06|  0:01:01s\n","epoch 88 | loss: 0.00029 | val_0_mse: 9.999999747378752e-06|  0:01:01s\n","epoch 89 | loss: 0.0003  | val_0_mse: 9.999999747378752e-06|  0:01:02s\n","epoch 90 | loss: 0.00027 | val_0_mse: 9.999999747378752e-06|  0:01:03s\n","\n","Early stopping occurred at epoch 90 with best_epoch = 80 and best_val_0_mse = 0.0\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 08:36:15,184] Trial 6 finished with value: 3.0750113637623144e-06 and parameters: {'n_d': 32, 'n_steps': 4, 'gamma': 1.4634128053967146, 'n_independent': 2, 'n_shared': 4, 'momentum': 0.306699552109943}. Best is trial 4 with value: 1.9699176334597723e-07.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 1.69646 | val_0_mse: 11.150839805603027|  0:00:01s\n","epoch 1  | loss: 0.98937 | val_0_mse: 2.187880039215088|  0:00:03s\n","epoch 2  | loss: 0.45136 | val_0_mse: 0.366349995136261|  0:00:05s\n","epoch 3  | loss: 0.24086 | val_0_mse: 0.0515500009059906|  0:00:07s\n","epoch 4  | loss: 0.31079 | val_0_mse: 0.5263800024986267|  0:00:08s\n","epoch 5  | loss: 0.28731 | val_0_mse: 0.10277000069618225|  0:00:10s\n","epoch 6  | loss: 0.03493 | val_0_mse: 0.04002000018954277|  0:00:12s\n","epoch 7  | loss: 0.01264 | val_0_mse: 0.024219999089837074|  0:00:14s\n","epoch 8  | loss: 0.02455 | val_0_mse: 0.0028899998869746923|  0:00:15s\n","epoch 9  | loss: 0.00484 | val_0_mse: 0.0013099999632686377|  0:00:17s\n","epoch 10 | loss: 0.00146 | val_0_mse: 0.0009599999757483602|  0:00:19s\n","epoch 11 | loss: 0.00061 | val_0_mse: 3.9999998989515007e-05|  0:00:21s\n","epoch 12 | loss: 0.00053 | val_0_mse: 9.999999747378752e-06|  0:00:23s\n","epoch 13 | loss: 0.00051 | val_0_mse: 9.999999747378752e-06|  0:00:24s\n","epoch 14 | loss: 0.00049 | val_0_mse: 0.0     |  0:00:26s\n","epoch 15 | loss: 0.00047 | val_0_mse: 0.0     |  0:00:28s\n","epoch 16 | loss: 0.00047 | val_0_mse: 0.0     |  0:00:30s\n","epoch 17 | loss: 0.00046 | val_0_mse: 0.0     |  0:00:31s\n","epoch 18 | loss: 0.00045 | val_0_mse: 0.0     |  0:00:33s\n","epoch 19 | loss: 0.00044 | val_0_mse: 0.0     |  0:00:35s\n","epoch 20 | loss: 0.00043 | val_0_mse: 0.0     |  0:00:37s\n","epoch 21 | loss: 0.00041 | val_0_mse: 0.0     |  0:00:38s\n","epoch 22 | loss: 0.00041 | val_0_mse: 0.0     |  0:00:40s\n","epoch 23 | loss: 0.00041 | val_0_mse: 0.0     |  0:00:42s\n","epoch 24 | loss: 0.00041 | val_0_mse: 0.0     |  0:00:44s\n","epoch 25 | loss: 0.0004  | val_0_mse: 0.0     |  0:00:45s\n","epoch 26 | loss: 0.00039 | val_0_mse: 0.0     |  0:00:47s\n","epoch 27 | loss: 0.00038 | val_0_mse: 0.0     |  0:00:49s\n","epoch 28 | loss: 0.00037 | val_0_mse: 0.0     |  0:00:51s\n","\n","Early stopping occurred at epoch 28 with best_epoch = 18 and best_val_0_mse = 0.0\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 08:37:07,174] Trial 7 finished with value: 7.320138024624612e-07 and parameters: {'n_d': 13, 'n_steps': 9, 'gamma': 1.2026140380191652, 'n_independent': 5, 'n_shared': 4, 'momentum': 0.08227584464367957}. Best is trial 4 with value: 1.9699176334597723e-07.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 1.08167 | val_0_mse: 17.232440948486328|  0:00:00s\n","epoch 1  | loss: 0.22118 | val_0_mse: 0.5103200078010559|  0:00:01s\n","epoch 2  | loss: 0.07657 | val_0_mse: 0.07349999994039536|  0:00:02s\n","epoch 3  | loss: 0.02874 | val_0_mse: 0.007890000008046627|  0:00:02s\n","epoch 4  | loss: 0.00879 | val_0_mse: 0.002090000081807375|  0:00:03s\n","epoch 5  | loss: 0.00403 | val_0_mse: 0.0002899999963119626|  0:00:04s\n","epoch 6  | loss: 0.00193 | val_0_mse: 0.00023999999393709004|  0:00:05s\n","epoch 7  | loss: 0.00142 | val_0_mse: 0.0002800000074785203|  0:00:05s\n","epoch 8  | loss: 0.00119 | val_0_mse: 9.000000136438757e-05|  0:00:06s\n","epoch 9  | loss: 0.00105 | val_0_mse: 0.00013000000035390258|  0:00:07s\n","epoch 10 | loss: 0.00095 | val_0_mse: 3.9999998989515007e-05|  0:00:07s\n","epoch 11 | loss: 0.00089 | val_0_mse: 7.000000186963007e-05|  0:00:08s\n","epoch 12 | loss: 0.00084 | val_0_mse: 2.9999999242136255e-05|  0:00:09s\n","epoch 13 | loss: 0.00081 | val_0_mse: 1.9999999494757503e-05|  0:00:10s\n","epoch 14 | loss: 0.00078 | val_0_mse: 3.9999998989515007e-05|  0:00:10s\n","epoch 15 | loss: 0.00074 | val_0_mse: 1.9999999494757503e-05|  0:00:11s\n","epoch 16 | loss: 0.00071 | val_0_mse: 9.999999747378752e-06|  0:00:12s\n","epoch 17 | loss: 0.00069 | val_0_mse: 1.9999999494757503e-05|  0:00:12s\n","epoch 18 | loss: 0.0007  | val_0_mse: 9.999999747378752e-06|  0:00:13s\n","epoch 19 | loss: 0.00067 | val_0_mse: 1.9999999494757503e-05|  0:00:14s\n","epoch 20 | loss: 0.00066 | val_0_mse: 1.9999999494757503e-05|  0:00:14s\n","epoch 21 | loss: 0.00066 | val_0_mse: 9.999999747378752e-06|  0:00:15s\n","epoch 22 | loss: 0.00062 | val_0_mse: 9.999999747378752e-06|  0:00:16s\n","epoch 23 | loss: 0.00062 | val_0_mse: 9.999999747378752e-06|  0:00:17s\n","epoch 24 | loss: 0.00058 | val_0_mse: 9.999999747378752e-06|  0:00:17s\n","epoch 25 | loss: 0.00059 | val_0_mse: 9.999999747378752e-06|  0:00:18s\n","epoch 26 | loss: 0.00056 | val_0_mse: 9.999999747378752e-06|  0:00:19s\n","epoch 27 | loss: 0.00054 | val_0_mse: 9.999999747378752e-06|  0:00:19s\n","epoch 28 | loss: 0.00053 | val_0_mse: 9.999999747378752e-06|  0:00:20s\n","epoch 29 | loss: 0.00052 | val_0_mse: 9.999999747378752e-06|  0:00:21s\n","epoch 30 | loss: 0.00052 | val_0_mse: 9.999999747378752e-06|  0:00:21s\n","epoch 31 | loss: 0.00051 | val_0_mse: 9.999999747378752e-06|  0:00:22s\n","epoch 32 | loss: 0.00053 | val_0_mse: 9.999999747378752e-06|  0:00:23s\n","epoch 33 | loss: 0.0005  | val_0_mse: 9.999999747378752e-06|  0:00:23s\n","epoch 34 | loss: 0.00049 | val_0_mse: 0.0     |  0:00:24s\n","epoch 35 | loss: 0.00049 | val_0_mse: 9.999999747378752e-06|  0:00:25s\n","epoch 36 | loss: 0.00047 | val_0_mse: 9.999999747378752e-06|  0:00:25s\n","epoch 37 | loss: 0.00045 | val_0_mse: 0.0     |  0:00:26s\n","epoch 38 | loss: 0.00045 | val_0_mse: 9.999999747378752e-06|  0:00:27s\n","epoch 39 | loss: 0.00044 | val_0_mse: 0.0     |  0:00:28s\n","epoch 40 | loss: 0.00043 | val_0_mse: 9.999999747378752e-06|  0:00:28s\n","epoch 41 | loss: 0.00043 | val_0_mse: 9.999999747378752e-06|  0:00:29s\n","epoch 42 | loss: 0.00043 | val_0_mse: 0.0     |  0:00:30s\n","epoch 43 | loss: 0.00042 | val_0_mse: 9.999999747378752e-06|  0:00:31s\n","epoch 44 | loss: 0.00041 | val_0_mse: 0.0     |  0:00:31s\n","epoch 45 | loss: 0.00042 | val_0_mse: 9.999999747378752e-06|  0:00:32s\n","epoch 46 | loss: 0.0004  | val_0_mse: 9.999999747378752e-06|  0:00:33s\n","epoch 47 | loss: 0.0004  | val_0_mse: 0.0     |  0:00:33s\n","epoch 48 | loss: 0.0004  | val_0_mse: 0.0     |  0:00:34s\n","epoch 49 | loss: 0.00038 | val_0_mse: 0.0     |  0:00:35s\n","epoch 50 | loss: 0.00038 | val_0_mse: 0.0     |  0:00:35s\n","epoch 51 | loss: 0.00037 | val_0_mse: 0.0     |  0:00:36s\n","epoch 52 | loss: 0.00036 | val_0_mse: 0.0     |  0:00:37s\n","epoch 53 | loss: 0.00035 | val_0_mse: 0.0     |  0:00:37s\n","epoch 54 | loss: 0.00035 | val_0_mse: 0.0     |  0:00:38s\n","epoch 55 | loss: 0.00035 | val_0_mse: 0.0     |  0:00:39s\n","epoch 56 | loss: 0.00033 | val_0_mse: 0.0     |  0:00:40s\n","epoch 57 | loss: 0.00033 | val_0_mse: 0.0     |  0:00:40s\n","epoch 58 | loss: 0.00033 | val_0_mse: 0.0     |  0:00:41s\n","epoch 59 | loss: 0.00033 | val_0_mse: 0.0     |  0:00:42s\n","epoch 60 | loss: 0.00032 | val_0_mse: 0.0     |  0:00:42s\n","epoch 61 | loss: 0.00032 | val_0_mse: 9.999999747378752e-06|  0:00:43s\n","epoch 62 | loss: 0.00031 | val_0_mse: 0.0     |  0:00:44s\n","epoch 63 | loss: 0.0003  | val_0_mse: 0.0     |  0:00:44s\n","epoch 64 | loss: 0.0003  | val_0_mse: 0.0     |  0:00:45s\n","epoch 65 | loss: 0.00029 | val_0_mse: 0.0     |  0:00:46s\n","epoch 66 | loss: 0.0003  | val_0_mse: 0.0     |  0:00:46s\n","epoch 67 | loss: 0.00029 | val_0_mse: 0.0     |  0:00:47s\n","epoch 68 | loss: 0.00027 | val_0_mse: 0.0     |  0:00:48s\n","epoch 69 | loss: 0.00028 | val_0_mse: 0.0     |  0:00:49s\n","epoch 70 | loss: 0.00028 | val_0_mse: 0.0     |  0:00:49s\n","epoch 71 | loss: 0.00027 | val_0_mse: 0.0     |  0:00:50s\n","epoch 72 | loss: 0.00026 | val_0_mse: 0.0     |  0:00:51s\n","epoch 73 | loss: 0.00025 | val_0_mse: 0.0     |  0:00:51s\n","epoch 74 | loss: 0.00025 | val_0_mse: 0.0     |  0:00:52s\n","epoch 75 | loss: 0.00025 | val_0_mse: 0.0     |  0:00:53s\n","epoch 76 | loss: 0.00024 | val_0_mse: 0.0     |  0:00:53s\n","epoch 77 | loss: 0.00024 | val_0_mse: 9.999999747378752e-06|  0:00:54s\n","epoch 78 | loss: 0.00024 | val_0_mse: 0.0     |  0:00:55s\n","epoch 79 | loss: 0.00023 | val_0_mse: 0.0     |  0:00:56s\n","epoch 80 | loss: 0.00023 | val_0_mse: 0.0     |  0:00:56s\n","epoch 81 | loss: 0.00024 | val_0_mse: 0.0     |  0:00:57s\n","epoch 82 | loss: 0.00022 | val_0_mse: 0.0     |  0:00:58s\n","epoch 83 | loss: 0.00022 | val_0_mse: 0.0     |  0:00:58s\n","epoch 84 | loss: 0.00022 | val_0_mse: 0.0     |  0:00:59s\n","epoch 85 | loss: 0.00022 | val_0_mse: 0.0     |  0:01:00s\n","epoch 86 | loss: 0.00021 | val_0_mse: 0.0     |  0:01:00s\n","epoch 87 | loss: 0.00021 | val_0_mse: 0.0     |  0:01:01s\n","epoch 88 | loss: 0.0002  | val_0_mse: 0.0     |  0:01:02s\n","epoch 89 | loss: 0.0002  | val_0_mse: 0.0     |  0:01:02s\n","epoch 90 | loss: 0.0002  | val_0_mse: 0.0     |  0:01:03s\n","epoch 91 | loss: 0.00021 | val_0_mse: 0.0     |  0:01:04s\n","\n","Early stopping occurred at epoch 91 with best_epoch = 81 and best_val_0_mse = 0.0\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 08:38:11,638] Trial 8 finished with value: 1.7575696347194025e-06 and parameters: {'n_d': 26, 'n_steps': 3, 'gamma': 1.6575039609657864, 'n_independent': 3, 'n_shared': 5, 'momentum': 0.21567481882823786}. Best is trial 4 with value: 1.9699176334597723e-07.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 10.71636| val_0_mse: 73.92342376708984|  0:00:01s\n","epoch 1  | loss: 3.20302 | val_0_mse: 6.4712700843811035|  0:00:03s\n","epoch 2  | loss: 2.52246 | val_0_mse: 5.170770168304443|  0:00:04s\n","epoch 3  | loss: 1.80329 | val_0_mse: 14.541600227355957|  0:00:06s\n","epoch 4  | loss: 2.89767 | val_0_mse: 10.858269691467285|  0:00:08s\n","epoch 5  | loss: 3.12566 | val_0_mse: 3.9444899559020996|  0:00:09s\n","epoch 6  | loss: 2.00811 | val_0_mse: 0.7448300123214722|  0:00:11s\n","epoch 7  | loss: 0.35397 | val_0_mse: 0.07287999987602234|  0:00:13s\n","epoch 8  | loss: 0.12245 | val_0_mse: 0.2581300139427185|  0:00:14s\n","epoch 9  | loss: 0.58507 | val_0_mse: 0.5595099925994873|  0:00:16s\n","epoch 10 | loss: 0.17251 | val_0_mse: 0.009379999712109566|  0:00:18s\n","epoch 11 | loss: 0.03322 | val_0_mse: 0.001509999972768128|  0:00:19s\n","epoch 12 | loss: 0.01005 | val_0_mse: 0.00279999990016222|  0:00:21s\n","epoch 13 | loss: 0.0045  | val_0_mse: 0.0009200000204145908|  0:00:23s\n","epoch 14 | loss: 0.00428 | val_0_mse: 0.004889999981969595|  0:00:24s\n","epoch 15 | loss: 0.00185 | val_0_mse: 0.0006000000284984708|  0:00:26s\n","epoch 16 | loss: 0.00095 | val_0_mse: 9.999999747378752e-05|  0:00:28s\n","epoch 17 | loss: 0.00056 | val_0_mse: 2.9999999242136255e-05|  0:00:30s\n","epoch 18 | loss: 0.0004  | val_0_mse: 1.9999999494757503e-05|  0:00:31s\n","epoch 19 | loss: 0.00032 | val_0_mse: 2.9999999242136255e-05|  0:00:33s\n","epoch 20 | loss: 0.00029 | val_0_mse: 2.9999999242136255e-05|  0:00:35s\n","epoch 21 | loss: 0.00026 | val_0_mse: 9.999999747378752e-06|  0:00:36s\n","epoch 22 | loss: 0.00026 | val_0_mse: 4.999999873689376e-05|  0:00:38s\n","epoch 23 | loss: 0.00025 | val_0_mse: 1.9999999494757503e-05|  0:00:40s\n","epoch 24 | loss: 0.00024 | val_0_mse: 9.999999747378752e-06|  0:00:41s\n","epoch 25 | loss: 0.00024 | val_0_mse: 1.9999999494757503e-05|  0:00:43s\n","epoch 26 | loss: 0.00023 | val_0_mse: 9.999999747378752e-06|  0:00:45s\n","epoch 27 | loss: 0.00023 | val_0_mse: 9.999999747378752e-06|  0:00:46s\n","epoch 28 | loss: 0.00023 | val_0_mse: 9.999999747378752e-06|  0:00:48s\n","epoch 29 | loss: 0.00022 | val_0_mse: 9.999999747378752e-06|  0:00:50s\n","epoch 30 | loss: 0.00022 | val_0_mse: 9.999999747378752e-06|  0:00:51s\n","epoch 31 | loss: 0.00021 | val_0_mse: 9.999999747378752e-06|  0:00:53s\n","epoch 32 | loss: 0.00022 | val_0_mse: 9.999999747378752e-06|  0:00:55s\n","epoch 33 | loss: 0.00022 | val_0_mse: 1.9999999494757503e-05|  0:00:57s\n","epoch 34 | loss: 0.00021 | val_0_mse: 9.999999747378752e-06|  0:00:58s\n","epoch 35 | loss: 0.00022 | val_0_mse: 9.999999747378752e-06|  0:01:00s\n","epoch 36 | loss: 0.00021 | val_0_mse: 0.0     |  0:01:02s\n","epoch 37 | loss: 0.00022 | val_0_mse: 0.0     |  0:01:04s\n","epoch 38 | loss: 0.00021 | val_0_mse: 9.999999747378752e-06|  0:01:05s\n","epoch 39 | loss: 0.00023 | val_0_mse: 3.9999998989515007e-05|  0:01:07s\n","epoch 40 | loss: 0.00024 | val_0_mse: 2.9999999242136255e-05|  0:01:09s\n","epoch 41 | loss: 0.00023 | val_0_mse: 9.999999747378752e-06|  0:01:11s\n","epoch 42 | loss: 0.00022 | val_0_mse: 9.999999747378752e-06|  0:01:12s\n","epoch 43 | loss: 0.00021 | val_0_mse: 9.999999747378752e-06|  0:01:14s\n","epoch 44 | loss: 0.00021 | val_0_mse: 9.999999747378752e-06|  0:01:16s\n","epoch 45 | loss: 0.0002  | val_0_mse: 9.999999747378752e-06|  0:01:17s\n","epoch 46 | loss: 0.0002  | val_0_mse: 9.999999747378752e-06|  0:01:19s\n","epoch 47 | loss: 0.00019 | val_0_mse: 0.0     |  0:01:21s\n","\n","Early stopping occurred at epoch 47 with best_epoch = 37 and best_val_0_mse = 0.0\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 08:39:33,675] Trial 9 finished with value: 4.2132364796998445e-06 and parameters: {'n_d': 43, 'n_steps': 8, 'gamma': 1.8616941282282364, 'n_independent': 5, 'n_shared': 5, 'momentum': 0.09626660842514442}. Best is trial 4 with value: 1.9699176334597723e-07.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 0.5601  | val_0_mse: 0.20089000463485718|  0:00:00s\n","epoch 1  | loss: 0.15216 | val_0_mse: 0.06232000142335892|  0:00:01s\n","epoch 2  | loss: 0.1225  | val_0_mse: 0.07129000127315521|  0:00:02s\n","epoch 3  | loss: 0.03581 | val_0_mse: 0.012059999629855156|  0:00:02s\n","epoch 4  | loss: 0.01866 | val_0_mse: 0.014689999632537365|  0:00:03s\n","epoch 5  | loss: 0.0541  | val_0_mse: 0.0036800000816583633|  0:00:04s\n","epoch 6  | loss: 0.00526 | val_0_mse: 0.006560000125318766|  0:00:05s\n","epoch 7  | loss: 0.00241 | val_0_mse: 0.00139999995008111|  0:00:05s\n","epoch 8  | loss: 0.00117 | val_0_mse: 0.0002699999895412475|  0:00:06s\n","epoch 9  | loss: 0.00045 | val_0_mse: 2.9999999242136255e-05|  0:00:07s\n","epoch 10 | loss: 0.00026 | val_0_mse: 4.999999873689376e-05|  0:00:08s\n","epoch 11 | loss: 0.00021 | val_0_mse: 2.9999999242136255e-05|  0:00:08s\n","epoch 12 | loss: 0.00016 | val_0_mse: 9.999999747378752e-06|  0:00:09s\n","epoch 13 | loss: 0.00015 | val_0_mse: 0.0     |  0:00:10s\n","epoch 14 | loss: 0.00015 | val_0_mse: 0.0     |  0:00:10s\n","epoch 15 | loss: 0.00014 | val_0_mse: 0.0     |  0:00:11s\n","epoch 16 | loss: 0.00013 | val_0_mse: 0.0     |  0:00:12s\n","epoch 17 | loss: 0.00013 | val_0_mse: 0.0     |  0:00:13s\n","epoch 18 | loss: 0.00013 | val_0_mse: 0.0     |  0:00:14s\n","epoch 19 | loss: 0.00013 | val_0_mse: 0.0     |  0:00:14s\n","epoch 20 | loss: 0.00013 | val_0_mse: 0.0     |  0:00:15s\n","epoch 21 | loss: 0.00012 | val_0_mse: 0.0     |  0:00:16s\n","epoch 22 | loss: 0.00012 | val_0_mse: 0.0     |  0:00:16s\n","epoch 23 | loss: 0.00012 | val_0_mse: 0.0     |  0:00:17s\n","epoch 24 | loss: 0.00012 | val_0_mse: 0.0     |  0:00:18s\n","\n","Early stopping occurred at epoch 24 with best_epoch = 14 and best_val_0_mse = 0.0\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 08:39:52,645] Trial 10 finished with value: 3.672357138384541e-07 and parameters: {'n_d': 8, 'n_steps': 10, 'gamma': 1.8813437045563584, 'n_independent': 1, 'n_shared': 1, 'momentum': 0.39807584606648855}. Best is trial 4 with value: 1.9699176334597723e-07.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 12.72928| val_0_mse: 16.925369262695312|  0:00:00s\n","epoch 1  | loss: 3.25867 | val_0_mse: 1.1276500225067139|  0:00:01s\n","epoch 2  | loss: 1.17829 | val_0_mse: 1.3093700408935547|  0:00:02s\n","epoch 3  | loss: 0.55838 | val_0_mse: 0.5885099768638611|  0:00:02s\n","epoch 4  | loss: 0.22174 | val_0_mse: 0.266510009765625|  0:00:03s\n","epoch 5  | loss: 0.16831 | val_0_mse: 0.01840999908745289|  0:00:04s\n","epoch 6  | loss: 0.56559 | val_0_mse: 0.3944700062274933|  0:00:05s\n","epoch 7  | loss: 0.4587  | val_0_mse: 0.042419999837875366|  0:00:05s\n","epoch 8  | loss: 0.2445  | val_0_mse: 0.07438000291585922|  0:00:06s\n","epoch 9  | loss: 0.209   | val_0_mse: 0.05615999922156334|  0:00:07s\n","epoch 10 | loss: 0.10253 | val_0_mse: 0.031619999557733536|  0:00:07s\n","epoch 11 | loss: 0.06144 | val_0_mse: 0.004809999838471413|  0:00:08s\n","epoch 12 | loss: 0.02547 | val_0_mse: 0.010470000095665455|  0:00:09s\n","epoch 13 | loss: 0.01219 | val_0_mse: 0.002240000059828162|  0:00:10s\n","epoch 14 | loss: 0.00447 | val_0_mse: 0.0006099999882280827|  0:00:10s\n","epoch 15 | loss: 0.00211 | val_0_mse: 0.00107999995816499|  0:00:11s\n","epoch 16 | loss: 0.00089 | val_0_mse: 0.00016999999934341758|  0:00:12s\n","epoch 17 | loss: 0.00043 | val_0_mse: 9.999999747378752e-05|  0:00:13s\n","epoch 18 | loss: 0.00025 | val_0_mse: 5.999999848427251e-05|  0:00:13s\n","epoch 19 | loss: 0.00019 | val_0_mse: 3.9999998989515007e-05|  0:00:14s\n","epoch 20 | loss: 0.00016 | val_0_mse: 1.9999999494757503e-05|  0:00:15s\n","epoch 21 | loss: 0.00015 | val_0_mse: 1.9999999494757503e-05|  0:00:16s\n","epoch 22 | loss: 0.00014 | val_0_mse: 9.999999747378752e-06|  0:00:16s\n","epoch 23 | loss: 0.00013 | val_0_mse: 0.0     |  0:00:17s\n","epoch 24 | loss: 0.00013 | val_0_mse: 9.999999747378752e-06|  0:00:18s\n","epoch 25 | loss: 0.00012 | val_0_mse: 0.0     |  0:00:18s\n","epoch 26 | loss: 0.00012 | val_0_mse: 0.0     |  0:00:19s\n","epoch 27 | loss: 0.00012 | val_0_mse: 0.0     |  0:00:20s\n","epoch 28 | loss: 0.00012 | val_0_mse: 0.0     |  0:00:20s\n","epoch 29 | loss: 0.00012 | val_0_mse: 0.0     |  0:00:21s\n","epoch 30 | loss: 0.00012 | val_0_mse: 0.0     |  0:00:22s\n","epoch 31 | loss: 0.00012 | val_0_mse: 0.0     |  0:00:23s\n","epoch 32 | loss: 0.00012 | val_0_mse: 0.0     |  0:00:23s\n","epoch 33 | loss: 0.00012 | val_0_mse: 0.0     |  0:00:24s\n","epoch 34 | loss: 0.00012 | val_0_mse: 0.0     |  0:00:25s\n","epoch 35 | loss: 0.00011 | val_0_mse: 0.0     |  0:00:26s\n","epoch 36 | loss: 0.00011 | val_0_mse: 0.0     |  0:00:26s\n","epoch 37 | loss: 0.00011 | val_0_mse: 0.0     |  0:00:27s\n","epoch 38 | loss: 0.00011 | val_0_mse: 0.0     |  0:00:28s\n","epoch 39 | loss: 0.00011 | val_0_mse: 0.0     |  0:00:28s\n","epoch 40 | loss: 0.00011 | val_0_mse: 0.0     |  0:00:29s\n","epoch 41 | loss: 0.00012 | val_0_mse: 0.0     |  0:00:30s\n","epoch 42 | loss: 0.00011 | val_0_mse: 0.0     |  0:00:30s\n","epoch 43 | loss: 0.00011 | val_0_mse: 0.0     |  0:00:31s\n","epoch 44 | loss: 0.00011 | val_0_mse: 0.0     |  0:00:32s\n","epoch 45 | loss: 0.00011 | val_0_mse: 0.0     |  0:00:33s\n","epoch 46 | loss: 0.00011 | val_0_mse: 0.0     |  0:00:33s\n","\n","Early stopping occurred at epoch 46 with best_epoch = 36 and best_val_0_mse = 0.0\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 08:40:26,838] Trial 11 finished with value: 4.370917281448783e-07 and parameters: {'n_d': 9, 'n_steps': 10, 'gamma': 1.949492687114529, 'n_independent': 1, 'n_shared': 1, 'momentum': 0.39223837328892475}. Best is trial 4 with value: 1.9699176334597723e-07.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 3.83957 | val_0_mse: 3.9745099544525146|  0:00:00s\n","epoch 1  | loss: 0.59429 | val_0_mse: 0.4955500066280365|  0:00:00s\n","epoch 2  | loss: 0.25964 | val_0_mse: 0.10255999863147736|  0:00:01s\n","epoch 3  | loss: 0.12173 | val_0_mse: 0.023879999294877052|  0:00:01s\n","epoch 4  | loss: 0.0539  | val_0_mse: 0.009789999574422836|  0:00:02s\n","epoch 5  | loss: 0.05804 | val_0_mse: 0.014000000432133675|  0:00:02s\n","epoch 6  | loss: 0.0375  | val_0_mse: 0.01460999995470047|  0:00:03s\n","epoch 7  | loss: 0.04007 | val_0_mse: 0.017909999936819077|  0:00:03s\n","epoch 8  | loss: 0.01805 | val_0_mse: 0.01104000024497509|  0:00:04s\n","epoch 9  | loss: 0.00757 | val_0_mse: 0.0011899999808520079|  0:00:04s\n","epoch 10 | loss: 0.00518 | val_0_mse: 0.000859999970998615|  0:00:05s\n","epoch 11 | loss: 0.00329 | val_0_mse: 0.0010300000431016088|  0:00:05s\n","epoch 12 | loss: 0.00262 | val_0_mse: 0.0006900000153109431|  0:00:06s\n","epoch 13 | loss: 0.00234 | val_0_mse: 0.0012700000079348683|  0:00:06s\n","epoch 14 | loss: 0.00199 | val_0_mse: 0.0008800000068731606|  0:00:07s\n","epoch 15 | loss: 0.00212 | val_0_mse: 0.0005699999746866524|  0:00:07s\n","epoch 16 | loss: 0.00213 | val_0_mse: 0.00023999999393709004|  0:00:08s\n","epoch 17 | loss: 0.00183 | val_0_mse: 0.00031999999191612005|  0:00:08s\n","epoch 18 | loss: 0.00138 | val_0_mse: 0.00033000000985339284|  0:00:08s\n","epoch 19 | loss: 0.001   | val_0_mse: 0.00041000000783242285|  0:00:09s\n","epoch 20 | loss: 0.00087 | val_0_mse: 0.00019999999494757503|  0:00:09s\n","epoch 21 | loss: 0.00075 | val_0_mse: 0.00016999999934341758|  0:00:10s\n","epoch 22 | loss: 0.00065 | val_0_mse: 0.00018000000272877514|  0:00:10s\n","epoch 23 | loss: 0.00067 | val_0_mse: 0.00014000000373926014|  0:00:11s\n","epoch 24 | loss: 0.00058 | val_0_mse: 0.00011999999696854502|  0:00:11s\n","epoch 25 | loss: 0.00055 | val_0_mse: 9.000000136438757e-05|  0:00:12s\n","epoch 26 | loss: 0.00051 | val_0_mse: 0.0001500000071246177|  0:00:12s\n","epoch 27 | loss: 0.00053 | val_0_mse: 0.00015999999595806003|  0:00:13s\n","epoch 28 | loss: 0.00051 | val_0_mse: 0.00014000000373926014|  0:00:13s\n","epoch 29 | loss: 0.0005  | val_0_mse: 0.00016999999934341758|  0:00:14s\n","epoch 30 | loss: 0.00049 | val_0_mse: 0.0001500000071246177|  0:00:14s\n","epoch 31 | loss: 0.00045 | val_0_mse: 0.0002099999983329326|  0:00:15s\n","epoch 32 | loss: 0.00045 | val_0_mse: 0.00015999999595806003|  0:00:15s\n","epoch 33 | loss: 0.00043 | val_0_mse: 0.00016999999934341758|  0:00:16s\n","epoch 34 | loss: 0.0004  | val_0_mse: 0.0002699999895412475|  0:00:16s\n","epoch 35 | loss: 0.00042 | val_0_mse: 0.00018000000272877514|  0:00:17s\n","\n","Early stopping occurred at epoch 35 with best_epoch = 25 and best_val_0_mse = 9.000000136438757e-05\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 08:40:44,432] Trial 12 finished with value: 9.009618952404708e-05 and parameters: {'n_d': 15, 'n_steps': 6, 'gamma': 1.8169593921493952, 'n_independent': 1, 'n_shared': 1, 'momentum': 0.3256762352194567}. Best is trial 4 with value: 1.9699176334597723e-07.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 64.11079| val_0_mse: 227.79458618164062|  0:00:01s\n","epoch 1  | loss: 7.73822 | val_0_mse: 12.031599998474121|  0:00:02s\n","epoch 2  | loss: 3.26321 | val_0_mse: 0.4706999957561493|  0:00:04s\n","epoch 3  | loss: 1.31446 | val_0_mse: 0.43698999285697937|  0:00:05s\n","epoch 4  | loss: 1.56336 | val_0_mse: 0.360150009393692|  0:00:06s\n","epoch 5  | loss: 0.85504 | val_0_mse: 0.9210399985313416|  0:00:08s\n","epoch 6  | loss: 0.7905  | val_0_mse: 0.2603200078010559|  0:00:09s\n","epoch 7  | loss: 0.91286 | val_0_mse: 0.2510800063610077|  0:00:11s\n","epoch 8  | loss: 0.94697 | val_0_mse: 0.2603299915790558|  0:00:12s\n","epoch 9  | loss: 0.26481 | val_0_mse: 0.0515500009059906|  0:00:13s\n","epoch 10 | loss: 0.07391 | val_0_mse: 0.011250000447034836|  0:00:15s\n","epoch 11 | loss: 0.02709 | val_0_mse: 0.004519999958574772|  0:00:16s\n","epoch 12 | loss: 0.01077 | val_0_mse: 0.005750000011175871|  0:00:17s\n","epoch 13 | loss: 0.00664 | val_0_mse: 0.0026400000788271427|  0:00:19s\n","epoch 14 | loss: 0.00468 | val_0_mse: 0.0008999999845400453|  0:00:20s\n","epoch 15 | loss: 0.00346 | val_0_mse: 0.0003100000030826777|  0:00:22s\n","epoch 16 | loss: 0.0016  | val_0_mse: 0.00026000000070780516|  0:00:23s\n","epoch 17 | loss: 0.00124 | val_0_mse: 0.0002899999963119626|  0:00:24s\n","epoch 18 | loss: 0.00112 | val_0_mse: 0.00016999999934341758|  0:00:26s\n","epoch 19 | loss: 0.00093 | val_0_mse: 0.0002300000051036477|  0:00:27s\n","epoch 20 | loss: 0.00069 | val_0_mse: 0.0002300000051036477|  0:00:29s\n","epoch 21 | loss: 0.00067 | val_0_mse: 0.00018000000272877514|  0:00:30s\n","epoch 22 | loss: 0.00065 | val_0_mse: 0.0001900000061141327|  0:00:31s\n","epoch 23 | loss: 0.00058 | val_0_mse: 0.0002300000051036477|  0:00:33s\n","epoch 24 | loss: 0.0006  | val_0_mse: 0.0002300000051036477|  0:00:34s\n","epoch 25 | loss: 0.00057 | val_0_mse: 0.00023999999393709004|  0:00:35s\n","epoch 26 | loss: 0.00063 | val_0_mse: 0.00015999999595806003|  0:00:37s\n","epoch 27 | loss: 0.00086 | val_0_mse: 0.00033999999868683517|  0:00:38s\n","epoch 28 | loss: 0.00094 | val_0_mse: 0.0002699999895412475|  0:00:40s\n","epoch 29 | loss: 0.00059 | val_0_mse: 0.00023999999393709004|  0:00:41s\n","epoch 30 | loss: 0.00043 | val_0_mse: 0.00014000000373926014|  0:00:42s\n","epoch 31 | loss: 0.00031 | val_0_mse: 9.000000136438757e-05|  0:00:44s\n","epoch 32 | loss: 0.00027 | val_0_mse: 7.000000186963007e-05|  0:00:45s\n","epoch 33 | loss: 0.00024 | val_0_mse: 5.999999848427251e-05|  0:00:46s\n","epoch 34 | loss: 0.00023 | val_0_mse: 7.000000186963007e-05|  0:00:48s\n","epoch 35 | loss: 0.00023 | val_0_mse: 5.999999848427251e-05|  0:00:49s\n","epoch 36 | loss: 0.00022 | val_0_mse: 4.999999873689376e-05|  0:00:51s\n","epoch 37 | loss: 0.00023 | val_0_mse: 4.999999873689376e-05|  0:00:52s\n","epoch 38 | loss: 0.00027 | val_0_mse: 5.999999848427251e-05|  0:00:53s\n","epoch 39 | loss: 0.00027 | val_0_mse: 9.000000136438757e-05|  0:00:55s\n","epoch 40 | loss: 0.00026 | val_0_mse: 5.999999848427251e-05|  0:00:56s\n","epoch 41 | loss: 0.00026 | val_0_mse: 5.999999848427251e-05|  0:00:57s\n","epoch 42 | loss: 0.00021 | val_0_mse: 4.999999873689376e-05|  0:00:59s\n","epoch 43 | loss: 0.00017 | val_0_mse: 3.9999998989515007e-05|  0:01:00s\n","epoch 44 | loss: 0.00018 | val_0_mse: 3.9999998989515007e-05|  0:01:02s\n","epoch 45 | loss: 0.00016 | val_0_mse: 3.9999998989515007e-05|  0:01:03s\n","epoch 46 | loss: 0.00016 | val_0_mse: 2.9999999242136255e-05|  0:01:04s\n","epoch 47 | loss: 0.00014 | val_0_mse: 2.9999999242136255e-05|  0:01:06s\n","epoch 48 | loss: 0.00014 | val_0_mse: 2.9999999242136255e-05|  0:01:07s\n","epoch 49 | loss: 0.00015 | val_0_mse: 1.9999999494757503e-05|  0:01:09s\n","epoch 50 | loss: 0.00016 | val_0_mse: 3.9999998989515007e-05|  0:01:10s\n","epoch 51 | loss: 0.00017 | val_0_mse: 2.9999999242136255e-05|  0:01:11s\n","epoch 52 | loss: 0.00016 | val_0_mse: 1.9999999494757503e-05|  0:01:13s\n","epoch 53 | loss: 0.00014 | val_0_mse: 2.9999999242136255e-05|  0:01:14s\n","epoch 54 | loss: 0.00013 | val_0_mse: 1.9999999494757503e-05|  0:01:15s\n","epoch 55 | loss: 0.00012 | val_0_mse: 1.9999999494757503e-05|  0:01:17s\n","epoch 56 | loss: 0.00012 | val_0_mse: 1.9999999494757503e-05|  0:01:18s\n","epoch 57 | loss: 0.00012 | val_0_mse: 9.999999747378752e-06|  0:01:20s\n","epoch 58 | loss: 0.00013 | val_0_mse: 2.9999999242136255e-05|  0:01:21s\n","epoch 59 | loss: 0.00014 | val_0_mse: 1.9999999494757503e-05|  0:01:22s\n","epoch 60 | loss: 0.00015 | val_0_mse: 9.999999747378752e-06|  0:01:24s\n","epoch 61 | loss: 0.00014 | val_0_mse: 9.999999747378752e-06|  0:01:25s\n","epoch 62 | loss: 0.00016 | val_0_mse: 4.999999873689376e-05|  0:01:26s\n","epoch 63 | loss: 0.00017 | val_0_mse: 3.9999998989515007e-05|  0:01:28s\n","epoch 64 | loss: 0.00017 | val_0_mse: 1.9999999494757503e-05|  0:01:29s\n","epoch 65 | loss: 0.00017 | val_0_mse: 2.9999999242136255e-05|  0:01:30s\n","epoch 66 | loss: 0.00016 | val_0_mse: 1.9999999494757503e-05|  0:01:32s\n","epoch 67 | loss: 0.00016 | val_0_mse: 1.9999999494757503e-05|  0:01:33s\n","\n","Early stopping occurred at epoch 67 with best_epoch = 57 and best_val_0_mse = 9.999999747378752e-06\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 08:42:18,797] Trial 13 finished with value: 1.0545541044848505e-05 and parameters: {'n_d': 20, 'n_steps': 10, 'gamma': 1.9829373440380302, 'n_independent': 4, 'n_shared': 2, 'momentum': 0.35159305285618475}. Best is trial 4 with value: 1.9699176334597723e-07.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 1.79812 | val_0_mse: 5.119929790496826|  0:00:01s\n","epoch 1  | loss: 0.47772 | val_0_mse: 0.17378999292850494|  0:00:02s\n","epoch 2  | loss: 0.16658 | val_0_mse: 0.19487999379634857|  0:00:03s\n","epoch 3  | loss: 0.05633 | val_0_mse: 0.010400000028312206|  0:00:04s\n","epoch 4  | loss: 0.01902 | val_0_mse: 0.0009200000204145908|  0:00:05s\n","epoch 5  | loss: 0.00366 | val_0_mse: 9.000000136438757e-05|  0:00:06s\n","epoch 6  | loss: 0.0007  | val_0_mse: 0.00011999999696854502|  0:00:07s\n","epoch 7  | loss: 0.00062 | val_0_mse: 2.9999999242136255e-05|  0:00:08s\n","epoch 8  | loss: 0.00041 | val_0_mse: 9.999999747378752e-06|  0:00:09s\n","epoch 9  | loss: 0.00037 | val_0_mse: 9.999999747378752e-06|  0:00:10s\n","epoch 10 | loss: 0.00031 | val_0_mse: 0.0     |  0:00:11s\n","epoch 11 | loss: 0.00028 | val_0_mse: 0.0     |  0:00:12s\n","epoch 12 | loss: 0.00029 | val_0_mse: 0.0     |  0:00:13s\n","epoch 13 | loss: 0.00031 | val_0_mse: 0.0     |  0:00:14s\n","epoch 14 | loss: 0.00031 | val_0_mse: 0.0     |  0:00:15s\n","epoch 15 | loss: 0.0003  | val_0_mse: 0.0     |  0:00:16s\n","epoch 16 | loss: 0.0003  | val_0_mse: 0.0     |  0:00:17s\n","epoch 17 | loss: 0.00029 | val_0_mse: 0.0     |  0:00:18s\n","epoch 18 | loss: 0.00028 | val_0_mse: 0.0     |  0:00:19s\n","epoch 19 | loss: 0.0003  | val_0_mse: 0.0     |  0:00:20s\n","epoch 20 | loss: 0.0003  | val_0_mse: 0.0     |  0:00:21s\n","epoch 21 | loss: 0.0003  | val_0_mse: 0.0     |  0:00:22s\n","epoch 22 | loss: 0.00031 | val_0_mse: 0.0     |  0:00:23s\n","epoch 23 | loss: 0.00031 | val_0_mse: 0.0     |  0:00:24s\n","epoch 24 | loss: 0.00029 | val_0_mse: 0.0     |  0:00:25s\n","epoch 25 | loss: 0.00028 | val_0_mse: 0.0     |  0:00:26s\n","epoch 26 | loss: 0.00027 | val_0_mse: 0.0     |  0:00:27s\n","\n","Early stopping occurred at epoch 26 with best_epoch = 16 and best_val_0_mse = 0.0\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 08:42:47,079] Trial 14 finished with value: 3.981761551585805e-07 and parameters: {'n_d': 8, 'n_steps': 7, 'gamma': 1.7551092190410313, 'n_independent': 4, 'n_shared': 2, 'momentum': 0.1597359770958812}. Best is trial 4 with value: 1.9699176334597723e-07.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 9.43078 | val_0_mse: 2.7413198947906494|  0:00:00s\n","epoch 1  | loss: 0.74983 | val_0_mse: 0.9262800216674805|  0:00:01s\n","epoch 2  | loss: 0.4136  | val_0_mse: 0.3768500089645386|  0:00:02s\n","epoch 3  | loss: 0.20816 | val_0_mse: 0.10491999983787537|  0:00:02s\n","epoch 4  | loss: 0.25822 | val_0_mse: 0.07526999711990356|  0:00:03s\n","epoch 5  | loss: 0.27137 | val_0_mse: 0.06164000183343887|  0:00:04s\n","epoch 6  | loss: 0.14172 | val_0_mse: 0.2836399972438812|  0:00:05s\n","epoch 7  | loss: 0.08269 | val_0_mse: 0.08976999670267105|  0:00:06s\n","epoch 8  | loss: 0.03813 | val_0_mse: 0.01640000008046627|  0:00:06s\n","epoch 9  | loss: 0.02034 | val_0_mse: 0.0028800000436604023|  0:00:07s\n","epoch 10 | loss: 0.01988 | val_0_mse: 0.0013599999947473407|  0:00:08s\n","epoch 11 | loss: 0.01476 | val_0_mse: 0.0005000000237487257|  0:00:09s\n","epoch 12 | loss: 0.00455 | val_0_mse: 0.0007300000288523734|  0:00:09s\n","epoch 13 | loss: 0.00241 | val_0_mse: 0.0001900000061141327|  0:00:10s\n","epoch 14 | loss: 0.00163 | val_0_mse: 0.00011000000085914508|  0:00:11s\n","epoch 15 | loss: 0.00113 | val_0_mse: 9.999999747378752e-05|  0:00:11s\n","epoch 16 | loss: 0.00087 | val_0_mse: 7.999999797903001e-05|  0:00:12s\n","epoch 17 | loss: 0.00071 | val_0_mse: 7.000000186963007e-05|  0:00:13s\n","epoch 18 | loss: 0.00058 | val_0_mse: 7.000000186963007e-05|  0:00:14s\n","epoch 19 | loss: 0.00048 | val_0_mse: 9.999999747378752e-05|  0:00:14s\n","epoch 20 | loss: 0.00042 | val_0_mse: 7.999999797903001e-05|  0:00:15s\n","epoch 21 | loss: 0.00041 | val_0_mse: 4.999999873689376e-05|  0:00:16s\n","epoch 22 | loss: 0.00037 | val_0_mse: 4.999999873689376e-05|  0:00:17s\n","epoch 23 | loss: 0.00038 | val_0_mse: 2.9999999242136255e-05|  0:00:17s\n","epoch 24 | loss: 0.00036 | val_0_mse: 2.9999999242136255e-05|  0:00:18s\n","epoch 25 | loss: 0.00036 | val_0_mse: 1.9999999494757503e-05|  0:00:19s\n","epoch 26 | loss: 0.00033 | val_0_mse: 1.9999999494757503e-05|  0:00:20s\n","epoch 27 | loss: 0.00029 | val_0_mse: 1.9999999494757503e-05|  0:00:20s\n","epoch 28 | loss: 0.00027 | val_0_mse: 9.999999747378752e-06|  0:00:21s\n","epoch 29 | loss: 0.00026 | val_0_mse: 9.999999747378752e-06|  0:00:22s\n","epoch 30 | loss: 0.00024 | val_0_mse: 9.999999747378752e-06|  0:00:23s\n","epoch 31 | loss: 0.00025 | val_0_mse: 9.999999747378752e-06|  0:00:23s\n","epoch 32 | loss: 0.00023 | val_0_mse: 9.999999747378752e-06|  0:00:24s\n","epoch 33 | loss: 0.00023 | val_0_mse: 9.999999747378752e-06|  0:00:25s\n","epoch 34 | loss: 0.00023 | val_0_mse: 9.999999747378752e-06|  0:00:26s\n","epoch 35 | loss: 0.00025 | val_0_mse: 1.9999999494757503e-05|  0:00:26s\n","epoch 36 | loss: 0.00025 | val_0_mse: 1.9999999494757503e-05|  0:00:27s\n","epoch 37 | loss: 0.00028 | val_0_mse: 2.9999999242136255e-05|  0:00:28s\n","epoch 38 | loss: 0.00026 | val_0_mse: 2.9999999242136255e-05|  0:00:28s\n","epoch 39 | loss: 0.00025 | val_0_mse: 1.9999999494757503e-05|  0:00:29s\n","epoch 40 | loss: 0.00023 | val_0_mse: 9.999999747378752e-06|  0:00:30s\n","epoch 41 | loss: 0.00023 | val_0_mse: 9.999999747378752e-06|  0:00:31s\n","epoch 42 | loss: 0.00022 | val_0_mse: 9.999999747378752e-06|  0:00:31s\n","epoch 43 | loss: 0.0002  | val_0_mse: 9.999999747378752e-06|  0:00:32s\n","epoch 44 | loss: 0.00021 | val_0_mse: 9.999999747378752e-06|  0:00:33s\n","\n","Early stopping occurred at epoch 44 with best_epoch = 34 and best_val_0_mse = 9.999999747378752e-06\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 08:43:20,775] Trial 15 finished with value: 5.531368515221402e-06 and parameters: {'n_d': 17, 'n_steps': 8, 'gamma': 1.5703213315479412, 'n_independent': 2, 'n_shared': 1, 'momentum': 0.27278016206186423}. Best is trial 4 with value: 1.9699176334597723e-07.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 6.80659 | val_0_mse: 2.769129991531372|  0:00:00s\n","epoch 1  | loss: 0.8487  | val_0_mse: 1.3017300367355347|  0:00:01s\n","epoch 2  | loss: 0.39831 | val_0_mse: 0.158270001411438|  0:00:02s\n","epoch 3  | loss: 0.22474 | val_0_mse: 0.11533000320196152|  0:00:03s\n","epoch 4  | loss: 0.14679 | val_0_mse: 0.06605000048875809|  0:00:04s\n","epoch 5  | loss: 0.09018 | val_0_mse: 0.014569999650120735|  0:00:04s\n","epoch 6  | loss: 0.04076 | val_0_mse: 0.002739999908953905|  0:00:05s\n","epoch 7  | loss: 0.01753 | val_0_mse: 0.0034000000450760126|  0:00:06s\n","epoch 8  | loss: 0.00674 | val_0_mse: 0.004470000043511391|  0:00:07s\n","epoch 9  | loss: 0.00389 | val_0_mse: 0.0018899999558925629|  0:00:07s\n","epoch 10 | loss: 0.0029  | val_0_mse: 0.0013000000035390258|  0:00:08s\n","epoch 11 | loss: 0.00271 | val_0_mse: 0.0008399999933317304|  0:00:09s\n","epoch 12 | loss: 0.00205 | val_0_mse: 0.00039000000106170774|  0:00:10s\n","epoch 13 | loss: 0.00182 | val_0_mse: 0.0004199999966658652|  0:00:11s\n","epoch 14 | loss: 0.0015  | val_0_mse: 0.0003699999942909926|  0:00:11s\n","epoch 15 | loss: 0.00141 | val_0_mse: 0.00022000000171829015|  0:00:12s\n","epoch 16 | loss: 0.00142 | val_0_mse: 0.0001900000061141327|  0:00:13s\n","epoch 17 | loss: 0.00128 | val_0_mse: 0.00015999999595806003|  0:00:14s\n","epoch 18 | loss: 0.00115 | val_0_mse: 0.00015999999595806003|  0:00:14s\n","epoch 19 | loss: 0.00114 | val_0_mse: 0.00011999999696854502|  0:00:15s\n","epoch 20 | loss: 0.00105 | val_0_mse: 9.999999747378752e-05|  0:00:16s\n","epoch 21 | loss: 0.00098 | val_0_mse: 9.999999747378752e-05|  0:00:17s\n","epoch 22 | loss: 0.00094 | val_0_mse: 4.999999873689376e-05|  0:00:18s\n","epoch 23 | loss: 0.0009  | val_0_mse: 7.000000186963007e-05|  0:00:18s\n","epoch 24 | loss: 0.001   | val_0_mse: 0.00018000000272877514|  0:00:19s\n","epoch 25 | loss: 0.00134 | val_0_mse: 0.0002500000118743628|  0:00:20s\n","epoch 26 | loss: 0.00139 | val_0_mse: 9.000000136438757e-05|  0:00:21s\n","epoch 27 | loss: 0.00113 | val_0_mse: 9.999999747378752e-05|  0:00:21s\n","epoch 28 | loss: 0.00102 | val_0_mse: 4.999999873689376e-05|  0:00:22s\n","epoch 29 | loss: 0.0009  | val_0_mse: 5.999999848427251e-05|  0:00:23s\n","epoch 30 | loss: 0.00083 | val_0_mse: 4.999999873689376e-05|  0:00:24s\n","epoch 31 | loss: 0.00076 | val_0_mse: 4.999999873689376e-05|  0:00:25s\n","epoch 32 | loss: 0.00072 | val_0_mse: 3.9999998989515007e-05|  0:00:25s\n","epoch 33 | loss: 0.00065 | val_0_mse: 2.9999999242136255e-05|  0:00:26s\n","epoch 34 | loss: 0.00063 | val_0_mse: 3.9999998989515007e-05|  0:00:27s\n","epoch 35 | loss: 0.0006  | val_0_mse: 2.9999999242136255e-05|  0:00:28s\n","epoch 36 | loss: 0.00058 | val_0_mse: 1.9999999494757503e-05|  0:00:29s\n","epoch 37 | loss: 0.00058 | val_0_mse: 1.9999999494757503e-05|  0:00:29s\n","epoch 38 | loss: 0.00055 | val_0_mse: 1.9999999494757503e-05|  0:00:30s\n","epoch 39 | loss: 0.00055 | val_0_mse: 1.9999999494757503e-05|  0:00:31s\n","epoch 40 | loss: 0.00053 | val_0_mse: 1.9999999494757503e-05|  0:00:32s\n","epoch 41 | loss: 0.00061 | val_0_mse: 3.9999998989515007e-05|  0:00:33s\n","epoch 42 | loss: 0.00067 | val_0_mse: 2.9999999242136255e-05|  0:00:33s\n","epoch 43 | loss: 0.00062 | val_0_mse: 1.9999999494757503e-05|  0:00:34s\n","epoch 44 | loss: 0.00057 | val_0_mse: 1.9999999494757503e-05|  0:00:35s\n","epoch 45 | loss: 0.00054 | val_0_mse: 1.9999999494757503e-05|  0:00:36s\n","epoch 46 | loss: 0.0005  | val_0_mse: 1.9999999494757503e-05|  0:00:36s\n","epoch 47 | loss: 0.0005  | val_0_mse: 9.999999747378752e-06|  0:00:37s\n","epoch 48 | loss: 0.00047 | val_0_mse: 3.9999998989515007e-05|  0:00:38s\n","epoch 49 | loss: 0.00046 | val_0_mse: 9.999999747378752e-06|  0:00:39s\n","epoch 50 | loss: 0.00044 | val_0_mse: 1.9999999494757503e-05|  0:00:39s\n","epoch 51 | loss: 0.00045 | val_0_mse: 9.999999747378752e-06|  0:00:40s\n","epoch 52 | loss: 0.00043 | val_0_mse: 1.9999999494757503e-05|  0:00:41s\n","epoch 53 | loss: 0.00044 | val_0_mse: 9.999999747378752e-06|  0:00:42s\n","epoch 54 | loss: 0.00042 | val_0_mse: 9.999999747378752e-06|  0:00:43s\n","epoch 55 | loss: 0.00043 | val_0_mse: 9.999999747378752e-06|  0:00:43s\n","epoch 56 | loss: 0.00042 | val_0_mse: 9.999999747378752e-06|  0:00:44s\n","epoch 57 | loss: 0.0004  | val_0_mse: 9.999999747378752e-06|  0:00:45s\n","epoch 58 | loss: 0.0004  | val_0_mse: 9.999999747378752e-06|  0:00:46s\n","epoch 59 | loss: 0.00041 | val_0_mse: 9.999999747378752e-06|  0:00:46s\n","\n","Early stopping occurred at epoch 59 with best_epoch = 49 and best_val_0_mse = 9.999999747378752e-06\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 08:44:08,143] Trial 16 finished with value: 1.227438133355463e-05 and parameters: {'n_d': 21, 'n_steps': 5, 'gamma': 1.0643234539238293, 'n_independent': 4, 'n_shared': 2, 'momentum': 0.364925431333303}. Best is trial 4 with value: 1.9699176334597723e-07.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 7.51143 | val_0_mse: 8.46072006225586|  0:00:00s\n","epoch 1  | loss: 2.06869 | val_0_mse: 0.9180200099945068|  0:00:01s\n","epoch 2  | loss: 0.77958 | val_0_mse: 0.4101499915122986|  0:00:01s\n","epoch 3  | loss: 0.38511 | val_0_mse: 0.44012999534606934|  0:00:02s\n","epoch 4  | loss: 0.66656 | val_0_mse: 0.39037999510765076|  0:00:03s\n","epoch 5  | loss: 0.59832 | val_0_mse: 0.47102999687194824|  0:00:03s\n","epoch 6  | loss: 0.32497 | val_0_mse: 0.4005900025367737|  0:00:04s\n","epoch 7  | loss: 0.56912 | val_0_mse: 0.15644000470638275|  0:00:05s\n","epoch 8  | loss: 0.21485 | val_0_mse: 0.06510999798774719|  0:00:05s\n","epoch 9  | loss: 0.16775 | val_0_mse: 0.02806999906897545|  0:00:06s\n","epoch 10 | loss: 0.0942  | val_0_mse: 0.0348300002515316|  0:00:07s\n","epoch 11 | loss: 0.07663 | val_0_mse: 0.02314000017940998|  0:00:07s\n","epoch 12 | loss: 0.03819 | val_0_mse: 0.007199999876320362|  0:00:08s\n","epoch 13 | loss: 0.01955 | val_0_mse: 0.004089999943971634|  0:00:09s\n","epoch 14 | loss: 0.0081  | val_0_mse: 0.003969999961555004|  0:00:09s\n","epoch 15 | loss: 0.00428 | val_0_mse: 0.002219999907538295|  0:00:10s\n","epoch 16 | loss: 0.00308 | val_0_mse: 0.0014700000174343586|  0:00:11s\n","epoch 17 | loss: 0.00247 | val_0_mse: 0.0006600000197067857|  0:00:11s\n","epoch 18 | loss: 0.00224 | val_0_mse: 0.001069999998435378|  0:00:12s\n","epoch 19 | loss: 0.00194 | val_0_mse: 0.0011099999537691474|  0:00:13s\n","epoch 20 | loss: 0.00177 | val_0_mse: 0.0003499999875202775|  0:00:13s\n","epoch 21 | loss: 0.00193 | val_0_mse: 0.0005699999746866524|  0:00:14s\n","epoch 22 | loss: 0.0016  | val_0_mse: 0.0004799999878741801|  0:00:15s\n","epoch 23 | loss: 0.00138 | val_0_mse: 0.00044999999227002263|  0:00:15s\n","epoch 24 | loss: 0.00142 | val_0_mse: 0.0008500000112690032|  0:00:16s\n","epoch 25 | loss: 0.00149 | val_0_mse: 0.0005799999926239252|  0:00:17s\n","epoch 26 | loss: 0.00119 | val_0_mse: 0.00033999999868683517|  0:00:17s\n","epoch 27 | loss: 0.00093 | val_0_mse: 0.00026000000070780516|  0:00:18s\n","epoch 28 | loss: 0.0009  | val_0_mse: 0.00022000000171829015|  0:00:19s\n","epoch 29 | loss: 0.00074 | val_0_mse: 0.0002099999983329326|  0:00:19s\n","epoch 30 | loss: 0.00077 | val_0_mse: 0.00016999999934341758|  0:00:20s\n","epoch 31 | loss: 0.0007  | val_0_mse: 0.00013000000035390258|  0:00:21s\n","epoch 32 | loss: 0.00063 | val_0_mse: 0.00011999999696854502|  0:00:21s\n","epoch 33 | loss: 0.00064 | val_0_mse: 0.00023999999393709004|  0:00:22s\n","epoch 34 | loss: 0.00085 | val_0_mse: 0.0001900000061141327|  0:00:23s\n","epoch 35 | loss: 0.00082 | val_0_mse: 0.00016999999934341758|  0:00:23s\n","epoch 36 | loss: 0.00079 | val_0_mse: 0.0003699999942909926|  0:00:24s\n","epoch 37 | loss: 0.00068 | val_0_mse: 0.0001900000061141327|  0:00:25s\n","epoch 38 | loss: 0.0007  | val_0_mse: 0.00031999999191612005|  0:00:25s\n","epoch 39 | loss: 0.00056 | val_0_mse: 7.999999797903001e-05|  0:00:26s\n","epoch 40 | loss: 0.00054 | val_0_mse: 0.0001500000071246177|  0:00:26s\n","epoch 41 | loss: 0.0008  | val_0_mse: 0.00016999999934341758|  0:00:27s\n","epoch 42 | loss: 0.0006  | val_0_mse: 0.00011999999696854502|  0:00:28s\n","epoch 43 | loss: 0.00059 | val_0_mse: 0.0001500000071246177|  0:00:28s\n","epoch 44 | loss: 0.00049 | val_0_mse: 7.000000186963007e-05|  0:00:29s\n","epoch 45 | loss: 0.00041 | val_0_mse: 7.999999797903001e-05|  0:00:30s\n","epoch 46 | loss: 0.00033 | val_0_mse: 9.999999747378752e-05|  0:00:30s\n","epoch 47 | loss: 0.00032 | val_0_mse: 3.9999998989515007e-05|  0:00:31s\n","epoch 48 | loss: 0.00031 | val_0_mse: 2.9999999242136255e-05|  0:00:32s\n","epoch 49 | loss: 0.00028 | val_0_mse: 5.999999848427251e-05|  0:00:32s\n","epoch 50 | loss: 0.00029 | val_0_mse: 7.999999797903001e-05|  0:00:33s\n","epoch 51 | loss: 0.00026 | val_0_mse: 2.9999999242136255e-05|  0:00:34s\n","epoch 52 | loss: 0.00022 | val_0_mse: 4.999999873689376e-05|  0:00:34s\n","epoch 53 | loss: 0.00021 | val_0_mse: 3.9999998989515007e-05|  0:00:35s\n","epoch 54 | loss: 0.0002  | val_0_mse: 3.9999998989515007e-05|  0:00:36s\n","epoch 55 | loss: 0.00021 | val_0_mse: 2.9999999242136255e-05|  0:00:36s\n","epoch 56 | loss: 0.0002  | val_0_mse: 2.9999999242136255e-05|  0:00:37s\n","epoch 57 | loss: 0.00018 | val_0_mse: 3.9999998989515007e-05|  0:00:38s\n","epoch 58 | loss: 0.00017 | val_0_mse: 2.9999999242136255e-05|  0:00:38s\n","epoch 59 | loss: 0.00016 | val_0_mse: 1.9999999494757503e-05|  0:00:39s\n","epoch 60 | loss: 0.00017 | val_0_mse: 1.9999999494757503e-05|  0:00:40s\n","epoch 61 | loss: 0.00017 | val_0_mse: 1.9999999494757503e-05|  0:00:40s\n","epoch 62 | loss: 0.00018 | val_0_mse: 9.999999747378752e-06|  0:00:41s\n","epoch 63 | loss: 0.00016 | val_0_mse: 1.9999999494757503e-05|  0:00:42s\n","epoch 64 | loss: 0.00016 | val_0_mse: 9.999999747378752e-06|  0:00:42s\n","epoch 65 | loss: 0.00015 | val_0_mse: 1.9999999494757503e-05|  0:00:43s\n","epoch 66 | loss: 0.00015 | val_0_mse: 9.999999747378752e-06|  0:00:44s\n","epoch 67 | loss: 0.00015 | val_0_mse: 9.999999747378752e-06|  0:00:45s\n","epoch 68 | loss: 0.00014 | val_0_mse: 9.999999747378752e-06|  0:00:45s\n","epoch 69 | loss: 0.00014 | val_0_mse: 9.999999747378752e-06|  0:00:46s\n","epoch 70 | loss: 0.00016 | val_0_mse: 9.999999747378752e-06|  0:00:47s\n","epoch 71 | loss: 0.00013 | val_0_mse: 9.999999747378752e-06|  0:00:47s\n","epoch 72 | loss: 0.00014 | val_0_mse: 9.999999747378752e-06|  0:00:48s\n","epoch 73 | loss: 0.00013 | val_0_mse: 9.999999747378752e-06|  0:00:49s\n","epoch 74 | loss: 0.00013 | val_0_mse: 0.0     |  0:00:49s\n","epoch 75 | loss: 0.00013 | val_0_mse: 0.0     |  0:00:50s\n","epoch 76 | loss: 0.00012 | val_0_mse: 0.0     |  0:00:50s\n","epoch 77 | loss: 0.00012 | val_0_mse: 9.999999747378752e-06|  0:00:51s\n","epoch 78 | loss: 0.00012 | val_0_mse: 9.999999747378752e-06|  0:00:52s\n","epoch 79 | loss: 0.00012 | val_0_mse: 0.0     |  0:00:53s\n","epoch 80 | loss: 0.00012 | val_0_mse: 9.999999747378752e-06|  0:00:53s\n","epoch 81 | loss: 0.00013 | val_0_mse: 2.9999999242136255e-05|  0:00:54s\n","epoch 82 | loss: 0.00013 | val_0_mse: 9.999999747378752e-06|  0:00:54s\n","epoch 83 | loss: 0.00012 | val_0_mse: 9.999999747378752e-06|  0:00:55s\n","epoch 84 | loss: 0.00012 | val_0_mse: 9.999999747378752e-06|  0:00:56s\n","epoch 85 | loss: 0.00011 | val_0_mse: 9.999999747378752e-06|  0:00:56s\n","epoch 86 | loss: 0.00011 | val_0_mse: 9.999999747378752e-06|  0:00:57s\n","epoch 87 | loss: 0.00011 | val_0_mse: 0.0     |  0:00:58s\n","epoch 88 | loss: 0.0001  | val_0_mse: 9.999999747378752e-06|  0:00:58s\n","epoch 89 | loss: 0.0001  | val_0_mse: 0.0     |  0:00:59s\n","epoch 90 | loss: 0.0001  | val_0_mse: 0.0     |  0:01:00s\n","epoch 91 | loss: 0.0001  | val_0_mse: 0.0     |  0:01:00s\n","epoch 92 | loss: 0.0001  | val_0_mse: 0.0     |  0:01:01s\n","epoch 93 | loss: 0.0001  | val_0_mse: 0.0     |  0:01:02s\n","epoch 94 | loss: 9e-05   | val_0_mse: 0.0     |  0:01:02s\n","epoch 95 | loss: 0.0001  | val_0_mse: 0.0     |  0:01:03s\n","epoch 96 | loss: 9e-05   | val_0_mse: 0.0     |  0:01:04s\n","epoch 97 | loss: 0.0001  | val_0_mse: 0.0     |  0:01:04s\n","epoch 98 | loss: 9e-05   | val_0_mse: 0.0     |  0:01:05s\n","epoch 99 | loss: 9e-05   | val_0_mse: 0.0     |  0:01:06s\n","Stop training because you reached max_epochs = 100 with best_epoch = 99 and best_val_0_mse = 0.0\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 08:45:14,754] Trial 17 finished with value: 5.153112283551309e-07 and parameters: {'n_d': 38, 'n_steps': 9, 'gamma': 1.8682858431513139, 'n_independent': 1, 'n_shared': 1, 'momentum': 0.348503825892172}. Best is trial 4 with value: 1.9699176334597723e-07.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 1.05457 | val_0_mse: 2.675800085067749|  0:00:00s\n","epoch 1  | loss: 0.19781 | val_0_mse: 0.19134999811649323|  0:00:01s\n","epoch 2  | loss: 0.07783 | val_0_mse: 0.022120000794529915|  0:00:02s\n","epoch 3  | loss: 0.03381 | val_0_mse: 0.014650000259280205|  0:00:03s\n","epoch 4  | loss: 0.00609 | val_0_mse: 0.001180000021122396|  0:00:03s\n","epoch 5  | loss: 0.0016  | val_0_mse: 0.0005000000237487257|  0:00:04s\n","epoch 6  | loss: 0.00093 | val_0_mse: 0.00013000000035390258|  0:00:05s\n","epoch 7  | loss: 0.0008  | val_0_mse: 0.00039999998989515007|  0:00:06s\n","epoch 8  | loss: 0.00066 | val_0_mse: 3.9999998989515007e-05|  0:00:07s\n","epoch 9  | loss: 0.00057 | val_0_mse: 0.0     |  0:00:08s\n","epoch 10 | loss: 0.00056 | val_0_mse: 0.0     |  0:00:09s\n","epoch 11 | loss: 0.00056 | val_0_mse: 0.0     |  0:00:09s\n","epoch 12 | loss: 0.00055 | val_0_mse: 0.0     |  0:00:10s\n","epoch 13 | loss: 0.00054 | val_0_mse: 0.0     |  0:00:11s\n","epoch 14 | loss: 0.00052 | val_0_mse: 0.0     |  0:00:12s\n","epoch 15 | loss: 0.00051 | val_0_mse: 0.0     |  0:00:13s\n","epoch 16 | loss: 0.0005  | val_0_mse: 0.0     |  0:00:13s\n","epoch 17 | loss: 0.00049 | val_0_mse: 0.0     |  0:00:14s\n","epoch 18 | loss: 0.00048 | val_0_mse: 0.0     |  0:00:15s\n","epoch 19 | loss: 0.00048 | val_0_mse: 0.0     |  0:00:16s\n","epoch 20 | loss: 0.00047 | val_0_mse: 0.0     |  0:00:17s\n","epoch 21 | loss: 0.00045 | val_0_mse: 0.0     |  0:00:17s\n","epoch 22 | loss: 0.00044 | val_0_mse: 0.0     |  0:00:18s\n","epoch 23 | loss: 0.00043 | val_0_mse: 0.0     |  0:00:19s\n","epoch 24 | loss: 0.00043 | val_0_mse: 0.0     |  0:00:20s\n","epoch 25 | loss: 0.00042 | val_0_mse: 0.0     |  0:00:21s\n","epoch 26 | loss: 0.00041 | val_0_mse: 0.0     |  0:00:21s\n","epoch 27 | loss: 0.0004  | val_0_mse: 0.0     |  0:00:22s\n","epoch 28 | loss: 0.00038 | val_0_mse: 0.0     |  0:00:23s\n","epoch 29 | loss: 0.00037 | val_0_mse: 0.0     |  0:00:24s\n","\n","Early stopping occurred at epoch 29 with best_epoch = 19 and best_val_0_mse = 0.0\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 08:45:39,430] Trial 18 finished with value: 6.020548539709125e-07 and parameters: {'n_d': 9, 'n_steps': 5, 'gamma': 1.5791946039706086, 'n_independent': 2, 'n_shared': 4, 'momentum': 0.16075293815528197}. Best is trial 4 with value: 1.9699176334597723e-07.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 8.40472 | val_0_mse: 22.332799911499023|  0:00:01s\n","epoch 1  | loss: 23.92443| val_0_mse: 21.800939559936523|  0:00:02s\n","epoch 2  | loss: 22.80805| val_0_mse: 10.34508991241455|  0:00:03s\n","epoch 3  | loss: 6.59721 | val_0_mse: 7.443880081176758|  0:00:05s\n","epoch 4  | loss: 15.45654| val_0_mse: 4.197790145874023|  0:00:06s\n","epoch 5  | loss: 6.96742 | val_0_mse: 4.635019779205322|  0:00:07s\n","epoch 6  | loss: 1.83963 | val_0_mse: 0.8331400156021118|  0:00:09s\n","epoch 7  | loss: 0.54936 | val_0_mse: 0.15185000002384186|  0:00:10s\n","epoch 8  | loss: 1.91226 | val_0_mse: 0.4528200030326843|  0:00:11s\n","epoch 9  | loss: 1.59631 | val_0_mse: 0.08557000011205673|  0:00:13s\n","epoch 10 | loss: 0.21787 | val_0_mse: 0.07458999752998352|  0:00:14s\n","epoch 11 | loss: 0.10877 | val_0_mse: 0.01107999961823225|  0:00:15s\n","epoch 12 | loss: 0.07695 | val_0_mse: 0.00395999988541007|  0:00:17s\n","epoch 13 | loss: 0.01656 | val_0_mse: 0.0018500000005587935|  0:00:18s\n","epoch 14 | loss: 0.00567 | val_0_mse: 0.0031300000846385956|  0:00:19s\n","epoch 15 | loss: 0.00329 | val_0_mse: 0.0020800000056624413|  0:00:21s\n","epoch 16 | loss: 0.00148 | val_0_mse: 0.0006200000061653554|  0:00:22s\n","epoch 17 | loss: 0.00107 | val_0_mse: 0.0003600000054575503|  0:00:23s\n","epoch 18 | loss: 0.00083 | val_0_mse: 0.00014000000373926014|  0:00:25s\n","epoch 19 | loss: 0.0007  | val_0_mse: 0.00016999999934341758|  0:00:26s\n","epoch 20 | loss: 0.00068 | val_0_mse: 0.00018000000272877514|  0:00:27s\n","epoch 21 | loss: 0.00063 | val_0_mse: 0.00014000000373926014|  0:00:29s\n","epoch 22 | loss: 0.00074 | val_0_mse: 0.00013000000035390258|  0:00:30s\n","epoch 23 | loss: 0.00071 | val_0_mse: 9.000000136438757e-05|  0:00:31s\n","epoch 24 | loss: 0.00059 | val_0_mse: 0.00014000000373926014|  0:00:33s\n","epoch 25 | loss: 0.00045 | val_0_mse: 9.000000136438757e-05|  0:00:34s\n","epoch 26 | loss: 0.00043 | val_0_mse: 2.9999999242136255e-05|  0:00:35s\n","epoch 27 | loss: 0.00042 | val_0_mse: 2.9999999242136255e-05|  0:00:37s\n","epoch 28 | loss: 0.00039 | val_0_mse: 2.9999999242136255e-05|  0:00:38s\n","epoch 29 | loss: 0.00035 | val_0_mse: 2.9999999242136255e-05|  0:00:39s\n","epoch 30 | loss: 0.00035 | val_0_mse: 5.999999848427251e-05|  0:00:41s\n","epoch 31 | loss: 0.00035 | val_0_mse: 2.9999999242136255e-05|  0:00:42s\n","epoch 32 | loss: 0.00033 | val_0_mse: 2.9999999242136255e-05|  0:00:43s\n","epoch 33 | loss: 0.00033 | val_0_mse: 2.9999999242136255e-05|  0:00:45s\n","epoch 34 | loss: 0.0003  | val_0_mse: 2.9999999242136255e-05|  0:00:46s\n","epoch 35 | loss: 0.00029 | val_0_mse: 1.9999999494757503e-05|  0:00:48s\n","epoch 36 | loss: 0.00028 | val_0_mse: 1.9999999494757503e-05|  0:00:49s\n","epoch 37 | loss: 0.00028 | val_0_mse: 9.999999747378752e-06|  0:00:50s\n","epoch 38 | loss: 0.00027 | val_0_mse: 1.9999999494757503e-05|  0:00:52s\n","epoch 39 | loss: 0.00026 | val_0_mse: 1.9999999494757503e-05|  0:00:53s\n","epoch 40 | loss: 0.00028 | val_0_mse: 1.9999999494757503e-05|  0:00:54s\n","epoch 41 | loss: 0.00026 | val_0_mse: 1.9999999494757503e-05|  0:00:56s\n","epoch 42 | loss: 0.00025 | val_0_mse: 9.999999747378752e-06|  0:00:57s\n","epoch 43 | loss: 0.00025 | val_0_mse: 9.999999747378752e-06|  0:00:58s\n","epoch 44 | loss: 0.00025 | val_0_mse: 9.999999747378752e-06|  0:01:00s\n","epoch 45 | loss: 0.00026 | val_0_mse: 2.9999999242136255e-05|  0:01:01s\n","epoch 46 | loss: 0.00026 | val_0_mse: 1.9999999494757503e-05|  0:01:02s\n","epoch 47 | loss: 0.00025 | val_0_mse: 1.9999999494757503e-05|  0:01:04s\n","epoch 48 | loss: 0.00025 | val_0_mse: 1.9999999494757503e-05|  0:01:05s\n","epoch 49 | loss: 0.00025 | val_0_mse: 9.999999747378752e-06|  0:01:06s\n","epoch 50 | loss: 0.00024 | val_0_mse: 9.999999747378752e-06|  0:01:08s\n","epoch 51 | loss: 0.00023 | val_0_mse: 9.999999747378752e-06|  0:01:09s\n","epoch 52 | loss: 0.00023 | val_0_mse: 9.999999747378752e-06|  0:01:10s\n","epoch 53 | loss: 0.00023 | val_0_mse: 9.999999747378752e-06|  0:01:12s\n","epoch 54 | loss: 0.00023 | val_0_mse: 9.999999747378752e-06|  0:01:13s\n","epoch 55 | loss: 0.00023 | val_0_mse: 0.0     |  0:01:14s\n","epoch 56 | loss: 0.00023 | val_0_mse: 9.999999747378752e-06|  0:01:16s\n","epoch 57 | loss: 0.00023 | val_0_mse: 9.999999747378752e-06|  0:01:17s\n","epoch 58 | loss: 0.00022 | val_0_mse: 9.999999747378752e-06|  0:01:18s\n","epoch 59 | loss: 0.00022 | val_0_mse: 9.999999747378752e-06|  0:01:20s\n","epoch 60 | loss: 0.00019 | val_0_mse: 0.0     |  0:01:21s\n","epoch 61 | loss: 0.00018 | val_0_mse: 0.0     |  0:01:22s\n","epoch 62 | loss: 0.00017 | val_0_mse: 0.0     |  0:01:24s\n","epoch 63 | loss: 0.00017 | val_0_mse: 0.0     |  0:01:25s\n","epoch 64 | loss: 0.00016 | val_0_mse: 0.0     |  0:01:26s\n","epoch 65 | loss: 0.00016 | val_0_mse: 0.0     |  0:01:28s\n","epoch 66 | loss: 0.00016 | val_0_mse: 0.0     |  0:01:29s\n","epoch 67 | loss: 0.00016 | val_0_mse: 0.0     |  0:01:30s\n","epoch 68 | loss: 0.00015 | val_0_mse: 0.0     |  0:01:32s\n","epoch 69 | loss: 0.00015 | val_0_mse: 0.0     |  0:01:33s\n","epoch 70 | loss: 0.00015 | val_0_mse: 0.0     |  0:01:34s\n","epoch 71 | loss: 0.00015 | val_0_mse: 0.0     |  0:01:36s\n","epoch 72 | loss: 0.00015 | val_0_mse: 0.0     |  0:01:37s\n","epoch 73 | loss: 0.00015 | val_0_mse: 0.0     |  0:01:38s\n","epoch 74 | loss: 0.00015 | val_0_mse: 0.0     |  0:01:40s\n","epoch 75 | loss: 0.00015 | val_0_mse: 0.0     |  0:01:41s\n","epoch 76 | loss: 0.00016 | val_0_mse: 9.999999747378752e-06|  0:01:42s\n","epoch 77 | loss: 0.00016 | val_0_mse: 9.999999747378752e-06|  0:01:44s\n","epoch 78 | loss: 0.00015 | val_0_mse: 9.999999747378752e-06|  0:01:45s\n","epoch 79 | loss: 0.00015 | val_0_mse: 9.999999747378752e-06|  0:01:46s\n","epoch 80 | loss: 0.00015 | val_0_mse: 0.0     |  0:01:47s\n","epoch 81 | loss: 0.00015 | val_0_mse: 9.999999747378752e-06|  0:01:49s\n","epoch 82 | loss: 0.00015 | val_0_mse: 0.0     |  0:01:50s\n","epoch 83 | loss: 0.00015 | val_0_mse: 0.0     |  0:01:51s\n","epoch 84 | loss: 0.00014 | val_0_mse: 0.0     |  0:01:53s\n","\n","Early stopping occurred at epoch 84 with best_epoch = 74 and best_val_0_mse = 0.0\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 08:47:33,451] Trial 19 finished with value: 9.617548357709893e-07 and parameters: {'n_d': 63, 'n_steps': 9, 'gamma': 1.77661818369273, 'n_independent': 4, 'n_shared': 2, 'momentum': 0.011970609546690825}. Best is trial 4 with value: 1.9699176334597723e-07.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 4.1191  | val_0_mse: 14.712759971618652|  0:00:00s\n","epoch 1  | loss: 0.75422 | val_0_mse: 5.724820137023926|  0:00:01s\n","epoch 2  | loss: 0.74691 | val_0_mse: 1.434880018234253|  0:00:02s\n","epoch 3  | loss: 0.78304 | val_0_mse: 0.16485999524593353|  0:00:03s\n","epoch 4  | loss: 0.53316 | val_0_mse: 0.13654999434947968|  0:00:04s\n","epoch 5  | loss: 0.47717 | val_0_mse: 0.4577600061893463|  0:00:05s\n","epoch 6  | loss: 0.2799  | val_0_mse: 0.050360001623630524|  0:00:05s\n","epoch 7  | loss: 0.1803  | val_0_mse: 0.02679000049829483|  0:00:06s\n","epoch 8  | loss: 0.08879 | val_0_mse: 0.01752999983727932|  0:00:07s\n","epoch 9  | loss: 0.02861 | val_0_mse: 0.011250000447034836|  0:00:08s\n","epoch 10 | loss: 0.02434 | val_0_mse: 0.02160000056028366|  0:00:09s\n","epoch 11 | loss: 0.01864 | val_0_mse: 0.0021299999207258224|  0:00:10s\n","epoch 12 | loss: 0.00863 | val_0_mse: 0.001829999964684248|  0:00:10s\n","epoch 13 | loss: 0.00481 | val_0_mse: 0.0027600000612437725|  0:00:11s\n","epoch 14 | loss: 0.00313 | val_0_mse: 0.0007999999797903001|  0:00:12s\n","epoch 15 | loss: 0.00248 | val_0_mse: 0.0004299999854993075|  0:00:13s\n","epoch 16 | loss: 0.00181 | val_0_mse: 0.000590000010561198|  0:00:14s\n","epoch 17 | loss: 0.00127 | val_0_mse: 0.0002899999963119626|  0:00:15s\n","epoch 18 | loss: 0.00097 | val_0_mse: 0.0002699999895412475|  0:00:15s\n","epoch 19 | loss: 0.00085 | val_0_mse: 0.00044999999227002263|  0:00:16s\n","epoch 20 | loss: 0.00081 | val_0_mse: 0.0002099999983329326|  0:00:17s\n","epoch 21 | loss: 0.00072 | val_0_mse: 0.00015999999595806003|  0:00:18s\n","epoch 22 | loss: 0.00065 | val_0_mse: 0.00018000000272877514|  0:00:19s\n","epoch 23 | loss: 0.0006  | val_0_mse: 0.0001500000071246177|  0:00:20s\n","epoch 24 | loss: 0.00054 | val_0_mse: 0.00011000000085914508|  0:00:20s\n","epoch 25 | loss: 0.00052 | val_0_mse: 0.00019999999494757503|  0:00:21s\n","epoch 26 | loss: 0.00046 | val_0_mse: 9.999999747378752e-05|  0:00:22s\n","epoch 27 | loss: 0.00042 | val_0_mse: 0.0002300000051036477|  0:00:23s\n","epoch 28 | loss: 0.00035 | val_0_mse: 0.0001500000071246177|  0:00:24s\n","epoch 29 | loss: 0.00031 | val_0_mse: 0.00013000000035390258|  0:00:25s\n","epoch 30 | loss: 0.00029 | val_0_mse: 0.0002300000051036477|  0:00:25s\n","epoch 31 | loss: 0.00026 | val_0_mse: 0.00014000000373926014|  0:00:26s\n","epoch 32 | loss: 0.00026 | val_0_mse: 9.000000136438757e-05|  0:00:27s\n","epoch 33 | loss: 0.00025 | val_0_mse: 0.0001900000061141327|  0:00:28s\n","epoch 34 | loss: 0.00024 | val_0_mse: 9.999999747378752e-05|  0:00:29s\n","epoch 35 | loss: 0.00023 | val_0_mse: 0.00014000000373926014|  0:00:30s\n","epoch 36 | loss: 0.00021 | val_0_mse: 9.999999747378752e-05|  0:00:30s\n","epoch 37 | loss: 0.00021 | val_0_mse: 9.999999747378752e-05|  0:00:31s\n","epoch 38 | loss: 0.0002  | val_0_mse: 7.999999797903001e-05|  0:00:32s\n","epoch 39 | loss: 0.0002  | val_0_mse: 7.999999797903001e-05|  0:00:33s\n","epoch 40 | loss: 0.0002  | val_0_mse: 9.000000136438757e-05|  0:00:34s\n","epoch 41 | loss: 0.00019 | val_0_mse: 4.999999873689376e-05|  0:00:34s\n","epoch 42 | loss: 0.00018 | val_0_mse: 0.00011000000085914508|  0:00:35s\n","epoch 43 | loss: 0.00018 | val_0_mse: 5.999999848427251e-05|  0:00:36s\n","epoch 44 | loss: 0.00018 | val_0_mse: 0.00011999999696854502|  0:00:37s\n","epoch 45 | loss: 0.00017 | val_0_mse: 4.999999873689376e-05|  0:00:38s\n","epoch 46 | loss: 0.00017 | val_0_mse: 3.9999998989515007e-05|  0:00:39s\n","epoch 47 | loss: 0.00017 | val_0_mse: 2.9999999242136255e-05|  0:00:39s\n","epoch 48 | loss: 0.00016 | val_0_mse: 1.9999999494757503e-05|  0:00:40s\n","epoch 49 | loss: 0.00016 | val_0_mse: 2.9999999242136255e-05|  0:00:41s\n","epoch 50 | loss: 0.00016 | val_0_mse: 3.9999998989515007e-05|  0:00:42s\n","epoch 51 | loss: 0.00016 | val_0_mse: 2.9999999242136255e-05|  0:00:43s\n","epoch 52 | loss: 0.00016 | val_0_mse: 2.9999999242136255e-05|  0:00:44s\n","epoch 53 | loss: 0.00016 | val_0_mse: 3.9999998989515007e-05|  0:00:44s\n","epoch 54 | loss: 0.00016 | val_0_mse: 9.999999747378752e-06|  0:00:45s\n","epoch 55 | loss: 0.00016 | val_0_mse: 2.9999999242136255e-05|  0:00:46s\n","epoch 56 | loss: 0.00015 | val_0_mse: 1.9999999494757503e-05|  0:00:47s\n","epoch 57 | loss: 0.00015 | val_0_mse: 1.9999999494757503e-05|  0:00:48s\n","epoch 58 | loss: 0.00015 | val_0_mse: 1.9999999494757503e-05|  0:00:49s\n","epoch 59 | loss: 0.00015 | val_0_mse: 9.999999747378752e-06|  0:00:49s\n","epoch 60 | loss: 0.00014 | val_0_mse: 9.999999747378752e-06|  0:00:50s\n","epoch 61 | loss: 0.00014 | val_0_mse: 9.999999747378752e-06|  0:00:51s\n","epoch 62 | loss: 0.00014 | val_0_mse: 9.999999747378752e-06|  0:00:52s\n","epoch 63 | loss: 0.00014 | val_0_mse: 9.999999747378752e-06|  0:00:53s\n","epoch 64 | loss: 0.00014 | val_0_mse: 0.0     |  0:00:54s\n","epoch 65 | loss: 0.00014 | val_0_mse: 9.999999747378752e-06|  0:00:54s\n","epoch 66 | loss: 0.00014 | val_0_mse: 0.0     |  0:00:55s\n","epoch 67 | loss: 0.00013 | val_0_mse: 9.999999747378752e-06|  0:00:56s\n","epoch 68 | loss: 0.00014 | val_0_mse: 0.0     |  0:00:57s\n","epoch 69 | loss: 0.00013 | val_0_mse: 0.0     |  0:00:58s\n","epoch 70 | loss: 0.00014 | val_0_mse: 0.0     |  0:00:58s\n","epoch 71 | loss: 0.00013 | val_0_mse: 0.0     |  0:00:59s\n","epoch 72 | loss: 0.00013 | val_0_mse: 0.0     |  0:01:00s\n","epoch 73 | loss: 0.00013 | val_0_mse: 0.0     |  0:01:01s\n","epoch 74 | loss: 0.00013 | val_0_mse: 0.0     |  0:01:02s\n","epoch 75 | loss: 0.00014 | val_0_mse: 0.0     |  0:01:02s\n","epoch 76 | loss: 0.00014 | val_0_mse: 0.0     |  0:01:03s\n","epoch 77 | loss: 0.00014 | val_0_mse: 0.0     |  0:01:04s\n","epoch 78 | loss: 0.00014 | val_0_mse: 0.0     |  0:01:05s\n","epoch 79 | loss: 0.00014 | val_0_mse: 0.0     |  0:01:06s\n","epoch 80 | loss: 0.00015 | val_0_mse: 0.0     |  0:01:07s\n","epoch 81 | loss: 0.00014 | val_0_mse: 0.0     |  0:01:07s\n","epoch 82 | loss: 0.00014 | val_0_mse: 0.0     |  0:01:08s\n","epoch 83 | loss: 0.00014 | val_0_mse: 0.0     |  0:01:09s\n","epoch 84 | loss: 0.00014 | val_0_mse: 0.0     |  0:01:10s\n","epoch 85 | loss: 0.00014 | val_0_mse: 0.0     |  0:01:11s\n","epoch 86 | loss: 0.00014 | val_0_mse: 0.0     |  0:01:12s\n","epoch 87 | loss: 0.00014 | val_0_mse: 0.0     |  0:01:12s\n","epoch 88 | loss: 0.00014 | val_0_mse: 0.0     |  0:01:13s\n","epoch 89 | loss: 0.00015 | val_0_mse: 0.0     |  0:01:14s\n","epoch 90 | loss: 0.00019 | val_0_mse: 0.0     |  0:01:15s\n","epoch 91 | loss: 0.0002  | val_0_mse: 0.0     |  0:01:16s\n","epoch 92 | loss: 0.0002  | val_0_mse: 0.0     |  0:01:17s\n","epoch 93 | loss: 0.0002  | val_0_mse: 0.0     |  0:01:17s\n","epoch 94 | loss: 0.00019 | val_0_mse: 0.0     |  0:01:18s\n","epoch 95 | loss: 0.00019 | val_0_mse: 0.0     |  0:01:19s\n","epoch 96 | loss: 0.00019 | val_0_mse: 0.0     |  0:01:20s\n","epoch 97 | loss: 0.00016 | val_0_mse: 0.0     |  0:01:21s\n","epoch 98 | loss: 0.00016 | val_0_mse: 0.0     |  0:01:22s\n","epoch 99 | loss: 0.00016 | val_0_mse: 0.0     |  0:01:22s\n","Stop training because you reached max_epochs = 100 with best_epoch = 98 and best_val_0_mse = 0.0\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 08:48:56,855] Trial 20 finished with value: 1.2763081258526654e-07 and parameters: {'n_d': 35, 'n_steps': 7, 'gamma': 1.9187448447979616, 'n_independent': 1, 'n_shared': 3, 'momentum': 0.2539679747829539}. Best is trial 20 with value: 1.2763081258526654e-07.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 3.83708 | val_0_mse: 3.3669300079345703|  0:00:00s\n","epoch 1  | loss: 1.02238 | val_0_mse: 8.143830299377441|  0:00:01s\n","epoch 2  | loss: 0.82913 | val_0_mse: 1.1121100187301636|  0:00:02s\n","epoch 3  | loss: 0.69951 | val_0_mse: 0.23197999596595764|  0:00:03s\n","epoch 4  | loss: 0.32811 | val_0_mse: 0.1699499934911728|  0:00:04s\n","epoch 5  | loss: 0.22636 | val_0_mse: 0.30803000926971436|  0:00:04s\n","epoch 6  | loss: 0.1765  | val_0_mse: 0.06778000295162201|  0:00:05s\n","epoch 7  | loss: 0.10929 | val_0_mse: 0.05375999957323074|  0:00:06s\n","epoch 8  | loss: 0.16767 | val_0_mse: 0.1889999955892563|  0:00:07s\n","epoch 9  | loss: 0.1299  | val_0_mse: 0.05446000024676323|  0:00:08s\n","epoch 10 | loss: 0.03238 | val_0_mse: 0.0064500002190470695|  0:00:09s\n","epoch 11 | loss: 0.01175 | val_0_mse: 0.003590000094845891|  0:00:09s\n","epoch 12 | loss: 0.00597 | val_0_mse: 0.0014199999859556556|  0:00:10s\n","epoch 13 | loss: 0.00361 | val_0_mse: 0.0005699999746866524|  0:00:11s\n","epoch 14 | loss: 0.00229 | val_0_mse: 0.0006200000061653554|  0:00:12s\n","epoch 15 | loss: 0.00174 | val_0_mse: 0.0006099999882280827|  0:00:13s\n","epoch 16 | loss: 0.00129 | val_0_mse: 0.0003800000122282654|  0:00:13s\n","epoch 17 | loss: 0.00112 | val_0_mse: 0.0003499999875202775|  0:00:14s\n","epoch 18 | loss: 0.0009  | val_0_mse: 0.00018000000272877514|  0:00:15s\n","epoch 19 | loss: 0.00079 | val_0_mse: 0.0001900000061141327|  0:00:16s\n","epoch 20 | loss: 0.00067 | val_0_mse: 0.00013000000035390258|  0:00:17s\n","epoch 21 | loss: 0.00067 | val_0_mse: 0.00011000000085914508|  0:00:18s\n","epoch 22 | loss: 0.00073 | val_0_mse: 0.00018000000272877514|  0:00:19s\n","epoch 23 | loss: 0.00066 | val_0_mse: 0.00013000000035390258|  0:00:20s\n","epoch 24 | loss: 0.00063 | val_0_mse: 9.000000136438757e-05|  0:00:20s\n","epoch 25 | loss: 0.00058 | val_0_mse: 7.999999797903001e-05|  0:00:21s\n","epoch 26 | loss: 0.00052 | val_0_mse: 0.00014000000373926014|  0:00:22s\n","epoch 27 | loss: 0.00048 | val_0_mse: 9.000000136438757e-05|  0:00:23s\n","epoch 28 | loss: 0.00045 | val_0_mse: 5.999999848427251e-05|  0:00:24s\n","epoch 29 | loss: 0.00043 | val_0_mse: 9.000000136438757e-05|  0:00:24s\n","epoch 30 | loss: 0.00043 | val_0_mse: 9.000000136438757e-05|  0:00:25s\n","epoch 31 | loss: 0.00046 | val_0_mse: 9.000000136438757e-05|  0:00:26s\n","epoch 32 | loss: 0.00043 | val_0_mse: 7.999999797903001e-05|  0:00:27s\n","epoch 33 | loss: 0.00042 | val_0_mse: 9.999999747378752e-05|  0:00:28s\n","epoch 34 | loss: 0.0004  | val_0_mse: 7.000000186963007e-05|  0:00:29s\n","epoch 35 | loss: 0.00039 | val_0_mse: 0.00011000000085914508|  0:00:29s\n","epoch 36 | loss: 0.00036 | val_0_mse: 7.000000186963007e-05|  0:00:30s\n","epoch 37 | loss: 0.00033 | val_0_mse: 7.000000186963007e-05|  0:00:31s\n","epoch 38 | loss: 0.00033 | val_0_mse: 9.000000136438757e-05|  0:00:32s\n","\n","Early stopping occurred at epoch 38 with best_epoch = 28 and best_val_0_mse = 5.999999848427251e-05\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 08:49:29,738] Trial 21 finished with value: 5.6753589888103306e-05 and parameters: {'n_d': 34, 'n_steps': 7, 'gamma': 1.917861846956097, 'n_independent': 1, 'n_shared': 3, 'momentum': 0.2548829172242266}. Best is trial 20 with value: 1.2763081258526654e-07.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 1.7777  | val_0_mse: 8.162879943847656|  0:00:00s\n","epoch 1  | loss: 0.77638 | val_0_mse: 1.274649977684021|  0:00:01s\n","epoch 2  | loss: 0.35785 | val_0_mse: 2.007689952850342|  0:00:02s\n","epoch 3  | loss: 0.23014 | val_0_mse: 0.32519999146461487|  0:00:02s\n","epoch 4  | loss: 0.29008 | val_0_mse: 0.5797200202941895|  0:00:03s\n","epoch 5  | loss: 0.35179 | val_0_mse: 0.009870000183582306|  0:00:04s\n","epoch 6  | loss: 0.12267 | val_0_mse: 0.00686000008136034|  0:00:05s\n","epoch 7  | loss: 0.0856  | val_0_mse: 0.0018899999558925629|  0:00:05s\n","epoch 8  | loss: 0.02858 | val_0_mse: 0.0027000000700354576|  0:00:06s\n","epoch 9  | loss: 0.02052 | val_0_mse: 0.0006200000061653554|  0:00:07s\n","epoch 10 | loss: 0.01069 | val_0_mse: 0.0007300000288523734|  0:00:08s\n","epoch 11 | loss: 0.00539 | val_0_mse: 0.00033999999868683517|  0:00:08s\n","epoch 12 | loss: 0.00299 | val_0_mse: 0.00022000000171829015|  0:00:09s\n","epoch 13 | loss: 0.00187 | val_0_mse: 0.00016999999934341758|  0:00:10s\n","epoch 14 | loss: 0.00133 | val_0_mse: 0.00016999999934341758|  0:00:10s\n","epoch 15 | loss: 0.00117 | val_0_mse: 0.00011999999696854502|  0:00:11s\n","epoch 16 | loss: 0.00101 | val_0_mse: 9.999999747378752e-05|  0:00:12s\n","epoch 17 | loss: 0.00085 | val_0_mse: 0.00011000000085914508|  0:00:13s\n","epoch 18 | loss: 0.00083 | val_0_mse: 9.000000136438757e-05|  0:00:13s\n","epoch 19 | loss: 0.00075 | val_0_mse: 9.999999747378752e-05|  0:00:14s\n","epoch 20 | loss: 0.0007  | val_0_mse: 7.000000186963007e-05|  0:00:15s\n","epoch 21 | loss: 0.00062 | val_0_mse: 7.999999797903001e-05|  0:00:15s\n","epoch 22 | loss: 0.00058 | val_0_mse: 7.000000186963007e-05|  0:00:16s\n","epoch 23 | loss: 0.00051 | val_0_mse: 4.999999873689376e-05|  0:00:17s\n","epoch 24 | loss: 0.00048 | val_0_mse: 3.9999998989515007e-05|  0:00:18s\n","epoch 25 | loss: 0.00047 | val_0_mse: 5.999999848427251e-05|  0:00:19s\n","epoch 26 | loss: 0.00049 | val_0_mse: 4.999999873689376e-05|  0:00:19s\n","epoch 27 | loss: 0.00047 | val_0_mse: 7.000000186963007e-05|  0:00:20s\n","epoch 28 | loss: 0.00043 | val_0_mse: 4.999999873689376e-05|  0:00:21s\n","epoch 29 | loss: 0.00042 | val_0_mse: 4.999999873689376e-05|  0:00:22s\n","epoch 30 | loss: 0.00044 | val_0_mse: 7.000000186963007e-05|  0:00:22s\n","epoch 31 | loss: 0.00048 | val_0_mse: 3.9999998989515007e-05|  0:00:23s\n","epoch 32 | loss: 0.00044 | val_0_mse: 2.9999999242136255e-05|  0:00:24s\n","epoch 33 | loss: 0.00043 | val_0_mse: 2.9999999242136255e-05|  0:00:24s\n","epoch 34 | loss: 0.00038 | val_0_mse: 1.9999999494757503e-05|  0:00:25s\n","epoch 35 | loss: 0.00035 | val_0_mse: 1.9999999494757503e-05|  0:00:26s\n","epoch 36 | loss: 0.00035 | val_0_mse: 1.9999999494757503e-05|  0:00:27s\n","epoch 37 | loss: 0.00032 | val_0_mse: 1.9999999494757503e-05|  0:00:27s\n","epoch 38 | loss: 0.00031 | val_0_mse: 1.9999999494757503e-05|  0:00:28s\n","epoch 39 | loss: 0.00029 | val_0_mse: 9.999999747378752e-06|  0:00:29s\n","epoch 40 | loss: 0.00028 | val_0_mse: 9.999999747378752e-06|  0:00:30s\n","epoch 41 | loss: 0.00028 | val_0_mse: 9.999999747378752e-06|  0:00:31s\n","epoch 42 | loss: 0.00027 | val_0_mse: 9.999999747378752e-06|  0:00:31s\n","epoch 43 | loss: 0.00027 | val_0_mse: 9.999999747378752e-06|  0:00:32s\n","epoch 44 | loss: 0.00026 | val_0_mse: 9.999999747378752e-06|  0:00:33s\n","epoch 45 | loss: 0.00025 | val_0_mse: 9.999999747378752e-06|  0:00:33s\n","epoch 46 | loss: 0.00024 | val_0_mse: 9.999999747378752e-06|  0:00:34s\n","epoch 47 | loss: 0.00024 | val_0_mse: 9.999999747378752e-06|  0:00:35s\n","epoch 48 | loss: 0.00023 | val_0_mse: 9.999999747378752e-06|  0:00:36s\n","epoch 49 | loss: 0.00023 | val_0_mse: 9.999999747378752e-06|  0:00:36s\n","epoch 50 | loss: 0.00022 | val_0_mse: 9.999999747378752e-06|  0:00:37s\n","epoch 51 | loss: 0.00022 | val_0_mse: 9.999999747378752e-06|  0:00:38s\n","epoch 52 | loss: 0.00022 | val_0_mse: 0.0     |  0:00:38s\n","epoch 53 | loss: 0.00021 | val_0_mse: 9.999999747378752e-06|  0:00:39s\n","epoch 54 | loss: 0.00021 | val_0_mse: 0.0     |  0:00:40s\n","epoch 55 | loss: 0.00021 | val_0_mse: 0.0     |  0:00:41s\n","epoch 56 | loss: 0.0002  | val_0_mse: 0.0     |  0:00:41s\n","epoch 57 | loss: 0.0002  | val_0_mse: 0.0     |  0:00:42s\n","epoch 58 | loss: 0.0002  | val_0_mse: 0.0     |  0:00:43s\n","epoch 59 | loss: 0.0002  | val_0_mse: 0.0     |  0:00:44s\n","epoch 60 | loss: 0.0002  | val_0_mse: 0.0     |  0:00:44s\n","epoch 61 | loss: 0.0002  | val_0_mse: 0.0     |  0:00:45s\n","epoch 62 | loss: 0.0002  | val_0_mse: 0.0     |  0:00:46s\n","epoch 63 | loss: 0.00019 | val_0_mse: 0.0     |  0:00:46s\n","epoch 64 | loss: 0.00019 | val_0_mse: 0.0     |  0:00:47s\n","epoch 65 | loss: 0.00019 | val_0_mse: 0.0     |  0:00:48s\n","epoch 66 | loss: 0.00019 | val_0_mse: 0.0     |  0:00:49s\n","epoch 67 | loss: 0.00019 | val_0_mse: 0.0     |  0:00:49s\n","epoch 68 | loss: 0.00019 | val_0_mse: 0.0     |  0:00:50s\n","epoch 69 | loss: 0.00019 | val_0_mse: 0.0     |  0:00:51s\n","epoch 70 | loss: 0.00019 | val_0_mse: 0.0     |  0:00:52s\n","epoch 71 | loss: 0.00019 | val_0_mse: 0.0     |  0:00:52s\n","epoch 72 | loss: 0.00019 | val_0_mse: 0.0     |  0:00:53s\n","epoch 73 | loss: 0.00019 | val_0_mse: 0.0     |  0:00:54s\n","epoch 74 | loss: 0.00019 | val_0_mse: 0.0     |  0:00:55s\n","epoch 75 | loss: 0.00019 | val_0_mse: 0.0     |  0:00:55s\n","epoch 76 | loss: 0.00018 | val_0_mse: 0.0     |  0:00:56s\n","epoch 77 | loss: 0.00019 | val_0_mse: 0.0     |  0:00:57s\n","epoch 78 | loss: 0.00018 | val_0_mse: 0.0     |  0:00:57s\n","epoch 79 | loss: 0.00018 | val_0_mse: 0.0     |  0:00:58s\n","epoch 80 | loss: 0.00018 | val_0_mse: 0.0     |  0:00:59s\n","epoch 81 | loss: 0.00018 | val_0_mse: 0.0     |  0:01:00s\n","epoch 82 | loss: 0.00018 | val_0_mse: 0.0     |  0:01:00s\n","epoch 83 | loss: 0.00018 | val_0_mse: 0.0     |  0:01:01s\n","epoch 84 | loss: 0.00018 | val_0_mse: 0.0     |  0:01:02s\n","epoch 85 | loss: 0.00018 | val_0_mse: 0.0     |  0:01:03s\n","epoch 86 | loss: 0.00018 | val_0_mse: 0.0     |  0:01:03s\n","epoch 87 | loss: 0.00018 | val_0_mse: 0.0     |  0:01:04s\n","epoch 88 | loss: 0.00018 | val_0_mse: 0.0     |  0:01:05s\n","epoch 89 | loss: 0.00017 | val_0_mse: 0.0     |  0:01:05s\n","epoch 90 | loss: 0.00017 | val_0_mse: 0.0     |  0:01:06s\n","epoch 91 | loss: 0.00017 | val_0_mse: 0.0     |  0:01:07s\n","epoch 92 | loss: 0.00017 | val_0_mse: 0.0     |  0:01:08s\n","epoch 93 | loss: 0.00017 | val_0_mse: 0.0     |  0:01:08s\n","epoch 94 | loss: 0.00017 | val_0_mse: 0.0     |  0:01:09s\n","epoch 95 | loss: 0.00017 | val_0_mse: 0.0     |  0:01:10s\n","epoch 96 | loss: 0.00017 | val_0_mse: 0.0     |  0:01:11s\n","epoch 97 | loss: 0.00017 | val_0_mse: 0.0     |  0:01:11s\n","epoch 98 | loss: 0.00017 | val_0_mse: 0.0     |  0:01:12s\n","epoch 99 | loss: 0.00017 | val_0_mse: 0.0     |  0:01:13s\n","Stop training because you reached max_epochs = 100 with best_epoch = 96 and best_val_0_mse = 0.0\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 08:50:43,453] Trial 22 finished with value: 3.4327615594520466e-07 and parameters: {'n_d': 21, 'n_steps': 6, 'gamma': 1.9981737202234586, 'n_independent': 1, 'n_shared': 3, 'momentum': 0.17661613519894948}. Best is trial 20 with value: 1.2763081258526654e-07.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 6.19133 | val_0_mse: 8.090069770812988|  0:00:00s\n","epoch 1  | loss: 0.77862 | val_0_mse: 6.275469779968262|  0:00:01s\n","epoch 2  | loss: 0.33181 | val_0_mse: 3.326849937438965|  0:00:02s\n","epoch 3  | loss: 0.15422 | val_0_mse: 0.2766999900341034|  0:00:03s\n","epoch 4  | loss: 0.05262 | val_0_mse: 0.11403000354766846|  0:00:04s\n","epoch 5  | loss: 0.04693 | val_0_mse: 0.015209999866783619|  0:00:05s\n","epoch 6  | loss: 0.01683 | val_0_mse: 0.005429999902844429|  0:00:06s\n","epoch 7  | loss: 0.00599 | val_0_mse: 0.0028200000524520874|  0:00:06s\n","epoch 8  | loss: 0.00181 | val_0_mse: 0.0008399999933317304|  0:00:07s\n","epoch 9  | loss: 0.0008  | val_0_mse: 0.0002300000051036477|  0:00:08s\n","epoch 10 | loss: 0.00052 | val_0_mse: 7.000000186963007e-05|  0:00:09s\n","epoch 11 | loss: 0.00032 | val_0_mse: 3.9999998989515007e-05|  0:00:10s\n","epoch 12 | loss: 0.00026 | val_0_mse: 1.9999999494757503e-05|  0:00:11s\n","epoch 13 | loss: 0.00023 | val_0_mse: 9.999999747378752e-06|  0:00:12s\n","epoch 14 | loss: 0.00022 | val_0_mse: 9.999999747378752e-06|  0:00:12s\n","epoch 15 | loss: 0.00021 | val_0_mse: 9.999999747378752e-06|  0:00:13s\n","epoch 16 | loss: 0.00021 | val_0_mse: 0.0     |  0:00:14s\n","epoch 17 | loss: 0.0002  | val_0_mse: 0.0     |  0:00:15s\n","epoch 18 | loss: 0.0002  | val_0_mse: 0.0     |  0:00:16s\n","epoch 19 | loss: 0.0002  | val_0_mse: 0.0     |  0:00:17s\n","epoch 20 | loss: 0.0002  | val_0_mse: 0.0     |  0:00:17s\n","epoch 21 | loss: 0.00019 | val_0_mse: 0.0     |  0:00:18s\n","epoch 22 | loss: 0.00019 | val_0_mse: 0.0     |  0:00:19s\n","epoch 23 | loss: 0.0002  | val_0_mse: 0.0     |  0:00:20s\n","epoch 24 | loss: 0.0002  | val_0_mse: 0.0     |  0:00:21s\n","epoch 25 | loss: 0.00019 | val_0_mse: 0.0     |  0:00:22s\n","epoch 26 | loss: 0.00019 | val_0_mse: 0.0     |  0:00:22s\n","epoch 27 | loss: 0.00019 | val_0_mse: 0.0     |  0:00:23s\n","epoch 28 | loss: 0.00019 | val_0_mse: 0.0     |  0:00:24s\n","epoch 29 | loss: 0.00019 | val_0_mse: 0.0     |  0:00:25s\n","epoch 30 | loss: 0.00019 | val_0_mse: 0.0     |  0:00:26s\n","epoch 31 | loss: 0.00019 | val_0_mse: 0.0     |  0:00:27s\n","epoch 32 | loss: 0.00019 | val_0_mse: 0.0     |  0:00:27s\n","epoch 33 | loss: 0.00019 | val_0_mse: 0.0     |  0:00:28s\n","epoch 34 | loss: 0.00019 | val_0_mse: 0.0     |  0:00:29s\n","epoch 35 | loss: 0.00018 | val_0_mse: 0.0     |  0:00:30s\n","epoch 36 | loss: 0.00018 | val_0_mse: 0.0     |  0:00:31s\n","epoch 37 | loss: 0.00018 | val_0_mse: 0.0     |  0:00:32s\n","epoch 38 | loss: 0.00018 | val_0_mse: 0.0     |  0:00:32s\n","epoch 39 | loss: 0.00018 | val_0_mse: 0.0     |  0:00:33s\n","epoch 40 | loss: 0.00018 | val_0_mse: 0.0     |  0:00:34s\n","epoch 41 | loss: 0.00018 | val_0_mse: 0.0     |  0:00:35s\n","epoch 42 | loss: 0.00018 | val_0_mse: 0.0     |  0:00:36s\n","epoch 43 | loss: 0.00018 | val_0_mse: 0.0     |  0:00:37s\n","epoch 44 | loss: 0.00018 | val_0_mse: 0.0     |  0:00:38s\n","epoch 45 | loss: 0.00018 | val_0_mse: 0.0     |  0:00:39s\n","epoch 46 | loss: 0.00018 | val_0_mse: 0.0     |  0:00:39s\n","epoch 47 | loss: 0.00018 | val_0_mse: 0.0     |  0:00:40s\n","epoch 48 | loss: 0.00018 | val_0_mse: 0.0     |  0:00:41s\n","epoch 49 | loss: 0.00018 | val_0_mse: 0.0     |  0:00:42s\n","\n","Early stopping occurred at epoch 49 with best_epoch = 39 and best_val_0_mse = 0.0\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 08:51:26,304] Trial 23 finished with value: 3.200838705197384e-07 and parameters: {'n_d': 22, 'n_steps': 6, 'gamma': 1.9928603425664952, 'n_independent': 2, 'n_shared': 3, 'momentum': 0.18051351509211205}. Best is trial 20 with value: 1.2763081258526654e-07.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 7.45804 | val_0_mse: 8.815309524536133|  0:00:00s\n","epoch 1  | loss: 1.40312 | val_0_mse: 0.783490002155304|  0:00:01s\n","epoch 2  | loss: 0.73369 | val_0_mse: 0.6382799744606018|  0:00:02s\n","epoch 3  | loss: 1.06504 | val_0_mse: 0.6449000239372253|  0:00:03s\n","epoch 4  | loss: 0.70462 | val_0_mse: 0.06741999834775925|  0:00:04s\n","epoch 5  | loss: 0.1663  | val_0_mse: 0.10599999874830246|  0:00:05s\n","epoch 6  | loss: 0.25147 | val_0_mse: 0.35273000597953796|  0:00:06s\n","epoch 7  | loss: 0.05329 | val_0_mse: 0.018219999969005585|  0:00:07s\n","epoch 8  | loss: 0.03362 | val_0_mse: 0.011409999802708626|  0:00:08s\n","epoch 9  | loss: 0.01267 | val_0_mse: 0.01979999989271164|  0:00:09s\n","epoch 10 | loss: 0.00434 | val_0_mse: 0.0023799999617040157|  0:00:10s\n","epoch 11 | loss: 0.0021  | val_0_mse: 0.0008200000156648457|  0:00:11s\n","epoch 12 | loss: 0.00125 | val_0_mse: 0.00019999999494757503|  0:00:12s\n","epoch 13 | loss: 0.00088 | val_0_mse: 0.00033999999868683517|  0:00:13s\n","epoch 14 | loss: 0.00074 | val_0_mse: 0.00015999999595806003|  0:00:14s\n","epoch 15 | loss: 0.00067 | val_0_mse: 0.00033000000985339284|  0:00:15s\n","epoch 16 | loss: 0.00063 | val_0_mse: 0.00016999999934341758|  0:00:16s\n","epoch 17 | loss: 0.00056 | val_0_mse: 9.000000136438757e-05|  0:00:17s\n","epoch 18 | loss: 0.00052 | val_0_mse: 5.999999848427251e-05|  0:00:18s\n","epoch 19 | loss: 0.00049 | val_0_mse: 9.000000136438757e-05|  0:00:19s\n","epoch 20 | loss: 0.00048 | val_0_mse: 7.999999797903001e-05|  0:00:20s\n","epoch 21 | loss: 0.00047 | val_0_mse: 3.9999998989515007e-05|  0:00:20s\n","epoch 22 | loss: 0.00048 | val_0_mse: 5.999999848427251e-05|  0:00:21s\n","epoch 23 | loss: 0.00045 | val_0_mse: 2.9999999242136255e-05|  0:00:22s\n","epoch 24 | loss: 0.00038 | val_0_mse: 2.9999999242136255e-05|  0:00:23s\n","epoch 25 | loss: 0.00034 | val_0_mse: 2.9999999242136255e-05|  0:00:24s\n","epoch 26 | loss: 0.00033 | val_0_mse: 2.9999999242136255e-05|  0:00:25s\n","epoch 27 | loss: 0.00034 | val_0_mse: 2.9999999242136255e-05|  0:00:26s\n","epoch 28 | loss: 0.00031 | val_0_mse: 1.9999999494757503e-05|  0:00:27s\n","epoch 29 | loss: 0.00032 | val_0_mse: 1.9999999494757503e-05|  0:00:28s\n","epoch 30 | loss: 0.00033 | val_0_mse: 1.9999999494757503e-05|  0:00:29s\n","epoch 31 | loss: 0.00032 | val_0_mse: 3.9999998989515007e-05|  0:00:30s\n","epoch 32 | loss: 0.00033 | val_0_mse: 1.9999999494757503e-05|  0:00:31s\n","epoch 33 | loss: 0.00034 | val_0_mse: 1.9999999494757503e-05|  0:00:32s\n","epoch 34 | loss: 0.0003  | val_0_mse: 1.9999999494757503e-05|  0:00:33s\n","epoch 35 | loss: 0.0003  | val_0_mse: 1.9999999494757503e-05|  0:00:34s\n","epoch 36 | loss: 0.0003  | val_0_mse: 1.9999999494757503e-05|  0:00:35s\n","epoch 37 | loss: 0.00031 | val_0_mse: 1.9999999494757503e-05|  0:00:36s\n","epoch 38 | loss: 0.0003  | val_0_mse: 1.9999999494757503e-05|  0:00:37s\n","epoch 39 | loss: 0.0003  | val_0_mse: 9.999999747378752e-06|  0:00:38s\n","epoch 40 | loss: 0.00028 | val_0_mse: 9.999999747378752e-06|  0:00:39s\n","epoch 41 | loss: 0.00027 | val_0_mse: 9.999999747378752e-06|  0:00:40s\n","epoch 42 | loss: 0.00027 | val_0_mse: 9.999999747378752e-06|  0:00:41s\n","epoch 43 | loss: 0.00027 | val_0_mse: 9.999999747378752e-06|  0:00:42s\n","epoch 44 | loss: 0.00026 | val_0_mse: 9.999999747378752e-06|  0:00:43s\n","epoch 45 | loss: 0.00026 | val_0_mse: 9.999999747378752e-06|  0:00:43s\n","epoch 46 | loss: 0.00026 | val_0_mse: 9.999999747378752e-06|  0:00:44s\n","epoch 47 | loss: 0.00026 | val_0_mse: 9.999999747378752e-06|  0:00:45s\n","epoch 48 | loss: 0.00026 | val_0_mse: 9.999999747378752e-06|  0:00:46s\n","epoch 49 | loss: 0.00025 | val_0_mse: 9.999999747378752e-06|  0:00:47s\n","epoch 50 | loss: 0.00025 | val_0_mse: 9.999999747378752e-06|  0:00:48s\n","epoch 51 | loss: 0.00025 | val_0_mse: 9.999999747378752e-06|  0:00:49s\n","epoch 52 | loss: 0.00024 | val_0_mse: 9.999999747378752e-06|  0:00:50s\n","epoch 53 | loss: 0.00024 | val_0_mse: 9.999999747378752e-06|  0:00:51s\n","epoch 54 | loss: 0.00025 | val_0_mse: 9.999999747378752e-06|  0:00:52s\n","epoch 55 | loss: 0.00024 | val_0_mse: 9.999999747378752e-06|  0:00:53s\n","epoch 56 | loss: 0.00024 | val_0_mse: 9.999999747378752e-06|  0:00:54s\n","epoch 57 | loss: 0.00023 | val_0_mse: 0.0     |  0:00:55s\n","epoch 58 | loss: 0.00023 | val_0_mse: 9.999999747378752e-06|  0:00:56s\n","epoch 59 | loss: 0.00023 | val_0_mse: 9.999999747378752e-06|  0:00:57s\n","epoch 60 | loss: 0.00023 | val_0_mse: 9.999999747378752e-06|  0:00:58s\n","epoch 61 | loss: 0.00023 | val_0_mse: 9.999999747378752e-06|  0:00:59s\n","epoch 62 | loss: 0.00023 | val_0_mse: 0.0     |  0:00:59s\n","epoch 63 | loss: 0.00023 | val_0_mse: 0.0     |  0:01:00s\n","epoch 64 | loss: 0.00022 | val_0_mse: 0.0     |  0:01:01s\n","epoch 65 | loss: 0.00022 | val_0_mse: 9.999999747378752e-06|  0:01:02s\n","epoch 66 | loss: 0.00021 | val_0_mse: 0.0     |  0:01:03s\n","epoch 67 | loss: 0.00021 | val_0_mse: 0.0     |  0:01:04s\n","epoch 68 | loss: 0.00021 | val_0_mse: 0.0     |  0:01:05s\n","epoch 69 | loss: 0.00021 | val_0_mse: 0.0     |  0:01:06s\n","epoch 70 | loss: 0.00021 | val_0_mse: 0.0     |  0:01:07s\n","epoch 71 | loss: 0.00021 | val_0_mse: 0.0     |  0:01:08s\n","epoch 72 | loss: 0.00021 | val_0_mse: 0.0     |  0:01:08s\n","epoch 73 | loss: 0.00021 | val_0_mse: 0.0     |  0:01:09s\n","epoch 74 | loss: 0.00021 | val_0_mse: 0.0     |  0:01:10s\n","epoch 75 | loss: 0.0002  | val_0_mse: 0.0     |  0:01:11s\n","epoch 76 | loss: 0.0002  | val_0_mse: 0.0     |  0:01:12s\n","epoch 77 | loss: 0.0002  | val_0_mse: 0.0     |  0:01:13s\n","epoch 78 | loss: 0.0002  | val_0_mse: 0.0     |  0:01:14s\n","epoch 79 | loss: 0.0002  | val_0_mse: 0.0     |  0:01:15s\n","epoch 80 | loss: 0.0002  | val_0_mse: 0.0     |  0:01:16s\n","epoch 81 | loss: 0.0002  | val_0_mse: 0.0     |  0:01:17s\n","epoch 82 | loss: 0.0002  | val_0_mse: 9.999999747378752e-06|  0:01:17s\n","epoch 83 | loss: 0.0002  | val_0_mse: 0.0     |  0:01:18s\n","epoch 84 | loss: 0.0002  | val_0_mse: 0.0     |  0:01:19s\n","epoch 85 | loss: 0.00019 | val_0_mse: 0.0     |  0:01:20s\n","epoch 86 | loss: 0.00019 | val_0_mse: 0.0     |  0:01:21s\n","epoch 87 | loss: 0.00019 | val_0_mse: 0.0     |  0:01:22s\n","epoch 88 | loss: 0.00019 | val_0_mse: 0.0     |  0:01:23s\n","epoch 89 | loss: 0.00019 | val_0_mse: 0.0     |  0:01:24s\n","epoch 90 | loss: 0.00019 | val_0_mse: 0.0     |  0:01:25s\n","epoch 91 | loss: 0.00019 | val_0_mse: 0.0     |  0:01:26s\n","epoch 92 | loss: 0.00019 | val_0_mse: 0.0     |  0:01:27s\n","epoch 93 | loss: 0.00019 | val_0_mse: 0.0     |  0:01:27s\n","epoch 94 | loss: 0.00019 | val_0_mse: 0.0     |  0:01:28s\n","epoch 95 | loss: 0.00019 | val_0_mse: 0.0     |  0:01:29s\n","epoch 96 | loss: 0.00018 | val_0_mse: 0.0     |  0:01:30s\n","epoch 97 | loss: 0.00018 | val_0_mse: 0.0     |  0:01:31s\n","epoch 98 | loss: 0.00018 | val_0_mse: 9.999999747378752e-06|  0:01:32s\n","epoch 99 | loss: 0.00027 | val_0_mse: 0.00013000000035390258|  0:01:33s\n","Stop training because you reached max_epochs = 100 with best_epoch = 97 and best_val_0_mse = 0.0\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 08:53:00,075] Trial 24 finished with value: 4.55115355180169e-07 and parameters: {'n_d': 29, 'n_steps': 6, 'gamma': 1.757359405096942, 'n_independent': 2, 'n_shared': 4, 'momentum': 0.12094229586674937}. Best is trial 20 with value: 1.2763081258526654e-07.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 11.57366| val_0_mse: 11.957839965820312|  0:00:00s\n","epoch 1  | loss: 3.60972 | val_0_mse: 2.338639974594116|  0:00:01s\n","epoch 2  | loss: 3.98226 | val_0_mse: 0.3929699957370758|  0:00:02s\n","epoch 3  | loss: 2.28854 | val_0_mse: 0.5494499802589417|  0:00:03s\n","epoch 4  | loss: 3.0107  | val_0_mse: 1.2839299440383911|  0:00:04s\n","epoch 5  | loss: 0.80672 | val_0_mse: 0.4348300099372864|  0:00:05s\n","epoch 6  | loss: 0.32043 | val_0_mse: 0.07342000305652618|  0:00:06s\n","epoch 7  | loss: 0.42027 | val_0_mse: 0.13697999715805054|  0:00:07s\n","epoch 8  | loss: 0.23743 | val_0_mse: 0.12506000697612762|  0:00:08s\n","epoch 9  | loss: 0.42623 | val_0_mse: 0.056620001792907715|  0:00:09s\n","epoch 10 | loss: 0.05544 | val_0_mse: 0.005229999776929617|  0:00:09s\n","epoch 11 | loss: 0.02468 | val_0_mse: 0.0021200000774115324|  0:00:10s\n","epoch 12 | loss: 0.00936 | val_0_mse: 0.0006000000284984708|  0:00:11s\n","epoch 13 | loss: 0.00408 | val_0_mse: 0.0002899999963119626|  0:00:12s\n","epoch 14 | loss: 0.00235 | val_0_mse: 0.00033000000985339284|  0:00:13s\n","epoch 15 | loss: 0.00136 | val_0_mse: 0.00026000000070780516|  0:00:14s\n","epoch 16 | loss: 0.0011  | val_0_mse: 0.0002899999963119626|  0:00:15s\n","epoch 17 | loss: 0.00094 | val_0_mse: 0.0002099999983329326|  0:00:16s\n","epoch 18 | loss: 0.00084 | val_0_mse: 0.00015999999595806003|  0:00:17s\n","epoch 19 | loss: 0.00081 | val_0_mse: 0.00011000000085914508|  0:00:18s\n","epoch 20 | loss: 0.00064 | val_0_mse: 0.00013000000035390258|  0:00:19s\n","epoch 21 | loss: 0.00052 | val_0_mse: 9.000000136438757e-05|  0:00:20s\n","epoch 22 | loss: 0.0006  | val_0_mse: 0.0001900000061141327|  0:00:21s\n","epoch 23 | loss: 0.00055 | val_0_mse: 0.00013000000035390258|  0:00:22s\n","epoch 24 | loss: 0.00055 | val_0_mse: 7.000000186963007e-05|  0:00:22s\n","epoch 25 | loss: 0.00057 | val_0_mse: 1.9999999494757503e-05|  0:00:23s\n","epoch 26 | loss: 0.00044 | val_0_mse: 3.9999998989515007e-05|  0:00:24s\n","epoch 27 | loss: 0.00039 | val_0_mse: 1.9999999494757503e-05|  0:00:25s\n","epoch 28 | loss: 0.00034 | val_0_mse: 1.9999999494757503e-05|  0:00:26s\n","epoch 29 | loss: 0.00031 | val_0_mse: 1.9999999494757503e-05|  0:00:27s\n","epoch 30 | loss: 0.00029 | val_0_mse: 9.999999747378752e-06|  0:00:28s\n","epoch 31 | loss: 0.00027 | val_0_mse: 1.9999999494757503e-05|  0:00:29s\n","epoch 32 | loss: 0.00026 | val_0_mse: 1.9999999494757503e-05|  0:00:30s\n","epoch 33 | loss: 0.00026 | val_0_mse: 9.999999747378752e-06|  0:00:31s\n","epoch 34 | loss: 0.00024 | val_0_mse: 9.999999747378752e-06|  0:00:32s\n","epoch 35 | loss: 0.00024 | val_0_mse: 9.999999747378752e-06|  0:00:33s\n","epoch 36 | loss: 0.00023 | val_0_mse: 9.999999747378752e-06|  0:00:33s\n","epoch 37 | loss: 0.00023 | val_0_mse: 9.999999747378752e-06|  0:00:34s\n","epoch 38 | loss: 0.00023 | val_0_mse: 9.999999747378752e-06|  0:00:35s\n","epoch 39 | loss: 0.00022 | val_0_mse: 9.999999747378752e-06|  0:00:36s\n","epoch 40 | loss: 0.00022 | val_0_mse: 9.999999747378752e-06|  0:00:37s\n","epoch 41 | loss: 0.00022 | val_0_mse: 9.999999747378752e-06|  0:00:38s\n","epoch 42 | loss: 0.00022 | val_0_mse: 9.999999747378752e-06|  0:00:39s\n","epoch 43 | loss: 0.00022 | val_0_mse: 0.0     |  0:00:40s\n","epoch 44 | loss: 0.00021 | val_0_mse: 9.999999747378752e-06|  0:00:41s\n","epoch 45 | loss: 0.00021 | val_0_mse: 0.0     |  0:00:41s\n","epoch 46 | loss: 0.00021 | val_0_mse: 0.0     |  0:00:42s\n","epoch 47 | loss: 0.00021 | val_0_mse: 0.0     |  0:00:43s\n","epoch 48 | loss: 0.0002  | val_0_mse: 0.0     |  0:00:44s\n","epoch 49 | loss: 0.00021 | val_0_mse: 0.0     |  0:00:45s\n","epoch 50 | loss: 0.0002  | val_0_mse: 0.0     |  0:00:46s\n","epoch 51 | loss: 0.00019 | val_0_mse: 0.0     |  0:00:47s\n","epoch 52 | loss: 0.00019 | val_0_mse: 0.0     |  0:00:48s\n","epoch 53 | loss: 0.00019 | val_0_mse: 0.0     |  0:00:49s\n","epoch 54 | loss: 0.00019 | val_0_mse: 0.0     |  0:00:50s\n","epoch 55 | loss: 0.00019 | val_0_mse: 0.0     |  0:00:51s\n","epoch 56 | loss: 0.00018 | val_0_mse: 0.0     |  0:00:52s\n","epoch 57 | loss: 0.00019 | val_0_mse: 0.0     |  0:00:52s\n","epoch 58 | loss: 0.00019 | val_0_mse: 0.0     |  0:00:53s\n","epoch 59 | loss: 0.00018 | val_0_mse: 0.0     |  0:00:54s\n","epoch 60 | loss: 0.00017 | val_0_mse: 0.0     |  0:00:55s\n","epoch 61 | loss: 0.00018 | val_0_mse: 0.0     |  0:00:56s\n","epoch 62 | loss: 0.00018 | val_0_mse: 0.0     |  0:00:57s\n","epoch 63 | loss: 0.00018 | val_0_mse: 0.0     |  0:00:58s\n","epoch 64 | loss: 0.0002  | val_0_mse: 0.0     |  0:00:59s\n","epoch 65 | loss: 0.00022 | val_0_mse: 0.0     |  0:01:00s\n","epoch 66 | loss: 0.00021 | val_0_mse: 0.0     |  0:01:00s\n","epoch 67 | loss: 0.00022 | val_0_mse: 0.0     |  0:01:01s\n","epoch 68 | loss: 0.00023 | val_0_mse: 0.0     |  0:01:02s\n","epoch 69 | loss: 0.00023 | val_0_mse: 0.0     |  0:01:03s\n","epoch 70 | loss: 0.00023 | val_0_mse: 0.0     |  0:01:04s\n","epoch 71 | loss: 0.00023 | val_0_mse: 0.0     |  0:01:05s\n","epoch 72 | loss: 0.00023 | val_0_mse: 0.0     |  0:01:06s\n","epoch 73 | loss: 0.00022 | val_0_mse: 0.0     |  0:01:07s\n","epoch 74 | loss: 0.00022 | val_0_mse: 0.0     |  0:01:08s\n","epoch 75 | loss: 0.00021 | val_0_mse: 0.0     |  0:01:09s\n","epoch 76 | loss: 0.00022 | val_0_mse: 0.0     |  0:01:09s\n","epoch 77 | loss: 0.00022 | val_0_mse: 0.0     |  0:01:10s\n","epoch 78 | loss: 0.00022 | val_0_mse: 0.0     |  0:01:11s\n","epoch 79 | loss: 0.00023 | val_0_mse: 0.0     |  0:01:12s\n","epoch 80 | loss: 0.00023 | val_0_mse: 0.0     |  0:01:13s\n","epoch 81 | loss: 0.00023 | val_0_mse: 0.0     |  0:01:14s\n","epoch 82 | loss: 0.00021 | val_0_mse: 0.0     |  0:01:15s\n","epoch 83 | loss: 0.00021 | val_0_mse: 0.0     |  0:01:16s\n","epoch 84 | loss: 0.00021 | val_0_mse: 0.0     |  0:01:17s\n","epoch 85 | loss: 0.00021 | val_0_mse: 0.0     |  0:01:18s\n","epoch 86 | loss: 0.00021 | val_0_mse: 0.0     |  0:01:18s\n","epoch 87 | loss: 0.00021 | val_0_mse: 0.0     |  0:01:19s\n","epoch 88 | loss: 0.00021 | val_0_mse: 0.0     |  0:01:20s\n","epoch 89 | loss: 0.00021 | val_0_mse: 0.0     |  0:01:21s\n","epoch 90 | loss: 0.0002  | val_0_mse: 0.0     |  0:01:22s\n","epoch 91 | loss: 0.00021 | val_0_mse: 0.0     |  0:01:23s\n","epoch 92 | loss: 0.0002  | val_0_mse: 0.0     |  0:01:24s\n","epoch 93 | loss: 0.0002  | val_0_mse: 0.0     |  0:01:25s\n","epoch 94 | loss: 0.00021 | val_0_mse: 0.0     |  0:01:26s\n","epoch 95 | loss: 0.00021 | val_0_mse: 0.0     |  0:01:27s\n","epoch 96 | loss: 0.00021 | val_0_mse: 0.0     |  0:01:27s\n","epoch 97 | loss: 0.00022 | val_0_mse: 0.0     |  0:01:28s\n","epoch 98 | loss: 0.00022 | val_0_mse: 0.0     |  0:01:29s\n","epoch 99 | loss: 0.00022 | val_0_mse: 0.0     |  0:01:30s\n","Stop training because you reached max_epochs = 100 with best_epoch = 97 and best_val_0_mse = 0.0\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 08:54:31,221] Trial 25 finished with value: 1.580339699103206e-07 and parameters: {'n_d': 40, 'n_steps': 7, 'gamma': 1.9279555342282344, 'n_independent': 2, 'n_shared': 3, 'momentum': 0.18489507336972288}. Best is trial 20 with value: 1.2763081258526654e-07.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 2.48878 | val_0_mse: 13.211380004882812|  0:00:01s\n","epoch 1  | loss: 0.82461 | val_0_mse: 0.5714600086212158|  0:00:02s\n","epoch 2  | loss: 0.38713 | val_0_mse: 0.524649977684021|  0:00:03s\n","epoch 3  | loss: 0.57465 | val_0_mse: 0.4678199887275696|  0:00:04s\n","epoch 4  | loss: 0.18831 | val_0_mse: 0.010879999957978725|  0:00:05s\n","epoch 5  | loss: 0.05705 | val_0_mse: 0.042160000652074814|  0:00:06s\n","epoch 6  | loss: 0.19233 | val_0_mse: 0.008550000376999378|  0:00:07s\n","epoch 7  | loss: 0.03164 | val_0_mse: 0.0014900000533089042|  0:00:08s\n","epoch 8  | loss: 0.05063 | val_0_mse: 0.013779999688267708|  0:00:09s\n","epoch 9  | loss: 0.01106 | val_0_mse: 0.0023499999660998583|  0:00:10s\n","epoch 10 | loss: 0.00467 | val_0_mse: 0.0016599999507889152|  0:00:11s\n","epoch 11 | loss: 0.00263 | val_0_mse: 0.00033000000985339284|  0:00:12s\n","epoch 12 | loss: 0.00109 | val_0_mse: 0.0001500000071246177|  0:00:13s\n","epoch 13 | loss: 0.00064 | val_0_mse: 3.9999998989515007e-05|  0:00:14s\n","epoch 14 | loss: 0.00043 | val_0_mse: 4.999999873689376e-05|  0:00:15s\n","epoch 15 | loss: 0.00034 | val_0_mse: 2.9999999242136255e-05|  0:00:16s\n","epoch 16 | loss: 0.00031 | val_0_mse: 9.999999747378752e-06|  0:00:17s\n","epoch 17 | loss: 0.00028 | val_0_mse: 9.999999747378752e-06|  0:00:18s\n","epoch 18 | loss: 0.00027 | val_0_mse: 1.9999999494757503e-05|  0:00:19s\n","epoch 19 | loss: 0.00026 | val_0_mse: 9.999999747378752e-06|  0:00:20s\n","epoch 20 | loss: 0.00026 | val_0_mse: 0.0     |  0:00:21s\n","epoch 21 | loss: 0.00025 | val_0_mse: 0.0     |  0:00:22s\n","epoch 22 | loss: 0.00024 | val_0_mse: 0.0     |  0:00:23s\n","epoch 23 | loss: 0.00024 | val_0_mse: 0.0     |  0:00:24s\n","epoch 24 | loss: 0.00023 | val_0_mse: 0.0     |  0:00:25s\n","epoch 25 | loss: 0.00023 | val_0_mse: 0.0     |  0:00:26s\n","epoch 26 | loss: 0.00022 | val_0_mse: 0.0     |  0:00:27s\n","epoch 27 | loss: 0.00022 | val_0_mse: 0.0     |  0:00:28s\n","epoch 28 | loss: 0.00023 | val_0_mse: 0.0     |  0:00:29s\n","epoch 29 | loss: 0.00022 | val_0_mse: 0.0     |  0:00:30s\n","epoch 30 | loss: 0.00022 | val_0_mse: 0.0     |  0:00:31s\n","epoch 31 | loss: 0.00021 | val_0_mse: 0.0     |  0:00:32s\n","epoch 32 | loss: 0.00021 | val_0_mse: 0.0     |  0:00:33s\n","epoch 33 | loss: 0.00022 | val_0_mse: 0.0     |  0:00:34s\n","epoch 34 | loss: 0.00021 | val_0_mse: 0.0     |  0:00:36s\n","epoch 35 | loss: 0.00021 | val_0_mse: 0.0     |  0:00:37s\n","epoch 36 | loss: 0.00022 | val_0_mse: 0.0     |  0:00:38s\n","epoch 37 | loss: 0.00022 | val_0_mse: 0.0     |  0:00:39s\n","epoch 38 | loss: 0.00022 | val_0_mse: 0.0     |  0:00:40s\n","epoch 39 | loss: 0.00022 | val_0_mse: 0.0     |  0:00:41s\n","epoch 40 | loss: 0.00022 | val_0_mse: 0.0     |  0:00:42s\n","epoch 41 | loss: 0.00021 | val_0_mse: 0.0     |  0:00:43s\n","epoch 42 | loss: 0.00022 | val_0_mse: 0.0     |  0:00:44s\n","epoch 43 | loss: 0.00021 | val_0_mse: 0.0     |  0:00:45s\n","epoch 44 | loss: 0.0002  | val_0_mse: 0.0     |  0:00:46s\n","epoch 45 | loss: 0.0002  | val_0_mse: 0.0     |  0:00:47s\n","epoch 46 | loss: 0.0002  | val_0_mse: 0.0     |  0:00:48s\n","epoch 47 | loss: 0.0002  | val_0_mse: 0.0     |  0:00:49s\n","epoch 48 | loss: 0.0002  | val_0_mse: 0.0     |  0:00:50s\n","epoch 49 | loss: 0.0002  | val_0_mse: 0.0     |  0:00:51s\n","epoch 50 | loss: 0.0002  | val_0_mse: 0.0     |  0:00:52s\n","epoch 51 | loss: 0.0002  | val_0_mse: 0.0     |  0:00:53s\n","epoch 52 | loss: 0.00019 | val_0_mse: 0.0     |  0:00:54s\n","epoch 53 | loss: 0.00019 | val_0_mse: 0.0     |  0:00:55s\n","epoch 54 | loss: 0.00019 | val_0_mse: 0.0     |  0:00:56s\n","epoch 55 | loss: 0.0002  | val_0_mse: 0.0     |  0:00:57s\n","epoch 56 | loss: 0.00019 | val_0_mse: 0.0     |  0:00:58s\n","epoch 57 | loss: 0.00018 | val_0_mse: 0.0     |  0:00:59s\n","epoch 58 | loss: 0.00018 | val_0_mse: 0.0     |  0:01:00s\n","epoch 59 | loss: 0.00017 | val_0_mse: 0.0     |  0:01:01s\n","epoch 60 | loss: 0.00017 | val_0_mse: 0.0     |  0:01:02s\n","epoch 61 | loss: 0.00017 | val_0_mse: 0.0     |  0:01:03s\n","epoch 62 | loss: 0.00017 | val_0_mse: 0.0     |  0:01:04s\n","epoch 63 | loss: 0.00018 | val_0_mse: 0.0     |  0:01:05s\n","epoch 64 | loss: 0.00018 | val_0_mse: 0.0     |  0:01:06s\n","epoch 65 | loss: 0.00019 | val_0_mse: 0.0     |  0:01:07s\n","epoch 66 | loss: 0.00019 | val_0_mse: 0.0     |  0:01:08s\n","epoch 67 | loss: 0.00019 | val_0_mse: 0.0     |  0:01:09s\n","epoch 68 | loss: 0.00019 | val_0_mse: 0.0     |  0:01:11s\n","epoch 69 | loss: 0.0002  | val_0_mse: 0.0     |  0:01:12s\n","epoch 70 | loss: 0.00019 | val_0_mse: 0.0     |  0:01:13s\n","epoch 71 | loss: 0.0002  | val_0_mse: 0.0     |  0:01:14s\n","epoch 72 | loss: 0.0002  | val_0_mse: 0.0     |  0:01:15s\n","epoch 73 | loss: 0.0002  | val_0_mse: 0.0     |  0:01:16s\n","epoch 74 | loss: 0.00019 | val_0_mse: 0.0     |  0:01:17s\n","\n","Early stopping occurred at epoch 74 with best_epoch = 64 and best_val_0_mse = 0.0\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 08:55:49,088] Trial 26 finished with value: 1.7219437609128363e-07 and parameters: {'n_d': 40, 'n_steps': 7, 'gamma': 1.8366085199126874, 'n_independent': 3, 'n_shared': 3, 'momentum': 0.2538879151840504}. Best is trial 20 with value: 1.2763081258526654e-07.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 6.83688 | val_0_mse: 120.34285736083984|  0:00:01s\n","epoch 1  | loss: 2.0864  | val_0_mse: 68.80229187011719|  0:00:02s\n","epoch 2  | loss: 1.75529 | val_0_mse: 5.645890235900879|  0:00:03s\n","epoch 3  | loss: 1.50333 | val_0_mse: 3.451900005340576|  0:00:04s\n","epoch 4  | loss: 1.98975 | val_0_mse: 0.5024799704551697|  0:00:05s\n","epoch 5  | loss: 0.89328 | val_0_mse: 0.2812100052833557|  0:00:07s\n","epoch 6  | loss: 2.17559 | val_0_mse: 0.14917999505996704|  0:00:08s\n","epoch 7  | loss: 0.82596 | val_0_mse: 0.020840000361204147|  0:00:09s\n","epoch 8  | loss: 0.27185 | val_0_mse: 0.02295999974012375|  0:00:10s\n","epoch 9  | loss: 0.10503 | val_0_mse: 0.006610000040382147|  0:00:11s\n","epoch 10 | loss: 0.08619 | val_0_mse: 0.0037400000728666782|  0:00:12s\n","epoch 11 | loss: 0.03155 | val_0_mse: 0.013509999960660934|  0:00:13s\n","epoch 12 | loss: 0.01455 | val_0_mse: 0.0012799999676644802|  0:00:14s\n","epoch 13 | loss: 0.00669 | val_0_mse: 0.0008699999889358878|  0:00:16s\n","epoch 14 | loss: 0.00426 | val_0_mse: 0.000539999979082495|  0:00:17s\n","epoch 15 | loss: 0.00345 | val_0_mse: 0.0004199999966658652|  0:00:18s\n","epoch 16 | loss: 0.00192 | val_0_mse: 0.0003699999942909926|  0:00:19s\n","epoch 17 | loss: 0.00128 | val_0_mse: 0.00031999999191612005|  0:00:20s\n","epoch 18 | loss: 0.00107 | val_0_mse: 0.0001900000061141327|  0:00:21s\n","epoch 19 | loss: 0.00108 | val_0_mse: 0.0003699999942909926|  0:00:23s\n","epoch 20 | loss: 0.00111 | val_0_mse: 0.00018000000272877514|  0:00:24s\n","epoch 21 | loss: 0.00096 | val_0_mse: 0.0003100000030826777|  0:00:25s\n","epoch 22 | loss: 0.00074 | val_0_mse: 0.00014000000373926014|  0:00:26s\n","epoch 23 | loss: 0.00057 | val_0_mse: 0.00013000000035390258|  0:00:27s\n","epoch 24 | loss: 0.0005  | val_0_mse: 7.999999797903001e-05|  0:00:29s\n","epoch 25 | loss: 0.00052 | val_0_mse: 9.999999747378752e-05|  0:00:30s\n","epoch 26 | loss: 0.00052 | val_0_mse: 7.000000186963007e-05|  0:00:31s\n","epoch 27 | loss: 0.00049 | val_0_mse: 5.999999848427251e-05|  0:00:32s\n","epoch 28 | loss: 0.0004  | val_0_mse: 4.999999873689376e-05|  0:00:33s\n","epoch 29 | loss: 0.00033 | val_0_mse: 5.999999848427251e-05|  0:00:34s\n","epoch 30 | loss: 0.0003  | val_0_mse: 3.9999998989515007e-05|  0:00:35s\n","epoch 31 | loss: 0.00028 | val_0_mse: 4.999999873689376e-05|  0:00:36s\n","epoch 32 | loss: 0.00027 | val_0_mse: 2.9999999242136255e-05|  0:00:38s\n","epoch 33 | loss: 0.00026 | val_0_mse: 2.9999999242136255e-05|  0:00:39s\n","epoch 34 | loss: 0.00024 | val_0_mse: 3.9999998989515007e-05|  0:00:40s\n","epoch 35 | loss: 0.00024 | val_0_mse: 2.9999999242136255e-05|  0:00:41s\n","epoch 36 | loss: 0.00023 | val_0_mse: 3.9999998989515007e-05|  0:00:42s\n","epoch 37 | loss: 0.00025 | val_0_mse: 4.999999873689376e-05|  0:00:43s\n","epoch 38 | loss: 0.00025 | val_0_mse: 4.999999873689376e-05|  0:00:45s\n","epoch 39 | loss: 0.00024 | val_0_mse: 3.9999998989515007e-05|  0:00:46s\n","epoch 40 | loss: 0.00023 | val_0_mse: 3.9999998989515007e-05|  0:00:47s\n","epoch 41 | loss: 0.00022 | val_0_mse: 3.9999998989515007e-05|  0:00:48s\n","epoch 42 | loss: 0.00022 | val_0_mse: 3.9999998989515007e-05|  0:00:49s\n","\n","Early stopping occurred at epoch 42 with best_epoch = 32 and best_val_0_mse = 2.9999999242136255e-05\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 08:56:39,384] Trial 27 finished with value: 2.8891598049085587e-05 and parameters: {'n_d': 40, 'n_steps': 8, 'gamma': 1.8382918963349884, 'n_independent': 3, 'n_shared': 3, 'momentum': 0.2520654226805192}. Best is trial 20 with value: 1.2763081258526654e-07.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 3.33292 | val_0_mse: 18.449249267578125|  0:00:01s\n","epoch 1  | loss: 1.57072 | val_0_mse: 0.864579975605011|  0:00:02s\n","epoch 2  | loss: 1.12181 | val_0_mse: 2.1550700664520264|  0:00:03s\n","epoch 3  | loss: 0.82761 | val_0_mse: 0.4885700047016144|  0:00:04s\n","epoch 4  | loss: 0.72941 | val_0_mse: 0.14885999262332916|  0:00:05s\n","epoch 5  | loss: 0.31289 | val_0_mse: 0.16812999546527863|  0:00:06s\n","epoch 6  | loss: 0.31523 | val_0_mse: 0.32565000653266907|  0:00:07s\n","epoch 7  | loss: 0.147   | val_0_mse: 0.004900000058114529|  0:00:09s\n","epoch 8  | loss: 0.03645 | val_0_mse: 0.011549999937415123|  0:00:10s\n","epoch 9  | loss: 0.01063 | val_0_mse: 0.0037299999967217445|  0:00:11s\n","epoch 10 | loss: 0.00406 | val_0_mse: 0.0001900000061141327|  0:00:12s\n","epoch 11 | loss: 0.00183 | val_0_mse: 9.000000136438757e-05|  0:00:13s\n","epoch 12 | loss: 0.00095 | val_0_mse: 5.999999848427251e-05|  0:00:15s\n","epoch 13 | loss: 0.0008  | val_0_mse: 9.000000136438757e-05|  0:00:16s\n","epoch 14 | loss: 0.00054 | val_0_mse: 0.00011999999696854502|  0:00:17s\n","epoch 15 | loss: 0.00045 | val_0_mse: 3.9999998989515007e-05|  0:00:18s\n","epoch 16 | loss: 0.0004  | val_0_mse: 1.9999999494757503e-05|  0:00:19s\n","epoch 17 | loss: 0.00033 | val_0_mse: 9.999999747378752e-06|  0:00:20s\n","epoch 18 | loss: 0.00028 | val_0_mse: 1.9999999494757503e-05|  0:00:21s\n","epoch 19 | loss: 0.00026 | val_0_mse: 9.999999747378752e-06|  0:00:23s\n","epoch 20 | loss: 0.00026 | val_0_mse: 0.0     |  0:00:24s\n","epoch 21 | loss: 0.00023 | val_0_mse: 9.999999747378752e-06|  0:00:25s\n","epoch 22 | loss: 0.00023 | val_0_mse: 9.999999747378752e-06|  0:00:26s\n","epoch 23 | loss: 0.00023 | val_0_mse: 0.0     |  0:00:27s\n","epoch 24 | loss: 0.00022 | val_0_mse: 9.999999747378752e-06|  0:00:28s\n","epoch 25 | loss: 0.00022 | val_0_mse: 9.999999747378752e-06|  0:00:29s\n","epoch 26 | loss: 0.00021 | val_0_mse: 0.0     |  0:00:30s\n","epoch 27 | loss: 0.0002  | val_0_mse: 0.0     |  0:00:32s\n","epoch 28 | loss: 0.0002  | val_0_mse: 0.0     |  0:00:33s\n","epoch 29 | loss: 0.0002  | val_0_mse: 0.0     |  0:00:34s\n","epoch 30 | loss: 0.00019 | val_0_mse: 0.0     |  0:00:35s\n","epoch 31 | loss: 0.00018 | val_0_mse: 0.0     |  0:00:36s\n","epoch 32 | loss: 0.00018 | val_0_mse: 0.0     |  0:00:37s\n","epoch 33 | loss: 0.00018 | val_0_mse: 0.0     |  0:00:39s\n","epoch 34 | loss: 0.00018 | val_0_mse: 0.0     |  0:00:40s\n","epoch 35 | loss: 0.00018 | val_0_mse: 0.0     |  0:00:41s\n","epoch 36 | loss: 0.00017 | val_0_mse: 0.0     |  0:00:42s\n","epoch 37 | loss: 0.00017 | val_0_mse: 0.0     |  0:00:43s\n","epoch 38 | loss: 0.00017 | val_0_mse: 0.0     |  0:00:44s\n","epoch 39 | loss: 0.00017 | val_0_mse: 0.0     |  0:00:46s\n","epoch 40 | loss: 0.00016 | val_0_mse: 0.0     |  0:00:47s\n","epoch 41 | loss: 0.00016 | val_0_mse: 0.0     |  0:00:48s\n","epoch 42 | loss: 0.00016 | val_0_mse: 0.0     |  0:00:49s\n","epoch 43 | loss: 0.00016 | val_0_mse: 0.0     |  0:00:50s\n","epoch 44 | loss: 0.00016 | val_0_mse: 0.0     |  0:00:51s\n","epoch 45 | loss: 0.00016 | val_0_mse: 0.0     |  0:00:52s\n","epoch 46 | loss: 0.00015 | val_0_mse: 0.0     |  0:00:54s\n","epoch 47 | loss: 0.00015 | val_0_mse: 0.0     |  0:00:55s\n","epoch 48 | loss: 0.00015 | val_0_mse: 0.0     |  0:00:56s\n","epoch 49 | loss: 0.00015 | val_0_mse: 0.0     |  0:00:57s\n","epoch 50 | loss: 0.00015 | val_0_mse: 0.0     |  0:00:58s\n","epoch 51 | loss: 0.00015 | val_0_mse: 0.0     |  0:00:59s\n","epoch 52 | loss: 0.00015 | val_0_mse: 0.0     |  0:01:01s\n","epoch 53 | loss: 0.00015 | val_0_mse: 0.0     |  0:01:02s\n","epoch 54 | loss: 0.00015 | val_0_mse: 0.0     |  0:01:03s\n","epoch 55 | loss: 0.00015 | val_0_mse: 0.0     |  0:01:04s\n","epoch 56 | loss: 0.00015 | val_0_mse: 0.0     |  0:01:05s\n","epoch 57 | loss: 0.00015 | val_0_mse: 0.0     |  0:01:07s\n","epoch 58 | loss: 0.00014 | val_0_mse: 0.0     |  0:01:08s\n","epoch 59 | loss: 0.00014 | val_0_mse: 0.0     |  0:01:09s\n","epoch 60 | loss: 0.00022 | val_0_mse: 3.9999998989515007e-05|  0:01:10s\n","epoch 61 | loss: 0.00073 | val_0_mse: 1.9999999494757503e-05|  0:01:11s\n","epoch 62 | loss: 0.00026 | val_0_mse: 1.9999999494757503e-05|  0:01:13s\n","epoch 63 | loss: 0.00018 | val_0_mse: 0.0     |  0:01:14s\n","epoch 64 | loss: 0.00016 | val_0_mse: 0.0     |  0:01:15s\n","\n","Early stopping occurred at epoch 64 with best_epoch = 54 and best_val_0_mse = 0.0\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 08:57:55,460] Trial 28 finished with value: 2.0497688524301338e-07 and parameters: {'n_d': 48, 'n_steps': 7, 'gamma': 1.91700410019284, 'n_independent': 3, 'n_shared': 4, 'momentum': 0.19622416441727497}. Best is trial 20 with value: 1.2763081258526654e-07.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 6.34386 | val_0_mse: 18.68832015991211|  0:00:01s\n","epoch 1  | loss: 6.06508 | val_0_mse: 1.1692099571228027|  0:00:02s\n","epoch 2  | loss: 2.94926 | val_0_mse: 0.7589600086212158|  0:00:03s\n","epoch 3  | loss: 2.24586 | val_0_mse: 0.7599499821662903|  0:00:04s\n","epoch 4  | loss: 1.98518 | val_0_mse: 1.2851999998092651|  0:00:05s\n","epoch 5  | loss: 3.36859 | val_0_mse: 0.8695700168609619|  0:00:06s\n","epoch 6  | loss: 0.8456  | val_0_mse: 0.09898000210523605|  0:00:07s\n","epoch 7  | loss: 0.31835 | val_0_mse: 0.02522999979555607|  0:00:08s\n","epoch 8  | loss: 0.21395 | val_0_mse: 0.05758000165224075|  0:00:09s\n","epoch 9  | loss: 0.14385 | val_0_mse: 0.06390000134706497|  0:00:10s\n","epoch 10 | loss: 0.12423 | val_0_mse: 0.011239999905228615|  0:00:11s\n","epoch 11 | loss: 0.05225 | val_0_mse: 0.003719999920576811|  0:00:12s\n","epoch 12 | loss: 0.03    | val_0_mse: 0.002859999891370535|  0:00:13s\n","epoch 13 | loss: 0.01309 | val_0_mse: 0.0016799999866634607|  0:00:14s\n","epoch 14 | loss: 0.00561 | val_0_mse: 0.0004199999966658652|  0:00:16s\n","epoch 15 | loss: 0.00354 | val_0_mse: 0.0014400000218302011|  0:00:17s\n","epoch 16 | loss: 0.00204 | val_0_mse: 0.00046999999904073775|  0:00:18s\n","epoch 17 | loss: 0.00197 | val_0_mse: 0.00026000000070780516|  0:00:19s\n","epoch 18 | loss: 0.00146 | val_0_mse: 0.0002300000051036477|  0:00:20s\n","epoch 19 | loss: 0.00122 | val_0_mse: 0.00018000000272877514|  0:00:21s\n","epoch 20 | loss: 0.00104 | val_0_mse: 0.00013000000035390258|  0:00:22s\n","epoch 21 | loss: 0.00103 | val_0_mse: 5.999999848427251e-05|  0:00:23s\n","epoch 22 | loss: 0.00099 | val_0_mse: 5.999999848427251e-05|  0:00:24s\n","epoch 23 | loss: 0.0007  | val_0_mse: 3.9999998989515007e-05|  0:00:25s\n","epoch 24 | loss: 0.00059 | val_0_mse: 3.9999998989515007e-05|  0:00:26s\n","epoch 25 | loss: 0.00048 | val_0_mse: 3.9999998989515007e-05|  0:00:27s\n","epoch 26 | loss: 0.00043 | val_0_mse: 3.9999998989515007e-05|  0:00:28s\n","epoch 27 | loss: 0.00043 | val_0_mse: 4.999999873689376e-05|  0:00:29s\n","epoch 28 | loss: 0.0004  | val_0_mse: 3.9999998989515007e-05|  0:00:30s\n","epoch 29 | loss: 0.00038 | val_0_mse: 2.9999999242136255e-05|  0:00:31s\n","epoch 30 | loss: 0.00035 | val_0_mse: 2.9999999242136255e-05|  0:00:32s\n","epoch 31 | loss: 0.00033 | val_0_mse: 1.9999999494757503e-05|  0:00:34s\n","epoch 32 | loss: 0.00032 | val_0_mse: 2.9999999242136255e-05|  0:00:35s\n","epoch 33 | loss: 0.00031 | val_0_mse: 9.999999747378752e-06|  0:00:36s\n","epoch 34 | loss: 0.0003  | val_0_mse: 1.9999999494757503e-05|  0:00:37s\n","epoch 35 | loss: 0.00031 | val_0_mse: 1.9999999494757503e-05|  0:00:38s\n","epoch 36 | loss: 0.00029 | val_0_mse: 1.9999999494757503e-05|  0:00:39s\n","epoch 37 | loss: 0.00028 | val_0_mse: 1.9999999494757503e-05|  0:00:40s\n","epoch 38 | loss: 0.00027 | val_0_mse: 9.999999747378752e-06|  0:00:41s\n","epoch 39 | loss: 0.00027 | val_0_mse: 9.999999747378752e-06|  0:00:42s\n","epoch 40 | loss: 0.00027 | val_0_mse: 1.9999999494757503e-05|  0:00:43s\n","epoch 41 | loss: 0.00027 | val_0_mse: 9.999999747378752e-06|  0:00:44s\n","epoch 42 | loss: 0.00025 | val_0_mse: 9.999999747378752e-06|  0:00:45s\n","epoch 43 | loss: 0.00026 | val_0_mse: 9.999999747378752e-06|  0:00:46s\n","epoch 44 | loss: 0.00026 | val_0_mse: 1.9999999494757503e-05|  0:00:47s\n","epoch 45 | loss: 0.00026 | val_0_mse: 1.9999999494757503e-05|  0:00:48s\n","epoch 46 | loss: 0.00026 | val_0_mse: 9.999999747378752e-06|  0:00:49s\n","epoch 47 | loss: 0.00025 | val_0_mse: 9.999999747378752e-06|  0:00:51s\n","epoch 48 | loss: 0.00025 | val_0_mse: 9.999999747378752e-06|  0:00:52s\n","epoch 49 | loss: 0.00025 | val_0_mse: 9.999999747378752e-06|  0:00:53s\n","epoch 50 | loss: 0.00024 | val_0_mse: 9.999999747378752e-06|  0:00:54s\n","epoch 51 | loss: 0.00024 | val_0_mse: 9.999999747378752e-06|  0:00:55s\n","epoch 52 | loss: 0.00023 | val_0_mse: 9.999999747378752e-06|  0:00:56s\n","epoch 53 | loss: 0.00023 | val_0_mse: 9.999999747378752e-06|  0:00:57s\n","epoch 54 | loss: 0.00023 | val_0_mse: 9.999999747378752e-06|  0:00:58s\n","epoch 55 | loss: 0.00023 | val_0_mse: 9.999999747378752e-06|  0:00:59s\n","epoch 56 | loss: 0.00023 | val_0_mse: 0.0     |  0:01:00s\n","epoch 57 | loss: 0.00023 | val_0_mse: 9.999999747378752e-06|  0:01:01s\n","epoch 58 | loss: 0.00023 | val_0_mse: 9.999999747378752e-06|  0:01:02s\n","epoch 59 | loss: 0.00023 | val_0_mse: 9.999999747378752e-06|  0:01:03s\n","epoch 60 | loss: 0.00022 | val_0_mse: 9.999999747378752e-06|  0:01:04s\n","epoch 61 | loss: 0.00022 | val_0_mse: 0.0     |  0:01:05s\n","epoch 62 | loss: 0.00022 | val_0_mse: 9.999999747378752e-06|  0:01:06s\n","epoch 63 | loss: 0.00022 | val_0_mse: 0.0     |  0:01:07s\n","epoch 64 | loss: 0.00022 | val_0_mse: 0.0     |  0:01:08s\n","epoch 65 | loss: 0.00021 | val_0_mse: 0.0     |  0:01:09s\n","epoch 66 | loss: 0.00021 | val_0_mse: 0.0     |  0:01:11s\n","epoch 67 | loss: 0.00021 | val_0_mse: 0.0     |  0:01:12s\n","epoch 68 | loss: 0.00021 | val_0_mse: 0.0     |  0:01:13s\n","epoch 69 | loss: 0.00021 | val_0_mse: 0.0     |  0:01:14s\n","epoch 70 | loss: 0.0002  | val_0_mse: 0.0     |  0:01:15s\n","epoch 71 | loss: 0.0002  | val_0_mse: 0.0     |  0:01:16s\n","epoch 72 | loss: 0.0002  | val_0_mse: 0.0     |  0:01:17s\n","epoch 73 | loss: 0.0002  | val_0_mse: 0.0     |  0:01:18s\n","epoch 74 | loss: 0.0002  | val_0_mse: 0.0     |  0:01:19s\n","epoch 75 | loss: 0.0002  | val_0_mse: 0.0     |  0:01:20s\n","epoch 76 | loss: 0.00019 | val_0_mse: 0.0     |  0:01:21s\n","epoch 77 | loss: 0.0002  | val_0_mse: 0.0     |  0:01:22s\n","epoch 78 | loss: 0.0002  | val_0_mse: 0.0     |  0:01:23s\n","epoch 79 | loss: 0.00019 | val_0_mse: 0.0     |  0:01:24s\n","epoch 80 | loss: 0.00019 | val_0_mse: 0.0     |  0:01:25s\n","epoch 81 | loss: 0.00019 | val_0_mse: 0.0     |  0:01:26s\n","epoch 82 | loss: 0.00019 | val_0_mse: 0.0     |  0:01:27s\n","epoch 83 | loss: 0.00019 | val_0_mse: 0.0     |  0:01:28s\n","epoch 84 | loss: 0.00018 | val_0_mse: 0.0     |  0:01:30s\n","epoch 85 | loss: 0.00018 | val_0_mse: 0.0     |  0:01:31s\n","epoch 86 | loss: 0.00018 | val_0_mse: 0.0     |  0:01:32s\n","epoch 87 | loss: 0.00018 | val_0_mse: 0.0     |  0:01:33s\n","epoch 88 | loss: 0.00018 | val_0_mse: 0.0     |  0:01:34s\n","epoch 89 | loss: 0.00018 | val_0_mse: 0.0     |  0:01:35s\n","epoch 90 | loss: 0.00018 | val_0_mse: 0.0     |  0:01:36s\n","epoch 91 | loss: 0.00018 | val_0_mse: 0.0     |  0:01:37s\n","epoch 92 | loss: 0.00018 | val_0_mse: 0.0     |  0:01:38s\n","epoch 93 | loss: 0.00018 | val_0_mse: 0.0     |  0:01:39s\n","epoch 94 | loss: 0.00017 | val_0_mse: 0.0     |  0:01:40s\n","epoch 95 | loss: 0.00017 | val_0_mse: 0.0     |  0:01:41s\n","epoch 96 | loss: 0.00017 | val_0_mse: 0.0     |  0:01:42s\n","epoch 97 | loss: 0.00018 | val_0_mse: 0.0     |  0:01:43s\n","epoch 98 | loss: 0.00018 | val_0_mse: 0.0     |  0:01:44s\n","epoch 99 | loss: 0.00018 | val_0_mse: 0.0     |  0:01:46s\n","Stop training because you reached max_epochs = 100 with best_epoch = 99 and best_val_0_mse = 0.0\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 08:59:42,181] Trial 29 finished with value: 2.6093115934600064e-07 and parameters: {'n_d': 51, 'n_steps': 8, 'gamma': 1.5567091975076657, 'n_independent': 2, 'n_shared': 3, 'momentum': 0.22839609994959864}. Best is trial 20 with value: 1.2763081258526654e-07.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 7.71125 | val_0_mse: 3.188339948654175|  0:00:00s\n","epoch 1  | loss: 0.86878 | val_0_mse: 0.8865000009536743|  0:00:01s\n","epoch 2  | loss: 0.7857  | val_0_mse: 0.12789000570774078|  0:00:02s\n","epoch 3  | loss: 0.46417 | val_0_mse: 0.05974999815225601|  0:00:03s\n","epoch 4  | loss: 0.2112  | val_0_mse: 0.06063999980688095|  0:00:04s\n","epoch 5  | loss: 0.14352 | val_0_mse: 0.13946999609470367|  0:00:05s\n","epoch 6  | loss: 0.21884 | val_0_mse: 0.06565000116825104|  0:00:06s\n","epoch 7  | loss: 0.09007 | val_0_mse: 0.012489999644458294|  0:00:07s\n","epoch 8  | loss: 0.01815 | val_0_mse: 0.0019000000320374966|  0:00:08s\n","epoch 9  | loss: 0.00583 | val_0_mse: 0.0005300000193528831|  0:00:09s\n","epoch 10 | loss: 0.00233 | val_0_mse: 0.0004400000034365803|  0:00:10s\n","epoch 11 | loss: 0.00116 | val_0_mse: 0.00039999998989515007|  0:00:11s\n","epoch 12 | loss: 0.00089 | val_0_mse: 7.000000186963007e-05|  0:00:12s\n","epoch 13 | loss: 0.00063 | val_0_mse: 3.9999998989515007e-05|  0:00:13s\n","epoch 14 | loss: 0.00051 | val_0_mse: 5.999999848427251e-05|  0:00:14s\n","epoch 15 | loss: 0.00048 | val_0_mse: 4.999999873689376e-05|  0:00:15s\n","epoch 16 | loss: 0.00046 | val_0_mse: 2.9999999242136255e-05|  0:00:16s\n","epoch 17 | loss: 0.00038 | val_0_mse: 2.9999999242136255e-05|  0:00:17s\n","epoch 18 | loss: 0.00037 | val_0_mse: 1.9999999494757503e-05|  0:00:17s\n","epoch 19 | loss: 0.00034 | val_0_mse: 1.9999999494757503e-05|  0:00:18s\n","epoch 20 | loss: 0.00033 | val_0_mse: 1.9999999494757503e-05|  0:00:19s\n","epoch 21 | loss: 0.00032 | val_0_mse: 9.999999747378752e-06|  0:00:20s\n","epoch 22 | loss: 0.00031 | val_0_mse: 9.999999747378752e-06|  0:00:21s\n","epoch 23 | loss: 0.00031 | val_0_mse: 9.999999747378752e-06|  0:00:22s\n","epoch 24 | loss: 0.0003  | val_0_mse: 9.999999747378752e-06|  0:00:23s\n","epoch 25 | loss: 0.0003  | val_0_mse: 1.9999999494757503e-05|  0:00:24s\n","epoch 26 | loss: 0.0003  | val_0_mse: 9.999999747378752e-06|  0:00:25s\n","epoch 27 | loss: 0.00029 | val_0_mse: 0.0     |  0:00:26s\n","epoch 28 | loss: 0.00029 | val_0_mse: 9.999999747378752e-06|  0:00:27s\n","epoch 29 | loss: 0.00028 | val_0_mse: 0.0     |  0:00:28s\n","epoch 30 | loss: 0.00028 | val_0_mse: 9.999999747378752e-06|  0:00:29s\n","epoch 31 | loss: 0.00028 | val_0_mse: 0.0     |  0:00:30s\n","epoch 32 | loss: 0.00028 | val_0_mse: 0.0     |  0:00:31s\n","epoch 33 | loss: 0.00028 | val_0_mse: 0.0     |  0:00:32s\n","epoch 34 | loss: 0.00027 | val_0_mse: 0.0     |  0:00:33s\n","epoch 35 | loss: 0.00027 | val_0_mse: 0.0     |  0:00:34s\n","epoch 36 | loss: 0.00027 | val_0_mse: 0.0     |  0:00:35s\n","epoch 37 | loss: 0.00027 | val_0_mse: 0.0     |  0:00:36s\n","epoch 38 | loss: 0.00026 | val_0_mse: 0.0     |  0:00:37s\n","epoch 39 | loss: 0.00026 | val_0_mse: 0.0     |  0:00:38s\n","epoch 40 | loss: 0.00026 | val_0_mse: 0.0     |  0:00:39s\n","epoch 41 | loss: 0.00026 | val_0_mse: 0.0     |  0:00:40s\n","epoch 42 | loss: 0.00025 | val_0_mse: 0.0     |  0:00:40s\n","epoch 43 | loss: 0.00025 | val_0_mse: 0.0     |  0:00:41s\n","epoch 44 | loss: 0.00025 | val_0_mse: 0.0     |  0:00:42s\n","epoch 45 | loss: 0.00025 | val_0_mse: 0.0     |  0:00:43s\n","epoch 46 | loss: 0.00025 | val_0_mse: 0.0     |  0:00:44s\n","epoch 47 | loss: 0.00024 | val_0_mse: 0.0     |  0:00:45s\n","epoch 48 | loss: 0.00024 | val_0_mse: 0.0     |  0:00:46s\n","epoch 49 | loss: 0.00025 | val_0_mse: 0.0     |  0:00:47s\n","epoch 50 | loss: 0.00024 | val_0_mse: 0.0     |  0:00:48s\n","epoch 51 | loss: 0.00023 | val_0_mse: 0.0     |  0:00:49s\n","epoch 52 | loss: 0.00023 | val_0_mse: 0.0     |  0:00:50s\n","epoch 53 | loss: 0.00023 | val_0_mse: 0.0     |  0:00:51s\n","epoch 54 | loss: 0.00023 | val_0_mse: 0.0     |  0:00:52s\n","epoch 55 | loss: 0.00023 | val_0_mse: 0.0     |  0:00:53s\n","epoch 56 | loss: 0.00023 | val_0_mse: 0.0     |  0:00:54s\n","epoch 57 | loss: 0.00023 | val_0_mse: 0.0     |  0:00:55s\n","epoch 58 | loss: 0.00022 | val_0_mse: 0.0     |  0:00:56s\n","epoch 59 | loss: 0.00022 | val_0_mse: 0.0     |  0:00:57s\n","epoch 60 | loss: 0.00022 | val_0_mse: 0.0     |  0:00:58s\n","epoch 61 | loss: 0.00022 | val_0_mse: 0.0     |  0:00:59s\n","epoch 62 | loss: 0.00022 | val_0_mse: 0.0     |  0:01:00s\n","epoch 63 | loss: 0.00022 | val_0_mse: 0.0     |  0:01:00s\n","epoch 64 | loss: 0.00021 | val_0_mse: 0.0     |  0:01:01s\n","epoch 65 | loss: 0.00021 | val_0_mse: 0.0     |  0:01:02s\n","epoch 66 | loss: 0.00021 | val_0_mse: 0.0     |  0:01:03s\n","epoch 67 | loss: 0.00021 | val_0_mse: 0.0     |  0:01:04s\n","epoch 68 | loss: 0.00021 | val_0_mse: 0.0     |  0:01:05s\n","epoch 69 | loss: 0.0002  | val_0_mse: 0.0     |  0:01:06s\n","epoch 70 | loss: 0.00022 | val_0_mse: 0.0     |  0:01:07s\n","epoch 71 | loss: 0.00024 | val_0_mse: 0.0     |  0:01:08s\n","epoch 72 | loss: 0.00025 | val_0_mse: 0.0     |  0:01:09s\n","epoch 73 | loss: 0.00024 | val_0_mse: 0.0     |  0:01:10s\n","epoch 74 | loss: 0.00024 | val_0_mse: 0.0     |  0:01:11s\n","epoch 75 | loss: 0.00024 | val_0_mse: 0.0     |  0:01:11s\n","epoch 76 | loss: 0.00024 | val_0_mse: 0.0     |  0:01:12s\n","epoch 77 | loss: 0.00024 | val_0_mse: 0.0     |  0:01:13s\n","epoch 78 | loss: 0.00023 | val_0_mse: 0.0     |  0:01:14s\n","epoch 79 | loss: 0.00023 | val_0_mse: 0.0     |  0:01:15s\n","epoch 80 | loss: 0.00023 | val_0_mse: 0.0     |  0:01:16s\n","epoch 81 | loss: 0.00026 | val_0_mse: 3.9999998989515007e-05|  0:01:17s\n","epoch 82 | loss: 0.0005  | val_0_mse: 0.0     |  0:01:18s\n","epoch 83 | loss: 0.00029 | val_0_mse: 2.9999999242136255e-05|  0:01:19s\n","epoch 84 | loss: 0.00025 | val_0_mse: 9.999999747378752e-06|  0:01:20s\n","epoch 85 | loss: 0.00024 | val_0_mse: 9.999999747378752e-06|  0:01:21s\n","epoch 86 | loss: 0.00023 | val_0_mse: 9.999999747378752e-06|  0:01:22s\n","epoch 87 | loss: 0.00023 | val_0_mse: 0.0     |  0:01:23s\n","epoch 88 | loss: 0.00022 | val_0_mse: 0.0     |  0:01:24s\n","\n","Early stopping occurred at epoch 88 with best_epoch = 78 and best_val_0_mse = 0.0\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 09:01:06,928] Trial 30 finished with value: 1.8104618959569052e-07 and parameters: {'n_d': 36, 'n_steps': 7, 'gamma': 1.7057621856090028, 'n_independent': 3, 'n_shared': 2, 'momentum': 0.12604779933706006}. Best is trial 20 with value: 1.2763081258526654e-07.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 5.52197 | val_0_mse: 15.818440437316895|  0:00:00s\n","epoch 1  | loss: 1.91857 | val_0_mse: 2.697580099105835|  0:00:01s\n","epoch 2  | loss: 1.37799 | val_0_mse: 6.3085198402404785|  0:00:02s\n","epoch 3  | loss: 1.84494 | val_0_mse: 0.3967899978160858|  0:00:03s\n","epoch 4  | loss: 1.0906  | val_0_mse: 0.5651400089263916|  0:00:04s\n","epoch 5  | loss: 0.62066 | val_0_mse: 0.23149000108242035|  0:00:05s\n","epoch 6  | loss: 0.28601 | val_0_mse: 0.45166999101638794|  0:00:06s\n","epoch 7  | loss: 0.31907 | val_0_mse: 0.019829999655485153|  0:00:07s\n","epoch 8  | loss: 0.13409 | val_0_mse: 0.018810000270605087|  0:00:08s\n","epoch 9  | loss: 0.1171  | val_0_mse: 0.018079999834299088|  0:00:09s\n","epoch 10 | loss: 0.0866  | val_0_mse: 0.005229999776929617|  0:00:10s\n","epoch 11 | loss: 0.0431  | val_0_mse: 0.0020000000949949026|  0:00:11s\n","epoch 12 | loss: 0.01414 | val_0_mse: 0.003809999907389283|  0:00:12s\n","epoch 13 | loss: 0.00787 | val_0_mse: 0.0022799998987466097|  0:00:13s\n","epoch 14 | loss: 0.00476 | val_0_mse: 0.001509999972768128|  0:00:13s\n","epoch 15 | loss: 0.00343 | val_0_mse: 0.0005099999834783375|  0:00:14s\n","epoch 16 | loss: 0.00263 | val_0_mse: 0.0004199999966658652|  0:00:15s\n","epoch 17 | loss: 0.00247 | val_0_mse: 0.0003499999875202775|  0:00:16s\n","epoch 18 | loss: 0.00183 | val_0_mse: 0.00031999999191612005|  0:00:17s\n","epoch 19 | loss: 0.00188 | val_0_mse: 0.0005300000193528831|  0:00:18s\n","epoch 20 | loss: 0.00185 | val_0_mse: 0.0012600000482052565|  0:00:19s\n","epoch 21 | loss: 0.00217 | val_0_mse: 0.0005000000237487257|  0:00:20s\n","epoch 22 | loss: 0.00209 | val_0_mse: 0.0003699999942909926|  0:00:21s\n","epoch 23 | loss: 0.00209 | val_0_mse: 0.0004900000058114529|  0:00:22s\n","epoch 24 | loss: 0.00181 | val_0_mse: 0.0003699999942909926|  0:00:23s\n","epoch 25 | loss: 0.00187 | val_0_mse: 0.00041000000783242285|  0:00:24s\n","epoch 26 | loss: 0.00193 | val_0_mse: 0.0006000000284984708|  0:00:24s\n","epoch 27 | loss: 0.00232 | val_0_mse: 0.00046999999904073775|  0:00:25s\n","epoch 28 | loss: 0.0019  | val_0_mse: 0.00033000000985339284|  0:00:26s\n","\n","Early stopping occurred at epoch 28 with best_epoch = 18 and best_val_0_mse = 0.00031999999191612005\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 09:01:34,255] Trial 31 finished with value: 0.0003155448066536337 and parameters: {'n_d': 37, 'n_steps': 7, 'gamma': 1.7206986221107825, 'n_independent': 3, 'n_shared': 2, 'momentum': 0.12888826407098966}. Best is trial 20 with value: 1.2763081258526654e-07.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 4.36307 | val_0_mse: 10.035799980163574|  0:00:01s\n","epoch 1  | loss: 1.80331 | val_0_mse: 0.5826399922370911|  0:00:02s\n","epoch 2  | loss: 2.01462 | val_0_mse: 1.7943300008773804|  0:00:03s\n","epoch 3  | loss: 2.13966 | val_0_mse: 0.09701000154018402|  0:00:04s\n","epoch 4  | loss: 1.01167 | val_0_mse: 0.43307000398635864|  0:00:05s\n","epoch 5  | loss: 0.78698 | val_0_mse: 0.06126999855041504|  0:00:06s\n","epoch 6  | loss: 0.5523  | val_0_mse: 0.02466999925673008|  0:00:07s\n","epoch 7  | loss: 0.53723 | val_0_mse: 0.029570000246167183|  0:00:08s\n","epoch 8  | loss: 0.17388 | val_0_mse: 0.007600000128149986|  0:00:09s\n","epoch 9  | loss: 0.12114 | val_0_mse: 0.013079999946057796|  0:00:10s\n","epoch 10 | loss: 0.11458 | val_0_mse: 0.003980000037699938|  0:00:11s\n","epoch 11 | loss: 0.02977 | val_0_mse: 0.010029999539256096|  0:00:12s\n","epoch 12 | loss: 0.00911 | val_0_mse: 0.0010300000431016088|  0:00:13s\n","epoch 13 | loss: 0.00427 | val_0_mse: 0.00039999998989515007|  0:00:14s\n","epoch 14 | loss: 0.00238 | val_0_mse: 0.000859999970998615|  0:00:15s\n","epoch 15 | loss: 0.00162 | val_0_mse: 0.0004900000058114529|  0:00:16s\n","epoch 16 | loss: 0.00121 | val_0_mse: 0.0002500000118743628|  0:00:17s\n","epoch 17 | loss: 0.001   | val_0_mse: 0.0002300000051036477|  0:00:18s\n","epoch 18 | loss: 0.0008  | val_0_mse: 0.00015999999595806003|  0:00:19s\n","epoch 19 | loss: 0.00067 | val_0_mse: 0.00014000000373926014|  0:00:20s\n","epoch 20 | loss: 0.00063 | val_0_mse: 0.00015999999595806003|  0:00:21s\n","epoch 21 | loss: 0.00061 | val_0_mse: 0.00011000000085914508|  0:00:22s\n","epoch 22 | loss: 0.00058 | val_0_mse: 9.000000136438757e-05|  0:00:23s\n","epoch 23 | loss: 0.00055 | val_0_mse: 0.00011000000085914508|  0:00:24s\n","epoch 24 | loss: 0.00049 | val_0_mse: 9.000000136438757e-05|  0:00:25s\n","epoch 25 | loss: 0.0005  | val_0_mse: 9.999999747378752e-05|  0:00:26s\n","epoch 26 | loss: 0.00048 | val_0_mse: 5.999999848427251e-05|  0:00:27s\n","epoch 27 | loss: 0.00045 | val_0_mse: 4.999999873689376e-05|  0:00:29s\n","epoch 28 | loss: 0.00043 | val_0_mse: 3.9999998989515007e-05|  0:00:30s\n","epoch 29 | loss: 0.0004  | val_0_mse: 2.9999999242136255e-05|  0:00:31s\n","epoch 30 | loss: 0.00039 | val_0_mse: 3.9999998989515007e-05|  0:00:32s\n","epoch 31 | loss: 0.00039 | val_0_mse: 2.9999999242136255e-05|  0:00:33s\n","epoch 32 | loss: 0.00037 | val_0_mse: 3.9999998989515007e-05|  0:00:34s\n","epoch 33 | loss: 0.0004  | val_0_mse: 7.999999797903001e-05|  0:00:35s\n","epoch 34 | loss: 0.00038 | val_0_mse: 4.999999873689376e-05|  0:00:36s\n","epoch 35 | loss: 0.00037 | val_0_mse: 3.9999998989515007e-05|  0:00:37s\n","epoch 36 | loss: 0.00036 | val_0_mse: 3.9999998989515007e-05|  0:00:38s\n","epoch 37 | loss: 0.00037 | val_0_mse: 9.000000136438757e-05|  0:00:39s\n","epoch 38 | loss: 0.00044 | val_0_mse: 0.00011000000085914508|  0:00:40s\n","epoch 39 | loss: 0.00051 | val_0_mse: 0.00022000000171829015|  0:00:41s\n","epoch 40 | loss: 0.00058 | val_0_mse: 0.0001500000071246177|  0:00:42s\n","epoch 41 | loss: 0.0005  | val_0_mse: 0.00015999999595806003|  0:00:43s\n","\n","Early stopping occurred at epoch 41 with best_epoch = 31 and best_val_0_mse = 2.9999999242136255e-05\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 09:02:18,460] Trial 32 finished with value: 2.8575168471434154e-05 and parameters: {'n_d': 42, 'n_steps': 7, 'gamma': 1.831621389650859, 'n_independent': 3, 'n_shared': 3, 'momentum': 0.13900311572720767}. Best is trial 20 with value: 1.2763081258526654e-07.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 11.36805| val_0_mse: 15.735910415649414|  0:00:01s\n","epoch 1  | loss: 4.96844 | val_0_mse: 14.596870422363281|  0:00:02s\n","epoch 2  | loss: 1.89708 | val_0_mse: 4.7296600341796875|  0:00:03s\n","epoch 3  | loss: 2.2019  | val_0_mse: 18.503419876098633|  0:00:04s\n","epoch 4  | loss: 0.7158  | val_0_mse: 0.31060999631881714|  0:00:05s\n","epoch 5  | loss: 0.54836 | val_0_mse: 1.994860053062439|  0:00:06s\n","epoch 6  | loss: 2.64388 | val_0_mse: 1.480180025100708|  0:00:07s\n","epoch 7  | loss: 0.65641 | val_0_mse: 0.5468999743461609|  0:00:08s\n","epoch 8  | loss: 0.10302 | val_0_mse: 0.07393000274896622|  0:00:09s\n","epoch 9  | loss: 0.04325 | val_0_mse: 0.07586999982595444|  0:00:10s\n","epoch 10 | loss: 0.01471 | val_0_mse: 0.010029999539256096|  0:00:11s\n","epoch 11 | loss: 0.00533 | val_0_mse: 0.009820000268518925|  0:00:12s\n","epoch 12 | loss: 0.00268 | val_0_mse: 0.0006300000241026282|  0:00:13s\n","epoch 13 | loss: 0.0019  | val_0_mse: 0.00026000000070780516|  0:00:14s\n","epoch 14 | loss: 0.00127 | val_0_mse: 0.00023999999393709004|  0:00:15s\n","epoch 15 | loss: 0.00093 | val_0_mse: 0.0002800000074785203|  0:00:16s\n","epoch 16 | loss: 0.00088 | val_0_mse: 7.999999797903001e-05|  0:00:17s\n","epoch 17 | loss: 0.00078 | val_0_mse: 0.00014000000373926014|  0:00:18s\n","epoch 18 | loss: 0.00068 | val_0_mse: 5.999999848427251e-05|  0:00:19s\n","epoch 19 | loss: 0.00076 | val_0_mse: 7.000000186963007e-05|  0:00:20s\n","epoch 20 | loss: 0.00074 | val_0_mse: 5.999999848427251e-05|  0:00:21s\n","epoch 21 | loss: 0.00079 | val_0_mse: 7.999999797903001e-05|  0:00:22s\n","epoch 22 | loss: 0.00076 | val_0_mse: 7.000000186963007e-05|  0:00:23s\n","epoch 23 | loss: 0.00072 | val_0_mse: 7.999999797903001e-05|  0:00:24s\n","epoch 24 | loss: 0.00147 | val_0_mse: 0.00011999999696854502|  0:00:25s\n","epoch 25 | loss: 0.00121 | val_0_mse: 9.999999747378752e-05|  0:00:26s\n","epoch 26 | loss: 0.00096 | val_0_mse: 0.00019999999494757503|  0:00:27s\n","epoch 27 | loss: 0.00084 | val_0_mse: 0.00013000000035390258|  0:00:28s\n","epoch 28 | loss: 0.00075 | val_0_mse: 0.00014000000373926014|  0:00:29s\n","epoch 29 | loss: 0.00067 | val_0_mse: 7.999999797903001e-05|  0:00:30s\n","epoch 30 | loss: 0.00056 | val_0_mse: 7.000000186963007e-05|  0:00:31s\n","\n","Early stopping occurred at epoch 30 with best_epoch = 20 and best_val_0_mse = 5.999999848427251e-05\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 09:02:50,640] Trial 33 finished with value: 6.136242882348597e-05 and parameters: {'n_d': 46, 'n_steps': 8, 'gamma': 1.3729435703479975, 'n_independent': 3, 'n_shared': 2, 'momentum': 0.24741902185824344}. Best is trial 20 with value: 1.2763081258526654e-07.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 2.38719 | val_0_mse: 4.1743998527526855|  0:00:00s\n","epoch 1  | loss: 0.86599 | val_0_mse: 1.825410008430481|  0:00:01s\n","epoch 2  | loss: 1.25381 | val_0_mse: 0.9846900105476379|  0:00:02s\n","epoch 3  | loss: 0.88207 | val_0_mse: 0.3905099928379059|  0:00:03s\n","epoch 4  | loss: 0.52605 | val_0_mse: 0.3949500024318695|  0:00:04s\n","epoch 5  | loss: 1.88855 | val_0_mse: 2.2140400409698486|  0:00:05s\n","epoch 6  | loss: 0.90736 | val_0_mse: 0.15296000242233276|  0:00:06s\n","epoch 7  | loss: 0.11173 | val_0_mse: 0.03720000013709068|  0:00:07s\n","epoch 8  | loss: 0.05713 | val_0_mse: 0.04129999876022339|  0:00:08s\n","epoch 9  | loss: 0.05754 | val_0_mse: 0.010769999586045742|  0:00:09s\n","epoch 10 | loss: 0.02729 | val_0_mse: 0.003719999920576811|  0:00:09s\n","epoch 11 | loss: 0.00686 | val_0_mse: 0.001500000013038516|  0:00:10s\n","epoch 12 | loss: 0.00361 | val_0_mse: 0.0009200000204145908|  0:00:11s\n","epoch 13 | loss: 0.00189 | val_0_mse: 0.00033999999868683517|  0:00:12s\n","epoch 14 | loss: 0.00093 | val_0_mse: 0.0001900000061141327|  0:00:13s\n","epoch 15 | loss: 0.00064 | val_0_mse: 0.0002300000051036477|  0:00:14s\n","epoch 16 | loss: 0.00053 | val_0_mse: 9.000000136438757e-05|  0:00:15s\n","epoch 17 | loss: 0.00046 | val_0_mse: 9.000000136438757e-05|  0:00:16s\n","epoch 18 | loss: 0.00042 | val_0_mse: 4.999999873689376e-05|  0:00:17s\n","epoch 19 | loss: 0.00039 | val_0_mse: 9.000000136438757e-05|  0:00:18s\n","epoch 20 | loss: 0.00036 | val_0_mse: 3.9999998989515007e-05|  0:00:19s\n","epoch 21 | loss: 0.00034 | val_0_mse: 2.9999999242136255e-05|  0:00:20s\n","epoch 22 | loss: 0.00032 | val_0_mse: 2.9999999242136255e-05|  0:00:21s\n","epoch 23 | loss: 0.00031 | val_0_mse: 2.9999999242136255e-05|  0:00:21s\n","epoch 24 | loss: 0.0003  | val_0_mse: 1.9999999494757503e-05|  0:00:22s\n","epoch 25 | loss: 0.0003  | val_0_mse: 1.9999999494757503e-05|  0:00:23s\n","epoch 26 | loss: 0.00029 | val_0_mse: 1.9999999494757503e-05|  0:00:24s\n","epoch 27 | loss: 0.00028 | val_0_mse: 9.999999747378752e-06|  0:00:25s\n","epoch 28 | loss: 0.00027 | val_0_mse: 9.999999747378752e-06|  0:00:26s\n","epoch 29 | loss: 0.00027 | val_0_mse: 9.999999747378752e-06|  0:00:27s\n","epoch 30 | loss: 0.00026 | val_0_mse: 9.999999747378752e-06|  0:00:28s\n","epoch 31 | loss: 0.00025 | val_0_mse: 9.999999747378752e-06|  0:00:29s\n","epoch 32 | loss: 0.00024 | val_0_mse: 9.999999747378752e-06|  0:00:30s\n","epoch 33 | loss: 0.00024 | val_0_mse: 9.999999747378752e-06|  0:00:31s\n","epoch 34 | loss: 0.00024 | val_0_mse: 9.999999747378752e-06|  0:00:31s\n","epoch 35 | loss: 0.00024 | val_0_mse: 9.999999747378752e-06|  0:00:32s\n","epoch 36 | loss: 0.00024 | val_0_mse: 9.999999747378752e-06|  0:00:33s\n","epoch 37 | loss: 0.00023 | val_0_mse: 9.999999747378752e-06|  0:00:34s\n","epoch 38 | loss: 0.00023 | val_0_mse: 0.0     |  0:00:35s\n","epoch 39 | loss: 0.00023 | val_0_mse: 0.0     |  0:00:36s\n","epoch 40 | loss: 0.00022 | val_0_mse: 0.0     |  0:00:37s\n","epoch 41 | loss: 0.00022 | val_0_mse: 0.0     |  0:00:38s\n","epoch 42 | loss: 0.00022 | val_0_mse: 0.0     |  0:00:39s\n","epoch 43 | loss: 0.00022 | val_0_mse: 0.0     |  0:00:40s\n","epoch 44 | loss: 0.00022 | val_0_mse: 0.0     |  0:00:41s\n","epoch 45 | loss: 0.00022 | val_0_mse: 0.0     |  0:00:42s\n","epoch 46 | loss: 0.00022 | val_0_mse: 0.0     |  0:00:42s\n","epoch 47 | loss: 0.00022 | val_0_mse: 0.0     |  0:00:43s\n","epoch 48 | loss: 0.00021 | val_0_mse: 0.0     |  0:00:44s\n","epoch 49 | loss: 0.00021 | val_0_mse: 0.0     |  0:00:45s\n","epoch 50 | loss: 0.00022 | val_0_mse: 0.0     |  0:00:46s\n","epoch 51 | loss: 0.00021 | val_0_mse: 0.0     |  0:00:47s\n","epoch 52 | loss: 0.00021 | val_0_mse: 0.0     |  0:00:48s\n","epoch 53 | loss: 0.00021 | val_0_mse: 0.0     |  0:00:49s\n","epoch 54 | loss: 0.00021 | val_0_mse: 0.0     |  0:00:50s\n","epoch 55 | loss: 0.00021 | val_0_mse: 0.0     |  0:00:51s\n","epoch 56 | loss: 0.00021 | val_0_mse: 0.0     |  0:00:52s\n","epoch 57 | loss: 0.00021 | val_0_mse: 0.0     |  0:00:52s\n","epoch 58 | loss: 0.00021 | val_0_mse: 0.0     |  0:00:53s\n","epoch 59 | loss: 0.00021 | val_0_mse: 0.0     |  0:00:54s\n","epoch 60 | loss: 0.00021 | val_0_mse: 0.0     |  0:00:55s\n","epoch 61 | loss: 0.00021 | val_0_mse: 0.0     |  0:00:56s\n","epoch 62 | loss: 0.00021 | val_0_mse: 0.0     |  0:00:57s\n","epoch 63 | loss: 0.00021 | val_0_mse: 0.0     |  0:00:58s\n","epoch 64 | loss: 0.00021 | val_0_mse: 0.0     |  0:00:59s\n","epoch 65 | loss: 0.00021 | val_0_mse: 0.0     |  0:01:00s\n","epoch 66 | loss: 0.00021 | val_0_mse: 0.0     |  0:01:01s\n","epoch 67 | loss: 0.00021 | val_0_mse: 0.0     |  0:01:02s\n","epoch 68 | loss: 0.00021 | val_0_mse: 0.0     |  0:01:03s\n","epoch 69 | loss: 0.00021 | val_0_mse: 0.0     |  0:01:03s\n","epoch 70 | loss: 0.00022 | val_0_mse: 0.0     |  0:01:04s\n","epoch 71 | loss: 0.00022 | val_0_mse: 0.0     |  0:01:05s\n","epoch 72 | loss: 0.00022 | val_0_mse: 0.0     |  0:01:06s\n","epoch 73 | loss: 0.00022 | val_0_mse: 0.0     |  0:01:07s\n","epoch 74 | loss: 0.00021 | val_0_mse: 0.0     |  0:01:08s\n","epoch 75 | loss: 0.00021 | val_0_mse: 0.0     |  0:01:09s\n","epoch 76 | loss: 0.00021 | val_0_mse: 0.0     |  0:01:10s\n","epoch 77 | loss: 0.00021 | val_0_mse: 0.0     |  0:01:11s\n","epoch 78 | loss: 0.00021 | val_0_mse: 0.0     |  0:01:12s\n","epoch 79 | loss: 0.00021 | val_0_mse: 0.0     |  0:01:13s\n","epoch 80 | loss: 0.0002  | val_0_mse: 0.0     |  0:01:14s\n","epoch 81 | loss: 0.0002  | val_0_mse: 0.0     |  0:01:15s\n","epoch 82 | loss: 0.0002  | val_0_mse: 0.0     |  0:01:16s\n","epoch 83 | loss: 0.00021 | val_0_mse: 0.0     |  0:01:17s\n","epoch 84 | loss: 0.00021 | val_0_mse: 0.0     |  0:01:18s\n","epoch 85 | loss: 0.00021 | val_0_mse: 0.0     |  0:01:19s\n","epoch 86 | loss: 0.00022 | val_0_mse: 0.0     |  0:01:20s\n","epoch 87 | loss: 0.00023 | val_0_mse: 0.0     |  0:01:22s\n","epoch 88 | loss: 0.00023 | val_0_mse: 0.0     |  0:01:23s\n","epoch 89 | loss: 0.00022 | val_0_mse: 0.0     |  0:01:23s\n","epoch 90 | loss: 0.00022 | val_0_mse: 0.0     |  0:01:25s\n","epoch 91 | loss: 0.00022 | val_0_mse: 0.0     |  0:01:26s\n","epoch 92 | loss: 0.00022 | val_0_mse: 0.0     |  0:01:27s\n","epoch 93 | loss: 0.00021 | val_0_mse: 0.0     |  0:01:28s\n","epoch 94 | loss: 0.00021 | val_0_mse: 0.0     |  0:01:28s\n","epoch 95 | loss: 0.00021 | val_0_mse: 0.0     |  0:01:29s\n","epoch 96 | loss: 0.00021 | val_0_mse: 0.0     |  0:01:30s\n","epoch 97 | loss: 0.0002  | val_0_mse: 0.0     |  0:01:31s\n","epoch 98 | loss: 0.00019 | val_0_mse: 0.0     |  0:01:32s\n","epoch 99 | loss: 0.00019 | val_0_mse: 0.0     |  0:01:33s\n","Stop training because you reached max_epochs = 100 with best_epoch = 99 and best_val_0_mse = 0.0\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 09:04:24,984] Trial 34 finished with value: 3.3380075592504e-07 and parameters: {'n_d': 31, 'n_steps': 7, 'gamma': 1.6482404875722092, 'n_independent': 2, 'n_shared': 3, 'momentum': 0.27561645017956043}. Best is trial 20 with value: 1.2763081258526654e-07.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 6.27611 | val_0_mse: 34.00408172607422|  0:00:01s\n","epoch 1  | loss: 3.75337 | val_0_mse: 19.13128089904785|  0:00:02s\n","epoch 2  | loss: 5.811   | val_0_mse: 4.51161003112793|  0:00:03s\n","epoch 3  | loss: 1.8534  | val_0_mse: 2.7330100536346436|  0:00:04s\n","epoch 4  | loss: 0.60173 | val_0_mse: 1.1951700448989868|  0:00:05s\n","epoch 5  | loss: 0.58454 | val_0_mse: 1.0651700496673584|  0:00:07s\n","epoch 6  | loss: 1.33743 | val_0_mse: 1.2749799489974976|  0:00:08s\n","epoch 7  | loss: 0.73475 | val_0_mse: 0.12732000648975372|  0:00:09s\n","epoch 8  | loss: 0.58542 | val_0_mse: 0.020160000771284103|  0:00:10s\n","epoch 9  | loss: 0.15769 | val_0_mse: 0.055390000343322754|  0:00:11s\n","epoch 10 | loss: 0.14737 | val_0_mse: 0.012059999629855156|  0:00:13s\n","epoch 11 | loss: 0.06632 | val_0_mse: 0.006279999855905771|  0:00:14s\n","epoch 12 | loss: 0.02296 | val_0_mse: 0.00044999999227002263|  0:00:15s\n","epoch 13 | loss: 0.00814 | val_0_mse: 0.0005200000014156103|  0:00:16s\n","epoch 14 | loss: 0.00375 | val_0_mse: 0.00033000000985339284|  0:00:17s\n","epoch 15 | loss: 0.00195 | val_0_mse: 0.00026000000070780516|  0:00:18s\n","epoch 16 | loss: 0.00139 | val_0_mse: 0.00016999999934341758|  0:00:20s\n","epoch 17 | loss: 0.00105 | val_0_mse: 0.00039999998989515007|  0:00:21s\n","epoch 18 | loss: 0.00093 | val_0_mse: 0.0004799999878741801|  0:00:22s\n","epoch 19 | loss: 0.00099 | val_0_mse: 0.00039000000106170774|  0:00:23s\n","epoch 20 | loss: 0.00101 | val_0_mse: 0.0003800000122282654|  0:00:24s\n","epoch 21 | loss: 0.00086 | val_0_mse: 0.0002699999895412475|  0:00:25s\n","epoch 22 | loss: 0.00078 | val_0_mse: 0.0002099999983329326|  0:00:27s\n","epoch 23 | loss: 0.00066 | val_0_mse: 0.0001900000061141327|  0:00:28s\n","epoch 24 | loss: 0.00063 | val_0_mse: 0.00013000000035390258|  0:00:29s\n","epoch 25 | loss: 0.00054 | val_0_mse: 7.000000186963007e-05|  0:00:30s\n","epoch 26 | loss: 0.00052 | val_0_mse: 5.999999848427251e-05|  0:00:31s\n","epoch 27 | loss: 0.00047 | val_0_mse: 3.9999998989515007e-05|  0:00:32s\n","epoch 28 | loss: 0.00047 | val_0_mse: 3.9999998989515007e-05|  0:00:34s\n","epoch 29 | loss: 0.00045 | val_0_mse: 7.999999797903001e-05|  0:00:35s\n","epoch 30 | loss: 0.00042 | val_0_mse: 9.999999747378752e-05|  0:00:36s\n","epoch 31 | loss: 0.0004  | val_0_mse: 7.000000186963007e-05|  0:00:37s\n","epoch 32 | loss: 0.00041 | val_0_mse: 3.9999998989515007e-05|  0:00:38s\n","epoch 33 | loss: 0.00076 | val_0_mse: 7.000000186963007e-05|  0:00:40s\n","epoch 34 | loss: 0.0007  | val_0_mse: 0.00011999999696854502|  0:00:41s\n","epoch 35 | loss: 0.00059 | val_0_mse: 7.999999797903001e-05|  0:00:42s\n","epoch 36 | loss: 0.00054 | val_0_mse: 9.999999747378752e-05|  0:00:43s\n","epoch 37 | loss: 0.00053 | val_0_mse: 9.000000136438757e-05|  0:00:44s\n","epoch 38 | loss: 0.00051 | val_0_mse: 4.999999873689376e-05|  0:00:46s\n","epoch 39 | loss: 0.00049 | val_0_mse: 5.999999848427251e-05|  0:00:47s\n","epoch 40 | loss: 0.00044 | val_0_mse: 5.999999848427251e-05|  0:00:48s\n","epoch 41 | loss: 0.00043 | val_0_mse: 4.999999873689376e-05|  0:00:49s\n","epoch 42 | loss: 0.0004  | val_0_mse: 3.9999998989515007e-05|  0:00:50s\n","\n","Early stopping occurred at epoch 42 with best_epoch = 32 and best_val_0_mse = 3.9999998989515007e-05\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 09:05:16,384] Trial 35 finished with value: 3.6593835829989985e-05 and parameters: {'n_d': 34, 'n_steps': 8, 'gamma': 1.9213316991143887, 'n_independent': 4, 'n_shared': 2, 'momentum': 0.20005505766421197}. Best is trial 20 with value: 1.2763081258526654e-07.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 4.77165 | val_0_mse: 21.934019088745117|  0:00:00s\n","epoch 1  | loss: 1.76879 | val_0_mse: 7.937769889831543|  0:00:01s\n","epoch 2  | loss: 1.978   | val_0_mse: 0.3390200138092041|  0:00:02s\n","epoch 3  | loss: 0.86553 | val_0_mse: 0.47091999650001526|  0:00:02s\n","epoch 4  | loss: 0.22044 | val_0_mse: 0.0690699964761734|  0:00:03s\n","epoch 5  | loss: 0.14506 | val_0_mse: 0.06809999793767929|  0:00:04s\n","epoch 6  | loss: 0.07989 | val_0_mse: 0.020269999280571938|  0:00:05s\n","epoch 7  | loss: 0.03944 | val_0_mse: 0.007890000008046627|  0:00:05s\n","epoch 8  | loss: 0.03206 | val_0_mse: 0.008059999905526638|  0:00:06s\n","epoch 9  | loss: 0.01646 | val_0_mse: 0.008489999920129776|  0:00:07s\n","epoch 10 | loss: 0.01349 | val_0_mse: 0.00571999978274107|  0:00:08s\n","epoch 11 | loss: 0.00764 | val_0_mse: 0.0029299999587237835|  0:00:08s\n","epoch 12 | loss: 0.00734 | val_0_mse: 0.002099999925121665|  0:00:09s\n","epoch 13 | loss: 0.00461 | val_0_mse: 0.0019199999514967203|  0:00:10s\n","epoch 14 | loss: 0.00288 | val_0_mse: 0.0013200000394135714|  0:00:10s\n","epoch 15 | loss: 0.00217 | val_0_mse: 0.00039999998989515007|  0:00:11s\n","epoch 16 | loss: 0.00168 | val_0_mse: 0.0005300000193528831|  0:00:12s\n","epoch 17 | loss: 0.00161 | val_0_mse: 0.0005000000237487257|  0:00:13s\n","epoch 18 | loss: 0.00162 | val_0_mse: 0.0004600000102072954|  0:00:13s\n","epoch 19 | loss: 0.00175 | val_0_mse: 0.0012400000123307109|  0:00:14s\n","epoch 20 | loss: 0.00118 | val_0_mse: 0.0004299999854993075|  0:00:15s\n","epoch 21 | loss: 0.00167 | val_0_mse: 0.0005600000149570405|  0:00:15s\n","epoch 22 | loss: 0.00168 | val_0_mse: 0.0007900000200606883|  0:00:16s\n","epoch 23 | loss: 0.00105 | val_0_mse: 0.00041000000783242285|  0:00:17s\n","epoch 24 | loss: 0.00071 | val_0_mse: 0.0002699999895412475|  0:00:18s\n","epoch 25 | loss: 0.00057 | val_0_mse: 0.00011999999696854502|  0:00:18s\n","epoch 26 | loss: 0.00046 | val_0_mse: 0.00011999999696854502|  0:00:19s\n","epoch 27 | loss: 0.00045 | val_0_mse: 0.00013000000035390258|  0:00:20s\n","epoch 28 | loss: 0.00044 | val_0_mse: 7.000000186963007e-05|  0:00:21s\n","epoch 29 | loss: 0.00047 | val_0_mse: 9.000000136438757e-05|  0:00:21s\n","epoch 30 | loss: 0.00047 | val_0_mse: 7.000000186963007e-05|  0:00:22s\n","epoch 31 | loss: 0.0004  | val_0_mse: 7.000000186963007e-05|  0:00:23s\n","epoch 32 | loss: 0.00041 | val_0_mse: 0.00011000000085914508|  0:00:23s\n","epoch 33 | loss: 0.00044 | val_0_mse: 7.000000186963007e-05|  0:00:24s\n","epoch 34 | loss: 0.0004  | val_0_mse: 4.999999873689376e-05|  0:00:25s\n","epoch 35 | loss: 0.00036 | val_0_mse: 4.999999873689376e-05|  0:00:26s\n","epoch 36 | loss: 0.00035 | val_0_mse: 4.999999873689376e-05|  0:00:26s\n","epoch 37 | loss: 0.00039 | val_0_mse: 3.9999998989515007e-05|  0:00:27s\n","epoch 38 | loss: 0.00035 | val_0_mse: 7.000000186963007e-05|  0:00:28s\n","epoch 39 | loss: 0.00033 | val_0_mse: 5.999999848427251e-05|  0:00:28s\n","epoch 40 | loss: 0.00032 | val_0_mse: 5.999999848427251e-05|  0:00:29s\n","epoch 41 | loss: 0.00032 | val_0_mse: 5.999999848427251e-05|  0:00:30s\n","epoch 42 | loss: 0.00029 | val_0_mse: 4.999999873689376e-05|  0:00:30s\n","epoch 43 | loss: 0.0003  | val_0_mse: 7.999999797903001e-05|  0:00:31s\n","epoch 44 | loss: 0.00035 | val_0_mse: 2.9999999242136255e-05|  0:00:32s\n","epoch 45 | loss: 0.00028 | val_0_mse: 2.9999999242136255e-05|  0:00:33s\n","epoch 46 | loss: 0.00028 | val_0_mse: 2.9999999242136255e-05|  0:00:33s\n","epoch 47 | loss: 0.00026 | val_0_mse: 2.9999999242136255e-05|  0:00:34s\n","epoch 48 | loss: 0.00027 | val_0_mse: 2.9999999242136255e-05|  0:00:35s\n","epoch 49 | loss: 0.00027 | val_0_mse: 1.9999999494757503e-05|  0:00:35s\n","epoch 50 | loss: 0.00026 | val_0_mse: 2.9999999242136255e-05|  0:00:36s\n","epoch 51 | loss: 0.00026 | val_0_mse: 2.9999999242136255e-05|  0:00:37s\n","epoch 52 | loss: 0.00024 | val_0_mse: 2.9999999242136255e-05|  0:00:38s\n","epoch 53 | loss: 0.00024 | val_0_mse: 2.9999999242136255e-05|  0:00:38s\n","epoch 54 | loss: 0.00024 | val_0_mse: 2.9999999242136255e-05|  0:00:39s\n","epoch 55 | loss: 0.00028 | val_0_mse: 2.9999999242136255e-05|  0:00:40s\n","epoch 56 | loss: 0.00027 | val_0_mse: 1.9999999494757503e-05|  0:00:40s\n","epoch 57 | loss: 0.00025 | val_0_mse: 1.9999999494757503e-05|  0:00:41s\n","epoch 58 | loss: 0.00027 | val_0_mse: 4.999999873689376e-05|  0:00:42s\n","epoch 59 | loss: 0.00026 | val_0_mse: 2.9999999242136255e-05|  0:00:43s\n","epoch 60 | loss: 0.00025 | val_0_mse: 2.9999999242136255e-05|  0:00:43s\n","epoch 61 | loss: 0.00026 | val_0_mse: 2.9999999242136255e-05|  0:00:44s\n","epoch 62 | loss: 0.00024 | val_0_mse: 4.999999873689376e-05|  0:00:45s\n","epoch 63 | loss: 0.00026 | val_0_mse: 1.9999999494757503e-05|  0:00:45s\n","epoch 64 | loss: 0.00023 | val_0_mse: 4.999999873689376e-05|  0:00:46s\n","epoch 65 | loss: 0.00026 | val_0_mse: 1.9999999494757503e-05|  0:00:47s\n","epoch 66 | loss: 0.00035 | val_0_mse: 3.9999998989515007e-05|  0:00:47s\n","epoch 67 | loss: 0.00024 | val_0_mse: 1.9999999494757503e-05|  0:00:48s\n","epoch 68 | loss: 0.00024 | val_0_mse: 2.9999999242136255e-05|  0:00:49s\n","epoch 69 | loss: 0.00024 | val_0_mse: 1.9999999494757503e-05|  0:00:49s\n","epoch 70 | loss: 0.00023 | val_0_mse: 1.9999999494757503e-05|  0:00:50s\n","epoch 71 | loss: 0.00023 | val_0_mse: 3.9999998989515007e-05|  0:00:51s\n","epoch 72 | loss: 0.00043 | val_0_mse: 0.0002300000051036477|  0:00:52s\n","epoch 73 | loss: 0.00049 | val_0_mse: 9.999999747378752e-05|  0:00:52s\n","epoch 74 | loss: 0.00037 | val_0_mse: 7.000000186963007e-05|  0:00:53s\n","epoch 75 | loss: 0.00032 | val_0_mse: 7.999999797903001e-05|  0:00:54s\n","epoch 76 | loss: 0.0003  | val_0_mse: 2.9999999242136255e-05|  0:00:55s\n","epoch 77 | loss: 0.00029 | val_0_mse: 7.999999797903001e-05|  0:00:55s\n","\n","Early stopping occurred at epoch 77 with best_epoch = 67 and best_val_0_mse = 1.9999999494757503e-05\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 09:06:12,570] Trial 36 finished with value: 1.6221347323153168e-05 and parameters: {'n_d': 57, 'n_steps': 5, 'gamma': 1.6955034252307042, 'n_independent': 2, 'n_shared': 3, 'momentum': 0.22547761813396022}. Best is trial 20 with value: 1.2763081258526654e-07.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 4.29458 | val_0_mse: 12.174059867858887|  0:00:01s\n","epoch 1  | loss: 3.62382 | val_0_mse: 0.7661899924278259|  0:00:02s\n","epoch 2  | loss: 1.39085 | val_0_mse: 1.147029995918274|  0:00:03s\n","epoch 3  | loss: 1.21152 | val_0_mse: 0.42500999569892883|  0:00:04s\n","epoch 4  | loss: 0.42867 | val_0_mse: 1.4659500122070312|  0:00:05s\n","epoch 5  | loss: 0.26353 | val_0_mse: 0.2049800008535385|  0:00:06s\n","epoch 6  | loss: 0.15097 | val_0_mse: 0.01655999943614006|  0:00:07s\n","epoch 7  | loss: 0.10719 | val_0_mse: 0.02993999980390072|  0:00:08s\n","epoch 8  | loss: 0.04797 | val_0_mse: 0.006020000204443932|  0:00:09s\n","epoch 9  | loss: 0.02518 | val_0_mse: 0.003909999970346689|  0:00:10s\n","epoch 10 | loss: 0.01036 | val_0_mse: 0.0007099999929778278|  0:00:11s\n","epoch 11 | loss: 0.00376 | val_0_mse: 0.0006000000284984708|  0:00:12s\n","epoch 12 | loss: 0.00183 | val_0_mse: 0.0003000000142492354|  0:00:13s\n","epoch 13 | loss: 0.00134 | val_0_mse: 0.0004600000102072954|  0:00:14s\n","epoch 14 | loss: 0.00139 | val_0_mse: 0.0002699999895412475|  0:00:15s\n","epoch 15 | loss: 0.00136 | val_0_mse: 0.0002899999963119626|  0:00:16s\n","epoch 16 | loss: 0.00211 | val_0_mse: 0.0004400000034365803|  0:00:17s\n","epoch 17 | loss: 0.00265 | val_0_mse: 0.0004600000102072954|  0:00:18s\n","epoch 18 | loss: 0.00182 | val_0_mse: 0.00023999999393709004|  0:00:19s\n","epoch 19 | loss: 0.00165 | val_0_mse: 0.0002899999963119626|  0:00:20s\n","epoch 20 | loss: 0.00133 | val_0_mse: 0.00016999999934341758|  0:00:21s\n","epoch 21 | loss: 0.00162 | val_0_mse: 0.0003100000030826777|  0:00:22s\n","epoch 22 | loss: 0.00117 | val_0_mse: 0.0003800000122282654|  0:00:24s\n","epoch 23 | loss: 0.00098 | val_0_mse: 0.00033999999868683517|  0:00:25s\n","epoch 24 | loss: 0.00093 | val_0_mse: 0.0003000000142492354|  0:00:26s\n","epoch 25 | loss: 0.00091 | val_0_mse: 0.00023999999393709004|  0:00:27s\n","epoch 26 | loss: 0.00062 | val_0_mse: 0.0001500000071246177|  0:00:28s\n","epoch 27 | loss: 0.00052 | val_0_mse: 0.00011999999696854502|  0:00:29s\n","epoch 28 | loss: 0.00047 | val_0_mse: 0.00013000000035390258|  0:00:30s\n","epoch 29 | loss: 0.00044 | val_0_mse: 0.0001500000071246177|  0:00:31s\n","epoch 30 | loss: 0.00039 | val_0_mse: 9.999999747378752e-05|  0:00:32s\n","epoch 31 | loss: 0.00038 | val_0_mse: 0.00013000000035390258|  0:00:33s\n","epoch 32 | loss: 0.00037 | val_0_mse: 7.999999797903001e-05|  0:00:34s\n","epoch 33 | loss: 0.00054 | val_0_mse: 0.00011999999696854502|  0:00:35s\n","epoch 34 | loss: 0.00058 | val_0_mse: 7.000000186963007e-05|  0:00:36s\n","epoch 35 | loss: 0.00049 | val_0_mse: 0.00011000000085914508|  0:00:37s\n","epoch 36 | loss: 0.00044 | val_0_mse: 5.999999848427251e-05|  0:00:38s\n","epoch 37 | loss: 0.00043 | val_0_mse: 7.000000186963007e-05|  0:00:39s\n","epoch 38 | loss: 0.00036 | val_0_mse: 4.999999873689376e-05|  0:00:40s\n","epoch 39 | loss: 0.00032 | val_0_mse: 3.9999998989515007e-05|  0:00:41s\n","epoch 40 | loss: 0.00034 | val_0_mse: 3.9999998989515007e-05|  0:00:43s\n","epoch 41 | loss: 0.00031 | val_0_mse: 2.9999999242136255e-05|  0:00:44s\n","epoch 42 | loss: 0.0003  | val_0_mse: 2.9999999242136255e-05|  0:00:45s\n","epoch 43 | loss: 0.0003  | val_0_mse: 2.9999999242136255e-05|  0:00:46s\n","epoch 44 | loss: 0.00027 | val_0_mse: 2.9999999242136255e-05|  0:00:47s\n","epoch 45 | loss: 0.00026 | val_0_mse: 1.9999999494757503e-05|  0:00:48s\n","epoch 46 | loss: 0.00026 | val_0_mse: 2.9999999242136255e-05|  0:00:49s\n","epoch 47 | loss: 0.00026 | val_0_mse: 2.9999999242136255e-05|  0:00:50s\n","epoch 48 | loss: 0.00026 | val_0_mse: 2.9999999242136255e-05|  0:00:51s\n","epoch 49 | loss: 0.00026 | val_0_mse: 2.9999999242136255e-05|  0:00:52s\n","epoch 50 | loss: 0.00025 | val_0_mse: 2.9999999242136255e-05|  0:00:53s\n","epoch 51 | loss: 0.00023 | val_0_mse: 1.9999999494757503e-05|  0:00:54s\n","epoch 52 | loss: 0.00023 | val_0_mse: 1.9999999494757503e-05|  0:00:55s\n","epoch 53 | loss: 0.00022 | val_0_mse: 1.9999999494757503e-05|  0:00:57s\n","epoch 54 | loss: 0.00023 | val_0_mse: 1.9999999494757503e-05|  0:00:58s\n","epoch 55 | loss: 0.00023 | val_0_mse: 1.9999999494757503e-05|  0:00:59s\n","epoch 56 | loss: 0.00022 | val_0_mse: 1.9999999494757503e-05|  0:01:00s\n","epoch 57 | loss: 0.00022 | val_0_mse: 1.9999999494757503e-05|  0:01:01s\n","epoch 58 | loss: 0.00023 | val_0_mse: 1.9999999494757503e-05|  0:01:02s\n","epoch 59 | loss: 0.00022 | val_0_mse: 2.9999999242136255e-05|  0:01:03s\n","epoch 60 | loss: 0.00021 | val_0_mse: 1.9999999494757503e-05|  0:01:04s\n","epoch 61 | loss: 0.0002  | val_0_mse: 1.9999999494757503e-05|  0:01:05s\n","epoch 62 | loss: 0.00021 | val_0_mse: 1.9999999494757503e-05|  0:01:06s\n","epoch 63 | loss: 0.00023 | val_0_mse: 1.9999999494757503e-05|  0:01:07s\n","epoch 64 | loss: 0.00021 | val_0_mse: 1.9999999494757503e-05|  0:01:08s\n","epoch 65 | loss: 0.00021 | val_0_mse: 9.999999747378752e-06|  0:01:09s\n","epoch 66 | loss: 0.0002  | val_0_mse: 9.999999747378752e-06|  0:01:10s\n","epoch 67 | loss: 0.0002  | val_0_mse: 9.999999747378752e-06|  0:01:11s\n","epoch 68 | loss: 0.0002  | val_0_mse: 1.9999999494757503e-05|  0:01:12s\n","epoch 69 | loss: 0.00024 | val_0_mse: 1.9999999494757503e-05|  0:01:13s\n","epoch 70 | loss: 0.00021 | val_0_mse: 1.9999999494757503e-05|  0:01:14s\n","epoch 71 | loss: 0.00021 | val_0_mse: 9.999999747378752e-06|  0:01:16s\n","epoch 72 | loss: 0.0002  | val_0_mse: 9.999999747378752e-06|  0:01:17s\n","epoch 73 | loss: 0.00019 | val_0_mse: 9.999999747378752e-06|  0:01:18s\n","epoch 74 | loss: 0.00019 | val_0_mse: 9.999999747378752e-06|  0:01:19s\n","epoch 75 | loss: 0.00019 | val_0_mse: 1.9999999494757503e-05|  0:01:20s\n","epoch 76 | loss: 0.0002  | val_0_mse: 9.999999747378752e-06|  0:01:21s\n","epoch 77 | loss: 0.00021 | val_0_mse: 1.9999999494757503e-05|  0:01:22s\n","epoch 78 | loss: 0.00021 | val_0_mse: 9.999999747378752e-06|  0:01:23s\n","epoch 79 | loss: 0.0002  | val_0_mse: 1.9999999494757503e-05|  0:01:24s\n","epoch 80 | loss: 0.00022 | val_0_mse: 1.9999999494757503e-05|  0:01:25s\n","epoch 81 | loss: 0.00021 | val_0_mse: 9.999999747378752e-06|  0:01:26s\n","epoch 82 | loss: 0.00021 | val_0_mse: 9.999999747378752e-06|  0:01:27s\n","epoch 83 | loss: 0.0002  | val_0_mse: 2.9999999242136255e-05|  0:01:28s\n","epoch 84 | loss: 0.00022 | val_0_mse: 3.9999998989515007e-05|  0:01:29s\n","\n","Early stopping occurred at epoch 84 with best_epoch = 74 and best_val_0_mse = 9.999999747378752e-06\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 09:07:42,955] Trial 37 finished with value: 8.247037840192206e-06 and parameters: {'n_d': 39, 'n_steps': 7, 'gamma': 1.8243458143742244, 'n_independent': 3, 'n_shared': 3, 'momentum': 0.048388719352264964}. Best is trial 20 with value: 1.2763081258526654e-07.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 11.6838 | val_0_mse: 6.282430171966553|  0:00:00s\n","epoch 1  | loss: 2.19275 | val_0_mse: 5.624259948730469|  0:00:01s\n","epoch 2  | loss: 1.02468 | val_0_mse: 0.6336100101470947|  0:00:02s\n","epoch 3  | loss: 0.88947 | val_0_mse: 0.5517699718475342|  0:00:03s\n","epoch 4  | loss: 0.49736 | val_0_mse: 0.15674999356269836|  0:00:04s\n","epoch 5  | loss: 0.24563 | val_0_mse: 0.249549999833107|  0:00:05s\n","epoch 6  | loss: 0.20432 | val_0_mse: 0.08382999897003174|  0:00:06s\n","epoch 7  | loss: 0.06374 | val_0_mse: 0.05462000146508217|  0:00:07s\n","epoch 8  | loss: 0.11374 | val_0_mse: 0.04820999875664711|  0:00:08s\n","epoch 9  | loss: 0.06364 | val_0_mse: 0.004350000061094761|  0:00:09s\n","epoch 10 | loss: 0.02056 | val_0_mse: 0.003909999970346689|  0:00:10s\n","epoch 11 | loss: 0.00944 | val_0_mse: 0.002139999996870756|  0:00:11s\n","epoch 12 | loss: 0.00565 | val_0_mse: 0.0013899999903514981|  0:00:12s\n","epoch 13 | loss: 0.00359 | val_0_mse: 0.001180000021122396|  0:00:13s\n","epoch 14 | loss: 0.00269 | val_0_mse: 0.0005799999926239252|  0:00:13s\n","epoch 15 | loss: 0.002   | val_0_mse: 0.0003600000054575503|  0:00:14s\n","epoch 16 | loss: 0.0016  | val_0_mse: 0.0003499999875202775|  0:00:15s\n","epoch 17 | loss: 0.00135 | val_0_mse: 0.00022000000171829015|  0:00:16s\n","epoch 18 | loss: 0.0012  | val_0_mse: 0.0002500000118743628|  0:00:17s\n","epoch 19 | loss: 0.00116 | val_0_mse: 0.0001900000061141327|  0:00:18s\n","epoch 20 | loss: 0.00108 | val_0_mse: 0.00015999999595806003|  0:00:19s\n","epoch 21 | loss: 0.00095 | val_0_mse: 0.00016999999934341758|  0:00:20s\n","epoch 22 | loss: 0.00092 | val_0_mse: 0.00014000000373926014|  0:00:21s\n","epoch 23 | loss: 0.00083 | val_0_mse: 0.00011999999696854502|  0:00:22s\n","epoch 24 | loss: 0.00078 | val_0_mse: 0.00011000000085914508|  0:00:23s\n","epoch 25 | loss: 0.00073 | val_0_mse: 0.00011000000085914508|  0:00:24s\n","epoch 26 | loss: 0.00072 | val_0_mse: 0.00011999999696854502|  0:00:25s\n","epoch 27 | loss: 0.0007  | val_0_mse: 9.999999747378752e-05|  0:00:26s\n","epoch 28 | loss: 0.00065 | val_0_mse: 9.999999747378752e-05|  0:00:27s\n","epoch 29 | loss: 0.00068 | val_0_mse: 7.999999797903001e-05|  0:00:28s\n","epoch 30 | loss: 0.00063 | val_0_mse: 7.999999797903001e-05|  0:00:29s\n","epoch 31 | loss: 0.00065 | val_0_mse: 9.000000136438757e-05|  0:00:29s\n","epoch 32 | loss: 0.00058 | val_0_mse: 7.000000186963007e-05|  0:00:30s\n","epoch 33 | loss: 0.00057 | val_0_mse: 7.999999797903001e-05|  0:00:31s\n","epoch 34 | loss: 0.00053 | val_0_mse: 5.999999848427251e-05|  0:00:32s\n","epoch 35 | loss: 0.00054 | val_0_mse: 7.999999797903001e-05|  0:00:33s\n","epoch 36 | loss: 0.00051 | val_0_mse: 9.000000136438757e-05|  0:00:34s\n","epoch 37 | loss: 0.00049 | val_0_mse: 7.000000186963007e-05|  0:00:35s\n","epoch 38 | loss: 0.00046 | val_0_mse: 7.000000186963007e-05|  0:00:36s\n","epoch 39 | loss: 0.00046 | val_0_mse: 4.999999873689376e-05|  0:00:37s\n","epoch 40 | loss: 0.00045 | val_0_mse: 7.999999797903001e-05|  0:00:38s\n","epoch 41 | loss: 0.00044 | val_0_mse: 9.999999747378752e-05|  0:00:39s\n","epoch 42 | loss: 0.00043 | val_0_mse: 5.999999848427251e-05|  0:00:40s\n","epoch 43 | loss: 0.00043 | val_0_mse: 7.000000186963007e-05|  0:00:41s\n","epoch 44 | loss: 0.00042 | val_0_mse: 7.000000186963007e-05|  0:00:41s\n","epoch 45 | loss: 0.00043 | val_0_mse: 7.000000186963007e-05|  0:00:42s\n","epoch 46 | loss: 0.00043 | val_0_mse: 5.999999848427251e-05|  0:00:43s\n","epoch 47 | loss: 0.0004  | val_0_mse: 5.999999848427251e-05|  0:00:44s\n","epoch 48 | loss: 0.0004  | val_0_mse: 9.000000136438757e-05|  0:00:45s\n","epoch 49 | loss: 0.00041 | val_0_mse: 9.999999747378752e-05|  0:00:46s\n","\n","Early stopping occurred at epoch 49 with best_epoch = 39 and best_val_0_mse = 4.999999873689376e-05\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 09:08:30,065] Trial 38 finished with value: 5.3040115744806826e-05 and parameters: {'n_d': 49, 'n_steps': 6, 'gamma': 1.614540183398855, 'n_independent': 2, 'n_shared': 4, 'momentum': 0.2866377816973795}. Best is trial 20 with value: 1.2763081258526654e-07.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 13.10719| val_0_mse: 49.42372131347656|  0:00:01s\n","epoch 1  | loss: 6.30488 | val_0_mse: 11.490340232849121|  0:00:02s\n","epoch 2  | loss: 4.15664 | val_0_mse: 2.187380075454712|  0:00:03s\n","epoch 3  | loss: 4.81389 | val_0_mse: 1.672760009765625|  0:00:04s\n","epoch 4  | loss: 5.83695 | val_0_mse: 0.4145199954509735|  0:00:05s\n","epoch 5  | loss: 2.18914 | val_0_mse: 1.5344599485397339|  0:00:07s\n","epoch 6  | loss: 2.25863 | val_0_mse: 0.1318099945783615|  0:00:08s\n","epoch 7  | loss: 6.14579 | val_0_mse: 0.20362000167369843|  0:00:09s\n","epoch 8  | loss: 0.89159 | val_0_mse: 0.22453999519348145|  0:00:10s\n","epoch 9  | loss: 0.48416 | val_0_mse: 0.1266999989748001|  0:00:11s\n","epoch 10 | loss: 1.04511 | val_0_mse: 0.10976999998092651|  0:00:12s\n","epoch 11 | loss: 0.53426 | val_0_mse: 0.020659999921917915|  0:00:14s\n","epoch 12 | loss: 0.15734 | val_0_mse: 0.025119999423623085|  0:00:15s\n","epoch 13 | loss: 0.04525 | val_0_mse: 0.0030300000216811895|  0:00:16s\n","epoch 14 | loss: 0.01853 | val_0_mse: 0.004170000087469816|  0:00:17s\n","epoch 15 | loss: 0.01005 | val_0_mse: 0.0012000000569969416|  0:00:18s\n","epoch 16 | loss: 0.00543 | val_0_mse: 0.001120000029914081|  0:00:19s\n","epoch 17 | loss: 0.00292 | val_0_mse: 0.0008399999933317304|  0:00:21s\n","epoch 18 | loss: 0.00214 | val_0_mse: 0.0007699999841861427|  0:00:22s\n","epoch 19 | loss: 0.00187 | val_0_mse: 0.0003600000054575503|  0:00:23s\n","epoch 20 | loss: 0.00211 | val_0_mse: 0.0002500000118743628|  0:00:24s\n","epoch 21 | loss: 0.00188 | val_0_mse: 0.0004400000034365803|  0:00:25s\n","epoch 22 | loss: 0.00147 | val_0_mse: 0.0003499999875202775|  0:00:26s\n","epoch 23 | loss: 0.00127 | val_0_mse: 0.00016999999934341758|  0:00:27s\n","epoch 24 | loss: 0.00121 | val_0_mse: 0.0002699999895412475|  0:00:29s\n","epoch 25 | loss: 0.00121 | val_0_mse: 0.00033000000985339284|  0:00:30s\n","epoch 26 | loss: 0.00144 | val_0_mse: 0.00026000000070780516|  0:00:31s\n","epoch 27 | loss: 0.00125 | val_0_mse: 0.00014000000373926014|  0:00:32s\n","epoch 28 | loss: 0.00189 | val_0_mse: 0.0002300000051036477|  0:00:33s\n","epoch 29 | loss: 0.00128 | val_0_mse: 0.00016999999934341758|  0:00:34s\n","epoch 30 | loss: 0.00115 | val_0_mse: 0.00013000000035390258|  0:00:36s\n","epoch 31 | loss: 0.00108 | val_0_mse: 0.00013000000035390258|  0:00:37s\n","epoch 32 | loss: 0.00182 | val_0_mse: 0.00033999999868683517|  0:00:38s\n","epoch 33 | loss: 0.00459 | val_0_mse: 0.0003600000054575503|  0:00:39s\n","epoch 34 | loss: 0.00323 | val_0_mse: 0.00023999999393709004|  0:00:40s\n","epoch 35 | loss: 0.00201 | val_0_mse: 0.0003499999875202775|  0:00:41s\n","epoch 36 | loss: 0.00151 | val_0_mse: 0.00015999999595806003|  0:00:43s\n","epoch 37 | loss: 0.00136 | val_0_mse: 0.0001500000071246177|  0:00:44s\n","epoch 38 | loss: 0.00101 | val_0_mse: 0.00013000000035390258|  0:00:45s\n","epoch 39 | loss: 0.00089 | val_0_mse: 0.00015999999595806003|  0:00:46s\n","epoch 40 | loss: 0.00075 | val_0_mse: 0.0001500000071246177|  0:00:47s\n","epoch 41 | loss: 0.00062 | val_0_mse: 0.00014000000373926014|  0:00:48s\n","\n","Early stopping occurred at epoch 41 with best_epoch = 31 and best_val_0_mse = 0.00013000000035390258\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 09:09:19,494] Trial 39 finished with value: 0.00012509019870776683 and parameters: {'n_d': 35, 'n_steps': 9, 'gamma': 1.7864818283183768, 'n_independent': 3, 'n_shared': 2, 'momentum': 0.10254295075279986}. Best is trial 20 with value: 1.2763081258526654e-07.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 3.12503 | val_0_mse: 0.4264500141143799|  0:00:00s\n","epoch 1  | loss: 1.00267 | val_0_mse: 1.08256995677948|  0:00:01s\n","epoch 2  | loss: 0.39752 | val_0_mse: 0.16080999374389648|  0:00:01s\n","epoch 3  | loss: 0.13511 | val_0_mse: 0.14100000262260437|  0:00:02s\n","epoch 4  | loss: 0.06486 | val_0_mse: 0.032019998878240585|  0:00:03s\n","epoch 5  | loss: 0.02774 | val_0_mse: 0.007780000101774931|  0:00:03s\n","epoch 6  | loss: 0.01232 | val_0_mse: 0.0033199999015778303|  0:00:04s\n","epoch 7  | loss: 0.00858 | val_0_mse: 0.0023300000466406345|  0:00:04s\n","epoch 8  | loss: 0.00548 | val_0_mse: 0.0010400000028312206|  0:00:05s\n","epoch 9  | loss: 0.00346 | val_0_mse: 0.001019999966956675|  0:00:06s\n","epoch 10 | loss: 0.00255 | val_0_mse: 0.0010000000474974513|  0:00:06s\n","epoch 11 | loss: 0.00205 | val_0_mse: 0.0007999999797903001|  0:00:07s\n","epoch 12 | loss: 0.00167 | val_0_mse: 0.0006000000284984708|  0:00:08s\n","epoch 13 | loss: 0.00167 | val_0_mse: 0.0003600000054575503|  0:00:08s\n","epoch 14 | loss: 0.0014  | val_0_mse: 0.00031999999191612005|  0:00:09s\n","epoch 15 | loss: 0.00137 | val_0_mse: 0.0002500000118743628|  0:00:09s\n","epoch 16 | loss: 0.00124 | val_0_mse: 0.00023999999393709004|  0:00:10s\n","epoch 17 | loss: 0.00122 | val_0_mse: 0.0001900000061141327|  0:00:11s\n","epoch 18 | loss: 0.0012  | val_0_mse: 0.0003000000142492354|  0:00:11s\n","epoch 19 | loss: 0.00119 | val_0_mse: 0.00016999999934341758|  0:00:12s\n","epoch 20 | loss: 0.00106 | val_0_mse: 0.0002099999983329326|  0:00:12s\n","epoch 21 | loss: 0.00106 | val_0_mse: 0.00015999999595806003|  0:00:13s\n","epoch 22 | loss: 0.00112 | val_0_mse: 9.999999747378752e-05|  0:00:14s\n","epoch 23 | loss: 0.00097 | val_0_mse: 0.00015999999595806003|  0:00:14s\n","epoch 24 | loss: 0.00116 | val_0_mse: 0.00011000000085914508|  0:00:15s\n","epoch 25 | loss: 0.00119 | val_0_mse: 9.000000136438757e-05|  0:00:16s\n","epoch 26 | loss: 0.00111 | val_0_mse: 0.00015999999595806003|  0:00:16s\n","epoch 27 | loss: 0.00122 | val_0_mse: 0.00014000000373926014|  0:00:17s\n","epoch 28 | loss: 0.00099 | val_0_mse: 0.0001500000071246177|  0:00:17s\n","epoch 29 | loss: 0.00093 | val_0_mse: 0.00011999999696854502|  0:00:18s\n","epoch 30 | loss: 0.00093 | val_0_mse: 0.00016999999934341758|  0:00:19s\n","epoch 31 | loss: 0.00093 | val_0_mse: 0.00011000000085914508|  0:00:19s\n","epoch 32 | loss: 0.0008  | val_0_mse: 0.00011999999696854502|  0:00:20s\n","epoch 33 | loss: 0.00082 | val_0_mse: 0.0001900000061141327|  0:00:20s\n","epoch 34 | loss: 0.0009  | val_0_mse: 0.00016999999934341758|  0:00:21s\n","epoch 35 | loss: 0.00083 | val_0_mse: 9.999999747378752e-05|  0:00:22s\n","\n","Early stopping occurred at epoch 35 with best_epoch = 25 and best_val_0_mse = 9.000000136438757e-05\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 09:09:42,014] Trial 40 finished with value: 8.555046952096745e-05 and parameters: {'n_d': 54, 'n_steps': 4, 'gamma': 1.4671903482350723, 'n_independent': 1, 'n_shared': 4, 'momentum': 0.1457445557441982}. Best is trial 20 with value: 1.2763081258526654e-07.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 3.33771 | val_0_mse: 23.6058406829834|  0:00:01s\n","epoch 1  | loss: 1.34361 | val_0_mse: 2.037630081176758|  0:00:02s\n","epoch 2  | loss: 1.23791 | val_0_mse: 0.8169999718666077|  0:00:03s\n","epoch 3  | loss: 0.66    | val_0_mse: 0.0747700035572052|  0:00:04s\n","epoch 4  | loss: 0.32442 | val_0_mse: 0.0437299981713295|  0:00:05s\n","epoch 5  | loss: 0.37911 | val_0_mse: 0.06289999932050705|  0:00:06s\n","epoch 6  | loss: 0.1882  | val_0_mse: 0.1757200062274933|  0:00:08s\n","epoch 7  | loss: 0.07962 | val_0_mse: 0.061650000512599945|  0:00:09s\n","epoch 8  | loss: 0.03578 | val_0_mse: 0.013939999975264072|  0:00:10s\n","epoch 9  | loss: 0.01285 | val_0_mse: 0.011250000447034836|  0:00:11s\n","epoch 10 | loss: 0.00501 | val_0_mse: 0.0020000000949949026|  0:00:12s\n","epoch 11 | loss: 0.00266 | val_0_mse: 0.000750000006519258|  0:00:13s\n","epoch 12 | loss: 0.00153 | val_0_mse: 0.0007099999929778278|  0:00:14s\n","epoch 13 | loss: 0.00102 | val_0_mse: 0.0002300000051036477|  0:00:16s\n","epoch 14 | loss: 0.00077 | val_0_mse: 0.0002099999983329326|  0:00:17s\n","epoch 15 | loss: 0.00064 | val_0_mse: 0.00022000000171829015|  0:00:18s\n","epoch 16 | loss: 0.00054 | val_0_mse: 0.0002300000051036477|  0:00:19s\n","epoch 17 | loss: 0.00055 | val_0_mse: 0.0002300000051036477|  0:00:20s\n","epoch 18 | loss: 0.00057 | val_0_mse: 9.000000136438757e-05|  0:00:21s\n","epoch 19 | loss: 0.00051 | val_0_mse: 0.00013000000035390258|  0:00:22s\n","epoch 20 | loss: 0.00043 | val_0_mse: 0.0004600000102072954|  0:00:23s\n","epoch 21 | loss: 0.0004  | val_0_mse: 0.00013000000035390258|  0:00:25s\n","epoch 22 | loss: 0.00038 | val_0_mse: 5.999999848427251e-05|  0:00:26s\n","epoch 23 | loss: 0.00036 | val_0_mse: 9.999999747378752e-05|  0:00:27s\n","epoch 24 | loss: 0.00034 | val_0_mse: 4.999999873689376e-05|  0:00:28s\n","epoch 25 | loss: 0.00033 | val_0_mse: 7.999999797903001e-05|  0:00:29s\n","epoch 26 | loss: 0.00031 | val_0_mse: 4.999999873689376e-05|  0:00:30s\n","epoch 27 | loss: 0.00032 | val_0_mse: 2.9999999242136255e-05|  0:00:32s\n","epoch 28 | loss: 0.00033 | val_0_mse: 3.9999998989515007e-05|  0:00:33s\n","epoch 29 | loss: 0.00031 | val_0_mse: 1.9999999494757503e-05|  0:00:34s\n","epoch 30 | loss: 0.0003  | val_0_mse: 1.9999999494757503e-05|  0:00:35s\n","epoch 31 | loss: 0.0003  | val_0_mse: 2.9999999242136255e-05|  0:00:36s\n","epoch 32 | loss: 0.0003  | val_0_mse: 3.9999998989515007e-05|  0:00:37s\n","epoch 33 | loss: 0.0003  | val_0_mse: 1.9999999494757503e-05|  0:00:38s\n","epoch 34 | loss: 0.00029 | val_0_mse: 1.9999999494757503e-05|  0:00:39s\n","epoch 35 | loss: 0.00034 | val_0_mse: 5.999999848427251e-05|  0:00:41s\n","epoch 36 | loss: 0.00035 | val_0_mse: 2.9999999242136255e-05|  0:00:42s\n","epoch 37 | loss: 0.00032 | val_0_mse: 1.9999999494757503e-05|  0:00:43s\n","epoch 38 | loss: 0.0003  | val_0_mse: 2.9999999242136255e-05|  0:00:44s\n","epoch 39 | loss: 0.0003  | val_0_mse: 1.9999999494757503e-05|  0:00:45s\n","epoch 40 | loss: 0.00029 | val_0_mse: 1.9999999494757503e-05|  0:00:46s\n","epoch 41 | loss: 0.00028 | val_0_mse: 1.9999999494757503e-05|  0:00:47s\n","epoch 42 | loss: 0.00027 | val_0_mse: 9.999999747378752e-06|  0:00:49s\n","epoch 43 | loss: 0.00026 | val_0_mse: 9.999999747378752e-06|  0:00:50s\n","epoch 44 | loss: 0.00025 | val_0_mse: 1.9999999494757503e-05|  0:00:51s\n","epoch 45 | loss: 0.00025 | val_0_mse: 9.999999747378752e-06|  0:00:52s\n","epoch 46 | loss: 0.00024 | val_0_mse: 1.9999999494757503e-05|  0:00:53s\n","epoch 47 | loss: 0.00024 | val_0_mse: 9.999999747378752e-06|  0:00:54s\n","epoch 48 | loss: 0.00025 | val_0_mse: 9.999999747378752e-06|  0:00:56s\n","epoch 49 | loss: 0.00024 | val_0_mse: 7.000000186963007e-05|  0:00:57s\n","epoch 50 | loss: 0.00024 | val_0_mse: 2.9999999242136255e-05|  0:00:58s\n","epoch 51 | loss: 0.00023 | val_0_mse: 1.9999999494757503e-05|  0:00:59s\n","epoch 52 | loss: 0.00023 | val_0_mse: 1.9999999494757503e-05|  0:01:00s\n","epoch 53 | loss: 0.00022 | val_0_mse: 9.999999747378752e-06|  0:01:01s\n","epoch 54 | loss: 0.00022 | val_0_mse: 9.999999747378752e-06|  0:01:02s\n","epoch 55 | loss: 0.00021 | val_0_mse: 9.999999747378752e-06|  0:01:04s\n","epoch 56 | loss: 0.00021 | val_0_mse: 1.9999999494757503e-05|  0:01:05s\n","epoch 57 | loss: 0.0002  | val_0_mse: 9.999999747378752e-06|  0:01:06s\n","epoch 58 | loss: 0.0002  | val_0_mse: 9.999999747378752e-06|  0:01:07s\n","epoch 59 | loss: 0.00019 | val_0_mse: 9.999999747378752e-06|  0:01:08s\n","epoch 60 | loss: 0.00019 | val_0_mse: 9.999999747378752e-06|  0:01:09s\n","epoch 61 | loss: 0.00019 | val_0_mse: 9.999999747378752e-06|  0:01:10s\n","epoch 62 | loss: 0.00019 | val_0_mse: 9.999999747378752e-06|  0:01:12s\n","epoch 63 | loss: 0.00019 | val_0_mse: 9.999999747378752e-06|  0:01:13s\n","epoch 64 | loss: 0.00019 | val_0_mse: 9.999999747378752e-06|  0:01:14s\n","epoch 65 | loss: 0.00019 | val_0_mse: 9.999999747378752e-06|  0:01:15s\n","epoch 66 | loss: 0.00019 | val_0_mse: 9.999999747378752e-06|  0:01:16s\n","epoch 67 | loss: 0.00019 | val_0_mse: 9.999999747378752e-06|  0:01:17s\n","epoch 68 | loss: 0.00019 | val_0_mse: 9.999999747378752e-06|  0:01:18s\n","epoch 69 | loss: 0.00018 | val_0_mse: 9.999999747378752e-06|  0:01:19s\n","epoch 70 | loss: 0.00018 | val_0_mse: 9.999999747378752e-06|  0:01:21s\n","epoch 71 | loss: 0.00018 | val_0_mse: 9.999999747378752e-06|  0:01:22s\n","epoch 72 | loss: 0.00018 | val_0_mse: 9.999999747378752e-06|  0:01:23s\n","epoch 73 | loss: 0.00017 | val_0_mse: 0.0     |  0:01:24s\n","epoch 74 | loss: 0.00017 | val_0_mse: 0.0     |  0:01:25s\n","epoch 75 | loss: 0.00017 | val_0_mse: 0.0     |  0:01:26s\n","epoch 76 | loss: 0.00017 | val_0_mse: 0.0     |  0:01:28s\n","epoch 77 | loss: 0.00017 | val_0_mse: 0.0     |  0:01:29s\n","epoch 78 | loss: 0.00017 | val_0_mse: 0.0     |  0:01:30s\n","epoch 79 | loss: 0.00017 | val_0_mse: 0.0     |  0:01:31s\n","epoch 80 | loss: 0.00016 | val_0_mse: 0.0     |  0:01:32s\n","epoch 81 | loss: 0.00016 | val_0_mse: 0.0     |  0:01:33s\n","epoch 82 | loss: 0.00016 | val_0_mse: 0.0     |  0:01:34s\n","epoch 83 | loss: 0.00016 | val_0_mse: 0.0     |  0:01:36s\n","epoch 84 | loss: 0.00016 | val_0_mse: 0.0     |  0:01:37s\n","epoch 85 | loss: 0.00016 | val_0_mse: 0.0     |  0:01:38s\n","epoch 86 | loss: 0.00016 | val_0_mse: 0.0     |  0:01:39s\n","epoch 87 | loss: 0.00016 | val_0_mse: 0.0     |  0:01:40s\n","epoch 88 | loss: 0.00016 | val_0_mse: 0.0     |  0:01:41s\n","epoch 89 | loss: 0.00015 | val_0_mse: 0.0     |  0:01:42s\n","epoch 90 | loss: 0.00015 | val_0_mse: 0.0     |  0:01:44s\n","epoch 91 | loss: 0.00015 | val_0_mse: 0.0     |  0:01:45s\n","epoch 92 | loss: 0.00015 | val_0_mse: 0.0     |  0:01:46s\n","epoch 93 | loss: 0.00015 | val_0_mse: 0.0     |  0:01:47s\n","epoch 94 | loss: 0.00015 | val_0_mse: 0.0     |  0:01:48s\n","epoch 95 | loss: 0.00015 | val_0_mse: 0.0     |  0:01:49s\n","epoch 96 | loss: 0.00015 | val_0_mse: 0.0     |  0:01:51s\n","epoch 97 | loss: 0.00015 | val_0_mse: 0.0     |  0:01:52s\n","epoch 98 | loss: 0.00015 | val_0_mse: 0.0     |  0:01:53s\n","epoch 99 | loss: 0.00015 | val_0_mse: 0.0     |  0:01:54s\n","Stop training because you reached max_epochs = 100 with best_epoch = 97 and best_val_0_mse = 0.0\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 09:11:37,195] Trial 41 finished with value: 1.8953879532546125e-07 and parameters: {'n_d': 41, 'n_steps': 6, 'gamma': 1.7218459429174844, 'n_independent': 5, 'n_shared': 3, 'momentum': 0.2046082743017688}. Best is trial 20 with value: 1.2763081258526654e-07.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 4.95613 | val_0_mse: 8.091099739074707|  0:00:01s\n","epoch 1  | loss: 1.34125 | val_0_mse: 5.653629779815674|  0:00:02s\n","epoch 2  | loss: 1.29952 | val_0_mse: 2.6064400672912598|  0:00:03s\n","epoch 3  | loss: 0.63324 | val_0_mse: 2.943619966506958|  0:00:04s\n","epoch 4  | loss: 0.50448 | val_0_mse: 0.5362899899482727|  0:00:05s\n","epoch 5  | loss: 0.52562 | val_0_mse: 0.051589999347925186|  0:00:07s\n","epoch 6  | loss: 0.1207  | val_0_mse: 0.010619999840855598|  0:00:08s\n","epoch 7  | loss: 0.03962 | val_0_mse: 0.005659999791532755|  0:00:09s\n","epoch 8  | loss: 0.01281 | val_0_mse: 0.0015800000401213765|  0:00:10s\n","epoch 9  | loss: 0.00553 | val_0_mse: 0.0018700000364333391|  0:00:11s\n","epoch 10 | loss: 0.00272 | val_0_mse: 0.003980000037699938|  0:00:12s\n","epoch 11 | loss: 0.00158 | val_0_mse: 0.0016199999954551458|  0:00:14s\n","epoch 12 | loss: 0.00116 | val_0_mse: 0.0004799999878741801|  0:00:15s\n","epoch 13 | loss: 0.00092 | val_0_mse: 0.00033999999868683517|  0:00:16s\n","epoch 14 | loss: 0.00079 | val_0_mse: 0.0002800000074785203|  0:00:17s\n","epoch 15 | loss: 0.00074 | val_0_mse: 0.00044999999227002263|  0:00:18s\n","epoch 16 | loss: 0.00063 | val_0_mse: 0.00033000000985339284|  0:00:20s\n","epoch 17 | loss: 0.00064 | val_0_mse: 0.0004400000034365803|  0:00:21s\n","epoch 18 | loss: 0.00056 | val_0_mse: 0.0003800000122282654|  0:00:22s\n","epoch 19 | loss: 0.00055 | val_0_mse: 0.00011999999696854502|  0:00:23s\n","epoch 20 | loss: 0.00056 | val_0_mse: 0.0003100000030826777|  0:00:24s\n","epoch 21 | loss: 0.00055 | val_0_mse: 0.0001500000071246177|  0:00:25s\n","epoch 22 | loss: 0.00043 | val_0_mse: 0.00018000000272877514|  0:00:26s\n","epoch 23 | loss: 0.00041 | val_0_mse: 7.000000186963007e-05|  0:00:28s\n","epoch 24 | loss: 0.0004  | val_0_mse: 7.999999797903001e-05|  0:00:29s\n","epoch 25 | loss: 0.00038 | val_0_mse: 0.0001500000071246177|  0:00:30s\n","epoch 26 | loss: 0.00041 | val_0_mse: 0.00013000000035390258|  0:00:31s\n","epoch 27 | loss: 0.00039 | val_0_mse: 7.000000186963007e-05|  0:00:32s\n","epoch 28 | loss: 0.00036 | val_0_mse: 7.999999797903001e-05|  0:00:33s\n","epoch 29 | loss: 0.00034 | val_0_mse: 0.00011999999696854502|  0:00:35s\n","epoch 30 | loss: 0.00037 | val_0_mse: 7.000000186963007e-05|  0:00:36s\n","epoch 31 | loss: 0.00035 | val_0_mse: 5.999999848427251e-05|  0:00:37s\n","epoch 32 | loss: 0.00033 | val_0_mse: 5.999999848427251e-05|  0:00:38s\n","epoch 33 | loss: 0.00035 | val_0_mse: 0.00013000000035390258|  0:00:39s\n","epoch 34 | loss: 0.00034 | val_0_mse: 7.000000186963007e-05|  0:00:40s\n","epoch 35 | loss: 0.00065 | val_0_mse: 0.0002699999895412475|  0:00:41s\n","epoch 36 | loss: 0.00072 | val_0_mse: 0.00044999999227002263|  0:00:43s\n","epoch 37 | loss: 0.00075 | val_0_mse: 0.0001900000061141327|  0:00:44s\n","epoch 38 | loss: 0.00078 | val_0_mse: 0.00019999999494757503|  0:00:45s\n","epoch 39 | loss: 0.00069 | val_0_mse: 0.00015999999595806003|  0:00:46s\n","epoch 40 | loss: 0.00058 | val_0_mse: 0.00011000000085914508|  0:00:47s\n","epoch 41 | loss: 0.00073 | val_0_mse: 0.00023999999393709004|  0:00:48s\n","epoch 42 | loss: 0.00071 | val_0_mse: 0.00039000000106170774|  0:00:49s\n","\n","Early stopping occurred at epoch 42 with best_epoch = 32 and best_val_0_mse = 5.999999848427251e-05\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 09:12:27,845] Trial 42 finished with value: 5.941298877587542e-05 and parameters: {'n_d': 42, 'n_steps': 6, 'gamma': 1.70902715488221, 'n_independent': 5, 'n_shared': 3, 'momentum': 0.3060888867736322}. Best is trial 20 with value: 1.2763081258526654e-07.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 6.32833 | val_0_mse: 24.233749389648438|  0:00:01s\n","epoch 1  | loss: 4.11457 | val_0_mse: 0.6256099939346313|  0:00:02s\n","epoch 2  | loss: 6.38242 | val_0_mse: 4.081769943237305|  0:00:03s\n","epoch 3  | loss: 6.43454 | val_0_mse: 0.8317000269889832|  0:00:04s\n","epoch 4  | loss: 0.92506 | val_0_mse: 0.5776100158691406|  0:00:06s\n","epoch 5  | loss: 0.58997 | val_0_mse: 0.5593199729919434|  0:00:07s\n","epoch 6  | loss: 0.79664 | val_0_mse: 1.1422300338745117|  0:00:08s\n","epoch 7  | loss: 0.71396 | val_0_mse: 1.2452000379562378|  0:00:09s\n","epoch 8  | loss: 0.24045 | val_0_mse: 0.054340001195669174|  0:00:10s\n","epoch 9  | loss: 0.12528 | val_0_mse: 0.05110999941825867|  0:00:12s\n","epoch 10 | loss: 0.07156 | val_0_mse: 0.025919999927282333|  0:00:13s\n","epoch 11 | loss: 0.02243 | val_0_mse: 0.003379999892786145|  0:00:14s\n","epoch 12 | loss: 0.01185 | val_0_mse: 0.001509999972768128|  0:00:15s\n","epoch 13 | loss: 0.00898 | val_0_mse: 0.001019999966956675|  0:00:16s\n","epoch 14 | loss: 0.00549 | val_0_mse: 0.0005699999746866524|  0:00:17s\n","epoch 15 | loss: 0.00337 | val_0_mse: 0.0005300000193528831|  0:00:19s\n","epoch 16 | loss: 0.00224 | val_0_mse: 0.0004299999854993075|  0:00:20s\n","epoch 17 | loss: 0.00262 | val_0_mse: 0.0007999999797903001|  0:00:21s\n","epoch 18 | loss: 0.00236 | val_0_mse: 0.0004900000058114529|  0:00:22s\n","epoch 19 | loss: 0.002   | val_0_mse: 0.00046999999904073775|  0:00:23s\n","epoch 20 | loss: 0.00175 | val_0_mse: 0.0006399999838322401|  0:00:25s\n","epoch 21 | loss: 0.00185 | val_0_mse: 0.0003800000122282654|  0:00:26s\n","epoch 22 | loss: 0.00138 | val_0_mse: 0.0004299999854993075|  0:00:27s\n","epoch 23 | loss: 0.00114 | val_0_mse: 0.00014000000373926014|  0:00:28s\n","epoch 24 | loss: 0.00093 | val_0_mse: 0.00031999999191612005|  0:00:29s\n","epoch 25 | loss: 0.00095 | val_0_mse: 0.00014000000373926014|  0:00:31s\n","epoch 26 | loss: 0.00071 | val_0_mse: 0.00013000000035390258|  0:00:32s\n","epoch 27 | loss: 0.00067 | val_0_mse: 0.00014000000373926014|  0:00:33s\n","epoch 28 | loss: 0.00058 | val_0_mse: 0.00011000000085914508|  0:00:34s\n","epoch 29 | loss: 0.00052 | val_0_mse: 9.999999747378752e-05|  0:00:36s\n","epoch 30 | loss: 0.00048 | val_0_mse: 0.00011000000085914508|  0:00:37s\n","epoch 31 | loss: 0.00042 | val_0_mse: 7.999999797903001e-05|  0:00:38s\n","epoch 32 | loss: 0.00043 | val_0_mse: 9.000000136438757e-05|  0:00:39s\n","epoch 33 | loss: 0.00039 | val_0_mse: 5.999999848427251e-05|  0:00:40s\n","epoch 34 | loss: 0.00037 | val_0_mse: 7.999999797903001e-05|  0:00:41s\n","epoch 35 | loss: 0.00036 | val_0_mse: 4.999999873689376e-05|  0:00:43s\n","epoch 36 | loss: 0.00036 | val_0_mse: 0.00011999999696854502|  0:00:44s\n","epoch 37 | loss: 0.00033 | val_0_mse: 3.9999998989515007e-05|  0:00:45s\n","epoch 38 | loss: 0.00031 | val_0_mse: 7.999999797903001e-05|  0:00:46s\n","epoch 39 | loss: 0.00032 | val_0_mse: 7.000000186963007e-05|  0:00:47s\n","epoch 40 | loss: 0.00032 | val_0_mse: 7.999999797903001e-05|  0:00:49s\n","epoch 41 | loss: 0.00036 | val_0_mse: 3.9999998989515007e-05|  0:00:50s\n","epoch 42 | loss: 0.00037 | val_0_mse: 3.9999998989515007e-05|  0:00:51s\n","epoch 43 | loss: 0.00032 | val_0_mse: 4.999999873689376e-05|  0:00:52s\n","epoch 44 | loss: 0.00027 | val_0_mse: 9.000000136438757e-05|  0:00:53s\n","epoch 45 | loss: 0.00026 | val_0_mse: 2.9999999242136255e-05|  0:00:54s\n","epoch 46 | loss: 0.00026 | val_0_mse: 4.999999873689376e-05|  0:00:56s\n","epoch 47 | loss: 0.00027 | val_0_mse: 2.9999999242136255e-05|  0:00:57s\n","epoch 48 | loss: 0.00026 | val_0_mse: 2.9999999242136255e-05|  0:00:58s\n","epoch 49 | loss: 0.00024 | val_0_mse: 2.9999999242136255e-05|  0:00:59s\n","epoch 50 | loss: 0.00024 | val_0_mse: 7.000000186963007e-05|  0:01:00s\n","epoch 51 | loss: 0.00024 | val_0_mse: 1.9999999494757503e-05|  0:01:02s\n","epoch 52 | loss: 0.00024 | val_0_mse: 1.9999999494757503e-05|  0:01:03s\n","epoch 53 | loss: 0.00023 | val_0_mse: 4.999999873689376e-05|  0:01:04s\n","epoch 54 | loss: 0.00024 | val_0_mse: 2.9999999242136255e-05|  0:01:05s\n","epoch 55 | loss: 0.00025 | val_0_mse: 2.9999999242136255e-05|  0:01:06s\n","epoch 56 | loss: 0.00026 | val_0_mse: 2.9999999242136255e-05|  0:01:07s\n","epoch 57 | loss: 0.00026 | val_0_mse: 1.9999999494757503e-05|  0:01:09s\n","epoch 58 | loss: 0.00025 | val_0_mse: 1.9999999494757503e-05|  0:01:10s\n","epoch 59 | loss: 0.00025 | val_0_mse: 1.9999999494757503e-05|  0:01:11s\n","epoch 60 | loss: 0.00024 | val_0_mse: 1.9999999494757503e-05|  0:01:12s\n","epoch 61 | loss: 0.00024 | val_0_mse: 1.9999999494757503e-05|  0:01:14s\n","epoch 62 | loss: 0.00027 | val_0_mse: 3.9999998989515007e-05|  0:01:15s\n","epoch 63 | loss: 0.00043 | val_0_mse: 0.00022000000171829015|  0:01:16s\n","epoch 64 | loss: 0.00053 | val_0_mse: 5.999999848427251e-05|  0:01:17s\n","epoch 65 | loss: 0.00042 | val_0_mse: 4.999999873689376e-05|  0:01:18s\n","epoch 66 | loss: 0.00032 | val_0_mse: 7.000000186963007e-05|  0:01:20s\n","epoch 67 | loss: 0.00028 | val_0_mse: 3.9999998989515007e-05|  0:01:21s\n","epoch 68 | loss: 0.00026 | val_0_mse: 2.9999999242136255e-05|  0:01:22s\n","epoch 69 | loss: 0.00027 | val_0_mse: 2.9999999242136255e-05|  0:01:23s\n","epoch 70 | loss: 0.00026 | val_0_mse: 2.9999999242136255e-05|  0:01:24s\n","\n","Early stopping occurred at epoch 70 with best_epoch = 60 and best_val_0_mse = 1.9999999494757503e-05\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 09:13:53,288] Trial 43 finished with value: 1.5205213458102662e-05 and parameters: {'n_d': 45, 'n_steps': 7, 'gamma': 1.8900292217405328, 'n_independent': 4, 'n_shared': 3, 'momentum': 0.20905025979632913}. Best is trial 20 with value: 1.2763081258526654e-07.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 6.46164 | val_0_mse: 5.693960189819336|  0:00:01s\n","epoch 1  | loss: 1.94477 | val_0_mse: 0.4262799918651581|  0:00:02s\n","epoch 2  | loss: 1.01243 | val_0_mse: 0.10582000017166138|  0:00:03s\n","epoch 3  | loss: 0.50951 | val_0_mse: 0.08267000317573547|  0:00:04s\n","epoch 4  | loss: 0.38631 | val_0_mse: 0.27671000361442566|  0:00:06s\n","epoch 5  | loss: 0.21368 | val_0_mse: 0.2691099941730499|  0:00:07s\n","epoch 6  | loss: 0.08813 | val_0_mse: 0.026990000158548355|  0:00:08s\n","epoch 7  | loss: 0.1698  | val_0_mse: 0.03556999936699867|  0:00:09s\n","epoch 8  | loss: 0.07786 | val_0_mse: 0.017650000751018524|  0:00:10s\n","epoch 9  | loss: 0.01851 | val_0_mse: 0.00430000014603138|  0:00:11s\n","epoch 10 | loss: 0.00763 | val_0_mse: 0.0009699999936856329|  0:00:13s\n","epoch 11 | loss: 0.00351 | val_0_mse: 0.0007099999929778278|  0:00:14s\n","epoch 12 | loss: 0.00154 | val_0_mse: 0.000590000010561198|  0:00:15s\n","epoch 13 | loss: 0.00095 | val_0_mse: 0.0002300000051036477|  0:00:16s\n","epoch 14 | loss: 0.00078 | val_0_mse: 0.0001500000071246177|  0:00:18s\n","epoch 15 | loss: 0.0006  | val_0_mse: 0.00011000000085914508|  0:00:19s\n","epoch 16 | loss: 0.00048 | val_0_mse: 7.000000186963007e-05|  0:00:20s\n","epoch 17 | loss: 0.00042 | val_0_mse: 4.999999873689376e-05|  0:00:21s\n","epoch 18 | loss: 0.00037 | val_0_mse: 3.9999998989515007e-05|  0:00:22s\n","epoch 19 | loss: 0.00036 | val_0_mse: 2.9999999242136255e-05|  0:00:24s\n","epoch 20 | loss: 0.00034 | val_0_mse: 3.9999998989515007e-05|  0:00:25s\n","epoch 21 | loss: 0.00032 | val_0_mse: 5.999999848427251e-05|  0:00:26s\n","epoch 22 | loss: 0.00035 | val_0_mse: 5.999999848427251e-05|  0:00:27s\n","epoch 23 | loss: 0.00034 | val_0_mse: 3.9999998989515007e-05|  0:00:28s\n","epoch 24 | loss: 0.0003  | val_0_mse: 2.9999999242136255e-05|  0:00:30s\n","epoch 25 | loss: 0.0003  | val_0_mse: 3.9999998989515007e-05|  0:00:31s\n","epoch 26 | loss: 0.00031 | val_0_mse: 2.9999999242136255e-05|  0:00:32s\n","epoch 27 | loss: 0.0004  | val_0_mse: 2.9999999242136255e-05|  0:00:33s\n","epoch 28 | loss: 0.00042 | val_0_mse: 1.9999999494757503e-05|  0:00:34s\n","epoch 29 | loss: 0.00038 | val_0_mse: 1.9999999494757503e-05|  0:00:35s\n","epoch 30 | loss: 0.00032 | val_0_mse: 1.9999999494757503e-05|  0:00:36s\n","epoch 31 | loss: 0.00027 | val_0_mse: 1.9999999494757503e-05|  0:00:38s\n","epoch 32 | loss: 0.00026 | val_0_mse: 1.9999999494757503e-05|  0:00:39s\n","epoch 33 | loss: 0.00026 | val_0_mse: 1.9999999494757503e-05|  0:00:40s\n","epoch 34 | loss: 0.00024 | val_0_mse: 9.999999747378752e-06|  0:00:41s\n","epoch 35 | loss: 0.00023 | val_0_mse: 9.999999747378752e-06|  0:00:42s\n","epoch 36 | loss: 0.00023 | val_0_mse: 9.999999747378752e-06|  0:00:44s\n","epoch 37 | loss: 0.00022 | val_0_mse: 9.999999747378752e-06|  0:00:45s\n","epoch 38 | loss: 0.00022 | val_0_mse: 9.999999747378752e-06|  0:00:46s\n","epoch 39 | loss: 0.00022 | val_0_mse: 9.999999747378752e-06|  0:00:47s\n","epoch 40 | loss: 0.00021 | val_0_mse: 9.999999747378752e-06|  0:00:48s\n","epoch 41 | loss: 0.00021 | val_0_mse: 9.999999747378752e-06|  0:00:50s\n","epoch 42 | loss: 0.00021 | val_0_mse: 9.999999747378752e-06|  0:00:51s\n","epoch 43 | loss: 0.00021 | val_0_mse: 9.999999747378752e-06|  0:00:52s\n","epoch 44 | loss: 0.00022 | val_0_mse: 1.9999999494757503e-05|  0:00:53s\n","epoch 45 | loss: 0.00023 | val_0_mse: 1.9999999494757503e-05|  0:00:54s\n","epoch 46 | loss: 0.00022 | val_0_mse: 1.9999999494757503e-05|  0:00:56s\n","epoch 47 | loss: 0.00023 | val_0_mse: 3.9999998989515007e-05|  0:00:57s\n","epoch 48 | loss: 0.00021 | val_0_mse: 2.9999999242136255e-05|  0:00:58s\n","epoch 49 | loss: 0.0002  | val_0_mse: 1.9999999494757503e-05|  0:00:59s\n","\n","Early stopping occurred at epoch 49 with best_epoch = 39 and best_val_0_mse = 9.999999747378752e-06\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 09:14:53,443] Trial 44 finished with value: 5.865286766493227e-06 and parameters: {'n_d': 27, 'n_steps': 7, 'gamma': 1.9626214331023912, 'n_independent': 3, 'n_shared': 4, 'momentum': 0.17983296961958983}. Best is trial 20 with value: 1.2763081258526654e-07.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 3.74674 | val_0_mse: 19.003620147705078|  0:00:01s\n","epoch 1  | loss: 1.46525 | val_0_mse: 1.4646400213241577|  0:00:02s\n","epoch 2  | loss: 0.75827 | val_0_mse: 0.5214999914169312|  0:00:03s\n","epoch 3  | loss: 0.80156 | val_0_mse: 0.10933999717235565|  0:00:05s\n","epoch 4  | loss: 0.48373 | val_0_mse: 0.050999999046325684|  0:00:06s\n","epoch 5  | loss: 0.38442 | val_0_mse: 0.009270000271499157|  0:00:07s\n","epoch 6  | loss: 0.16502 | val_0_mse: 0.0037400000728666782|  0:00:08s\n","epoch 7  | loss: 0.07782 | val_0_mse: 0.004040000028908253|  0:00:10s\n","epoch 8  | loss: 0.02326 | val_0_mse: 0.0013599999947473407|  0:00:11s\n","epoch 9  | loss: 0.00767 | val_0_mse: 0.0004199999966658652|  0:00:12s\n","epoch 10 | loss: 0.00272 | val_0_mse: 0.00013000000035390258|  0:00:13s\n","epoch 11 | loss: 0.00154 | val_0_mse: 0.00018000000272877514|  0:00:15s\n","epoch 12 | loss: 0.00117 | val_0_mse: 0.00014000000373926014|  0:00:16s\n","epoch 13 | loss: 0.00092 | val_0_mse: 5.999999848427251e-05|  0:00:17s\n","epoch 14 | loss: 0.00067 | val_0_mse: 7.000000186963007e-05|  0:00:18s\n","epoch 15 | loss: 0.00058 | val_0_mse: 3.9999998989515007e-05|  0:00:20s\n","epoch 16 | loss: 0.00054 | val_0_mse: 3.9999998989515007e-05|  0:00:21s\n","epoch 17 | loss: 0.00051 | val_0_mse: 2.9999999242136255e-05|  0:00:22s\n","epoch 18 | loss: 0.00048 | val_0_mse: 2.9999999242136255e-05|  0:00:24s\n","epoch 19 | loss: 0.00047 | val_0_mse: 2.9999999242136255e-05|  0:00:25s\n","epoch 20 | loss: 0.00044 | val_0_mse: 1.9999999494757503e-05|  0:00:26s\n","epoch 21 | loss: 0.00044 | val_0_mse: 2.9999999242136255e-05|  0:00:27s\n","epoch 22 | loss: 0.00042 | val_0_mse: 3.9999998989515007e-05|  0:00:29s\n","epoch 23 | loss: 0.00041 | val_0_mse: 1.9999999494757503e-05|  0:00:30s\n","epoch 24 | loss: 0.00039 | val_0_mse: 2.9999999242136255e-05|  0:00:31s\n","epoch 25 | loss: 0.00038 | val_0_mse: 1.9999999494757503e-05|  0:00:32s\n","epoch 26 | loss: 0.00037 | val_0_mse: 9.999999747378752e-06|  0:00:34s\n","epoch 27 | loss: 0.00036 | val_0_mse: 1.9999999494757503e-05|  0:00:35s\n","epoch 28 | loss: 0.00036 | val_0_mse: 1.9999999494757503e-05|  0:00:36s\n","epoch 29 | loss: 0.00034 | val_0_mse: 9.999999747378752e-06|  0:00:38s\n","epoch 30 | loss: 0.00034 | val_0_mse: 9.999999747378752e-06|  0:00:39s\n","epoch 31 | loss: 0.00033 | val_0_mse: 9.999999747378752e-06|  0:00:40s\n","epoch 32 | loss: 0.00033 | val_0_mse: 1.9999999494757503e-05|  0:00:41s\n","epoch 33 | loss: 0.00033 | val_0_mse: 1.9999999494757503e-05|  0:00:42s\n","epoch 34 | loss: 0.00031 | val_0_mse: 9.999999747378752e-06|  0:00:44s\n","epoch 35 | loss: 0.00031 | val_0_mse: 1.9999999494757503e-05|  0:00:45s\n","epoch 36 | loss: 0.0003  | val_0_mse: 9.999999747378752e-06|  0:00:46s\n","epoch 37 | loss: 0.0003  | val_0_mse: 9.999999747378752e-06|  0:00:48s\n","epoch 38 | loss: 0.0003  | val_0_mse: 1.9999999494757503e-05|  0:00:49s\n","epoch 39 | loss: 0.0003  | val_0_mse: 1.9999999494757503e-05|  0:00:50s\n","epoch 40 | loss: 0.00028 | val_0_mse: 9.999999747378752e-06|  0:00:51s\n","epoch 41 | loss: 0.00027 | val_0_mse: 9.999999747378752e-06|  0:00:53s\n","epoch 42 | loss: 0.00028 | val_0_mse: 9.999999747378752e-06|  0:00:54s\n","epoch 43 | loss: 0.00027 | val_0_mse: 9.999999747378752e-06|  0:00:55s\n","epoch 44 | loss: 0.00028 | val_0_mse: 9.999999747378752e-06|  0:00:56s\n","epoch 45 | loss: 0.00028 | val_0_mse: 9.999999747378752e-06|  0:00:58s\n","epoch 46 | loss: 0.00026 | val_0_mse: 9.999999747378752e-06|  0:00:59s\n","epoch 47 | loss: 0.00026 | val_0_mse: 9.999999747378752e-06|  0:01:00s\n","epoch 48 | loss: 0.00025 | val_0_mse: 9.999999747378752e-06|  0:01:02s\n","epoch 49 | loss: 0.00025 | val_0_mse: 0.0     |  0:01:03s\n","epoch 50 | loss: 0.00025 | val_0_mse: 9.999999747378752e-06|  0:01:04s\n","epoch 51 | loss: 0.00024 | val_0_mse: 0.0     |  0:01:05s\n","epoch 52 | loss: 0.00025 | val_0_mse: 9.999999747378752e-06|  0:01:07s\n","epoch 53 | loss: 0.00024 | val_0_mse: 9.999999747378752e-06|  0:01:08s\n","epoch 54 | loss: 0.00024 | val_0_mse: 9.999999747378752e-06|  0:01:09s\n","epoch 55 | loss: 0.00024 | val_0_mse: 0.0     |  0:01:10s\n","epoch 56 | loss: 0.00024 | val_0_mse: 9.999999747378752e-06|  0:01:12s\n","epoch 57 | loss: 0.00025 | val_0_mse: 9.999999747378752e-06|  0:01:13s\n","epoch 58 | loss: 0.00023 | val_0_mse: 9.999999747378752e-06|  0:01:14s\n","epoch 59 | loss: 0.00023 | val_0_mse: 1.9999999494757503e-05|  0:01:15s\n","epoch 60 | loss: 0.00023 | val_0_mse: 0.0     |  0:01:17s\n","epoch 61 | loss: 0.00023 | val_0_mse: 9.999999747378752e-06|  0:01:18s\n","epoch 62 | loss: 0.00022 | val_0_mse: 9.999999747378752e-06|  0:01:19s\n","epoch 63 | loss: 0.00022 | val_0_mse: 9.999999747378752e-06|  0:01:20s\n","epoch 64 | loss: 0.00023 | val_0_mse: 9.999999747378752e-06|  0:01:21s\n","epoch 65 | loss: 0.00022 | val_0_mse: 9.999999747378752e-06|  0:01:23s\n","\n","Early stopping occurred at epoch 65 with best_epoch = 55 and best_val_0_mse = 0.0\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 09:16:17,371] Trial 45 finished with value: 4.4215371417521965e-06 and parameters: {'n_d': 31, 'n_steps': 6, 'gamma': 1.7986190554481443, 'n_independent': 4, 'n_shared': 5, 'momentum': 0.2478823318614827}. Best is trial 20 with value: 1.2763081258526654e-07.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 5.99628 | val_0_mse: 19.289400100708008|  0:00:01s\n","epoch 1  | loss: 1.91176 | val_0_mse: 14.422369956970215|  0:00:02s\n","epoch 2  | loss: 1.34908 | val_0_mse: 4.706679821014404|  0:00:04s\n","epoch 3  | loss: 0.63998 | val_0_mse: 0.043869998306035995|  0:00:05s\n","epoch 4  | loss: 0.38331 | val_0_mse: 0.059379998594522476|  0:00:07s\n","epoch 5  | loss: 1.25333 | val_0_mse: 0.07101000100374222|  0:00:08s\n","epoch 6  | loss: 0.26633 | val_0_mse: 0.04382999986410141|  0:00:10s\n","epoch 7  | loss: 0.47051 | val_0_mse: 0.008430000394582748|  0:00:11s\n","epoch 8  | loss: 0.07865 | val_0_mse: 0.003759999992325902|  0:00:13s\n","epoch 9  | loss: 0.04629 | val_0_mse: 0.012040000408887863|  0:00:14s\n","epoch 10 | loss: 0.01171 | val_0_mse: 0.0005499999970197678|  0:00:16s\n","epoch 11 | loss: 0.00314 | val_0_mse: 0.0008299999753944576|  0:00:17s\n","epoch 12 | loss: 0.00128 | val_0_mse: 0.0002099999983329326|  0:00:19s\n","epoch 13 | loss: 0.00068 | val_0_mse: 4.999999873689376e-05|  0:00:20s\n","epoch 14 | loss: 0.00044 | val_0_mse: 9.999999747378752e-06|  0:00:22s\n","epoch 15 | loss: 0.00036 | val_0_mse: 9.999999747378752e-06|  0:00:23s\n","epoch 16 | loss: 0.00034 | val_0_mse: 0.0     |  0:00:24s\n","epoch 17 | loss: 0.00031 | val_0_mse: 9.999999747378752e-06|  0:00:26s\n","epoch 18 | loss: 0.00029 | val_0_mse: 9.999999747378752e-06|  0:00:27s\n","epoch 19 | loss: 0.00027 | val_0_mse: 9.999999747378752e-06|  0:00:29s\n","epoch 20 | loss: 0.00027 | val_0_mse: 2.9999999242136255e-05|  0:00:30s\n","epoch 21 | loss: 0.00026 | val_0_mse: 9.999999747378752e-06|  0:00:32s\n","epoch 22 | loss: 0.00026 | val_0_mse: 9.999999747378752e-06|  0:00:33s\n","epoch 23 | loss: 0.00025 | val_0_mse: 9.999999747378752e-06|  0:00:35s\n","epoch 24 | loss: 0.00025 | val_0_mse: 9.999999747378752e-06|  0:00:36s\n","epoch 25 | loss: 0.00024 | val_0_mse: 9.999999747378752e-06|  0:00:38s\n","epoch 26 | loss: 0.00024 | val_0_mse: 9.999999747378752e-06|  0:00:39s\n","\n","Early stopping occurred at epoch 26 with best_epoch = 16 and best_val_0_mse = 0.0\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 09:16:57,658] Trial 46 finished with value: 4.858008196606534e-06 and parameters: {'n_d': 41, 'n_steps': 8, 'gamma': 1.516546258307161, 'n_independent': 5, 'n_shared': 3, 'momentum': 0.2380249006064084}. Best is trial 20 with value: 1.2763081258526654e-07.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 3.25693 | val_0_mse: 13.258999824523926|  0:00:00s\n","epoch 1  | loss: 1.15185 | val_0_mse: 2.460629940032959|  0:00:01s\n","epoch 2  | loss: 0.65306 | val_0_mse: 0.14087000489234924|  0:00:02s\n","epoch 3  | loss: 0.76458 | val_0_mse: 0.09533999860286713|  0:00:02s\n","epoch 4  | loss: 0.59103 | val_0_mse: 0.07266999781131744|  0:00:03s\n","epoch 5  | loss: 0.34211 | val_0_mse: 0.02572000026702881|  0:00:04s\n","epoch 6  | loss: 0.23559 | val_0_mse: 0.008299999870359898|  0:00:05s\n","epoch 7  | loss: 0.07123 | val_0_mse: 0.005210000090301037|  0:00:05s\n","epoch 8  | loss: 0.02992 | val_0_mse: 0.002739999908953905|  0:00:06s\n","epoch 9  | loss: 0.013   | val_0_mse: 0.0015999999595806003|  0:00:07s\n","epoch 10 | loss: 0.00835 | val_0_mse: 0.0016799999866634607|  0:00:08s\n","epoch 11 | loss: 0.01025 | val_0_mse: 0.000910000002477318|  0:00:08s\n","epoch 12 | loss: 0.0095  | val_0_mse: 0.0008399999933317304|  0:00:09s\n","epoch 13 | loss: 0.00535 | val_0_mse: 0.0006600000197067857|  0:00:10s\n","epoch 14 | loss: 0.00359 | val_0_mse: 0.0005200000014156103|  0:00:10s\n","epoch 15 | loss: 0.00264 | val_0_mse: 0.0007600000244565308|  0:00:11s\n","epoch 16 | loss: 0.00239 | val_0_mse: 0.00039000000106170774|  0:00:12s\n","epoch 17 | loss: 0.00225 | val_0_mse: 0.0003800000122282654|  0:00:13s\n","epoch 18 | loss: 0.00196 | val_0_mse: 0.0005799999926239252|  0:00:13s\n","epoch 19 | loss: 0.00278 | val_0_mse: 0.0005000000237487257|  0:00:14s\n","epoch 20 | loss: 0.00244 | val_0_mse: 0.00041000000783242285|  0:00:15s\n","epoch 21 | loss: 0.00177 | val_0_mse: 0.0003600000054575503|  0:00:15s\n","epoch 22 | loss: 0.00142 | val_0_mse: 0.00019999999494757503|  0:00:16s\n","epoch 23 | loss: 0.00125 | val_0_mse: 0.0001900000061141327|  0:00:17s\n","epoch 24 | loss: 0.00104 | val_0_mse: 0.00016999999934341758|  0:00:18s\n","epoch 25 | loss: 0.00091 | val_0_mse: 0.00015999999595806003|  0:00:18s\n","epoch 26 | loss: 0.00086 | val_0_mse: 0.00015999999595806003|  0:00:19s\n","epoch 27 | loss: 0.00082 | val_0_mse: 0.00014000000373926014|  0:00:20s\n","epoch 28 | loss: 0.00072 | val_0_mse: 7.999999797903001e-05|  0:00:20s\n","epoch 29 | loss: 0.00067 | val_0_mse: 9.000000136438757e-05|  0:00:21s\n","epoch 30 | loss: 0.00063 | val_0_mse: 9.000000136438757e-05|  0:00:22s\n","epoch 31 | loss: 0.00061 | val_0_mse: 9.000000136438757e-05|  0:00:22s\n","epoch 32 | loss: 0.00058 | val_0_mse: 7.999999797903001e-05|  0:00:23s\n","epoch 33 | loss: 0.00055 | val_0_mse: 4.999999873689376e-05|  0:00:24s\n","epoch 34 | loss: 0.00055 | val_0_mse: 4.999999873689376e-05|  0:00:25s\n","epoch 35 | loss: 0.0005  | val_0_mse: 5.999999848427251e-05|  0:00:25s\n","epoch 36 | loss: 0.00049 | val_0_mse: 5.999999848427251e-05|  0:00:26s\n","epoch 37 | loss: 0.00048 | val_0_mse: 5.999999848427251e-05|  0:00:27s\n","epoch 38 | loss: 0.00049 | val_0_mse: 4.999999873689376e-05|  0:00:27s\n","epoch 39 | loss: 0.00057 | val_0_mse: 7.000000186963007e-05|  0:00:28s\n","epoch 40 | loss: 0.00049 | val_0_mse: 9.000000136438757e-05|  0:00:29s\n","epoch 41 | loss: 0.00051 | val_0_mse: 4.999999873689376e-05|  0:00:30s\n","epoch 42 | loss: 0.00047 | val_0_mse: 3.9999998989515007e-05|  0:00:30s\n","epoch 43 | loss: 0.00043 | val_0_mse: 4.999999873689376e-05|  0:00:31s\n","epoch 44 | loss: 0.0004  | val_0_mse: 4.999999873689376e-05|  0:00:32s\n","epoch 45 | loss: 0.00036 | val_0_mse: 4.999999873689376e-05|  0:00:32s\n","epoch 46 | loss: 0.00035 | val_0_mse: 4.999999873689376e-05|  0:00:33s\n","epoch 47 | loss: 0.00032 | val_0_mse: 4.999999873689376e-05|  0:00:34s\n","epoch 48 | loss: 0.0004  | val_0_mse: 7.999999797903001e-05|  0:00:34s\n","epoch 49 | loss: 0.00037 | val_0_mse: 7.999999797903001e-05|  0:00:35s\n","epoch 50 | loss: 0.00033 | val_0_mse: 3.9999998989515007e-05|  0:00:36s\n","epoch 51 | loss: 0.00029 | val_0_mse: 4.999999873689376e-05|  0:00:37s\n","epoch 52 | loss: 0.00029 | val_0_mse: 3.9999998989515007e-05|  0:00:37s\n","epoch 53 | loss: 0.00027 | val_0_mse: 3.9999998989515007e-05|  0:00:38s\n","epoch 54 | loss: 0.00026 | val_0_mse: 2.9999999242136255e-05|  0:00:39s\n","epoch 55 | loss: 0.00024 | val_0_mse: 1.9999999494757503e-05|  0:00:40s\n","epoch 56 | loss: 0.00023 | val_0_mse: 2.9999999242136255e-05|  0:00:40s\n","epoch 57 | loss: 0.00023 | val_0_mse: 1.9999999494757503e-05|  0:00:41s\n","epoch 58 | loss: 0.00022 | val_0_mse: 2.9999999242136255e-05|  0:00:42s\n","epoch 59 | loss: 0.00021 | val_0_mse: 1.9999999494757503e-05|  0:00:42s\n","epoch 60 | loss: 0.00021 | val_0_mse: 1.9999999494757503e-05|  0:00:43s\n","epoch 61 | loss: 0.00022 | val_0_mse: 1.9999999494757503e-05|  0:00:44s\n","epoch 62 | loss: 0.00024 | val_0_mse: 9.999999747378752e-06|  0:00:45s\n","epoch 63 | loss: 0.00022 | val_0_mse: 9.999999747378752e-06|  0:00:45s\n","epoch 64 | loss: 0.0002  | val_0_mse: 1.9999999494757503e-05|  0:00:46s\n","epoch 65 | loss: 0.0002  | val_0_mse: 9.999999747378752e-06|  0:00:47s\n","epoch 66 | loss: 0.0002  | val_0_mse: 9.999999747378752e-06|  0:00:47s\n","epoch 67 | loss: 0.00021 | val_0_mse: 9.999999747378752e-06|  0:00:48s\n","epoch 68 | loss: 0.00021 | val_0_mse: 1.9999999494757503e-05|  0:00:49s\n","epoch 69 | loss: 0.0002  | val_0_mse: 1.9999999494757503e-05|  0:00:49s\n","epoch 70 | loss: 0.00021 | val_0_mse: 1.9999999494757503e-05|  0:00:50s\n","epoch 71 | loss: 0.00021 | val_0_mse: 9.999999747378752e-06|  0:00:51s\n","epoch 72 | loss: 0.0002  | val_0_mse: 1.9999999494757503e-05|  0:00:52s\n","epoch 73 | loss: 0.0002  | val_0_mse: 9.999999747378752e-06|  0:00:52s\n","epoch 74 | loss: 0.00019 | val_0_mse: 9.999999747378752e-06|  0:00:53s\n","epoch 75 | loss: 0.00019 | val_0_mse: 1.9999999494757503e-05|  0:00:54s\n","epoch 76 | loss: 0.0002  | val_0_mse: 1.9999999494757503e-05|  0:00:54s\n","epoch 77 | loss: 0.0002  | val_0_mse: 9.999999747378752e-06|  0:00:55s\n","epoch 78 | loss: 0.00019 | val_0_mse: 1.9999999494757503e-05|  0:00:56s\n","epoch 79 | loss: 0.00019 | val_0_mse: 9.999999747378752e-06|  0:00:57s\n","epoch 80 | loss: 0.00019 | val_0_mse: 9.999999747378752e-06|  0:00:57s\n","epoch 81 | loss: 0.00018 | val_0_mse: 9.999999747378752e-06|  0:00:58s\n","epoch 82 | loss: 0.00018 | val_0_mse: 9.999999747378752e-06|  0:00:59s\n","epoch 83 | loss: 0.00018 | val_0_mse: 9.999999747378752e-06|  0:00:59s\n","epoch 84 | loss: 0.00018 | val_0_mse: 9.999999747378752e-06|  0:01:00s\n","epoch 85 | loss: 0.00017 | val_0_mse: 9.999999747378752e-06|  0:01:01s\n","epoch 86 | loss: 0.00017 | val_0_mse: 9.999999747378752e-06|  0:01:02s\n","epoch 87 | loss: 0.00017 | val_0_mse: 9.999999747378752e-06|  0:01:02s\n","epoch 88 | loss: 0.00017 | val_0_mse: 9.999999747378752e-06|  0:01:03s\n","epoch 89 | loss: 0.00017 | val_0_mse: 9.999999747378752e-06|  0:01:04s\n","epoch 90 | loss: 0.00017 | val_0_mse: 1.9999999494757503e-05|  0:01:04s\n","epoch 91 | loss: 0.00017 | val_0_mse: 9.999999747378752e-06|  0:01:05s\n","epoch 92 | loss: 0.00017 | val_0_mse: 9.999999747378752e-06|  0:01:06s\n","epoch 93 | loss: 0.00016 | val_0_mse: 9.999999747378752e-06|  0:01:06s\n","epoch 94 | loss: 0.00016 | val_0_mse: 9.999999747378752e-06|  0:01:07s\n","epoch 95 | loss: 0.00016 | val_0_mse: 9.999999747378752e-06|  0:01:08s\n","epoch 96 | loss: 0.00016 | val_0_mse: 9.999999747378752e-06|  0:01:09s\n","\n","Early stopping occurred at epoch 96 with best_epoch = 86 and best_val_0_mse = 9.999999747378752e-06\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 09:18:07,325] Trial 47 finished with value: 7.270072728715604e-06 and parameters: {'n_d': 36, 'n_steps': 6, 'gamma': 1.738269021245237, 'n_independent': 2, 'n_shared': 2, 'momentum': 0.19256783498941557}. Best is trial 20 with value: 1.2763081258526654e-07.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 3.67593 | val_0_mse: 2.9916300773620605|  0:00:00s\n","epoch 1  | loss: 0.83216 | val_0_mse: 0.9961199760437012|  0:00:01s\n","epoch 2  | loss: 0.30313 | val_0_mse: 0.7061399817466736|  0:00:02s\n","epoch 3  | loss: 0.15608 | val_0_mse: 0.03601999953389168|  0:00:03s\n","epoch 4  | loss: 0.11081 | val_0_mse: 0.01336000021547079|  0:00:04s\n","epoch 5  | loss: 0.04371 | val_0_mse: 0.005200000014156103|  0:00:05s\n","epoch 6  | loss: 0.00808 | val_0_mse: 0.0014100000262260437|  0:00:06s\n","epoch 7  | loss: 0.00414 | val_0_mse: 0.0005600000149570405|  0:00:07s\n","epoch 8  | loss: 0.00211 | val_0_mse: 0.0002899999963119626|  0:00:08s\n","epoch 9  | loss: 0.0011  | val_0_mse: 9.999999747378752e-05|  0:00:09s\n","epoch 10 | loss: 0.00081 | val_0_mse: 7.000000186963007e-05|  0:00:09s\n","epoch 11 | loss: 0.00071 | val_0_mse: 3.9999998989515007e-05|  0:00:10s\n","epoch 12 | loss: 0.00057 | val_0_mse: 3.9999998989515007e-05|  0:00:11s\n","epoch 13 | loss: 0.00048 | val_0_mse: 2.9999999242136255e-05|  0:00:12s\n","epoch 14 | loss: 0.00044 | val_0_mse: 1.9999999494757503e-05|  0:00:13s\n","epoch 15 | loss: 0.00044 | val_0_mse: 1.9999999494757503e-05|  0:00:14s\n","epoch 16 | loss: 0.00041 | val_0_mse: 9.999999747378752e-06|  0:00:15s\n","epoch 17 | loss: 0.00038 | val_0_mse: 9.999999747378752e-06|  0:00:16s\n","epoch 18 | loss: 0.00037 | val_0_mse: 9.999999747378752e-06|  0:00:17s\n","epoch 19 | loss: 0.00035 | val_0_mse: 9.999999747378752e-06|  0:00:18s\n","epoch 20 | loss: 0.00033 | val_0_mse: 9.999999747378752e-06|  0:00:18s\n","epoch 21 | loss: 0.00032 | val_0_mse: 9.999999747378752e-06|  0:00:19s\n","epoch 22 | loss: 0.00031 | val_0_mse: 0.0     |  0:00:20s\n","epoch 23 | loss: 0.0003  | val_0_mse: 0.0     |  0:00:21s\n","epoch 24 | loss: 0.00029 | val_0_mse: 0.0     |  0:00:22s\n","epoch 25 | loss: 0.00029 | val_0_mse: 0.0     |  0:00:23s\n","epoch 26 | loss: 0.00028 | val_0_mse: 0.0     |  0:00:24s\n","epoch 27 | loss: 0.00029 | val_0_mse: 0.0     |  0:00:25s\n","epoch 28 | loss: 0.00028 | val_0_mse: 0.0     |  0:00:26s\n","epoch 29 | loss: 0.00028 | val_0_mse: 0.0     |  0:00:27s\n","epoch 30 | loss: 0.00028 | val_0_mse: 0.0     |  0:00:28s\n","epoch 31 | loss: 0.00028 | val_0_mse: 0.0     |  0:00:29s\n","epoch 32 | loss: 0.00028 | val_0_mse: 0.0     |  0:00:30s\n","epoch 33 | loss: 0.00028 | val_0_mse: 0.0     |  0:00:30s\n","epoch 34 | loss: 0.00027 | val_0_mse: 0.0     |  0:00:31s\n","epoch 35 | loss: 0.00027 | val_0_mse: 0.0     |  0:00:32s\n","epoch 36 | loss: 0.00027 | val_0_mse: 0.0     |  0:00:33s\n","epoch 37 | loss: 0.00026 | val_0_mse: 0.0     |  0:00:34s\n","epoch 38 | loss: 0.00026 | val_0_mse: 0.0     |  0:00:35s\n","epoch 39 | loss: 0.00026 | val_0_mse: 0.0     |  0:00:36s\n","epoch 40 | loss: 0.00025 | val_0_mse: 0.0     |  0:00:37s\n","epoch 41 | loss: 0.00025 | val_0_mse: 0.0     |  0:00:38s\n","epoch 42 | loss: 0.00025 | val_0_mse: 0.0     |  0:00:39s\n","epoch 43 | loss: 0.00025 | val_0_mse: 0.0     |  0:00:39s\n","epoch 44 | loss: 0.00024 | val_0_mse: 0.0     |  0:00:40s\n","epoch 45 | loss: 0.00025 | val_0_mse: 0.0     |  0:00:41s\n","epoch 46 | loss: 0.00025 | val_0_mse: 0.0     |  0:00:42s\n","epoch 47 | loss: 0.00024 | val_0_mse: 0.0     |  0:00:43s\n","epoch 48 | loss: 0.00025 | val_0_mse: 0.0     |  0:00:44s\n","epoch 49 | loss: 0.00025 | val_0_mse: 0.0     |  0:00:45s\n","epoch 50 | loss: 0.00024 | val_0_mse: 0.0     |  0:00:46s\n","epoch 51 | loss: 0.00024 | val_0_mse: 0.0     |  0:00:47s\n","epoch 52 | loss: 0.00024 | val_0_mse: 0.0     |  0:00:47s\n","epoch 53 | loss: 0.00023 | val_0_mse: 0.0     |  0:00:48s\n","epoch 54 | loss: 0.00023 | val_0_mse: 0.0     |  0:00:49s\n","epoch 55 | loss: 0.00023 | val_0_mse: 0.0     |  0:00:50s\n","epoch 56 | loss: 0.00023 | val_0_mse: 0.0     |  0:00:51s\n","epoch 57 | loss: 0.00022 | val_0_mse: 0.0     |  0:00:52s\n","epoch 58 | loss: 0.00022 | val_0_mse: 0.0     |  0:00:53s\n","epoch 59 | loss: 0.00022 | val_0_mse: 0.0     |  0:00:54s\n","epoch 60 | loss: 0.00022 | val_0_mse: 0.0     |  0:00:55s\n","\n","Early stopping occurred at epoch 60 with best_epoch = 50 and best_val_0_mse = 0.0\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 09:19:02,997] Trial 48 finished with value: 3.5296835676490446e-07 and parameters: {'n_d': 33, 'n_steps': 5, 'gamma': 1.8867011558364588, 'n_independent': 3, 'n_shared': 4, 'momentum': 0.26504861700531934}. Best is trial 20 with value: 1.2763081258526654e-07.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 4.83391 | val_0_mse: 9.147379875183105|  0:00:00s\n","epoch 1  | loss: 1.28289 | val_0_mse: 1.670680046081543|  0:00:01s\n","epoch 2  | loss: 0.46226 | val_0_mse: 0.261029988527298|  0:00:02s\n","epoch 3  | loss: 0.60372 | val_0_mse: 0.46577998995780945|  0:00:02s\n","epoch 4  | loss: 0.5559  | val_0_mse: 0.18951000273227692|  0:00:03s\n","epoch 5  | loss: 0.33077 | val_0_mse: 0.06872999668121338|  0:00:04s\n","epoch 6  | loss: 0.13988 | val_0_mse: 0.08906000107526779|  0:00:04s\n","epoch 7  | loss: 0.10419 | val_0_mse: 0.014750000089406967|  0:00:05s\n","epoch 8  | loss: 0.03577 | val_0_mse: 0.005189999938011169|  0:00:06s\n","epoch 9  | loss: 0.01763 | val_0_mse: 0.007110000122338533|  0:00:07s\n","epoch 10 | loss: 0.01455 | val_0_mse: 0.0017800000496208668|  0:00:07s\n","epoch 11 | loss: 0.00968 | val_0_mse: 0.0012499999720603228|  0:00:08s\n","epoch 12 | loss: 0.00595 | val_0_mse: 0.0004199999966658652|  0:00:09s\n","epoch 13 | loss: 0.0029  | val_0_mse: 0.00031999999191612005|  0:00:09s\n","epoch 14 | loss: 0.00202 | val_0_mse: 0.0002500000118743628|  0:00:10s\n","epoch 15 | loss: 0.00143 | val_0_mse: 0.00044999999227002263|  0:00:11s\n","epoch 16 | loss: 0.00113 | val_0_mse: 0.0003699999942909926|  0:00:11s\n","epoch 17 | loss: 0.0011  | val_0_mse: 0.0004299999854993075|  0:00:12s\n","epoch 18 | loss: 0.00111 | val_0_mse: 0.00019999999494757503|  0:00:13s\n","epoch 19 | loss: 0.00087 | val_0_mse: 0.00013000000035390258|  0:00:13s\n","epoch 20 | loss: 0.0007  | val_0_mse: 0.00011999999696854502|  0:00:14s\n","epoch 21 | loss: 0.00059 | val_0_mse: 0.00011999999696854502|  0:00:15s\n","epoch 22 | loss: 0.00056 | val_0_mse: 9.999999747378752e-05|  0:00:15s\n","epoch 23 | loss: 0.00055 | val_0_mse: 9.000000136438757e-05|  0:00:16s\n","epoch 24 | loss: 0.00047 | val_0_mse: 5.999999848427251e-05|  0:00:17s\n","epoch 25 | loss: 0.00041 | val_0_mse: 4.999999873689376e-05|  0:00:17s\n","epoch 26 | loss: 0.00038 | val_0_mse: 3.9999998989515007e-05|  0:00:18s\n","epoch 27 | loss: 0.00036 | val_0_mse: 2.9999999242136255e-05|  0:00:19s\n","epoch 28 | loss: 0.00035 | val_0_mse: 2.9999999242136255e-05|  0:00:19s\n","epoch 29 | loss: 0.00033 | val_0_mse: 2.9999999242136255e-05|  0:00:20s\n","epoch 30 | loss: 0.00032 | val_0_mse: 1.9999999494757503e-05|  0:00:21s\n","epoch 31 | loss: 0.00029 | val_0_mse: 1.9999999494757503e-05|  0:00:21s\n","epoch 32 | loss: 0.00029 | val_0_mse: 1.9999999494757503e-05|  0:00:22s\n","epoch 33 | loss: 0.00029 | val_0_mse: 1.9999999494757503e-05|  0:00:23s\n","epoch 34 | loss: 0.00028 | val_0_mse: 1.9999999494757503e-05|  0:00:23s\n","epoch 35 | loss: 0.00029 | val_0_mse: 1.9999999494757503e-05|  0:00:24s\n","epoch 36 | loss: 0.00027 | val_0_mse: 1.9999999494757503e-05|  0:00:25s\n","epoch 37 | loss: 0.00026 | val_0_mse: 1.9999999494757503e-05|  0:00:26s\n","epoch 38 | loss: 0.00026 | val_0_mse: 9.999999747378752e-06|  0:00:26s\n","epoch 39 | loss: 0.00024 | val_0_mse: 9.999999747378752e-06|  0:00:27s\n","epoch 40 | loss: 0.00025 | val_0_mse: 9.999999747378752e-06|  0:00:28s\n","epoch 41 | loss: 0.00023 | val_0_mse: 9.999999747378752e-06|  0:00:28s\n","epoch 42 | loss: 0.00023 | val_0_mse: 9.999999747378752e-06|  0:00:29s\n","epoch 43 | loss: 0.00022 | val_0_mse: 9.999999747378752e-06|  0:00:30s\n","epoch 44 | loss: 0.00022 | val_0_mse: 9.999999747378752e-06|  0:00:30s\n","epoch 45 | loss: 0.00022 | val_0_mse: 9.999999747378752e-06|  0:00:31s\n","epoch 46 | loss: 0.00022 | val_0_mse: 9.999999747378752e-06|  0:00:32s\n","epoch 47 | loss: 0.00021 | val_0_mse: 9.999999747378752e-06|  0:00:32s\n","epoch 48 | loss: 0.00022 | val_0_mse: 0.0     |  0:00:33s\n","epoch 49 | loss: 0.00021 | val_0_mse: 9.999999747378752e-06|  0:00:34s\n","epoch 50 | loss: 0.00021 | val_0_mse: 9.999999747378752e-06|  0:00:34s\n","epoch 51 | loss: 0.0002  | val_0_mse: 0.0     |  0:00:35s\n","epoch 52 | loss: 0.0002  | val_0_mse: 0.0     |  0:00:36s\n","epoch 53 | loss: 0.0002  | val_0_mse: 9.999999747378752e-06|  0:00:36s\n","epoch 54 | loss: 0.0002  | val_0_mse: 0.0     |  0:00:37s\n","epoch 55 | loss: 0.0002  | val_0_mse: 0.0     |  0:00:38s\n","epoch 56 | loss: 0.0002  | val_0_mse: 9.999999747378752e-06|  0:00:39s\n","epoch 57 | loss: 0.0002  | val_0_mse: 9.999999747378752e-06|  0:00:39s\n","epoch 58 | loss: 0.0002  | val_0_mse: 0.0     |  0:00:40s\n","epoch 59 | loss: 0.00019 | val_0_mse: 0.0     |  0:00:41s\n","epoch 60 | loss: 0.00019 | val_0_mse: 0.0     |  0:00:41s\n","epoch 61 | loss: 0.00019 | val_0_mse: 0.0     |  0:00:42s\n","epoch 62 | loss: 0.00019 | val_0_mse: 0.0     |  0:00:43s\n","epoch 63 | loss: 0.00019 | val_0_mse: 0.0     |  0:00:43s\n","epoch 64 | loss: 0.00018 | val_0_mse: 0.0     |  0:00:44s\n","epoch 65 | loss: 0.00019 | val_0_mse: 0.0     |  0:00:45s\n","epoch 66 | loss: 0.00019 | val_0_mse: 0.0     |  0:00:45s\n","epoch 67 | loss: 0.00019 | val_0_mse: 0.0     |  0:00:46s\n","epoch 68 | loss: 0.00018 | val_0_mse: 0.0     |  0:00:47s\n","epoch 69 | loss: 0.00018 | val_0_mse: 0.0     |  0:00:47s\n","epoch 70 | loss: 0.00018 | val_0_mse: 0.0     |  0:00:48s\n","epoch 71 | loss: 0.00017 | val_0_mse: 0.0     |  0:00:49s\n","epoch 72 | loss: 0.00017 | val_0_mse: 0.0     |  0:00:49s\n","epoch 73 | loss: 0.00017 | val_0_mse: 0.0     |  0:00:50s\n","epoch 74 | loss: 0.00017 | val_0_mse: 0.0     |  0:00:51s\n","epoch 75 | loss: 0.00016 | val_0_mse: 0.0     |  0:00:51s\n","epoch 76 | loss: 0.00016 | val_0_mse: 0.0     |  0:00:52s\n","epoch 77 | loss: 0.00017 | val_0_mse: 0.0     |  0:00:53s\n","epoch 78 | loss: 0.00016 | val_0_mse: 0.0     |  0:00:53s\n","epoch 79 | loss: 0.00016 | val_0_mse: 0.0     |  0:00:54s\n","epoch 80 | loss: 0.00016 | val_0_mse: 0.0     |  0:00:55s\n","epoch 81 | loss: 0.00017 | val_0_mse: 0.0     |  0:00:55s\n","epoch 82 | loss: 0.00017 | val_0_mse: 0.0     |  0:00:56s\n","epoch 83 | loss: 0.00017 | val_0_mse: 0.0     |  0:00:57s\n","epoch 84 | loss: 0.00017 | val_0_mse: 0.0     |  0:00:57s\n","epoch 85 | loss: 0.00017 | val_0_mse: 0.0     |  0:00:58s\n","epoch 86 | loss: 0.00018 | val_0_mse: 0.0     |  0:00:59s\n","epoch 87 | loss: 0.00018 | val_0_mse: 0.0     |  0:00:59s\n","epoch 88 | loss: 0.00019 | val_0_mse: 0.0     |  0:01:00s\n","epoch 89 | loss: 0.00019 | val_0_mse: 0.0     |  0:01:01s\n","epoch 90 | loss: 0.00018 | val_0_mse: 0.0     |  0:01:01s\n","epoch 91 | loss: 0.00018 | val_0_mse: 0.0     |  0:01:02s\n","epoch 92 | loss: 0.00018 | val_0_mse: 0.0     |  0:01:03s\n","epoch 93 | loss: 0.00018 | val_0_mse: 0.0     |  0:01:04s\n","epoch 94 | loss: 0.00018 | val_0_mse: 0.0     |  0:01:04s\n","epoch 95 | loss: 0.00022 | val_0_mse: 3.9999998989515007e-05|  0:01:05s\n","epoch 96 | loss: 0.00069 | val_0_mse: 1.9999999494757503e-05|  0:01:06s\n","\n","Early stopping occurred at epoch 96 with best_epoch = 86 and best_val_0_mse = 0.0\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 09:20:09,454] Trial 49 finished with value: 3.241377442009252e-07 and parameters: {'n_d': 46, 'n_steps': 7, 'gamma': 1.6544621807340327, 'n_independent': 1, 'n_shared': 2, 'momentum': 0.2140142012315886}. Best is trial 20 with value: 1.2763081258526654e-07.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 2.18642 | val_0_mse: 5.646570205688477|  0:00:01s\n","epoch 1  | loss: 1.29267 | val_0_mse: 1.3156399726867676|  0:00:02s\n","epoch 2  | loss: 0.48124 | val_0_mse: 0.11954999715089798|  0:00:03s\n","epoch 3  | loss: 1.72787 | val_0_mse: 0.23964999616146088|  0:00:04s\n","epoch 4  | loss: 0.33797 | val_0_mse: 0.021570000797510147|  0:00:05s\n","epoch 5  | loss: 0.15739 | val_0_mse: 0.11174999922513962|  0:00:06s\n","epoch 6  | loss: 0.17721 | val_0_mse: 0.05116000026464462|  0:00:07s\n","epoch 7  | loss: 0.25634 | val_0_mse: 0.02402999997138977|  0:00:08s\n","epoch 8  | loss: 0.09235 | val_0_mse: 0.056620001792907715|  0:00:09s\n","epoch 9  | loss: 0.00939 | val_0_mse: 0.0019000000320374966|  0:00:10s\n","epoch 10 | loss: 0.00258 | val_0_mse: 0.00026000000070780516|  0:00:11s\n","epoch 11 | loss: 0.00086 | val_0_mse: 0.0002099999983329326|  0:00:12s\n","epoch 12 | loss: 0.00049 | val_0_mse: 0.0003000000142492354|  0:00:13s\n","epoch 13 | loss: 0.00028 | val_0_mse: 9.000000136438757e-05|  0:00:14s\n","epoch 14 | loss: 0.00023 | val_0_mse: 1.9999999494757503e-05|  0:00:15s\n","epoch 15 | loss: 0.0002  | val_0_mse: 9.999999747378752e-06|  0:00:16s\n","epoch 16 | loss: 0.00019 | val_0_mse: 9.999999747378752e-06|  0:00:17s\n","epoch 17 | loss: 0.00018 | val_0_mse: 0.0     |  0:00:18s\n","epoch 18 | loss: 0.00018 | val_0_mse: 0.0     |  0:00:19s\n","epoch 19 | loss: 0.00018 | val_0_mse: 0.0     |  0:00:20s\n","epoch 20 | loss: 0.00018 | val_0_mse: 0.0     |  0:00:21s\n","epoch 21 | loss: 0.00017 | val_0_mse: 0.0     |  0:00:22s\n","epoch 22 | loss: 0.00017 | val_0_mse: 0.0     |  0:00:23s\n","epoch 23 | loss: 0.00017 | val_0_mse: 0.0     |  0:00:24s\n","epoch 24 | loss: 0.00017 | val_0_mse: 0.0     |  0:00:25s\n","epoch 25 | loss: 0.00017 | val_0_mse: 0.0     |  0:00:26s\n","epoch 26 | loss: 0.00017 | val_0_mse: 0.0     |  0:00:27s\n","epoch 27 | loss: 0.00017 | val_0_mse: 0.0     |  0:00:28s\n","epoch 28 | loss: 0.00017 | val_0_mse: 0.0     |  0:00:29s\n","epoch 29 | loss: 0.00017 | val_0_mse: 0.0     |  0:00:30s\n","epoch 30 | loss: 0.00016 | val_0_mse: 0.0     |  0:00:32s\n","epoch 31 | loss: 0.00016 | val_0_mse: 0.0     |  0:00:33s\n","epoch 32 | loss: 0.00016 | val_0_mse: 0.0     |  0:00:34s\n","epoch 33 | loss: 0.00016 | val_0_mse: 0.0     |  0:00:35s\n","epoch 34 | loss: 0.00016 | val_0_mse: 0.0     |  0:00:36s\n","epoch 35 | loss: 0.00016 | val_0_mse: 0.0     |  0:00:37s\n","epoch 36 | loss: 0.00015 | val_0_mse: 0.0     |  0:00:38s\n","epoch 37 | loss: 0.00015 | val_0_mse: 0.0     |  0:00:39s\n","epoch 38 | loss: 0.00015 | val_0_mse: 0.0     |  0:00:40s\n","epoch 39 | loss: 0.00015 | val_0_mse: 0.0     |  0:00:41s\n","epoch 40 | loss: 0.00015 | val_0_mse: 0.0     |  0:00:42s\n","epoch 41 | loss: 0.00015 | val_0_mse: 0.0     |  0:00:43s\n","epoch 42 | loss: 0.00015 | val_0_mse: 0.0     |  0:00:44s\n","epoch 43 | loss: 0.00015 | val_0_mse: 0.0     |  0:00:45s\n","epoch 44 | loss: 0.00016 | val_0_mse: 0.0     |  0:00:46s\n","epoch 45 | loss: 0.00016 | val_0_mse: 0.0     |  0:00:47s\n","epoch 46 | loss: 0.00016 | val_0_mse: 0.0     |  0:00:48s\n","epoch 47 | loss: 0.00016 | val_0_mse: 0.0     |  0:00:49s\n","epoch 48 | loss: 0.00016 | val_0_mse: 0.0     |  0:00:50s\n","epoch 49 | loss: 0.00016 | val_0_mse: 0.0     |  0:00:51s\n","epoch 50 | loss: 0.00016 | val_0_mse: 0.0     |  0:00:52s\n","epoch 51 | loss: 0.00016 | val_0_mse: 0.0     |  0:00:53s\n","epoch 52 | loss: 0.00016 | val_0_mse: 0.0     |  0:00:54s\n","epoch 53 | loss: 0.00016 | val_0_mse: 0.0     |  0:00:55s\n","epoch 54 | loss: 0.00016 | val_0_mse: 0.0     |  0:00:56s\n","epoch 55 | loss: 0.00016 | val_0_mse: 0.0     |  0:00:57s\n","epoch 56 | loss: 0.00016 | val_0_mse: 0.0     |  0:00:58s\n","epoch 57 | loss: 0.00016 | val_0_mse: 0.0     |  0:00:59s\n","epoch 58 | loss: 0.00016 | val_0_mse: 0.0     |  0:01:00s\n","epoch 59 | loss: 0.00016 | val_0_mse: 0.0     |  0:01:01s\n","epoch 60 | loss: 0.00016 | val_0_mse: 0.0     |  0:01:02s\n","\n","Early stopping occurred at epoch 60 with best_epoch = 50 and best_val_0_mse = 0.0\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 09:21:12,889] Trial 50 finished with value: 2.2272669752965157e-07 and parameters: {'n_d': 39, 'n_steps': 8, 'gamma': 1.9434653992692783, 'n_independent': 2, 'n_shared': 3, 'momentum': 0.3249351110248427}. Best is trial 20 with value: 1.2763081258526654e-07.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 1.16143 | val_0_mse: 1.0629099607467651|  0:00:01s\n","epoch 1  | loss: 0.42552 | val_0_mse: 0.15649999678134918|  0:00:02s\n","epoch 2  | loss: 0.19558 | val_0_mse: 0.044190000742673874|  0:00:03s\n","epoch 3  | loss: 0.05769 | val_0_mse: 0.0072200000286102295|  0:00:04s\n","epoch 4  | loss: 0.01606 | val_0_mse: 0.014820000156760216|  0:00:05s\n","epoch 5  | loss: 0.0067  | val_0_mse: 0.0004799999878741801|  0:00:06s\n","epoch 6  | loss: 0.0014  | val_0_mse: 0.00015999999595806003|  0:00:07s\n","epoch 7  | loss: 0.00056 | val_0_mse: 7.000000186963007e-05|  0:00:09s\n","epoch 8  | loss: 0.00049 | val_0_mse: 4.999999873689376e-05|  0:00:10s\n","epoch 9  | loss: 0.00042 | val_0_mse: 1.9999999494757503e-05|  0:00:11s\n","epoch 10 | loss: 0.00037 | val_0_mse: 0.0     |  0:00:12s\n","epoch 11 | loss: 0.00034 | val_0_mse: 0.0     |  0:00:13s\n","epoch 12 | loss: 0.00033 | val_0_mse: 0.0     |  0:00:14s\n","epoch 13 | loss: 0.00032 | val_0_mse: 0.0     |  0:00:15s\n","epoch 14 | loss: 0.00031 | val_0_mse: 0.0     |  0:00:17s\n","epoch 15 | loss: 0.0003  | val_0_mse: 0.0     |  0:00:18s\n","epoch 16 | loss: 0.0003  | val_0_mse: 0.0     |  0:00:19s\n","epoch 17 | loss: 0.0003  | val_0_mse: 0.0     |  0:00:20s\n","epoch 18 | loss: 0.00029 | val_0_mse: 0.0     |  0:00:21s\n","epoch 19 | loss: 0.00029 | val_0_mse: 0.0     |  0:00:22s\n","epoch 20 | loss: 0.00029 | val_0_mse: 0.0     |  0:00:23s\n","epoch 21 | loss: 0.00028 | val_0_mse: 0.0     |  0:00:25s\n","epoch 22 | loss: 0.00029 | val_0_mse: 0.0     |  0:00:26s\n","epoch 23 | loss: 0.00029 | val_0_mse: 0.0     |  0:00:27s\n","epoch 24 | loss: 0.00028 | val_0_mse: 0.0     |  0:00:28s\n","epoch 25 | loss: 0.00027 | val_0_mse: 0.0     |  0:00:29s\n","epoch 26 | loss: 0.00026 | val_0_mse: 0.0     |  0:00:30s\n","epoch 27 | loss: 0.00026 | val_0_mse: 0.0     |  0:00:31s\n","epoch 28 | loss: 0.00026 | val_0_mse: 0.0     |  0:00:32s\n","epoch 29 | loss: 0.00026 | val_0_mse: 0.0     |  0:00:34s\n","epoch 30 | loss: 0.00026 | val_0_mse: 0.0     |  0:00:35s\n","epoch 31 | loss: 0.00025 | val_0_mse: 0.0     |  0:00:36s\n","epoch 32 | loss: 0.00024 | val_0_mse: 0.0     |  0:00:37s\n","epoch 33 | loss: 0.00024 | val_0_mse: 0.0     |  0:00:38s\n","epoch 34 | loss: 0.00023 | val_0_mse: 0.0     |  0:00:39s\n","epoch 35 | loss: 0.00022 | val_0_mse: 0.0     |  0:00:40s\n","epoch 36 | loss: 0.00021 | val_0_mse: 0.0     |  0:00:42s\n","epoch 37 | loss: 0.00021 | val_0_mse: 0.0     |  0:00:43s\n","epoch 38 | loss: 0.0002  | val_0_mse: 0.0     |  0:00:44s\n","epoch 39 | loss: 0.0002  | val_0_mse: 0.0     |  0:00:45s\n","epoch 40 | loss: 0.00021 | val_0_mse: 0.0     |  0:00:46s\n","epoch 41 | loss: 0.00021 | val_0_mse: 0.0     |  0:00:47s\n","epoch 42 | loss: 0.0002  | val_0_mse: 0.0     |  0:00:48s\n","epoch 43 | loss: 0.0002  | val_0_mse: 0.0     |  0:00:50s\n","epoch 44 | loss: 0.0002  | val_0_mse: 0.0     |  0:00:51s\n","epoch 45 | loss: 0.00019 | val_0_mse: 0.0     |  0:00:52s\n","epoch 46 | loss: 0.00019 | val_0_mse: 0.0     |  0:00:53s\n","\n","Early stopping occurred at epoch 46 with best_epoch = 36 and best_val_0_mse = 0.0\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 09:22:06,833] Trial 51 finished with value: 3.821948837412492e-07 and parameters: {'n_d': 12, 'n_steps': 6, 'gamma': 1.855897803448684, 'n_independent': 5, 'n_shared': 3, 'momentum': 0.07783486965088668}. Best is trial 20 with value: 1.2763081258526654e-07.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 3.42179 | val_0_mse: 2.0881500244140625|  0:00:00s\n","epoch 1  | loss: 0.9723  | val_0_mse: 0.1406099945306778|  0:00:02s\n","epoch 2  | loss: 0.43539 | val_0_mse: 0.3052699863910675|  0:00:03s\n","epoch 3  | loss: 0.34453 | val_0_mse: 0.01355000026524067|  0:00:04s\n","epoch 4  | loss: 0.30057 | val_0_mse: 0.14157000184059143|  0:00:05s\n","epoch 5  | loss: 0.06454 | val_0_mse: 0.015230000019073486|  0:00:06s\n","epoch 6  | loss: 0.02138 | val_0_mse: 0.009100000374019146|  0:00:07s\n","epoch 7  | loss: 0.00709 | val_0_mse: 0.0008900000248104334|  0:00:08s\n","epoch 8  | loss: 0.00309 | val_0_mse: 0.00013000000035390258|  0:00:09s\n","epoch 9  | loss: 0.00179 | val_0_mse: 0.0003000000142492354|  0:00:10s\n","epoch 10 | loss: 0.0012  | val_0_mse: 9.000000136438757e-05|  0:00:11s\n","epoch 11 | loss: 0.00118 | val_0_mse: 7.000000186963007e-05|  0:00:12s\n","epoch 12 | loss: 0.0011  | val_0_mse: 0.00011999999696854502|  0:00:13s\n","epoch 13 | loss: 0.00081 | val_0_mse: 0.00014000000373926014|  0:00:14s\n","epoch 14 | loss: 0.0008  | val_0_mse: 0.00013000000035390258|  0:00:15s\n","epoch 15 | loss: 0.00081 | val_0_mse: 0.00011999999696854502|  0:00:16s\n","epoch 16 | loss: 0.00069 | val_0_mse: 5.999999848427251e-05|  0:00:17s\n","epoch 17 | loss: 0.00062 | val_0_mse: 4.999999873689376e-05|  0:00:18s\n","epoch 18 | loss: 0.00056 | val_0_mse: 4.999999873689376e-05|  0:00:19s\n","epoch 19 | loss: 0.00058 | val_0_mse: 0.00011999999696854502|  0:00:20s\n","epoch 20 | loss: 0.00066 | val_0_mse: 9.000000136438757e-05|  0:00:21s\n","epoch 21 | loss: 0.00062 | val_0_mse: 4.999999873689376e-05|  0:00:22s\n","epoch 22 | loss: 0.00061 | val_0_mse: 4.999999873689376e-05|  0:00:22s\n","epoch 23 | loss: 0.0006  | val_0_mse: 3.9999998989515007e-05|  0:00:23s\n","epoch 24 | loss: 0.00059 | val_0_mse: 3.9999998989515007e-05|  0:00:24s\n","epoch 25 | loss: 0.00052 | val_0_mse: 2.9999999242136255e-05|  0:00:25s\n","epoch 26 | loss: 0.00047 | val_0_mse: 2.9999999242136255e-05|  0:00:26s\n","epoch 27 | loss: 0.00046 | val_0_mse: 1.9999999494757503e-05|  0:00:27s\n","epoch 28 | loss: 0.00045 | val_0_mse: 1.9999999494757503e-05|  0:00:28s\n","epoch 29 | loss: 0.00044 | val_0_mse: 1.9999999494757503e-05|  0:00:29s\n","epoch 30 | loss: 0.00044 | val_0_mse: 1.9999999494757503e-05|  0:00:30s\n","epoch 31 | loss: 0.00044 | val_0_mse: 1.9999999494757503e-05|  0:00:32s\n","epoch 32 | loss: 0.00043 | val_0_mse: 1.9999999494757503e-05|  0:00:33s\n","epoch 33 | loss: 0.00043 | val_0_mse: 1.9999999494757503e-05|  0:00:33s\n","epoch 34 | loss: 0.00041 | val_0_mse: 1.9999999494757503e-05|  0:00:34s\n","epoch 35 | loss: 0.00041 | val_0_mse: 9.999999747378752e-06|  0:00:35s\n","epoch 36 | loss: 0.00041 | val_0_mse: 1.9999999494757503e-05|  0:00:36s\n","epoch 37 | loss: 0.0004  | val_0_mse: 1.9999999494757503e-05|  0:00:37s\n","epoch 38 | loss: 0.00039 | val_0_mse: 1.9999999494757503e-05|  0:00:38s\n","epoch 39 | loss: 0.00039 | val_0_mse: 2.9999999242136255e-05|  0:00:39s\n","epoch 40 | loss: 0.0004  | val_0_mse: 1.9999999494757503e-05|  0:00:40s\n","epoch 41 | loss: 0.0004  | val_0_mse: 1.9999999494757503e-05|  0:00:41s\n","epoch 42 | loss: 0.00039 | val_0_mse: 1.9999999494757503e-05|  0:00:42s\n","epoch 43 | loss: 0.00039 | val_0_mse: 1.9999999494757503e-05|  0:00:43s\n","epoch 44 | loss: 0.00038 | val_0_mse: 1.9999999494757503e-05|  0:00:44s\n","epoch 45 | loss: 0.00036 | val_0_mse: 9.999999747378752e-06|  0:00:45s\n","epoch 46 | loss: 0.00037 | val_0_mse: 1.9999999494757503e-05|  0:00:46s\n","epoch 47 | loss: 0.00036 | val_0_mse: 9.999999747378752e-06|  0:00:47s\n","epoch 48 | loss: 0.00038 | val_0_mse: 1.9999999494757503e-05|  0:00:48s\n","epoch 49 | loss: 0.00037 | val_0_mse: 9.999999747378752e-06|  0:00:49s\n","epoch 50 | loss: 0.00037 | val_0_mse: 1.9999999494757503e-05|  0:00:50s\n","epoch 51 | loss: 0.00038 | val_0_mse: 1.9999999494757503e-05|  0:00:51s\n","epoch 52 | loss: 0.00038 | val_0_mse: 9.999999747378752e-06|  0:00:52s\n","epoch 53 | loss: 0.00035 | val_0_mse: 9.999999747378752e-06|  0:00:53s\n","epoch 54 | loss: 0.00035 | val_0_mse: 9.999999747378752e-06|  0:00:54s\n","epoch 55 | loss: 0.00034 | val_0_mse: 1.9999999494757503e-05|  0:00:55s\n","\n","Early stopping occurred at epoch 55 with best_epoch = 45 and best_val_0_mse = 9.999999747378752e-06\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 09:23:03,080] Trial 52 finished with value: 1.1970515515713487e-05 and parameters: {'n_d': 43, 'n_steps': 5, 'gamma': 1.799470400995009, 'n_independent': 5, 'n_shared': 3, 'momentum': 0.11095633212151447}. Best is trial 20 with value: 1.2763081258526654e-07.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 5.24494 | val_0_mse: 32.33591079711914|  0:00:01s\n","epoch 1  | loss: 1.80954 | val_0_mse: 1.5702500343322754|  0:00:02s\n","epoch 2  | loss: 0.91076 | val_0_mse: 0.3904399871826172|  0:00:03s\n","epoch 3  | loss: 0.60898 | val_0_mse: 0.4307900071144104|  0:00:04s\n","epoch 4  | loss: 0.73519 | val_0_mse: 2.4825599193573|  0:00:05s\n","epoch 5  | loss: 0.37053 | val_0_mse: 0.20167000591754913|  0:00:06s\n","epoch 6  | loss: 0.10282 | val_0_mse: 0.020479999482631683|  0:00:08s\n","epoch 7  | loss: 0.03626 | val_0_mse: 0.004519999958574772|  0:00:09s\n","epoch 8  | loss: 0.01255 | val_0_mse: 0.0010999999940395355|  0:00:10s\n","epoch 9  | loss: 0.00538 | val_0_mse: 0.0003000000142492354|  0:00:11s\n","epoch 10 | loss: 0.00314 | val_0_mse: 0.0007099999929778278|  0:00:12s\n","epoch 11 | loss: 0.00264 | val_0_mse: 0.00015999999595806003|  0:00:13s\n","epoch 12 | loss: 0.00191 | val_0_mse: 7.000000186963007e-05|  0:00:14s\n","epoch 13 | loss: 0.0018  | val_0_mse: 7.000000186963007e-05|  0:00:16s\n","epoch 14 | loss: 0.00163 | val_0_mse: 9.999999747378752e-05|  0:00:17s\n","epoch 15 | loss: 0.00137 | val_0_mse: 5.999999848427251e-05|  0:00:18s\n","epoch 16 | loss: 0.0012  | val_0_mse: 4.999999873689376e-05|  0:00:19s\n","epoch 17 | loss: 0.00122 | val_0_mse: 5.999999848427251e-05|  0:00:20s\n","epoch 18 | loss: 0.00132 | val_0_mse: 7.000000186963007e-05|  0:00:21s\n","epoch 19 | loss: 0.00113 | val_0_mse: 2.9999999242136255e-05|  0:00:22s\n","epoch 20 | loss: 0.0011  | val_0_mse: 5.999999848427251e-05|  0:00:24s\n","epoch 21 | loss: 0.00117 | val_0_mse: 3.9999998989515007e-05|  0:00:25s\n","epoch 22 | loss: 0.00099 | val_0_mse: 2.9999999242136255e-05|  0:00:26s\n","epoch 23 | loss: 0.00095 | val_0_mse: 3.9999998989515007e-05|  0:00:27s\n","epoch 24 | loss: 0.00098 | val_0_mse: 2.9999999242136255e-05|  0:00:28s\n","epoch 25 | loss: 0.00096 | val_0_mse: 1.9999999494757503e-05|  0:00:29s\n","epoch 26 | loss: 0.00089 | val_0_mse: 1.9999999494757503e-05|  0:00:30s\n","epoch 27 | loss: 0.00086 | val_0_mse: 2.9999999242136255e-05|  0:00:32s\n","epoch 28 | loss: 0.00087 | val_0_mse: 9.999999747378752e-06|  0:00:33s\n","epoch 29 | loss: 0.00098 | val_0_mse: 1.9999999494757503e-05|  0:00:34s\n","epoch 30 | loss: 0.00117 | val_0_mse: 3.9999998989515007e-05|  0:00:35s\n","epoch 31 | loss: 0.00116 | val_0_mse: 4.999999873689376e-05|  0:00:36s\n","epoch 32 | loss: 0.00106 | val_0_mse: 3.9999998989515007e-05|  0:00:37s\n","epoch 33 | loss: 0.00088 | val_0_mse: 3.9999998989515007e-05|  0:00:38s\n","epoch 34 | loss: 0.00074 | val_0_mse: 2.9999999242136255e-05|  0:00:40s\n","epoch 35 | loss: 0.00069 | val_0_mse: 2.9999999242136255e-05|  0:00:41s\n","epoch 36 | loss: 0.00071 | val_0_mse: 3.9999998989515007e-05|  0:00:42s\n","epoch 37 | loss: 0.00062 | val_0_mse: 1.9999999494757503e-05|  0:00:43s\n","epoch 38 | loss: 0.00057 | val_0_mse: 1.9999999494757503e-05|  0:00:44s\n","\n","Early stopping occurred at epoch 38 with best_epoch = 28 and best_val_0_mse = 9.999999747378752e-06\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 09:23:48,400] Trial 53 finished with value: 1.2104001143597998e-05 and parameters: {'n_d': 37, 'n_steps': 6, 'gamma': 1.243624279443585, 'n_independent': 5, 'n_shared': 3, 'momentum': 0.15875553011615803}. Best is trial 20 with value: 1.2763081258526654e-07.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 3.58519 | val_0_mse: 7.406700134277344|  0:00:01s\n","epoch 1  | loss: 1.4337  | val_0_mse: 1.0019299983978271|  0:00:02s\n","epoch 2  | loss: 0.85057 | val_0_mse: 0.598039984703064|  0:00:03s\n","epoch 3  | loss: 0.77181 | val_0_mse: 0.1569499969482422|  0:00:04s\n","epoch 4  | loss: 0.80167 | val_0_mse: 0.05956000089645386|  0:00:05s\n","epoch 5  | loss: 0.37073 | val_0_mse: 0.05319000035524368|  0:00:07s\n","epoch 6  | loss: 0.17077 | val_0_mse: 0.024159999564290047|  0:00:08s\n","epoch 7  | loss: 0.09696 | val_0_mse: 0.10791999846696854|  0:00:09s\n","epoch 8  | loss: 0.14618 | val_0_mse: 0.009080000221729279|  0:00:10s\n","epoch 9  | loss: 0.10123 | val_0_mse: 0.004730000160634518|  0:00:11s\n","epoch 10 | loss: 0.04186 | val_0_mse: 0.0047900001518428326|  0:00:12s\n","epoch 11 | loss: 0.01708 | val_0_mse: 0.002319999970495701|  0:00:14s\n","epoch 12 | loss: 0.00462 | val_0_mse: 0.000750000006519258|  0:00:15s\n","epoch 13 | loss: 0.00253 | val_0_mse: 0.0005499999970197678|  0:00:16s\n","epoch 14 | loss: 0.00144 | val_0_mse: 0.0003699999942909926|  0:00:17s\n","epoch 15 | loss: 0.00102 | val_0_mse: 0.00018000000272877514|  0:00:18s\n","epoch 16 | loss: 0.00074 | val_0_mse: 5.999999848427251e-05|  0:00:19s\n","epoch 17 | loss: 0.00067 | val_0_mse: 5.999999848427251e-05|  0:00:21s\n","epoch 18 | loss: 0.0007  | val_0_mse: 0.00011000000085914508|  0:00:22s\n","epoch 19 | loss: 0.00061 | val_0_mse: 9.999999747378752e-05|  0:00:23s\n","epoch 20 | loss: 0.00054 | val_0_mse: 5.999999848427251e-05|  0:00:24s\n","epoch 21 | loss: 0.00049 | val_0_mse: 4.999999873689376e-05|  0:00:25s\n","epoch 22 | loss: 0.0005  | val_0_mse: 2.9999999242136255e-05|  0:00:27s\n","epoch 23 | loss: 0.00044 | val_0_mse: 1.9999999494757503e-05|  0:00:28s\n","epoch 24 | loss: 0.00041 | val_0_mse: 2.9999999242136255e-05|  0:00:29s\n","epoch 25 | loss: 0.0004  | val_0_mse: 2.9999999242136255e-05|  0:00:30s\n","epoch 26 | loss: 0.00037 | val_0_mse: 1.9999999494757503e-05|  0:00:31s\n","epoch 27 | loss: 0.00035 | val_0_mse: 1.9999999494757503e-05|  0:00:32s\n","epoch 28 | loss: 0.00034 | val_0_mse: 1.9999999494757503e-05|  0:00:34s\n","epoch 29 | loss: 0.00033 | val_0_mse: 1.9999999494757503e-05|  0:00:35s\n","epoch 30 | loss: 0.00031 | val_0_mse: 1.9999999494757503e-05|  0:00:36s\n","epoch 31 | loss: 0.00029 | val_0_mse: 9.999999747378752e-06|  0:00:37s\n","epoch 32 | loss: 0.00029 | val_0_mse: 9.999999747378752e-06|  0:00:38s\n","epoch 33 | loss: 0.00028 | val_0_mse: 9.999999747378752e-06|  0:00:40s\n","epoch 34 | loss: 0.00027 | val_0_mse: 9.999999747378752e-06|  0:00:41s\n","epoch 35 | loss: 0.00027 | val_0_mse: 9.999999747378752e-06|  0:00:42s\n","epoch 36 | loss: 0.00027 | val_0_mse: 9.999999747378752e-06|  0:00:43s\n","epoch 37 | loss: 0.00027 | val_0_mse: 9.999999747378752e-06|  0:00:44s\n","epoch 38 | loss: 0.00026 | val_0_mse: 9.999999747378752e-06|  0:00:45s\n","epoch 39 | loss: 0.00026 | val_0_mse: 9.999999747378752e-06|  0:00:46s\n","epoch 40 | loss: 0.00026 | val_0_mse: 9.999999747378752e-06|  0:00:48s\n","epoch 41 | loss: 0.00026 | val_0_mse: 9.999999747378752e-06|  0:00:49s\n","epoch 42 | loss: 0.00026 | val_0_mse: 9.999999747378752e-06|  0:00:50s\n","epoch 43 | loss: 0.00026 | val_0_mse: 9.999999747378752e-06|  0:00:51s\n","epoch 44 | loss: 0.00025 | val_0_mse: 9.999999747378752e-06|  0:00:52s\n","epoch 45 | loss: 0.00025 | val_0_mse: 9.999999747378752e-06|  0:00:53s\n","epoch 46 | loss: 0.00025 | val_0_mse: 9.999999747378752e-06|  0:00:55s\n","epoch 47 | loss: 0.00025 | val_0_mse: 9.999999747378752e-06|  0:00:56s\n","epoch 48 | loss: 0.00025 | val_0_mse: 9.999999747378752e-06|  0:00:57s\n","epoch 49 | loss: 0.00025 | val_0_mse: 0.0     |  0:00:58s\n","epoch 50 | loss: 0.00025 | val_0_mse: 0.0     |  0:00:59s\n","epoch 51 | loss: 0.00025 | val_0_mse: 9.999999747378752e-06|  0:01:00s\n","epoch 52 | loss: 0.00026 | val_0_mse: 9.999999747378752e-06|  0:01:02s\n","epoch 53 | loss: 0.00026 | val_0_mse: 9.999999747378752e-06|  0:01:03s\n","epoch 54 | loss: 0.00026 | val_0_mse: 9.999999747378752e-06|  0:01:04s\n","epoch 55 | loss: 0.00026 | val_0_mse: 9.999999747378752e-06|  0:01:05s\n","epoch 56 | loss: 0.00026 | val_0_mse: 0.0     |  0:01:06s\n","epoch 57 | loss: 0.00026 | val_0_mse: 9.999999747378752e-06|  0:01:07s\n","epoch 58 | loss: 0.00026 | val_0_mse: 9.999999747378752e-06|  0:01:08s\n","epoch 59 | loss: 0.00026 | val_0_mse: 0.0     |  0:01:10s\n","epoch 60 | loss: 0.00027 | val_0_mse: 9.999999747378752e-06|  0:01:11s\n","epoch 61 | loss: 0.00027 | val_0_mse: 0.0     |  0:01:12s\n","epoch 62 | loss: 0.00027 | val_0_mse: 9.999999747378752e-06|  0:01:13s\n","epoch 63 | loss: 0.00027 | val_0_mse: 0.0     |  0:01:15s\n","epoch 64 | loss: 0.00026 | val_0_mse: 0.0     |  0:01:16s\n","epoch 65 | loss: 0.00026 | val_0_mse: 0.0     |  0:01:17s\n","epoch 66 | loss: 0.00025 | val_0_mse: 0.0     |  0:01:18s\n","epoch 67 | loss: 0.00025 | val_0_mse: 0.0     |  0:01:19s\n","epoch 68 | loss: 0.00025 | val_0_mse: 0.0     |  0:01:20s\n","epoch 69 | loss: 0.00025 | val_0_mse: 0.0     |  0:01:22s\n","epoch 70 | loss: 0.00024 | val_0_mse: 0.0     |  0:01:23s\n","epoch 71 | loss: 0.00025 | val_0_mse: 0.0     |  0:01:24s\n","epoch 72 | loss: 0.00025 | val_0_mse: 0.0     |  0:01:25s\n","epoch 73 | loss: 0.00024 | val_0_mse: 0.0     |  0:01:26s\n","epoch 74 | loss: 0.00024 | val_0_mse: 0.0     |  0:01:27s\n","epoch 75 | loss: 0.00024 | val_0_mse: 0.0     |  0:01:28s\n","epoch 76 | loss: 0.00024 | val_0_mse: 0.0     |  0:01:30s\n","epoch 77 | loss: 0.00023 | val_0_mse: 0.0     |  0:01:31s\n","epoch 78 | loss: 0.00023 | val_0_mse: 0.0     |  0:01:32s\n","epoch 79 | loss: 0.00023 | val_0_mse: 0.0     |  0:01:33s\n","epoch 80 | loss: 0.00023 | val_0_mse: 0.0     |  0:01:34s\n","epoch 81 | loss: 0.00023 | val_0_mse: 0.0     |  0:01:36s\n","epoch 82 | loss: 0.00023 | val_0_mse: 0.0     |  0:01:37s\n","epoch 83 | loss: 0.00023 | val_0_mse: 0.0     |  0:01:38s\n","epoch 84 | loss: 0.00023 | val_0_mse: 0.0     |  0:01:39s\n","epoch 85 | loss: 0.00023 | val_0_mse: 0.0     |  0:01:40s\n","epoch 86 | loss: 0.00023 | val_0_mse: 0.0     |  0:01:41s\n","epoch 87 | loss: 0.00023 | val_0_mse: 0.0     |  0:01:43s\n","epoch 88 | loss: 0.00023 | val_0_mse: 0.0     |  0:01:44s\n","epoch 89 | loss: 0.00023 | val_0_mse: 0.0     |  0:01:45s\n","epoch 90 | loss: 0.00023 | val_0_mse: 0.0     |  0:01:46s\n","epoch 91 | loss: 0.00023 | val_0_mse: 0.0     |  0:01:47s\n","epoch 92 | loss: 0.00022 | val_0_mse: 0.0     |  0:01:48s\n","epoch 93 | loss: 0.00021 | val_0_mse: 0.0     |  0:01:50s\n","epoch 94 | loss: 0.0002  | val_0_mse: 0.0     |  0:01:51s\n","epoch 95 | loss: 0.0002  | val_0_mse: 0.0     |  0:01:52s\n","epoch 96 | loss: 0.00019 | val_0_mse: 0.0     |  0:01:53s\n","epoch 97 | loss: 0.00019 | val_0_mse: 0.0     |  0:01:54s\n","epoch 98 | loss: 0.0002  | val_0_mse: 0.0     |  0:01:55s\n","epoch 99 | loss: 0.0002  | val_0_mse: 0.0     |  0:01:57s\n","Stop training because you reached max_epochs = 100 with best_epoch = 92 and best_val_0_mse = 0.0\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 09:25:46,207] Trial 54 finished with value: 8.602443699601281e-07 and parameters: {'n_d': 30, 'n_steps': 7, 'gamma': 1.6151719665781994, 'n_independent': 4, 'n_shared': 3, 'momentum': 0.301776386131968}. Best is trial 20 with value: 1.2763081258526654e-07.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 2.15296 | val_0_mse: 1.0203100442886353|  0:00:01s\n","epoch 1  | loss: 0.54278 | val_0_mse: 1.0534000396728516|  0:00:02s\n","epoch 2  | loss: 0.27225 | val_0_mse: 0.4084399938583374|  0:00:03s\n","epoch 3  | loss: 0.177   | val_0_mse: 0.04535999894142151|  0:00:04s\n","epoch 4  | loss: 0.11092 | val_0_mse: 0.03260999917984009|  0:00:05s\n","epoch 5  | loss: 0.23628 | val_0_mse: 0.12246000021696091|  0:00:06s\n","epoch 6  | loss: 0.20883 | val_0_mse: 0.06072999909520149|  0:00:07s\n","epoch 7  | loss: 0.13079 | val_0_mse: 0.009569999761879444|  0:00:08s\n","epoch 8  | loss: 0.04881 | val_0_mse: 0.004579999949783087|  0:00:09s\n","epoch 9  | loss: 0.00679 | val_0_mse: 0.0009599999757483602|  0:00:10s\n","epoch 10 | loss: 0.00286 | val_0_mse: 0.0006099999882280827|  0:00:11s\n","epoch 11 | loss: 0.00146 | val_0_mse: 0.0003499999875202775|  0:00:12s\n","epoch 12 | loss: 0.00102 | val_0_mse: 0.00018000000272877514|  0:00:14s\n","epoch 13 | loss: 0.00074 | val_0_mse: 5.999999848427251e-05|  0:00:15s\n","epoch 14 | loss: 0.00062 | val_0_mse: 7.999999797903001e-05|  0:00:16s\n","epoch 15 | loss: 0.00051 | val_0_mse: 3.9999998989515007e-05|  0:00:17s\n","epoch 16 | loss: 0.00043 | val_0_mse: 3.9999998989515007e-05|  0:00:18s\n","epoch 17 | loss: 0.00037 | val_0_mse: 1.9999999494757503e-05|  0:00:19s\n","epoch 18 | loss: 0.00033 | val_0_mse: 9.999999747378752e-06|  0:00:20s\n","epoch 19 | loss: 0.00032 | val_0_mse: 9.999999747378752e-06|  0:00:21s\n","epoch 20 | loss: 0.0003  | val_0_mse: 9.999999747378752e-06|  0:00:22s\n","epoch 21 | loss: 0.00029 | val_0_mse: 9.999999747378752e-06|  0:00:23s\n","epoch 22 | loss: 0.00027 | val_0_mse: 9.999999747378752e-06|  0:00:24s\n","epoch 23 | loss: 0.00027 | val_0_mse: 9.999999747378752e-06|  0:00:25s\n","epoch 24 | loss: 0.00026 | val_0_mse: 9.999999747378752e-06|  0:00:26s\n","epoch 25 | loss: 0.00027 | val_0_mse: 9.999999747378752e-06|  0:00:27s\n","epoch 26 | loss: 0.00026 | val_0_mse: 9.999999747378752e-06|  0:00:28s\n","epoch 27 | loss: 0.00026 | val_0_mse: 0.0     |  0:00:29s\n","epoch 28 | loss: 0.00026 | val_0_mse: 0.0     |  0:00:30s\n","epoch 29 | loss: 0.00026 | val_0_mse: 0.0     |  0:00:31s\n","epoch 30 | loss: 0.00025 | val_0_mse: 9.999999747378752e-06|  0:00:32s\n","epoch 31 | loss: 0.00024 | val_0_mse: 0.0     |  0:00:33s\n","epoch 32 | loss: 0.00024 | val_0_mse: 0.0     |  0:00:34s\n","epoch 33 | loss: 0.00023 | val_0_mse: 0.0     |  0:00:35s\n","epoch 34 | loss: 0.00023 | val_0_mse: 0.0     |  0:00:36s\n","epoch 35 | loss: 0.00022 | val_0_mse: 0.0     |  0:00:37s\n","epoch 36 | loss: 0.00021 | val_0_mse: 0.0     |  0:00:39s\n","epoch 37 | loss: 0.00021 | val_0_mse: 0.0     |  0:00:40s\n","epoch 38 | loss: 0.0002  | val_0_mse: 0.0     |  0:00:41s\n","epoch 39 | loss: 0.0002  | val_0_mse: 0.0     |  0:00:42s\n","epoch 40 | loss: 0.0002  | val_0_mse: 0.0     |  0:00:43s\n","epoch 41 | loss: 0.00022 | val_0_mse: 9.999999747378752e-06|  0:00:44s\n","epoch 42 | loss: 0.00024 | val_0_mse: 9.999999747378752e-06|  0:00:45s\n","epoch 43 | loss: 0.00023 | val_0_mse: 9.999999747378752e-06|  0:00:46s\n","epoch 44 | loss: 0.00022 | val_0_mse: 9.999999747378752e-06|  0:00:47s\n","epoch 45 | loss: 0.00021 | val_0_mse: 0.0     |  0:00:48s\n","epoch 46 | loss: 0.00021 | val_0_mse: 0.0     |  0:00:49s\n","epoch 47 | loss: 0.00021 | val_0_mse: 0.0     |  0:00:50s\n","epoch 48 | loss: 0.00021 | val_0_mse: 0.0     |  0:00:51s\n","epoch 49 | loss: 0.0002  | val_0_mse: 0.0     |  0:00:52s\n","epoch 50 | loss: 0.0002  | val_0_mse: 0.0     |  0:00:53s\n","epoch 51 | loss: 0.0002  | val_0_mse: 0.0     |  0:00:54s\n","epoch 52 | loss: 0.0002  | val_0_mse: 0.0     |  0:00:55s\n","epoch 53 | loss: 0.0002  | val_0_mse: 0.0     |  0:00:56s\n","epoch 54 | loss: 0.0002  | val_0_mse: 0.0     |  0:00:57s\n","epoch 55 | loss: 0.00019 | val_0_mse: 0.0     |  0:00:58s\n","epoch 56 | loss: 0.00019 | val_0_mse: 0.0     |  0:00:59s\n","epoch 57 | loss: 0.00019 | val_0_mse: 0.0     |  0:01:00s\n","epoch 58 | loss: 0.00018 | val_0_mse: 0.0     |  0:01:01s\n","epoch 59 | loss: 0.00018 | val_0_mse: 0.0     |  0:01:02s\n","epoch 60 | loss: 0.00018 | val_0_mse: 0.0     |  0:01:03s\n","epoch 61 | loss: 0.00018 | val_0_mse: 0.0     |  0:01:04s\n","epoch 62 | loss: 0.00018 | val_0_mse: 0.0     |  0:01:06s\n","epoch 63 | loss: 0.00018 | val_0_mse: 0.0     |  0:01:07s\n","epoch 64 | loss: 0.00017 | val_0_mse: 0.0     |  0:01:07s\n","epoch 65 | loss: 0.00017 | val_0_mse: 0.0     |  0:01:09s\n","epoch 66 | loss: 0.00017 | val_0_mse: 0.0     |  0:01:10s\n","epoch 67 | loss: 0.00017 | val_0_mse: 0.0     |  0:01:11s\n","epoch 68 | loss: 0.00017 | val_0_mse: 0.0     |  0:01:12s\n","\n","Early stopping occurred at epoch 68 with best_epoch = 58 and best_val_0_mse = 0.0\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 09:26:59,079] Trial 55 finished with value: 3.774935635192378e-07 and parameters: {'n_d': 23, 'n_steps': 7, 'gamma': 1.7399824365441052, 'n_independent': 4, 'n_shared': 2, 'momentum': 0.3349079470094912}. Best is trial 20 with value: 1.2763081258526654e-07.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 4.72442 | val_0_mse: 117.69416809082031|  0:00:01s\n","epoch 1  | loss: 1.96739 | val_0_mse: 17.633529663085938|  0:00:02s\n","epoch 2  | loss: 0.90378 | val_0_mse: 4.4025797843933105|  0:00:03s\n","epoch 3  | loss: 0.61143 | val_0_mse: 0.3463500142097473|  0:00:04s\n","epoch 4  | loss: 0.36957 | val_0_mse: 0.18554000556468964|  0:00:06s\n","epoch 5  | loss: 0.29031 | val_0_mse: 0.1839500069618225|  0:00:07s\n","epoch 6  | loss: 0.19098 | val_0_mse: 0.08677999675273895|  0:00:08s\n","epoch 7  | loss: 0.10583 | val_0_mse: 0.02889999933540821|  0:00:09s\n","epoch 8  | loss: 0.02765 | val_0_mse: 0.009700000286102295|  0:00:11s\n","epoch 9  | loss: 0.01044 | val_0_mse: 0.003120000008493662|  0:00:12s\n","epoch 10 | loss: 0.00401 | val_0_mse: 0.001550000044517219|  0:00:13s\n","epoch 11 | loss: 0.00185 | val_0_mse: 0.0009399999980814755|  0:00:14s\n","epoch 12 | loss: 0.00103 | val_0_mse: 0.00041000000783242285|  0:00:15s\n","epoch 13 | loss: 0.00082 | val_0_mse: 0.00011999999696854502|  0:00:17s\n","epoch 14 | loss: 0.00062 | val_0_mse: 0.0001900000061141327|  0:00:18s\n","epoch 15 | loss: 0.00055 | val_0_mse: 0.00014000000373926014|  0:00:19s\n","epoch 16 | loss: 0.00054 | val_0_mse: 9.999999747378752e-05|  0:00:20s\n","epoch 17 | loss: 0.0005  | val_0_mse: 7.999999797903001e-05|  0:00:21s\n","epoch 18 | loss: 0.0005  | val_0_mse: 0.00011000000085914508|  0:00:23s\n","epoch 19 | loss: 0.00047 | val_0_mse: 0.00015999999595806003|  0:00:24s\n","epoch 20 | loss: 0.00046 | val_0_mse: 9.000000136438757e-05|  0:00:25s\n","epoch 21 | loss: 0.00046 | val_0_mse: 7.000000186963007e-05|  0:00:26s\n","epoch 22 | loss: 0.00044 | val_0_mse: 9.000000136438757e-05|  0:00:28s\n","epoch 23 | loss: 0.00042 | val_0_mse: 5.999999848427251e-05|  0:00:29s\n","epoch 24 | loss: 0.0004  | val_0_mse: 4.999999873689376e-05|  0:00:30s\n","epoch 25 | loss: 0.0004  | val_0_mse: 3.9999998989515007e-05|  0:00:31s\n","epoch 26 | loss: 0.00038 | val_0_mse: 2.9999999242136255e-05|  0:00:32s\n","epoch 27 | loss: 0.00037 | val_0_mse: 3.9999998989515007e-05|  0:00:34s\n","epoch 28 | loss: 0.00036 | val_0_mse: 2.9999999242136255e-05|  0:00:35s\n","epoch 29 | loss: 0.00036 | val_0_mse: 2.9999999242136255e-05|  0:00:36s\n","epoch 30 | loss: 0.00035 | val_0_mse: 2.9999999242136255e-05|  0:00:37s\n","epoch 31 | loss: 0.00034 | val_0_mse: 1.9999999494757503e-05|  0:00:38s\n","epoch 32 | loss: 0.00034 | val_0_mse: 1.9999999494757503e-05|  0:00:40s\n","epoch 33 | loss: 0.00032 | val_0_mse: 1.9999999494757503e-05|  0:00:41s\n","epoch 34 | loss: 0.00032 | val_0_mse: 1.9999999494757503e-05|  0:00:42s\n","epoch 35 | loss: 0.00032 | val_0_mse: 1.9999999494757503e-05|  0:00:43s\n","epoch 36 | loss: 0.00032 | val_0_mse: 1.9999999494757503e-05|  0:00:45s\n","epoch 37 | loss: 0.00031 | val_0_mse: 1.9999999494757503e-05|  0:00:46s\n","epoch 38 | loss: 0.0003  | val_0_mse: 1.9999999494757503e-05|  0:00:47s\n","epoch 39 | loss: 0.00029 | val_0_mse: 1.9999999494757503e-05|  0:00:48s\n","epoch 40 | loss: 0.00028 | val_0_mse: 9.999999747378752e-06|  0:00:49s\n","epoch 41 | loss: 0.00029 | val_0_mse: 9.999999747378752e-06|  0:00:51s\n","epoch 42 | loss: 0.00028 | val_0_mse: 1.9999999494757503e-05|  0:00:52s\n","epoch 43 | loss: 0.00027 | val_0_mse: 9.999999747378752e-06|  0:00:53s\n","epoch 44 | loss: 0.00027 | val_0_mse: 9.999999747378752e-06|  0:00:54s\n","epoch 45 | loss: 0.00027 | val_0_mse: 9.999999747378752e-06|  0:00:56s\n","epoch 46 | loss: 0.00026 | val_0_mse: 9.999999747378752e-06|  0:00:57s\n","epoch 47 | loss: 0.00026 | val_0_mse: 9.999999747378752e-06|  0:00:58s\n","epoch 48 | loss: 0.00026 | val_0_mse: 9.999999747378752e-06|  0:00:59s\n","epoch 49 | loss: 0.00026 | val_0_mse: 9.999999747378752e-06|  0:01:00s\n","epoch 50 | loss: 0.00025 | val_0_mse: 9.999999747378752e-06|  0:01:02s\n","epoch 51 | loss: 0.00025 | val_0_mse: 9.999999747378752e-06|  0:01:03s\n","epoch 52 | loss: 0.00025 | val_0_mse: 9.999999747378752e-06|  0:01:04s\n","epoch 53 | loss: 0.00025 | val_0_mse: 9.999999747378752e-06|  0:01:05s\n","epoch 54 | loss: 0.00024 | val_0_mse: 9.999999747378752e-06|  0:01:07s\n","epoch 55 | loss: 0.00023 | val_0_mse: 9.999999747378752e-06|  0:01:08s\n","epoch 56 | loss: 0.00023 | val_0_mse: 9.999999747378752e-06|  0:01:09s\n","epoch 57 | loss: 0.00023 | val_0_mse: 9.999999747378752e-06|  0:01:10s\n","epoch 58 | loss: 0.00023 | val_0_mse: 9.999999747378752e-06|  0:01:11s\n","epoch 59 | loss: 0.00023 | val_0_mse: 9.999999747378752e-06|  0:01:13s\n","epoch 60 | loss: 0.00022 | val_0_mse: 1.9999999494757503e-05|  0:01:14s\n","epoch 61 | loss: 0.00023 | val_0_mse: 9.999999747378752e-06|  0:01:15s\n","epoch 62 | loss: 0.00022 | val_0_mse: 9.999999747378752e-06|  0:01:16s\n","epoch 63 | loss: 0.00023 | val_0_mse: 1.9999999494757503e-05|  0:01:17s\n","epoch 64 | loss: 0.00022 | val_0_mse: 9.999999747378752e-06|  0:01:19s\n","epoch 65 | loss: 0.00022 | val_0_mse: 9.999999747378752e-06|  0:01:20s\n","epoch 66 | loss: 0.00021 | val_0_mse: 1.9999999494757503e-05|  0:01:21s\n","\n","Early stopping occurred at epoch 66 with best_epoch = 56 and best_val_0_mse = 9.999999747378752e-06\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 09:28:21,187] Trial 56 finished with value: 6.765217676729662e-06 and parameters: {'n_d': 25, 'n_steps': 6, 'gamma': 1.6827930021632038, 'n_independent': 5, 'n_shared': 4, 'momentum': 0.372866958495246}. Best is trial 20 with value: 1.2763081258526654e-07.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 1.34997 | val_0_mse: 0.19585999846458435|  0:00:00s\n","epoch 1  | loss: 0.22096 | val_0_mse: 0.09673000127077103|  0:00:00s\n","epoch 2  | loss: 0.11375 | val_0_mse: 0.033080000430345535|  0:00:01s\n","epoch 3  | loss: 0.07357 | val_0_mse: 0.04667999967932701|  0:00:01s\n","epoch 4  | loss: 0.04934 | val_0_mse: 0.04280000180006027|  0:00:02s\n","epoch 5  | loss: 0.0232  | val_0_mse: 0.02174999937415123|  0:00:02s\n","epoch 6  | loss: 0.01233 | val_0_mse: 0.004100000020116568|  0:00:02s\n","epoch 7  | loss: 0.00611 | val_0_mse: 0.005640000104904175|  0:00:03s\n","epoch 8  | loss: 0.00428 | val_0_mse: 0.0016299999551847577|  0:00:03s\n","epoch 9  | loss: 0.00295 | val_0_mse: 0.0009399999980814755|  0:00:04s\n","epoch 10 | loss: 0.00234 | val_0_mse: 0.0006200000061653554|  0:00:04s\n","epoch 11 | loss: 0.00198 | val_0_mse: 0.0003800000122282654|  0:00:05s\n","epoch 12 | loss: 0.00184 | val_0_mse: 0.00033000000985339284|  0:00:05s\n","epoch 13 | loss: 0.00156 | val_0_mse: 0.0002500000118743628|  0:00:06s\n","epoch 14 | loss: 0.00139 | val_0_mse: 0.0001900000061141327|  0:00:06s\n","epoch 15 | loss: 0.0013  | val_0_mse: 0.00014000000373926014|  0:00:06s\n","epoch 16 | loss: 0.00122 | val_0_mse: 0.00016999999934341758|  0:00:07s\n","epoch 17 | loss: 0.0012  | val_0_mse: 0.00014000000373926014|  0:00:07s\n","epoch 18 | loss: 0.00109 | val_0_mse: 0.0001900000061141327|  0:00:08s\n","epoch 19 | loss: 0.00106 | val_0_mse: 0.00016999999934341758|  0:00:08s\n","epoch 20 | loss: 0.001   | val_0_mse: 0.00013000000035390258|  0:00:08s\n","epoch 21 | loss: 0.00093 | val_0_mse: 0.00011999999696854502|  0:00:09s\n","epoch 22 | loss: 0.00088 | val_0_mse: 0.00011000000085914508|  0:00:09s\n","epoch 23 | loss: 0.00085 | val_0_mse: 0.00011000000085914508|  0:00:10s\n","epoch 24 | loss: 0.00082 | val_0_mse: 9.000000136438757e-05|  0:00:10s\n","epoch 25 | loss: 0.0008  | val_0_mse: 9.000000136438757e-05|  0:00:11s\n","epoch 26 | loss: 0.00075 | val_0_mse: 7.000000186963007e-05|  0:00:11s\n","epoch 27 | loss: 0.00074 | val_0_mse: 4.999999873689376e-05|  0:00:12s\n","epoch 28 | loss: 0.00072 | val_0_mse: 5.999999848427251e-05|  0:00:12s\n","epoch 29 | loss: 0.00072 | val_0_mse: 4.999999873689376e-05|  0:00:12s\n","epoch 30 | loss: 0.00068 | val_0_mse: 3.9999998989515007e-05|  0:00:13s\n","epoch 31 | loss: 0.00067 | val_0_mse: 4.999999873689376e-05|  0:00:13s\n","epoch 32 | loss: 0.00067 | val_0_mse: 4.999999873689376e-05|  0:00:14s\n","epoch 33 | loss: 0.00069 | val_0_mse: 5.999999848427251e-05|  0:00:14s\n","epoch 34 | loss: 0.00067 | val_0_mse: 4.999999873689376e-05|  0:00:15s\n","epoch 35 | loss: 0.00066 | val_0_mse: 4.999999873689376e-05|  0:00:15s\n","epoch 36 | loss: 0.00065 | val_0_mse: 2.9999999242136255e-05|  0:00:15s\n","epoch 37 | loss: 0.00064 | val_0_mse: 3.9999998989515007e-05|  0:00:16s\n","epoch 38 | loss: 0.00062 | val_0_mse: 3.9999998989515007e-05|  0:00:16s\n","epoch 39 | loss: 0.0006  | val_0_mse: 3.9999998989515007e-05|  0:00:17s\n","epoch 40 | loss: 0.00059 | val_0_mse: 2.9999999242136255e-05|  0:00:17s\n","epoch 41 | loss: 0.00058 | val_0_mse: 2.9999999242136255e-05|  0:00:18s\n","epoch 42 | loss: 0.00058 | val_0_mse: 2.9999999242136255e-05|  0:00:18s\n","epoch 43 | loss: 0.00056 | val_0_mse: 1.9999999494757503e-05|  0:00:18s\n","epoch 44 | loss: 0.00054 | val_0_mse: 1.9999999494757503e-05|  0:00:19s\n","epoch 45 | loss: 0.00054 | val_0_mse: 1.9999999494757503e-05|  0:00:19s\n","epoch 46 | loss: 0.00053 | val_0_mse: 1.9999999494757503e-05|  0:00:20s\n","epoch 47 | loss: 0.00052 | val_0_mse: 1.9999999494757503e-05|  0:00:20s\n","epoch 48 | loss: 0.00051 | val_0_mse: 1.9999999494757503e-05|  0:00:21s\n","epoch 49 | loss: 0.00051 | val_0_mse: 1.9999999494757503e-05|  0:00:21s\n","epoch 50 | loss: 0.0005  | val_0_mse: 1.9999999494757503e-05|  0:00:21s\n","epoch 51 | loss: 0.00049 | val_0_mse: 1.9999999494757503e-05|  0:00:22s\n","epoch 52 | loss: 0.00049 | val_0_mse: 9.999999747378752e-06|  0:00:22s\n","epoch 53 | loss: 0.00048 | val_0_mse: 1.9999999494757503e-05|  0:00:23s\n","epoch 54 | loss: 0.00047 | val_0_mse: 9.999999747378752e-06|  0:00:23s\n","epoch 55 | loss: 0.00047 | val_0_mse: 9.999999747378752e-06|  0:00:23s\n","epoch 56 | loss: 0.00047 | val_0_mse: 9.999999747378752e-06|  0:00:24s\n","epoch 57 | loss: 0.00046 | val_0_mse: 9.999999747378752e-06|  0:00:24s\n","epoch 58 | loss: 0.00045 | val_0_mse: 9.999999747378752e-06|  0:00:25s\n","epoch 59 | loss: 0.00044 | val_0_mse: 9.999999747378752e-06|  0:00:25s\n","epoch 60 | loss: 0.00044 | val_0_mse: 9.999999747378752e-06|  0:00:26s\n","epoch 61 | loss: 0.00044 | val_0_mse: 9.999999747378752e-06|  0:00:26s\n","epoch 62 | loss: 0.00043 | val_0_mse: 9.999999747378752e-06|  0:00:26s\n","epoch 63 | loss: 0.00043 | val_0_mse: 9.999999747378752e-06|  0:00:27s\n","epoch 64 | loss: 0.00042 | val_0_mse: 9.999999747378752e-06|  0:00:27s\n","epoch 65 | loss: 0.00042 | val_0_mse: 9.999999747378752e-06|  0:00:28s\n","epoch 66 | loss: 0.00042 | val_0_mse: 9.999999747378752e-06|  0:00:28s\n","epoch 67 | loss: 0.00041 | val_0_mse: 9.999999747378752e-06|  0:00:29s\n","epoch 68 | loss: 0.00041 | val_0_mse: 9.999999747378752e-06|  0:00:29s\n","epoch 69 | loss: 0.0004  | val_0_mse: 9.999999747378752e-06|  0:00:30s\n","epoch 70 | loss: 0.0004  | val_0_mse: 9.999999747378752e-06|  0:00:30s\n","epoch 71 | loss: 0.0004  | val_0_mse: 0.0     |  0:00:31s\n","epoch 72 | loss: 0.0004  | val_0_mse: 0.0     |  0:00:31s\n","epoch 73 | loss: 0.00039 | val_0_mse: 9.999999747378752e-06|  0:00:31s\n","epoch 74 | loss: 0.00039 | val_0_mse: 0.0     |  0:00:32s\n","epoch 75 | loss: 0.00039 | val_0_mse: 0.0     |  0:00:32s\n","epoch 76 | loss: 0.00038 | val_0_mse: 0.0     |  0:00:33s\n","epoch 77 | loss: 0.00038 | val_0_mse: 0.0     |  0:00:33s\n","epoch 78 | loss: 0.00038 | val_0_mse: 0.0     |  0:00:33s\n","epoch 79 | loss: 0.00038 | val_0_mse: 9.999999747378752e-06|  0:00:34s\n","epoch 80 | loss: 0.00037 | val_0_mse: 0.0     |  0:00:34s\n","epoch 81 | loss: 0.00037 | val_0_mse: 0.0     |  0:00:35s\n","epoch 82 | loss: 0.00037 | val_0_mse: 0.0     |  0:00:35s\n","epoch 83 | loss: 0.00037 | val_0_mse: 0.0     |  0:00:36s\n","epoch 84 | loss: 0.00036 | val_0_mse: 0.0     |  0:00:36s\n","epoch 85 | loss: 0.00036 | val_0_mse: 0.0     |  0:00:36s\n","epoch 86 | loss: 0.00036 | val_0_mse: 0.0     |  0:00:37s\n","epoch 87 | loss: 0.00036 | val_0_mse: 0.0     |  0:00:37s\n","epoch 88 | loss: 0.00035 | val_0_mse: 0.0     |  0:00:38s\n","epoch 89 | loss: 0.00035 | val_0_mse: 0.0     |  0:00:38s\n","epoch 90 | loss: 0.00035 | val_0_mse: 0.0     |  0:00:38s\n","epoch 91 | loss: 0.00035 | val_0_mse: 0.0     |  0:00:39s\n","epoch 92 | loss: 0.00034 | val_0_mse: 0.0     |  0:00:39s\n","epoch 93 | loss: 0.00034 | val_0_mse: 0.0     |  0:00:40s\n","epoch 94 | loss: 0.00034 | val_0_mse: 0.0     |  0:00:40s\n","epoch 95 | loss: 0.00033 | val_0_mse: 0.0     |  0:00:41s\n","epoch 96 | loss: 0.00033 | val_0_mse: 0.0     |  0:00:41s\n","epoch 97 | loss: 0.00033 | val_0_mse: 0.0     |  0:00:41s\n","epoch 98 | loss: 0.00033 | val_0_mse: 0.0     |  0:00:42s\n","epoch 99 | loss: 0.00033 | val_0_mse: 0.0     |  0:00:42s\n","Stop training because you reached max_epochs = 100 with best_epoch = 94 and best_val_0_mse = 0.0\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 09:29:04,221] Trial 57 finished with value: 1.3738209645453026e-06 and parameters: {'n_d': 17, 'n_steps': 5, 'gamma': 1.0859869605196435, 'n_independent': 1, 'n_shared': 1, 'momentum': 0.28609996958512357}. Best is trial 20 with value: 1.2763081258526654e-07.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 9.1809  | val_0_mse: 5.238019943237305|  0:00:00s\n","epoch 1  | loss: 1.17072 | val_0_mse: 11.886930465698242|  0:00:01s\n","epoch 2  | loss: 0.77611 | val_0_mse: 0.2879199981689453|  0:00:01s\n","epoch 3  | loss: 0.28381 | val_0_mse: 0.7988899946212769|  0:00:02s\n","epoch 4  | loss: 0.17735 | val_0_mse: 0.10006999969482422|  0:00:03s\n","epoch 5  | loss: 0.10278 | val_0_mse: 0.03010999970138073|  0:00:03s\n","epoch 6  | loss: 0.04814 | val_0_mse: 0.0157299991697073|  0:00:04s\n","epoch 7  | loss: 0.0339  | val_0_mse: 0.015530000440776348|  0:00:05s\n","epoch 8  | loss: 0.0175  | val_0_mse: 0.005200000014156103|  0:00:05s\n","epoch 9  | loss: 0.00906 | val_0_mse: 0.00279000005684793|  0:00:06s\n","epoch 10 | loss: 0.00665 | val_0_mse: 0.0022299999836832285|  0:00:07s\n","epoch 11 | loss: 0.00374 | val_0_mse: 0.0009899999713525176|  0:00:08s\n","epoch 12 | loss: 0.00288 | val_0_mse: 0.0007200000109151006|  0:00:08s\n","epoch 13 | loss: 0.00206 | val_0_mse: 0.0005600000149570405|  0:00:09s\n","epoch 14 | loss: 0.00183 | val_0_mse: 0.00039999998989515007|  0:00:10s\n","epoch 15 | loss: 0.00177 | val_0_mse: 0.0005000000237487257|  0:00:10s\n","epoch 16 | loss: 0.00168 | val_0_mse: 0.0002699999895412475|  0:00:11s\n","epoch 17 | loss: 0.00135 | val_0_mse: 0.0003000000142492354|  0:00:12s\n","epoch 18 | loss: 0.00147 | val_0_mse: 0.00023999999393709004|  0:00:12s\n","epoch 19 | loss: 0.00162 | val_0_mse: 0.0003699999942909926|  0:00:13s\n","epoch 20 | loss: 0.00168 | val_0_mse: 0.00039999998989515007|  0:00:14s\n","epoch 21 | loss: 0.00139 | val_0_mse: 0.0001900000061141327|  0:00:14s\n","epoch 22 | loss: 0.0021  | val_0_mse: 0.0002300000051036477|  0:00:15s\n","epoch 23 | loss: 0.00172 | val_0_mse: 0.0002500000118743628|  0:00:16s\n","epoch 24 | loss: 0.00127 | val_0_mse: 0.0002300000051036477|  0:00:16s\n","epoch 25 | loss: 0.00135 | val_0_mse: 0.0002699999895412475|  0:00:17s\n","epoch 26 | loss: 0.00135 | val_0_mse: 0.00019999999494757503|  0:00:18s\n","epoch 27 | loss: 0.0013  | val_0_mse: 0.0001900000061141327|  0:00:18s\n","epoch 28 | loss: 0.00105 | val_0_mse: 0.00014000000373926014|  0:00:19s\n","epoch 29 | loss: 0.00105 | val_0_mse: 0.00011999999696854502|  0:00:20s\n","epoch 30 | loss: 0.00096 | val_0_mse: 0.0001500000071246177|  0:00:20s\n","epoch 31 | loss: 0.00116 | val_0_mse: 0.00018000000272877514|  0:00:21s\n","epoch 32 | loss: 0.00088 | val_0_mse: 0.00011999999696854502|  0:00:22s\n","epoch 33 | loss: 0.00094 | val_0_mse: 0.00014000000373926014|  0:00:22s\n","epoch 34 | loss: 0.00106 | val_0_mse: 0.00011999999696854502|  0:00:23s\n","epoch 35 | loss: 0.00088 | val_0_mse: 0.00011999999696854502|  0:00:24s\n","epoch 36 | loss: 0.00081 | val_0_mse: 0.00015999999595806003|  0:00:24s\n","epoch 37 | loss: 0.00086 | val_0_mse: 0.00013000000035390258|  0:00:25s\n","epoch 38 | loss: 0.00101 | val_0_mse: 0.00014000000373926014|  0:00:26s\n","epoch 39 | loss: 0.00099 | val_0_mse: 0.00014000000373926014|  0:00:26s\n","epoch 40 | loss: 0.00084 | val_0_mse: 0.00011000000085914508|  0:00:27s\n","epoch 41 | loss: 0.00074 | val_0_mse: 9.000000136438757e-05|  0:00:28s\n","epoch 42 | loss: 0.00084 | val_0_mse: 0.00016999999934341758|  0:00:28s\n","epoch 43 | loss: 0.00076 | val_0_mse: 0.00011000000085914508|  0:00:29s\n","epoch 44 | loss: 0.00074 | val_0_mse: 0.00011000000085914508|  0:00:30s\n","epoch 45 | loss: 0.00066 | val_0_mse: 7.999999797903001e-05|  0:00:30s\n","epoch 46 | loss: 0.00085 | val_0_mse: 0.00011999999696854502|  0:00:31s\n","epoch 47 | loss: 0.00076 | val_0_mse: 0.00011000000085914508|  0:00:32s\n","epoch 48 | loss: 0.00068 | val_0_mse: 9.000000136438757e-05|  0:00:32s\n","epoch 49 | loss: 0.00061 | val_0_mse: 7.000000186963007e-05|  0:00:33s\n","epoch 50 | loss: 0.00067 | val_0_mse: 4.999999873689376e-05|  0:00:34s\n","epoch 51 | loss: 0.00074 | val_0_mse: 7.000000186963007e-05|  0:00:34s\n","epoch 52 | loss: 0.0009  | val_0_mse: 7.000000186963007e-05|  0:00:35s\n","epoch 53 | loss: 0.00085 | val_0_mse: 0.00016999999934341758|  0:00:36s\n","epoch 54 | loss: 0.00091 | val_0_mse: 0.00011999999696854502|  0:00:36s\n","epoch 55 | loss: 0.00073 | val_0_mse: 0.00013000000035390258|  0:00:37s\n","epoch 56 | loss: 0.00083 | val_0_mse: 0.00013000000035390258|  0:00:38s\n","epoch 57 | loss: 0.00085 | val_0_mse: 0.00013000000035390258|  0:00:39s\n","epoch 58 | loss: 0.0007  | val_0_mse: 7.999999797903001e-05|  0:00:39s\n","epoch 59 | loss: 0.00058 | val_0_mse: 5.999999848427251e-05|  0:00:40s\n","epoch 60 | loss: 0.00061 | val_0_mse: 7.000000186963007e-05|  0:00:41s\n","\n","Early stopping occurred at epoch 60 with best_epoch = 50 and best_val_0_mse = 4.999999873689376e-05\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 09:29:45,795] Trial 58 finished with value: 5.302142017171718e-05 and parameters: {'n_d': 44, 'n_steps': 4, 'gamma': 1.8721007103999898, 'n_independent': 3, 'n_shared': 3, 'momentum': 0.3784967073936804}. Best is trial 20 with value: 1.2763081258526654e-07.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 0.98548 | val_0_mse: 15.382309913635254|  0:00:00s\n","epoch 1  | loss: 0.21669 | val_0_mse: 5.380660057067871|  0:00:01s\n","epoch 2  | loss: 0.09496 | val_0_mse: 0.05406999960541725|  0:00:02s\n","epoch 3  | loss: 0.01795 | val_0_mse: 0.02319999970495701|  0:00:02s\n","epoch 4  | loss: 0.00523 | val_0_mse: 0.004259999841451645|  0:00:03s\n","epoch 5  | loss: 0.00291 | val_0_mse: 0.000699999975040555|  0:00:04s\n","epoch 6  | loss: 0.00187 | val_0_mse: 0.0004199999966658652|  0:00:04s\n","epoch 7  | loss: 0.00131 | val_0_mse: 0.00026000000070780516|  0:00:05s\n","epoch 8  | loss: 0.00121 | val_0_mse: 0.00019999999494757503|  0:00:06s\n","epoch 9  | loss: 0.00105 | val_0_mse: 0.00011000000085914508|  0:00:06s\n","epoch 10 | loss: 0.001   | val_0_mse: 0.00011999999696854502|  0:00:07s\n","epoch 11 | loss: 0.00089 | val_0_mse: 5.999999848427251e-05|  0:00:08s\n","epoch 12 | loss: 0.00082 | val_0_mse: 4.999999873689376e-05|  0:00:08s\n","epoch 13 | loss: 0.00078 | val_0_mse: 3.9999998989515007e-05|  0:00:09s\n","epoch 14 | loss: 0.00073 | val_0_mse: 2.9999999242136255e-05|  0:00:10s\n","epoch 15 | loss: 0.00071 | val_0_mse: 3.9999998989515007e-05|  0:00:10s\n","epoch 16 | loss: 0.00067 | val_0_mse: 3.9999998989515007e-05|  0:00:11s\n","epoch 17 | loss: 0.00063 | val_0_mse: 2.9999999242136255e-05|  0:00:12s\n","epoch 18 | loss: 0.00059 | val_0_mse: 2.9999999242136255e-05|  0:00:12s\n","epoch 19 | loss: 0.00058 | val_0_mse: 2.9999999242136255e-05|  0:00:13s\n","epoch 20 | loss: 0.00055 | val_0_mse: 1.9999999494757503e-05|  0:00:14s\n","epoch 21 | loss: 0.00053 | val_0_mse: 1.9999999494757503e-05|  0:00:15s\n","epoch 22 | loss: 0.00054 | val_0_mse: 1.9999999494757503e-05|  0:00:15s\n","epoch 23 | loss: 0.00052 | val_0_mse: 1.9999999494757503e-05|  0:00:16s\n","epoch 24 | loss: 0.0005  | val_0_mse: 9.999999747378752e-06|  0:00:17s\n","epoch 25 | loss: 0.00048 | val_0_mse: 9.999999747378752e-06|  0:00:17s\n","epoch 26 | loss: 0.00047 | val_0_mse: 9.999999747378752e-06|  0:00:18s\n","epoch 27 | loss: 0.00046 | val_0_mse: 9.999999747378752e-06|  0:00:19s\n","epoch 28 | loss: 0.00046 | val_0_mse: 9.999999747378752e-06|  0:00:19s\n","epoch 29 | loss: 0.00045 | val_0_mse: 9.999999747378752e-06|  0:00:20s\n","epoch 30 | loss: 0.00045 | val_0_mse: 9.999999747378752e-06|  0:00:20s\n","epoch 31 | loss: 0.00044 | val_0_mse: 9.999999747378752e-06|  0:00:21s\n","epoch 32 | loss: 0.00043 | val_0_mse: 9.999999747378752e-06|  0:00:22s\n","epoch 33 | loss: 0.00042 | val_0_mse: 1.9999999494757503e-05|  0:00:22s\n","epoch 34 | loss: 0.00041 | val_0_mse: 9.999999747378752e-06|  0:00:23s\n","epoch 35 | loss: 0.00041 | val_0_mse: 9.999999747378752e-06|  0:00:24s\n","epoch 36 | loss: 0.0004  | val_0_mse: 1.9999999494757503e-05|  0:00:25s\n","epoch 37 | loss: 0.00039 | val_0_mse: 1.9999999494757503e-05|  0:00:25s\n","\n","Early stopping occurred at epoch 37 with best_epoch = 27 and best_val_0_mse = 9.999999747378752e-06\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 09:30:12,031] Trial 59 finished with value: 1.2233272173034493e-05 and parameters: {'n_d': 28, 'n_steps': 3, 'gamma': 1.9535757991955396, 'n_independent': 5, 'n_shared': 3, 'momentum': 0.2663463950496964}. Best is trial 20 with value: 1.2763081258526654e-07.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 8.76375 | val_0_mse: 34.90414810180664|  0:00:01s\n","epoch 1  | loss: 3.56448 | val_0_mse: 9.920639991760254|  0:00:02s\n","epoch 2  | loss: 2.29124 | val_0_mse: 1.0600600242614746|  0:00:04s\n","epoch 3  | loss: 7.52412 | val_0_mse: 13.148730278015137|  0:00:05s\n","epoch 4  | loss: 4.08149 | val_0_mse: 0.2589600086212158|  0:00:07s\n","epoch 5  | loss: 3.97174 | val_0_mse: 0.2488500028848648|  0:00:08s\n","epoch 6  | loss: 1.53318 | val_0_mse: 0.26787999272346497|  0:00:10s\n","epoch 7  | loss: 0.64801 | val_0_mse: 0.3300899863243103|  0:00:11s\n","epoch 8  | loss: 1.71099 | val_0_mse: 0.09099999815225601|  0:00:12s\n","epoch 9  | loss: 1.26333 | val_0_mse: 0.06846000254154205|  0:00:14s\n","epoch 10 | loss: 0.47532 | val_0_mse: 0.20524999499320984|  0:00:15s\n","epoch 11 | loss: 0.22711 | val_0_mse: 0.04190000146627426|  0:00:17s\n","epoch 12 | loss: 0.08254 | val_0_mse: 0.01498000044375658|  0:00:18s\n","epoch 13 | loss: 0.01715 | val_0_mse: 0.0033199999015778303|  0:00:19s\n","epoch 14 | loss: 0.01082 | val_0_mse: 0.0020600000862032175|  0:00:21s\n","epoch 15 | loss: 0.00445 | val_0_mse: 0.0007600000244565308|  0:00:22s\n","epoch 16 | loss: 0.00216 | val_0_mse: 0.0003100000030826777|  0:00:24s\n","epoch 17 | loss: 0.00107 | val_0_mse: 0.00026000000070780516|  0:00:25s\n","epoch 18 | loss: 0.00069 | val_0_mse: 0.00014000000373926014|  0:00:27s\n","epoch 19 | loss: 0.00049 | val_0_mse: 0.00011000000085914508|  0:00:28s\n","epoch 20 | loss: 0.0004  | val_0_mse: 0.00011999999696854502|  0:00:30s\n","epoch 21 | loss: 0.00037 | val_0_mse: 7.999999797903001e-05|  0:00:31s\n","epoch 22 | loss: 0.00035 | val_0_mse: 5.999999848427251e-05|  0:00:32s\n","epoch 23 | loss: 0.00033 | val_0_mse: 5.999999848427251e-05|  0:00:34s\n","epoch 24 | loss: 0.00033 | val_0_mse: 3.9999998989515007e-05|  0:00:35s\n","epoch 25 | loss: 0.00029 | val_0_mse: 4.999999873689376e-05|  0:00:37s\n","epoch 26 | loss: 0.00033 | val_0_mse: 7.999999797903001e-05|  0:00:38s\n","epoch 27 | loss: 0.00034 | val_0_mse: 5.999999848427251e-05|  0:00:39s\n","epoch 28 | loss: 0.00032 | val_0_mse: 7.000000186963007e-05|  0:00:41s\n","epoch 29 | loss: 0.00029 | val_0_mse: 7.999999797903001e-05|  0:00:42s\n","epoch 30 | loss: 0.00031 | val_0_mse: 5.999999848427251e-05|  0:00:44s\n","epoch 31 | loss: 0.00031 | val_0_mse: 7.000000186963007e-05|  0:00:45s\n","epoch 32 | loss: 0.0003  | val_0_mse: 5.999999848427251e-05|  0:00:47s\n","epoch 33 | loss: 0.0003  | val_0_mse: 4.999999873689376e-05|  0:00:48s\n","epoch 34 | loss: 0.00032 | val_0_mse: 4.999999873689376e-05|  0:00:49s\n","\n","Early stopping occurred at epoch 34 with best_epoch = 24 and best_val_0_mse = 3.9999998989515007e-05\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 09:31:02,658] Trial 60 finished with value: 3.744293644558638e-05 and parameters: {'n_d': 48, 'n_steps': 8, 'gamma': 1.7609183058019366, 'n_independent': 4, 'n_shared': 4, 'momentum': 0.1675551070943452}. Best is trial 20 with value: 1.2763081258526654e-07.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 9.91647 | val_0_mse: 23.116819381713867|  0:00:01s\n","epoch 1  | loss: 4.8152  | val_0_mse: 29.202159881591797|  0:00:02s\n","epoch 2  | loss: 4.16998 | val_0_mse: 7.815499782562256|  0:00:03s\n","epoch 3  | loss: 3.3042  | val_0_mse: 1.315790057182312|  0:00:04s\n","epoch 4  | loss: 1.53425 | val_0_mse: 0.25273001194000244|  0:00:05s\n","epoch 5  | loss: 1.02051 | val_0_mse: 0.2761799991130829|  0:00:07s\n","epoch 6  | loss: 0.47931 | val_0_mse: 0.06261999905109406|  0:00:08s\n","epoch 7  | loss: 0.29434 | val_0_mse: 0.15658999979496002|  0:00:09s\n","epoch 8  | loss: 0.15467 | val_0_mse: 0.032829999923706055|  0:00:10s\n","epoch 9  | loss: 0.10834 | val_0_mse: 0.01840999908745289|  0:00:11s\n","epoch 10 | loss: 0.10165 | val_0_mse: 0.08511000126600266|  0:00:12s\n","epoch 11 | loss: 0.07054 | val_0_mse: 0.005200000014156103|  0:00:14s\n","epoch 12 | loss: 0.01561 | val_0_mse: 0.002360000042244792|  0:00:15s\n","epoch 13 | loss: 0.00832 | val_0_mse: 0.0027000000700354576|  0:00:16s\n","epoch 14 | loss: 0.00526 | val_0_mse: 0.0013000000035390258|  0:00:17s\n","epoch 15 | loss: 0.00359 | val_0_mse: 0.0005200000014156103|  0:00:18s\n","epoch 16 | loss: 0.00255 | val_0_mse: 0.0005200000014156103|  0:00:19s\n","epoch 17 | loss: 0.00198 | val_0_mse: 0.0005099999834783375|  0:00:20s\n","epoch 18 | loss: 0.00183 | val_0_mse: 0.0004900000058114529|  0:00:22s\n","epoch 19 | loss: 0.00171 | val_0_mse: 0.0003699999942909926|  0:00:23s\n","epoch 20 | loss: 0.00153 | val_0_mse: 0.00039999998989515007|  0:00:24s\n","epoch 21 | loss: 0.00151 | val_0_mse: 0.00015999999595806003|  0:00:25s\n","epoch 22 | loss: 0.00145 | val_0_mse: 0.0003600000054575503|  0:00:26s\n","epoch 23 | loss: 0.00177 | val_0_mse: 0.00046999999904073775|  0:00:27s\n","epoch 24 | loss: 0.002   | val_0_mse: 0.0004900000058114529|  0:00:28s\n","epoch 25 | loss: 0.00148 | val_0_mse: 0.0002099999983329326|  0:00:30s\n","epoch 26 | loss: 0.00122 | val_0_mse: 0.00022000000171829015|  0:00:31s\n","epoch 27 | loss: 0.00127 | val_0_mse: 0.00023999999393709004|  0:00:32s\n","epoch 28 | loss: 0.00136 | val_0_mse: 0.0002099999983329326|  0:00:33s\n","epoch 29 | loss: 0.00117 | val_0_mse: 0.00013000000035390258|  0:00:34s\n","epoch 30 | loss: 0.00102 | val_0_mse: 0.00011000000085914508|  0:00:35s\n","epoch 31 | loss: 0.00082 | val_0_mse: 0.00011000000085914508|  0:00:36s\n","epoch 32 | loss: 0.00092 | val_0_mse: 0.0002800000074785203|  0:00:37s\n","epoch 33 | loss: 0.00072 | val_0_mse: 9.999999747378752e-05|  0:00:39s\n","epoch 34 | loss: 0.00062 | val_0_mse: 0.00013000000035390258|  0:00:40s\n","epoch 35 | loss: 0.00058 | val_0_mse: 0.00014000000373926014|  0:00:41s\n","epoch 36 | loss: 0.00064 | val_0_mse: 4.999999873689376e-05|  0:00:42s\n","epoch 37 | loss: 0.0005  | val_0_mse: 4.999999873689376e-05|  0:00:43s\n","epoch 38 | loss: 0.00044 | val_0_mse: 5.999999848427251e-05|  0:00:44s\n","epoch 39 | loss: 0.00037 | val_0_mse: 4.999999873689376e-05|  0:00:46s\n","epoch 40 | loss: 0.00036 | val_0_mse: 4.999999873689376e-05|  0:00:47s\n","epoch 41 | loss: 0.00036 | val_0_mse: 5.999999848427251e-05|  0:00:48s\n","epoch 42 | loss: 0.00039 | val_0_mse: 3.9999998989515007e-05|  0:00:49s\n","epoch 43 | loss: 0.00043 | val_0_mse: 9.999999747378752e-05|  0:00:50s\n","epoch 44 | loss: 0.00052 | val_0_mse: 0.0002099999983329326|  0:00:51s\n","epoch 45 | loss: 0.00062 | val_0_mse: 9.000000136438757e-05|  0:00:52s\n","epoch 46 | loss: 0.00051 | val_0_mse: 7.999999797903001e-05|  0:00:54s\n","epoch 47 | loss: 0.00041 | val_0_mse: 3.9999998989515007e-05|  0:00:55s\n","epoch 48 | loss: 0.00043 | val_0_mse: 0.00013000000035390258|  0:00:56s\n","epoch 49 | loss: 0.00041 | val_0_mse: 0.00018000000272877514|  0:00:57s\n","epoch 50 | loss: 0.0004  | val_0_mse: 7.999999797903001e-05|  0:00:58s\n","epoch 51 | loss: 0.00035 | val_0_mse: 3.9999998989515007e-05|  0:00:59s\n","epoch 52 | loss: 0.00029 | val_0_mse: 4.999999873689376e-05|  0:01:00s\n","\n","Early stopping occurred at epoch 52 with best_epoch = 42 and best_val_0_mse = 3.9999998989515007e-05\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 09:32:04,139] Trial 61 finished with value: 3.647603080025874e-05 and parameters: {'n_d': 52, 'n_steps': 7, 'gamma': 1.9105968350856914, 'n_independent': 3, 'n_shared': 4, 'momentum': 0.1924806176397487}. Best is trial 20 with value: 1.2763081258526654e-07.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 4.63493 | val_0_mse: 27.360279083251953|  0:00:01s\n","epoch 1  | loss: 2.23943 | val_0_mse: 2.4009599685668945|  0:00:02s\n","epoch 2  | loss: 1.87138 | val_0_mse: 22.91436004638672|  0:00:03s\n","epoch 3  | loss: 2.01741 | val_0_mse: 3.4381799697875977|  0:00:04s\n","epoch 4  | loss: 0.68249 | val_0_mse: 2.9859399795532227|  0:00:05s\n","epoch 5  | loss: 0.9604  | val_0_mse: 1.450160026550293|  0:00:06s\n","epoch 6  | loss: 0.72843 | val_0_mse: 0.053679998964071274|  0:00:07s\n","epoch 7  | loss: 0.37081 | val_0_mse: 0.08456999808549881|  0:00:08s\n","epoch 8  | loss: 0.94444 | val_0_mse: 0.038839999586343765|  0:00:09s\n","epoch 9  | loss: 0.28408 | val_0_mse: 0.008860000409185886|  0:00:10s\n","epoch 10 | loss: 0.22208 | val_0_mse: 0.06852000206708908|  0:00:11s\n","epoch 11 | loss: 0.08585 | val_0_mse: 0.0028200000524520874|  0:00:12s\n","epoch 12 | loss: 0.02712 | val_0_mse: 0.002859999891370535|  0:00:13s\n","epoch 13 | loss: 0.00648 | val_0_mse: 0.001550000044517219|  0:00:14s\n","epoch 14 | loss: 0.00318 | val_0_mse: 0.0013200000394135714|  0:00:15s\n","epoch 15 | loss: 0.00206 | val_0_mse: 0.0007099999929778278|  0:00:16s\n","epoch 16 | loss: 0.00138 | val_0_mse: 0.0002800000074785203|  0:00:17s\n","epoch 17 | loss: 0.0011  | val_0_mse: 0.0001500000071246177|  0:00:18s\n","epoch 18 | loss: 0.00096 | val_0_mse: 0.00014000000373926014|  0:00:19s\n","epoch 19 | loss: 0.00083 | val_0_mse: 0.00011999999696854502|  0:00:20s\n","epoch 20 | loss: 0.00065 | val_0_mse: 9.000000136438757e-05|  0:00:21s\n","epoch 21 | loss: 0.00066 | val_0_mse: 3.9999998989515007e-05|  0:00:22s\n","epoch 22 | loss: 0.0006  | val_0_mse: 7.000000186963007e-05|  0:00:23s\n","epoch 23 | loss: 0.00057 | val_0_mse: 4.999999873689376e-05|  0:00:24s\n","epoch 24 | loss: 0.00047 | val_0_mse: 3.9999998989515007e-05|  0:00:25s\n","epoch 25 | loss: 0.00038 | val_0_mse: 3.9999998989515007e-05|  0:00:26s\n","epoch 26 | loss: 0.00035 | val_0_mse: 1.9999999494757503e-05|  0:00:27s\n","epoch 27 | loss: 0.00032 | val_0_mse: 1.9999999494757503e-05|  0:00:28s\n","epoch 28 | loss: 0.00031 | val_0_mse: 9.999999747378752e-06|  0:00:29s\n","epoch 29 | loss: 0.00032 | val_0_mse: 9.999999747378752e-06|  0:00:30s\n","epoch 30 | loss: 0.00033 | val_0_mse: 9.999999747378752e-06|  0:00:31s\n","epoch 31 | loss: 0.00031 | val_0_mse: 9.999999747378752e-06|  0:00:32s\n","epoch 32 | loss: 0.00033 | val_0_mse: 9.999999747378752e-06|  0:00:33s\n","epoch 33 | loss: 0.00034 | val_0_mse: 9.999999747378752e-06|  0:00:34s\n","epoch 34 | loss: 0.00033 | val_0_mse: 9.999999747378752e-06|  0:00:35s\n","epoch 35 | loss: 0.0003  | val_0_mse: 9.999999747378752e-06|  0:00:36s\n","epoch 36 | loss: 0.00031 | val_0_mse: 9.999999747378752e-06|  0:00:37s\n","epoch 37 | loss: 0.0003  | val_0_mse: 0.0     |  0:00:38s\n","epoch 38 | loss: 0.00028 | val_0_mse: 0.0     |  0:00:39s\n","epoch 39 | loss: 0.00028 | val_0_mse: 0.0     |  0:00:40s\n","epoch 40 | loss: 0.00027 | val_0_mse: 0.0     |  0:00:41s\n","epoch 41 | loss: 0.00026 | val_0_mse: 0.0     |  0:00:42s\n","epoch 42 | loss: 0.00027 | val_0_mse: 0.0     |  0:00:43s\n","epoch 43 | loss: 0.00026 | val_0_mse: 0.0     |  0:00:45s\n","epoch 44 | loss: 0.00025 | val_0_mse: 0.0     |  0:00:46s\n","epoch 45 | loss: 0.00024 | val_0_mse: 0.0     |  0:00:47s\n","epoch 46 | loss: 0.00025 | val_0_mse: 0.0     |  0:00:48s\n","epoch 47 | loss: 0.00024 | val_0_mse: 0.0     |  0:00:49s\n","epoch 48 | loss: 0.00025 | val_0_mse: 0.0     |  0:00:50s\n","epoch 49 | loss: 0.00024 | val_0_mse: 0.0     |  0:00:51s\n","epoch 50 | loss: 0.00025 | val_0_mse: 0.0     |  0:00:52s\n","epoch 51 | loss: 0.00025 | val_0_mse: 0.0     |  0:00:53s\n","epoch 52 | loss: 0.00025 | val_0_mse: 0.0     |  0:00:54s\n","epoch 53 | loss: 0.00025 | val_0_mse: 0.0     |  0:00:55s\n","epoch 54 | loss: 0.00024 | val_0_mse: 0.0     |  0:00:56s\n","epoch 55 | loss: 0.00024 | val_0_mse: 0.0     |  0:00:57s\n","epoch 56 | loss: 0.00024 | val_0_mse: 0.0     |  0:00:58s\n","epoch 57 | loss: 0.00023 | val_0_mse: 0.0     |  0:00:59s\n","epoch 58 | loss: 0.00022 | val_0_mse: 0.0     |  0:01:00s\n","epoch 59 | loss: 0.00022 | val_0_mse: 0.0     |  0:01:01s\n","epoch 60 | loss: 0.00021 | val_0_mse: 0.0     |  0:01:02s\n","epoch 61 | loss: 0.00021 | val_0_mse: 0.0     |  0:01:03s\n","epoch 62 | loss: 0.00021 | val_0_mse: 0.0     |  0:01:04s\n","epoch 63 | loss: 0.00021 | val_0_mse: 0.0     |  0:01:05s\n","epoch 64 | loss: 0.00021 | val_0_mse: 0.0     |  0:01:06s\n","epoch 65 | loss: 0.00022 | val_0_mse: 0.0     |  0:01:07s\n","epoch 66 | loss: 0.00021 | val_0_mse: 0.0     |  0:01:08s\n","epoch 67 | loss: 0.0002  | val_0_mse: 0.0     |  0:01:09s\n","epoch 68 | loss: 0.0002  | val_0_mse: 0.0     |  0:01:10s\n","epoch 69 | loss: 0.0002  | val_0_mse: 0.0     |  0:01:11s\n","epoch 70 | loss: 0.00021 | val_0_mse: 0.0     |  0:01:12s\n","epoch 71 | loss: 0.0002  | val_0_mse: 0.0     |  0:01:13s\n","epoch 72 | loss: 0.0002  | val_0_mse: 0.0     |  0:01:14s\n","epoch 73 | loss: 0.00044 | val_0_mse: 0.0002300000051036477|  0:01:15s\n","epoch 74 | loss: 0.00149 | val_0_mse: 9.999999747378752e-06|  0:01:16s\n","\n","Early stopping occurred at epoch 74 with best_epoch = 64 and best_val_0_mse = 0.0\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 09:33:21,244] Trial 62 finished with value: 1.9038962761896983e-07 and parameters: {'n_d': 48, 'n_steps': 7, 'gamma': 1.9108136843476595, 'n_independent': 1, 'n_shared': 5, 'momentum': 0.1459436805933024}. Best is trial 20 with value: 1.2763081258526654e-07.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 9.10835 | val_0_mse: 6.340640068054199|  0:00:01s\n","epoch 1  | loss: 9.22867 | val_0_mse: 0.8639900088310242|  0:00:02s\n","epoch 2  | loss: 4.2624  | val_0_mse: 0.9021599888801575|  0:00:03s\n","epoch 3  | loss: 2.33384 | val_0_mse: 0.34731000661849976|  0:00:04s\n","epoch 4  | loss: 1.35046 | val_0_mse: 1.0527600049972534|  0:00:05s\n","epoch 5  | loss: 1.6171  | val_0_mse: 0.3939799964427948|  0:00:06s\n","epoch 6  | loss: 0.3386  | val_0_mse: 0.08974000066518784|  0:00:07s\n","epoch 7  | loss: 0.29984 | val_0_mse: 0.1344199925661087|  0:00:08s\n","epoch 8  | loss: 0.18948 | val_0_mse: 0.013489999808371067|  0:00:09s\n","epoch 9  | loss: 0.08397 | val_0_mse: 0.01655000075697899|  0:00:10s\n","epoch 10 | loss: 0.06381 | val_0_mse: 0.006339999847114086|  0:00:11s\n","epoch 11 | loss: 0.0311  | val_0_mse: 0.005350000225007534|  0:00:12s\n","epoch 12 | loss: 0.0289  | val_0_mse: 0.0026199999265372753|  0:00:13s\n","epoch 13 | loss: 0.02671 | val_0_mse: 0.0040699997916817665|  0:00:14s\n","epoch 14 | loss: 0.00829 | val_0_mse: 0.0017800000496208668|  0:00:15s\n","epoch 15 | loss: 0.00414 | val_0_mse: 0.000859999970998615|  0:00:16s\n","epoch 16 | loss: 0.00313 | val_0_mse: 0.0007800000021234155|  0:00:17s\n","epoch 17 | loss: 0.00235 | val_0_mse: 0.0009899999713525176|  0:00:18s\n","epoch 18 | loss: 0.00187 | val_0_mse: 0.0008099999977275729|  0:00:19s\n","epoch 19 | loss: 0.00152 | val_0_mse: 0.0002300000051036477|  0:00:20s\n","epoch 20 | loss: 0.00137 | val_0_mse: 0.00026000000070780516|  0:00:21s\n","epoch 21 | loss: 0.0013  | val_0_mse: 0.0001900000061141327|  0:00:22s\n","epoch 22 | loss: 0.00109 | val_0_mse: 0.0001900000061141327|  0:00:23s\n","epoch 23 | loss: 0.00098 | val_0_mse: 0.00015999999595806003|  0:00:24s\n","epoch 24 | loss: 0.00084 | val_0_mse: 0.00018000000272877514|  0:00:25s\n","epoch 25 | loss: 0.00088 | val_0_mse: 0.00013000000035390258|  0:00:26s\n","epoch 26 | loss: 0.0008  | val_0_mse: 9.999999747378752e-05|  0:00:27s\n","epoch 27 | loss: 0.00068 | val_0_mse: 0.00014000000373926014|  0:00:28s\n","epoch 28 | loss: 0.0007  | val_0_mse: 0.00015999999595806003|  0:00:29s\n","epoch 29 | loss: 0.00066 | val_0_mse: 9.999999747378752e-05|  0:00:30s\n","epoch 30 | loss: 0.00065 | val_0_mse: 9.999999747378752e-05|  0:00:31s\n","epoch 31 | loss: 0.00061 | val_0_mse: 0.00019999999494757503|  0:00:32s\n","epoch 32 | loss: 0.00058 | val_0_mse: 9.000000136438757e-05|  0:00:33s\n","epoch 33 | loss: 0.00051 | val_0_mse: 9.999999747378752e-05|  0:00:34s\n","epoch 34 | loss: 0.00048 | val_0_mse: 7.000000186963007e-05|  0:00:35s\n","epoch 35 | loss: 0.00049 | val_0_mse: 7.000000186963007e-05|  0:00:36s\n","epoch 36 | loss: 0.00051 | val_0_mse: 9.999999747378752e-05|  0:00:37s\n","epoch 37 | loss: 0.00049 | val_0_mse: 0.00014000000373926014|  0:00:38s\n","epoch 38 | loss: 0.00045 | val_0_mse: 0.0002099999983329326|  0:00:39s\n","epoch 39 | loss: 0.00048 | val_0_mse: 0.00016999999934341758|  0:00:40s\n","epoch 40 | loss: 0.00055 | val_0_mse: 0.00018000000272877514|  0:00:41s\n","epoch 41 | loss: 0.00049 | val_0_mse: 0.00018000000272877514|  0:00:42s\n","epoch 42 | loss: 0.00064 | val_0_mse: 0.0002099999983329326|  0:00:43s\n","epoch 43 | loss: 0.00054 | val_0_mse: 0.0002099999983329326|  0:00:44s\n","epoch 44 | loss: 0.00059 | val_0_mse: 0.0002800000074785203|  0:00:45s\n","\n","Early stopping occurred at epoch 44 with best_epoch = 34 and best_val_0_mse = 7.000000186963007e-05\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 09:34:07,329] Trial 63 finished with value: 7.145066047087312e-05 and parameters: {'n_d': 60, 'n_steps': 7, 'gamma': 1.8506467724711786, 'n_independent': 1, 'n_shared': 5, 'momentum': 0.1401470672329468}. Best is trial 20 with value: 1.2763081258526654e-07.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 5.35988 | val_0_mse: 5.522799968719482|  0:00:00s\n","epoch 1  | loss: 1.02303 | val_0_mse: 0.5364900231361389|  0:00:01s\n","epoch 2  | loss: 0.56086 | val_0_mse: 1.0201900005340576|  0:00:02s\n","epoch 3  | loss: 1.78683 | val_0_mse: 0.9509400129318237|  0:00:02s\n","epoch 4  | loss: 0.51037 | val_0_mse: 0.17936000227928162|  0:00:03s\n","epoch 5  | loss: 0.49591 | val_0_mse: 0.07777000218629837|  0:00:04s\n","epoch 6  | loss: 0.14691 | val_0_mse: 0.06289999932050705|  0:00:04s\n","epoch 7  | loss: 0.06721 | val_0_mse: 0.01948999986052513|  0:00:05s\n","epoch 8  | loss: 0.05278 | val_0_mse: 0.02387000061571598|  0:00:06s\n","epoch 9  | loss: 0.05959 | val_0_mse: 0.008829999715089798|  0:00:06s\n","epoch 10 | loss: 0.04248 | val_0_mse: 0.012269999831914902|  0:00:07s\n","epoch 11 | loss: 0.01695 | val_0_mse: 0.003710000077262521|  0:00:08s\n","epoch 12 | loss: 0.01115 | val_0_mse: 0.003759999992325902|  0:00:08s\n","epoch 13 | loss: 0.00815 | val_0_mse: 0.0015399999683722854|  0:00:09s\n","epoch 14 | loss: 0.0053  | val_0_mse: 0.0014700000174343586|  0:00:10s\n","epoch 15 | loss: 0.00344 | val_0_mse: 0.0009899999713525176|  0:00:11s\n","epoch 16 | loss: 0.00289 | val_0_mse: 0.0008399999933317304|  0:00:11s\n","epoch 17 | loss: 0.00222 | val_0_mse: 0.0005000000237487257|  0:00:12s\n","epoch 18 | loss: 0.00215 | val_0_mse: 0.00044999999227002263|  0:00:13s\n","epoch 19 | loss: 0.00275 | val_0_mse: 0.0005799999926239252|  0:00:13s\n","epoch 20 | loss: 0.00226 | val_0_mse: 0.0005000000237487257|  0:00:14s\n","epoch 21 | loss: 0.00177 | val_0_mse: 0.0002699999895412475|  0:00:15s\n","epoch 22 | loss: 0.00134 | val_0_mse: 0.0002300000051036477|  0:00:16s\n","epoch 23 | loss: 0.00112 | val_0_mse: 0.00019999999494757503|  0:00:16s\n","epoch 24 | loss: 0.00098 | val_0_mse: 0.0001900000061141327|  0:00:17s\n","epoch 25 | loss: 0.00105 | val_0_mse: 0.00023999999393709004|  0:00:18s\n","epoch 26 | loss: 0.00101 | val_0_mse: 0.00015999999595806003|  0:00:18s\n","epoch 27 | loss: 0.00094 | val_0_mse: 0.00014000000373926014|  0:00:19s\n","epoch 28 | loss: 0.0008  | val_0_mse: 9.000000136438757e-05|  0:00:20s\n","epoch 29 | loss: 0.00078 | val_0_mse: 0.00011999999696854502|  0:00:20s\n","epoch 30 | loss: 0.00081 | val_0_mse: 7.000000186963007e-05|  0:00:21s\n","epoch 31 | loss: 0.00065 | val_0_mse: 9.999999747378752e-05|  0:00:22s\n","epoch 32 | loss: 0.00062 | val_0_mse: 9.999999747378752e-05|  0:00:22s\n","epoch 33 | loss: 0.00054 | val_0_mse: 5.999999848427251e-05|  0:00:23s\n","epoch 34 | loss: 0.00051 | val_0_mse: 5.999999848427251e-05|  0:00:24s\n","epoch 35 | loss: 0.00043 | val_0_mse: 5.999999848427251e-05|  0:00:25s\n","epoch 36 | loss: 0.00039 | val_0_mse: 4.999999873689376e-05|  0:00:25s\n","epoch 37 | loss: 0.00038 | val_0_mse: 4.999999873689376e-05|  0:00:26s\n","epoch 38 | loss: 0.00033 | val_0_mse: 2.9999999242136255e-05|  0:00:27s\n","epoch 39 | loss: 0.00036 | val_0_mse: 3.9999998989515007e-05|  0:00:27s\n","epoch 40 | loss: 0.00033 | val_0_mse: 2.9999999242136255e-05|  0:00:28s\n","epoch 41 | loss: 0.00031 | val_0_mse: 2.9999999242136255e-05|  0:00:29s\n","epoch 42 | loss: 0.0003  | val_0_mse: 2.9999999242136255e-05|  0:00:29s\n","epoch 43 | loss: 0.0003  | val_0_mse: 1.9999999494757503e-05|  0:00:30s\n","epoch 44 | loss: 0.00029 | val_0_mse: 1.9999999494757503e-05|  0:00:31s\n","epoch 45 | loss: 0.00028 | val_0_mse: 1.9999999494757503e-05|  0:00:31s\n","epoch 46 | loss: 0.00026 | val_0_mse: 1.9999999494757503e-05|  0:00:32s\n","epoch 47 | loss: 0.00026 | val_0_mse: 1.9999999494757503e-05|  0:00:33s\n","epoch 48 | loss: 0.00026 | val_0_mse: 1.9999999494757503e-05|  0:00:33s\n","epoch 49 | loss: 0.00025 | val_0_mse: 1.9999999494757503e-05|  0:00:34s\n","epoch 50 | loss: 0.00026 | val_0_mse: 9.999999747378752e-06|  0:00:35s\n","epoch 51 | loss: 0.00025 | val_0_mse: 9.999999747378752e-06|  0:00:36s\n","epoch 52 | loss: 0.00024 | val_0_mse: 1.9999999494757503e-05|  0:00:36s\n","epoch 53 | loss: 0.00025 | val_0_mse: 1.9999999494757503e-05|  0:00:37s\n","epoch 54 | loss: 0.00024 | val_0_mse: 9.999999747378752e-06|  0:00:38s\n","epoch 55 | loss: 0.00023 | val_0_mse: 9.999999747378752e-06|  0:00:38s\n","epoch 56 | loss: 0.00022 | val_0_mse: 9.999999747378752e-06|  0:00:39s\n","epoch 57 | loss: 0.00022 | val_0_mse: 9.999999747378752e-06|  0:00:40s\n","epoch 58 | loss: 0.00022 | val_0_mse: 9.999999747378752e-06|  0:00:41s\n","epoch 59 | loss: 0.00022 | val_0_mse: 1.9999999494757503e-05|  0:00:41s\n","epoch 60 | loss: 0.00021 | val_0_mse: 9.999999747378752e-06|  0:00:42s\n","epoch 61 | loss: 0.00021 | val_0_mse: 9.999999747378752e-06|  0:00:43s\n","epoch 62 | loss: 0.0002  | val_0_mse: 9.999999747378752e-06|  0:00:43s\n","epoch 63 | loss: 0.0002  | val_0_mse: 9.999999747378752e-06|  0:00:44s\n","epoch 64 | loss: 0.0002  | val_0_mse: 9.999999747378752e-06|  0:00:45s\n","epoch 65 | loss: 0.0002  | val_0_mse: 9.999999747378752e-06|  0:00:45s\n","epoch 66 | loss: 0.0002  | val_0_mse: 9.999999747378752e-06|  0:00:46s\n","epoch 67 | loss: 0.0002  | val_0_mse: 1.9999999494757503e-05|  0:00:47s\n","epoch 68 | loss: 0.0002  | val_0_mse: 9.999999747378752e-06|  0:00:48s\n","epoch 69 | loss: 0.0002  | val_0_mse: 9.999999747378752e-06|  0:00:48s\n","epoch 70 | loss: 0.0002  | val_0_mse: 9.999999747378752e-06|  0:00:49s\n","epoch 71 | loss: 0.00019 | val_0_mse: 9.999999747378752e-06|  0:00:50s\n","epoch 72 | loss: 0.00019 | val_0_mse: 9.999999747378752e-06|  0:00:50s\n","epoch 73 | loss: 0.00019 | val_0_mse: 9.999999747378752e-06|  0:00:51s\n","epoch 74 | loss: 0.00019 | val_0_mse: 9.999999747378752e-06|  0:00:52s\n","epoch 75 | loss: 0.00018 | val_0_mse: 9.999999747378752e-06|  0:00:52s\n","epoch 76 | loss: 0.00018 | val_0_mse: 9.999999747378752e-06|  0:00:53s\n","epoch 77 | loss: 0.00019 | val_0_mse: 9.999999747378752e-06|  0:00:54s\n","epoch 78 | loss: 0.00018 | val_0_mse: 9.999999747378752e-06|  0:00:54s\n","epoch 79 | loss: 0.00018 | val_0_mse: 9.999999747378752e-06|  0:00:55s\n","epoch 80 | loss: 0.00018 | val_0_mse: 9.999999747378752e-06|  0:00:56s\n","epoch 81 | loss: 0.00018 | val_0_mse: 9.999999747378752e-06|  0:00:56s\n","epoch 82 | loss: 0.00018 | val_0_mse: 9.999999747378752e-06|  0:00:57s\n","epoch 83 | loss: 0.00018 | val_0_mse: 9.999999747378752e-06|  0:00:58s\n","epoch 84 | loss: 0.00018 | val_0_mse: 9.999999747378752e-06|  0:00:58s\n","epoch 85 | loss: 0.00018 | val_0_mse: 9.999999747378752e-06|  0:00:59s\n","epoch 86 | loss: 0.00018 | val_0_mse: 9.999999747378752e-06|  0:01:00s\n","epoch 87 | loss: 0.00018 | val_0_mse: 9.999999747378752e-06|  0:01:01s\n","epoch 88 | loss: 0.00017 | val_0_mse: 9.999999747378752e-06|  0:01:01s\n","epoch 89 | loss: 0.00018 | val_0_mse: 9.999999747378752e-06|  0:01:02s\n","epoch 90 | loss: 0.00018 | val_0_mse: 9.999999747378752e-06|  0:01:03s\n","epoch 91 | loss: 0.00018 | val_0_mse: 0.0     |  0:01:03s\n","epoch 92 | loss: 0.00018 | val_0_mse: 9.999999747378752e-06|  0:01:04s\n","epoch 93 | loss: 0.00019 | val_0_mse: 9.999999747378752e-06|  0:01:05s\n","epoch 94 | loss: 0.00018 | val_0_mse: 9.999999747378752e-06|  0:01:05s\n","epoch 95 | loss: 0.00019 | val_0_mse: 9.999999747378752e-06|  0:01:06s\n","epoch 96 | loss: 0.00019 | val_0_mse: 9.999999747378752e-06|  0:01:07s\n","epoch 97 | loss: 0.00018 | val_0_mse: 9.999999747378752e-06|  0:01:07s\n","epoch 98 | loss: 0.00018 | val_0_mse: 9.999999747378752e-06|  0:01:08s\n","epoch 99 | loss: 0.00018 | val_0_mse: 9.999999747378752e-06|  0:01:09s\n","Stop training because you reached max_epochs = 100 with best_epoch = 91 and best_val_0_mse = 0.0\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 09:35:17,069] Trial 64 finished with value: 4.101977538084611e-06 and parameters: {'n_d': 40, 'n_steps': 6, 'gamma': 1.8170024164083598, 'n_independent': 1, 'n_shared': 3, 'momentum': 0.1545453365082834}. Best is trial 20 with value: 1.2763081258526654e-07.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 4.93903 | val_0_mse: 9.292510032653809|  0:00:00s\n","epoch 1  | loss: 2.12013 | val_0_mse: 6.91595983505249|  0:00:01s\n","epoch 2  | loss: 0.93467 | val_0_mse: 0.4710400104522705|  0:00:02s\n","epoch 3  | loss: 0.92491 | val_0_mse: 0.602940022945404|  0:00:03s\n","epoch 4  | loss: 1.29251 | val_0_mse: 0.7512099742889404|  0:00:04s\n","epoch 5  | loss: 0.35948 | val_0_mse: 0.12756000459194183|  0:00:04s\n","epoch 6  | loss: 0.23869 | val_0_mse: 0.02800999954342842|  0:00:05s\n","epoch 7  | loss: 0.20737 | val_0_mse: 0.05163000151515007|  0:00:06s\n","epoch 8  | loss: 0.16517 | val_0_mse: 0.004519999958574772|  0:00:07s\n","epoch 9  | loss: 0.15844 | val_0_mse: 0.012520000338554382|  0:00:08s\n","epoch 10 | loss: 0.059   | val_0_mse: 0.003019999945536256|  0:00:08s\n","epoch 11 | loss: 0.014   | val_0_mse: 0.0036299999337643385|  0:00:09s\n","epoch 12 | loss: 0.00784 | val_0_mse: 0.0016299999551847577|  0:00:10s\n","epoch 13 | loss: 0.00513 | val_0_mse: 0.0004199999966658652|  0:00:11s\n","epoch 14 | loss: 0.00337 | val_0_mse: 0.00033000000985339284|  0:00:11s\n","epoch 15 | loss: 0.00261 | val_0_mse: 0.0002699999895412475|  0:00:12s\n","epoch 16 | loss: 0.00193 | val_0_mse: 0.00022000000171829015|  0:00:13s\n","epoch 17 | loss: 0.00158 | val_0_mse: 0.0004299999854993075|  0:00:14s\n","epoch 18 | loss: 0.00133 | val_0_mse: 0.00018000000272877514|  0:00:15s\n","epoch 19 | loss: 0.00103 | val_0_mse: 0.0003000000142492354|  0:00:15s\n","epoch 20 | loss: 0.00097 | val_0_mse: 0.00023999999393709004|  0:00:16s\n","epoch 21 | loss: 0.00073 | val_0_mse: 0.0002699999895412475|  0:00:17s\n","epoch 22 | loss: 0.00076 | val_0_mse: 9.000000136438757e-05|  0:00:18s\n","epoch 23 | loss: 0.00071 | val_0_mse: 7.999999797903001e-05|  0:00:19s\n","epoch 24 | loss: 0.00061 | val_0_mse: 9.000000136438757e-05|  0:00:19s\n","epoch 25 | loss: 0.00056 | val_0_mse: 5.999999848427251e-05|  0:00:20s\n","epoch 26 | loss: 0.00056 | val_0_mse: 0.00013000000035390258|  0:00:21s\n","epoch 27 | loss: 0.00051 | val_0_mse: 5.999999848427251e-05|  0:00:22s\n","epoch 28 | loss: 0.00052 | val_0_mse: 0.00016999999934341758|  0:00:22s\n","epoch 29 | loss: 0.00051 | val_0_mse: 0.00011000000085914508|  0:00:23s\n","epoch 30 | loss: 0.00052 | val_0_mse: 5.999999848427251e-05|  0:00:24s\n","epoch 31 | loss: 0.00048 | val_0_mse: 5.999999848427251e-05|  0:00:25s\n","epoch 32 | loss: 0.00046 | val_0_mse: 5.999999848427251e-05|  0:00:26s\n","epoch 33 | loss: 0.00039 | val_0_mse: 3.9999998989515007e-05|  0:00:26s\n","epoch 34 | loss: 0.00041 | val_0_mse: 4.999999873689376e-05|  0:00:27s\n","epoch 35 | loss: 0.00038 | val_0_mse: 4.999999873689376e-05|  0:00:28s\n","epoch 36 | loss: 0.00045 | val_0_mse: 7.000000186963007e-05|  0:00:29s\n","epoch 37 | loss: 0.00053 | val_0_mse: 7.999999797903001e-05|  0:00:29s\n","epoch 38 | loss: 0.00045 | val_0_mse: 5.999999848427251e-05|  0:00:30s\n","epoch 39 | loss: 0.00038 | val_0_mse: 3.9999998989515007e-05|  0:00:31s\n","epoch 40 | loss: 0.00038 | val_0_mse: 3.9999998989515007e-05|  0:00:32s\n","epoch 41 | loss: 0.00036 | val_0_mse: 3.9999998989515007e-05|  0:00:32s\n","epoch 42 | loss: 0.00034 | val_0_mse: 3.9999998989515007e-05|  0:00:33s\n","epoch 43 | loss: 0.00034 | val_0_mse: 3.9999998989515007e-05|  0:00:34s\n","\n","Early stopping occurred at epoch 43 with best_epoch = 33 and best_val_0_mse = 3.9999998989515007e-05\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 09:35:52,157] Trial 65 finished with value: 3.8459202187368646e-05 and parameters: {'n_d': 54, 'n_steps': 7, 'gamma': 1.9469551201926885, 'n_independent': 1, 'n_shared': 3, 'momentum': 0.23669658345754854}. Best is trial 20 with value: 1.2763081258526654e-07.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 6.28961 | val_0_mse: 95.53922271728516|  0:00:01s\n","epoch 1  | loss: 2.76354 | val_0_mse: 3.1256699562072754|  0:00:02s\n","epoch 2  | loss: 1.87132 | val_0_mse: 4.09542989730835|  0:00:03s\n","epoch 3  | loss: 3.96591 | val_0_mse: 6.135149955749512|  0:00:04s\n","epoch 4  | loss: 0.91712 | val_0_mse: 0.6155800223350525|  0:00:05s\n","epoch 5  | loss: 7.27377 | val_0_mse: 15.576129913330078|  0:00:06s\n","epoch 6  | loss: 4.38942 | val_0_mse: 0.1032399982213974|  0:00:07s\n","epoch 7  | loss: 0.3561  | val_0_mse: 0.03590000048279762|  0:00:08s\n","epoch 8  | loss: 0.11077 | val_0_mse: 0.015209999866783619|  0:00:10s\n","epoch 9  | loss: 0.25719 | val_0_mse: 0.03221999853849411|  0:00:11s\n","epoch 10 | loss: 0.26015 | val_0_mse: 0.023499999195337296|  0:00:12s\n","epoch 11 | loss: 0.06422 | val_0_mse: 0.016189999878406525|  0:00:13s\n","epoch 12 | loss: 0.05858 | val_0_mse: 0.0038399999029934406|  0:00:14s\n","epoch 13 | loss: 0.04136 | val_0_mse: 0.001560000004246831|  0:00:15s\n","epoch 14 | loss: 0.00871 | val_0_mse: 0.00044999999227002263|  0:00:16s\n","epoch 15 | loss: 0.00434 | val_0_mse: 0.0004299999854993075|  0:00:18s\n","epoch 16 | loss: 0.00181 | val_0_mse: 0.00013000000035390258|  0:00:19s\n","epoch 17 | loss: 0.00086 | val_0_mse: 0.00011000000085914508|  0:00:20s\n","epoch 18 | loss: 0.00046 | val_0_mse: 2.9999999242136255e-05|  0:00:21s\n","epoch 19 | loss: 0.00033 | val_0_mse: 1.9999999494757503e-05|  0:00:22s\n","epoch 20 | loss: 0.00025 | val_0_mse: 9.999999747378752e-06|  0:00:23s\n","epoch 21 | loss: 0.00022 | val_0_mse: 9.999999747378752e-06|  0:00:24s\n","epoch 22 | loss: 0.00021 | val_0_mse: 9.999999747378752e-06|  0:00:26s\n","epoch 23 | loss: 0.00019 | val_0_mse: 9.999999747378752e-06|  0:00:27s\n","epoch 24 | loss: 0.00019 | val_0_mse: 9.999999747378752e-06|  0:00:28s\n","epoch 25 | loss: 0.00018 | val_0_mse: 9.999999747378752e-06|  0:00:29s\n","epoch 26 | loss: 0.00018 | val_0_mse: 9.999999747378752e-06|  0:00:30s\n","epoch 27 | loss: 0.00018 | val_0_mse: 0.0     |  0:00:31s\n","epoch 28 | loss: 0.00018 | val_0_mse: 0.0     |  0:00:32s\n","epoch 29 | loss: 0.00017 | val_0_mse: 0.0     |  0:00:34s\n","epoch 30 | loss: 0.00017 | val_0_mse: 0.0     |  0:00:35s\n","epoch 31 | loss: 0.00017 | val_0_mse: 0.0     |  0:00:36s\n","epoch 32 | loss: 0.00017 | val_0_mse: 0.0     |  0:00:37s\n","epoch 33 | loss: 0.00016 | val_0_mse: 0.0     |  0:00:38s\n","epoch 34 | loss: 0.00016 | val_0_mse: 0.0     |  0:00:39s\n","epoch 35 | loss: 0.00015 | val_0_mse: 0.0     |  0:00:40s\n","epoch 36 | loss: 0.00015 | val_0_mse: 0.0     |  0:00:42s\n","epoch 37 | loss: 0.00015 | val_0_mse: 0.0     |  0:00:43s\n","epoch 38 | loss: 0.00015 | val_0_mse: 0.0     |  0:00:44s\n","epoch 39 | loss: 0.00014 | val_0_mse: 0.0     |  0:00:45s\n","epoch 40 | loss: 0.00014 | val_0_mse: 0.0     |  0:00:46s\n","epoch 41 | loss: 0.00014 | val_0_mse: 0.0     |  0:00:47s\n","epoch 42 | loss: 0.00015 | val_0_mse: 0.0     |  0:00:48s\n","epoch 43 | loss: 0.00016 | val_0_mse: 0.0     |  0:00:50s\n","epoch 44 | loss: 0.00015 | val_0_mse: 0.0     |  0:00:51s\n","epoch 45 | loss: 0.00015 | val_0_mse: 0.0     |  0:00:52s\n","epoch 46 | loss: 0.00014 | val_0_mse: 0.0     |  0:00:53s\n","epoch 47 | loss: 0.00014 | val_0_mse: 0.0     |  0:00:54s\n","epoch 48 | loss: 0.00014 | val_0_mse: 0.0     |  0:00:55s\n","epoch 49 | loss: 0.00014 | val_0_mse: 0.0     |  0:00:56s\n","epoch 50 | loss: 0.00014 | val_0_mse: 0.0     |  0:00:57s\n","epoch 51 | loss: 0.00014 | val_0_mse: 0.0     |  0:00:59s\n","epoch 52 | loss: 0.00014 | val_0_mse: 0.0     |  0:01:00s\n","epoch 53 | loss: 0.00014 | val_0_mse: 0.0     |  0:01:01s\n","epoch 54 | loss: 0.00015 | val_0_mse: 0.0     |  0:01:02s\n","epoch 55 | loss: 0.00014 | val_0_mse: 0.0     |  0:01:03s\n","\n","Early stopping occurred at epoch 55 with best_epoch = 45 and best_val_0_mse = 0.0\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 09:36:56,506] Trial 66 finished with value: 6.183412324389792e-07 and parameters: {'n_d': 38, 'n_steps': 8, 'gamma': 1.902116063285141, 'n_independent': 1, 'n_shared': 5, 'momentum': 0.11852650412422973}. Best is trial 20 with value: 1.2763081258526654e-07.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 7.46791 | val_0_mse: 2.621579885482788|  0:00:00s\n","epoch 1  | loss: 1.06107 | val_0_mse: 0.20730000734329224|  0:00:01s\n","epoch 2  | loss: 0.63578 | val_0_mse: 0.2713100016117096|  0:00:02s\n","epoch 3  | loss: 0.57583 | val_0_mse: 1.363420009613037|  0:00:03s\n","epoch 4  | loss: 1.14898 | val_0_mse: 0.07236000150442123|  0:00:03s\n","epoch 5  | loss: 0.38874 | val_0_mse: 0.06764999777078629|  0:00:04s\n","epoch 6  | loss: 0.18647 | val_0_mse: 0.19303999841213226|  0:00:05s\n","epoch 7  | loss: 0.07255 | val_0_mse: 0.06404999643564224|  0:00:06s\n","epoch 8  | loss: 0.03167 | val_0_mse: 0.010830000042915344|  0:00:07s\n","epoch 9  | loss: 0.01118 | val_0_mse: 0.007739999797195196|  0:00:07s\n","epoch 10 | loss: 0.00597 | val_0_mse: 0.0035600000992417336|  0:00:08s\n","epoch 11 | loss: 0.00349 | val_0_mse: 0.00279999990016222|  0:00:09s\n","epoch 12 | loss: 0.00209 | val_0_mse: 0.004980000201612711|  0:00:10s\n","epoch 13 | loss: 0.00176 | val_0_mse: 0.0013899999903514981|  0:00:10s\n","epoch 14 | loss: 0.00127 | val_0_mse: 0.00033000000985339284|  0:00:11s\n","epoch 15 | loss: 0.00126 | val_0_mse: 0.00026000000070780516|  0:00:12s\n","epoch 16 | loss: 0.00095 | val_0_mse: 0.00014000000373926014|  0:00:13s\n","epoch 17 | loss: 0.00078 | val_0_mse: 0.00011000000085914508|  0:00:13s\n","epoch 18 | loss: 0.00065 | val_0_mse: 0.00011999999696854502|  0:00:14s\n","epoch 19 | loss: 0.00054 | val_0_mse: 9.999999747378752e-05|  0:00:15s\n","epoch 20 | loss: 0.00054 | val_0_mse: 9.000000136438757e-05|  0:00:16s\n","epoch 21 | loss: 0.00075 | val_0_mse: 0.0003100000030826777|  0:00:17s\n","epoch 22 | loss: 0.00067 | val_0_mse: 0.0002300000051036477|  0:00:17s\n","epoch 23 | loss: 0.00059 | val_0_mse: 0.0004600000102072954|  0:00:18s\n","epoch 24 | loss: 0.00084 | val_0_mse: 0.0004600000102072954|  0:00:19s\n","epoch 25 | loss: 0.0007  | val_0_mse: 0.00019999999494757503|  0:00:20s\n","epoch 26 | loss: 0.00043 | val_0_mse: 0.00015999999595806003|  0:00:20s\n","epoch 27 | loss: 0.00038 | val_0_mse: 0.0001500000071246177|  0:00:21s\n","epoch 28 | loss: 0.00034 | val_0_mse: 9.999999747378752e-05|  0:00:22s\n","epoch 29 | loss: 0.00031 | val_0_mse: 4.999999873689376e-05|  0:00:23s\n","epoch 30 | loss: 0.00031 | val_0_mse: 5.999999848427251e-05|  0:00:24s\n","epoch 31 | loss: 0.00032 | val_0_mse: 3.9999998989515007e-05|  0:00:24s\n","epoch 32 | loss: 0.00029 | val_0_mse: 2.9999999242136255e-05|  0:00:25s\n","epoch 33 | loss: 0.00028 | val_0_mse: 7.999999797903001e-05|  0:00:26s\n","epoch 34 | loss: 0.00027 | val_0_mse: 2.9999999242136255e-05|  0:00:27s\n","epoch 35 | loss: 0.00026 | val_0_mse: 1.9999999494757503e-05|  0:00:27s\n","epoch 36 | loss: 0.00027 | val_0_mse: 4.999999873689376e-05|  0:00:28s\n","epoch 37 | loss: 0.00026 | val_0_mse: 1.9999999494757503e-05|  0:00:29s\n","epoch 38 | loss: 0.00026 | val_0_mse: 2.9999999242136255e-05|  0:00:30s\n","epoch 39 | loss: 0.00024 | val_0_mse: 2.9999999242136255e-05|  0:00:31s\n","epoch 40 | loss: 0.00024 | val_0_mse: 2.9999999242136255e-05|  0:00:31s\n","epoch 41 | loss: 0.00023 | val_0_mse: 1.9999999494757503e-05|  0:00:32s\n","epoch 42 | loss: 0.00022 | val_0_mse: 1.9999999494757503e-05|  0:00:33s\n","epoch 43 | loss: 0.00022 | val_0_mse: 1.9999999494757503e-05|  0:00:34s\n","epoch 44 | loss: 0.00021 | val_0_mse: 1.9999999494757503e-05|  0:00:35s\n","epoch 45 | loss: 0.0002  | val_0_mse: 1.9999999494757503e-05|  0:00:35s\n","epoch 46 | loss: 0.00021 | val_0_mse: 1.9999999494757503e-05|  0:00:36s\n","epoch 47 | loss: 0.0002  | val_0_mse: 9.999999747378752e-06|  0:00:37s\n","epoch 48 | loss: 0.0002  | val_0_mse: 1.9999999494757503e-05|  0:00:38s\n","epoch 49 | loss: 0.0002  | val_0_mse: 2.9999999242136255e-05|  0:00:38s\n","epoch 50 | loss: 0.00021 | val_0_mse: 9.999999747378752e-06|  0:00:39s\n","epoch 51 | loss: 0.0002  | val_0_mse: 1.9999999494757503e-05|  0:00:40s\n","epoch 52 | loss: 0.00019 | val_0_mse: 9.999999747378752e-06|  0:00:41s\n","epoch 53 | loss: 0.00018 | val_0_mse: 9.999999747378752e-06|  0:00:42s\n","epoch 54 | loss: 0.00019 | val_0_mse: 9.999999747378752e-06|  0:00:42s\n","epoch 55 | loss: 0.00018 | val_0_mse: 3.9999998989515007e-05|  0:00:43s\n","epoch 56 | loss: 0.0002  | val_0_mse: 9.999999747378752e-06|  0:00:44s\n","epoch 57 | loss: 0.00019 | val_0_mse: 9.999999747378752e-06|  0:00:45s\n","epoch 58 | loss: 0.00019 | val_0_mse: 1.9999999494757503e-05|  0:00:45s\n","epoch 59 | loss: 0.00018 | val_0_mse: 9.999999747378752e-06|  0:00:46s\n","epoch 60 | loss: 0.00018 | val_0_mse: 9.999999747378752e-06|  0:00:47s\n","epoch 61 | loss: 0.00018 | val_0_mse: 9.999999747378752e-06|  0:00:48s\n","epoch 62 | loss: 0.00017 | val_0_mse: 9.999999747378752e-06|  0:00:48s\n","epoch 63 | loss: 0.00017 | val_0_mse: 9.999999747378752e-06|  0:00:49s\n","epoch 64 | loss: 0.00017 | val_0_mse: 9.999999747378752e-06|  0:00:50s\n","epoch 65 | loss: 0.00016 | val_0_mse: 9.999999747378752e-06|  0:00:51s\n","epoch 66 | loss: 0.00017 | val_0_mse: 9.999999747378752e-06|  0:00:52s\n","epoch 67 | loss: 0.00017 | val_0_mse: 9.999999747378752e-06|  0:00:52s\n","epoch 68 | loss: 0.00016 | val_0_mse: 9.999999747378752e-06|  0:00:53s\n","epoch 69 | loss: 0.00018 | val_0_mse: 9.999999747378752e-06|  0:00:54s\n","epoch 70 | loss: 0.00018 | val_0_mse: 9.999999747378752e-06|  0:00:55s\n","epoch 71 | loss: 0.00019 | val_0_mse: 9.999999747378752e-06|  0:00:56s\n","epoch 72 | loss: 0.0002  | val_0_mse: 2.9999999242136255e-05|  0:00:56s\n","epoch 73 | loss: 0.00018 | val_0_mse: 9.999999747378752e-06|  0:00:57s\n","\n","Early stopping occurred at epoch 73 with best_epoch = 63 and best_val_0_mse = 9.999999747378752e-06\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 09:37:54,525] Trial 67 finished with value: 5.931109171797289e-06 and parameters: {'n_d': 33, 'n_steps': 7, 'gamma': 1.7828055676024082, 'n_independent': 2, 'n_shared': 2, 'momentum': 0.1848112909666487}. Best is trial 20 with value: 1.2763081258526654e-07.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 4.57736 | val_0_mse: 6.5010199546813965|  0:00:00s\n","epoch 1  | loss: 4.2912  | val_0_mse: 0.6350299715995789|  0:00:01s\n","epoch 2  | loss: 1.53467 | val_0_mse: 0.1827400028705597|  0:00:02s\n","epoch 3  | loss: 1.85109 | val_0_mse: 0.21536999940872192|  0:00:02s\n","epoch 4  | loss: 0.4845  | val_0_mse: 0.050609998404979706|  0:00:03s\n","epoch 5  | loss: 0.30538 | val_0_mse: 0.03029000014066696|  0:00:04s\n","epoch 6  | loss: 1.08975 | val_0_mse: 0.01590999960899353|  0:00:05s\n","epoch 7  | loss: 0.26438 | val_0_mse: 0.006870000157505274|  0:00:05s\n","epoch 8  | loss: 0.08759 | val_0_mse: 0.01001999992877245|  0:00:06s\n","epoch 9  | loss: 0.11393 | val_0_mse: 0.016820000484585762|  0:00:07s\n","epoch 10 | loss: 0.05593 | val_0_mse: 0.0020800000056624413|  0:00:07s\n","epoch 11 | loss: 0.02203 | val_0_mse: 0.0008200000156648457|  0:00:08s\n","epoch 12 | loss: 0.01059 | val_0_mse: 0.0012000000569969416|  0:00:09s\n","epoch 13 | loss: 0.00838 | val_0_mse: 0.0003699999942909926|  0:00:09s\n","epoch 14 | loss: 0.00619 | val_0_mse: 0.0005000000237487257|  0:00:10s\n","epoch 15 | loss: 0.00377 | val_0_mse: 0.00022000000171829015|  0:00:11s\n","epoch 16 | loss: 0.00347 | val_0_mse: 0.0003699999942909926|  0:00:11s\n","epoch 17 | loss: 0.00283 | val_0_mse: 0.0002300000051036477|  0:00:12s\n","epoch 18 | loss: 0.00233 | val_0_mse: 0.0002099999983329326|  0:00:13s\n","epoch 19 | loss: 0.00182 | val_0_mse: 0.0001500000071246177|  0:00:14s\n","epoch 20 | loss: 0.00153 | val_0_mse: 9.000000136438757e-05|  0:00:14s\n","epoch 21 | loss: 0.0015  | val_0_mse: 9.000000136438757e-05|  0:00:15s\n","epoch 22 | loss: 0.00179 | val_0_mse: 0.00011000000085914508|  0:00:16s\n","epoch 23 | loss: 0.00157 | val_0_mse: 0.0002899999963119626|  0:00:16s\n","epoch 24 | loss: 0.00167 | val_0_mse: 0.0002800000074785203|  0:00:17s\n","epoch 25 | loss: 0.00145 | val_0_mse: 0.00018000000272877514|  0:00:18s\n","epoch 26 | loss: 0.00124 | val_0_mse: 0.00022000000171829015|  0:00:18s\n","epoch 27 | loss: 0.00117 | val_0_mse: 0.00013000000035390258|  0:00:19s\n","epoch 28 | loss: 0.00116 | val_0_mse: 0.00022000000171829015|  0:00:20s\n","epoch 29 | loss: 0.001   | val_0_mse: 0.00014000000373926014|  0:00:20s\n","epoch 30 | loss: 0.00084 | val_0_mse: 0.00011999999696854502|  0:00:21s\n","epoch 31 | loss: 0.00075 | val_0_mse: 0.00013000000035390258|  0:00:22s\n","\n","Early stopping occurred at epoch 31 with best_epoch = 21 and best_val_0_mse = 9.000000136438757e-05\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 09:38:17,325] Trial 68 finished with value: 8.960777631727979e-05 and parameters: {'n_d': 47, 'n_steps': 6, 'gamma': 1.8615109234278853, 'n_independent': 1, 'n_shared': 3, 'momentum': 0.2220171120579258}. Best is trial 20 with value: 1.2763081258526654e-07.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 5.49219 | val_0_mse: 57.5324592590332|  0:00:00s\n","epoch 1  | loss: 2.31171 | val_0_mse: 11.262760162353516|  0:00:01s\n","epoch 2  | loss: 1.40737 | val_0_mse: 0.09025000035762787|  0:00:02s\n","epoch 3  | loss: 0.57824 | val_0_mse: 0.2195899933576584|  0:00:02s\n","epoch 4  | loss: 0.46761 | val_0_mse: 0.05917000025510788|  0:00:03s\n","epoch 5  | loss: 0.68908 | val_0_mse: 0.2161100059747696|  0:00:04s\n","epoch 6  | loss: 0.49719 | val_0_mse: 0.03742000088095665|  0:00:04s\n","epoch 7  | loss: 0.08642 | val_0_mse: 0.017500000074505806|  0:00:05s\n","epoch 8  | loss: 0.03315 | val_0_mse: 0.006279999855905771|  0:00:06s\n","epoch 9  | loss: 0.01698 | val_0_mse: 0.0037499999161809683|  0:00:06s\n","epoch 10 | loss: 0.02306 | val_0_mse: 0.003000000026077032|  0:00:07s\n","epoch 11 | loss: 0.0129  | val_0_mse: 0.0009399999980814755|  0:00:08s\n","epoch 12 | loss: 0.00675 | val_0_mse: 0.002319999970495701|  0:00:09s\n","epoch 13 | loss: 0.00405 | val_0_mse: 0.0007999999797903001|  0:00:09s\n","epoch 14 | loss: 0.00275 | val_0_mse: 0.0009800000116229057|  0:00:10s\n","epoch 15 | loss: 0.00179 | val_0_mse: 0.0004199999966658652|  0:00:11s\n","epoch 16 | loss: 0.00129 | val_0_mse: 0.0002699999895412475|  0:00:11s\n","epoch 17 | loss: 0.00102 | val_0_mse: 0.00022000000171829015|  0:00:12s\n","epoch 18 | loss: 0.00086 | val_0_mse: 0.0001500000071246177|  0:00:13s\n","epoch 19 | loss: 0.00077 | val_0_mse: 0.00014000000373926014|  0:00:13s\n","epoch 20 | loss: 0.00069 | val_0_mse: 0.0001500000071246177|  0:00:14s\n","epoch 21 | loss: 0.00068 | val_0_mse: 9.000000136438757e-05|  0:00:15s\n","epoch 22 | loss: 0.00068 | val_0_mse: 0.00015999999595806003|  0:00:15s\n","epoch 23 | loss: 0.00066 | val_0_mse: 9.000000136438757e-05|  0:00:16s\n","epoch 24 | loss: 0.00062 | val_0_mse: 0.00013000000035390258|  0:00:17s\n","epoch 25 | loss: 0.00059 | val_0_mse: 0.00011999999696854502|  0:00:17s\n","epoch 26 | loss: 0.00055 | val_0_mse: 0.00013000000035390258|  0:00:18s\n","epoch 27 | loss: 0.00055 | val_0_mse: 0.00011000000085914508|  0:00:19s\n","epoch 28 | loss: 0.0006  | val_0_mse: 0.00015999999595806003|  0:00:19s\n","epoch 29 | loss: 0.00082 | val_0_mse: 0.00026000000070780516|  0:00:20s\n","epoch 30 | loss: 0.00083 | val_0_mse: 0.00014000000373926014|  0:00:21s\n","epoch 31 | loss: 0.00061 | val_0_mse: 0.00011000000085914508|  0:00:21s\n","epoch 32 | loss: 0.00054 | val_0_mse: 7.999999797903001e-05|  0:00:22s\n","epoch 33 | loss: 0.00047 | val_0_mse: 7.000000186963007e-05|  0:00:23s\n","epoch 34 | loss: 0.00049 | val_0_mse: 0.00019999999494757503|  0:00:23s\n","epoch 35 | loss: 0.00047 | val_0_mse: 0.00018000000272877514|  0:00:24s\n","epoch 36 | loss: 0.00044 | val_0_mse: 0.0002099999983329326|  0:00:25s\n","epoch 37 | loss: 0.00049 | val_0_mse: 9.999999747378752e-05|  0:00:25s\n","epoch 38 | loss: 0.00037 | val_0_mse: 4.999999873689376e-05|  0:00:26s\n","epoch 39 | loss: 0.00032 | val_0_mse: 4.999999873689376e-05|  0:00:27s\n","epoch 40 | loss: 0.00036 | val_0_mse: 3.9999998989515007e-05|  0:00:27s\n","epoch 41 | loss: 0.00033 | val_0_mse: 7.000000186963007e-05|  0:00:28s\n","epoch 42 | loss: 0.00029 | val_0_mse: 4.999999873689376e-05|  0:00:29s\n","epoch 43 | loss: 0.00029 | val_0_mse: 7.000000186963007e-05|  0:00:29s\n","epoch 44 | loss: 0.00026 | val_0_mse: 3.9999998989515007e-05|  0:00:30s\n","epoch 45 | loss: 0.00025 | val_0_mse: 3.9999998989515007e-05|  0:00:31s\n","epoch 46 | loss: 0.00024 | val_0_mse: 3.9999998989515007e-05|  0:00:31s\n","epoch 47 | loss: 0.00023 | val_0_mse: 3.9999998989515007e-05|  0:00:32s\n","epoch 48 | loss: 0.00025 | val_0_mse: 4.999999873689376e-05|  0:00:33s\n","epoch 49 | loss: 0.00027 | val_0_mse: 3.9999998989515007e-05|  0:00:33s\n","epoch 50 | loss: 0.00025 | val_0_mse: 2.9999999242136255e-05|  0:00:34s\n","epoch 51 | loss: 0.00023 | val_0_mse: 2.9999999242136255e-05|  0:00:35s\n","epoch 52 | loss: 0.00023 | val_0_mse: 2.9999999242136255e-05|  0:00:35s\n","epoch 53 | loss: 0.00022 | val_0_mse: 1.9999999494757503e-05|  0:00:36s\n","epoch 54 | loss: 0.00021 | val_0_mse: 1.9999999494757503e-05|  0:00:37s\n","epoch 55 | loss: 0.00021 | val_0_mse: 1.9999999494757503e-05|  0:00:37s\n","epoch 56 | loss: 0.00021 | val_0_mse: 1.9999999494757503e-05|  0:00:38s\n","epoch 57 | loss: 0.0002  | val_0_mse: 1.9999999494757503e-05|  0:00:39s\n","epoch 58 | loss: 0.0002  | val_0_mse: 1.9999999494757503e-05|  0:00:40s\n","epoch 59 | loss: 0.00021 | val_0_mse: 1.9999999494757503e-05|  0:00:40s\n","epoch 60 | loss: 0.00021 | val_0_mse: 2.9999999242136255e-05|  0:00:41s\n","epoch 61 | loss: 0.0002  | val_0_mse: 9.999999747378752e-06|  0:00:42s\n","epoch 62 | loss: 0.00019 | val_0_mse: 9.999999747378752e-06|  0:00:42s\n","epoch 63 | loss: 0.00019 | val_0_mse: 9.999999747378752e-06|  0:00:43s\n","epoch 64 | loss: 0.0002  | val_0_mse: 9.999999747378752e-06|  0:00:44s\n","epoch 65 | loss: 0.00019 | val_0_mse: 9.999999747378752e-06|  0:00:44s\n","epoch 66 | loss: 0.00019 | val_0_mse: 9.999999747378752e-06|  0:00:45s\n","epoch 67 | loss: 0.00018 | val_0_mse: 9.999999747378752e-06|  0:00:46s\n","epoch 68 | loss: 0.00019 | val_0_mse: 9.999999747378752e-06|  0:00:46s\n","epoch 69 | loss: 0.00019 | val_0_mse: 1.9999999494757503e-05|  0:00:47s\n","epoch 70 | loss: 0.0002  | val_0_mse: 9.999999747378752e-06|  0:00:48s\n","epoch 71 | loss: 0.00018 | val_0_mse: 9.999999747378752e-06|  0:00:48s\n","epoch 72 | loss: 0.00018 | val_0_mse: 9.999999747378752e-06|  0:00:49s\n","epoch 73 | loss: 0.00017 | val_0_mse: 9.999999747378752e-06|  0:00:50s\n","epoch 74 | loss: 0.00015 | val_0_mse: 9.999999747378752e-06|  0:00:50s\n","epoch 75 | loss: 0.00015 | val_0_mse: 9.999999747378752e-06|  0:00:51s\n","epoch 76 | loss: 0.00014 | val_0_mse: 9.999999747378752e-06|  0:00:52s\n","epoch 77 | loss: 0.00014 | val_0_mse: 0.0     |  0:00:53s\n","epoch 78 | loss: 0.00014 | val_0_mse: 9.999999747378752e-06|  0:00:53s\n","epoch 79 | loss: 0.00014 | val_0_mse: 9.999999747378752e-06|  0:00:54s\n","epoch 80 | loss: 0.00014 | val_0_mse: 0.0     |  0:00:55s\n","epoch 81 | loss: 0.00014 | val_0_mse: 9.999999747378752e-06|  0:00:55s\n","epoch 82 | loss: 0.00014 | val_0_mse: 0.0     |  0:00:56s\n","epoch 83 | loss: 0.00013 | val_0_mse: 0.0     |  0:00:57s\n","epoch 84 | loss: 0.00015 | val_0_mse: 9.999999747378752e-06|  0:00:57s\n","epoch 85 | loss: 0.00014 | val_0_mse: 9.999999747378752e-06|  0:00:58s\n","epoch 86 | loss: 0.00014 | val_0_mse: 0.0     |  0:00:58s\n","epoch 87 | loss: 0.00013 | val_0_mse: 9.999999747378752e-06|  0:00:59s\n","epoch 88 | loss: 0.00014 | val_0_mse: 9.999999747378752e-06|  0:01:00s\n","epoch 89 | loss: 0.00014 | val_0_mse: 0.0     |  0:01:01s\n","epoch 90 | loss: 0.00015 | val_0_mse: 0.0     |  0:01:01s\n","epoch 91 | loss: 0.00016 | val_0_mse: 9.999999747378752e-06|  0:01:02s\n","epoch 92 | loss: 0.00014 | val_0_mse: 0.0     |  0:01:03s\n","epoch 93 | loss: 0.00023 | val_0_mse: 9.999999747378752e-06|  0:01:03s\n","epoch 94 | loss: 0.00017 | val_0_mse: 9.999999747378752e-06|  0:01:04s\n","epoch 95 | loss: 0.00015 | val_0_mse: 2.9999999242136255e-05|  0:01:04s\n","epoch 96 | loss: 0.00017 | val_0_mse: 0.0     |  0:01:05s\n","epoch 97 | loss: 0.00014 | val_0_mse: 0.0     |  0:01:06s\n","epoch 98 | loss: 0.00014 | val_0_mse: 2.9999999242136255e-05|  0:01:06s\n","epoch 99 | loss: 0.00019 | val_0_mse: 2.9999999242136255e-05|  0:01:07s\n","Stop training because you reached max_epochs = 100 with best_epoch = 90 and best_val_0_mse = 0.0\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 09:39:25,278] Trial 69 finished with value: 1.2210037994009326e-06 and parameters: {'n_d': 50, 'n_steps': 7, 'gamma': 1.986691989415293, 'n_independent': 2, 'n_shared': 1, 'momentum': 0.17209549124535828}. Best is trial 20 with value: 1.2763081258526654e-07.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 19.6302 | val_0_mse: 22.069040298461914|  0:00:01s\n","epoch 1  | loss: 3.60884 | val_0_mse: 5.465179920196533|  0:00:01s\n","epoch 2  | loss: 2.30278 | val_0_mse: 9.829930305480957|  0:00:02s\n","epoch 3  | loss: 1.53217 | val_0_mse: 4.806680202484131|  0:00:03s\n","epoch 4  | loss: 1.35052 | val_0_mse: 0.8090000152587891|  0:00:04s\n","epoch 5  | loss: 0.75478 | val_0_mse: 0.37397998571395874|  0:00:05s\n","epoch 6  | loss: 0.85323 | val_0_mse: 0.3927299976348877|  0:00:06s\n","epoch 7  | loss: 0.56782 | val_0_mse: 0.11209999769926071|  0:00:07s\n","epoch 8  | loss: 0.28462 | val_0_mse: 0.11965999752283096|  0:00:07s\n","epoch 9  | loss: 2.07291 | val_0_mse: 0.48183000087738037|  0:00:08s\n","epoch 10 | loss: 0.55056 | val_0_mse: 0.044449999928474426|  0:00:09s\n","epoch 11 | loss: 0.10563 | val_0_mse: 0.04605000093579292|  0:00:10s\n","epoch 12 | loss: 0.30454 | val_0_mse: 0.06550999730825424|  0:00:11s\n","epoch 13 | loss: 0.25514 | val_0_mse: 0.01841999962925911|  0:00:12s\n","epoch 14 | loss: 0.08749 | val_0_mse: 0.004040000028908253|  0:00:13s\n","epoch 15 | loss: 0.01454 | val_0_mse: 0.0019000000320374966|  0:00:13s\n","epoch 16 | loss: 0.00726 | val_0_mse: 0.0004799999878741801|  0:00:14s\n","epoch 17 | loss: 0.00382 | val_0_mse: 0.0006000000284984708|  0:00:15s\n","epoch 18 | loss: 0.00218 | val_0_mse: 0.0003000000142492354|  0:00:16s\n","epoch 19 | loss: 0.00158 | val_0_mse: 0.0002300000051036477|  0:00:17s\n","epoch 20 | loss: 0.0017  | val_0_mse: 0.0002099999983329326|  0:00:18s\n","epoch 21 | loss: 0.00141 | val_0_mse: 0.0001500000071246177|  0:00:19s\n","epoch 22 | loss: 0.00121 | val_0_mse: 0.0001900000061141327|  0:00:19s\n","epoch 23 | loss: 0.00094 | val_0_mse: 0.00018000000272877514|  0:00:20s\n","epoch 24 | loss: 0.00084 | val_0_mse: 0.00016999999934341758|  0:00:21s\n","epoch 25 | loss: 0.00076 | val_0_mse: 0.00011999999696854502|  0:00:22s\n","epoch 26 | loss: 0.00078 | val_0_mse: 0.0002099999983329326|  0:00:23s\n","epoch 27 | loss: 0.0007  | val_0_mse: 9.999999747378752e-05|  0:00:24s\n","epoch 28 | loss: 0.00068 | val_0_mse: 0.0002300000051036477|  0:00:25s\n","epoch 29 | loss: 0.00061 | val_0_mse: 0.00013000000035390258|  0:00:26s\n","epoch 30 | loss: 0.00057 | val_0_mse: 9.000000136438757e-05|  0:00:26s\n","epoch 31 | loss: 0.00054 | val_0_mse: 0.0001900000061141327|  0:00:27s\n","epoch 32 | loss: 0.00051 | val_0_mse: 0.00011999999696854502|  0:00:28s\n","epoch 33 | loss: 0.00053 | val_0_mse: 4.999999873689376e-05|  0:00:29s\n","epoch 34 | loss: 0.00071 | val_0_mse: 0.00016999999934341758|  0:00:30s\n","epoch 35 | loss: 0.00066 | val_0_mse: 0.0001900000061141327|  0:00:31s\n","epoch 36 | loss: 0.00056 | val_0_mse: 0.00014000000373926014|  0:00:32s\n","epoch 37 | loss: 0.00056 | val_0_mse: 0.00015999999595806003|  0:00:32s\n","epoch 38 | loss: 0.00058 | val_0_mse: 0.00016999999934341758|  0:00:33s\n","epoch 39 | loss: 0.00055 | val_0_mse: 0.00023999999393709004|  0:00:34s\n","epoch 40 | loss: 0.00049 | val_0_mse: 0.00016999999934341758|  0:00:35s\n","epoch 41 | loss: 0.00049 | val_0_mse: 0.00014000000373926014|  0:00:36s\n","epoch 42 | loss: 0.00044 | val_0_mse: 0.00013000000035390258|  0:00:37s\n","epoch 43 | loss: 0.0004  | val_0_mse: 0.00013000000035390258|  0:00:38s\n","\n","Early stopping occurred at epoch 43 with best_epoch = 33 and best_val_0_mse = 4.999999873689376e-05\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 09:40:04,031] Trial 70 finished with value: 5.305345985107124e-05 and parameters: {'n_d': 44, 'n_steps': 8, 'gamma': 1.6137575271058358, 'n_independent': 1, 'n_shared': 3, 'momentum': 0.08279093713315808}. Best is trial 20 with value: 1.2763081258526654e-07.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 7.92573 | val_0_mse: 15.18628978729248|  0:00:01s\n","epoch 1  | loss: 3.11088 | val_0_mse: 1.7690199613571167|  0:00:02s\n","epoch 2  | loss: 2.17983 | val_0_mse: 2.48432993888855|  0:00:03s\n","epoch 3  | loss: 2.5565  | val_0_mse: 0.26982998847961426|  0:00:05s\n","epoch 4  | loss: 0.79406 | val_0_mse: 0.6528900265693665|  0:00:06s\n","epoch 5  | loss: 0.42507 | val_0_mse: 0.4107300043106079|  0:00:07s\n","epoch 6  | loss: 0.45096 | val_0_mse: 0.20204000174999237|  0:00:08s\n","epoch 7  | loss: 0.8145  | val_0_mse: 0.3883900046348572|  0:00:10s\n","epoch 8  | loss: 0.35581 | val_0_mse: 0.016019999980926514|  0:00:11s\n","epoch 9  | loss: 0.03169 | val_0_mse: 0.0073899999260902405|  0:00:12s\n","epoch 10 | loss: 0.04355 | val_0_mse: 0.003650000086054206|  0:00:13s\n","epoch 11 | loss: 0.02949 | val_0_mse: 0.004259999841451645|  0:00:15s\n","epoch 12 | loss: 0.01347 | val_0_mse: 0.0010999999940395355|  0:00:16s\n","epoch 13 | loss: 0.00722 | val_0_mse: 0.0006900000153109431|  0:00:17s\n","epoch 14 | loss: 0.00352 | val_0_mse: 0.00019999999494757503|  0:00:18s\n","epoch 15 | loss: 0.00166 | val_0_mse: 0.0001900000061141327|  0:00:20s\n","epoch 16 | loss: 0.00099 | val_0_mse: 0.00011000000085914508|  0:00:21s\n","epoch 17 | loss: 0.00065 | val_0_mse: 9.000000136438757e-05|  0:00:22s\n","epoch 18 | loss: 0.00052 | val_0_mse: 7.000000186963007e-05|  0:00:23s\n","epoch 19 | loss: 0.00041 | val_0_mse: 7.000000186963007e-05|  0:00:25s\n","epoch 20 | loss: 0.00042 | val_0_mse: 4.999999873689376e-05|  0:00:26s\n","epoch 21 | loss: 0.00039 | val_0_mse: 3.9999998989515007e-05|  0:00:27s\n","epoch 22 | loss: 0.00041 | val_0_mse: 3.9999998989515007e-05|  0:00:29s\n","epoch 23 | loss: 0.00042 | val_0_mse: 2.9999999242136255e-05|  0:00:30s\n","epoch 24 | loss: 0.00037 | val_0_mse: 1.9999999494757503e-05|  0:00:31s\n","epoch 25 | loss: 0.00035 | val_0_mse: 1.9999999494757503e-05|  0:00:32s\n","epoch 26 | loss: 0.00032 | val_0_mse: 1.9999999494757503e-05|  0:00:34s\n","epoch 27 | loss: 0.00031 | val_0_mse: 1.9999999494757503e-05|  0:00:35s\n","epoch 28 | loss: 0.0003  | val_0_mse: 1.9999999494757503e-05|  0:00:36s\n","epoch 29 | loss: 0.0003  | val_0_mse: 1.9999999494757503e-05|  0:00:37s\n","epoch 30 | loss: 0.00027 | val_0_mse: 1.9999999494757503e-05|  0:00:39s\n","epoch 31 | loss: 0.00026 | val_0_mse: 9.999999747378752e-06|  0:00:40s\n","epoch 32 | loss: 0.00025 | val_0_mse: 9.999999747378752e-06|  0:00:41s\n","epoch 33 | loss: 0.00025 | val_0_mse: 9.999999747378752e-06|  0:00:42s\n","epoch 34 | loss: 0.00024 | val_0_mse: 9.999999747378752e-06|  0:00:44s\n","epoch 35 | loss: 0.00023 | val_0_mse: 9.999999747378752e-06|  0:00:45s\n","epoch 36 | loss: 0.00023 | val_0_mse: 9.999999747378752e-06|  0:00:46s\n","epoch 37 | loss: 0.00023 | val_0_mse: 9.999999747378752e-06|  0:00:47s\n","epoch 38 | loss: 0.00022 | val_0_mse: 9.999999747378752e-06|  0:00:49s\n","epoch 39 | loss: 0.00021 | val_0_mse: 9.999999747378752e-06|  0:00:50s\n","epoch 40 | loss: 0.00021 | val_0_mse: 0.0     |  0:00:51s\n","epoch 41 | loss: 0.00021 | val_0_mse: 9.999999747378752e-06|  0:00:53s\n","epoch 42 | loss: 0.00021 | val_0_mse: 9.999999747378752e-06|  0:00:54s\n","epoch 43 | loss: 0.00022 | val_0_mse: 9.999999747378752e-06|  0:00:55s\n","epoch 44 | loss: 0.00023 | val_0_mse: 9.999999747378752e-06|  0:00:56s\n","epoch 45 | loss: 0.00023 | val_0_mse: 9.999999747378752e-06|  0:00:58s\n","epoch 46 | loss: 0.00025 | val_0_mse: 2.9999999242136255e-05|  0:00:59s\n","epoch 47 | loss: 0.00031 | val_0_mse: 1.9999999494757503e-05|  0:01:00s\n","epoch 48 | loss: 0.00028 | val_0_mse: 1.9999999494757503e-05|  0:01:01s\n","epoch 49 | loss: 0.00026 | val_0_mse: 9.999999747378752e-06|  0:01:03s\n","epoch 50 | loss: 0.00026 | val_0_mse: 9.999999747378752e-06|  0:01:04s\n","\n","Early stopping occurred at epoch 50 with best_epoch = 40 and best_val_0_mse = 0.0\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 09:41:09,057] Trial 71 finished with value: 3.886956619680859e-06 and parameters: {'n_d': 42, 'n_steps': 7, 'gamma': 1.9366072275402335, 'n_independent': 3, 'n_shared': 5, 'momentum': 0.20381888498180237}. Best is trial 20 with value: 1.2763081258526654e-07.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 3.20792 | val_0_mse: 4.178579807281494|  0:00:00s\n","epoch 1  | loss: 1.26924 | val_0_mse: 6.560910224914551|  0:00:01s\n","epoch 2  | loss: 0.85002 | val_0_mse: 0.9200299978256226|  0:00:02s\n","epoch 3  | loss: 0.86669 | val_0_mse: 0.1793700009584427|  0:00:03s\n","epoch 4  | loss: 0.403   | val_0_mse: 0.1680700033903122|  0:00:05s\n","epoch 5  | loss: 0.28089 | val_0_mse: 0.027899999171495438|  0:00:06s\n","epoch 6  | loss: 0.19843 | val_0_mse: 0.03044999949634075|  0:00:07s\n","epoch 7  | loss: 0.11225 | val_0_mse: 0.004889999981969595|  0:00:08s\n","epoch 8  | loss: 0.06088 | val_0_mse: 0.016119999811053276|  0:00:09s\n","epoch 9  | loss: 0.0394  | val_0_mse: 0.0019199999514967203|  0:00:10s\n","epoch 10 | loss: 0.04208 | val_0_mse: 0.0012499999720603228|  0:00:11s\n","epoch 11 | loss: 0.00999 | val_0_mse: 0.0014199999859556556|  0:00:12s\n","epoch 12 | loss: 0.00443 | val_0_mse: 0.000699999975040555|  0:00:13s\n","epoch 13 | loss: 0.00164 | val_0_mse: 0.0003100000030826777|  0:00:14s\n","epoch 14 | loss: 0.0009  | val_0_mse: 0.0002500000118743628|  0:00:15s\n","epoch 15 | loss: 0.00061 | val_0_mse: 0.00011999999696854502|  0:00:16s\n","epoch 16 | loss: 0.00045 | val_0_mse: 4.999999873689376e-05|  0:00:17s\n","epoch 17 | loss: 0.00036 | val_0_mse: 1.9999999494757503e-05|  0:00:18s\n","epoch 18 | loss: 0.00034 | val_0_mse: 3.9999998989515007e-05|  0:00:19s\n","epoch 19 | loss: 0.00031 | val_0_mse: 2.9999999242136255e-05|  0:00:20s\n","epoch 20 | loss: 0.0003  | val_0_mse: 9.999999747378752e-06|  0:00:21s\n","epoch 21 | loss: 0.00027 | val_0_mse: 2.9999999242136255e-05|  0:00:22s\n","epoch 22 | loss: 0.00026 | val_0_mse: 2.9999999242136255e-05|  0:00:23s\n","epoch 23 | loss: 0.00026 | val_0_mse: 2.9999999242136255e-05|  0:00:24s\n","epoch 24 | loss: 0.00025 | val_0_mse: 2.9999999242136255e-05|  0:00:25s\n","epoch 25 | loss: 0.00024 | val_0_mse: 1.9999999494757503e-05|  0:00:26s\n","epoch 26 | loss: 0.00024 | val_0_mse: 1.9999999494757503e-05|  0:00:27s\n","epoch 27 | loss: 0.00023 | val_0_mse: 9.999999747378752e-06|  0:00:28s\n","epoch 28 | loss: 0.00023 | val_0_mse: 1.9999999494757503e-05|  0:00:29s\n","epoch 29 | loss: 0.00022 | val_0_mse: 9.999999747378752e-06|  0:00:30s\n","epoch 30 | loss: 0.00022 | val_0_mse: 1.9999999494757503e-05|  0:00:31s\n","epoch 31 | loss: 0.00021 | val_0_mse: 9.999999747378752e-06|  0:00:32s\n","epoch 32 | loss: 0.0002  | val_0_mse: 9.999999747378752e-06|  0:00:33s\n","epoch 33 | loss: 0.0002  | val_0_mse: 9.999999747378752e-06|  0:00:34s\n","epoch 34 | loss: 0.00019 | val_0_mse: 9.999999747378752e-06|  0:00:35s\n","epoch 35 | loss: 0.00019 | val_0_mse: 9.999999747378752e-06|  0:00:36s\n","epoch 36 | loss: 0.00019 | val_0_mse: 9.999999747378752e-06|  0:00:37s\n","epoch 37 | loss: 0.0002  | val_0_mse: 9.999999747378752e-06|  0:00:38s\n","epoch 38 | loss: 0.00019 | val_0_mse: 9.999999747378752e-06|  0:00:40s\n","epoch 39 | loss: 0.00019 | val_0_mse: 9.999999747378752e-06|  0:00:41s\n","epoch 40 | loss: 0.00019 | val_0_mse: 9.999999747378752e-06|  0:00:41s\n","epoch 41 | loss: 0.00019 | val_0_mse: 9.999999747378752e-06|  0:00:42s\n","epoch 42 | loss: 0.00018 | val_0_mse: 9.999999747378752e-06|  0:00:44s\n","epoch 43 | loss: 0.00018 | val_0_mse: 9.999999747378752e-06|  0:00:45s\n","epoch 44 | loss: 0.00018 | val_0_mse: 0.0     |  0:00:46s\n","epoch 45 | loss: 0.00018 | val_0_mse: 9.999999747378752e-06|  0:00:47s\n","epoch 46 | loss: 0.00018 | val_0_mse: 9.999999747378752e-06|  0:00:48s\n","epoch 47 | loss: 0.00018 | val_0_mse: 0.0     |  0:00:49s\n","epoch 48 | loss: 0.00018 | val_0_mse: 9.999999747378752e-06|  0:00:50s\n","epoch 49 | loss: 0.00017 | val_0_mse: 0.0     |  0:00:51s\n","epoch 50 | loss: 0.00017 | val_0_mse: 0.0     |  0:00:52s\n","epoch 51 | loss: 0.00017 | val_0_mse: 0.0     |  0:00:53s\n","epoch 52 | loss: 0.00017 | val_0_mse: 0.0     |  0:00:54s\n","epoch 53 | loss: 0.00017 | val_0_mse: 0.0     |  0:00:55s\n","epoch 54 | loss: 0.00017 | val_0_mse: 0.0     |  0:00:56s\n","epoch 55 | loss: 0.00017 | val_0_mse: 0.0     |  0:00:57s\n","epoch 56 | loss: 0.00016 | val_0_mse: 0.0     |  0:00:58s\n","epoch 57 | loss: 0.00016 | val_0_mse: 0.0     |  0:00:59s\n","epoch 58 | loss: 0.00016 | val_0_mse: 0.0     |  0:01:00s\n","epoch 59 | loss: 0.00016 | val_0_mse: 0.0     |  0:01:01s\n","epoch 60 | loss: 0.00016 | val_0_mse: 0.0     |  0:01:02s\n","epoch 61 | loss: 0.00016 | val_0_mse: 0.0     |  0:01:03s\n","epoch 62 | loss: 0.00016 | val_0_mse: 0.0     |  0:01:04s\n","epoch 63 | loss: 0.00015 | val_0_mse: 0.0     |  0:01:05s\n","epoch 64 | loss: 0.00015 | val_0_mse: 0.0     |  0:01:06s\n","epoch 65 | loss: 0.00016 | val_0_mse: 0.0     |  0:01:07s\n","epoch 66 | loss: 0.00017 | val_0_mse: 0.0     |  0:01:08s\n","epoch 67 | loss: 0.00017 | val_0_mse: 9.999999747378752e-06|  0:01:09s\n","epoch 68 | loss: 0.00016 | val_0_mse: 0.0     |  0:01:10s\n","epoch 69 | loss: 0.00016 | val_0_mse: 0.0     |  0:01:11s\n","epoch 70 | loss: 0.00016 | val_0_mse: 0.0     |  0:01:12s\n","epoch 71 | loss: 0.00016 | val_0_mse: 0.0     |  0:01:13s\n","epoch 72 | loss: 0.00016 | val_0_mse: 0.0     |  0:01:14s\n","epoch 73 | loss: 0.00016 | val_0_mse: 0.0     |  0:01:15s\n","epoch 74 | loss: 0.00016 | val_0_mse: 0.0     |  0:01:16s\n","\n","Early stopping occurred at epoch 74 with best_epoch = 64 and best_val_0_mse = 0.0\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 09:42:26,371] Trial 72 finished with value: 1.280304672945931e-06 and parameters: {'n_d': 36, 'n_steps': 6, 'gamma': 1.9725000458011395, 'n_independent': 3, 'n_shared': 4, 'momentum': 0.14870376929688583}. Best is trial 20 with value: 1.2763081258526654e-07.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 6.4454  | val_0_mse: 20.799480438232422|  0:00:01s\n","epoch 1  | loss: 4.26925 | val_0_mse: 27.644269943237305|  0:00:02s\n","epoch 2  | loss: 2.78125 | val_0_mse: 14.944080352783203|  0:00:03s\n","epoch 3  | loss: 3.8521  | val_0_mse: 1.1318299770355225|  0:00:05s\n","epoch 4  | loss: 1.93791 | val_0_mse: 1.003290057182312|  0:00:06s\n","epoch 5  | loss: 1.28488 | val_0_mse: 0.9462000131607056|  0:00:07s\n","epoch 6  | loss: 1.28591 | val_0_mse: 0.05113999918103218|  0:00:09s\n","epoch 7  | loss: 0.25309 | val_0_mse: 0.07248999923467636|  0:00:10s\n","epoch 8  | loss: 0.22625 | val_0_mse: 0.038359999656677246|  0:00:11s\n","epoch 9  | loss: 0.16601 | val_0_mse: 0.021090000867843628|  0:00:12s\n","epoch 10 | loss: 0.03572 | val_0_mse: 0.015490000136196613|  0:00:14s\n","epoch 11 | loss: 0.01293 | val_0_mse: 0.0015899999998509884|  0:00:15s\n","epoch 12 | loss: 0.00512 | val_0_mse: 0.0007800000021234155|  0:00:16s\n","epoch 13 | loss: 0.00267 | val_0_mse: 0.0008500000112690032|  0:00:18s\n","epoch 14 | loss: 0.00222 | val_0_mse: 0.001560000004246831|  0:00:19s\n","epoch 15 | loss: 0.00179 | val_0_mse: 0.0002300000051036477|  0:00:20s\n","epoch 16 | loss: 0.00112 | val_0_mse: 0.00013000000035390258|  0:00:21s\n","epoch 17 | loss: 0.00099 | val_0_mse: 0.00016999999934341758|  0:00:23s\n","epoch 18 | loss: 0.00089 | val_0_mse: 9.999999747378752e-05|  0:00:24s\n","epoch 19 | loss: 0.00073 | val_0_mse: 0.00016999999934341758|  0:00:25s\n","epoch 20 | loss: 0.00063 | val_0_mse: 9.999999747378752e-05|  0:00:26s\n","epoch 21 | loss: 0.00059 | val_0_mse: 9.999999747378752e-05|  0:00:28s\n","epoch 22 | loss: 0.00047 | val_0_mse: 9.000000136438757e-05|  0:00:29s\n","epoch 23 | loss: 0.0005  | val_0_mse: 0.00011999999696854502|  0:00:30s\n","epoch 24 | loss: 0.00053 | val_0_mse: 0.00018000000272877514|  0:00:32s\n","epoch 25 | loss: 0.00061 | val_0_mse: 9.000000136438757e-05|  0:00:33s\n","epoch 26 | loss: 0.00051 | val_0_mse: 5.999999848427251e-05|  0:00:34s\n","epoch 27 | loss: 0.00043 | val_0_mse: 4.999999873689376e-05|  0:00:35s\n","epoch 28 | loss: 0.00043 | val_0_mse: 4.999999873689376e-05|  0:00:37s\n","epoch 29 | loss: 0.00043 | val_0_mse: 7.999999797903001e-05|  0:00:38s\n","epoch 30 | loss: 0.00042 | val_0_mse: 4.999999873689376e-05|  0:00:39s\n","epoch 31 | loss: 0.00032 | val_0_mse: 4.999999873689376e-05|  0:00:40s\n","epoch 32 | loss: 0.00033 | val_0_mse: 3.9999998989515007e-05|  0:00:42s\n","epoch 33 | loss: 0.00035 | val_0_mse: 2.9999999242136255e-05|  0:00:43s\n","epoch 34 | loss: 0.00034 | val_0_mse: 7.999999797903001e-05|  0:00:44s\n","epoch 35 | loss: 0.00034 | val_0_mse: 5.999999848427251e-05|  0:00:45s\n","epoch 36 | loss: 0.00033 | val_0_mse: 4.999999873689376e-05|  0:00:47s\n","epoch 37 | loss: 0.00031 | val_0_mse: 9.000000136438757e-05|  0:00:48s\n","epoch 38 | loss: 0.00031 | val_0_mse: 1.9999999494757503e-05|  0:00:49s\n","epoch 39 | loss: 0.00029 | val_0_mse: 4.999999873689376e-05|  0:00:50s\n","epoch 40 | loss: 0.0003  | val_0_mse: 2.9999999242136255e-05|  0:00:52s\n","epoch 41 | loss: 0.00027 | val_0_mse: 1.9999999494757503e-05|  0:00:53s\n","epoch 42 | loss: 0.00026 | val_0_mse: 1.9999999494757503e-05|  0:00:54s\n","epoch 43 | loss: 0.00025 | val_0_mse: 2.9999999242136255e-05|  0:00:55s\n","epoch 44 | loss: 0.00031 | val_0_mse: 0.00011999999696854502|  0:00:57s\n","epoch 45 | loss: 0.00032 | val_0_mse: 0.00011000000085914508|  0:00:58s\n","epoch 46 | loss: 0.00036 | val_0_mse: 0.00011000000085914508|  0:00:59s\n","epoch 47 | loss: 0.00037 | val_0_mse: 2.9999999242136255e-05|  0:01:00s\n","epoch 48 | loss: 0.00031 | val_0_mse: 5.999999848427251e-05|  0:01:01s\n","epoch 49 | loss: 0.00038 | val_0_mse: 2.9999999242136255e-05|  0:01:03s\n","epoch 50 | loss: 0.00034 | val_0_mse: 7.999999797903001e-05|  0:01:04s\n","epoch 51 | loss: 0.00036 | val_0_mse: 7.999999797903001e-05|  0:01:05s\n","epoch 52 | loss: 0.00031 | val_0_mse: 7.000000186963007e-05|  0:01:06s\n","\n","Early stopping occurred at epoch 52 with best_epoch = 42 and best_val_0_mse = 1.9999999494757503e-05\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 09:43:33,975] Trial 73 finished with value: 1.7549129552207887e-05 and parameters: {'n_d': 52, 'n_steps': 7, 'gamma': 1.914410716510965, 'n_independent': 3, 'n_shared': 5, 'momentum': 0.130133973652532}. Best is trial 20 with value: 1.2763081258526654e-07.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 12.59205| val_0_mse: 41.87739944458008|  0:00:00s\n","epoch 1  | loss: 1.51726 | val_0_mse: 43.79671859741211|  0:00:01s\n","epoch 2  | loss: 0.92757 | val_0_mse: 1.3280500173568726|  0:00:02s\n","epoch 3  | loss: 1.03109 | val_0_mse: 0.23356999456882477|  0:00:03s\n","epoch 4  | loss: 0.53109 | val_0_mse: 0.4352099895477295|  0:00:04s\n","epoch 5  | loss: 0.49026 | val_0_mse: 0.06471999734640121|  0:00:05s\n","epoch 6  | loss: 0.34648 | val_0_mse: 0.05270000174641609|  0:00:06s\n","epoch 7  | loss: 0.10345 | val_0_mse: 0.038690000772476196|  0:00:07s\n","epoch 8  | loss: 0.04709 | val_0_mse: 0.027329999953508377|  0:00:09s\n","epoch 9  | loss: 0.02335 | val_0_mse: 0.0022899999748915434|  0:00:10s\n","epoch 10 | loss: 0.00724 | val_0_mse: 0.0007900000200606883|  0:00:11s\n","epoch 11 | loss: 0.00355 | val_0_mse: 0.00033999999868683517|  0:00:12s\n","epoch 12 | loss: 0.00218 | val_0_mse: 0.0007800000021234155|  0:00:13s\n","epoch 13 | loss: 0.00206 | val_0_mse: 0.0003800000122282654|  0:00:14s\n","epoch 14 | loss: 0.00164 | val_0_mse: 0.0012199999764561653|  0:00:14s\n","epoch 15 | loss: 0.00122 | val_0_mse: 0.0001500000071246177|  0:00:16s\n","epoch 16 | loss: 0.00096 | val_0_mse: 9.000000136438757e-05|  0:00:17s\n","epoch 17 | loss: 0.00067 | val_0_mse: 4.999999873689376e-05|  0:00:18s\n","epoch 18 | loss: 0.00065 | val_0_mse: 9.000000136438757e-05|  0:00:19s\n","epoch 19 | loss: 0.00068 | val_0_mse: 7.000000186963007e-05|  0:00:20s\n","epoch 20 | loss: 0.00072 | val_0_mse: 0.00014000000373926014|  0:00:21s\n","epoch 21 | loss: 0.00057 | val_0_mse: 5.999999848427251e-05|  0:00:22s\n","epoch 22 | loss: 0.0005  | val_0_mse: 0.00015999999595806003|  0:00:22s\n","epoch 23 | loss: 0.0005  | val_0_mse: 5.999999848427251e-05|  0:00:23s\n","epoch 24 | loss: 0.00044 | val_0_mse: 4.999999873689376e-05|  0:00:24s\n","epoch 25 | loss: 0.00041 | val_0_mse: 0.00011000000085914508|  0:00:25s\n","epoch 26 | loss: 0.0004  | val_0_mse: 2.9999999242136255e-05|  0:00:26s\n","epoch 27 | loss: 0.00041 | val_0_mse: 4.999999873689376e-05|  0:00:27s\n","epoch 28 | loss: 0.00037 | val_0_mse: 4.999999873689376e-05|  0:00:28s\n","epoch 29 | loss: 0.0004  | val_0_mse: 3.9999998989515007e-05|  0:00:29s\n","epoch 30 | loss: 0.0004  | val_0_mse: 3.9999998989515007e-05|  0:00:30s\n","epoch 31 | loss: 0.00042 | val_0_mse: 2.9999999242136255e-05|  0:00:31s\n","epoch 32 | loss: 0.0004  | val_0_mse: 2.9999999242136255e-05|  0:00:32s\n","epoch 33 | loss: 0.00036 | val_0_mse: 2.9999999242136255e-05|  0:00:33s\n","epoch 34 | loss: 0.00034 | val_0_mse: 4.999999873689376e-05|  0:00:34s\n","epoch 35 | loss: 0.00036 | val_0_mse: 1.9999999494757503e-05|  0:00:35s\n","epoch 36 | loss: 0.00037 | val_0_mse: 3.9999998989515007e-05|  0:00:36s\n","epoch 37 | loss: 0.00036 | val_0_mse: 1.9999999494757503e-05|  0:00:37s\n","epoch 38 | loss: 0.00034 | val_0_mse: 1.9999999494757503e-05|  0:00:38s\n","epoch 39 | loss: 0.00031 | val_0_mse: 5.999999848427251e-05|  0:00:39s\n","epoch 40 | loss: 0.00031 | val_0_mse: 1.9999999494757503e-05|  0:00:40s\n","epoch 41 | loss: 0.0003  | val_0_mse: 2.9999999242136255e-05|  0:00:41s\n","epoch 42 | loss: 0.00032 | val_0_mse: 1.9999999494757503e-05|  0:00:42s\n","epoch 43 | loss: 0.00032 | val_0_mse: 2.9999999242136255e-05|  0:00:43s\n","epoch 44 | loss: 0.00029 | val_0_mse: 3.9999998989515007e-05|  0:00:44s\n","epoch 45 | loss: 0.00031 | val_0_mse: 1.9999999494757503e-05|  0:00:45s\n","epoch 46 | loss: 0.0003  | val_0_mse: 3.9999998989515007e-05|  0:00:46s\n","epoch 47 | loss: 0.0003  | val_0_mse: 3.9999998989515007e-05|  0:00:47s\n","\n","Early stopping occurred at epoch 47 with best_epoch = 37 and best_val_0_mse = 1.9999999494757503e-05\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 09:44:22,374] Trial 74 finished with value: 1.5119643649086356e-05 and parameters: {'n_d': 48, 'n_steps': 6, 'gamma': 1.8313973087039022, 'n_independent': 3, 'n_shared': 4, 'momentum': 0.20110044962734297}. Best is trial 20 with value: 1.2763081258526654e-07.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 6.7657  | val_0_mse: 11.402680397033691|  0:00:00s\n","epoch 1  | loss: 9.46364 | val_0_mse: 5.316689968109131|  0:00:01s\n","epoch 2  | loss: 1.8046  | val_0_mse: 1.6597900390625|  0:00:02s\n","epoch 3  | loss: 1.67219 | val_0_mse: 2.9215900897979736|  0:00:03s\n","epoch 4  | loss: 1.59515 | val_0_mse: 0.11376000195741653|  0:00:04s\n","epoch 5  | loss: 0.47715 | val_0_mse: 0.16335000097751617|  0:00:05s\n","epoch 6  | loss: 0.234   | val_0_mse: 0.051100000739097595|  0:00:06s\n","epoch 7  | loss: 0.79389 | val_0_mse: 0.6124799847602844|  0:00:07s\n","epoch 8  | loss: 0.36215 | val_0_mse: 0.023269999772310257|  0:00:08s\n","epoch 9  | loss: 0.11762 | val_0_mse: 0.014349999837577343|  0:00:09s\n","epoch 10 | loss: 0.07216 | val_0_mse: 0.002859999891370535|  0:00:09s\n","epoch 11 | loss: 0.02918 | val_0_mse: 0.006409999914467335|  0:00:10s\n","epoch 12 | loss: 0.01278 | val_0_mse: 0.0014799999771639705|  0:00:11s\n","epoch 13 | loss: 0.00617 | val_0_mse: 0.0005300000193528831|  0:00:12s\n","epoch 14 | loss: 0.00411 | val_0_mse: 0.00033999999868683517|  0:00:13s\n","epoch 15 | loss: 0.00291 | val_0_mse: 0.0003699999942909926|  0:00:14s\n","epoch 16 | loss: 0.00301 | val_0_mse: 0.00022000000171829015|  0:00:15s\n","epoch 17 | loss: 0.00325 | val_0_mse: 7.000000186963007e-05|  0:00:16s\n","epoch 18 | loss: 0.00204 | val_0_mse: 9.999999747378752e-05|  0:00:17s\n","epoch 19 | loss: 0.00128 | val_0_mse: 9.000000136438757e-05|  0:00:18s\n","epoch 20 | loss: 0.00107 | val_0_mse: 9.999999747378752e-05|  0:00:19s\n","epoch 21 | loss: 0.00103 | val_0_mse: 7.999999797903001e-05|  0:00:20s\n","epoch 22 | loss: 0.00096 | val_0_mse: 0.00011999999696854502|  0:00:20s\n","epoch 23 | loss: 0.00086 | val_0_mse: 0.00015999999595806003|  0:00:21s\n","epoch 24 | loss: 0.00072 | val_0_mse: 7.000000186963007e-05|  0:00:22s\n","epoch 25 | loss: 0.0006  | val_0_mse: 7.999999797903001e-05|  0:00:23s\n","epoch 26 | loss: 0.00058 | val_0_mse: 9.999999747378752e-05|  0:00:24s\n","epoch 27 | loss: 0.0005  | val_0_mse: 9.000000136438757e-05|  0:00:25s\n","\n","Early stopping occurred at epoch 27 with best_epoch = 17 and best_val_0_mse = 7.000000186963007e-05\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 09:44:48,274] Trial 75 finished with value: 6.700368976453319e-05 and parameters: {'n_d': 57, 'n_steps': 7, 'gamma': 1.7163230938375214, 'n_independent': 2, 'n_shared': 3, 'momentum': 0.18899146216770812}. Best is trial 20 with value: 1.2763081258526654e-07.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 6.69152 | val_0_mse: 38.866180419921875|  0:00:01s\n","epoch 1  | loss: 4.8777  | val_0_mse: 19.464799880981445|  0:00:03s\n","epoch 2  | loss: 2.98211 | val_0_mse: 2.561609983444214|  0:00:04s\n","epoch 3  | loss: 4.80819 | val_0_mse: 1.0095499753952026|  0:00:06s\n","epoch 4  | loss: 2.47153 | val_0_mse: 0.2971000075340271|  0:00:07s\n","epoch 5  | loss: 2.91529 | val_0_mse: 1.0619499683380127|  0:00:09s\n","epoch 6  | loss: 3.13944 | val_0_mse: 0.20106999576091766|  0:00:10s\n","epoch 7  | loss: 1.23417 | val_0_mse: 0.5668900012969971|  0:00:12s\n","epoch 8  | loss: 0.5548  | val_0_mse: 0.030629999935626984|  0:00:14s\n","epoch 9  | loss: 0.18305 | val_0_mse: 0.014639999717473984|  0:00:15s\n","epoch 10 | loss: 0.07192 | val_0_mse: 0.019500000402331352|  0:00:17s\n","epoch 11 | loss: 0.07271 | val_0_mse: 0.010230000130832195|  0:00:18s\n","epoch 12 | loss: 0.02156 | val_0_mse: 0.006169999949634075|  0:00:20s\n","epoch 13 | loss: 0.0096  | val_0_mse: 0.00139999995008111|  0:00:21s\n","epoch 14 | loss: 0.00629 | val_0_mse: 0.00039000000106170774|  0:00:23s\n","epoch 15 | loss: 0.00281 | val_0_mse: 0.0002699999895412475|  0:00:25s\n","epoch 16 | loss: 0.00159 | val_0_mse: 0.00026000000070780516|  0:00:27s\n","epoch 17 | loss: 0.00094 | val_0_mse: 0.0005600000149570405|  0:00:28s\n","epoch 18 | loss: 0.00079 | val_0_mse: 0.00019999999494757503|  0:00:30s\n","epoch 19 | loss: 0.00054 | val_0_mse: 0.00013000000035390258|  0:00:31s\n","epoch 20 | loss: 0.00042 | val_0_mse: 0.0003000000142492354|  0:00:33s\n","epoch 21 | loss: 0.0003  | val_0_mse: 7.000000186963007e-05|  0:00:34s\n","epoch 22 | loss: 0.00027 | val_0_mse: 4.999999873689376e-05|  0:00:36s\n","epoch 23 | loss: 0.00025 | val_0_mse: 9.999999747378752e-05|  0:00:38s\n","epoch 24 | loss: 0.00025 | val_0_mse: 2.9999999242136255e-05|  0:00:39s\n","epoch 25 | loss: 0.00025 | val_0_mse: 9.999999747378752e-06|  0:00:41s\n","epoch 26 | loss: 0.00022 | val_0_mse: 9.999999747378752e-06|  0:00:42s\n","epoch 27 | loss: 0.00024 | val_0_mse: 9.999999747378752e-06|  0:00:44s\n","epoch 28 | loss: 0.00023 | val_0_mse: 9.999999747378752e-06|  0:00:45s\n","epoch 29 | loss: 0.00018 | val_0_mse: 9.999999747378752e-06|  0:00:47s\n","epoch 30 | loss: 0.00018 | val_0_mse: 9.999999747378752e-06|  0:00:48s\n","epoch 31 | loss: 0.00016 | val_0_mse: 9.999999747378752e-06|  0:00:50s\n","epoch 32 | loss: 0.00016 | val_0_mse: 9.999999747378752e-06|  0:00:51s\n","epoch 33 | loss: 0.00016 | val_0_mse: 9.999999747378752e-06|  0:00:53s\n","epoch 34 | loss: 0.00014 | val_0_mse: 9.999999747378752e-06|  0:00:54s\n","epoch 35 | loss: 0.00014 | val_0_mse: 0.0     |  0:00:56s\n","epoch 36 | loss: 0.00014 | val_0_mse: 0.0     |  0:00:58s\n","epoch 37 | loss: 0.00014 | val_0_mse: 0.0     |  0:00:59s\n","epoch 38 | loss: 0.00015 | val_0_mse: 9.999999747378752e-06|  0:01:01s\n","epoch 39 | loss: 0.00015 | val_0_mse: 9.999999747378752e-06|  0:01:02s\n","epoch 40 | loss: 0.00019 | val_0_mse: 9.999999747378752e-06|  0:01:04s\n","epoch 41 | loss: 0.00021 | val_0_mse: 0.0     |  0:01:05s\n","epoch 42 | loss: 0.00019 | val_0_mse: 9.999999747378752e-06|  0:01:07s\n","epoch 43 | loss: 0.00018 | val_0_mse: 9.999999747378752e-06|  0:01:08s\n","epoch 44 | loss: 0.00018 | val_0_mse: 9.999999747378752e-06|  0:01:10s\n","epoch 45 | loss: 0.00017 | val_0_mse: 9.999999747378752e-06|  0:01:11s\n","epoch 46 | loss: 0.00015 | val_0_mse: 9.999999747378752e-06|  0:01:13s\n","epoch 47 | loss: 0.00016 | val_0_mse: 9.999999747378752e-06|  0:01:14s\n","\n","Early stopping occurred at epoch 47 with best_epoch = 37 and best_val_0_mse = 0.0\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 09:46:04,043] Trial 76 finished with value: 2.402097834419692e-06 and parameters: {'n_d': 40, 'n_steps': 8, 'gamma': 1.8813072378998144, 'n_independent': 4, 'n_shared': 5, 'momentum': 0.16802257818254193}. Best is trial 20 with value: 1.2763081258526654e-07.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 3.75708 | val_0_mse: 1.6350899934768677|  0:00:00s\n","epoch 1  | loss: 1.96763 | val_0_mse: 4.386839866638184|  0:00:01s\n","epoch 2  | loss: 1.71262 | val_0_mse: 0.5562999844551086|  0:00:02s\n","epoch 3  | loss: 0.71164 | val_0_mse: 0.17463000118732452|  0:00:03s\n","epoch 4  | loss: 0.34877 | val_0_mse: 0.291020005941391|  0:00:04s\n","epoch 5  | loss: 0.7479  | val_0_mse: 0.45041999220848083|  0:00:05s\n","epoch 6  | loss: 0.66817 | val_0_mse: 0.3009600043296814|  0:00:06s\n","epoch 7  | loss: 0.23835 | val_0_mse: 0.1163799986243248|  0:00:07s\n","epoch 8  | loss: 0.08818 | val_0_mse: 0.019029999151825905|  0:00:08s\n","epoch 9  | loss: 0.02787 | val_0_mse: 0.014279999770224094|  0:00:08s\n","epoch 10 | loss: 0.00851 | val_0_mse: 0.002739999908953905|  0:00:09s\n","epoch 11 | loss: 0.00331 | val_0_mse: 0.000699999975040555|  0:00:10s\n","epoch 12 | loss: 0.0021  | val_0_mse: 0.0010400000028312206|  0:00:11s\n","epoch 13 | loss: 0.00149 | val_0_mse: 0.00041000000783242285|  0:00:12s\n","epoch 14 | loss: 0.001   | val_0_mse: 0.0004199999966658652|  0:00:13s\n","epoch 15 | loss: 0.00083 | val_0_mse: 0.0004900000058114529|  0:00:14s\n","epoch 16 | loss: 0.00073 | val_0_mse: 0.00026000000070780516|  0:00:15s\n","epoch 17 | loss: 0.00066 | val_0_mse: 0.00014000000373926014|  0:00:16s\n","epoch 18 | loss: 0.00062 | val_0_mse: 0.00019999999494757503|  0:00:16s\n","epoch 19 | loss: 0.00059 | val_0_mse: 0.00016999999934341758|  0:00:17s\n","epoch 20 | loss: 0.00055 | val_0_mse: 9.999999747378752e-05|  0:00:18s\n","epoch 21 | loss: 0.00052 | val_0_mse: 9.999999747378752e-05|  0:00:19s\n","epoch 22 | loss: 0.00049 | val_0_mse: 9.000000136438757e-05|  0:00:20s\n","epoch 23 | loss: 0.00049 | val_0_mse: 7.000000186963007e-05|  0:00:21s\n","epoch 24 | loss: 0.00046 | val_0_mse: 5.999999848427251e-05|  0:00:22s\n","epoch 25 | loss: 0.00044 | val_0_mse: 5.999999848427251e-05|  0:00:23s\n","epoch 26 | loss: 0.00044 | val_0_mse: 5.999999848427251e-05|  0:00:24s\n","epoch 27 | loss: 0.00041 | val_0_mse: 4.999999873689376e-05|  0:00:25s\n","epoch 28 | loss: 0.00039 | val_0_mse: 3.9999998989515007e-05|  0:00:26s\n","epoch 29 | loss: 0.00037 | val_0_mse: 2.9999999242136255e-05|  0:00:26s\n","epoch 30 | loss: 0.00037 | val_0_mse: 2.9999999242136255e-05|  0:00:27s\n","epoch 31 | loss: 0.00036 | val_0_mse: 3.9999998989515007e-05|  0:00:28s\n","epoch 32 | loss: 0.00034 | val_0_mse: 2.9999999242136255e-05|  0:00:29s\n","epoch 33 | loss: 0.00033 | val_0_mse: 2.9999999242136255e-05|  0:00:30s\n","epoch 34 | loss: 0.00033 | val_0_mse: 2.9999999242136255e-05|  0:00:31s\n","epoch 35 | loss: 0.00032 | val_0_mse: 1.9999999494757503e-05|  0:00:32s\n","epoch 36 | loss: 0.00031 | val_0_mse: 1.9999999494757503e-05|  0:00:33s\n","epoch 37 | loss: 0.00031 | val_0_mse: 1.9999999494757503e-05|  0:00:34s\n","epoch 38 | loss: 0.00031 | val_0_mse: 1.9999999494757503e-05|  0:00:35s\n","epoch 39 | loss: 0.0003  | val_0_mse: 1.9999999494757503e-05|  0:00:35s\n","epoch 40 | loss: 0.0003  | val_0_mse: 1.9999999494757503e-05|  0:00:36s\n","epoch 41 | loss: 0.0003  | val_0_mse: 1.9999999494757503e-05|  0:00:37s\n","epoch 42 | loss: 0.00029 | val_0_mse: 9.999999747378752e-06|  0:00:38s\n","epoch 43 | loss: 0.00029 | val_0_mse: 9.999999747378752e-06|  0:00:39s\n","epoch 44 | loss: 0.00029 | val_0_mse: 1.9999999494757503e-05|  0:00:40s\n","epoch 45 | loss: 0.0003  | val_0_mse: 9.999999747378752e-06|  0:00:41s\n","epoch 46 | loss: 0.00029 | val_0_mse: 9.999999747378752e-06|  0:00:42s\n","epoch 47 | loss: 0.00029 | val_0_mse: 9.999999747378752e-06|  0:00:42s\n","epoch 48 | loss: 0.00029 | val_0_mse: 9.999999747378752e-06|  0:00:43s\n","epoch 49 | loss: 0.00028 | val_0_mse: 9.999999747378752e-06|  0:00:44s\n","epoch 50 | loss: 0.00028 | val_0_mse: 9.999999747378752e-06|  0:00:45s\n","epoch 51 | loss: 0.00027 | val_0_mse: 9.999999747378752e-06|  0:00:46s\n","epoch 52 | loss: 0.00027 | val_0_mse: 9.999999747378752e-06|  0:00:47s\n","epoch 53 | loss: 0.00027 | val_0_mse: 9.999999747378752e-06|  0:00:48s\n","epoch 54 | loss: 0.00027 | val_0_mse: 9.999999747378752e-06|  0:00:49s\n","epoch 55 | loss: 0.00026 | val_0_mse: 9.999999747378752e-06|  0:00:50s\n","epoch 56 | loss: 0.00026 | val_0_mse: 9.999999747378752e-06|  0:00:51s\n","epoch 57 | loss: 0.00026 | val_0_mse: 0.0     |  0:00:52s\n","epoch 58 | loss: 0.00026 | val_0_mse: 0.0     |  0:00:53s\n","epoch 59 | loss: 0.00026 | val_0_mse: 0.0     |  0:00:53s\n","epoch 60 | loss: 0.00026 | val_0_mse: 0.0     |  0:00:54s\n","epoch 61 | loss: 0.00026 | val_0_mse: 0.0     |  0:00:55s\n","epoch 62 | loss: 0.00026 | val_0_mse: 0.0     |  0:00:56s\n","epoch 63 | loss: 0.00026 | val_0_mse: 0.0     |  0:00:57s\n","epoch 64 | loss: 0.00025 | val_0_mse: 0.0     |  0:00:58s\n","epoch 65 | loss: 0.00025 | val_0_mse: 0.0     |  0:00:59s\n","epoch 66 | loss: 0.00025 | val_0_mse: 0.0     |  0:01:00s\n","epoch 67 | loss: 0.00024 | val_0_mse: 0.0     |  0:01:01s\n","epoch 68 | loss: 0.00024 | val_0_mse: 0.0     |  0:01:01s\n","epoch 69 | loss: 0.00024 | val_0_mse: 0.0     |  0:01:02s\n","epoch 70 | loss: 0.00024 | val_0_mse: 0.0     |  0:01:03s\n","epoch 71 | loss: 0.00024 | val_0_mse: 0.0     |  0:01:04s\n","epoch 72 | loss: 0.00024 | val_0_mse: 0.0     |  0:01:05s\n","epoch 73 | loss: 0.00024 | val_0_mse: 0.0     |  0:01:06s\n","epoch 74 | loss: 0.00024 | val_0_mse: 0.0     |  0:01:07s\n","epoch 75 | loss: 0.00023 | val_0_mse: 0.0     |  0:01:08s\n","epoch 76 | loss: 0.00023 | val_0_mse: 0.0     |  0:01:09s\n","epoch 77 | loss: 0.00023 | val_0_mse: 0.0     |  0:01:10s\n","epoch 78 | loss: 0.00023 | val_0_mse: 0.0     |  0:01:10s\n","epoch 79 | loss: 0.00023 | val_0_mse: 0.0     |  0:01:11s\n","epoch 80 | loss: 0.00023 | val_0_mse: 0.0     |  0:01:12s\n","epoch 81 | loss: 0.00022 | val_0_mse: 0.0     |  0:01:13s\n","epoch 82 | loss: 0.00022 | val_0_mse: 0.0     |  0:01:14s\n","epoch 83 | loss: 0.00022 | val_0_mse: 0.0     |  0:01:15s\n","epoch 84 | loss: 0.00022 | val_0_mse: 0.0     |  0:01:16s\n","epoch 85 | loss: 0.00022 | val_0_mse: 0.0     |  0:01:17s\n","epoch 86 | loss: 0.00022 | val_0_mse: 0.0     |  0:01:18s\n","epoch 87 | loss: 0.00022 | val_0_mse: 0.0     |  0:01:19s\n","epoch 88 | loss: 0.00022 | val_0_mse: 0.0     |  0:01:20s\n","epoch 89 | loss: 0.00022 | val_0_mse: 0.0     |  0:01:20s\n","epoch 90 | loss: 0.00022 | val_0_mse: 0.0     |  0:01:21s\n","epoch 91 | loss: 0.00022 | val_0_mse: 0.0     |  0:01:22s\n","epoch 92 | loss: 0.00021 | val_0_mse: 0.0     |  0:01:23s\n","epoch 93 | loss: 0.00021 | val_0_mse: 0.0     |  0:01:24s\n","epoch 94 | loss: 0.00021 | val_0_mse: 0.0     |  0:01:25s\n","epoch 95 | loss: 0.00021 | val_0_mse: 0.0     |  0:01:26s\n","epoch 96 | loss: 0.00022 | val_0_mse: 0.0     |  0:01:27s\n","epoch 97 | loss: 0.00021 | val_0_mse: 0.0     |  0:01:28s\n","epoch 98 | loss: 0.00021 | val_0_mse: 0.0     |  0:01:28s\n","epoch 99 | loss: 0.00021 | val_0_mse: 0.0     |  0:01:29s\n","Stop training because you reached max_epochs = 100 with best_epoch = 93 and best_val_0_mse = 0.0\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 09:47:34,341] Trial 77 finished with value: 3.7570720223811804e-07 and parameters: {'n_d': 46, 'n_steps': 7, 'gamma': 1.3952209921166674, 'n_independent': 2, 'n_shared': 3, 'momentum': 0.21054758464100407}. Best is trial 20 with value: 1.2763081258526654e-07.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 7.14233 | val_0_mse: 18.389490127563477|  0:00:00s\n","epoch 1  | loss: 0.95246 | val_0_mse: 1.5081499814987183|  0:00:01s\n","epoch 2  | loss: 0.87256 | val_0_mse: 0.49950000643730164|  0:00:02s\n","epoch 3  | loss: 0.48027 | val_0_mse: 0.07165999710559845|  0:00:03s\n","epoch 4  | loss: 0.34235 | val_0_mse: 0.00687999976798892|  0:00:04s\n","epoch 5  | loss: 0.21425 | val_0_mse: 0.0044200001284480095|  0:00:05s\n","epoch 6  | loss: 0.09512 | val_0_mse: 0.007369999773800373|  0:00:06s\n","epoch 7  | loss: 0.02471 | val_0_mse: 0.0018899999558925629|  0:00:07s\n","epoch 8  | loss: 0.01498 | val_0_mse: 0.0009899999713525176|  0:00:08s\n","epoch 9  | loss: 0.00696 | val_0_mse: 0.0003800000122282654|  0:00:09s\n","epoch 10 | loss: 0.00332 | val_0_mse: 0.00019999999494757503|  0:00:10s\n","epoch 11 | loss: 0.00204 | val_0_mse: 0.0004199999966658652|  0:00:12s\n","epoch 12 | loss: 0.00173 | val_0_mse: 0.00016999999934341758|  0:00:13s\n","epoch 13 | loss: 0.00149 | val_0_mse: 0.00014000000373926014|  0:00:14s\n","epoch 14 | loss: 0.00126 | val_0_mse: 3.9999998989515007e-05|  0:00:15s\n","epoch 15 | loss: 0.00136 | val_0_mse: 5.999999848427251e-05|  0:00:16s\n","epoch 16 | loss: 0.00088 | val_0_mse: 9.000000136438757e-05|  0:00:17s\n","epoch 17 | loss: 0.0007  | val_0_mse: 4.999999873689376e-05|  0:00:18s\n","epoch 18 | loss: 0.00058 | val_0_mse: 4.999999873689376e-05|  0:00:19s\n","epoch 19 | loss: 0.00054 | val_0_mse: 1.9999999494757503e-05|  0:00:20s\n","epoch 20 | loss: 0.0005  | val_0_mse: 9.999999747378752e-06|  0:00:21s\n","epoch 21 | loss: 0.00046 | val_0_mse: 1.9999999494757503e-05|  0:00:22s\n","epoch 22 | loss: 0.00042 | val_0_mse: 2.9999999242136255e-05|  0:00:23s\n","epoch 23 | loss: 0.0004  | val_0_mse: 1.9999999494757503e-05|  0:00:24s\n","epoch 24 | loss: 0.00038 | val_0_mse: 9.999999747378752e-06|  0:00:25s\n","epoch 25 | loss: 0.00037 | val_0_mse: 9.999999747378752e-06|  0:00:26s\n","epoch 26 | loss: 0.00036 | val_0_mse: 9.999999747378752e-06|  0:00:27s\n","epoch 27 | loss: 0.00035 | val_0_mse: 1.9999999494757503e-05|  0:00:28s\n","epoch 28 | loss: 0.00034 | val_0_mse: 9.999999747378752e-06|  0:00:29s\n","epoch 29 | loss: 0.00033 | val_0_mse: 1.9999999494757503e-05|  0:00:30s\n","epoch 30 | loss: 0.00033 | val_0_mse: 9.999999747378752e-06|  0:00:31s\n","epoch 31 | loss: 0.00031 | val_0_mse: 9.999999747378752e-06|  0:00:32s\n","epoch 32 | loss: 0.00031 | val_0_mse: 9.999999747378752e-06|  0:00:33s\n","epoch 33 | loss: 0.0003  | val_0_mse: 9.999999747378752e-06|  0:00:33s\n","epoch 34 | loss: 0.00032 | val_0_mse: 9.999999747378752e-06|  0:00:34s\n","epoch 35 | loss: 0.0003  | val_0_mse: 0.0     |  0:00:35s\n","epoch 36 | loss: 0.0003  | val_0_mse: 9.999999747378752e-06|  0:00:36s\n","epoch 37 | loss: 0.00028 | val_0_mse: 9.999999747378752e-06|  0:00:37s\n","epoch 38 | loss: 0.00028 | val_0_mse: 9.999999747378752e-06|  0:00:38s\n","epoch 39 | loss: 0.00028 | val_0_mse: 9.999999747378752e-06|  0:00:39s\n","epoch 40 | loss: 0.00028 | val_0_mse: 9.999999747378752e-06|  0:00:40s\n","epoch 41 | loss: 0.00028 | val_0_mse: 0.0     |  0:00:41s\n","epoch 42 | loss: 0.00027 | val_0_mse: 9.999999747378752e-06|  0:00:42s\n","epoch 43 | loss: 0.00027 | val_0_mse: 9.999999747378752e-06|  0:00:44s\n","epoch 44 | loss: 0.00027 | val_0_mse: 0.0     |  0:00:45s\n","epoch 45 | loss: 0.00027 | val_0_mse: 2.9999999242136255e-05|  0:00:46s\n","\n","Early stopping occurred at epoch 45 with best_epoch = 35 and best_val_0_mse = 0.0\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 09:48:20,957] Trial 78 finished with value: 4.23739584221039e-06 and parameters: {'n_d': 35, 'n_steps': 6, 'gamma': 1.8100197950921448, 'n_independent': 3, 'n_shared': 4, 'momentum': 0.23236879570413124}. Best is trial 20 with value: 1.2763081258526654e-07.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 5.01927 | val_0_mse: 10.85824966430664|  0:00:00s\n","epoch 1  | loss: 2.09152 | val_0_mse: 12.441740036010742|  0:00:01s\n","epoch 2  | loss: 2.75535 | val_0_mse: 3.1946399211883545|  0:00:02s\n","epoch 3  | loss: 1.82758 | val_0_mse: 0.7910100221633911|  0:00:03s\n","epoch 4  | loss: 0.84114 | val_0_mse: 1.104490041732788|  0:00:04s\n","epoch 5  | loss: 1.04986 | val_0_mse: 0.4370099902153015|  0:00:06s\n","epoch 6  | loss: 0.77353 | val_0_mse: 0.13142000138759613|  0:00:07s\n","epoch 7  | loss: 0.43234 | val_0_mse: 0.045499999076128006|  0:00:08s\n","epoch 8  | loss: 0.34802 | val_0_mse: 0.13955000042915344|  0:00:09s\n","epoch 9  | loss: 0.33782 | val_0_mse: 0.06620000302791595|  0:00:10s\n","epoch 10 | loss: 0.09978 | val_0_mse: 0.05057999864220619|  0:00:11s\n","epoch 11 | loss: 0.09514 | val_0_mse: 0.016289999708533287|  0:00:12s\n","epoch 12 | loss: 0.02334 | val_0_mse: 0.006630000192672014|  0:00:13s\n","epoch 13 | loss: 0.00884 | val_0_mse: 0.0033599999733269215|  0:00:14s\n","epoch 14 | loss: 0.00428 | val_0_mse: 0.002319999970495701|  0:00:15s\n","epoch 15 | loss: 0.00269 | val_0_mse: 0.000859999970998615|  0:00:16s\n","epoch 16 | loss: 0.00207 | val_0_mse: 0.0007399999885819852|  0:00:17s\n","epoch 17 | loss: 0.0018  | val_0_mse: 0.0003699999942909926|  0:00:18s\n","epoch 18 | loss: 0.00151 | val_0_mse: 0.00033999999868683517|  0:00:19s\n","epoch 19 | loss: 0.0015  | val_0_mse: 0.0003100000030826777|  0:00:20s\n","epoch 20 | loss: 0.0014  | val_0_mse: 0.0005699999746866524|  0:00:21s\n","epoch 21 | loss: 0.00126 | val_0_mse: 0.0002899999963119626|  0:00:22s\n","epoch 22 | loss: 0.00115 | val_0_mse: 0.0003100000030826777|  0:00:23s\n","epoch 23 | loss: 0.00111 | val_0_mse: 0.0003600000054575503|  0:00:24s\n","epoch 24 | loss: 0.001   | val_0_mse: 0.0002699999895412475|  0:00:25s\n","epoch 25 | loss: 0.00095 | val_0_mse: 0.0003100000030826777|  0:00:26s\n","epoch 26 | loss: 0.00097 | val_0_mse: 0.00018000000272877514|  0:00:27s\n","epoch 27 | loss: 0.00095 | val_0_mse: 0.0001500000071246177|  0:00:28s\n","epoch 28 | loss: 0.00079 | val_0_mse: 0.00019999999494757503|  0:00:29s\n","epoch 29 | loss: 0.00096 | val_0_mse: 0.0004400000034365803|  0:00:30s\n","epoch 30 | loss: 0.0011  | val_0_mse: 0.0005499999970197678|  0:00:31s\n","epoch 31 | loss: 0.00098 | val_0_mse: 0.00039999998989515007|  0:00:32s\n","epoch 32 | loss: 0.00088 | val_0_mse: 0.00046999999904073775|  0:00:33s\n","epoch 33 | loss: 0.00072 | val_0_mse: 0.00022000000171829015|  0:00:34s\n","epoch 34 | loss: 0.00065 | val_0_mse: 0.00018000000272877514|  0:00:35s\n","epoch 35 | loss: 0.00067 | val_0_mse: 0.0001500000071246177|  0:00:36s\n","epoch 36 | loss: 0.00068 | val_0_mse: 9.999999747378752e-05|  0:00:37s\n","epoch 37 | loss: 0.00059 | val_0_mse: 0.00016999999934341758|  0:00:38s\n","epoch 38 | loss: 0.00059 | val_0_mse: 0.00011000000085914508|  0:00:39s\n","epoch 39 | loss: 0.00074 | val_0_mse: 7.000000186963007e-05|  0:00:40s\n","epoch 40 | loss: 0.00079 | val_0_mse: 0.0002899999963119626|  0:00:41s\n","epoch 41 | loss: 0.00087 | val_0_mse: 0.0003000000142492354|  0:00:42s\n","epoch 42 | loss: 0.0009  | val_0_mse: 0.0002099999983329326|  0:00:43s\n","epoch 43 | loss: 0.00085 | val_0_mse: 0.00023999999393709004|  0:00:44s\n","epoch 44 | loss: 0.00077 | val_0_mse: 0.0002500000118743628|  0:00:45s\n","epoch 45 | loss: 0.00119 | val_0_mse: 0.0005600000149570405|  0:00:46s\n","epoch 46 | loss: 0.00129 | val_0_mse: 0.00033000000985339284|  0:00:47s\n","epoch 47 | loss: 0.00109 | val_0_mse: 0.00033000000985339284|  0:00:48s\n","epoch 48 | loss: 0.00091 | val_0_mse: 0.0002699999895412475|  0:00:49s\n","epoch 49 | loss: 0.0008  | val_0_mse: 0.00046999999904073775|  0:00:50s\n","\n","Early stopping occurred at epoch 49 with best_epoch = 39 and best_val_0_mse = 7.000000186963007e-05\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 09:49:11,947] Trial 79 finished with value: 7.309079956030473e-05 and parameters: {'n_d': 38, 'n_steps': 7, 'gamma': 1.929778695722315, 'n_independent': 3, 'n_shared': 3, 'momentum': 0.31671559210457445}. Best is trial 20 with value: 1.2763081258526654e-07.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 6.2318  | val_0_mse: 84.37487030029297|  0:00:01s\n","epoch 1  | loss: 3.57516 | val_0_mse: 5.772659778594971|  0:00:02s\n","epoch 2  | loss: 3.39063 | val_0_mse: 5.063360214233398|  0:00:03s\n","epoch 3  | loss: 1.63469 | val_0_mse: 0.5156300067901611|  0:00:05s\n","epoch 4  | loss: 4.03895 | val_0_mse: 10.95715045928955|  0:00:06s\n","epoch 5  | loss: 11.03197| val_0_mse: 2.8907101154327393|  0:00:07s\n","epoch 6  | loss: 2.14805 | val_0_mse: 0.22015999257564545|  0:00:08s\n","epoch 7  | loss: 0.28474 | val_0_mse: 0.051580000668764114|  0:00:10s\n","epoch 8  | loss: 0.08387 | val_0_mse: 0.021460000425577164|  0:00:11s\n","epoch 9  | loss: 0.04382 | val_0_mse: 0.006390000227838755|  0:00:12s\n","epoch 10 | loss: 0.01273 | val_0_mse: 0.0013500000350177288|  0:00:13s\n","epoch 11 | loss: 0.00518 | val_0_mse: 0.0006300000241026282|  0:00:15s\n","epoch 12 | loss: 0.00194 | val_0_mse: 0.0003100000030826777|  0:00:16s\n","epoch 13 | loss: 0.00088 | val_0_mse: 9.000000136438757e-05|  0:00:17s\n","epoch 14 | loss: 0.0004  | val_0_mse: 2.9999999242136255e-05|  0:00:18s\n","epoch 15 | loss: 0.00025 | val_0_mse: 1.9999999494757503e-05|  0:00:20s\n","epoch 16 | loss: 0.00019 | val_0_mse: 9.999999747378752e-06|  0:00:21s\n","epoch 17 | loss: 0.00016 | val_0_mse: 9.999999747378752e-06|  0:00:22s\n","epoch 18 | loss: 0.00014 | val_0_mse: 9.999999747378752e-06|  0:00:23s\n","epoch 19 | loss: 0.00014 | val_0_mse: 9.999999747378752e-06|  0:00:25s\n","epoch 20 | loss: 0.00013 | val_0_mse: 0.0     |  0:00:26s\n","epoch 21 | loss: 0.00013 | val_0_mse: 0.0     |  0:00:27s\n","epoch 22 | loss: 0.00013 | val_0_mse: 0.0     |  0:00:29s\n","epoch 23 | loss: 0.00013 | val_0_mse: 0.0     |  0:00:30s\n","epoch 24 | loss: 0.00013 | val_0_mse: 0.0     |  0:00:31s\n","epoch 25 | loss: 0.00013 | val_0_mse: 0.0     |  0:00:32s\n","epoch 26 | loss: 0.00013 | val_0_mse: 0.0     |  0:00:34s\n","epoch 27 | loss: 0.00013 | val_0_mse: 0.0     |  0:00:35s\n","epoch 28 | loss: 0.00014 | val_0_mse: 0.0     |  0:00:36s\n","epoch 29 | loss: 0.00014 | val_0_mse: 0.0     |  0:00:38s\n","epoch 30 | loss: 0.00014 | val_0_mse: 0.0     |  0:00:39s\n","epoch 31 | loss: 0.00014 | val_0_mse: 0.0     |  0:00:40s\n","epoch 32 | loss: 0.00014 | val_0_mse: 0.0     |  0:00:41s\n","epoch 33 | loss: 0.00014 | val_0_mse: 0.0     |  0:00:43s\n","epoch 34 | loss: 0.00014 | val_0_mse: 0.0     |  0:00:44s\n","epoch 35 | loss: 0.00014 | val_0_mse: 0.0     |  0:00:45s\n","epoch 36 | loss: 0.00013 | val_0_mse: 0.0     |  0:00:46s\n","epoch 37 | loss: 0.00013 | val_0_mse: 0.0     |  0:00:48s\n","epoch 38 | loss: 0.00014 | val_0_mse: 0.0     |  0:00:49s\n","epoch 39 | loss: 0.00014 | val_0_mse: 0.0     |  0:00:50s\n","epoch 40 | loss: 0.00013 | val_0_mse: 0.0     |  0:00:51s\n","epoch 41 | loss: 0.00013 | val_0_mse: 0.0     |  0:00:52s\n","epoch 42 | loss: 0.00013 | val_0_mse: 0.0     |  0:00:54s\n","epoch 43 | loss: 0.00013 | val_0_mse: 0.0     |  0:00:55s\n","epoch 44 | loss: 0.00014 | val_0_mse: 0.0     |  0:00:56s\n","epoch 45 | loss: 0.00014 | val_0_mse: 0.0     |  0:00:57s\n","epoch 46 | loss: 0.00013 | val_0_mse: 0.0     |  0:00:59s\n","epoch 47 | loss: 0.00013 | val_0_mse: 0.0     |  0:01:00s\n","epoch 48 | loss: 0.00013 | val_0_mse: 0.0     |  0:01:01s\n","epoch 49 | loss: 0.00013 | val_0_mse: 0.0     |  0:01:02s\n","epoch 50 | loss: 0.00013 | val_0_mse: 0.0     |  0:01:04s\n","epoch 51 | loss: 0.00013 | val_0_mse: 0.0     |  0:01:05s\n","epoch 52 | loss: 0.00013 | val_0_mse: 0.0     |  0:01:06s\n","epoch 53 | loss: 0.00013 | val_0_mse: 0.0     |  0:01:07s\n","epoch 54 | loss: 0.00013 | val_0_mse: 0.0     |  0:01:09s\n","epoch 55 | loss: 0.00013 | val_0_mse: 0.0     |  0:01:10s\n","epoch 56 | loss: 0.00013 | val_0_mse: 0.0     |  0:01:11s\n","epoch 57 | loss: 0.00013 | val_0_mse: 0.0     |  0:01:12s\n","epoch 58 | loss: 0.00013 | val_0_mse: 0.0     |  0:01:14s\n","epoch 59 | loss: 0.00013 | val_0_mse: 0.0     |  0:01:15s\n","epoch 60 | loss: 0.00013 | val_0_mse: 0.0     |  0:01:16s\n","epoch 61 | loss: 0.00013 | val_0_mse: 0.0     |  0:01:17s\n","\n","Early stopping occurred at epoch 61 with best_epoch = 51 and best_val_0_mse = 0.0\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 09:50:30,473] Trial 80 finished with value: 2.918960433362372e-07 and parameters: {'n_d': 41, 'n_steps': 9, 'gamma': 1.7660271588011593, 'n_independent': 3, 'n_shared': 3, 'momentum': 0.09464686222962873}. Best is trial 20 with value: 1.2763081258526654e-07.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 1.87788 | val_0_mse: 4.010570049285889|  0:00:00s\n","epoch 1  | loss: 1.61201 | val_0_mse: 0.8217599987983704|  0:00:02s\n","epoch 2  | loss: 0.67915 | val_0_mse: 0.13465000689029694|  0:00:03s\n","epoch 3  | loss: 0.84499 | val_0_mse: 0.10045000165700912|  0:00:04s\n","epoch 4  | loss: 0.40604 | val_0_mse: 0.1043500006198883|  0:00:05s\n","epoch 5  | loss: 0.31291 | val_0_mse: 0.009390000253915787|  0:00:06s\n","epoch 6  | loss: 0.43807 | val_0_mse: 0.4612799882888794|  0:00:07s\n","epoch 7  | loss: 0.12584 | val_0_mse: 0.033149998635053635|  0:00:08s\n","epoch 8  | loss: 0.03067 | val_0_mse: 0.004739999771118164|  0:00:09s\n","epoch 9  | loss: 0.00761 | val_0_mse: 0.0011099999537691474|  0:00:10s\n","epoch 10 | loss: 0.00303 | val_0_mse: 0.00031999999191612005|  0:00:11s\n","epoch 11 | loss: 0.00157 | val_0_mse: 0.00018000000272877514|  0:00:12s\n","epoch 12 | loss: 0.00115 | val_0_mse: 0.00033999999868683517|  0:00:13s\n","epoch 13 | loss: 0.00098 | val_0_mse: 0.00013000000035390258|  0:00:14s\n","epoch 14 | loss: 0.0006  | val_0_mse: 9.999999747378752e-05|  0:00:15s\n","epoch 15 | loss: 0.00046 | val_0_mse: 3.9999998989515007e-05|  0:00:16s\n","epoch 16 | loss: 0.0004  | val_0_mse: 2.9999999242136255e-05|  0:00:17s\n","epoch 17 | loss: 0.00038 | val_0_mse: 3.9999998989515007e-05|  0:00:18s\n","epoch 18 | loss: 0.00038 | val_0_mse: 2.9999999242136255e-05|  0:00:19s\n","epoch 19 | loss: 0.00061 | val_0_mse: 0.0001500000071246177|  0:00:20s\n","epoch 20 | loss: 0.00051 | val_0_mse: 7.999999797903001e-05|  0:00:21s\n","epoch 21 | loss: 0.00038 | val_0_mse: 4.999999873689376e-05|  0:00:22s\n","epoch 22 | loss: 0.00028 | val_0_mse: 3.9999998989515007e-05|  0:00:23s\n","epoch 23 | loss: 0.00023 | val_0_mse: 2.9999999242136255e-05|  0:00:24s\n","epoch 24 | loss: 0.0002  | val_0_mse: 1.9999999494757503e-05|  0:00:25s\n","epoch 25 | loss: 0.00019 | val_0_mse: 1.9999999494757503e-05|  0:00:26s\n","epoch 26 | loss: 0.00019 | val_0_mse: 9.999999747378752e-06|  0:00:27s\n","epoch 27 | loss: 0.00017 | val_0_mse: 9.999999747378752e-06|  0:00:28s\n","epoch 28 | loss: 0.00016 | val_0_mse: 9.999999747378752e-06|  0:00:29s\n","epoch 29 | loss: 0.00016 | val_0_mse: 9.999999747378752e-06|  0:00:30s\n","epoch 30 | loss: 0.00016 | val_0_mse: 9.999999747378752e-06|  0:00:31s\n","epoch 31 | loss: 0.00015 | val_0_mse: 9.999999747378752e-06|  0:00:32s\n","epoch 32 | loss: 0.00015 | val_0_mse: 9.999999747378752e-06|  0:00:33s\n","epoch 33 | loss: 0.00014 | val_0_mse: 9.999999747378752e-06|  0:00:34s\n","epoch 34 | loss: 0.00014 | val_0_mse: 9.999999747378752e-06|  0:00:35s\n","epoch 35 | loss: 0.00013 | val_0_mse: 9.999999747378752e-06|  0:00:36s\n","epoch 36 | loss: 0.00013 | val_0_mse: 9.999999747378752e-06|  0:00:37s\n","epoch 37 | loss: 0.00013 | val_0_mse: 9.999999747378752e-06|  0:00:38s\n","epoch 38 | loss: 0.00013 | val_0_mse: 0.0     |  0:00:39s\n","epoch 39 | loss: 0.00013 | val_0_mse: 0.0     |  0:00:40s\n","epoch 40 | loss: 0.00013 | val_0_mse: 0.0     |  0:00:41s\n","epoch 41 | loss: 0.00012 | val_0_mse: 0.0     |  0:00:42s\n","epoch 42 | loss: 0.00012 | val_0_mse: 0.0     |  0:00:43s\n","epoch 43 | loss: 0.00012 | val_0_mse: 0.0     |  0:00:44s\n","epoch 44 | loss: 0.00012 | val_0_mse: 0.0     |  0:00:45s\n","epoch 45 | loss: 0.00012 | val_0_mse: 0.0     |  0:00:46s\n","epoch 46 | loss: 0.00012 | val_0_mse: 0.0     |  0:00:47s\n","epoch 47 | loss: 0.00012 | val_0_mse: 0.0     |  0:00:48s\n","epoch 48 | loss: 0.00012 | val_0_mse: 0.0     |  0:00:49s\n","epoch 49 | loss: 0.00012 | val_0_mse: 0.0     |  0:00:50s\n","epoch 50 | loss: 0.00012 | val_0_mse: 0.0     |  0:00:51s\n","epoch 51 | loss: 0.00011 | val_0_mse: 0.0     |  0:00:52s\n","epoch 52 | loss: 0.00012 | val_0_mse: 0.0     |  0:00:53s\n","epoch 53 | loss: 0.00012 | val_0_mse: 0.0     |  0:00:54s\n","epoch 54 | loss: 0.00012 | val_0_mse: 0.0     |  0:00:55s\n","epoch 55 | loss: 0.00012 | val_0_mse: 0.0     |  0:00:56s\n","epoch 56 | loss: 0.00012 | val_0_mse: 0.0     |  0:00:57s\n","epoch 57 | loss: 0.00012 | val_0_mse: 0.0     |  0:00:59s\n","epoch 58 | loss: 0.00012 | val_0_mse: 0.0     |  0:01:00s\n","epoch 59 | loss: 0.00012 | val_0_mse: 0.0     |  0:01:01s\n","epoch 60 | loss: 0.00012 | val_0_mse: 0.0     |  0:01:02s\n","epoch 61 | loss: 0.00012 | val_0_mse: 0.0     |  0:01:03s\n","epoch 62 | loss: 0.00012 | val_0_mse: 0.0     |  0:01:04s\n","epoch 63 | loss: 0.00011 | val_0_mse: 0.0     |  0:01:05s\n","epoch 64 | loss: 0.00012 | val_0_mse: 0.0     |  0:01:06s\n","epoch 65 | loss: 0.00012 | val_0_mse: 0.0     |  0:01:07s\n","epoch 66 | loss: 0.00012 | val_0_mse: 0.0     |  0:01:08s\n","epoch 67 | loss: 0.00013 | val_0_mse: 0.0     |  0:01:09s\n","epoch 68 | loss: 0.00012 | val_0_mse: 0.0     |  0:01:10s\n","epoch 69 | loss: 0.00012 | val_0_mse: 0.0     |  0:01:11s\n","epoch 70 | loss: 0.00012 | val_0_mse: 0.0     |  0:01:12s\n","epoch 71 | loss: 0.00012 | val_0_mse: 0.0     |  0:01:13s\n","epoch 72 | loss: 0.00012 | val_0_mse: 0.0     |  0:01:14s\n","epoch 73 | loss: 0.00011 | val_0_mse: 0.0     |  0:01:15s\n","epoch 74 | loss: 0.00012 | val_0_mse: 0.0     |  0:01:16s\n","epoch 75 | loss: 0.00013 | val_0_mse: 0.0     |  0:01:17s\n","epoch 76 | loss: 0.00013 | val_0_mse: 0.0     |  0:01:18s\n","epoch 77 | loss: 0.00014 | val_0_mse: 0.0     |  0:01:19s\n","epoch 78 | loss: 0.00015 | val_0_mse: 0.0     |  0:01:20s\n","epoch 79 | loss: 0.00015 | val_0_mse: 0.0     |  0:01:21s\n","epoch 80 | loss: 0.00015 | val_0_mse: 0.0     |  0:01:22s\n","epoch 81 | loss: 0.00015 | val_0_mse: 0.0     |  0:01:23s\n","epoch 82 | loss: 0.00015 | val_0_mse: 0.0     |  0:01:24s\n","epoch 83 | loss: 0.00015 | val_0_mse: 0.0     |  0:01:25s\n","epoch 84 | loss: 0.00015 | val_0_mse: 0.0     |  0:01:26s\n","epoch 85 | loss: 0.00014 | val_0_mse: 0.0     |  0:01:27s\n","epoch 86 | loss: 0.00014 | val_0_mse: 0.0     |  0:01:28s\n","\n","Early stopping occurred at epoch 86 with best_epoch = 76 and best_val_0_mse = 0.0\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 09:51:59,461] Trial 81 finished with value: 1.8954008851324033e-07 and parameters: {'n_d': 39, 'n_steps': 8, 'gamma': 1.9655845687941023, 'n_independent': 2, 'n_shared': 3, 'momentum': 0.35376681058516}. Best is trial 20 with value: 1.2763081258526654e-07.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 6.45969 | val_0_mse: 2.4731500148773193|  0:00:01s\n","epoch 1  | loss: 3.37405 | val_0_mse: 16.897769927978516|  0:00:02s\n","epoch 2  | loss: 3.24984 | val_0_mse: 21.317720413208008|  0:00:04s\n","epoch 3  | loss: 2.36998 | val_0_mse: 0.11242000013589859|  0:00:05s\n","epoch 4  | loss: 1.18286 | val_0_mse: 0.07715000212192535|  0:00:06s\n","epoch 5  | loss: 3.03992 | val_0_mse: 1.1380399465560913|  0:00:08s\n","epoch 6  | loss: 3.02991 | val_0_mse: 0.06808999925851822|  0:00:09s\n","epoch 7  | loss: 0.4228  | val_0_mse: 0.08539000153541565|  0:00:11s\n","epoch 8  | loss: 0.13794 | val_0_mse: 0.11218000203371048|  0:00:12s\n","epoch 9  | loss: 0.11236 | val_0_mse: 0.021709999069571495|  0:00:13s\n","epoch 10 | loss: 0.09475 | val_0_mse: 0.07711999863386154|  0:00:15s\n","epoch 11 | loss: 0.18166 | val_0_mse: 0.34171000123023987|  0:00:16s\n","epoch 12 | loss: 0.05237 | val_0_mse: 0.018069999292492867|  0:00:17s\n","epoch 13 | loss: 0.00944 | val_0_mse: 0.0016499999910593033|  0:00:19s\n","epoch 14 | loss: 0.00389 | val_0_mse: 0.0006300000241026282|  0:00:20s\n","epoch 15 | loss: 0.00191 | val_0_mse: 0.00019999999494757503|  0:00:22s\n","epoch 16 | loss: 0.001   | val_0_mse: 0.0001500000071246177|  0:00:23s\n","epoch 17 | loss: 0.00057 | val_0_mse: 0.00011000000085914508|  0:00:24s\n","epoch 18 | loss: 0.00049 | val_0_mse: 9.999999747378752e-05|  0:00:26s\n","epoch 19 | loss: 0.00057 | val_0_mse: 0.00015999999595806003|  0:00:27s\n","epoch 20 | loss: 0.00064 | val_0_mse: 0.00031999999191612005|  0:00:29s\n","epoch 21 | loss: 0.0006  | val_0_mse: 0.0002800000074785203|  0:00:30s\n","epoch 22 | loss: 0.0007  | val_0_mse: 9.999999747378752e-05|  0:00:31s\n","epoch 23 | loss: 0.00066 | val_0_mse: 0.00011999999696854502|  0:00:33s\n","epoch 24 | loss: 0.00047 | val_0_mse: 0.00011999999696854502|  0:00:34s\n","epoch 25 | loss: 0.00041 | val_0_mse: 9.000000136438757e-05|  0:00:36s\n","epoch 26 | loss: 0.0004  | val_0_mse: 7.000000186963007e-05|  0:00:37s\n","epoch 27 | loss: 0.00035 | val_0_mse: 5.999999848427251e-05|  0:00:38s\n","epoch 28 | loss: 0.00033 | val_0_mse: 3.9999998989515007e-05|  0:00:40s\n","epoch 29 | loss: 0.00032 | val_0_mse: 3.9999998989515007e-05|  0:00:41s\n","epoch 30 | loss: 0.00031 | val_0_mse: 3.9999998989515007e-05|  0:00:43s\n","epoch 31 | loss: 0.00031 | val_0_mse: 4.999999873689376e-05|  0:00:44s\n","epoch 32 | loss: 0.0003  | val_0_mse: 7.000000186963007e-05|  0:00:45s\n","epoch 33 | loss: 0.00029 | val_0_mse: 4.999999873689376e-05|  0:00:47s\n","epoch 34 | loss: 0.00029 | val_0_mse: 4.999999873689376e-05|  0:00:48s\n","epoch 35 | loss: 0.00027 | val_0_mse: 2.9999999242136255e-05|  0:00:50s\n","epoch 36 | loss: 0.00026 | val_0_mse: 3.9999998989515007e-05|  0:00:51s\n","epoch 37 | loss: 0.00026 | val_0_mse: 3.9999998989515007e-05|  0:00:52s\n","epoch 38 | loss: 0.00027 | val_0_mse: 1.9999999494757503e-05|  0:00:54s\n","epoch 39 | loss: 0.00025 | val_0_mse: 1.9999999494757503e-05|  0:00:55s\n","epoch 40 | loss: 0.00024 | val_0_mse: 1.9999999494757503e-05|  0:00:56s\n","epoch 41 | loss: 0.00024 | val_0_mse: 1.9999999494757503e-05|  0:00:58s\n","epoch 42 | loss: 0.00026 | val_0_mse: 4.999999873689376e-05|  0:00:59s\n","epoch 43 | loss: 0.00031 | val_0_mse: 9.000000136438757e-05|  0:01:01s\n","epoch 44 | loss: 0.00033 | val_0_mse: 7.000000186963007e-05|  0:01:02s\n","epoch 45 | loss: 0.00031 | val_0_mse: 4.999999873689376e-05|  0:01:04s\n","epoch 46 | loss: 0.00031 | val_0_mse: 4.999999873689376e-05|  0:01:05s\n","epoch 47 | loss: 0.00028 | val_0_mse: 2.9999999242136255e-05|  0:01:06s\n","epoch 48 | loss: 0.00027 | val_0_mse: 4.999999873689376e-05|  0:01:08s\n","epoch 49 | loss: 0.00026 | val_0_mse: 3.9999998989515007e-05|  0:01:09s\n","\n","Early stopping occurred at epoch 49 with best_epoch = 39 and best_val_0_mse = 1.9999999494757503e-05\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 09:53:09,720] Trial 82 finished with value: 2.0822111764573492e-05 and parameters: {'n_d': 44, 'n_steps': 8, 'gamma': 1.8972761622958212, 'n_independent': 5, 'n_shared': 3, 'momentum': 0.34812532617687486}. Best is trial 20 with value: 1.2763081258526654e-07.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 4.68607 | val_0_mse: 70.62300109863281|  0:00:00s\n","epoch 1  | loss: 2.50322 | val_0_mse: 4.316450119018555|  0:00:02s\n","epoch 2  | loss: 1.48945 | val_0_mse: 0.6729300022125244|  0:00:03s\n","epoch 3  | loss: 1.16374 | val_0_mse: 0.2677299976348877|  0:00:04s\n","epoch 4  | loss: 1.21198 | val_0_mse: 0.1304599940776825|  0:00:05s\n","epoch 5  | loss: 2.58152 | val_0_mse: 0.13907000422477722|  0:00:06s\n","epoch 6  | loss: 0.83578 | val_0_mse: 0.21046000719070435|  0:00:07s\n","epoch 7  | loss: 0.57616 | val_0_mse: 0.06678000092506409|  0:00:08s\n","epoch 8  | loss: 0.14653 | val_0_mse: 0.03316999971866608|  0:00:09s\n","epoch 9  | loss: 0.09766 | val_0_mse: 0.01537999976426363|  0:00:10s\n","epoch 10 | loss: 0.05833 | val_0_mse: 0.004809999838471413|  0:00:11s\n","epoch 11 | loss: 0.01776 | val_0_mse: 0.004389999900013208|  0:00:12s\n","epoch 12 | loss: 0.00886 | val_0_mse: 0.001120000029914081|  0:00:13s\n","epoch 13 | loss: 0.00484 | val_0_mse: 0.0006500000017695129|  0:00:14s\n","epoch 14 | loss: 0.00297 | val_0_mse: 0.0009399999980814755|  0:00:15s\n","epoch 15 | loss: 0.00185 | val_0_mse: 0.00039999998989515007|  0:00:16s\n","epoch 16 | loss: 0.00145 | val_0_mse: 0.00044999999227002263|  0:00:17s\n","epoch 17 | loss: 0.00118 | val_0_mse: 0.0003600000054575503|  0:00:18s\n","epoch 18 | loss: 0.00089 | val_0_mse: 0.0002099999983329326|  0:00:19s\n","epoch 19 | loss: 0.00085 | val_0_mse: 0.0002500000118743628|  0:00:20s\n","epoch 20 | loss: 0.00098 | val_0_mse: 0.00016999999934341758|  0:00:21s\n","epoch 21 | loss: 0.00069 | val_0_mse: 0.00016999999934341758|  0:00:22s\n","epoch 22 | loss: 0.00063 | val_0_mse: 0.00033000000985339284|  0:00:23s\n","epoch 23 | loss: 0.00064 | val_0_mse: 7.999999797903001e-05|  0:00:24s\n","epoch 24 | loss: 0.00044 | val_0_mse: 9.000000136438757e-05|  0:00:25s\n","epoch 25 | loss: 0.00036 | val_0_mse: 9.999999747378752e-05|  0:00:26s\n","epoch 26 | loss: 0.00033 | val_0_mse: 0.0001500000071246177|  0:00:27s\n","epoch 27 | loss: 0.00033 | val_0_mse: 9.000000136438757e-05|  0:00:28s\n","epoch 28 | loss: 0.00033 | val_0_mse: 7.000000186963007e-05|  0:00:29s\n","epoch 29 | loss: 0.00028 | val_0_mse: 3.9999998989515007e-05|  0:00:30s\n","epoch 30 | loss: 0.00027 | val_0_mse: 4.999999873689376e-05|  0:00:32s\n","epoch 31 | loss: 0.00026 | val_0_mse: 5.999999848427251e-05|  0:00:33s\n","epoch 32 | loss: 0.00024 | val_0_mse: 4.999999873689376e-05|  0:00:34s\n","epoch 33 | loss: 0.00025 | val_0_mse: 5.999999848427251e-05|  0:00:35s\n","epoch 34 | loss: 0.00021 | val_0_mse: 1.9999999494757503e-05|  0:00:36s\n","epoch 35 | loss: 0.00021 | val_0_mse: 4.999999873689376e-05|  0:00:37s\n","epoch 36 | loss: 0.00022 | val_0_mse: 4.999999873689376e-05|  0:00:38s\n","epoch 37 | loss: 0.00022 | val_0_mse: 3.9999998989515007e-05|  0:00:39s\n","epoch 38 | loss: 0.0002  | val_0_mse: 2.9999999242136255e-05|  0:00:40s\n","epoch 39 | loss: 0.0002  | val_0_mse: 3.9999998989515007e-05|  0:00:41s\n","epoch 40 | loss: 0.00019 | val_0_mse: 1.9999999494757503e-05|  0:00:42s\n","epoch 41 | loss: 0.00021 | val_0_mse: 3.9999998989515007e-05|  0:00:43s\n","epoch 42 | loss: 0.00024 | val_0_mse: 1.9999999494757503e-05|  0:00:44s\n","epoch 43 | loss: 0.00025 | val_0_mse: 1.9999999494757503e-05|  0:00:45s\n","epoch 44 | loss: 0.00021 | val_0_mse: 1.9999999494757503e-05|  0:00:46s\n","epoch 45 | loss: 0.00019 | val_0_mse: 1.9999999494757503e-05|  0:00:47s\n","epoch 46 | loss: 0.00021 | val_0_mse: 1.9999999494757503e-05|  0:00:48s\n","epoch 47 | loss: 0.00026 | val_0_mse: 2.9999999242136255e-05|  0:00:49s\n","epoch 48 | loss: 0.00024 | val_0_mse: 9.999999747378752e-06|  0:00:50s\n","epoch 49 | loss: 0.00021 | val_0_mse: 9.999999747378752e-06|  0:00:51s\n","epoch 50 | loss: 0.00021 | val_0_mse: 9.999999747378752e-06|  0:00:52s\n","epoch 51 | loss: 0.0002  | val_0_mse: 9.999999747378752e-06|  0:00:53s\n","epoch 52 | loss: 0.0002  | val_0_mse: 1.9999999494757503e-05|  0:00:54s\n","epoch 53 | loss: 0.00024 | val_0_mse: 1.9999999494757503e-05|  0:00:55s\n","epoch 54 | loss: 0.00021 | val_0_mse: 9.999999747378752e-06|  0:00:57s\n","epoch 55 | loss: 0.00021 | val_0_mse: 9.999999747378752e-06|  0:00:58s\n","epoch 56 | loss: 0.00018 | val_0_mse: 1.9999999494757503e-05|  0:00:59s\n","epoch 57 | loss: 0.00017 | val_0_mse: 9.999999747378752e-06|  0:01:00s\n","epoch 58 | loss: 0.00016 | val_0_mse: 9.999999747378752e-06|  0:01:01s\n","epoch 59 | loss: 0.00017 | val_0_mse: 1.9999999494757503e-05|  0:01:02s\n","epoch 60 | loss: 0.00018 | val_0_mse: 3.9999998989515007e-05|  0:01:03s\n","epoch 61 | loss: 0.00019 | val_0_mse: 1.9999999494757503e-05|  0:01:04s\n","epoch 62 | loss: 0.00017 | val_0_mse: 1.9999999494757503e-05|  0:01:05s\n","epoch 63 | loss: 0.00016 | val_0_mse: 9.999999747378752e-06|  0:01:06s\n","epoch 64 | loss: 0.00015 | val_0_mse: 0.0     |  0:01:07s\n","epoch 65 | loss: 0.00014 | val_0_mse: 0.0     |  0:01:08s\n","epoch 66 | loss: 0.00014 | val_0_mse: 0.0     |  0:01:09s\n","epoch 67 | loss: 0.00014 | val_0_mse: 0.0     |  0:01:10s\n","epoch 68 | loss: 0.00014 | val_0_mse: 9.999999747378752e-06|  0:01:11s\n","epoch 69 | loss: 0.00014 | val_0_mse: 9.999999747378752e-06|  0:01:12s\n","epoch 70 | loss: 0.00013 | val_0_mse: 0.0     |  0:01:13s\n","epoch 71 | loss: 0.00013 | val_0_mse: 0.0     |  0:01:14s\n","epoch 72 | loss: 0.00013 | val_0_mse: 0.0     |  0:01:15s\n","epoch 73 | loss: 0.00013 | val_0_mse: 0.0     |  0:01:16s\n","epoch 74 | loss: 0.00012 | val_0_mse: 0.0     |  0:01:17s\n","epoch 75 | loss: 0.00012 | val_0_mse: 9.999999747378752e-06|  0:01:18s\n","epoch 76 | loss: 0.00012 | val_0_mse: 0.0     |  0:01:19s\n","epoch 77 | loss: 0.00012 | val_0_mse: 0.0     |  0:01:20s\n","epoch 78 | loss: 0.00012 | val_0_mse: 0.0     |  0:01:21s\n","epoch 79 | loss: 0.00012 | val_0_mse: 0.0     |  0:01:22s\n","epoch 80 | loss: 0.00012 | val_0_mse: 0.0     |  0:01:23s\n","epoch 81 | loss: 0.00012 | val_0_mse: 0.0     |  0:01:24s\n","epoch 82 | loss: 0.00012 | val_0_mse: 0.0     |  0:01:25s\n","epoch 83 | loss: 0.00012 | val_0_mse: 0.0     |  0:01:26s\n","epoch 84 | loss: 0.00012 | val_0_mse: 0.0     |  0:01:28s\n","epoch 85 | loss: 0.00012 | val_0_mse: 0.0     |  0:01:29s\n","epoch 86 | loss: 0.00012 | val_0_mse: 0.0     |  0:01:30s\n","epoch 87 | loss: 0.00012 | val_0_mse: 0.0     |  0:01:31s\n","epoch 88 | loss: 0.00012 | val_0_mse: 0.0     |  0:01:32s\n","epoch 89 | loss: 0.00012 | val_0_mse: 9.999999747378752e-06|  0:01:33s\n","epoch 90 | loss: 0.00012 | val_0_mse: 0.0     |  0:01:34s\n","epoch 91 | loss: 0.00012 | val_0_mse: 0.0     |  0:01:35s\n","epoch 92 | loss: 0.00012 | val_0_mse: 0.0     |  0:01:36s\n","epoch 93 | loss: 0.00012 | val_0_mse: 0.0     |  0:01:37s\n","epoch 94 | loss: 0.00012 | val_0_mse: 0.0     |  0:01:38s\n","epoch 95 | loss: 0.00012 | val_0_mse: 0.0     |  0:01:39s\n","epoch 96 | loss: 0.00012 | val_0_mse: 0.0     |  0:01:40s\n","epoch 97 | loss: 0.00012 | val_0_mse: 0.0     |  0:01:41s\n","epoch 98 | loss: 0.00012 | val_0_mse: 0.0     |  0:01:42s\n","epoch 99 | loss: 0.00011 | val_0_mse: 0.0     |  0:01:43s\n","Stop training because you reached max_epochs = 100 with best_epoch = 98 and best_val_0_mse = 0.0\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 09:54:53,792] Trial 83 finished with value: 1.2998740430703037e-06 and parameters: {'n_d': 39, 'n_steps': 7, 'gamma': 1.972036128996197, 'n_independent': 2, 'n_shared': 4, 'momentum': 0.3896405085450193}. Best is trial 20 with value: 1.2763081258526654e-07.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 3.48929 | val_0_mse: 6.679930210113525|  0:00:00s\n","epoch 1  | loss: 0.97435 | val_0_mse: 0.9018099904060364|  0:00:01s\n","epoch 2  | loss: 0.46356 | val_0_mse: 0.453249990940094|  0:00:02s\n","epoch 3  | loss: 0.32375 | val_0_mse: 0.3721800148487091|  0:00:03s\n","epoch 4  | loss: 0.23226 | val_0_mse: 0.10423000156879425|  0:00:04s\n","epoch 5  | loss: 0.31948 | val_0_mse: 0.14975999295711517|  0:00:04s\n","epoch 6  | loss: 0.26478 | val_0_mse: 0.13155999779701233|  0:00:05s\n","epoch 7  | loss: 0.26346 | val_0_mse: 0.0516900010406971|  0:00:06s\n","epoch 8  | loss: 0.2041  | val_0_mse: 0.04772999882698059|  0:00:07s\n","epoch 9  | loss: 0.17186 | val_0_mse: 0.01128000020980835|  0:00:07s\n","epoch 10 | loss: 0.05288 | val_0_mse: 0.0031399999279528856|  0:00:08s\n","epoch 11 | loss: 0.01329 | val_0_mse: 0.0019199999514967203|  0:00:09s\n","epoch 12 | loss: 0.00727 | val_0_mse: 0.0007999999797903001|  0:00:10s\n","epoch 13 | loss: 0.00415 | val_0_mse: 0.000699999975040555|  0:00:11s\n","epoch 14 | loss: 0.00258 | val_0_mse: 0.00041000000783242285|  0:00:12s\n","epoch 15 | loss: 0.00126 | val_0_mse: 0.00019999999494757503|  0:00:12s\n","epoch 16 | loss: 0.00067 | val_0_mse: 0.00016999999934341758|  0:00:13s\n","epoch 17 | loss: 0.00043 | val_0_mse: 2.9999999242136255e-05|  0:00:14s\n","epoch 18 | loss: 0.00029 | val_0_mse: 3.9999998989515007e-05|  0:00:15s\n","epoch 19 | loss: 0.00024 | val_0_mse: 1.9999999494757503e-05|  0:00:16s\n","epoch 20 | loss: 0.0002  | val_0_mse: 9.999999747378752e-06|  0:00:17s\n","epoch 21 | loss: 0.00019 | val_0_mse: 0.0     |  0:00:17s\n","epoch 22 | loss: 0.00018 | val_0_mse: 0.0     |  0:00:18s\n","epoch 23 | loss: 0.00017 | val_0_mse: 0.0     |  0:00:19s\n","epoch 24 | loss: 0.00016 | val_0_mse: 0.0     |  0:00:20s\n","epoch 25 | loss: 0.00016 | val_0_mse: 0.0     |  0:00:21s\n","epoch 26 | loss: 0.00016 | val_0_mse: 0.0     |  0:00:21s\n","epoch 27 | loss: 0.00016 | val_0_mse: 0.0     |  0:00:22s\n","epoch 28 | loss: 0.00016 | val_0_mse: 0.0     |  0:00:23s\n","epoch 29 | loss: 0.00015 | val_0_mse: 0.0     |  0:00:24s\n","epoch 30 | loss: 0.00015 | val_0_mse: 0.0     |  0:00:25s\n","epoch 31 | loss: 0.00015 | val_0_mse: 0.0     |  0:00:25s\n","epoch 32 | loss: 0.00015 | val_0_mse: 0.0     |  0:00:26s\n","epoch 33 | loss: 0.00015 | val_0_mse: 0.0     |  0:00:27s\n","epoch 34 | loss: 0.00015 | val_0_mse: 0.0     |  0:00:28s\n","epoch 35 | loss: 0.00015 | val_0_mse: 0.0     |  0:00:29s\n","epoch 36 | loss: 0.00015 | val_0_mse: 0.0     |  0:00:29s\n","epoch 37 | loss: 0.00015 | val_0_mse: 0.0     |  0:00:30s\n","epoch 38 | loss: 0.00015 | val_0_mse: 0.0     |  0:00:31s\n","epoch 39 | loss: 0.00015 | val_0_mse: 0.0     |  0:00:32s\n","epoch 40 | loss: 0.00015 | val_0_mse: 0.0     |  0:00:33s\n","epoch 41 | loss: 0.00015 | val_0_mse: 0.0     |  0:00:33s\n","epoch 42 | loss: 0.00015 | val_0_mse: 0.0     |  0:00:34s\n","epoch 43 | loss: 0.00015 | val_0_mse: 0.0     |  0:00:35s\n","epoch 44 | loss: 0.00015 | val_0_mse: 0.0     |  0:00:36s\n","epoch 45 | loss: 0.00015 | val_0_mse: 0.0     |  0:00:37s\n","epoch 46 | loss: 0.00016 | val_0_mse: 0.0     |  0:00:37s\n","epoch 47 | loss: 0.00016 | val_0_mse: 0.0     |  0:00:38s\n","epoch 48 | loss: 0.00016 | val_0_mse: 0.0     |  0:00:39s\n","epoch 49 | loss: 0.00016 | val_0_mse: 0.0     |  0:00:40s\n","epoch 50 | loss: 0.00016 | val_0_mse: 0.0     |  0:00:41s\n","epoch 51 | loss: 0.00016 | val_0_mse: 0.0     |  0:00:41s\n","epoch 52 | loss: 0.00016 | val_0_mse: 0.0     |  0:00:42s\n","epoch 53 | loss: 0.00016 | val_0_mse: 0.0     |  0:00:43s\n","epoch 54 | loss: 0.00016 | val_0_mse: 0.0     |  0:00:44s\n","epoch 55 | loss: 0.00016 | val_0_mse: 0.0     |  0:00:45s\n","epoch 56 | loss: 0.00016 | val_0_mse: 0.0     |  0:00:45s\n","epoch 57 | loss: 0.00016 | val_0_mse: 0.0     |  0:00:46s\n","epoch 58 | loss: 0.00017 | val_0_mse: 0.0     |  0:00:47s\n","epoch 59 | loss: 0.00017 | val_0_mse: 0.0     |  0:00:48s\n","epoch 60 | loss: 0.00017 | val_0_mse: 0.0     |  0:00:49s\n","epoch 61 | loss: 0.00016 | val_0_mse: 0.0     |  0:00:50s\n","epoch 62 | loss: 0.00016 | val_0_mse: 0.0     |  0:00:50s\n","epoch 63 | loss: 0.00016 | val_0_mse: 0.0     |  0:00:51s\n","\n","Early stopping occurred at epoch 63 with best_epoch = 53 and best_val_0_mse = 0.0\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 09:55:45,997] Trial 84 finished with value: 2.7433060267867404e-07 and parameters: {'n_d': 11, 'n_steps': 9, 'gamma': 1.842467670690055, 'n_independent': 1, 'n_shared': 2, 'momentum': 0.358355684434455}. Best is trial 20 with value: 1.2763081258526654e-07.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 2.80558 | val_0_mse: 19.9168701171875|  0:00:00s\n","epoch 1  | loss: 1.15689 | val_0_mse: 3.696310043334961|  0:00:01s\n","epoch 2  | loss: 0.52679 | val_0_mse: 0.36970001459121704|  0:00:02s\n","epoch 3  | loss: 0.20959 | val_0_mse: 0.32315000891685486|  0:00:03s\n","epoch 4  | loss: 0.20268 | val_0_mse: 0.15373000502586365|  0:00:03s\n","epoch 5  | loss: 0.36381 | val_0_mse: 0.2573400139808655|  0:00:04s\n","epoch 6  | loss: 0.24897 | val_0_mse: 0.011119999922811985|  0:00:05s\n","epoch 7  | loss: 0.17904 | val_0_mse: 0.15727999806404114|  0:00:06s\n","epoch 8  | loss: 0.42177 | val_0_mse: 0.06154999881982803|  0:00:07s\n","epoch 9  | loss: 0.15524 | val_0_mse: 0.005570000037550926|  0:00:07s\n","epoch 10 | loss: 0.01241 | val_0_mse: 0.0011599999852478504|  0:00:08s\n","epoch 11 | loss: 0.00398 | val_0_mse: 0.0005099999834783375|  0:00:09s\n","epoch 12 | loss: 0.00147 | val_0_mse: 0.0003699999942909926|  0:00:10s\n","epoch 13 | loss: 0.00074 | val_0_mse: 0.00011000000085914508|  0:00:10s\n","epoch 14 | loss: 0.00054 | val_0_mse: 5.999999848427251e-05|  0:00:11s\n","epoch 15 | loss: 0.00045 | val_0_mse: 3.9999998989515007e-05|  0:00:12s\n","epoch 16 | loss: 0.00039 | val_0_mse: 2.9999999242136255e-05|  0:00:13s\n","epoch 17 | loss: 0.00036 | val_0_mse: 2.9999999242136255e-05|  0:00:14s\n","epoch 18 | loss: 0.00034 | val_0_mse: 1.9999999494757503e-05|  0:00:14s\n","epoch 19 | loss: 0.00033 | val_0_mse: 1.9999999494757503e-05|  0:00:15s\n","epoch 20 | loss: 0.00032 | val_0_mse: 1.9999999494757503e-05|  0:00:16s\n","epoch 21 | loss: 0.00031 | val_0_mse: 9.999999747378752e-06|  0:00:17s\n","epoch 22 | loss: 0.0003  | val_0_mse: 9.999999747378752e-06|  0:00:18s\n","epoch 23 | loss: 0.00029 | val_0_mse: 1.9999999494757503e-05|  0:00:18s\n","epoch 24 | loss: 0.00028 | val_0_mse: 9.999999747378752e-06|  0:00:19s\n","epoch 25 | loss: 0.00027 | val_0_mse: 9.999999747378752e-06|  0:00:20s\n","epoch 26 | loss: 0.00026 | val_0_mse: 9.999999747378752e-06|  0:00:21s\n","epoch 27 | loss: 0.00026 | val_0_mse: 1.9999999494757503e-05|  0:00:22s\n","epoch 28 | loss: 0.00025 | val_0_mse: 9.999999747378752e-06|  0:00:22s\n","epoch 29 | loss: 0.00026 | val_0_mse: 1.9999999494757503e-05|  0:00:23s\n","epoch 30 | loss: 0.00026 | val_0_mse: 9.999999747378752e-06|  0:00:24s\n","epoch 31 | loss: 0.00024 | val_0_mse: 9.999999747378752e-06|  0:00:25s\n","epoch 32 | loss: 0.00024 | val_0_mse: 9.999999747378752e-06|  0:00:25s\n","epoch 33 | loss: 0.00024 | val_0_mse: 0.0     |  0:00:26s\n","epoch 34 | loss: 0.00023 | val_0_mse: 9.999999747378752e-06|  0:00:27s\n","epoch 35 | loss: 0.00023 | val_0_mse: 9.999999747378752e-06|  0:00:28s\n","epoch 36 | loss: 0.00023 | val_0_mse: 0.0     |  0:00:29s\n","epoch 37 | loss: 0.00023 | val_0_mse: 0.0     |  0:00:30s\n","epoch 38 | loss: 0.00023 | val_0_mse: 0.0     |  0:00:30s\n","epoch 39 | loss: 0.00022 | val_0_mse: 0.0     |  0:00:31s\n","epoch 40 | loss: 0.00021 | val_0_mse: 9.999999747378752e-06|  0:00:32s\n","epoch 41 | loss: 0.00021 | val_0_mse: 0.0     |  0:00:33s\n","epoch 42 | loss: 0.00021 | val_0_mse: 0.0     |  0:00:33s\n","epoch 43 | loss: 0.00021 | val_0_mse: 0.0     |  0:00:34s\n","epoch 44 | loss: 0.0002  | val_0_mse: 0.0     |  0:00:35s\n","epoch 45 | loss: 0.00019 | val_0_mse: 0.0     |  0:00:36s\n","epoch 46 | loss: 0.00018 | val_0_mse: 0.0     |  0:00:37s\n","epoch 47 | loss: 0.00018 | val_0_mse: 0.0     |  0:00:37s\n","epoch 48 | loss: 0.00017 | val_0_mse: 0.0     |  0:00:38s\n","epoch 49 | loss: 0.00017 | val_0_mse: 0.0     |  0:00:39s\n","epoch 50 | loss: 0.00017 | val_0_mse: 0.0     |  0:00:40s\n","epoch 51 | loss: 0.00017 | val_0_mse: 0.0     |  0:00:40s\n","epoch 52 | loss: 0.00018 | val_0_mse: 0.0     |  0:00:41s\n","epoch 53 | loss: 0.00018 | val_0_mse: 0.0     |  0:00:42s\n","epoch 54 | loss: 0.00019 | val_0_mse: 0.0     |  0:00:43s\n","epoch 55 | loss: 0.00019 | val_0_mse: 0.0     |  0:00:43s\n","epoch 56 | loss: 0.00019 | val_0_mse: 0.0     |  0:00:44s\n","epoch 57 | loss: 0.00019 | val_0_mse: 0.0     |  0:00:45s\n","epoch 58 | loss: 0.00018 | val_0_mse: 0.0     |  0:00:46s\n","epoch 59 | loss: 0.00018 | val_0_mse: 0.0     |  0:00:47s\n","epoch 60 | loss: 0.00018 | val_0_mse: 0.0     |  0:00:47s\n","epoch 61 | loss: 0.00018 | val_0_mse: 0.0     |  0:00:48s\n","epoch 62 | loss: 0.00018 | val_0_mse: 0.0     |  0:00:49s\n","epoch 63 | loss: 0.00018 | val_0_mse: 0.0     |  0:00:50s\n","epoch 64 | loss: 0.00019 | val_0_mse: 0.0     |  0:00:50s\n","epoch 65 | loss: 0.00018 | val_0_mse: 0.0     |  0:00:51s\n","epoch 66 | loss: 0.00017 | val_0_mse: 0.0     |  0:00:52s\n","epoch 67 | loss: 0.00018 | val_0_mse: 0.0     |  0:00:53s\n","epoch 68 | loss: 0.00019 | val_0_mse: 0.0     |  0:00:54s\n","epoch 69 | loss: 0.00019 | val_0_mse: 0.0     |  0:00:55s\n","epoch 70 | loss: 0.00019 | val_0_mse: 0.0     |  0:00:55s\n","epoch 71 | loss: 0.00018 | val_0_mse: 0.0     |  0:00:56s\n","epoch 72 | loss: 0.00018 | val_0_mse: 0.0     |  0:00:57s\n","epoch 73 | loss: 0.00018 | val_0_mse: 0.0     |  0:00:58s\n","epoch 74 | loss: 0.00017 | val_0_mse: 0.0     |  0:00:59s\n","epoch 75 | loss: 0.00017 | val_0_mse: 0.0     |  0:01:00s\n","epoch 76 | loss: 0.00016 | val_0_mse: 0.0     |  0:01:00s\n","epoch 77 | loss: 0.00017 | val_0_mse: 0.0     |  0:01:01s\n","epoch 78 | loss: 0.00016 | val_0_mse: 0.0     |  0:01:02s\n","epoch 79 | loss: 0.00016 | val_0_mse: 0.0     |  0:01:03s\n","epoch 80 | loss: 0.00016 | val_0_mse: 0.0     |  0:01:04s\n","epoch 81 | loss: 0.00016 | val_0_mse: 0.0     |  0:01:04s\n","epoch 82 | loss: 0.00016 | val_0_mse: 0.0     |  0:01:05s\n","epoch 83 | loss: 0.00016 | val_0_mse: 0.0     |  0:01:06s\n","epoch 84 | loss: 0.00016 | val_0_mse: 0.0     |  0:01:07s\n","\n","Early stopping occurred at epoch 84 with best_epoch = 74 and best_val_0_mse = 0.0\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 09:56:53,771] Trial 85 finished with value: 2.833276369074156e-07 and parameters: {'n_d': 19, 'n_steps': 7, 'gamma': 1.9199353773270862, 'n_independent': 1, 'n_shared': 3, 'momentum': 0.3972205433794322}. Best is trial 20 with value: 1.2763081258526654e-07.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 6.64784 | val_0_mse: 9.559800148010254|  0:00:01s\n","epoch 1  | loss: 2.47349 | val_0_mse: 3.5183498859405518|  0:00:02s\n","epoch 2  | loss: 1.44446 | val_0_mse: 0.1748100072145462|  0:00:03s\n","epoch 3  | loss: 2.13536 | val_0_mse: 0.54721999168396|  0:00:05s\n","epoch 4  | loss: 2.71936 | val_0_mse: 0.5677300095558167|  0:00:06s\n","epoch 5  | loss: 0.89988 | val_0_mse: 0.21151000261306763|  0:00:07s\n","epoch 6  | loss: 0.82698 | val_0_mse: 0.019600000232458115|  0:00:09s\n","epoch 7  | loss: 0.44886 | val_0_mse: 0.1218700036406517|  0:00:10s\n","epoch 8  | loss: 1.11331 | val_0_mse: 0.10847999900579453|  0:00:11s\n","epoch 9  | loss: 0.17925 | val_0_mse: 0.05181000009179115|  0:00:12s\n","epoch 10 | loss: 0.01689 | val_0_mse: 0.0029700000304728746|  0:00:14s\n","epoch 11 | loss: 0.00515 | val_0_mse: 0.0003699999942909926|  0:00:15s\n","epoch 12 | loss: 0.00209 | val_0_mse: 0.0002500000118743628|  0:00:16s\n","epoch 13 | loss: 0.00138 | val_0_mse: 0.0002899999963119626|  0:00:18s\n","epoch 14 | loss: 0.00103 | val_0_mse: 0.00022000000171829015|  0:00:19s\n","epoch 15 | loss: 0.00088 | val_0_mse: 0.00013000000035390258|  0:00:20s\n","epoch 16 | loss: 0.00068 | val_0_mse: 9.999999747378752e-05|  0:00:22s\n","epoch 17 | loss: 0.00062 | val_0_mse: 0.0001900000061141327|  0:00:23s\n","epoch 18 | loss: 0.00055 | val_0_mse: 3.9999998989515007e-05|  0:00:25s\n","epoch 19 | loss: 0.00058 | val_0_mse: 4.999999873689376e-05|  0:00:26s\n","epoch 20 | loss: 0.00059 | val_0_mse: 7.000000186963007e-05|  0:00:27s\n","epoch 21 | loss: 0.00048 | val_0_mse: 5.999999848427251e-05|  0:00:29s\n","epoch 22 | loss: 0.00047 | val_0_mse: 4.999999873689376e-05|  0:00:30s\n","epoch 23 | loss: 0.00043 | val_0_mse: 0.00011000000085914508|  0:00:31s\n","epoch 24 | loss: 0.00044 | val_0_mse: 7.999999797903001e-05|  0:00:33s\n","epoch 25 | loss: 0.00038 | val_0_mse: 9.000000136438757e-05|  0:00:34s\n","epoch 26 | loss: 0.00034 | val_0_mse: 4.999999873689376e-05|  0:00:35s\n","epoch 27 | loss: 0.00031 | val_0_mse: 4.999999873689376e-05|  0:00:36s\n","epoch 28 | loss: 0.00033 | val_0_mse: 4.999999873689376e-05|  0:00:38s\n","\n","Early stopping occurred at epoch 28 with best_epoch = 18 and best_val_0_mse = 3.9999998989515007e-05\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 09:57:32,770] Trial 86 finished with value: 4.135939525440335e-05 and parameters: {'n_d': 32, 'n_steps': 8, 'gamma': 1.7353643705675317, 'n_independent': 5, 'n_shared': 2, 'momentum': 0.21959482606735042}. Best is trial 20 with value: 1.2763081258526654e-07.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 3.69602 | val_0_mse: 10.702249526977539|  0:00:00s\n","epoch 1  | loss: 1.03297 | val_0_mse: 1.422819972038269|  0:00:01s\n","epoch 2  | loss: 0.74199 | val_0_mse: 0.3529300093650818|  0:00:02s\n","epoch 3  | loss: 0.38491 | val_0_mse: 0.7910000085830688|  0:00:03s\n","epoch 4  | loss: 0.40362 | val_0_mse: 0.1385200023651123|  0:00:04s\n","epoch 5  | loss: 0.17327 | val_0_mse: 0.07914000004529953|  0:00:05s\n","epoch 6  | loss: 0.08057 | val_0_mse: 0.06266000121831894|  0:00:05s\n","epoch 7  | loss: 0.02735 | val_0_mse: 0.01834000088274479|  0:00:06s\n","epoch 8  | loss: 0.01698 | val_0_mse: 0.003710000077262521|  0:00:07s\n","epoch 9  | loss: 0.00888 | val_0_mse: 0.0020000000949949026|  0:00:08s\n","epoch 10 | loss: 0.00501 | val_0_mse: 0.0019499999471008778|  0:00:09s\n","epoch 11 | loss: 0.00294 | val_0_mse: 0.0006099999882280827|  0:00:10s\n","epoch 12 | loss: 0.00205 | val_0_mse: 0.0004799999878741801|  0:00:10s\n","epoch 13 | loss: 0.00143 | val_0_mse: 0.00026000000070780516|  0:00:11s\n","epoch 14 | loss: 0.00114 | val_0_mse: 0.00015999999595806003|  0:00:12s\n","epoch 15 | loss: 0.001   | val_0_mse: 0.0001900000061141327|  0:00:13s\n","epoch 16 | loss: 0.00095 | val_0_mse: 0.00011000000085914508|  0:00:14s\n","epoch 17 | loss: 0.00085 | val_0_mse: 0.00013000000035390258|  0:00:14s\n","epoch 18 | loss: 0.00082 | val_0_mse: 0.0002099999983329326|  0:00:15s\n","epoch 19 | loss: 0.00077 | val_0_mse: 9.999999747378752e-05|  0:00:16s\n","epoch 20 | loss: 0.0007  | val_0_mse: 0.00013000000035390258|  0:00:17s\n","epoch 21 | loss: 0.00068 | val_0_mse: 7.000000186963007e-05|  0:00:18s\n","epoch 22 | loss: 0.00065 | val_0_mse: 7.000000186963007e-05|  0:00:19s\n","epoch 23 | loss: 0.00065 | val_0_mse: 0.00011000000085914508|  0:00:19s\n","epoch 24 | loss: 0.00062 | val_0_mse: 7.999999797903001e-05|  0:00:20s\n","epoch 25 | loss: 0.00063 | val_0_mse: 7.000000186963007e-05|  0:00:21s\n","epoch 26 | loss: 0.00062 | val_0_mse: 7.999999797903001e-05|  0:00:22s\n","epoch 27 | loss: 0.00065 | val_0_mse: 4.999999873689376e-05|  0:00:23s\n","epoch 28 | loss: 0.00058 | val_0_mse: 5.999999848427251e-05|  0:00:23s\n","epoch 29 | loss: 0.00054 | val_0_mse: 4.999999873689376e-05|  0:00:24s\n","epoch 30 | loss: 0.00058 | val_0_mse: 7.999999797903001e-05|  0:00:25s\n","epoch 31 | loss: 0.00055 | val_0_mse: 3.9999998989515007e-05|  0:00:26s\n","epoch 32 | loss: 0.00052 | val_0_mse: 4.999999873689376e-05|  0:00:27s\n","epoch 33 | loss: 0.0005  | val_0_mse: 3.9999998989515007e-05|  0:00:28s\n","epoch 34 | loss: 0.00049 | val_0_mse: 4.999999873689376e-05|  0:00:28s\n","epoch 35 | loss: 0.00048 | val_0_mse: 4.999999873689376e-05|  0:00:29s\n","epoch 36 | loss: 0.00051 | val_0_mse: 4.999999873689376e-05|  0:00:30s\n","epoch 37 | loss: 0.00049 | val_0_mse: 4.999999873689376e-05|  0:00:31s\n","epoch 38 | loss: 0.00046 | val_0_mse: 4.999999873689376e-05|  0:00:31s\n","epoch 39 | loss: 0.00045 | val_0_mse: 2.9999999242136255e-05|  0:00:32s\n","epoch 40 | loss: 0.00045 | val_0_mse: 3.9999998989515007e-05|  0:00:33s\n","epoch 41 | loss: 0.00043 | val_0_mse: 2.9999999242136255e-05|  0:00:34s\n","epoch 42 | loss: 0.00041 | val_0_mse: 2.9999999242136255e-05|  0:00:35s\n","epoch 43 | loss: 0.00042 | val_0_mse: 4.999999873689376e-05|  0:00:36s\n","epoch 44 | loss: 0.00042 | val_0_mse: 1.9999999494757503e-05|  0:00:36s\n","epoch 45 | loss: 0.00041 | val_0_mse: 3.9999998989515007e-05|  0:00:37s\n","epoch 46 | loss: 0.00041 | val_0_mse: 3.9999998989515007e-05|  0:00:38s\n","epoch 47 | loss: 0.00038 | val_0_mse: 1.9999999494757503e-05|  0:00:39s\n","epoch 48 | loss: 0.00039 | val_0_mse: 1.9999999494757503e-05|  0:00:40s\n","epoch 49 | loss: 0.00039 | val_0_mse: 2.9999999242136255e-05|  0:00:40s\n","epoch 50 | loss: 0.00037 | val_0_mse: 1.9999999494757503e-05|  0:00:41s\n","epoch 51 | loss: 0.00036 | val_0_mse: 2.9999999242136255e-05|  0:00:42s\n","epoch 52 | loss: 0.00036 | val_0_mse: 3.9999998989515007e-05|  0:00:43s\n","epoch 53 | loss: 0.00035 | val_0_mse: 1.9999999494757503e-05|  0:00:43s\n","epoch 54 | loss: 0.00035 | val_0_mse: 1.9999999494757503e-05|  0:00:44s\n","epoch 55 | loss: 0.00035 | val_0_mse: 1.9999999494757503e-05|  0:00:45s\n","epoch 56 | loss: 0.00034 | val_0_mse: 4.999999873689376e-05|  0:00:46s\n","epoch 57 | loss: 0.00035 | val_0_mse: 1.9999999494757503e-05|  0:00:47s\n","epoch 58 | loss: 0.00034 | val_0_mse: 4.999999873689376e-05|  0:00:48s\n","epoch 59 | loss: 0.00034 | val_0_mse: 1.9999999494757503e-05|  0:00:48s\n","epoch 60 | loss: 0.00034 | val_0_mse: 1.9999999494757503e-05|  0:00:49s\n","\n","Early stopping occurred at epoch 60 with best_epoch = 50 and best_val_0_mse = 1.9999999494757503e-05\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 09:58:22,917] Trial 87 finished with value: 1.7065476640709676e-05 and parameters: {'n_d': 37, 'n_steps': 6, 'gamma': 1.3164403543240395, 'n_independent': 2, 'n_shared': 3, 'momentum': 0.3381075331997485}. Best is trial 20 with value: 1.2763081258526654e-07.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 4.74035 | val_0_mse: 2.20307993888855|  0:00:01s\n","epoch 1  | loss: 3.61186 | val_0_mse: 0.7253400087356567|  0:00:02s\n","epoch 2  | loss: 8.67279 | val_0_mse: 78.12882995605469|  0:00:03s\n","epoch 3  | loss: 37.57607| val_0_mse: 3.408400058746338|  0:00:04s\n","epoch 4  | loss: 3.26524 | val_0_mse: 0.5592799782752991|  0:00:05s\n","epoch 5  | loss: 6.23359 | val_0_mse: 0.34961000084877014|  0:00:07s\n","epoch 6  | loss: 1.93203 | val_0_mse: 1.1077200174331665|  0:00:08s\n","epoch 7  | loss: 0.97119 | val_0_mse: 0.06798999756574631|  0:00:09s\n","epoch 8  | loss: 0.15878 | val_0_mse: 0.020719999447464943|  0:00:10s\n","epoch 9  | loss: 0.17405 | val_0_mse: 0.07673999667167664|  0:00:11s\n","epoch 10 | loss: 0.11637 | val_0_mse: 0.010160000063478947|  0:00:12s\n","epoch 11 | loss: 0.075   | val_0_mse: 0.00892999954521656|  0:00:13s\n","epoch 12 | loss: 0.02602 | val_0_mse: 0.0038300000596791506|  0:00:15s\n","epoch 13 | loss: 0.01197 | val_0_mse: 0.0012499999720603228|  0:00:16s\n","epoch 14 | loss: 0.00401 | val_0_mse: 0.0004600000102072954|  0:00:17s\n","epoch 15 | loss: 0.00217 | val_0_mse: 0.0004400000034365803|  0:00:18s\n","epoch 16 | loss: 0.00132 | val_0_mse: 0.0003100000030826777|  0:00:19s\n","epoch 17 | loss: 0.00092 | val_0_mse: 0.00016999999934341758|  0:00:20s\n","epoch 18 | loss: 0.00064 | val_0_mse: 0.00011999999696854502|  0:00:21s\n","epoch 19 | loss: 0.00059 | val_0_mse: 9.999999747378752e-05|  0:00:23s\n","epoch 20 | loss: 0.00053 | val_0_mse: 0.00011999999696854502|  0:00:24s\n","epoch 21 | loss: 0.00046 | val_0_mse: 7.999999797903001e-05|  0:00:25s\n","epoch 22 | loss: 0.0004  | val_0_mse: 7.000000186963007e-05|  0:00:26s\n","epoch 23 | loss: 0.00038 | val_0_mse: 7.000000186963007e-05|  0:00:27s\n","epoch 24 | loss: 0.0004  | val_0_mse: 2.9999999242136255e-05|  0:00:28s\n","epoch 25 | loss: 0.00033 | val_0_mse: 7.999999797903001e-05|  0:00:29s\n","epoch 26 | loss: 0.00039 | val_0_mse: 4.999999873689376e-05|  0:00:31s\n","epoch 27 | loss: 0.00041 | val_0_mse: 4.999999873689376e-05|  0:00:32s\n","epoch 28 | loss: 0.00037 | val_0_mse: 7.000000186963007e-05|  0:00:33s\n","epoch 29 | loss: 0.00034 | val_0_mse: 5.999999848427251e-05|  0:00:34s\n","epoch 30 | loss: 0.00028 | val_0_mse: 3.9999998989515007e-05|  0:00:35s\n","epoch 31 | loss: 0.00026 | val_0_mse: 3.9999998989515007e-05|  0:00:36s\n","epoch 32 | loss: 0.00023 | val_0_mse: 3.9999998989515007e-05|  0:00:38s\n","epoch 33 | loss: 0.00022 | val_0_mse: 1.9999999494757503e-05|  0:00:39s\n","epoch 34 | loss: 0.00022 | val_0_mse: 2.9999999242136255e-05|  0:00:40s\n","epoch 35 | loss: 0.00023 | val_0_mse: 1.9999999494757503e-05|  0:00:41s\n","epoch 36 | loss: 0.00021 | val_0_mse: 1.9999999494757503e-05|  0:00:42s\n","epoch 37 | loss: 0.00024 | val_0_mse: 1.9999999494757503e-05|  0:00:43s\n","epoch 38 | loss: 0.00021 | val_0_mse: 1.9999999494757503e-05|  0:00:44s\n","epoch 39 | loss: 0.0002  | val_0_mse: 2.9999999242136255e-05|  0:00:46s\n","epoch 40 | loss: 0.00018 | val_0_mse: 1.9999999494757503e-05|  0:00:47s\n","epoch 41 | loss: 0.00019 | val_0_mse: 9.999999747378752e-06|  0:00:48s\n","epoch 42 | loss: 0.00018 | val_0_mse: 9.999999747378752e-06|  0:00:49s\n","epoch 43 | loss: 0.00024 | val_0_mse: 1.9999999494757503e-05|  0:00:50s\n","epoch 44 | loss: 0.00022 | val_0_mse: 9.999999747378752e-06|  0:00:51s\n","epoch 45 | loss: 0.00019 | val_0_mse: 1.9999999494757503e-05|  0:00:52s\n","epoch 46 | loss: 0.00017 | val_0_mse: 1.9999999494757503e-05|  0:00:53s\n","epoch 47 | loss: 0.00016 | val_0_mse: 9.999999747378752e-06|  0:00:55s\n","epoch 48 | loss: 0.00015 | val_0_mse: 1.9999999494757503e-05|  0:00:56s\n","epoch 49 | loss: 0.00015 | val_0_mse: 9.999999747378752e-06|  0:00:57s\n","epoch 50 | loss: 0.00015 | val_0_mse: 9.999999747378752e-06|  0:00:58s\n","epoch 51 | loss: 0.00014 | val_0_mse: 9.999999747378752e-06|  0:00:59s\n","epoch 52 | loss: 0.00013 | val_0_mse: 9.999999747378752e-06|  0:01:00s\n","epoch 53 | loss: 0.00013 | val_0_mse: 9.999999747378752e-06|  0:01:01s\n","epoch 54 | loss: 0.00013 | val_0_mse: 9.999999747378752e-06|  0:01:02s\n","epoch 55 | loss: 0.00013 | val_0_mse: 9.999999747378752e-06|  0:01:04s\n","epoch 56 | loss: 0.00013 | val_0_mse: 9.999999747378752e-06|  0:01:05s\n","epoch 57 | loss: 0.00012 | val_0_mse: 0.0     |  0:01:06s\n","epoch 58 | loss: 0.00012 | val_0_mse: 9.999999747378752e-06|  0:01:07s\n","epoch 59 | loss: 0.00012 | val_0_mse: 9.999999747378752e-06|  0:01:08s\n","epoch 60 | loss: 0.00014 | val_0_mse: 9.999999747378752e-06|  0:01:09s\n","epoch 61 | loss: 0.00013 | val_0_mse: 9.999999747378752e-06|  0:01:11s\n","epoch 62 | loss: 0.00012 | val_0_mse: 9.999999747378752e-06|  0:01:12s\n","epoch 63 | loss: 0.00012 | val_0_mse: 0.0     |  0:01:13s\n","epoch 64 | loss: 0.00011 | val_0_mse: 9.999999747378752e-06|  0:01:14s\n","epoch 65 | loss: 0.00011 | val_0_mse: 0.0     |  0:01:15s\n","epoch 66 | loss: 0.00011 | val_0_mse: 0.0     |  0:01:16s\n","epoch 67 | loss: 0.00011 | val_0_mse: 0.0     |  0:01:17s\n","epoch 68 | loss: 0.00011 | val_0_mse: 9.999999747378752e-06|  0:01:19s\n","epoch 69 | loss: 0.00011 | val_0_mse: 0.0     |  0:01:20s\n","epoch 70 | loss: 0.00011 | val_0_mse: 9.999999747378752e-06|  0:01:21s\n","epoch 71 | loss: 0.0001  | val_0_mse: 0.0     |  0:01:22s\n","epoch 72 | loss: 0.0001  | val_0_mse: 0.0     |  0:01:23s\n","epoch 73 | loss: 0.0001  | val_0_mse: 9.999999747378752e-06|  0:01:24s\n","epoch 74 | loss: 0.0001  | val_0_mse: 0.0     |  0:01:25s\n","epoch 75 | loss: 0.0001  | val_0_mse: 0.0     |  0:01:26s\n","epoch 76 | loss: 0.0001  | val_0_mse: 0.0     |  0:01:28s\n","epoch 77 | loss: 0.0001  | val_0_mse: 0.0     |  0:01:29s\n","epoch 78 | loss: 0.0001  | val_0_mse: 0.0     |  0:01:30s\n","epoch 79 | loss: 0.0001  | val_0_mse: 0.0     |  0:01:31s\n","epoch 80 | loss: 0.0001  | val_0_mse: 0.0     |  0:01:32s\n","epoch 81 | loss: 9e-05   | val_0_mse: 0.0     |  0:01:33s\n","epoch 82 | loss: 9e-05   | val_0_mse: 0.0     |  0:01:34s\n","epoch 83 | loss: 9e-05   | val_0_mse: 0.0     |  0:01:36s\n","epoch 84 | loss: 0.0001  | val_0_mse: 9.999999747378752e-06|  0:01:37s\n","epoch 85 | loss: 9e-05   | val_0_mse: 0.0     |  0:01:38s\n","epoch 86 | loss: 9e-05   | val_0_mse: 9.999999747378752e-06|  0:01:39s\n","epoch 87 | loss: 0.0001  | val_0_mse: 0.0     |  0:01:40s\n","\n","Early stopping occurred at epoch 87 with best_epoch = 77 and best_val_0_mse = 0.0\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 10:00:04,175] Trial 88 finished with value: 2.8763970476575196e-06 and parameters: {'n_d': 55, 'n_steps': 8, 'gamma': 1.9849242012083068, 'n_independent': 2, 'n_shared': 4, 'momentum': 0.1311684387222796}. Best is trial 20 with value: 1.2763081258526654e-07.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 4.23672 | val_0_mse: 12.895469665527344|  0:00:01s\n","epoch 1  | loss: 1.26956 | val_0_mse: 1.3732099533081055|  0:00:02s\n","epoch 2  | loss: 3.7818  | val_0_mse: 1.4896399974822998|  0:00:03s\n","epoch 3  | loss: 1.14618 | val_0_mse: 0.12490999698638916|  0:00:04s\n","epoch 4  | loss: 0.43907 | val_0_mse: 0.09881000220775604|  0:00:05s\n","epoch 5  | loss: 0.22636 | val_0_mse: 0.07161000370979309|  0:00:06s\n","epoch 6  | loss: 0.35719 | val_0_mse: 0.06313999742269516|  0:00:07s\n","epoch 7  | loss: 0.44993 | val_0_mse: 0.33388999104499817|  0:00:08s\n","epoch 8  | loss: 0.51175 | val_0_mse: 0.010540000163018703|  0:00:09s\n","epoch 9  | loss: 0.09481 | val_0_mse: 0.004900000058114529|  0:00:10s\n","epoch 10 | loss: 0.0489  | val_0_mse: 0.011599999852478504|  0:00:11s\n","epoch 11 | loss: 0.02378 | val_0_mse: 0.0022799998987466097|  0:00:12s\n","epoch 12 | loss: 0.00882 | val_0_mse: 0.001180000021122396|  0:00:13s\n","epoch 13 | loss: 0.00554 | val_0_mse: 0.0006099999882280827|  0:00:14s\n","epoch 14 | loss: 0.00249 | val_0_mse: 0.00023999999393709004|  0:00:15s\n","epoch 15 | loss: 0.00156 | val_0_mse: 0.0002300000051036477|  0:00:16s\n","epoch 16 | loss: 0.0012  | val_0_mse: 0.00014000000373926014|  0:00:17s\n","epoch 17 | loss: 0.00086 | val_0_mse: 0.0001500000071246177|  0:00:18s\n","epoch 18 | loss: 0.00074 | val_0_mse: 7.000000186963007e-05|  0:00:19s\n","epoch 19 | loss: 0.00069 | val_0_mse: 7.999999797903001e-05|  0:00:20s\n","epoch 20 | loss: 0.00064 | val_0_mse: 7.999999797903001e-05|  0:00:21s\n","epoch 21 | loss: 0.00063 | val_0_mse: 5.999999848427251e-05|  0:00:22s\n","epoch 22 | loss: 0.00072 | val_0_mse: 3.9999998989515007e-05|  0:00:23s\n","epoch 23 | loss: 0.00061 | val_0_mse: 4.999999873689376e-05|  0:00:24s\n","epoch 24 | loss: 0.00062 | val_0_mse: 3.9999998989515007e-05|  0:00:25s\n","epoch 25 | loss: 0.00055 | val_0_mse: 9.999999747378752e-05|  0:00:26s\n","epoch 26 | loss: 0.00052 | val_0_mse: 5.999999848427251e-05|  0:00:27s\n","epoch 27 | loss: 0.00047 | val_0_mse: 3.9999998989515007e-05|  0:00:28s\n","epoch 28 | loss: 0.00042 | val_0_mse: 5.999999848427251e-05|  0:00:29s\n","epoch 29 | loss: 0.00042 | val_0_mse: 4.999999873689376e-05|  0:00:30s\n","epoch 30 | loss: 0.00041 | val_0_mse: 4.999999873689376e-05|  0:00:31s\n","epoch 31 | loss: 0.00038 | val_0_mse: 2.9999999242136255e-05|  0:00:33s\n","epoch 32 | loss: 0.00037 | val_0_mse: 2.9999999242136255e-05|  0:00:34s\n","epoch 33 | loss: 0.00037 | val_0_mse: 1.9999999494757503e-05|  0:00:35s\n","epoch 34 | loss: 0.00037 | val_0_mse: 1.9999999494757503e-05|  0:00:36s\n","epoch 35 | loss: 0.00035 | val_0_mse: 1.9999999494757503e-05|  0:00:37s\n","epoch 36 | loss: 0.00035 | val_0_mse: 1.9999999494757503e-05|  0:00:38s\n","epoch 37 | loss: 0.00036 | val_0_mse: 2.9999999242136255e-05|  0:00:39s\n","epoch 38 | loss: 0.00035 | val_0_mse: 2.9999999242136255e-05|  0:00:40s\n","epoch 39 | loss: 0.00036 | val_0_mse: 1.9999999494757503e-05|  0:00:41s\n","epoch 40 | loss: 0.00034 | val_0_mse: 2.9999999242136255e-05|  0:00:42s\n","epoch 41 | loss: 0.00031 | val_0_mse: 2.9999999242136255e-05|  0:00:43s\n","epoch 42 | loss: 0.00031 | val_0_mse: 2.9999999242136255e-05|  0:00:44s\n","epoch 43 | loss: 0.00029 | val_0_mse: 4.999999873689376e-05|  0:00:45s\n","epoch 44 | loss: 0.00029 | val_0_mse: 2.9999999242136255e-05|  0:00:46s\n","epoch 45 | loss: 0.00028 | val_0_mse: 2.9999999242136255e-05|  0:00:47s\n","epoch 46 | loss: 0.00028 | val_0_mse: 1.9999999494757503e-05|  0:00:48s\n","epoch 47 | loss: 0.00027 | val_0_mse: 9.999999747378752e-06|  0:00:49s\n","epoch 48 | loss: 0.00026 | val_0_mse: 1.9999999494757503e-05|  0:00:50s\n","epoch 49 | loss: 0.00026 | val_0_mse: 2.9999999242136255e-05|  0:00:51s\n","epoch 50 | loss: 0.00026 | val_0_mse: 1.9999999494757503e-05|  0:00:52s\n","epoch 51 | loss: 0.00025 | val_0_mse: 2.9999999242136255e-05|  0:00:53s\n","epoch 52 | loss: 0.00025 | val_0_mse: 9.999999747378752e-06|  0:00:54s\n","epoch 53 | loss: 0.00024 | val_0_mse: 1.9999999494757503e-05|  0:00:55s\n","epoch 54 | loss: 0.00025 | val_0_mse: 2.9999999242136255e-05|  0:00:56s\n","epoch 55 | loss: 0.00023 | val_0_mse: 1.9999999494757503e-05|  0:00:57s\n","epoch 56 | loss: 0.00023 | val_0_mse: 9.999999747378752e-06|  0:00:58s\n","epoch 57 | loss: 0.00022 | val_0_mse: 1.9999999494757503e-05|  0:00:59s\n","epoch 58 | loss: 0.00022 | val_0_mse: 1.9999999494757503e-05|  0:01:00s\n","epoch 59 | loss: 0.00022 | val_0_mse: 9.999999747378752e-06|  0:01:01s\n","epoch 60 | loss: 0.00022 | val_0_mse: 9.999999747378752e-06|  0:01:02s\n","epoch 61 | loss: 0.00021 | val_0_mse: 1.9999999494757503e-05|  0:01:03s\n","epoch 62 | loss: 0.00023 | val_0_mse: 9.999999747378752e-06|  0:01:04s\n","epoch 63 | loss: 0.0002  | val_0_mse: 9.999999747378752e-06|  0:01:05s\n","epoch 64 | loss: 0.0002  | val_0_mse: 9.999999747378752e-06|  0:01:06s\n","epoch 65 | loss: 0.0002  | val_0_mse: 9.999999747378752e-06|  0:01:07s\n","epoch 66 | loss: 0.00019 | val_0_mse: 1.9999999494757503e-05|  0:01:08s\n","epoch 67 | loss: 0.00019 | val_0_mse: 9.999999747378752e-06|  0:01:09s\n","epoch 68 | loss: 0.00018 | val_0_mse: 9.999999747378752e-06|  0:01:10s\n","epoch 69 | loss: 0.00018 | val_0_mse: 1.9999999494757503e-05|  0:01:11s\n","epoch 70 | loss: 0.00021 | val_0_mse: 4.999999873689376e-05|  0:01:12s\n","epoch 71 | loss: 0.00022 | val_0_mse: 3.9999998989515007e-05|  0:01:13s\n","epoch 72 | loss: 0.00022 | val_0_mse: 2.9999999242136255e-05|  0:01:14s\n","epoch 73 | loss: 0.00019 | val_0_mse: 3.9999998989515007e-05|  0:01:15s\n","epoch 74 | loss: 0.00019 | val_0_mse: 2.9999999242136255e-05|  0:01:16s\n","\n","Early stopping occurred at epoch 74 with best_epoch = 64 and best_val_0_mse = 9.999999747378752e-06\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 10:01:21,696] Trial 89 finished with value: 1.0487638974154834e-05 and parameters: {'n_d': 41, 'n_steps': 7, 'gamma': 1.8761153665045491, 'n_independent': 4, 'n_shared': 2, 'momentum': 0.3683003011278684}. Best is trial 20 with value: 1.2763081258526654e-07.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 1.87746 | val_0_mse: 2.5334300994873047|  0:00:00s\n","epoch 1  | loss: 0.50681 | val_0_mse: 0.5135700106620789|  0:00:01s\n","epoch 2  | loss: 0.32088 | val_0_mse: 0.2936300039291382|  0:00:01s\n","epoch 3  | loss: 0.16552 | val_0_mse: 0.016750000417232513|  0:00:02s\n","epoch 4  | loss: 0.10996 | val_0_mse: 0.008740000426769257|  0:00:03s\n","epoch 5  | loss: 0.04405 | val_0_mse: 0.004000000189989805|  0:00:03s\n","epoch 6  | loss: 0.0202  | val_0_mse: 0.001979999942705035|  0:00:04s\n","epoch 7  | loss: 0.01005 | val_0_mse: 0.003700000001117587|  0:00:04s\n","epoch 8  | loss: 0.00853 | val_0_mse: 0.0009599999757483602|  0:00:05s\n","epoch 9  | loss: 0.00711 | val_0_mse: 0.0006000000284984708|  0:00:06s\n","epoch 10 | loss: 0.00601 | val_0_mse: 0.0004199999966658652|  0:00:06s\n","epoch 11 | loss: 0.00381 | val_0_mse: 0.00046999999904073775|  0:00:07s\n","epoch 12 | loss: 0.00333 | val_0_mse: 0.0010400000028312206|  0:00:07s\n","epoch 13 | loss: 0.00215 | val_0_mse: 0.00033999999868683517|  0:00:08s\n","epoch 14 | loss: 0.00144 | val_0_mse: 0.00041000000783242285|  0:00:09s\n","epoch 15 | loss: 0.00136 | val_0_mse: 0.0005600000149570405|  0:00:09s\n","epoch 16 | loss: 0.00173 | val_0_mse: 0.0003699999942909926|  0:00:10s\n","epoch 17 | loss: 0.00137 | val_0_mse: 0.0002899999963119626|  0:00:10s\n","epoch 18 | loss: 0.00114 | val_0_mse: 0.00019999999494757503|  0:00:11s\n","epoch 19 | loss: 0.00095 | val_0_mse: 0.00014000000373926014|  0:00:12s\n","epoch 20 | loss: 0.00086 | val_0_mse: 0.00013000000035390258|  0:00:12s\n","epoch 21 | loss: 0.00073 | val_0_mse: 0.0001500000071246177|  0:00:13s\n","epoch 22 | loss: 0.00063 | val_0_mse: 5.999999848427251e-05|  0:00:14s\n","epoch 23 | loss: 0.00061 | val_0_mse: 9.999999747378752e-05|  0:00:14s\n","epoch 24 | loss: 0.00059 | val_0_mse: 0.0002099999983329326|  0:00:15s\n","epoch 25 | loss: 0.00057 | val_0_mse: 9.000000136438757e-05|  0:00:15s\n","epoch 26 | loss: 0.00052 | val_0_mse: 5.999999848427251e-05|  0:00:16s\n","epoch 27 | loss: 0.00046 | val_0_mse: 0.00011000000085914508|  0:00:17s\n","epoch 28 | loss: 0.00043 | val_0_mse: 5.999999848427251e-05|  0:00:17s\n","epoch 29 | loss: 0.00042 | val_0_mse: 4.999999873689376e-05|  0:00:18s\n","epoch 30 | loss: 0.0004  | val_0_mse: 3.9999998989515007e-05|  0:00:19s\n","epoch 31 | loss: 0.0004  | val_0_mse: 7.999999797903001e-05|  0:00:19s\n","epoch 32 | loss: 0.0004  | val_0_mse: 2.9999999242136255e-05|  0:00:20s\n","epoch 33 | loss: 0.00038 | val_0_mse: 2.9999999242136255e-05|  0:00:20s\n","epoch 34 | loss: 0.00035 | val_0_mse: 3.9999998989515007e-05|  0:00:21s\n","epoch 35 | loss: 0.00036 | val_0_mse: 2.9999999242136255e-05|  0:00:22s\n","epoch 36 | loss: 0.00034 | val_0_mse: 2.9999999242136255e-05|  0:00:22s\n","epoch 37 | loss: 0.00033 | val_0_mse: 2.9999999242136255e-05|  0:00:23s\n","epoch 38 | loss: 0.00033 | val_0_mse: 2.9999999242136255e-05|  0:00:23s\n","epoch 39 | loss: 0.00032 | val_0_mse: 2.9999999242136255e-05|  0:00:24s\n","epoch 40 | loss: 0.00031 | val_0_mse: 1.9999999494757503e-05|  0:00:25s\n","epoch 41 | loss: 0.00031 | val_0_mse: 2.9999999242136255e-05|  0:00:25s\n","epoch 42 | loss: 0.00031 | val_0_mse: 2.9999999242136255e-05|  0:00:26s\n","epoch 43 | loss: 0.0003  | val_0_mse: 2.9999999242136255e-05|  0:00:26s\n","epoch 44 | loss: 0.00029 | val_0_mse: 1.9999999494757503e-05|  0:00:27s\n","epoch 45 | loss: 0.00029 | val_0_mse: 1.9999999494757503e-05|  0:00:28s\n","epoch 46 | loss: 0.00029 | val_0_mse: 1.9999999494757503e-05|  0:00:28s\n","epoch 47 | loss: 0.00029 | val_0_mse: 1.9999999494757503e-05|  0:00:29s\n","epoch 48 | loss: 0.00028 | val_0_mse: 9.999999747378752e-06|  0:00:29s\n","epoch 49 | loss: 0.00028 | val_0_mse: 9.999999747378752e-06|  0:00:30s\n","epoch 50 | loss: 0.00027 | val_0_mse: 9.999999747378752e-06|  0:00:31s\n","epoch 51 | loss: 0.00027 | val_0_mse: 9.999999747378752e-06|  0:00:31s\n","epoch 52 | loss: 0.00027 | val_0_mse: 9.999999747378752e-06|  0:00:32s\n","epoch 53 | loss: 0.00027 | val_0_mse: 9.999999747378752e-06|  0:00:33s\n","epoch 54 | loss: 0.00026 | val_0_mse: 9.999999747378752e-06|  0:00:33s\n","epoch 55 | loss: 0.00026 | val_0_mse: 9.999999747378752e-06|  0:00:34s\n","epoch 56 | loss: 0.00026 | val_0_mse: 9.999999747378752e-06|  0:00:34s\n","epoch 57 | loss: 0.00026 | val_0_mse: 9.999999747378752e-06|  0:00:35s\n","epoch 58 | loss: 0.00025 | val_0_mse: 9.999999747378752e-06|  0:00:36s\n","epoch 59 | loss: 0.00025 | val_0_mse: 9.999999747378752e-06|  0:00:36s\n","epoch 60 | loss: 0.00025 | val_0_mse: 0.0     |  0:00:37s\n","epoch 61 | loss: 0.00025 | val_0_mse: 0.0     |  0:00:37s\n","epoch 62 | loss: 0.00025 | val_0_mse: 0.0     |  0:00:38s\n","epoch 63 | loss: 0.00025 | val_0_mse: 0.0     |  0:00:39s\n","epoch 64 | loss: 0.00024 | val_0_mse: 0.0     |  0:00:39s\n","epoch 65 | loss: 0.00024 | val_0_mse: 0.0     |  0:00:40s\n","epoch 66 | loss: 0.00024 | val_0_mse: 0.0     |  0:00:41s\n","epoch 67 | loss: 0.00023 | val_0_mse: 0.0     |  0:00:41s\n","epoch 68 | loss: 0.00023 | val_0_mse: 0.0     |  0:00:42s\n","epoch 69 | loss: 0.00023 | val_0_mse: 0.0     |  0:00:42s\n","epoch 70 | loss: 0.00023 | val_0_mse: 0.0     |  0:00:43s\n","epoch 71 | loss: 0.00023 | val_0_mse: 0.0     |  0:00:44s\n","epoch 72 | loss: 0.00022 | val_0_mse: 0.0     |  0:00:44s\n","epoch 73 | loss: 0.00022 | val_0_mse: 0.0     |  0:00:45s\n","epoch 74 | loss: 0.00023 | val_0_mse: 0.0     |  0:00:45s\n","epoch 75 | loss: 0.00022 | val_0_mse: 0.0     |  0:00:46s\n","epoch 76 | loss: 0.00022 | val_0_mse: 0.0     |  0:00:47s\n","epoch 77 | loss: 0.00023 | val_0_mse: 0.0     |  0:00:47s\n","epoch 78 | loss: 0.00022 | val_0_mse: 0.0     |  0:00:48s\n","epoch 79 | loss: 0.00022 | val_0_mse: 0.0     |  0:00:48s\n","epoch 80 | loss: 0.00022 | val_0_mse: 0.0     |  0:00:49s\n","epoch 81 | loss: 0.00022 | val_0_mse: 0.0     |  0:00:50s\n","epoch 82 | loss: 0.00022 | val_0_mse: 0.0     |  0:00:50s\n","epoch 83 | loss: 0.00022 | val_0_mse: 0.0     |  0:00:51s\n","epoch 84 | loss: 0.00022 | val_0_mse: 0.0     |  0:00:51s\n","epoch 85 | loss: 0.00021 | val_0_mse: 0.0     |  0:00:52s\n","epoch 86 | loss: 0.00022 | val_0_mse: 0.0     |  0:00:53s\n","epoch 87 | loss: 0.00022 | val_0_mse: 0.0     |  0:00:53s\n","epoch 88 | loss: 0.00022 | val_0_mse: 0.0     |  0:00:54s\n","epoch 89 | loss: 0.00022 | val_0_mse: 0.0     |  0:00:54s\n","epoch 90 | loss: 0.00021 | val_0_mse: 0.0     |  0:00:55s\n","epoch 91 | loss: 0.00021 | val_0_mse: 0.0     |  0:00:56s\n","epoch 92 | loss: 0.00022 | val_0_mse: 0.0     |  0:00:56s\n","epoch 93 | loss: 0.00022 | val_0_mse: 0.0     |  0:00:57s\n","epoch 94 | loss: 0.00021 | val_0_mse: 0.0     |  0:00:58s\n","epoch 95 | loss: 0.00022 | val_0_mse: 0.0     |  0:00:58s\n","epoch 96 | loss: 0.00022 | val_0_mse: 0.0     |  0:00:59s\n","epoch 97 | loss: 0.00022 | val_0_mse: 0.0     |  0:00:59s\n","epoch 98 | loss: 0.00022 | val_0_mse: 0.0     |  0:01:00s\n","epoch 99 | loss: 0.00022 | val_0_mse: 0.0     |  0:01:01s\n","Stop training because you reached max_epochs = 100 with best_epoch = 99 and best_val_0_mse = 0.0\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 10:02:23,236] Trial 90 finished with value: 4.7676113013039867e-07 and parameters: {'n_d': 35, 'n_steps': 5, 'gamma': 1.9959596735602105, 'n_independent': 1, 'n_shared': 3, 'momentum': 0.179779762311487}. Best is trial 20 with value: 1.2763081258526654e-07.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 1.98887 | val_0_mse: 25.66663932800293|  0:00:01s\n","epoch 1  | loss: 0.78438 | val_0_mse: 0.8613200187683105|  0:00:02s\n","epoch 2  | loss: 0.91467 | val_0_mse: 0.07275000214576721|  0:00:03s\n","epoch 3  | loss: 0.96025 | val_0_mse: 0.0786300003528595|  0:00:04s\n","epoch 4  | loss: 0.24355 | val_0_mse: 0.384880006313324|  0:00:05s\n","epoch 5  | loss: 1.17999 | val_0_mse: 0.012140000239014626|  0:00:05s\n","epoch 6  | loss: 0.11284 | val_0_mse: 0.03869999945163727|  0:00:07s\n","epoch 7  | loss: 0.16238 | val_0_mse: 0.0787699967622757|  0:00:08s\n","epoch 8  | loss: 0.05552 | val_0_mse: 0.01779000088572502|  0:00:09s\n","epoch 9  | loss: 0.01337 | val_0_mse: 0.0011699999449774623|  0:00:10s\n","epoch 10 | loss: 0.00211 | val_0_mse: 0.00018000000272877514|  0:00:11s\n","epoch 11 | loss: 0.00085 | val_0_mse: 0.00015999999595806003|  0:00:12s\n","epoch 12 | loss: 0.00045 | val_0_mse: 0.0002300000051036477|  0:00:13s\n","epoch 13 | loss: 0.00032 | val_0_mse: 7.999999797903001e-05|  0:00:14s\n","epoch 14 | loss: 0.00029 | val_0_mse: 4.999999873689376e-05|  0:00:15s\n","epoch 15 | loss: 0.00024 | val_0_mse: 9.999999747378752e-06|  0:00:16s\n","epoch 16 | loss: 0.00021 | val_0_mse: 9.999999747378752e-06|  0:00:17s\n","epoch 17 | loss: 0.0002  | val_0_mse: 0.0     |  0:00:18s\n","epoch 18 | loss: 0.00019 | val_0_mse: 0.0     |  0:00:19s\n","epoch 19 | loss: 0.00019 | val_0_mse: 0.0     |  0:00:20s\n","epoch 20 | loss: 0.00017 | val_0_mse: 0.0     |  0:00:21s\n","epoch 21 | loss: 0.00016 | val_0_mse: 0.0     |  0:00:22s\n","epoch 22 | loss: 0.00016 | val_0_mse: 0.0     |  0:00:23s\n","epoch 23 | loss: 0.00016 | val_0_mse: 0.0     |  0:00:24s\n","epoch 24 | loss: 0.00016 | val_0_mse: 0.0     |  0:00:25s\n","epoch 25 | loss: 0.00015 | val_0_mse: 0.0     |  0:00:26s\n","epoch 26 | loss: 0.00015 | val_0_mse: 0.0     |  0:00:27s\n","epoch 27 | loss: 0.00015 | val_0_mse: 0.0     |  0:00:28s\n","epoch 28 | loss: 0.00014 | val_0_mse: 0.0     |  0:00:29s\n","epoch 29 | loss: 0.00014 | val_0_mse: 0.0     |  0:00:30s\n","epoch 30 | loss: 0.00014 | val_0_mse: 0.0     |  0:00:31s\n","epoch 31 | loss: 0.00014 | val_0_mse: 0.0     |  0:00:32s\n","epoch 32 | loss: 0.00014 | val_0_mse: 0.0     |  0:00:33s\n","epoch 33 | loss: 0.00013 | val_0_mse: 0.0     |  0:00:34s\n","epoch 34 | loss: 0.00013 | val_0_mse: 0.0     |  0:00:35s\n","epoch 35 | loss: 0.00013 | val_0_mse: 0.0     |  0:00:36s\n","epoch 36 | loss: 0.00013 | val_0_mse: 0.0     |  0:00:37s\n","epoch 37 | loss: 0.00013 | val_0_mse: 0.0     |  0:00:38s\n","epoch 38 | loss: 0.00013 | val_0_mse: 0.0     |  0:00:39s\n","epoch 39 | loss: 0.00014 | val_0_mse: 9.999999747378752e-06|  0:00:40s\n","epoch 40 | loss: 0.00013 | val_0_mse: 0.0     |  0:00:41s\n","epoch 41 | loss: 0.00013 | val_0_mse: 0.0     |  0:00:42s\n","epoch 42 | loss: 0.00012 | val_0_mse: 0.0     |  0:00:43s\n","epoch 43 | loss: 0.00012 | val_0_mse: 0.0     |  0:00:44s\n","epoch 44 | loss: 0.00012 | val_0_mse: 0.0     |  0:00:45s\n","epoch 45 | loss: 0.00013 | val_0_mse: 0.0     |  0:00:46s\n","epoch 46 | loss: 0.00013 | val_0_mse: 9.999999747378752e-06|  0:00:47s\n","epoch 47 | loss: 0.00014 | val_0_mse: 9.999999747378752e-06|  0:00:48s\n","epoch 48 | loss: 0.00014 | val_0_mse: 0.0     |  0:00:49s\n","epoch 49 | loss: 0.00014 | val_0_mse: 0.0     |  0:00:50s\n","epoch 50 | loss: 0.00014 | val_0_mse: 0.0     |  0:00:51s\n","epoch 51 | loss: 0.00014 | val_0_mse: 0.0     |  0:00:52s\n","epoch 52 | loss: 0.00014 | val_0_mse: 0.0     |  0:00:53s\n","epoch 53 | loss: 0.00014 | val_0_mse: 0.0     |  0:00:54s\n","epoch 54 | loss: 0.00013 | val_0_mse: 0.0     |  0:00:55s\n","epoch 55 | loss: 0.00013 | val_0_mse: 0.0     |  0:00:56s\n","epoch 56 | loss: 0.00013 | val_0_mse: 0.0     |  0:00:57s\n","epoch 57 | loss: 0.00013 | val_0_mse: 0.0     |  0:00:58s\n","epoch 58 | loss: 0.00013 | val_0_mse: 0.0     |  0:00:59s\n","epoch 59 | loss: 0.00013 | val_0_mse: 0.0     |  0:01:00s\n","epoch 60 | loss: 0.00013 | val_0_mse: 0.0     |  0:01:01s\n","epoch 61 | loss: 0.00013 | val_0_mse: 0.0     |  0:01:02s\n","epoch 62 | loss: 0.00013 | val_0_mse: 0.0     |  0:01:03s\n","epoch 63 | loss: 0.00013 | val_0_mse: 0.0     |  0:01:04s\n","epoch 64 | loss: 0.00013 | val_0_mse: 0.0     |  0:01:05s\n","epoch 65 | loss: 0.00013 | val_0_mse: 0.0     |  0:01:06s\n","epoch 66 | loss: 0.00013 | val_0_mse: 0.0     |  0:01:07s\n","epoch 67 | loss: 0.00013 | val_0_mse: 0.0     |  0:01:08s\n","epoch 68 | loss: 0.00012 | val_0_mse: 0.0     |  0:01:09s\n","epoch 69 | loss: 0.00012 | val_0_mse: 0.0     |  0:01:10s\n","epoch 70 | loss: 0.00012 | val_0_mse: 0.0     |  0:01:11s\n","epoch 71 | loss: 0.00013 | val_0_mse: 0.0     |  0:01:12s\n","epoch 72 | loss: 0.00013 | val_0_mse: 0.0     |  0:01:13s\n","epoch 73 | loss: 0.00013 | val_0_mse: 0.0     |  0:01:14s\n","epoch 74 | loss: 0.00012 | val_0_mse: 0.0     |  0:01:15s\n","epoch 75 | loss: 0.00012 | val_0_mse: 0.0     |  0:01:16s\n","epoch 76 | loss: 0.00012 | val_0_mse: 0.0     |  0:01:17s\n","epoch 77 | loss: 0.00012 | val_0_mse: 0.0     |  0:01:18s\n","epoch 78 | loss: 0.00011 | val_0_mse: 0.0     |  0:01:19s\n","epoch 79 | loss: 0.00011 | val_0_mse: 0.0     |  0:01:20s\n","epoch 80 | loss: 0.0001  | val_0_mse: 0.0     |  0:01:21s\n","epoch 81 | loss: 0.0001  | val_0_mse: 0.0     |  0:01:22s\n","epoch 82 | loss: 0.0001  | val_0_mse: 0.0     |  0:01:23s\n","epoch 83 | loss: 0.0001  | val_0_mse: 0.0     |  0:01:24s\n","epoch 84 | loss: 0.0001  | val_0_mse: 0.0     |  0:01:25s\n","epoch 85 | loss: 0.0001  | val_0_mse: 0.0     |  0:01:26s\n","epoch 86 | loss: 0.0001  | val_0_mse: 0.0     |  0:01:27s\n","epoch 87 | loss: 0.0001  | val_0_mse: 0.0     |  0:01:28s\n","epoch 88 | loss: 0.0001  | val_0_mse: 0.0     |  0:01:29s\n","epoch 89 | loss: 0.0001  | val_0_mse: 0.0     |  0:01:30s\n","epoch 90 | loss: 0.0001  | val_0_mse: 0.0     |  0:01:31s\n","\n","Early stopping occurred at epoch 90 with best_epoch = 80 and best_val_0_mse = 0.0\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 10:03:55,671] Trial 91 finished with value: 2.1623435486617382e-07 and parameters: {'n_d': 39, 'n_steps': 8, 'gamma': 1.9586525661118535, 'n_independent': 2, 'n_shared': 3, 'momentum': 0.32539712761355377}. Best is trial 20 with value: 1.2763081258526654e-07.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 11.54428| val_0_mse: 0.2502500116825104|  0:00:01s\n","epoch 1  | loss: 1.99652 | val_0_mse: 7.489950180053711|  0:00:02s\n","epoch 2  | loss: 0.89674 | val_0_mse: 0.5455499887466431|  0:00:03s\n","epoch 3  | loss: 0.73683 | val_0_mse: 0.7956600189208984|  0:00:04s\n","epoch 4  | loss: 0.39449 | val_0_mse: 0.07281000167131424|  0:00:05s\n","epoch 5  | loss: 0.26204 | val_0_mse: 0.20020000636577606|  0:00:06s\n","epoch 6  | loss: 0.39142 | val_0_mse: 0.12669000029563904|  0:00:08s\n","epoch 7  | loss: 0.23549 | val_0_mse: 0.09679999947547913|  0:00:09s\n","epoch 8  | loss: 0.04644 | val_0_mse: 0.014030000194907188|  0:00:10s\n","epoch 9  | loss: 0.00757 | val_0_mse: 0.0009200000204145908|  0:00:11s\n","epoch 10 | loss: 0.0029  | val_0_mse: 0.001129999989643693|  0:00:12s\n","epoch 11 | loss: 0.00122 | val_0_mse: 0.0005300000193528831|  0:00:13s\n","epoch 12 | loss: 0.00055 | val_0_mse: 0.00016999999934341758|  0:00:15s\n","epoch 13 | loss: 0.00035 | val_0_mse: 0.0001500000071246177|  0:00:16s\n","epoch 14 | loss: 0.00026 | val_0_mse: 1.9999999494757503e-05|  0:00:17s\n","epoch 15 | loss: 0.00022 | val_0_mse: 1.9999999494757503e-05|  0:00:18s\n","epoch 16 | loss: 0.00021 | val_0_mse: 9.999999747378752e-06|  0:00:20s\n","epoch 17 | loss: 0.0002  | val_0_mse: 9.999999747378752e-06|  0:00:21s\n","epoch 18 | loss: 0.00019 | val_0_mse: 9.999999747378752e-06|  0:00:22s\n","epoch 19 | loss: 0.00018 | val_0_mse: 0.0     |  0:00:23s\n","epoch 20 | loss: 0.00017 | val_0_mse: 0.0     |  0:00:24s\n","epoch 21 | loss: 0.00017 | val_0_mse: 0.0     |  0:00:26s\n","epoch 22 | loss: 0.00017 | val_0_mse: 0.0     |  0:00:27s\n","epoch 23 | loss: 0.00019 | val_0_mse: 0.0     |  0:00:28s\n","epoch 24 | loss: 0.0002  | val_0_mse: 0.0     |  0:00:29s\n","epoch 25 | loss: 0.00023 | val_0_mse: 9.999999747378752e-06|  0:00:30s\n","epoch 26 | loss: 0.00022 | val_0_mse: 9.999999747378752e-06|  0:00:32s\n","epoch 27 | loss: 0.00019 | val_0_mse: 0.0     |  0:00:33s\n","epoch 28 | loss: 0.00018 | val_0_mse: 0.0     |  0:00:34s\n","epoch 29 | loss: 0.00017 | val_0_mse: 0.0     |  0:00:35s\n","epoch 30 | loss: 0.00017 | val_0_mse: 0.0     |  0:00:36s\n","epoch 31 | loss: 0.00017 | val_0_mse: 0.0     |  0:00:37s\n","epoch 32 | loss: 0.00016 | val_0_mse: 0.0     |  0:00:39s\n","epoch 33 | loss: 0.00016 | val_0_mse: 0.0     |  0:00:40s\n","epoch 34 | loss: 0.00016 | val_0_mse: 0.0     |  0:00:41s\n","epoch 35 | loss: 0.00016 | val_0_mse: 0.0     |  0:00:42s\n","epoch 36 | loss: 0.00016 | val_0_mse: 0.0     |  0:00:43s\n","epoch 37 | loss: 0.00016 | val_0_mse: 0.0     |  0:00:45s\n","epoch 38 | loss: 0.00016 | val_0_mse: 0.0     |  0:00:46s\n","epoch 39 | loss: 0.00016 | val_0_mse: 0.0     |  0:00:47s\n","epoch 40 | loss: 0.00016 | val_0_mse: 0.0     |  0:00:48s\n","epoch 41 | loss: 0.00015 | val_0_mse: 0.0     |  0:00:50s\n","epoch 42 | loss: 0.00015 | val_0_mse: 0.0     |  0:00:51s\n","epoch 43 | loss: 0.00015 | val_0_mse: 0.0     |  0:00:52s\n","epoch 44 | loss: 0.00015 | val_0_mse: 0.0     |  0:00:53s\n","epoch 45 | loss: 0.00015 | val_0_mse: 0.0     |  0:00:54s\n","epoch 46 | loss: 0.00016 | val_0_mse: 0.0     |  0:00:56s\n","epoch 47 | loss: 0.00016 | val_0_mse: 0.0     |  0:00:57s\n","epoch 48 | loss: 0.00015 | val_0_mse: 0.0     |  0:00:58s\n","epoch 49 | loss: 0.00014 | val_0_mse: 0.0     |  0:00:59s\n","epoch 50 | loss: 0.00014 | val_0_mse: 0.0     |  0:01:00s\n","epoch 51 | loss: 0.00014 | val_0_mse: 0.0     |  0:01:02s\n","epoch 52 | loss: 0.00015 | val_0_mse: 0.0     |  0:01:03s\n","epoch 53 | loss: 0.00016 | val_0_mse: 0.0     |  0:01:04s\n","epoch 54 | loss: 0.00016 | val_0_mse: 0.0     |  0:01:05s\n","epoch 55 | loss: 0.00017 | val_0_mse: 0.0     |  0:01:06s\n","epoch 56 | loss: 0.00017 | val_0_mse: 0.0     |  0:01:07s\n","epoch 57 | loss: 0.00017 | val_0_mse: 0.0     |  0:01:09s\n","epoch 58 | loss: 0.00016 | val_0_mse: 0.0     |  0:01:10s\n","\n","Early stopping occurred at epoch 58 with best_epoch = 48 and best_val_0_mse = 0.0\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 10:05:06,537] Trial 92 finished with value: 3.2950967465694703e-07 and parameters: {'n_d': 37, 'n_steps': 8, 'gamma': 1.9560759407747712, 'n_independent': 3, 'n_shared': 3, 'momentum': 0.38364172494488313}. Best is trial 20 with value: 1.2763081258526654e-07.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 6.83825 | val_0_mse: 4.9846601486206055|  0:00:00s\n","epoch 1  | loss: 1.84572 | val_0_mse: 0.9502300024032593|  0:00:01s\n","epoch 2  | loss: 1.46313 | val_0_mse: 0.2607100009918213|  0:00:02s\n","epoch 3  | loss: 1.06402 | val_0_mse: 0.23849999904632568|  0:00:03s\n","epoch 4  | loss: 1.04507 | val_0_mse: 0.09669999778270721|  0:00:04s\n","epoch 5  | loss: 0.80169 | val_0_mse: 0.2366199940443039|  0:00:05s\n","epoch 6  | loss: 0.5469  | val_0_mse: 0.21467000246047974|  0:00:06s\n","epoch 7  | loss: 0.24351 | val_0_mse: 0.10283000022172928|  0:00:07s\n","epoch 8  | loss: 0.09429 | val_0_mse: 0.02670999988913536|  0:00:08s\n","epoch 9  | loss: 0.06752 | val_0_mse: 0.0134699996560812|  0:00:09s\n","epoch 10 | loss: 0.04101 | val_0_mse: 0.018239999189972878|  0:00:10s\n","epoch 11 | loss: 0.02236 | val_0_mse: 0.011090000160038471|  0:00:11s\n","epoch 12 | loss: 0.02173 | val_0_mse: 0.005770000163465738|  0:00:12s\n","epoch 13 | loss: 0.013   | val_0_mse: 0.004459999967366457|  0:00:13s\n","epoch 14 | loss: 0.00769 | val_0_mse: 0.001019999966956675|  0:00:14s\n","epoch 15 | loss: 0.00585 | val_0_mse: 0.0004600000102072954|  0:00:15s\n","epoch 16 | loss: 0.00292 | val_0_mse: 0.0005099999834783375|  0:00:16s\n","epoch 17 | loss: 0.00188 | val_0_mse: 0.00023999999393709004|  0:00:17s\n","epoch 18 | loss: 0.00169 | val_0_mse: 0.00023999999393709004|  0:00:18s\n","epoch 19 | loss: 0.00158 | val_0_mse: 0.0001500000071246177|  0:00:18s\n","epoch 20 | loss: 0.00111 | val_0_mse: 0.00013000000035390258|  0:00:19s\n","epoch 21 | loss: 0.00099 | val_0_mse: 0.0001500000071246177|  0:00:20s\n","epoch 22 | loss: 0.00097 | val_0_mse: 9.999999747378752e-05|  0:00:21s\n","epoch 23 | loss: 0.00073 | val_0_mse: 4.999999873689376e-05|  0:00:22s\n","epoch 24 | loss: 0.0007  | val_0_mse: 7.999999797903001e-05|  0:00:23s\n","epoch 25 | loss: 0.00066 | val_0_mse: 5.999999848427251e-05|  0:00:24s\n","epoch 26 | loss: 0.0006  | val_0_mse: 0.00013000000035390258|  0:00:25s\n","epoch 27 | loss: 0.00047 | val_0_mse: 5.999999848427251e-05|  0:00:26s\n","epoch 28 | loss: 0.00042 | val_0_mse: 3.9999998989515007e-05|  0:00:27s\n","epoch 29 | loss: 0.00038 | val_0_mse: 3.9999998989515007e-05|  0:00:28s\n","epoch 30 | loss: 0.0004  | val_0_mse: 2.9999999242136255e-05|  0:00:29s\n","epoch 31 | loss: 0.00039 | val_0_mse: 3.9999998989515007e-05|  0:00:30s\n","epoch 32 | loss: 0.00034 | val_0_mse: 2.9999999242136255e-05|  0:00:31s\n","epoch 33 | loss: 0.00032 | val_0_mse: 3.9999998989515007e-05|  0:00:31s\n","epoch 34 | loss: 0.00029 | val_0_mse: 2.9999999242136255e-05|  0:00:32s\n","epoch 35 | loss: 0.00028 | val_0_mse: 2.9999999242136255e-05|  0:00:33s\n","epoch 36 | loss: 0.00027 | val_0_mse: 3.9999998989515007e-05|  0:00:34s\n","epoch 37 | loss: 0.00029 | val_0_mse: 1.9999999494757503e-05|  0:00:35s\n","epoch 38 | loss: 0.00026 | val_0_mse: 2.9999999242136255e-05|  0:00:36s\n","epoch 39 | loss: 0.00027 | val_0_mse: 1.9999999494757503e-05|  0:00:37s\n","epoch 40 | loss: 0.00027 | val_0_mse: 2.9999999242136255e-05|  0:00:38s\n","epoch 41 | loss: 0.00028 | val_0_mse: 1.9999999494757503e-05|  0:00:39s\n","epoch 42 | loss: 0.00027 | val_0_mse: 1.9999999494757503e-05|  0:00:40s\n","epoch 43 | loss: 0.00028 | val_0_mse: 1.9999999494757503e-05|  0:00:41s\n","epoch 44 | loss: 0.00028 | val_0_mse: 1.9999999494757503e-05|  0:00:42s\n","epoch 45 | loss: 0.00024 | val_0_mse: 1.9999999494757503e-05|  0:00:43s\n","epoch 46 | loss: 0.00024 | val_0_mse: 1.9999999494757503e-05|  0:00:44s\n","epoch 47 | loss: 0.00023 | val_0_mse: 1.9999999494757503e-05|  0:00:45s\n","epoch 48 | loss: 0.00021 | val_0_mse: 1.9999999494757503e-05|  0:00:46s\n","epoch 49 | loss: 0.00022 | val_0_mse: 1.9999999494757503e-05|  0:00:46s\n","epoch 50 | loss: 0.00023 | val_0_mse: 1.9999999494757503e-05|  0:00:47s\n","epoch 51 | loss: 0.00023 | val_0_mse: 2.9999999242136255e-05|  0:00:48s\n","epoch 52 | loss: 0.00023 | val_0_mse: 2.9999999242136255e-05|  0:00:49s\n","\n","Early stopping occurred at epoch 52 with best_epoch = 42 and best_val_0_mse = 1.9999999494757503e-05\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 10:05:56,731] Trial 93 finished with value: 1.526485175418202e-05 and parameters: {'n_d': 43, 'n_steps': 7, 'gamma': 1.8978944880214776, 'n_independent': 2, 'n_shared': 3, 'momentum': 0.3424786405971548}. Best is trial 20 with value: 1.2763081258526654e-07.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 6.70403 | val_0_mse: 143.7989959716797|  0:00:01s\n","epoch 1  | loss: 14.30294| val_0_mse: 10.265870094299316|  0:00:02s\n","epoch 2  | loss: 9.49235 | val_0_mse: 1.9487799406051636|  0:00:03s\n","epoch 3  | loss: 3.21738 | val_0_mse: 4.761899948120117|  0:00:05s\n","epoch 4  | loss: 1.06784 | val_0_mse: 1.7181199789047241|  0:00:06s\n","epoch 5  | loss: 2.97029 | val_0_mse: 3.3322200775146484|  0:00:07s\n","epoch 6  | loss: 3.7796  | val_0_mse: 0.6958799958229065|  0:00:09s\n","epoch 7  | loss: 0.69662 | val_0_mse: 0.3737100064754486|  0:00:10s\n","epoch 8  | loss: 0.41192 | val_0_mse: 0.4809400141239166|  0:00:11s\n","epoch 9  | loss: 0.35045 | val_0_mse: 0.03125 |  0:00:13s\n","epoch 10 | loss: 0.34859 | val_0_mse: 0.15253999829292297|  0:00:14s\n","epoch 11 | loss: 0.29961 | val_0_mse: 0.028909999877214432|  0:00:15s\n","epoch 12 | loss: 0.17375 | val_0_mse: 0.021129999309778214|  0:00:16s\n","epoch 13 | loss: 0.03884 | val_0_mse: 0.006459999829530716|  0:00:18s\n","epoch 14 | loss: 0.02177 | val_0_mse: 0.0036899999249726534|  0:00:19s\n","epoch 15 | loss: 0.0073  | val_0_mse: 0.001930000027641654|  0:00:20s\n","epoch 16 | loss: 0.00402 | val_0_mse: 0.0012499999720603228|  0:00:22s\n","epoch 17 | loss: 0.00286 | val_0_mse: 0.0005200000014156103|  0:00:23s\n","epoch 18 | loss: 0.00171 | val_0_mse: 0.0005600000149570405|  0:00:24s\n","epoch 19 | loss: 0.0014  | val_0_mse: 0.0002699999895412475|  0:00:26s\n","epoch 20 | loss: 0.001   | val_0_mse: 0.00018000000272877514|  0:00:27s\n","epoch 21 | loss: 0.00085 | val_0_mse: 0.00023999999393709004|  0:00:28s\n","epoch 22 | loss: 0.00072 | val_0_mse: 0.00014000000373926014|  0:00:30s\n","epoch 23 | loss: 0.00065 | val_0_mse: 0.00015999999595806003|  0:00:31s\n","epoch 24 | loss: 0.00058 | val_0_mse: 0.0001900000061141327|  0:00:32s\n","epoch 25 | loss: 0.00062 | val_0_mse: 0.00022000000171829015|  0:00:33s\n","epoch 26 | loss: 0.00068 | val_0_mse: 0.00019999999494757503|  0:00:35s\n","epoch 27 | loss: 0.00076 | val_0_mse: 0.0004600000102072954|  0:00:36s\n","epoch 28 | loss: 0.0008  | val_0_mse: 0.0001900000061141327|  0:00:37s\n","epoch 29 | loss: 0.00064 | val_0_mse: 0.0001500000071246177|  0:00:39s\n","epoch 30 | loss: 0.00048 | val_0_mse: 7.000000186963007e-05|  0:00:40s\n","epoch 31 | loss: 0.0004  | val_0_mse: 4.999999873689376e-05|  0:00:41s\n","epoch 32 | loss: 0.00035 | val_0_mse: 5.999999848427251e-05|  0:00:43s\n","epoch 33 | loss: 0.00033 | val_0_mse: 4.999999873689376e-05|  0:00:44s\n","epoch 34 | loss: 0.00041 | val_0_mse: 4.999999873689376e-05|  0:00:45s\n","epoch 35 | loss: 0.00044 | val_0_mse: 4.999999873689376e-05|  0:00:47s\n","epoch 36 | loss: 0.00032 | val_0_mse: 3.9999998989515007e-05|  0:00:48s\n","epoch 37 | loss: 0.0003  | val_0_mse: 3.9999998989515007e-05|  0:00:49s\n","epoch 38 | loss: 0.00028 | val_0_mse: 9.000000136438757e-05|  0:00:50s\n","epoch 39 | loss: 0.00026 | val_0_mse: 5.999999848427251e-05|  0:00:52s\n","epoch 40 | loss: 0.00025 | val_0_mse: 3.9999998989515007e-05|  0:00:53s\n","epoch 41 | loss: 0.00025 | val_0_mse: 4.999999873689376e-05|  0:00:54s\n","epoch 42 | loss: 0.00022 | val_0_mse: 2.9999999242136255e-05|  0:00:56s\n","epoch 43 | loss: 0.0002  | val_0_mse: 3.9999998989515007e-05|  0:00:57s\n","epoch 44 | loss: 0.00019 | val_0_mse: 1.9999999494757503e-05|  0:00:58s\n","epoch 45 | loss: 0.00021 | val_0_mse: 4.999999873689376e-05|  0:01:00s\n","epoch 46 | loss: 0.00021 | val_0_mse: 3.9999998989515007e-05|  0:01:01s\n","epoch 47 | loss: 0.00018 | val_0_mse: 1.9999999494757503e-05|  0:01:02s\n","epoch 48 | loss: 0.00016 | val_0_mse: 2.9999999242136255e-05|  0:01:03s\n","epoch 49 | loss: 0.00016 | val_0_mse: 2.9999999242136255e-05|  0:01:05s\n","epoch 50 | loss: 0.00019 | val_0_mse: 3.9999998989515007e-05|  0:01:06s\n","epoch 51 | loss: 0.00017 | val_0_mse: 1.9999999494757503e-05|  0:01:07s\n","epoch 52 | loss: 0.00016 | val_0_mse: 1.9999999494757503e-05|  0:01:09s\n","epoch 53 | loss: 0.00015 | val_0_mse: 2.9999999242136255e-05|  0:01:10s\n","epoch 54 | loss: 0.00015 | val_0_mse: 2.9999999242136255e-05|  0:01:11s\n","\n","Early stopping occurred at epoch 54 with best_epoch = 44 and best_val_0_mse = 1.9999999494757503e-05\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 10:07:09,101] Trial 94 finished with value: 1.6794750990811735e-05 and parameters: {'n_d': 45, 'n_steps': 9, 'gamma': 1.929115410892118, 'n_independent': 3, 'n_shared': 3, 'momentum': 0.2946252108781285}. Best is trial 20 with value: 1.2763081258526654e-07.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 1.69053 | val_0_mse: 3.045140027999878|  0:00:01s\n","epoch 1  | loss: 1.37968 | val_0_mse: 4.957890033721924|  0:00:02s\n","epoch 2  | loss: 0.387   | val_0_mse: 1.2373900413513184|  0:00:03s\n","epoch 3  | loss: 0.24649 | val_0_mse: 0.1600400060415268|  0:00:04s\n","epoch 4  | loss: 0.46478 | val_0_mse: 0.1918099969625473|  0:00:05s\n","epoch 5  | loss: 0.24915 | val_0_mse: 3.2183499336242676|  0:00:06s\n","epoch 6  | loss: 0.56372 | val_0_mse: 0.15023000538349152|  0:00:07s\n","epoch 7  | loss: 0.17125 | val_0_mse: 0.17416000366210938|  0:00:08s\n","epoch 8  | loss: 0.09137 | val_0_mse: 0.0050200000405311584|  0:00:09s\n","epoch 9  | loss: 0.00794 | val_0_mse: 0.0023900000378489494|  0:00:10s\n","epoch 10 | loss: 0.00403 | val_0_mse: 0.0001500000071246177|  0:00:11s\n","epoch 11 | loss: 0.0012  | val_0_mse: 0.0002500000118743628|  0:00:12s\n","epoch 12 | loss: 0.00069 | val_0_mse: 0.00013000000035390258|  0:00:13s\n","epoch 13 | loss: 0.00037 | val_0_mse: 0.00011999999696854502|  0:00:14s\n","epoch 14 | loss: 0.00028 | val_0_mse: 2.9999999242136255e-05|  0:00:15s\n","epoch 15 | loss: 0.00023 | val_0_mse: 9.999999747378752e-06|  0:00:16s\n","epoch 16 | loss: 0.00021 | val_0_mse: 9.999999747378752e-06|  0:00:17s\n","epoch 17 | loss: 0.0002  | val_0_mse: 9.999999747378752e-06|  0:00:18s\n","epoch 18 | loss: 0.0002  | val_0_mse: 0.0     |  0:00:19s\n","epoch 19 | loss: 0.00019 | val_0_mse: 0.0     |  0:00:20s\n","epoch 20 | loss: 0.00018 | val_0_mse: 0.0     |  0:00:22s\n","epoch 21 | loss: 0.00018 | val_0_mse: 0.0     |  0:00:23s\n","epoch 22 | loss: 0.00018 | val_0_mse: 0.0     |  0:00:24s\n","epoch 23 | loss: 0.00018 | val_0_mse: 0.0     |  0:00:25s\n","epoch 24 | loss: 0.00018 | val_0_mse: 0.0     |  0:00:26s\n","epoch 25 | loss: 0.00018 | val_0_mse: 0.0     |  0:00:27s\n","epoch 26 | loss: 0.00018 | val_0_mse: 0.0     |  0:00:28s\n","epoch 27 | loss: 0.00018 | val_0_mse: 0.0     |  0:00:29s\n","epoch 28 | loss: 0.00018 | val_0_mse: 0.0     |  0:00:30s\n","epoch 29 | loss: 0.00018 | val_0_mse: 0.0     |  0:00:31s\n","epoch 30 | loss: 0.00018 | val_0_mse: 0.0     |  0:00:32s\n","epoch 31 | loss: 0.00018 | val_0_mse: 0.0     |  0:00:33s\n","epoch 32 | loss: 0.00018 | val_0_mse: 0.0     |  0:00:34s\n","epoch 33 | loss: 0.00018 | val_0_mse: 0.0     |  0:00:35s\n","epoch 34 | loss: 0.00017 | val_0_mse: 0.0     |  0:00:36s\n","epoch 35 | loss: 0.00017 | val_0_mse: 0.0     |  0:00:37s\n","epoch 36 | loss: 0.00017 | val_0_mse: 0.0     |  0:00:38s\n","epoch 37 | loss: 0.00017 | val_0_mse: 0.0     |  0:00:39s\n","epoch 38 | loss: 0.00016 | val_0_mse: 0.0     |  0:00:40s\n","epoch 39 | loss: 0.00016 | val_0_mse: 0.0     |  0:00:41s\n","epoch 40 | loss: 0.00016 | val_0_mse: 0.0     |  0:00:42s\n","epoch 41 | loss: 0.00016 | val_0_mse: 0.0     |  0:00:43s\n","epoch 42 | loss: 0.00016 | val_0_mse: 0.0     |  0:00:44s\n","epoch 43 | loss: 0.00016 | val_0_mse: 0.0     |  0:00:45s\n","epoch 44 | loss: 0.00016 | val_0_mse: 0.0     |  0:00:47s\n","epoch 45 | loss: 0.00016 | val_0_mse: 0.0     |  0:00:48s\n","epoch 46 | loss: 0.00016 | val_0_mse: 0.0     |  0:00:49s\n","epoch 47 | loss: 0.00016 | val_0_mse: 0.0     |  0:00:50s\n","epoch 48 | loss: 0.00016 | val_0_mse: 0.0     |  0:00:51s\n","epoch 49 | loss: 0.00015 | val_0_mse: 0.0     |  0:00:52s\n","epoch 50 | loss: 0.00015 | val_0_mse: 0.0     |  0:00:53s\n","epoch 51 | loss: 0.00015 | val_0_mse: 0.0     |  0:00:54s\n","epoch 52 | loss: 0.00015 | val_0_mse: 0.0     |  0:00:55s\n","epoch 53 | loss: 0.00015 | val_0_mse: 0.0     |  0:00:56s\n","epoch 54 | loss: 0.00015 | val_0_mse: 0.0     |  0:00:57s\n","epoch 55 | loss: 0.00015 | val_0_mse: 0.0     |  0:00:58s\n","epoch 56 | loss: 0.00014 | val_0_mse: 0.0     |  0:00:59s\n","epoch 57 | loss: 0.00014 | val_0_mse: 0.0     |  0:01:00s\n","epoch 58 | loss: 0.00013 | val_0_mse: 0.0     |  0:01:01s\n","epoch 59 | loss: 0.00013 | val_0_mse: 0.0     |  0:01:02s\n","epoch 60 | loss: 0.00013 | val_0_mse: 0.0     |  0:01:03s\n","epoch 61 | loss: 0.00014 | val_0_mse: 0.0     |  0:01:04s\n","epoch 62 | loss: 0.00015 | val_0_mse: 0.0     |  0:01:05s\n","epoch 63 | loss: 0.00015 | val_0_mse: 0.0     |  0:01:06s\n","epoch 64 | loss: 0.00015 | val_0_mse: 0.0     |  0:01:07s\n","epoch 65 | loss: 0.00015 | val_0_mse: 0.0     |  0:01:08s\n","epoch 66 | loss: 0.00015 | val_0_mse: 0.0     |  0:01:09s\n","epoch 67 | loss: 0.00015 | val_0_mse: 0.0     |  0:01:10s\n","epoch 68 | loss: 0.00016 | val_0_mse: 0.0     |  0:01:11s\n","epoch 69 | loss: 0.00017 | val_0_mse: 0.0     |  0:01:12s\n","epoch 70 | loss: 0.00017 | val_0_mse: 0.0     |  0:01:13s\n","epoch 71 | loss: 0.00017 | val_0_mse: 0.0     |  0:01:14s\n","epoch 72 | loss: 0.00017 | val_0_mse: 0.0     |  0:01:15s\n","epoch 73 | loss: 0.00016 | val_0_mse: 0.0     |  0:01:16s\n","epoch 74 | loss: 0.00016 | val_0_mse: 0.0     |  0:01:17s\n","epoch 75 | loss: 0.00016 | val_0_mse: 0.0     |  0:01:18s\n","epoch 76 | loss: 0.00016 | val_0_mse: 0.0     |  0:01:19s\n","epoch 77 | loss: 0.00016 | val_0_mse: 0.0     |  0:01:20s\n","epoch 78 | loss: 0.00016 | val_0_mse: 0.0     |  0:01:21s\n","epoch 79 | loss: 0.00016 | val_0_mse: 0.0     |  0:01:22s\n","epoch 80 | loss: 0.00015 | val_0_mse: 0.0     |  0:01:23s\n","epoch 81 | loss: 0.00015 | val_0_mse: 0.0     |  0:01:24s\n","\n","Early stopping occurred at epoch 81 with best_epoch = 71 and best_val_0_mse = 0.0\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 10:08:34,257] Trial 95 finished with value: 3.388311142771272e-07 and parameters: {'n_d': 39, 'n_steps': 8, 'gamma': 1.8449242240668737, 'n_independent': 2, 'n_shared': 3, 'momentum': 0.32717172429425634}. Best is trial 20 with value: 1.2763081258526654e-07.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 8.44594 | val_0_mse: 6.3024001121521|  0:00:00s\n","epoch 1  | loss: 1.95223 | val_0_mse: 4.9096999168396|  0:00:01s\n","epoch 2  | loss: 1.33076 | val_0_mse: 1.0155099630355835|  0:00:02s\n","epoch 3  | loss: 1.32169 | val_0_mse: 1.1415799856185913|  0:00:03s\n","epoch 4  | loss: 1.00839 | val_0_mse: 0.875220000743866|  0:00:04s\n","epoch 5  | loss: 0.87303 | val_0_mse: 0.11623000353574753|  0:00:05s\n","epoch 6  | loss: 0.29944 | val_0_mse: 0.05502999946475029|  0:00:06s\n","epoch 7  | loss: 0.14038 | val_0_mse: 0.05469999834895134|  0:00:07s\n","epoch 8  | loss: 0.07274 | val_0_mse: 0.029069999232888222|  0:00:08s\n","epoch 9  | loss: 0.02337 | val_0_mse: 0.02638999931514263|  0:00:09s\n","epoch 10 | loss: 0.01689 | val_0_mse: 0.0013000000035390258|  0:00:10s\n","epoch 11 | loss: 0.01526 | val_0_mse: 0.004269999917596579|  0:00:11s\n","epoch 12 | loss: 0.00596 | val_0_mse: 0.0008399999933317304|  0:00:12s\n","epoch 13 | loss: 0.00416 | val_0_mse: 0.00139999995008111|  0:00:13s\n","epoch 14 | loss: 0.00334 | val_0_mse: 0.0006300000241026282|  0:00:13s\n","epoch 15 | loss: 0.00381 | val_0_mse: 0.0006200000061653554|  0:00:14s\n","epoch 16 | loss: 0.00316 | val_0_mse: 0.0016499999910593033|  0:00:15s\n","epoch 17 | loss: 0.00358 | val_0_mse: 0.0008699999889358878|  0:00:16s\n","epoch 18 | loss: 0.00236 | val_0_mse: 0.0006200000061653554|  0:00:17s\n","epoch 19 | loss: 0.00219 | val_0_mse: 0.00046999999904073775|  0:00:18s\n","epoch 20 | loss: 0.00164 | val_0_mse: 0.0004799999878741801|  0:00:19s\n","epoch 21 | loss: 0.00138 | val_0_mse: 0.0003100000030826777|  0:00:20s\n","epoch 22 | loss: 0.00122 | val_0_mse: 0.0002500000118743628|  0:00:21s\n","epoch 23 | loss: 0.00094 | val_0_mse: 0.0001500000071246177|  0:00:22s\n","epoch 24 | loss: 0.001   | val_0_mse: 0.00011999999696854502|  0:00:23s\n","epoch 25 | loss: 0.00092 | val_0_mse: 0.00018000000272877514|  0:00:23s\n","epoch 26 | loss: 0.00076 | val_0_mse: 0.00014000000373926014|  0:00:25s\n","epoch 27 | loss: 0.00081 | val_0_mse: 0.00011999999696854502|  0:00:25s\n","epoch 28 | loss: 0.0007  | val_0_mse: 0.00011999999696854502|  0:00:26s\n","epoch 29 | loss: 0.00071 | val_0_mse: 0.00011000000085914508|  0:00:27s\n","epoch 30 | loss: 0.00066 | val_0_mse: 0.0001500000071246177|  0:00:28s\n","epoch 31 | loss: 0.0006  | val_0_mse: 0.00011999999696854502|  0:00:29s\n","epoch 32 | loss: 0.00057 | val_0_mse: 0.00011000000085914508|  0:00:30s\n","epoch 33 | loss: 0.0006  | val_0_mse: 0.00011000000085914508|  0:00:31s\n","epoch 34 | loss: 0.00062 | val_0_mse: 0.0001500000071246177|  0:00:32s\n","epoch 35 | loss: 0.00105 | val_0_mse: 0.00013000000035390258|  0:00:33s\n","epoch 36 | loss: 0.00146 | val_0_mse: 0.00016999999934341758|  0:00:34s\n","epoch 37 | loss: 0.0017  | val_0_mse: 0.0005200000014156103|  0:00:34s\n","epoch 38 | loss: 0.00178 | val_0_mse: 0.0002099999983329326|  0:00:35s\n","epoch 39 | loss: 0.00128 | val_0_mse: 0.00011000000085914508|  0:00:36s\n","epoch 40 | loss: 0.00086 | val_0_mse: 0.00015999999595806003|  0:00:37s\n","epoch 41 | loss: 0.00078 | val_0_mse: 9.000000136438757e-05|  0:00:38s\n","epoch 42 | loss: 0.00077 | val_0_mse: 0.00013000000035390258|  0:00:39s\n","epoch 43 | loss: 0.00059 | val_0_mse: 9.999999747378752e-05|  0:00:40s\n","epoch 44 | loss: 0.00054 | val_0_mse: 7.999999797903001e-05|  0:00:41s\n","epoch 45 | loss: 0.00045 | val_0_mse: 2.9999999242136255e-05|  0:00:41s\n","epoch 46 | loss: 0.00042 | val_0_mse: 2.9999999242136255e-05|  0:00:42s\n","epoch 47 | loss: 0.00039 | val_0_mse: 3.9999998989515007e-05|  0:00:43s\n","epoch 48 | loss: 0.00036 | val_0_mse: 1.9999999494757503e-05|  0:00:44s\n","epoch 49 | loss: 0.00034 | val_0_mse: 2.9999999242136255e-05|  0:00:45s\n","epoch 50 | loss: 0.00033 | val_0_mse: 2.9999999242136255e-05|  0:00:46s\n","epoch 51 | loss: 0.00032 | val_0_mse: 1.9999999494757503e-05|  0:00:47s\n","epoch 52 | loss: 0.00031 | val_0_mse: 3.9999998989515007e-05|  0:00:48s\n","epoch 53 | loss: 0.00031 | val_0_mse: 2.9999999242136255e-05|  0:00:49s\n","epoch 54 | loss: 0.00031 | val_0_mse: 2.9999999242136255e-05|  0:00:50s\n","epoch 55 | loss: 0.00032 | val_0_mse: 2.9999999242136255e-05|  0:00:50s\n","epoch 56 | loss: 0.00033 | val_0_mse: 1.9999999494757503e-05|  0:00:51s\n","epoch 57 | loss: 0.00031 | val_0_mse: 2.9999999242136255e-05|  0:00:52s\n","epoch 58 | loss: 0.0003  | val_0_mse: 2.9999999242136255e-05|  0:00:53s\n","epoch 59 | loss: 0.00034 | val_0_mse: 3.9999998989515007e-05|  0:00:54s\n","epoch 60 | loss: 0.0003  | val_0_mse: 1.9999999494757503e-05|  0:00:55s\n","epoch 61 | loss: 0.00031 | val_0_mse: 1.9999999494757503e-05|  0:00:56s\n","epoch 62 | loss: 0.00028 | val_0_mse: 2.9999999242136255e-05|  0:00:57s\n","epoch 63 | loss: 0.00027 | val_0_mse: 1.9999999494757503e-05|  0:00:58s\n","epoch 64 | loss: 0.00025 | val_0_mse: 2.9999999242136255e-05|  0:00:59s\n","epoch 65 | loss: 0.00026 | val_0_mse: 9.999999747378752e-06|  0:00:59s\n","epoch 66 | loss: 0.00025 | val_0_mse: 9.999999747378752e-06|  0:01:00s\n","epoch 67 | loss: 0.00026 | val_0_mse: 9.999999747378752e-06|  0:01:01s\n","epoch 68 | loss: 0.00029 | val_0_mse: 3.9999998989515007e-05|  0:01:02s\n","epoch 69 | loss: 0.00027 | val_0_mse: 9.999999747378752e-06|  0:01:03s\n","epoch 70 | loss: 0.00024 | val_0_mse: 9.999999747378752e-06|  0:01:04s\n","epoch 71 | loss: 0.00025 | val_0_mse: 9.999999747378752e-06|  0:01:05s\n","epoch 72 | loss: 0.00023 | val_0_mse: 5.999999848427251e-05|  0:01:06s\n","epoch 73 | loss: 0.00023 | val_0_mse: 9.999999747378752e-06|  0:01:07s\n","epoch 74 | loss: 0.00023 | val_0_mse: 1.9999999494757503e-05|  0:01:07s\n","epoch 75 | loss: 0.00022 | val_0_mse: 9.999999747378752e-06|  0:01:08s\n","epoch 76 | loss: 0.00022 | val_0_mse: 9.999999747378752e-06|  0:01:09s\n","epoch 77 | loss: 0.00023 | val_0_mse: 9.999999747378752e-06|  0:01:10s\n","epoch 78 | loss: 0.00022 | val_0_mse: 9.999999747378752e-06|  0:01:11s\n","epoch 79 | loss: 0.00022 | val_0_mse: 3.9999998989515007e-05|  0:01:12s\n","epoch 80 | loss: 0.00023 | val_0_mse: 3.9999998989515007e-05|  0:01:13s\n","epoch 81 | loss: 0.00024 | val_0_mse: 1.9999999494757503e-05|  0:01:14s\n","epoch 82 | loss: 0.00032 | val_0_mse: 3.9999998989515007e-05|  0:01:15s\n","epoch 83 | loss: 0.00028 | val_0_mse: 2.9999999242136255e-05|  0:01:15s\n","epoch 84 | loss: 0.00025 | val_0_mse: 1.9999999494757503e-05|  0:01:16s\n","epoch 85 | loss: 0.00022 | val_0_mse: 9.999999747378752e-06|  0:01:17s\n","epoch 86 | loss: 0.00022 | val_0_mse: 4.999999873689376e-05|  0:01:18s\n","epoch 87 | loss: 0.00024 | val_0_mse: 9.999999747378752e-06|  0:01:19s\n","\n","Early stopping occurred at epoch 87 with best_epoch = 77 and best_val_0_mse = 9.999999747378752e-06\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 10:09:54,293] Trial 96 finished with value: 8.247904588642996e-06 and parameters: {'n_d': 50, 'n_steps': 7, 'gamma': 1.680283342096777, 'n_independent': 2, 'n_shared': 3, 'momentum': 0.2579470961789791}. Best is trial 20 with value: 1.2763081258526654e-07.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 3.96983 | val_0_mse: 0.6049799919128418|  0:00:00s\n","epoch 1  | loss: 1.39701 | val_0_mse: 0.06913000345230103|  0:00:01s\n","epoch 2  | loss: 0.62807 | val_0_mse: 0.2473600059747696|  0:00:02s\n","epoch 3  | loss: 0.41832 | val_0_mse: 0.1358799934387207|  0:00:03s\n","epoch 4  | loss: 0.21738 | val_0_mse: 0.006819999776780605|  0:00:04s\n","epoch 5  | loss: 0.08231 | val_0_mse: 0.007519999984651804|  0:00:05s\n","epoch 6  | loss: 0.05965 | val_0_mse: 0.005400000140070915|  0:00:06s\n","epoch 7  | loss: 0.04348 | val_0_mse: 0.015780000016093254|  0:00:07s\n","epoch 8  | loss: 0.01846 | val_0_mse: 0.0020699999295175076|  0:00:08s\n","epoch 9  | loss: 0.00993 | val_0_mse: 0.0009599999757483602|  0:00:09s\n","epoch 10 | loss: 0.00597 | val_0_mse: 0.0007900000200606883|  0:00:10s\n","epoch 11 | loss: 0.00442 | val_0_mse: 0.0004400000034365803|  0:00:11s\n","epoch 12 | loss: 0.00283 | val_0_mse: 0.0003699999942909926|  0:00:11s\n","epoch 13 | loss: 0.00191 | val_0_mse: 0.004040000028908253|  0:00:12s\n","epoch 14 | loss: 0.0021  | val_0_mse: 0.0011099999537691474|  0:00:13s\n","epoch 15 | loss: 0.00142 | val_0_mse: 0.0007999999797903001|  0:00:14s\n","epoch 16 | loss: 0.00102 | val_0_mse: 0.0003699999942909926|  0:00:15s\n","epoch 17 | loss: 0.00078 | val_0_mse: 0.0002300000051036477|  0:00:16s\n","epoch 18 | loss: 0.00068 | val_0_mse: 0.00016999999934341758|  0:00:17s\n","epoch 19 | loss: 0.00062 | val_0_mse: 0.00011999999696854502|  0:00:18s\n","epoch 20 | loss: 0.00098 | val_0_mse: 0.00018000000272877514|  0:00:19s\n","epoch 21 | loss: 0.00108 | val_0_mse: 0.00011000000085914508|  0:00:20s\n","epoch 22 | loss: 0.00088 | val_0_mse: 9.000000136438757e-05|  0:00:20s\n","epoch 23 | loss: 0.00102 | val_0_mse: 9.000000136438757e-05|  0:00:21s\n","epoch 24 | loss: 0.00078 | val_0_mse: 9.000000136438757e-05|  0:00:22s\n","epoch 25 | loss: 0.00065 | val_0_mse: 7.000000186963007e-05|  0:00:23s\n","epoch 26 | loss: 0.00057 | val_0_mse: 4.999999873689376e-05|  0:00:24s\n","epoch 27 | loss: 0.00055 | val_0_mse: 4.999999873689376e-05|  0:00:25s\n","epoch 28 | loss: 0.0005  | val_0_mse: 4.999999873689376e-05|  0:00:26s\n","epoch 29 | loss: 0.00046 | val_0_mse: 2.9999999242136255e-05|  0:00:27s\n","epoch 30 | loss: 0.00042 | val_0_mse: 2.9999999242136255e-05|  0:00:28s\n","epoch 31 | loss: 0.00043 | val_0_mse: 3.9999998989515007e-05|  0:00:29s\n","epoch 32 | loss: 0.00043 | val_0_mse: 1.9999999494757503e-05|  0:00:29s\n","epoch 33 | loss: 0.0004  | val_0_mse: 2.9999999242136255e-05|  0:00:30s\n","epoch 34 | loss: 0.00038 | val_0_mse: 3.9999998989515007e-05|  0:00:31s\n","epoch 35 | loss: 0.00036 | val_0_mse: 2.9999999242136255e-05|  0:00:32s\n","epoch 36 | loss: 0.00036 | val_0_mse: 2.9999999242136255e-05|  0:00:33s\n","epoch 37 | loss: 0.00035 | val_0_mse: 1.9999999494757503e-05|  0:00:34s\n","epoch 38 | loss: 0.00035 | val_0_mse: 1.9999999494757503e-05|  0:00:35s\n","epoch 39 | loss: 0.00034 | val_0_mse: 3.9999998989515007e-05|  0:00:36s\n","epoch 40 | loss: 0.00033 | val_0_mse: 1.9999999494757503e-05|  0:00:37s\n","epoch 41 | loss: 0.00032 | val_0_mse: 1.9999999494757503e-05|  0:00:38s\n","epoch 42 | loss: 0.00032 | val_0_mse: 2.9999999242136255e-05|  0:00:39s\n","epoch 43 | loss: 0.00032 | val_0_mse: 9.999999747378752e-06|  0:00:39s\n","epoch 44 | loss: 0.00031 | val_0_mse: 1.9999999494757503e-05|  0:00:40s\n","epoch 45 | loss: 0.0003  | val_0_mse: 9.999999747378752e-06|  0:00:41s\n","epoch 46 | loss: 0.00029 | val_0_mse: 9.999999747378752e-06|  0:00:42s\n","epoch 47 | loss: 0.00028 | val_0_mse: 1.9999999494757503e-05|  0:00:43s\n","epoch 48 | loss: 0.00028 | val_0_mse: 9.999999747378752e-06|  0:00:44s\n","epoch 49 | loss: 0.00027 | val_0_mse: 9.999999747378752e-06|  0:00:45s\n","epoch 50 | loss: 0.00027 | val_0_mse: 9.999999747378752e-06|  0:00:46s\n","epoch 51 | loss: 0.00026 | val_0_mse: 9.999999747378752e-06|  0:00:47s\n","epoch 52 | loss: 0.00026 | val_0_mse: 9.999999747378752e-06|  0:00:47s\n","epoch 53 | loss: 0.00025 | val_0_mse: 9.999999747378752e-06|  0:00:48s\n","epoch 54 | loss: 0.00025 | val_0_mse: 9.999999747378752e-06|  0:00:49s\n","epoch 55 | loss: 0.00025 | val_0_mse: 9.999999747378752e-06|  0:00:50s\n","epoch 56 | loss: 0.00025 | val_0_mse: 9.999999747378752e-06|  0:00:51s\n","epoch 57 | loss: 0.00024 | val_0_mse: 9.999999747378752e-06|  0:00:52s\n","epoch 58 | loss: 0.00024 | val_0_mse: 9.999999747378752e-06|  0:00:53s\n","epoch 59 | loss: 0.00024 | val_0_mse: 9.999999747378752e-06|  0:00:54s\n","epoch 60 | loss: 0.00024 | val_0_mse: 9.999999747378752e-06|  0:00:55s\n","epoch 61 | loss: 0.00023 | val_0_mse: 9.999999747378752e-06|  0:00:56s\n","epoch 62 | loss: 0.00023 | val_0_mse: 9.999999747378752e-06|  0:00:56s\n","epoch 63 | loss: 0.00024 | val_0_mse: 9.999999747378752e-06|  0:00:57s\n","epoch 64 | loss: 0.00023 | val_0_mse: 9.999999747378752e-06|  0:00:58s\n","epoch 65 | loss: 0.00023 | val_0_mse: 9.999999747378752e-06|  0:00:59s\n","epoch 66 | loss: 0.00023 | val_0_mse: 9.999999747378752e-06|  0:01:00s\n","epoch 67 | loss: 0.00023 | val_0_mse: 9.999999747378752e-06|  0:01:01s\n","epoch 68 | loss: 0.00022 | val_0_mse: 9.999999747378752e-06|  0:01:02s\n","epoch 69 | loss: 0.00023 | val_0_mse: 9.999999747378752e-06|  0:01:03s\n","\n","Early stopping occurred at epoch 69 with best_epoch = 59 and best_val_0_mse = 9.999999747378752e-06\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 10:10:58,230] Trial 97 finished with value: 5.121512913319748e-06 and parameters: {'n_d': 34, 'n_steps': 6, 'gamma': 1.9574774408668043, 'n_independent': 3, 'n_shared': 3, 'momentum': 0.2441657243503528}. Best is trial 20 with value: 1.2763081258526654e-07.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 1.40433 | val_0_mse: 4.383780002593994|  0:00:00s\n","epoch 1  | loss: 0.35986 | val_0_mse: 0.874459981918335|  0:00:01s\n","epoch 2  | loss: 0.13455 | val_0_mse: 0.298799991607666|  0:00:02s\n","epoch 3  | loss: 0.15018 | val_0_mse: 0.04992000013589859|  0:00:03s\n","epoch 4  | loss: 0.04524 | val_0_mse: 0.028769999742507935|  0:00:03s\n","epoch 5  | loss: 0.01629 | val_0_mse: 0.004509999882429838|  0:00:04s\n","epoch 6  | loss: 0.00379 | val_0_mse: 0.0007699999841861427|  0:00:05s\n","epoch 7  | loss: 0.00109 | val_0_mse: 0.00011000000085914508|  0:00:06s\n","epoch 8  | loss: 0.00056 | val_0_mse: 1.9999999494757503e-05|  0:00:07s\n","epoch 9  | loss: 0.00039 | val_0_mse: 0.0     |  0:00:08s\n","epoch 10 | loss: 0.00036 | val_0_mse: 0.0     |  0:00:08s\n","epoch 11 | loss: 0.00036 | val_0_mse: 0.0     |  0:00:09s\n","epoch 12 | loss: 0.00035 | val_0_mse: 0.0     |  0:00:10s\n","epoch 13 | loss: 0.00035 | val_0_mse: 0.0     |  0:00:11s\n","epoch 14 | loss: 0.00034 | val_0_mse: 0.0     |  0:00:11s\n","epoch 15 | loss: 0.00034 | val_0_mse: 0.0     |  0:00:12s\n","epoch 16 | loss: 0.00033 | val_0_mse: 0.0     |  0:00:13s\n","epoch 17 | loss: 0.00033 | val_0_mse: 0.0     |  0:00:14s\n","epoch 18 | loss: 0.00033 | val_0_mse: 0.0     |  0:00:15s\n","epoch 19 | loss: 0.00034 | val_0_mse: 0.0     |  0:00:15s\n","epoch 20 | loss: 0.00033 | val_0_mse: 0.0     |  0:00:16s\n","epoch 21 | loss: 0.00033 | val_0_mse: 0.0     |  0:00:17s\n","epoch 22 | loss: 0.00033 | val_0_mse: 0.0     |  0:00:18s\n","epoch 23 | loss: 0.00034 | val_0_mse: 0.0     |  0:00:18s\n","epoch 24 | loss: 0.00033 | val_0_mse: 0.0     |  0:00:19s\n","epoch 25 | loss: 0.00032 | val_0_mse: 0.0     |  0:00:20s\n","epoch 26 | loss: 0.00033 | val_0_mse: 0.0     |  0:00:21s\n","\n","Early stopping occurred at epoch 26 with best_epoch = 16 and best_val_0_mse = 0.0\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 10:11:19,945] Trial 98 finished with value: 3.44907903127023e-07 and parameters: {'n_d': 15, 'n_steps': 6, 'gamma': 1.7898865154198038, 'n_independent': 2, 'n_shared': 3, 'momentum': 0.2824477472202193}. Best is trial 20 with value: 1.2763081258526654e-07.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 3.46404 | val_0_mse: 4.334219932556152|  0:00:01s\n","epoch 1  | loss: 3.55386 | val_0_mse: 5.557759761810303|  0:00:02s\n","epoch 2  | loss: 1.79668 | val_0_mse: 0.48489999771118164|  0:00:03s\n","epoch 3  | loss: 2.04503 | val_0_mse: 3.0330801010131836|  0:00:04s\n","epoch 4  | loss: 2.90141 | val_0_mse: 0.5649399757385254|  0:00:05s\n","epoch 5  | loss: 0.89841 | val_0_mse: 0.08320000022649765|  0:00:06s\n","epoch 6  | loss: 0.33335 | val_0_mse: 0.03303999826312065|  0:00:07s\n","epoch 7  | loss: 0.20255 | val_0_mse: 0.020800000056624413|  0:00:08s\n","epoch 8  | loss: 0.07586 | val_0_mse: 0.007420000154525042|  0:00:09s\n","epoch 9  | loss: 0.0186  | val_0_mse: 0.002689999993890524|  0:00:10s\n","epoch 10 | loss: 0.00572 | val_0_mse: 0.0003800000122282654|  0:00:11s\n","epoch 11 | loss: 0.00266 | val_0_mse: 0.000750000006519258|  0:00:12s\n","epoch 12 | loss: 0.00196 | val_0_mse: 0.0001900000061141327|  0:00:13s\n","epoch 13 | loss: 0.00147 | val_0_mse: 0.00018000000272877514|  0:00:14s\n","epoch 14 | loss: 0.001   | val_0_mse: 0.0001500000071246177|  0:00:15s\n","epoch 15 | loss: 0.001   | val_0_mse: 0.00031999999191612005|  0:00:16s\n","epoch 16 | loss: 0.00097 | val_0_mse: 0.00033999999868683517|  0:00:17s\n","epoch 17 | loss: 0.00069 | val_0_mse: 0.0001500000071246177|  0:00:18s\n","epoch 18 | loss: 0.00066 | val_0_mse: 9.999999747378752e-05|  0:00:19s\n","epoch 19 | loss: 0.00063 | val_0_mse: 0.00011999999696854502|  0:00:20s\n","epoch 20 | loss: 0.00052 | val_0_mse: 7.000000186963007e-05|  0:00:21s\n","epoch 21 | loss: 0.00051 | val_0_mse: 7.999999797903001e-05|  0:00:22s\n","epoch 22 | loss: 0.00045 | val_0_mse: 9.000000136438757e-05|  0:00:23s\n","epoch 23 | loss: 0.00043 | val_0_mse: 4.999999873689376e-05|  0:00:24s\n","epoch 24 | loss: 0.00045 | val_0_mse: 5.999999848427251e-05|  0:00:25s\n","epoch 25 | loss: 0.00044 | val_0_mse: 5.999999848427251e-05|  0:00:26s\n","epoch 26 | loss: 0.0005  | val_0_mse: 7.000000186963007e-05|  0:00:27s\n","epoch 27 | loss: 0.00048 | val_0_mse: 5.999999848427251e-05|  0:00:28s\n","epoch 28 | loss: 0.00047 | val_0_mse: 5.999999848427251e-05|  0:00:29s\n","epoch 29 | loss: 0.00055 | val_0_mse: 0.00011000000085914508|  0:00:30s\n","epoch 30 | loss: 0.00046 | val_0_mse: 9.000000136438757e-05|  0:00:31s\n","epoch 31 | loss: 0.00042 | val_0_mse: 0.00013000000035390258|  0:00:32s\n","epoch 32 | loss: 0.00039 | val_0_mse: 0.00015999999595806003|  0:00:33s\n","epoch 33 | loss: 0.00034 | val_0_mse: 7.999999797903001e-05|  0:00:34s\n","\n","Early stopping occurred at epoch 33 with best_epoch = 23 and best_val_0_mse = 4.999999873689376e-05\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 10:11:55,628] Trial 99 finished with value: 4.689306297223084e-05 and parameters: {'n_d': 47, 'n_steps': 7, 'gamma': 1.8600574189631538, 'n_independent': 3, 'n_shared': 3, 'momentum': 0.3621830700916767}. Best is trial 20 with value: 1.2763081258526654e-07.\n"]}]},{"cell_type":"code","source":["best_params"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sg7oYTivFBGe","executionInfo":{"status":"ok","timestamp":1728987116112,"user_tz":-480,"elapsed":69,"user":{"displayName":"Jonindo Pasaribu","userId":"10958990953097471082"}},"outputId":"fc3c4a94-2608-41ba-b89c-fea9eff3bd33"},"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'n_d': 35,\n"," 'n_steps': 7,\n"," 'gamma': 1.9187448447979616,\n"," 'n_independent': 1,\n"," 'n_shared': 3,\n"," 'momentum': 0.2539679747829539}"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["from pytorch_tabnet.callbacks import Callback\n","\n","def print_memory_usage():\n","    process = psutil.Process()\n","    mem_info = process.memory_info()\n","    print(f\"Memory Usage: {mem_info.rss / (1024 ** 2):.2f} MB\")\n","\n","class MemoryUsageCallback(Callback):\n","    def on_epoch_end(self, epoch, logs=None):\n","        print_memory_usage()"],"metadata":{"id":"Tc2ueju9nSae","executionInfo":{"status":"ok","timestamp":1728987116112,"user_tz":-480,"elapsed":2,"user":{"displayName":"Jonindo Pasaribu","userId":"10958990953097471082"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["# Train final model using best hyperparameters\n","best_model = TabNetRegressor(**best_params,\n","                             n_a=best_params['n_d'],\n","                             optimizer_fn=torch.optim.Adam,\n","                             optimizer_params=dict(lr=2e-2)\n","                             )\n","best_model.fit(\n","    X_train, y_train,\n","    eval_set=[(X_train, y_train), (X_valid, y_valid)],\n","    eval_name=['train', 'valid'],\n","    eval_metric=['mae', 'rmse'],\n","    callbacks=[MemoryUsageCallback()]\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rLdfMkJXw_Xl","executionInfo":{"status":"ok","timestamp":1728987233705,"user_tz":-480,"elapsed":117595,"user":{"displayName":"Jonindo Pasaribu","userId":"10958990953097471082"}},"outputId":"f1e2338d-8f0f-4e0e-a3de-b47d65829fdb"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 4.1191  | train_mae: 1.7066600322723389| train_rmse: 3.2469799518585205| valid_mae: 1.9961899518966675| valid_rmse: 3.8357200622558594|  0:00:01s\n","Memory Usage: 1231.29 MB\n","epoch 1  | loss: 0.72846 | train_mae: 0.9191399812698364| train_rmse: 1.2814500331878662| valid_mae: 0.8994899988174438| valid_rmse: 1.290779948234558|  0:00:02s\n","Memory Usage: 1231.29 MB\n","epoch 2  | loss: 0.53748 | train_mae: 0.7338600158691406| train_rmse: 1.276379942893982| valid_mae: 0.7178999781608582| valid_rmse: 1.297659993171692|  0:00:03s\n","Memory Usage: 1231.29 MB\n","epoch 3  | loss: 0.92815 | train_mae: 0.8736100196838379| train_rmse: 1.1634199619293213| valid_mae: 0.8591700196266174| valid_rmse: 1.1545100212097168|  0:00:05s\n","Memory Usage: 1231.29 MB\n","epoch 4  | loss: 0.60379 | train_mae: 0.17367999255657196| train_rmse: 0.29613998532295227| valid_mae: 0.162650004029274| valid_rmse: 0.2818099856376648|  0:00:06s\n","Memory Usage: 1231.29 MB\n","epoch 5  | loss: 0.20638 | train_mae: 0.5057799816131592| train_rmse: 0.5885199904441833| valid_mae: 0.48756998777389526| valid_rmse: 0.5656499862670898|  0:00:07s\n","Memory Usage: 1231.29 MB\n","epoch 6  | loss: 0.61823 | train_mae: 0.12099000066518784| train_rmse: 0.20090000331401825| valid_mae: 0.1132500022649765| valid_rmse: 0.19356000423431396|  0:00:08s\n","Memory Usage: 1231.29 MB\n","epoch 7  | loss: 0.09001 | train_mae: 0.06270000338554382| train_rmse: 0.12144999951124191| valid_mae: 0.06041000038385391| valid_rmse: 0.11610999703407288|  0:00:10s\n","Memory Usage: 1231.29 MB\n","epoch 8  | loss: 0.0348  | train_mae: 0.03736000135540962| train_rmse: 0.06114000082015991| valid_mae: 0.03660000115633011| valid_rmse: 0.0604499988257885|  0:00:11s\n","Memory Usage: 1231.29 MB\n","epoch 9  | loss: 0.02764 | train_mae: 0.02339000068604946| train_rmse: 0.039799999445676804| valid_mae: 0.021309999749064445| valid_rmse: 0.03348999843001366|  0:00:12s\n","Memory Usage: 1231.29 MB\n","epoch 10 | loss: 0.01242 | train_mae: 0.019419999793171883| train_rmse: 0.03579999879002571| valid_mae: 0.01816999912261963| valid_rmse: 0.03265000134706497|  0:00:13s\n","Memory Usage: 1231.29 MB\n","epoch 11 | loss: 0.00758 | train_mae: 0.02711999975144863| train_rmse: 0.036329999566078186| valid_mae: 0.027389999479055405| valid_rmse: 0.036890000104904175|  0:00:14s\n","Memory Usage: 1231.29 MB\n","epoch 12 | loss: 0.00475 | train_mae: 0.014949999749660492| train_rmse: 0.020409999415278435| valid_mae: 0.015189999714493752| valid_rmse: 0.0207700002938509|  0:00:15s\n","Memory Usage: 1231.29 MB\n","epoch 13 | loss: 0.00243 | train_mae: 0.011950000189244747| train_rmse: 0.02095000073313713| valid_mae: 0.01104000024497509| valid_rmse: 0.017069999128580093|  0:00:16s\n","Memory Usage: 1231.29 MB\n","epoch 14 | loss: 0.00165 | train_mae: 0.008009999990463257| train_rmse: 0.009979999624192715| valid_mae: 0.007840000092983246| valid_rmse: 0.009669999592006207|  0:00:18s\n","Memory Usage: 1231.29 MB\n","epoch 15 | loss: 0.00106 | train_mae: 0.008449999615550041| train_rmse: 0.011060000397264957| valid_mae: 0.008329999633133411| valid_rmse: 0.010870000347495079|  0:00:19s\n","Memory Usage: 1231.29 MB\n","epoch 16 | loss: 0.0008  | train_mae: 0.005760000087320805| train_rmse: 0.008390000090003014| valid_mae: 0.005630000028759241| valid_rmse: 0.008249999955296516|  0:00:20s\n","Memory Usage: 1231.29 MB\n","epoch 17 | loss: 0.00058 | train_mae: 0.005770000163465738| train_rmse: 0.007499999832361937| valid_mae: 0.005799999926239252| valid_rmse: 0.007670000195503235|  0:00:21s\n","Memory Usage: 1231.29 MB\n","epoch 18 | loss: 0.00043 | train_mae: 0.004279999993741512| train_rmse: 0.005750000011175871| valid_mae: 0.004399999976158142| valid_rmse: 0.006140000186860561|  0:00:22s\n","Memory Usage: 1231.29 MB\n","epoch 19 | loss: 0.00037 | train_mae: 0.003909999970346689| train_rmse: 0.005239999853074551| valid_mae: 0.003980000037699938| valid_rmse: 0.005429999902844429|  0:00:23s\n","Memory Usage: 1231.29 MB\n","epoch 20 | loss: 0.00034 | train_mae: 0.0033100000582635403| train_rmse: 0.0048699998296797276| valid_mae: 0.0033499998971819878| valid_rmse: 0.005439999978989363|  0:00:25s\n","Memory Usage: 1231.29 MB\n","epoch 21 | loss: 0.00031 | train_mae: 0.003949999809265137| train_rmse: 0.005470000207424164| valid_mae: 0.003930000122636557| valid_rmse: 0.00547999981790781|  0:00:26s\n","Memory Usage: 1231.29 MB\n","epoch 22 | loss: 0.00031 | train_mae: 0.0038799999747425318| train_rmse: 0.005379999987781048| valid_mae: 0.0038399999029934406| valid_rmse: 0.005280000157654285|  0:00:27s\n","Memory Usage: 1231.29 MB\n","epoch 23 | loss: 0.00032 | train_mae: 0.003860000055283308| train_rmse: 0.005309999920427799| valid_mae: 0.003819999983534217| valid_rmse: 0.005319999996572733|  0:00:28s\n","Memory Usage: 1231.29 MB\n","epoch 24 | loss: 0.00031 | train_mae: 0.0033100000582635403| train_rmse: 0.004639999940991402| valid_mae: 0.003280000062659383| valid_rmse: 0.004679999779909849|  0:00:29s\n","Memory Usage: 1231.29 MB\n","epoch 25 | loss: 0.00027 | train_mae: 0.003269999986514449| train_rmse: 0.005100000184029341| valid_mae: 0.003289999905973673| valid_rmse: 0.005270000081509352|  0:00:31s\n","Memory Usage: 1231.29 MB\n","epoch 26 | loss: 0.00026 | train_mae: 0.0029800001066178083| train_rmse: 0.0048699998296797276| valid_mae: 0.002839999971911311| valid_rmse: 0.004730000160634518|  0:00:32s\n","Memory Usage: 1231.29 MB\n","epoch 27 | loss: 0.00023 | train_mae: 0.0029800001066178083| train_rmse: 0.0044200001284480095| valid_mae: 0.002899999963119626| valid_rmse: 0.004350000061094761|  0:00:33s\n","Memory Usage: 1231.29 MB\n","epoch 28 | loss: 0.00023 | train_mae: 0.003449999960139394| train_rmse: 0.004819999914616346| valid_mae: 0.0032999999821186066| valid_rmse: 0.004720000084489584|  0:00:34s\n","Memory Usage: 1231.29 MB\n","epoch 29 | loss: 0.00024 | train_mae: 0.0037700000684708357| train_rmse: 0.005140000022947788| valid_mae: 0.003659999929368496| valid_rmse: 0.0050200000405311584|  0:00:35s\n","Memory Usage: 1231.29 MB\n","epoch 30 | loss: 0.00023 | train_mae: 0.0029700000304728746| train_rmse: 0.0043299999088048935| valid_mae: 0.0029200001154094934| valid_rmse: 0.004220000002533197|  0:00:36s\n","Memory Usage: 1231.29 MB\n","epoch 31 | loss: 0.00021 | train_mae: 0.002839999971911311| train_rmse: 0.004310000222176313| valid_mae: 0.002749999985098839| valid_rmse: 0.00418000016361475|  0:00:38s\n","Memory Usage: 1231.29 MB\n","epoch 32 | loss: 0.00021 | train_mae: 0.002739999908953905| train_rmse: 0.0040799998678267| valid_mae: 0.002630000002682209| valid_rmse: 0.003819999983534217|  0:00:39s\n","Memory Usage: 1231.29 MB\n","epoch 33 | loss: 0.00021 | train_mae: 0.0027099999133497477| train_rmse: 0.00394000019878149| valid_mae: 0.0026199999265372753| valid_rmse: 0.0036700000055134296|  0:00:40s\n","Memory Usage: 1231.29 MB\n","epoch 34 | loss: 0.0002  | train_mae: 0.0026100000832229853| train_rmse: 0.00395999988541007| valid_mae: 0.0025100000202655792| valid_rmse: 0.003800000064074993|  0:00:41s\n","Memory Usage: 1231.29 MB\n","epoch 35 | loss: 0.0002  | train_mae: 0.003280000062659383| train_rmse: 0.004370000213384628| valid_mae: 0.0031999999191612005| valid_rmse: 0.004220000002533197|  0:00:42s\n","Memory Usage: 1231.29 MB\n","epoch 36 | loss: 0.0002  | train_mae: 0.002749999985098839| train_rmse: 0.004120000172406435| valid_mae: 0.0026599999982863665| valid_rmse: 0.004040000028908253|  0:00:43s\n","Memory Usage: 1231.29 MB\n","epoch 37 | loss: 0.00019 | train_mae: 0.0024800000246614218| train_rmse: 0.003539999946951866| valid_mae: 0.0023499999660998583| valid_rmse: 0.0034199999645352364|  0:00:45s\n","Memory Usage: 1231.29 MB\n","epoch 38 | loss: 0.00021 | train_mae: 0.002420000033453107| train_rmse: 0.0038799999747425318| valid_mae: 0.0022799998987466097| valid_rmse: 0.0035000001080334187|  0:00:46s\n","Memory Usage: 1231.29 MB\n","epoch 39 | loss: 0.0002  | train_mae: 0.0020699999295175076| train_rmse: 0.0032099999953061342| valid_mae: 0.00203000009059906| valid_rmse: 0.0030300000216811895|  0:00:47s\n","Memory Usage: 1231.29 MB\n","epoch 40 | loss: 0.00019 | train_mae: 0.0024999999441206455| train_rmse: 0.003379999892786145| valid_mae: 0.002520000096410513| valid_rmse: 0.0034000000450760126|  0:00:48s\n","Memory Usage: 1231.29 MB\n","epoch 41 | loss: 0.00019 | train_mae: 0.0019199999514967203| train_rmse: 0.00279999990016222| valid_mae: 0.0018700000364333391| valid_rmse: 0.0027099999133497477|  0:00:49s\n","Memory Usage: 1231.29 MB\n","epoch 42 | loss: 0.00018 | train_mae: 0.0020800000056624413| train_rmse: 0.003010000102221966| valid_mae: 0.00203000009059906| valid_rmse: 0.0029700000304728746|  0:00:50s\n","Memory Usage: 1231.29 MB\n","epoch 43 | loss: 0.00019 | train_mae: 0.002240000059828162| train_rmse: 0.003289999905973673| valid_mae: 0.0022299999836832285| valid_rmse: 0.0035699999425560236|  0:00:52s\n","Memory Usage: 1231.29 MB\n","epoch 44 | loss: 0.00018 | train_mae: 0.0020099999383091927| train_rmse: 0.0028800000436604023| valid_mae: 0.00203000009059906| valid_rmse: 0.003000000026077032|  0:00:53s\n","Memory Usage: 1231.29 MB\n","epoch 45 | loss: 0.00018 | train_mae: 0.0016599999507889152| train_rmse: 0.0026199999265372753| valid_mae: 0.0016400000313296914| valid_rmse: 0.002580000087618828|  0:00:54s\n","Memory Usage: 1231.29 MB\n","epoch 46 | loss: 0.00018 | train_mae: 0.0014600000577047467| train_rmse: 0.002400000113993883| valid_mae: 0.0014600000577047467| valid_rmse: 0.002400000113993883|  0:00:55s\n","Memory Usage: 1231.29 MB\n","epoch 47 | loss: 0.00017 | train_mae: 0.001339999958872795| train_rmse: 0.0023300000466406345| valid_mae: 0.0012799999676644802| valid_rmse: 0.0021299999207258224|  0:00:56s\n","Memory Usage: 1231.29 MB\n","epoch 48 | loss: 0.00017 | train_mae: 0.0015300000086426735| train_rmse: 0.0026100000832229853| valid_mae: 0.0014799999771639705| valid_rmse: 0.0024999999441206455|  0:00:57s\n","Memory Usage: 1231.29 MB\n","epoch 49 | loss: 0.00017 | train_mae: 0.0012700000079348683| train_rmse: 0.0020099999383091927| valid_mae: 0.0012400000123307109| valid_rmse: 0.0019199999514967203|  0:00:59s\n","Memory Usage: 1231.29 MB\n","epoch 50 | loss: 0.00017 | train_mae: 0.0012199999764561653| train_rmse: 0.0019600000232458115| valid_mae: 0.0012499999720603228| valid_rmse: 0.0021200000774115324|  0:01:00s\n","Memory Usage: 1231.29 MB\n","epoch 51 | loss: 0.00017 | train_mae: 0.0013000000035390258| train_rmse: 0.001990000018849969| valid_mae: 0.0012700000079348683| valid_rmse: 0.001979999942705035|  0:01:01s\n","Memory Usage: 1231.29 MB\n","epoch 52 | loss: 0.00017 | train_mae: 0.0010100000072270632| train_rmse: 0.0017500000540167093| valid_mae: 0.0010400000028312206| valid_rmse: 0.001769999973475933|  0:01:02s\n","Memory Usage: 1231.29 MB\n","epoch 53 | loss: 0.00016 | train_mae: 0.00107999995816499| train_rmse: 0.0015300000086426735| valid_mae: 0.0010900000343099236| valid_rmse: 0.001550000044517219|  0:01:03s\n","Memory Usage: 1231.29 MB\n","epoch 54 | loss: 0.00016 | train_mae: 0.0009599999757483602| train_rmse: 0.0014299999456852674| valid_mae: 0.0009500000160187483| valid_rmse: 0.00139999995008111|  0:01:04s\n","Memory Usage: 1231.29 MB\n","epoch 55 | loss: 0.00016 | train_mae: 0.0009599999757483602| train_rmse: 0.0014199999859556556| valid_mae: 0.0009399999980814755| valid_rmse: 0.0013899999903514981|  0:01:06s\n","Memory Usage: 1231.29 MB\n","epoch 56 | loss: 0.00016 | train_mae: 0.0008900000248104334| train_rmse: 0.0013299999991431832| valid_mae: 0.0008800000068731606| valid_rmse: 0.0013099999632686377|  0:01:07s\n","Memory Usage: 1231.29 MB\n","epoch 57 | loss: 0.00016 | train_mae: 0.0009800000116229057| train_rmse: 0.0015200000489130616| valid_mae: 0.0009699999936856329| valid_rmse: 0.001449999981559813|  0:01:08s\n","Memory Usage: 1231.29 MB\n","epoch 58 | loss: 0.00015 | train_mae: 0.000859999970998615| train_rmse: 0.0013899999903514981| valid_mae: 0.000859999970998615| valid_rmse: 0.0013299999991431832|  0:01:09s\n","Memory Usage: 1231.29 MB\n","epoch 59 | loss: 0.00015 | train_mae: 0.0007200000109151006| train_rmse: 0.00107999995816499| valid_mae: 0.0007300000288523734| valid_rmse: 0.001129999989643693|  0:01:10s\n","Memory Usage: 1231.29 MB\n","epoch 60 | loss: 0.00015 | train_mae: 0.0007600000244565308| train_rmse: 0.0012000000569969416| valid_mae: 0.0007800000021234155| valid_rmse: 0.0012799999676644802|  0:01:11s\n","Memory Usage: 1231.29 MB\n","epoch 61 | loss: 0.00015 | train_mae: 0.0007800000021234155| train_rmse: 0.0011399999493733048| valid_mae: 0.0007699999841861427| valid_rmse: 0.0010999999940395355|  0:01:13s\n","Memory Usage: 1231.29 MB\n","epoch 62 | loss: 0.00015 | train_mae: 0.0007800000021234155| train_rmse: 0.001180000021122396| valid_mae: 0.0007399999885819852| valid_rmse: 0.001120000029914081|  0:01:14s\n","Memory Usage: 1231.29 MB\n","epoch 63 | loss: 0.00015 | train_mae: 0.0007800000021234155| train_rmse: 0.0011899999808520079| valid_mae: 0.000750000006519258| valid_rmse: 0.0011399999493733048|  0:01:15s\n","Memory Usage: 1231.29 MB\n","epoch 64 | loss: 0.00015 | train_mae: 0.0006500000017695129| train_rmse: 0.0009699999936856329| valid_mae: 0.0006399999838322401| valid_rmse: 0.0010400000028312206|  0:01:16s\n","Memory Usage: 1231.29 MB\n","epoch 65 | loss: 0.00014 | train_mae: 0.0006000000284984708| train_rmse: 0.0009200000204145908| valid_mae: 0.000590000010561198| valid_rmse: 0.0008699999889358878|  0:01:17s\n","Memory Usage: 1231.29 MB\n","epoch 66 | loss: 0.00014 | train_mae: 0.0006000000284984708| train_rmse: 0.0009399999980814755| valid_mae: 0.0005699999746866524| valid_rmse: 0.000859999970998615|  0:01:18s\n","Memory Usage: 1231.29 MB\n","epoch 67 | loss: 0.00014 | train_mae: 0.0006200000061653554| train_rmse: 0.0008699999889358878| valid_mae: 0.0006099999882280827| valid_rmse: 0.0008900000248104334|  0:01:20s\n","Memory Usage: 1231.29 MB\n","epoch 68 | loss: 0.00014 | train_mae: 0.0005699999746866524| train_rmse: 0.0008900000248104334| valid_mae: 0.0005499999970197678| valid_rmse: 0.0008299999753944576|  0:01:21s\n","Memory Usage: 1231.29 MB\n","epoch 69 | loss: 0.00014 | train_mae: 0.0005699999746866524| train_rmse: 0.0007999999797903001| valid_mae: 0.0005699999746866524| valid_rmse: 0.0008299999753944576|  0:01:22s\n","Memory Usage: 1231.29 MB\n","epoch 70 | loss: 0.00014 | train_mae: 0.0006900000153109431| train_rmse: 0.0009399999980814755| valid_mae: 0.0006500000017695129| valid_rmse: 0.0008900000248104334|  0:01:23s\n","Memory Usage: 1231.29 MB\n","epoch 71 | loss: 0.00014 | train_mae: 0.0006399999838322401| train_rmse: 0.0008800000068731606| valid_mae: 0.0006099999882280827| valid_rmse: 0.0008299999753944576|  0:01:24s\n","Memory Usage: 1231.29 MB\n","epoch 72 | loss: 0.00014 | train_mae: 0.0005600000149570405| train_rmse: 0.0008699999889358878| valid_mae: 0.0005699999746866524| valid_rmse: 0.0007999999797903001|  0:01:26s\n","Memory Usage: 1231.29 MB\n","epoch 73 | loss: 0.00014 | train_mae: 0.0005000000237487257| train_rmse: 0.0007200000109151006| valid_mae: 0.0004799999878741801| valid_rmse: 0.000699999975040555|  0:01:27s\n","Memory Usage: 1231.29 MB\n","epoch 74 | loss: 0.00014 | train_mae: 0.0006099999882280827| train_rmse: 0.0008399999933317304| valid_mae: 0.0005699999746866524| valid_rmse: 0.0007800000021234155|  0:01:28s\n","Memory Usage: 1231.29 MB\n","epoch 75 | loss: 0.00014 | train_mae: 0.0004600000102072954| train_rmse: 0.0006399999838322401| valid_mae: 0.0004400000034365803| valid_rmse: 0.0006099999882280827|  0:01:29s\n","Memory Usage: 1231.29 MB\n","epoch 76 | loss: 0.00014 | train_mae: 0.0005300000193528831| train_rmse: 0.000859999970998615| valid_mae: 0.0005200000014156103| valid_rmse: 0.0008200000156648457|  0:01:30s\n","Memory Usage: 1231.29 MB\n","epoch 77 | loss: 0.00014 | train_mae: 0.00044999999227002263| train_rmse: 0.0006099999882280827| valid_mae: 0.0004400000034365803| valid_rmse: 0.0006099999882280827|  0:01:31s\n","Memory Usage: 1231.29 MB\n","epoch 78 | loss: 0.00014 | train_mae: 0.0006300000241026282| train_rmse: 0.0008200000156648457| valid_mae: 0.000590000010561198| valid_rmse: 0.000750000006519258|  0:01:33s\n","Memory Usage: 1231.29 MB\n","epoch 79 | loss: 0.00014 | train_mae: 0.0005000000237487257| train_rmse: 0.0007099999929778278| valid_mae: 0.0005099999834783375| valid_rmse: 0.0006799999973736703|  0:01:34s\n","Memory Usage: 1231.29 MB\n","epoch 80 | loss: 0.00013 | train_mae: 0.00046999999904073775| train_rmse: 0.0007300000288523734| valid_mae: 0.00046999999904073775| valid_rmse: 0.0006399999838322401|  0:01:35s\n","Memory Usage: 1231.29 MB\n","epoch 81 | loss: 0.00014 | train_mae: 0.0005300000193528831| train_rmse: 0.0007600000244565308| valid_mae: 0.0005200000014156103| valid_rmse: 0.000750000006519258|  0:01:36s\n","Memory Usage: 1231.29 MB\n","epoch 82 | loss: 0.00014 | train_mae: 0.00044999999227002263| train_rmse: 0.000699999975040555| valid_mae: 0.0004400000034365803| valid_rmse: 0.0007300000288523734|  0:01:37s\n","Memory Usage: 1231.29 MB\n","epoch 83 | loss: 0.00014 | train_mae: 0.00039000000106170774| train_rmse: 0.0005099999834783375| valid_mae: 0.00039000000106170774| valid_rmse: 0.0005099999834783375|  0:01:39s\n","Memory Usage: 1231.29 MB\n","epoch 84 | loss: 0.00014 | train_mae: 0.0003699999942909926| train_rmse: 0.0004900000058114529| valid_mae: 0.0003699999942909926| valid_rmse: 0.0005000000237487257|  0:01:40s\n","Memory Usage: 1231.29 MB\n","epoch 85 | loss: 0.00015 | train_mae: 0.0003499999875202775| train_rmse: 0.0004799999878741801| valid_mae: 0.0003499999875202775| valid_rmse: 0.0004900000058114529|  0:01:41s\n","Memory Usage: 1231.29 MB\n","epoch 86 | loss: 0.00014 | train_mae: 0.0003499999875202775| train_rmse: 0.0004600000102072954| valid_mae: 0.00033999999868683517| valid_rmse: 0.00044999999227002263|  0:01:42s\n","Memory Usage: 1231.29 MB\n","epoch 87 | loss: 0.00014 | train_mae: 0.00033000000985339284| train_rmse: 0.0004400000034365803| valid_mae: 0.00031999999191612005| valid_rmse: 0.0004299999854993075|  0:01:43s\n","Memory Usage: 1231.29 MB\n","epoch 88 | loss: 0.00013 | train_mae: 0.00031999999191612005| train_rmse: 0.0004199999966658652| valid_mae: 0.00031999999191612005| valid_rmse: 0.00041000000783242285|  0:01:45s\n","Memory Usage: 1231.29 MB\n","epoch 89 | loss: 0.00013 | train_mae: 0.00033000000985339284| train_rmse: 0.0004400000034365803| valid_mae: 0.00033000000985339284| valid_rmse: 0.0004299999854993075|  0:01:46s\n","Memory Usage: 1231.29 MB\n","epoch 90 | loss: 0.00013 | train_mae: 0.00033000000985339284| train_rmse: 0.0004400000034365803| valid_mae: 0.00031999999191612005| valid_rmse: 0.0004199999966658652|  0:01:47s\n","Memory Usage: 1231.29 MB\n","epoch 91 | loss: 0.00013 | train_mae: 0.0004199999966658652| train_rmse: 0.0005499999970197678| valid_mae: 0.00041000000783242285| valid_rmse: 0.0005300000193528831|  0:01:48s\n","Memory Usage: 1231.29 MB\n","epoch 92 | loss: 0.00013 | train_mae: 0.00031999999191612005| train_rmse: 0.0004299999854993075| valid_mae: 0.00031999999191612005| valid_rmse: 0.0004199999966658652|  0:01:49s\n","Memory Usage: 1231.29 MB\n","epoch 93 | loss: 0.00013 | train_mae: 0.00033000000985339284| train_rmse: 0.0004299999854993075| valid_mae: 0.00033000000985339284| valid_rmse: 0.0004299999854993075|  0:01:51s\n","Memory Usage: 1231.29 MB\n","epoch 94 | loss: 0.00012 | train_mae: 0.0003699999942909926| train_rmse: 0.0005000000237487257| valid_mae: 0.0003600000054575503| valid_rmse: 0.0004900000058114529|  0:01:52s\n","Memory Usage: 1231.29 MB\n","epoch 95 | loss: 0.00013 | train_mae: 0.00033999999868683517| train_rmse: 0.00044999999227002263| valid_mae: 0.00033000000985339284| valid_rmse: 0.0004299999854993075|  0:01:53s\n","Memory Usage: 1231.29 MB\n","epoch 96 | loss: 0.00012 | train_mae: 0.0003699999942909926| train_rmse: 0.0004900000058114529| valid_mae: 0.0003499999875202775| valid_rmse: 0.00046999999904073775|  0:01:54s\n","Memory Usage: 1231.29 MB\n","epoch 97 | loss: 0.00012 | train_mae: 0.00039000000106170774| train_rmse: 0.0005099999834783375| valid_mae: 0.0003699999942909926| valid_rmse: 0.0004900000058114529|  0:01:55s\n","Memory Usage: 1231.29 MB\n","epoch 98 | loss: 0.00012 | train_mae: 0.00033000000985339284| train_rmse: 0.0004299999854993075| valid_mae: 0.00031999999191612005| valid_rmse: 0.0004199999966658652|  0:01:56s\n","Memory Usage: 1231.29 MB\n","\n","Early stopping occurred at epoch 98 with best_epoch = 88 and best_valid_rmse = 0.00041000000783242285\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n"]}]},{"cell_type":"code","source":["from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, classification_report\n","\n","preds = best_model.predict(X_test)\n","y_true = y_test\n","\n","mae_test = mean_absolute_error(y_pred=preds, y_true=y_true)\n","mse = mean_squared_error(y_pred=preds, y_true=y_true)\n","rmse_test = np.sqrt(mean_squared_error(y_true, y_pred=preds))\n","r2_test = r2_score(y_true=y_true, y_pred=preds)\n","\n","print(\"Best Valid RMSE:\", best_model.best_cost)\n","print(\"Test MAE:\", mae_test)\n","print(\"Test RMSE:\", rmse_test)\n","print(\"R-squared:\", r2_test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"o3TYXT_o_6oS","executionInfo":{"status":"ok","timestamp":1728987235062,"user_tz":-480,"elapsed":8,"user":{"displayName":"Jonindo Pasaribu","userId":"10958990953097471082"}},"outputId":"970c9be1-9c5e-45ef-f49f-92b499178542"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Best Valid RMSE: 0.00041069344\n","Test MAE: 0.0003236484\n","Test RMSE: 0.00042569902\n","R-squared: -0.12583589553833008\n"]}]},{"cell_type":"code","source":["base_preds = tnr.predict(X_test)\n","\n","base_mae_test = mean_absolute_error(y_pred=base_preds, y_true=y_true)\n","base_mse = mean_squared_error(y_pred=base_preds, y_true=y_true)\n","base_rmse_test = np.sqrt(mean_squared_error(y_true, y_pred=base_preds))\n","\n","print(\"Best Valid Score:\", tnr.best_cost)\n","print(\"Test MAE:\", base_mae_test)\n","print(\"Test RMSE:\", base_rmse_test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8nW4N4ls2O6R","executionInfo":{"status":"ok","timestamp":1719672605118,"user_tz":-420,"elapsed":499,"user":{"displayName":"Jonindo Pasaribu","userId":"10958990953097471082"}},"outputId":"2f082f17-fee7-459e-ceb6-3aa22068adad"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Best Valid Score: 0.0007780627\n","Test MAE: 0.00063304434\n","Test RMSE: 0.00079291884\n"]}]}]}