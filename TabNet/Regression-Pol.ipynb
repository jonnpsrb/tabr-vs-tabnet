{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","machine_shape":"hm","authorship_tag":"ABX9TyN5QXWQT0pPIe94yliLfNGy"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["!wget https://huggingface.co/datasets/puhsu/tabular-benchmarks/resolve/main/data.tar -O tabular-dl-tabr.tar.gz\n","!tar -xvf tabular-dl-tabr.tar.gz"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pulqlCAgJDEt","executionInfo":{"status":"ok","timestamp":1728996381923,"user_tz":-480,"elapsed":16966,"user":{"displayName":"Jonindo Pasaribu","userId":"10958990953097471082"}},"outputId":"dbaca8ed-2297-4785-fb68-d5e52666abd5"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["--2024-10-15 12:46:04--  https://huggingface.co/datasets/puhsu/tabular-benchmarks/resolve/main/data.tar\n","Resolving huggingface.co (huggingface.co)... 18.244.202.60, 18.244.202.68, 18.244.202.118, ...\n","Connecting to huggingface.co (huggingface.co)|18.244.202.60|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://cdn-lfs.hf.co/repos/1b/25/1b25d6e2556c827abfaf6ba9da6021338691cafc39fe9d77986955ae0a69243d/0d74e4b96febb48fbe4dd2d851f8638b5738354f82c3183f92adbd2abf2f256b?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27data.tar%3B+filename%3D%22data.tar%22%3B&response-content-type=application%2Fx-tar&Expires=1729255565&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcyOTI1NTU2NX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5oZi5jby9yZXBvcy8xYi8yNS8xYjI1ZDZlMjU1NmM4MjdhYmZhZjZiYTlkYTYwMjEzMzg2OTFjYWZjMzlmZTlkNzc5ODY5NTVhZTBhNjkyNDNkLzBkNzRlNGI5NmZlYmI0OGZiZTRkZDJkODUxZjg2MzhiNTczODM1NGY4MmMzMTgzZjkyYWRiZDJhYmYyZjI1NmI%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qJnJlc3BvbnNlLWNvbnRlbnQtdHlwZT0qIn1dfQ__&Signature=jBzz3T1WMPQeFqzSyWdB0PrQJuBXiXdTKTHVJsiFe4z5YvKR1GO3JT-6MQ05fi%7EfeZCN6bwAypv0c-d7-kNk36bcsN8wWNQgGhydTVAHmGU57R83gpnJTNP2ggQ93-sQdjcGYquVM%7EEg1L1r6sd8PQuAIfPBWdeQ-YMPla0cSL4sd%7EmWDioZzjbRz2EGI57OFTyNb53sBzAtBD8CtvTQwwIBu8ltOrmlK5lXShjXGTtV6xDbTOJtp3PLXnemxcghlNRbzkkiKxO6PmNGxqCGIZkDIwiVenZvcQqKm1LF3hqoWZXx7%7EHDhKj5VSWcHe%7Eq5%7EaLoJkZm97KlRh%7Ea%7EZHdg__&Key-Pair-Id=K3RPWS32NSSJCE [following]\n","--2024-10-15 12:46:05--  https://cdn-lfs.hf.co/repos/1b/25/1b25d6e2556c827abfaf6ba9da6021338691cafc39fe9d77986955ae0a69243d/0d74e4b96febb48fbe4dd2d851f8638b5738354f82c3183f92adbd2abf2f256b?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27data.tar%3B+filename%3D%22data.tar%22%3B&response-content-type=application%2Fx-tar&Expires=1729255565&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcyOTI1NTU2NX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5oZi5jby9yZXBvcy8xYi8yNS8xYjI1ZDZlMjU1NmM4MjdhYmZhZjZiYTlkYTYwMjEzMzg2OTFjYWZjMzlmZTlkNzc5ODY5NTVhZTBhNjkyNDNkLzBkNzRlNGI5NmZlYmI0OGZiZTRkZDJkODUxZjg2MzhiNTczODM1NGY4MmMzMTgzZjkyYWRiZDJhYmYyZjI1NmI%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qJnJlc3BvbnNlLWNvbnRlbnQtdHlwZT0qIn1dfQ__&Signature=jBzz3T1WMPQeFqzSyWdB0PrQJuBXiXdTKTHVJsiFe4z5YvKR1GO3JT-6MQ05fi%7EfeZCN6bwAypv0c-d7-kNk36bcsN8wWNQgGhydTVAHmGU57R83gpnJTNP2ggQ93-sQdjcGYquVM%7EEg1L1r6sd8PQuAIfPBWdeQ-YMPla0cSL4sd%7EmWDioZzjbRz2EGI57OFTyNb53sBzAtBD8CtvTQwwIBu8ltOrmlK5lXShjXGTtV6xDbTOJtp3PLXnemxcghlNRbzkkiKxO6PmNGxqCGIZkDIwiVenZvcQqKm1LF3hqoWZXx7%7EHDhKj5VSWcHe%7Eq5%7EaLoJkZm97KlRh%7Ea%7EZHdg__&Key-Pair-Id=K3RPWS32NSSJCE\n","Resolving cdn-lfs.hf.co (cdn-lfs.hf.co)... 18.160.78.43, 18.160.78.76, 18.160.78.83, ...\n","Connecting to cdn-lfs.hf.co (cdn-lfs.hf.co)|18.160.78.43|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 3094384640 (2.9G) [application/x-tar]\n","Saving to: ‘tabular-dl-tabr.tar.gz’\n","\n","tabular-dl-tabr.tar 100%[===================>]   2.88G   321MB/s    in 9.2s    \n","\n","2024-10-15 12:46:14 (320 MB/s) - ‘tabular-dl-tabr.tar.gz’ saved [3094384640/3094384640]\n","\n","data/\n","data/regression-num-medium-0-Ailerons/\n","data/regression-num-medium-0-Ailerons/X_num_val.npy\n","data/regression-num-medium-0-Ailerons/Y_val.npy\n","data/regression-num-medium-0-Ailerons/X_num_train.npy\n","data/regression-num-medium-0-Ailerons/info.json\n","data/regression-num-medium-0-Ailerons/READY\n","data/regression-num-medium-0-Ailerons/X_num_test.npy\n","data/regression-num-medium-0-Ailerons/Y_test.npy\n","data/regression-num-medium-0-Ailerons/Y_train.npy\n","data/regression-cat-medium-0-house_sales/\n","data/regression-cat-medium-0-house_sales/X_num_val.npy\n","data/regression-cat-medium-0-house_sales/Y_val.npy\n","data/regression-cat-medium-0-house_sales/X_bin_val.npy\n","data/regression-cat-medium-0-house_sales/X_num_train.npy\n","data/regression-cat-medium-0-house_sales/X_bin_train.npy\n","data/regression-cat-medium-0-house_sales/info.json\n","data/regression-cat-medium-0-house_sales/READY\n","data/regression-cat-medium-0-house_sales/X_bin_test.npy\n","data/regression-cat-medium-0-house_sales/X_num_test.npy\n","data/regression-cat-medium-0-house_sales/Y_test.npy\n","data/regression-cat-medium-0-house_sales/Y_train.npy\n","data/classif-cat-medium-2-KDDCup09_upselling/\n","data/classif-cat-medium-2-KDDCup09_upselling/X_cat_val.npy\n","data/classif-cat-medium-2-KDDCup09_upselling/X_num_val.npy\n","data/classif-cat-medium-2-KDDCup09_upselling/Y_val.npy\n","data/classif-cat-medium-2-KDDCup09_upselling/X_bin_val.npy\n","data/classif-cat-medium-2-KDDCup09_upselling/X_num_train.npy\n","data/classif-cat-medium-2-KDDCup09_upselling/X_cat_test.npy\n","data/classif-cat-medium-2-KDDCup09_upselling/X_bin_train.npy\n","data/classif-cat-medium-2-KDDCup09_upselling/X_cat_train.npy\n","data/classif-cat-medium-2-KDDCup09_upselling/info.json\n","data/classif-cat-medium-2-KDDCup09_upselling/READY\n","data/classif-cat-medium-2-KDDCup09_upselling/X_bin_test.npy\n","data/classif-cat-medium-2-KDDCup09_upselling/X_num_test.npy\n","data/classif-cat-medium-2-KDDCup09_upselling/Y_test.npy\n","data/classif-cat-medium-2-KDDCup09_upselling/Y_train.npy\n","data/regression-num-medium-2-isolet/\n","data/regression-num-medium-2-isolet/X_num_val.npy\n","data/regression-num-medium-2-isolet/Y_val.npy\n","data/regression-num-medium-2-isolet/X_num_train.npy\n","data/regression-num-medium-2-isolet/info.json\n","data/regression-num-medium-2-isolet/READY\n","data/regression-num-medium-2-isolet/X_num_test.npy\n","data/regression-num-medium-2-isolet/Y_test.npy\n","data/regression-num-medium-2-isolet/Y_train.npy\n","data/regression-cat-medium-1-Brazilian_houses/\n","data/regression-cat-medium-1-Brazilian_houses/X_cat_val.npy\n","data/regression-cat-medium-1-Brazilian_houses/X_num_val.npy\n","data/regression-cat-medium-1-Brazilian_houses/Y_val.npy\n","data/regression-cat-medium-1-Brazilian_houses/X_bin_val.npy\n","data/regression-cat-medium-1-Brazilian_houses/X_num_train.npy\n","data/regression-cat-medium-1-Brazilian_houses/X_cat_test.npy\n","data/regression-cat-medium-1-Brazilian_houses/X_bin_train.npy\n","data/regression-cat-medium-1-Brazilian_houses/X_cat_train.npy\n","data/regression-cat-medium-1-Brazilian_houses/info.json\n","data/regression-cat-medium-1-Brazilian_houses/READY\n","data/regression-cat-medium-1-Brazilian_houses/X_bin_test.npy\n","data/regression-cat-medium-1-Brazilian_houses/X_num_test.npy\n","data/regression-cat-medium-1-Brazilian_houses/Y_test.npy\n","data/regression-cat-medium-1-Brazilian_houses/Y_train.npy\n","data/regression-num-medium-2-wine_quality/\n","data/regression-num-medium-2-wine_quality/X_num_val.npy\n","data/regression-num-medium-2-wine_quality/Y_val.npy\n","data/regression-num-medium-2-wine_quality/X_num_train.npy\n","data/regression-num-medium-2-wine_quality/info.json\n","data/regression-num-medium-2-wine_quality/READY\n","data/regression-num-medium-2-wine_quality/X_num_test.npy\n","data/regression-num-medium-2-wine_quality/Y_test.npy\n","data/regression-num-medium-2-wine_quality/Y_train.npy\n","data/regression-num-medium-0-california/\n","data/regression-num-medium-0-california/X_num_val.npy\n","data/regression-num-medium-0-california/Y_val.npy\n","data/regression-num-medium-0-california/X_num_train.npy\n","data/regression-num-medium-0-california/info.json\n","data/regression-num-medium-0-california/READY\n","data/regression-num-medium-0-california/X_num_test.npy\n","data/regression-num-medium-0-california/Y_test.npy\n","data/regression-num-medium-0-california/Y_train.npy\n","data/classif-num-medium-2-wine/\n","data/classif-num-medium-2-wine/X_num_val.npy\n","data/classif-num-medium-2-wine/Y_val.npy\n","data/classif-num-medium-2-wine/X_num_train.npy\n","data/classif-num-medium-2-wine/info.json\n","data/classif-num-medium-2-wine/READY\n","data/classif-num-medium-2-wine/X_num_test.npy\n","data/classif-num-medium-2-wine/Y_test.npy\n","data/classif-num-medium-2-wine/Y_train.npy\n","data/classif-num-medium-1-phoneme/\n","data/classif-num-medium-1-phoneme/X_num_val.npy\n","data/classif-num-medium-1-phoneme/Y_val.npy\n","data/classif-num-medium-1-phoneme/X_num_train.npy\n","data/classif-num-medium-1-phoneme/info.json\n","data/classif-num-medium-1-phoneme/READY\n","data/classif-num-medium-1-phoneme/X_num_test.npy\n","data/classif-num-medium-1-phoneme/Y_test.npy\n","data/classif-num-medium-1-phoneme/Y_train.npy\n","data/regression-num-medium-1-isolet/\n","data/regression-num-medium-1-isolet/X_num_val.npy\n","data/regression-num-medium-1-isolet/Y_val.npy\n","data/regression-num-medium-1-isolet/X_num_train.npy\n","data/regression-num-medium-1-isolet/info.json\n","data/regression-num-medium-1-isolet/READY\n","data/regression-num-medium-1-isolet/X_num_test.npy\n","data/regression-num-medium-1-isolet/Y_test.npy\n","data/regression-num-medium-1-isolet/Y_train.npy\n","data/churn/\n","data/churn/X_cat_val.npy\n","data/churn/X_num_val.npy\n","data/churn/Y_val.npy\n","data/churn/X_bin_val.npy\n","data/churn/X_num_train.npy\n","data/churn/X_cat_test.npy\n","data/churn/X_bin_train.npy\n","data/churn/X_cat_train.npy\n","data/churn/info.json\n","data/churn/READY\n","data/churn/X_bin_test.npy\n","data/churn/X_num_test.npy\n","data/churn/Y_test.npy\n","data/churn/Y_train.npy\n","data/regression-num-medium-2-sulfur/\n","data/regression-num-medium-2-sulfur/X_num_val.npy\n","data/regression-num-medium-2-sulfur/Y_val.npy\n","data/regression-num-medium-2-sulfur/X_num_train.npy\n","data/regression-num-medium-2-sulfur/info.json\n","data/regression-num-medium-2-sulfur/READY\n","data/regression-num-medium-2-sulfur/X_num_test.npy\n","data/regression-num-medium-2-sulfur/Y_test.npy\n","data/regression-num-medium-2-sulfur/Y_train.npy\n","data/regression-cat-large-0-diamonds/\n","data/regression-cat-large-0-diamonds/X_cat_val.npy\n","data/regression-cat-large-0-diamonds/X_num_val.npy\n","data/regression-cat-large-0-diamonds/Y_val.npy\n","data/regression-cat-large-0-diamonds/X_num_train.npy\n","data/regression-cat-large-0-diamonds/X_cat_test.npy\n","data/regression-cat-large-0-diamonds/X_cat_train.npy\n","data/regression-cat-large-0-diamonds/info.json\n","data/regression-cat-large-0-diamonds/READY\n","data/regression-cat-large-0-diamonds/X_num_test.npy\n","data/regression-cat-large-0-diamonds/Y_test.npy\n","data/regression-cat-large-0-diamonds/Y_train.npy\n","data/classif-cat-large-0-road-safety/\n","data/classif-cat-large-0-road-safety/X_cat_val.npy\n","data/classif-cat-large-0-road-safety/X_num_val.npy\n","data/classif-cat-large-0-road-safety/Y_val.npy\n","data/classif-cat-large-0-road-safety/X_num_train.npy\n","data/classif-cat-large-0-road-safety/X_cat_test.npy\n","data/classif-cat-large-0-road-safety/X_cat_train.npy\n","data/classif-cat-large-0-road-safety/info.json\n","data/classif-cat-large-0-road-safety/READY\n","data/classif-cat-large-0-road-safety/X_num_test.npy\n","data/classif-cat-large-0-road-safety/Y_test.npy\n","data/classif-cat-large-0-road-safety/Y_train.npy\n","data/classif-num-medium-1-MagicTelescope/\n","data/classif-num-medium-1-MagicTelescope/X_num_val.npy\n","data/classif-num-medium-1-MagicTelescope/Y_val.npy\n","data/classif-num-medium-1-MagicTelescope/X_num_train.npy\n","data/classif-num-medium-1-MagicTelescope/info.json\n","data/classif-num-medium-1-MagicTelescope/READY\n","data/classif-num-medium-1-MagicTelescope/X_num_test.npy\n","data/classif-num-medium-1-MagicTelescope/Y_test.npy\n","data/classif-num-medium-1-MagicTelescope/Y_train.npy\n","data/regression-num-medium-0-wine_quality/\n","data/regression-num-medium-0-wine_quality/X_num_val.npy\n","data/regression-num-medium-0-wine_quality/Y_val.npy\n","data/regression-num-medium-0-wine_quality/X_num_train.npy\n","data/regression-num-medium-0-wine_quality/info.json\n","data/regression-num-medium-0-wine_quality/READY\n","data/regression-num-medium-0-wine_quality/X_num_test.npy\n","data/regression-num-medium-0-wine_quality/Y_test.npy\n","data/regression-num-medium-0-wine_quality/Y_train.npy\n","data/adult/\n","data/adult/X_cat_val.npy\n","data/adult/X_num_val.npy\n","data/adult/Y_val.npy\n","data/adult/X_bin_val.npy\n","data/adult/X_num_train.npy\n","data/adult/X_cat_test.npy\n","data/adult/X_bin_train.npy\n","data/adult/X_cat_train.npy\n","data/adult/info.json\n","data/adult/READY\n","data/adult/X_bin_test.npy\n","data/adult/X_num_test.npy\n","data/adult/Y_test.npy\n","data/adult/Y_train.npy\n","data/classif-num-medium-1-kdd_ipums_la_97-small/\n","data/classif-num-medium-1-kdd_ipums_la_97-small/X_num_val.npy\n","data/classif-num-medium-1-kdd_ipums_la_97-small/Y_val.npy\n","data/classif-num-medium-1-kdd_ipums_la_97-small/X_num_train.npy\n","data/classif-num-medium-1-kdd_ipums_la_97-small/info.json\n","data/classif-num-medium-1-kdd_ipums_la_97-small/READY\n","data/classif-num-medium-1-kdd_ipums_la_97-small/X_num_test.npy\n","data/classif-num-medium-1-kdd_ipums_la_97-small/Y_test.npy\n","data/classif-num-medium-1-kdd_ipums_la_97-small/Y_train.npy\n","data/regression-num-medium-0-superconduct/\n","data/regression-num-medium-0-superconduct/X_num_val.npy\n","data/regression-num-medium-0-superconduct/Y_val.npy\n","data/regression-num-medium-0-superconduct/X_num_train.npy\n","data/regression-num-medium-0-superconduct/info.json\n","data/regression-num-medium-0-superconduct/READY\n","data/regression-num-medium-0-superconduct/X_num_test.npy\n","data/regression-num-medium-0-superconduct/Y_test.npy\n","data/regression-num-medium-0-superconduct/Y_train.npy\n","data/regression-num-medium-0-house_16H/\n","data/regression-num-medium-0-house_16H/X_num_val.npy\n","data/regression-num-medium-0-house_16H/Y_val.npy\n","data/regression-num-medium-0-house_16H/X_num_train.npy\n","data/regression-num-medium-0-house_16H/info.json\n","data/regression-num-medium-0-house_16H/READY\n","data/regression-num-medium-0-house_16H/X_num_test.npy\n","data/regression-num-medium-0-house_16H/Y_test.npy\n","data/regression-num-medium-0-house_16H/Y_train.npy\n","data/weather-big/\n","data/weather-big/X_num_val.npy\n","data/weather-big/Y_val.npy\n","data/weather-big/X_bin_val.npy\n","data/weather-big/X_num_train.npy\n","data/weather-big/X_bin_train.npy\n","data/weather-big/LICENSE.md\n","data/weather-big/info.json\n","data/weather-big/READY\n","data/weather-big/X_bin_test.npy\n","data/weather-big/X_num_test.npy\n","data/weather-big/Y_test.npy\n","data/weather-big/Y_train.npy\n","data/classif-num-large-0-Higgs/\n","data/classif-num-large-0-Higgs/X_num_val.npy\n","data/classif-num-large-0-Higgs/Y_val.npy\n","data/classif-num-large-0-Higgs/X_num_train.npy\n","data/classif-num-large-0-Higgs/info.json\n","data/classif-num-large-0-Higgs/READY\n","data/classif-num-large-0-Higgs/X_num_test.npy\n","data/classif-num-large-0-Higgs/Y_test.npy\n","data/classif-num-large-0-Higgs/Y_train.npy\n","data/regression-cat-medium-2-analcatdata_supreme/\n","data/regression-cat-medium-2-analcatdata_supreme/X_num_val.npy\n","data/regression-cat-medium-2-analcatdata_supreme/Y_val.npy\n","data/regression-cat-medium-2-analcatdata_supreme/X_bin_val.npy\n","data/regression-cat-medium-2-analcatdata_supreme/X_num_train.npy\n","data/regression-cat-medium-2-analcatdata_supreme/X_bin_train.npy\n","data/regression-cat-medium-2-analcatdata_supreme/info.json\n","data/regression-cat-medium-2-analcatdata_supreme/READY\n","data/regression-cat-medium-2-analcatdata_supreme/X_bin_test.npy\n","data/regression-cat-medium-2-analcatdata_supreme/X_num_test.npy\n","data/regression-cat-medium-2-analcatdata_supreme/Y_test.npy\n","data/regression-cat-medium-2-analcatdata_supreme/Y_train.npy\n","data/regression-cat-large-0-black_friday/\n","data/regression-cat-large-0-black_friday/X_cat_val.npy\n","data/regression-cat-large-0-black_friday/X_num_val.npy\n","data/regression-cat-large-0-black_friday/Y_val.npy\n","data/regression-cat-large-0-black_friday/X_bin_val.npy\n","data/regression-cat-large-0-black_friday/X_num_train.npy\n","data/regression-cat-large-0-black_friday/X_cat_test.npy\n","data/regression-cat-large-0-black_friday/X_bin_train.npy\n","data/regression-cat-large-0-black_friday/X_cat_train.npy\n","data/regression-cat-large-0-black_friday/info.json\n","data/regression-cat-large-0-black_friday/READY\n","data/regression-cat-large-0-black_friday/X_bin_test.npy\n","data/regression-cat-large-0-black_friday/X_num_test.npy\n","data/regression-cat-large-0-black_friday/Y_test.npy\n","data/regression-cat-large-0-black_friday/Y_train.npy\n","data/classif-num-medium-1-wine/\n","data/classif-num-medium-1-wine/X_num_val.npy\n","data/classif-num-medium-1-wine/Y_val.npy\n","data/classif-num-medium-1-wine/X_num_train.npy\n","data/classif-num-medium-1-wine/info.json\n","data/classif-num-medium-1-wine/READY\n","data/classif-num-medium-1-wine/X_num_test.npy\n","data/classif-num-medium-1-wine/Y_test.npy\n","data/classif-num-medium-1-wine/Y_train.npy\n","data/regression-cat-medium-0-visualizing_soil/\n","data/regression-cat-medium-0-visualizing_soil/X_num_val.npy\n","data/regression-cat-medium-0-visualizing_soil/Y_val.npy\n","data/regression-cat-medium-0-visualizing_soil/X_bin_val.npy\n","data/regression-cat-medium-0-visualizing_soil/X_num_train.npy\n","data/regression-cat-medium-0-visualizing_soil/X_bin_train.npy\n","data/regression-cat-medium-0-visualizing_soil/info.json\n","data/regression-cat-medium-0-visualizing_soil/READY\n","data/regression-cat-medium-0-visualizing_soil/X_bin_test.npy\n","data/regression-cat-medium-0-visualizing_soil/X_num_test.npy\n","data/regression-cat-medium-0-visualizing_soil/Y_test.npy\n","data/regression-cat-medium-0-visualizing_soil/Y_train.npy\n","data/regression-cat-medium-1-Mercedes_Benz_Greener_Manufacturing/\n","data/regression-cat-medium-1-Mercedes_Benz_Greener_Manufacturing/X_cat_val.npy\n","data/regression-cat-medium-1-Mercedes_Benz_Greener_Manufacturing/Y_val.npy\n","data/regression-cat-medium-1-Mercedes_Benz_Greener_Manufacturing/X_bin_val.npy\n","data/regression-cat-medium-1-Mercedes_Benz_Greener_Manufacturing/X_cat_test.npy\n","data/regression-cat-medium-1-Mercedes_Benz_Greener_Manufacturing/X_bin_train.npy\n","data/regression-cat-medium-1-Mercedes_Benz_Greener_Manufacturing/X_cat_train.npy\n","data/regression-cat-medium-1-Mercedes_Benz_Greener_Manufacturing/info.json\n","data/regression-cat-medium-1-Mercedes_Benz_Greener_Manufacturing/READY\n","data/regression-cat-medium-1-Mercedes_Benz_Greener_Manufacturing/X_bin_test.npy\n","data/regression-cat-medium-1-Mercedes_Benz_Greener_Manufacturing/Y_test.npy\n","data/regression-cat-medium-1-Mercedes_Benz_Greener_Manufacturing/Y_train.npy\n","data/classif-num-medium-0-kdd_ipums_la_97-small/\n","data/classif-num-medium-0-kdd_ipums_la_97-small/X_num_val.npy\n","data/classif-num-medium-0-kdd_ipums_la_97-small/Y_val.npy\n","data/classif-num-medium-0-kdd_ipums_la_97-small/X_num_train.npy\n","data/classif-num-medium-0-kdd_ipums_la_97-small/info.json\n","data/classif-num-medium-0-kdd_ipums_la_97-small/READY\n","data/classif-num-medium-0-kdd_ipums_la_97-small/X_num_test.npy\n","data/classif-num-medium-0-kdd_ipums_la_97-small/Y_test.npy\n","data/classif-num-medium-0-kdd_ipums_la_97-small/Y_train.npy\n","data/regression-num-medium-1-MiamiHousing2016/\n","data/regression-num-medium-1-MiamiHousing2016/X_num_val.npy\n","data/regression-num-medium-1-MiamiHousing2016/Y_val.npy\n","data/regression-num-medium-1-MiamiHousing2016/X_num_train.npy\n","data/regression-num-medium-1-MiamiHousing2016/info.json\n","data/regression-num-medium-1-MiamiHousing2016/READY\n","data/regression-num-medium-1-MiamiHousing2016/X_num_test.npy\n","data/regression-num-medium-1-MiamiHousing2016/Y_test.npy\n","data/regression-num-medium-1-MiamiHousing2016/Y_train.npy\n","data/regression-cat-medium-0-OnlineNewsPopularity/\n","data/regression-cat-medium-0-OnlineNewsPopularity/X_num_val.npy\n","data/regression-cat-medium-0-OnlineNewsPopularity/Y_val.npy\n","data/regression-cat-medium-0-OnlineNewsPopularity/X_bin_val.npy\n","data/regression-cat-medium-0-OnlineNewsPopularity/X_num_train.npy\n","data/regression-cat-medium-0-OnlineNewsPopularity/X_bin_train.npy\n","data/regression-cat-medium-0-OnlineNewsPopularity/info.json\n","data/regression-cat-medium-0-OnlineNewsPopularity/READY\n","data/regression-cat-medium-0-OnlineNewsPopularity/X_bin_test.npy\n","data/regression-cat-medium-0-OnlineNewsPopularity/X_num_test.npy\n","data/regression-cat-medium-0-OnlineNewsPopularity/Y_test.npy\n","data/regression-cat-medium-0-OnlineNewsPopularity/Y_train.npy\n","data/regression-num-medium-1-elevators/\n","data/regression-num-medium-1-elevators/X_num_val.npy\n","data/regression-num-medium-1-elevators/Y_val.npy\n","data/regression-num-medium-1-elevators/X_num_train.npy\n","data/regression-num-medium-1-elevators/info.json\n","data/regression-num-medium-1-elevators/READY\n","data/regression-num-medium-1-elevators/X_num_test.npy\n","data/regression-num-medium-1-elevators/Y_test.npy\n","data/regression-num-medium-1-elevators/Y_train.npy\n","data/regression-num-medium-0-pol/\n","data/regression-num-medium-0-pol/X_num_val.npy\n","data/regression-num-medium-0-pol/Y_val.npy\n","data/regression-num-medium-0-pol/X_num_train.npy\n","data/regression-num-medium-0-pol/info.json\n","data/regression-num-medium-0-pol/READY\n","data/regression-num-medium-0-pol/X_num_test.npy\n","data/regression-num-medium-0-pol/Y_test.npy\n","data/regression-num-medium-0-pol/Y_train.npy\n","data/classif-num-medium-2-kdd_ipums_la_97-small/\n","data/classif-num-medium-2-kdd_ipums_la_97-small/X_num_val.npy\n","data/classif-num-medium-2-kdd_ipums_la_97-small/Y_val.npy\n","data/classif-num-medium-2-kdd_ipums_la_97-small/X_num_train.npy\n","data/classif-num-medium-2-kdd_ipums_la_97-small/info.json\n","data/classif-num-medium-2-kdd_ipums_la_97-small/READY\n","data/classif-num-medium-2-kdd_ipums_la_97-small/X_num_test.npy\n","data/classif-num-medium-2-kdd_ipums_la_97-small/Y_test.npy\n","data/classif-num-medium-2-kdd_ipums_la_97-small/Y_train.npy\n","data/classif-num-medium-0-phoneme/\n","data/classif-num-medium-0-phoneme/X_num_val.npy\n","data/classif-num-medium-0-phoneme/Y_val.npy\n","data/classif-num-medium-0-phoneme/X_num_train.npy\n","data/classif-num-medium-0-phoneme/info.json\n","data/classif-num-medium-0-phoneme/READY\n","data/classif-num-medium-0-phoneme/X_num_test.npy\n","data/classif-num-medium-0-phoneme/Y_test.npy\n","data/classif-num-medium-0-phoneme/Y_train.npy\n","data/regression-num-medium-0-sulfur/\n","data/regression-num-medium-0-sulfur/X_num_val.npy\n","data/regression-num-medium-0-sulfur/Y_val.npy\n","data/regression-num-medium-0-sulfur/X_num_train.npy\n","data/regression-num-medium-0-sulfur/info.json\n","data/regression-num-medium-0-sulfur/READY\n","data/regression-num-medium-0-sulfur/X_num_test.npy\n","data/regression-num-medium-0-sulfur/Y_test.npy\n","data/regression-num-medium-0-sulfur/Y_train.npy\n","data/regression-cat-medium-0-analcatdata_supreme/\n","data/regression-cat-medium-0-analcatdata_supreme/X_num_val.npy\n","data/regression-cat-medium-0-analcatdata_supreme/Y_val.npy\n","data/regression-cat-medium-0-analcatdata_supreme/X_bin_val.npy\n","data/regression-cat-medium-0-analcatdata_supreme/X_num_train.npy\n","data/regression-cat-medium-0-analcatdata_supreme/X_bin_train.npy\n","data/regression-cat-medium-0-analcatdata_supreme/info.json\n","data/regression-cat-medium-0-analcatdata_supreme/READY\n","data/regression-cat-medium-0-analcatdata_supreme/X_bin_test.npy\n","data/regression-cat-medium-0-analcatdata_supreme/X_num_test.npy\n","data/regression-cat-medium-0-analcatdata_supreme/Y_test.npy\n","data/regression-cat-medium-0-analcatdata_supreme/Y_train.npy\n","data/classif-num-medium-2-phoneme/\n","data/classif-num-medium-2-phoneme/X_num_val.npy\n","data/classif-num-medium-2-phoneme/Y_val.npy\n","data/classif-num-medium-2-phoneme/X_num_train.npy\n","data/classif-num-medium-2-phoneme/info.json\n","data/classif-num-medium-2-phoneme/READY\n","data/classif-num-medium-2-phoneme/X_num_test.npy\n","data/classif-num-medium-2-phoneme/Y_test.npy\n","data/classif-num-medium-2-phoneme/Y_train.npy\n","data/regression-cat-large-0-SGEMM_GPU_kernel_performance/\n","data/regression-cat-large-0-SGEMM_GPU_kernel_performance/X_num_val.npy\n","data/regression-cat-large-0-SGEMM_GPU_kernel_performance/Y_val.npy\n","data/regression-cat-large-0-SGEMM_GPU_kernel_performance/X_bin_val.npy\n","data/regression-cat-large-0-SGEMM_GPU_kernel_performance/X_num_train.npy\n","data/regression-cat-large-0-SGEMM_GPU_kernel_performance/X_bin_train.npy\n","data/regression-cat-large-0-SGEMM_GPU_kernel_performance/info.json\n","data/regression-cat-large-0-SGEMM_GPU_kernel_performance/READY\n","data/regression-cat-large-0-SGEMM_GPU_kernel_performance/X_bin_test.npy\n","data/regression-cat-large-0-SGEMM_GPU_kernel_performance/X_num_test.npy\n","data/regression-cat-large-0-SGEMM_GPU_kernel_performance/Y_test.npy\n","data/regression-cat-large-0-SGEMM_GPU_kernel_performance/Y_train.npy\n","data/regression-num-medium-1-wine_quality/\n","data/regression-num-medium-1-wine_quality/X_num_val.npy\n","data/regression-num-medium-1-wine_quality/Y_val.npy\n","data/regression-num-medium-1-wine_quality/X_num_train.npy\n","data/regression-num-medium-1-wine_quality/info.json\n","data/regression-num-medium-1-wine_quality/READY\n","data/regression-num-medium-1-wine_quality/X_num_test.npy\n","data/regression-num-medium-1-wine_quality/Y_test.npy\n","data/regression-num-medium-1-wine_quality/Y_train.npy\n","data/regression-num-medium-0-cpu_act/\n","data/regression-num-medium-0-cpu_act/X_num_val.npy\n","data/regression-num-medium-0-cpu_act/Y_val.npy\n","data/regression-num-medium-0-cpu_act/X_num_train.npy\n","data/regression-num-medium-0-cpu_act/info.json\n","data/regression-num-medium-0-cpu_act/READY\n","data/regression-num-medium-0-cpu_act/X_num_test.npy\n","data/regression-num-medium-0-cpu_act/Y_test.npy\n","data/regression-num-medium-0-cpu_act/Y_train.npy\n","data/regression-cat-medium-0-Bike_Sharing_Demand/\n","data/regression-cat-medium-0-Bike_Sharing_Demand/X_cat_val.npy\n","data/regression-cat-medium-0-Bike_Sharing_Demand/X_num_val.npy\n","data/regression-cat-medium-0-Bike_Sharing_Demand/Y_val.npy\n","data/regression-cat-medium-0-Bike_Sharing_Demand/X_bin_val.npy\n","data/regression-cat-medium-0-Bike_Sharing_Demand/X_num_train.npy\n","data/regression-cat-medium-0-Bike_Sharing_Demand/X_cat_test.npy\n","data/regression-cat-medium-0-Bike_Sharing_Demand/X_bin_train.npy\n","data/regression-cat-medium-0-Bike_Sharing_Demand/X_cat_train.npy\n","data/regression-cat-medium-0-Bike_Sharing_Demand/info.json\n","data/regression-cat-medium-0-Bike_Sharing_Demand/READY\n","data/regression-cat-medium-0-Bike_Sharing_Demand/X_bin_test.npy\n","data/regression-cat-medium-0-Bike_Sharing_Demand/X_num_test.npy\n","data/regression-cat-medium-0-Bike_Sharing_Demand/Y_test.npy\n","data/regression-cat-medium-0-Bike_Sharing_Demand/Y_train.npy\n","data/regression-cat-medium-1-visualizing_soil/\n","data/regression-cat-medium-1-visualizing_soil/X_num_val.npy\n","data/regression-cat-medium-1-visualizing_soil/Y_val.npy\n","data/regression-cat-medium-1-visualizing_soil/X_bin_val.npy\n","data/regression-cat-medium-1-visualizing_soil/X_num_train.npy\n","data/regression-cat-medium-1-visualizing_soil/X_bin_train.npy\n","data/regression-cat-medium-1-visualizing_soil/info.json\n","data/regression-cat-medium-1-visualizing_soil/READY\n","data/regression-cat-medium-1-visualizing_soil/X_bin_test.npy\n","data/regression-cat-medium-1-visualizing_soil/X_num_test.npy\n","data/regression-cat-medium-1-visualizing_soil/Y_test.npy\n","data/regression-cat-medium-1-visualizing_soil/Y_train.npy\n","data/classif-num-medium-4-phoneme/\n","data/classif-num-medium-4-phoneme/X_num_val.npy\n","data/classif-num-medium-4-phoneme/Y_val.npy\n","data/classif-num-medium-4-phoneme/X_num_train.npy\n","data/classif-num-medium-4-phoneme/info.json\n","data/classif-num-medium-4-phoneme/READY\n","data/classif-num-medium-4-phoneme/X_num_test.npy\n","data/classif-num-medium-4-phoneme/Y_test.npy\n","data/classif-num-medium-4-phoneme/Y_train.npy\n","data/house/\n","data/house/X_num_val.npy\n","data/house/Y_val.npy\n","data/house/X_num_train.npy\n","data/house/info.json\n","data/house/READY\n","data/house/X_num_test.npy\n","data/house/Y_test.npy\n","data/house/Y_train.npy\n","data/regression-cat-medium-2-Brazilian_houses/\n","data/regression-cat-medium-2-Brazilian_houses/X_cat_val.npy\n","data/regression-cat-medium-2-Brazilian_houses/X_num_val.npy\n","data/regression-cat-medium-2-Brazilian_houses/Y_val.npy\n","data/regression-cat-medium-2-Brazilian_houses/X_bin_val.npy\n","data/regression-cat-medium-2-Brazilian_houses/X_num_train.npy\n","data/regression-cat-medium-2-Brazilian_houses/X_cat_test.npy\n","data/regression-cat-medium-2-Brazilian_houses/X_bin_train.npy\n","data/regression-cat-medium-2-Brazilian_houses/X_cat_train.npy\n","data/regression-cat-medium-2-Brazilian_houses/info.json\n","data/regression-cat-medium-2-Brazilian_houses/READY\n","data/regression-cat-medium-2-Brazilian_houses/X_bin_test.npy\n","data/regression-cat-medium-2-Brazilian_houses/X_num_test.npy\n","data/regression-cat-medium-2-Brazilian_houses/Y_test.npy\n","data/regression-cat-medium-2-Brazilian_houses/Y_train.npy\n","data/regression-cat-large-0-particulate-matter-ukair-2017/\n","data/regression-cat-large-0-particulate-matter-ukair-2017/X_cat_val.npy\n","data/regression-cat-large-0-particulate-matter-ukair-2017/X_num_val.npy\n","data/regression-cat-large-0-particulate-matter-ukair-2017/Y_val.npy\n","data/regression-cat-large-0-particulate-matter-ukair-2017/X_num_train.npy\n","data/regression-cat-large-0-particulate-matter-ukair-2017/X_cat_test.npy\n","data/regression-cat-large-0-particulate-matter-ukair-2017/X_cat_train.npy\n","data/regression-cat-large-0-particulate-matter-ukair-2017/info.json\n","data/regression-cat-large-0-particulate-matter-ukair-2017/READY\n","data/regression-cat-large-0-particulate-matter-ukair-2017/X_num_test.npy\n","data/regression-cat-large-0-particulate-matter-ukair-2017/Y_test.npy\n","data/regression-cat-large-0-particulate-matter-ukair-2017/Y_train.npy\n","data/regression-cat-medium-2-Mercedes_Benz_Greener_Manufacturing/\n","data/regression-cat-medium-2-Mercedes_Benz_Greener_Manufacturing/X_cat_val.npy\n","data/regression-cat-medium-2-Mercedes_Benz_Greener_Manufacturing/Y_val.npy\n","data/regression-cat-medium-2-Mercedes_Benz_Greener_Manufacturing/X_bin_val.npy\n","data/regression-cat-medium-2-Mercedes_Benz_Greener_Manufacturing/X_cat_test.npy\n","data/regression-cat-medium-2-Mercedes_Benz_Greener_Manufacturing/X_bin_train.npy\n","data/regression-cat-medium-2-Mercedes_Benz_Greener_Manufacturing/X_cat_train.npy\n","data/regression-cat-medium-2-Mercedes_Benz_Greener_Manufacturing/info.json\n","data/regression-cat-medium-2-Mercedes_Benz_Greener_Manufacturing/READY\n","data/regression-cat-medium-2-Mercedes_Benz_Greener_Manufacturing/X_bin_test.npy\n","data/regression-cat-medium-2-Mercedes_Benz_Greener_Manufacturing/Y_test.npy\n","data/regression-cat-medium-2-Mercedes_Benz_Greener_Manufacturing/Y_train.npy\n","data/black-friday/\n","data/black-friday/X_cat_val.npy\n","data/black-friday/X_num_val.npy\n","data/black-friday/Y_val.npy\n","data/black-friday/X_bin_val.npy\n","data/black-friday/X_num_train.npy\n","data/black-friday/X_cat_test.npy\n","data/black-friday/X_bin_train.npy\n","data/black-friday/X_cat_train.npy\n","data/black-friday/info.json\n","data/black-friday/X_bin_test.npy\n","data/black-friday/X_num_test.npy\n","data/black-friday/Y_test.npy\n","data/black-friday/Y_train.npy\n","data/regression-num-medium-1-sulfur/\n","data/regression-num-medium-1-sulfur/X_num_val.npy\n","data/regression-num-medium-1-sulfur/Y_val.npy\n","data/regression-num-medium-1-sulfur/X_num_train.npy\n","data/regression-num-medium-1-sulfur/info.json\n","data/regression-num-medium-1-sulfur/READY\n","data/regression-num-medium-1-sulfur/X_num_test.npy\n","data/regression-num-medium-1-sulfur/Y_test.npy\n","data/regression-num-medium-1-sulfur/Y_train.npy\n","data/classif-num-medium-0-wine/\n","data/classif-num-medium-0-wine/X_num_val.npy\n","data/classif-num-medium-0-wine/Y_val.npy\n","data/classif-num-medium-0-wine/X_num_train.npy\n","data/classif-num-medium-0-wine/info.json\n","data/classif-num-medium-0-wine/READY\n","data/classif-num-medium-0-wine/X_num_test.npy\n","data/classif-num-medium-0-wine/Y_test.npy\n","data/classif-num-medium-0-wine/Y_train.npy\n","data/covtype/\n","data/covtype/X_num_val.npy\n","data/covtype/Y_val.npy\n","data/covtype/X_bin_val.npy\n","data/covtype/X_num_train.npy\n","data/covtype/X_bin_train.npy\n","data/covtype/info.json\n","data/covtype/READY\n","data/covtype/X_bin_test.npy\n","data/covtype/X_num_test.npy\n","data/covtype/Y_test.npy\n","data/covtype/Y_train.npy\n","data/regression-cat-large-0-nyc-taxi-green-dec-2016/\n","data/regression-cat-large-0-nyc-taxi-green-dec-2016/X_cat_val.npy\n","data/regression-cat-large-0-nyc-taxi-green-dec-2016/X_num_val.npy\n","data/regression-cat-large-0-nyc-taxi-green-dec-2016/Y_val.npy\n","data/regression-cat-large-0-nyc-taxi-green-dec-2016/X_bin_val.npy\n","data/regression-cat-large-0-nyc-taxi-green-dec-2016/X_num_train.npy\n","data/regression-cat-large-0-nyc-taxi-green-dec-2016/X_cat_test.npy\n","data/regression-cat-large-0-nyc-taxi-green-dec-2016/X_bin_train.npy\n","data/regression-cat-large-0-nyc-taxi-green-dec-2016/X_cat_train.npy\n","data/regression-cat-large-0-nyc-taxi-green-dec-2016/info.json\n","data/regression-cat-large-0-nyc-taxi-green-dec-2016/READY\n","data/regression-cat-large-0-nyc-taxi-green-dec-2016/X_bin_test.npy\n","data/regression-cat-large-0-nyc-taxi-green-dec-2016/X_num_test.npy\n","data/regression-cat-large-0-nyc-taxi-green-dec-2016/Y_test.npy\n","data/regression-cat-large-0-nyc-taxi-green-dec-2016/Y_train.npy\n","data/classif-num-medium-0-MagicTelescope/\n","data/classif-num-medium-0-MagicTelescope/X_num_val.npy\n","data/classif-num-medium-0-MagicTelescope/Y_val.npy\n","data/classif-num-medium-0-MagicTelescope/X_num_train.npy\n","data/classif-num-medium-0-MagicTelescope/info.json\n","data/classif-num-medium-0-MagicTelescope/READY\n","data/classif-num-medium-0-MagicTelescope/X_num_test.npy\n","data/classif-num-medium-0-MagicTelescope/Y_test.npy\n","data/classif-num-medium-0-MagicTelescope/Y_train.npy\n","data/regression-cat-medium-3-analcatdata_supreme/\n","data/regression-cat-medium-3-analcatdata_supreme/X_num_val.npy\n","data/regression-cat-medium-3-analcatdata_supreme/Y_val.npy\n","data/regression-cat-medium-3-analcatdata_supreme/X_bin_val.npy\n","data/regression-cat-medium-3-analcatdata_supreme/X_num_train.npy\n","data/regression-cat-medium-3-analcatdata_supreme/X_bin_train.npy\n","data/regression-cat-medium-3-analcatdata_supreme/info.json\n","data/regression-cat-medium-3-analcatdata_supreme/READY\n","data/regression-cat-medium-3-analcatdata_supreme/X_bin_test.npy\n","data/regression-cat-medium-3-analcatdata_supreme/X_num_test.npy\n","data/regression-cat-medium-3-analcatdata_supreme/Y_test.npy\n","data/regression-cat-medium-3-analcatdata_supreme/Y_train.npy\n","data/regression-cat-medium-0-Mercedes_Benz_Greener_Manufacturing/\n","data/regression-cat-medium-0-Mercedes_Benz_Greener_Manufacturing/X_cat_val.npy\n","data/regression-cat-medium-0-Mercedes_Benz_Greener_Manufacturing/Y_val.npy\n","data/regression-cat-medium-0-Mercedes_Benz_Greener_Manufacturing/X_bin_val.npy\n","data/regression-cat-medium-0-Mercedes_Benz_Greener_Manufacturing/X_cat_test.npy\n","data/regression-cat-medium-0-Mercedes_Benz_Greener_Manufacturing/X_bin_train.npy\n","data/regression-cat-medium-0-Mercedes_Benz_Greener_Manufacturing/X_cat_train.npy\n","data/regression-cat-medium-0-Mercedes_Benz_Greener_Manufacturing/info.json\n","data/regression-cat-medium-0-Mercedes_Benz_Greener_Manufacturing/READY\n","data/regression-cat-medium-0-Mercedes_Benz_Greener_Manufacturing/X_bin_test.npy\n","data/regression-cat-medium-0-Mercedes_Benz_Greener_Manufacturing/Y_test.npy\n","data/regression-cat-medium-0-Mercedes_Benz_Greener_Manufacturing/Y_train.npy\n","data/microsoft/\n","data/microsoft/X_num_val.npy\n","data/microsoft/Y_val.npy\n","data/microsoft/X_bin_val.npy\n","data/microsoft/X_num_train.npy\n","data/microsoft/X_bin_train.npy\n","data/microsoft/info.json\n","data/microsoft/READY\n","data/microsoft/X_bin_test.npy\n","data/microsoft/X_num_test.npy\n","data/microsoft/Y_test.npy\n","data/microsoft/Y_train.npy\n","data/regression-cat-medium-4-analcatdata_supreme/\n","data/regression-cat-medium-4-analcatdata_supreme/X_num_val.npy\n","data/regression-cat-medium-4-analcatdata_supreme/Y_val.npy\n","data/regression-cat-medium-4-analcatdata_supreme/X_bin_val.npy\n","data/regression-cat-medium-4-analcatdata_supreme/X_num_train.npy\n","data/regression-cat-medium-4-analcatdata_supreme/X_bin_train.npy\n","data/regression-cat-medium-4-analcatdata_supreme/info.json\n","data/regression-cat-medium-4-analcatdata_supreme/READY\n","data/regression-cat-medium-4-analcatdata_supreme/X_bin_test.npy\n","data/regression-cat-medium-4-analcatdata_supreme/X_num_test.npy\n","data/regression-cat-medium-4-analcatdata_supreme/Y_test.npy\n","data/regression-cat-medium-4-analcatdata_supreme/Y_train.npy\n","data/regression-num-medium-1-fifa/\n","data/regression-num-medium-1-fifa/X_num_val.npy\n","data/regression-num-medium-1-fifa/Y_val.npy\n","data/regression-num-medium-1-fifa/X_num_train.npy\n","data/regression-num-medium-1-fifa/info.json\n","data/regression-num-medium-1-fifa/READY\n","data/regression-num-medium-1-fifa/X_num_test.npy\n","data/regression-num-medium-1-fifa/Y_test.npy\n","data/regression-num-medium-1-fifa/Y_train.npy\n","data/regression-num-medium-0-isolet/\n","data/regression-num-medium-0-isolet/X_num_val.npy\n","data/regression-num-medium-0-isolet/Y_val.npy\n","data/regression-num-medium-0-isolet/X_num_train.npy\n","data/regression-num-medium-0-isolet/info.json\n","data/regression-num-medium-0-isolet/READY\n","data/regression-num-medium-0-isolet/X_num_test.npy\n","data/regression-num-medium-0-isolet/Y_test.npy\n","data/regression-num-medium-0-isolet/Y_train.npy\n","data/classif-num-medium-3-phoneme/\n","data/classif-num-medium-3-phoneme/X_num_val.npy\n","data/classif-num-medium-3-phoneme/Y_val.npy\n","data/classif-num-medium-3-phoneme/X_num_train.npy\n","data/classif-num-medium-3-phoneme/info.json\n","data/classif-num-medium-3-phoneme/READY\n","data/classif-num-medium-3-phoneme/X_num_test.npy\n","data/classif-num-medium-3-phoneme/Y_test.npy\n","data/classif-num-medium-3-phoneme/Y_train.npy\n","data/regression-cat-medium-3-Mercedes_Benz_Greener_Manufacturing/\n","data/regression-cat-medium-3-Mercedes_Benz_Greener_Manufacturing/X_cat_val.npy\n","data/regression-cat-medium-3-Mercedes_Benz_Greener_Manufacturing/Y_val.npy\n","data/regression-cat-medium-3-Mercedes_Benz_Greener_Manufacturing/X_bin_val.npy\n","data/regression-cat-medium-3-Mercedes_Benz_Greener_Manufacturing/X_cat_test.npy\n","data/regression-cat-medium-3-Mercedes_Benz_Greener_Manufacturing/X_bin_train.npy\n","data/regression-cat-medium-3-Mercedes_Benz_Greener_Manufacturing/X_cat_train.npy\n","data/regression-cat-medium-3-Mercedes_Benz_Greener_Manufacturing/info.json\n","data/regression-cat-medium-3-Mercedes_Benz_Greener_Manufacturing/READY\n","data/regression-cat-medium-3-Mercedes_Benz_Greener_Manufacturing/X_bin_test.npy\n","data/regression-cat-medium-3-Mercedes_Benz_Greener_Manufacturing/Y_test.npy\n","data/regression-cat-medium-3-Mercedes_Benz_Greener_Manufacturing/Y_train.npy\n","data/california/\n","data/california/X_num_val.npy\n","data/california/Y_val.npy\n","data/california/X_num_train.npy\n","data/california/info.json\n","data/california/READY\n","data/california/X_num_test.npy\n","data/california/Y_test.npy\n","data/california/Y_train.npy\n","data/classif-cat-medium-2-rl/\n","data/classif-cat-medium-2-rl/X_cat_val.npy\n","data/classif-cat-medium-2-rl/X_num_val.npy\n","data/classif-cat-medium-2-rl/Y_val.npy\n","data/classif-cat-medium-2-rl/X_bin_val.npy\n","data/classif-cat-medium-2-rl/X_num_train.npy\n","data/classif-cat-medium-2-rl/X_cat_test.npy\n","data/classif-cat-medium-2-rl/X_bin_train.npy\n","data/classif-cat-medium-2-rl/X_cat_train.npy\n","data/classif-cat-medium-2-rl/info.json\n","data/classif-cat-medium-2-rl/READY\n","data/classif-cat-medium-2-rl/X_bin_test.npy\n","data/classif-cat-medium-2-rl/X_num_test.npy\n","data/classif-cat-medium-2-rl/Y_test.npy\n","data/classif-cat-medium-2-rl/Y_train.npy\n","data/regression-cat-medium-0-Brazilian_houses/\n","data/regression-cat-medium-0-Brazilian_houses/X_cat_val.npy\n","data/regression-cat-medium-0-Brazilian_houses/X_num_val.npy\n","data/regression-cat-medium-0-Brazilian_houses/Y_val.npy\n","data/regression-cat-medium-0-Brazilian_houses/X_bin_val.npy\n","data/regression-cat-medium-0-Brazilian_houses/X_num_train.npy\n","data/regression-cat-medium-0-Brazilian_houses/X_cat_test.npy\n","data/regression-cat-medium-0-Brazilian_houses/X_bin_train.npy\n","data/regression-cat-medium-0-Brazilian_houses/X_cat_train.npy\n","data/regression-cat-medium-0-Brazilian_houses/info.json\n","data/regression-cat-medium-0-Brazilian_houses/READY\n","data/regression-cat-medium-0-Brazilian_houses/X_bin_test.npy\n","data/regression-cat-medium-0-Brazilian_houses/X_num_test.npy\n","data/regression-cat-medium-0-Brazilian_houses/Y_test.npy\n","data/regression-cat-medium-0-Brazilian_houses/Y_train.npy\n","data/regression-cat-medium-1-analcatdata_supreme/\n","data/regression-cat-medium-1-analcatdata_supreme/X_num_val.npy\n","data/regression-cat-medium-1-analcatdata_supreme/Y_val.npy\n","data/regression-cat-medium-1-analcatdata_supreme/X_bin_val.npy\n","data/regression-cat-medium-1-analcatdata_supreme/X_num_train.npy\n","data/regression-cat-medium-1-analcatdata_supreme/X_bin_train.npy\n","data/regression-cat-medium-1-analcatdata_supreme/info.json\n","data/regression-cat-medium-1-analcatdata_supreme/READY\n","data/regression-cat-medium-1-analcatdata_supreme/X_bin_test.npy\n","data/regression-cat-medium-1-analcatdata_supreme/X_num_test.npy\n","data/regression-cat-medium-1-analcatdata_supreme/Y_test.npy\n","data/regression-cat-medium-1-analcatdata_supreme/Y_train.npy\n","data/classif-num-medium-2-MagicTelescope/\n","data/classif-num-medium-2-MagicTelescope/X_num_val.npy\n","data/classif-num-medium-2-MagicTelescope/Y_val.npy\n","data/classif-num-medium-2-MagicTelescope/X_num_train.npy\n","data/classif-num-medium-2-MagicTelescope/info.json\n","data/classif-num-medium-2-MagicTelescope/READY\n","data/classif-num-medium-2-MagicTelescope/X_num_test.npy\n","data/classif-num-medium-2-MagicTelescope/Y_test.npy\n","data/classif-num-medium-2-MagicTelescope/Y_train.npy\n","data/classif-cat-medium-1-rl/\n","data/classif-cat-medium-1-rl/X_cat_val.npy\n","data/classif-cat-medium-1-rl/X_num_val.npy\n","data/classif-cat-medium-1-rl/Y_val.npy\n","data/classif-cat-medium-1-rl/X_bin_val.npy\n","data/classif-cat-medium-1-rl/X_num_train.npy\n","data/classif-cat-medium-1-rl/X_cat_test.npy\n","data/classif-cat-medium-1-rl/X_bin_train.npy\n","data/classif-cat-medium-1-rl/X_cat_train.npy\n","data/classif-cat-medium-1-rl/info.json\n","data/classif-cat-medium-1-rl/READY\n","data/classif-cat-medium-1-rl/X_bin_test.npy\n","data/classif-cat-medium-1-rl/X_num_test.npy\n","data/classif-cat-medium-1-rl/Y_test.npy\n","data/classif-cat-medium-1-rl/Y_train.npy\n","data/classif-cat-medium-0-compass/\n","data/classif-cat-medium-0-compass/X_cat_val.npy\n","data/classif-cat-medium-0-compass/X_num_val.npy\n","data/classif-cat-medium-0-compass/Y_val.npy\n","data/classif-cat-medium-0-compass/X_bin_val.npy\n","data/classif-cat-medium-0-compass/X_num_train.npy\n","data/classif-cat-medium-0-compass/X_cat_test.npy\n","data/classif-cat-medium-0-compass/X_bin_train.npy\n","data/classif-cat-medium-0-compass/X_cat_train.npy\n","data/classif-cat-medium-0-compass/info.json\n","data/classif-cat-medium-0-compass/READY\n","data/classif-cat-medium-0-compass/X_bin_test.npy\n","data/classif-cat-medium-0-compass/X_num_test.npy\n","data/classif-cat-medium-0-compass/Y_test.npy\n","data/classif-cat-medium-0-compass/Y_train.npy\n","data/regression-cat-medium-2-yprop_4_1/\n","data/regression-cat-medium-2-yprop_4_1/X_num_val.npy\n","data/regression-cat-medium-2-yprop_4_1/Y_val.npy\n","data/regression-cat-medium-2-yprop_4_1/X_bin_val.npy\n","data/regression-cat-medium-2-yprop_4_1/X_num_train.npy\n","data/regression-cat-medium-2-yprop_4_1/X_bin_train.npy\n","data/regression-cat-medium-2-yprop_4_1/info.json\n","data/regression-cat-medium-2-yprop_4_1/READY\n","data/regression-cat-medium-2-yprop_4_1/X_bin_test.npy\n","data/regression-cat-medium-2-yprop_4_1/X_num_test.npy\n","data/regression-cat-medium-2-yprop_4_1/Y_test.npy\n","data/regression-cat-medium-2-yprop_4_1/Y_train.npy\n","data/weather-small/\n","data/weather-small/X_num_val.npy\n","data/weather-small/Y_val.npy\n","data/weather-small/X_bin_val.npy\n","data/weather-small/X_num_train.npy\n","data/weather-small/X_bin_train.npy\n","data/weather-small/info.json\n","data/weather-small/READY\n","data/weather-small/X_bin_test.npy\n","data/weather-small/X_num_test.npy\n","data/weather-small/Y_test.npy\n","data/weather-small/Y_train.npy\n","data/diamond/\n","data/diamond/X_cat_val.npy\n","data/diamond/X_num_val.npy\n","data/diamond/Y_val.npy\n","data/diamond/X_num_train.npy\n","data/diamond/X_cat_test.npy\n","data/diamond/X_cat_train.npy\n","data/diamond/info.json\n","data/diamond/X_num_test.npy\n","data/diamond/Y_test.npy\n","data/diamond/Y_train.npy\n","data/regression-num-medium-0-fifa/\n","data/regression-num-medium-0-fifa/X_num_val.npy\n","data/regression-num-medium-0-fifa/Y_val.npy\n","data/regression-num-medium-0-fifa/X_num_train.npy\n","data/regression-num-medium-0-fifa/info.json\n","data/regression-num-medium-0-fifa/READY\n","data/regression-num-medium-0-fifa/X_num_test.npy\n","data/regression-num-medium-0-fifa/Y_test.npy\n","data/regression-num-medium-0-fifa/Y_train.npy\n","data/regression-num-medium-1-cpu_act/\n","data/regression-num-medium-1-cpu_act/X_num_val.npy\n","data/regression-num-medium-1-cpu_act/Y_val.npy\n","data/regression-num-medium-1-cpu_act/X_num_train.npy\n","data/regression-num-medium-1-cpu_act/info.json\n","data/regression-num-medium-1-cpu_act/READY\n","data/regression-num-medium-1-cpu_act/X_num_test.npy\n","data/regression-num-medium-1-cpu_act/Y_test.npy\n","data/regression-num-medium-1-cpu_act/Y_train.npy\n","data/regression-num-medium-1-pol/\n","data/regression-num-medium-1-pol/X_num_val.npy\n","data/regression-num-medium-1-pol/Y_val.npy\n","data/regression-num-medium-1-pol/X_num_train.npy\n","data/regression-num-medium-1-pol/info.json\n","data/regression-num-medium-1-pol/READY\n","data/regression-num-medium-1-pol/X_num_test.npy\n","data/regression-num-medium-1-pol/Y_test.npy\n","data/regression-num-medium-1-pol/Y_train.npy\n","data/regression-num-medium-0-elevators/\n","data/regression-num-medium-0-elevators/X_num_val.npy\n","data/regression-num-medium-0-elevators/Y_val.npy\n","data/regression-num-medium-0-elevators/X_num_train.npy\n","data/regression-num-medium-0-elevators/info.json\n","data/regression-num-medium-0-elevators/READY\n","data/regression-num-medium-0-elevators/X_num_test.npy\n","data/regression-num-medium-0-elevators/Y_test.npy\n","data/regression-num-medium-0-elevators/Y_train.npy\n","data/regression-cat-medium-4-Mercedes_Benz_Greener_Manufacturing/\n","data/regression-cat-medium-4-Mercedes_Benz_Greener_Manufacturing/X_cat_val.npy\n","data/regression-cat-medium-4-Mercedes_Benz_Greener_Manufacturing/Y_val.npy\n","data/regression-cat-medium-4-Mercedes_Benz_Greener_Manufacturing/X_bin_val.npy\n","data/regression-cat-medium-4-Mercedes_Benz_Greener_Manufacturing/X_cat_test.npy\n","data/regression-cat-medium-4-Mercedes_Benz_Greener_Manufacturing/X_bin_train.npy\n","data/regression-cat-medium-4-Mercedes_Benz_Greener_Manufacturing/X_cat_train.npy\n","data/regression-cat-medium-4-Mercedes_Benz_Greener_Manufacturing/info.json\n","data/regression-cat-medium-4-Mercedes_Benz_Greener_Manufacturing/READY\n","data/regression-cat-medium-4-Mercedes_Benz_Greener_Manufacturing/X_bin_test.npy\n","data/regression-cat-medium-4-Mercedes_Benz_Greener_Manufacturing/Y_test.npy\n","data/regression-cat-medium-4-Mercedes_Benz_Greener_Manufacturing/Y_train.npy\n","data/regression-num-medium-2-MiamiHousing2016/\n","data/regression-num-medium-2-MiamiHousing2016/X_num_val.npy\n","data/regression-num-medium-2-MiamiHousing2016/Y_val.npy\n","data/regression-num-medium-2-MiamiHousing2016/X_num_train.npy\n","data/regression-num-medium-2-MiamiHousing2016/info.json\n","data/regression-num-medium-2-MiamiHousing2016/READY\n","data/regression-num-medium-2-MiamiHousing2016/X_num_test.npy\n","data/regression-num-medium-2-MiamiHousing2016/Y_test.npy\n","data/regression-num-medium-2-MiamiHousing2016/Y_train.npy\n","data/regression-num-medium-1-Ailerons/\n","data/regression-num-medium-1-Ailerons/X_num_val.npy\n","data/regression-num-medium-1-Ailerons/Y_val.npy\n","data/regression-num-medium-1-Ailerons/X_num_train.npy\n","data/regression-num-medium-1-Ailerons/info.json\n","data/regression-num-medium-1-Ailerons/READY\n","data/regression-num-medium-1-Ailerons/X_num_test.npy\n","data/regression-num-medium-1-Ailerons/Y_test.npy\n","data/regression-num-medium-1-Ailerons/Y_train.npy\n","data/regression-num-medium-0-medical_charges/\n","data/regression-num-medium-0-medical_charges/X_num_val.npy\n","data/regression-num-medium-0-medical_charges/Y_val.npy\n","data/regression-num-medium-0-medical_charges/X_num_train.npy\n","data/regression-num-medium-0-medical_charges/info.json\n","data/regression-num-medium-0-medical_charges/READY\n","data/regression-num-medium-0-medical_charges/X_num_test.npy\n","data/regression-num-medium-0-medical_charges/Y_test.npy\n","data/regression-num-medium-0-medical_charges/Y_train.npy\n","data/classif-num-medium-0-bank-marketing/\n","data/classif-num-medium-0-bank-marketing/X_num_val.npy\n","data/classif-num-medium-0-bank-marketing/Y_val.npy\n","data/classif-num-medium-0-bank-marketing/X_num_train.npy\n","data/classif-num-medium-0-bank-marketing/info.json\n","data/classif-num-medium-0-bank-marketing/READY\n","data/classif-num-medium-0-bank-marketing/X_num_test.npy\n","data/classif-num-medium-0-bank-marketing/Y_test.npy\n","data/classif-num-medium-0-bank-marketing/Y_train.npy\n","data/classif-num-medium-3-wine/\n","data/classif-num-medium-3-wine/X_num_val.npy\n","data/classif-num-medium-3-wine/Y_val.npy\n","data/classif-num-medium-3-wine/X_num_train.npy\n","data/classif-num-medium-3-wine/info.json\n","data/classif-num-medium-3-wine/READY\n","data/classif-num-medium-3-wine/X_num_test.npy\n","data/classif-num-medium-3-wine/Y_test.npy\n","data/classif-num-medium-3-wine/Y_train.npy\n","data/classif-num-medium-2-bank-marketing/\n","data/classif-num-medium-2-bank-marketing/X_num_val.npy\n","data/classif-num-medium-2-bank-marketing/Y_val.npy\n","data/classif-num-medium-2-bank-marketing/X_num_train.npy\n","data/classif-num-medium-2-bank-marketing/info.json\n","data/classif-num-medium-2-bank-marketing/READY\n","data/classif-num-medium-2-bank-marketing/X_num_test.npy\n","data/classif-num-medium-2-bank-marketing/Y_test.npy\n","data/classif-num-medium-2-bank-marketing/Y_train.npy\n","data/classif-num-large-0-jannis/\n","data/classif-num-large-0-jannis/X_num_val.npy\n","data/classif-num-large-0-jannis/Y_val.npy\n","data/classif-num-large-0-jannis/X_num_train.npy\n","data/classif-num-large-0-jannis/info.json\n","data/classif-num-large-0-jannis/READY\n","data/classif-num-large-0-jannis/X_num_test.npy\n","data/classif-num-large-0-jannis/Y_test.npy\n","data/classif-num-large-0-jannis/Y_train.npy\n","data/regression-num-medium-0-houses/\n","data/regression-num-medium-0-houses/X_num_val.npy\n","data/regression-num-medium-0-houses/Y_val.npy\n","data/regression-num-medium-0-houses/X_num_train.npy\n","data/regression-num-medium-0-houses/info.json\n","data/regression-num-medium-0-houses/READY\n","data/regression-num-medium-0-houses/X_num_test.npy\n","data/regression-num-medium-0-houses/Y_test.npy\n","data/regression-num-medium-0-houses/Y_train.npy\n","data/regression-num-large-0-year/\n","data/regression-num-large-0-year/X_num_val.npy\n","data/regression-num-large-0-year/Y_val.npy\n","data/regression-num-large-0-year/X_num_train.npy\n","data/regression-num-large-0-year/info.json\n","data/regression-num-large-0-year/READY\n","data/regression-num-large-0-year/X_num_test.npy\n","data/regression-num-large-0-year/Y_test.npy\n","data/regression-num-large-0-year/Y_train.npy\n","data/classif-cat-medium-1-KDDCup09_upselling/\n","data/classif-cat-medium-1-KDDCup09_upselling/X_cat_val.npy\n","data/classif-cat-medium-1-KDDCup09_upselling/X_num_val.npy\n","data/classif-cat-medium-1-KDDCup09_upselling/Y_val.npy\n","data/classif-cat-medium-1-KDDCup09_upselling/X_bin_val.npy\n","data/classif-cat-medium-1-KDDCup09_upselling/X_num_train.npy\n","data/classif-cat-medium-1-KDDCup09_upselling/X_cat_test.npy\n","data/classif-cat-medium-1-KDDCup09_upselling/X_bin_train.npy\n","data/classif-cat-medium-1-KDDCup09_upselling/X_cat_train.npy\n","data/classif-cat-medium-1-KDDCup09_upselling/info.json\n","data/classif-cat-medium-1-KDDCup09_upselling/READY\n","data/classif-cat-medium-1-KDDCup09_upselling/X_bin_test.npy\n","data/classif-cat-medium-1-KDDCup09_upselling/X_num_test.npy\n","data/classif-cat-medium-1-KDDCup09_upselling/Y_test.npy\n","data/classif-cat-medium-1-KDDCup09_upselling/Y_train.npy\n","data/classif-cat-medium-0-KDDCup09_upselling/\n","data/classif-cat-medium-0-KDDCup09_upselling/X_cat_val.npy\n","data/classif-cat-medium-0-KDDCup09_upselling/X_num_val.npy\n","data/classif-cat-medium-0-KDDCup09_upselling/Y_val.npy\n","data/classif-cat-medium-0-KDDCup09_upselling/X_bin_val.npy\n","data/classif-cat-medium-0-KDDCup09_upselling/X_num_train.npy\n","data/classif-cat-medium-0-KDDCup09_upselling/X_cat_test.npy\n","data/classif-cat-medium-0-KDDCup09_upselling/X_bin_train.npy\n","data/classif-cat-medium-0-KDDCup09_upselling/X_cat_train.npy\n","data/classif-cat-medium-0-KDDCup09_upselling/info.json\n","data/classif-cat-medium-0-KDDCup09_upselling/READY\n","data/classif-cat-medium-0-KDDCup09_upselling/X_bin_test.npy\n","data/classif-cat-medium-0-KDDCup09_upselling/X_num_test.npy\n","data/classif-cat-medium-0-KDDCup09_upselling/Y_test.npy\n","data/classif-cat-medium-0-KDDCup09_upselling/Y_train.npy\n","data/classif-num-large-0-MiniBooNE/\n","data/classif-num-large-0-MiniBooNE/X_num_val.npy\n","data/classif-num-large-0-MiniBooNE/Y_val.npy\n","data/classif-num-large-0-MiniBooNE/X_num_train.npy\n","data/classif-num-large-0-MiniBooNE/info.json\n","data/classif-num-large-0-MiniBooNE/READY\n","data/classif-num-large-0-MiniBooNE/X_num_test.npy\n","data/classif-num-large-0-MiniBooNE/Y_test.npy\n","data/classif-num-large-0-MiniBooNE/Y_train.npy\n","data/regression-num-medium-0-MiamiHousing2016/\n","data/regression-num-medium-0-MiamiHousing2016/X_num_val.npy\n","data/regression-num-medium-0-MiamiHousing2016/Y_val.npy\n","data/regression-num-medium-0-MiamiHousing2016/X_num_train.npy\n","data/regression-num-medium-0-MiamiHousing2016/info.json\n","data/regression-num-medium-0-MiamiHousing2016/READY\n","data/regression-num-medium-0-MiamiHousing2016/X_num_test.npy\n","data/regression-num-medium-0-MiamiHousing2016/Y_test.npy\n","data/regression-num-medium-0-MiamiHousing2016/Y_train.npy\n","data/regression-num-medium-2-Ailerons/\n","data/regression-num-medium-2-Ailerons/X_num_val.npy\n","data/regression-num-medium-2-Ailerons/Y_val.npy\n","data/regression-num-medium-2-Ailerons/X_num_train.npy\n","data/regression-num-medium-2-Ailerons/info.json\n","data/regression-num-medium-2-Ailerons/READY\n","data/regression-num-medium-2-Ailerons/X_num_test.npy\n","data/regression-num-medium-2-Ailerons/Y_test.npy\n","data/regression-num-medium-2-Ailerons/Y_train.npy\n","data/classif-num-medium-0-credit/\n","data/classif-num-medium-0-credit/X_num_val.npy\n","data/classif-num-medium-0-credit/Y_val.npy\n","data/classif-num-medium-0-credit/X_num_train.npy\n","data/classif-num-medium-0-credit/info.json\n","data/classif-num-medium-0-credit/READY\n","data/classif-num-medium-0-credit/X_num_test.npy\n","data/classif-num-medium-0-credit/Y_test.npy\n","data/classif-num-medium-0-credit/Y_train.npy\n","data/classif-num-medium-4-wine/\n","data/classif-num-medium-4-wine/X_num_val.npy\n","data/classif-num-medium-4-wine/Y_val.npy\n","data/classif-num-medium-4-wine/X_num_train.npy\n","data/classif-num-medium-4-wine/info.json\n","data/classif-num-medium-4-wine/READY\n","data/classif-num-medium-4-wine/X_num_test.npy\n","data/classif-num-medium-4-wine/Y_test.npy\n","data/classif-num-medium-4-wine/Y_train.npy\n","data/higgs-small/\n","data/higgs-small/X_num_val.npy\n","data/higgs-small/Y_val.npy\n","data/higgs-small/X_num_train.npy\n","data/higgs-small/info.json\n","data/higgs-small/READY\n","data/higgs-small/X_num_test.npy\n","data/higgs-small/Y_test.npy\n","data/higgs-small/Y_train.npy\n","data/classif-cat-medium-1-compass/\n","data/classif-cat-medium-1-compass/X_cat_val.npy\n","data/classif-cat-medium-1-compass/X_num_val.npy\n","data/classif-cat-medium-1-compass/Y_val.npy\n","data/classif-cat-medium-1-compass/X_bin_val.npy\n","data/classif-cat-medium-1-compass/X_num_train.npy\n","data/classif-cat-medium-1-compass/X_cat_test.npy\n","data/classif-cat-medium-1-compass/X_bin_train.npy\n","data/classif-cat-medium-1-compass/X_cat_train.npy\n","data/classif-cat-medium-1-compass/info.json\n","data/classif-cat-medium-1-compass/READY\n","data/classif-cat-medium-1-compass/X_bin_test.npy\n","data/classif-cat-medium-1-compass/X_num_test.npy\n","data/classif-cat-medium-1-compass/Y_test.npy\n","data/classif-cat-medium-1-compass/Y_train.npy\n","data/classif-cat-medium-0-rl/\n","data/classif-cat-medium-0-rl/X_cat_val.npy\n","data/classif-cat-medium-0-rl/X_num_val.npy\n","data/classif-cat-medium-0-rl/Y_val.npy\n","data/classif-cat-medium-0-rl/X_bin_val.npy\n","data/classif-cat-medium-0-rl/X_num_train.npy\n","data/classif-cat-medium-0-rl/X_cat_test.npy\n","data/classif-cat-medium-0-rl/X_bin_train.npy\n","data/classif-cat-medium-0-rl/X_cat_train.npy\n","data/classif-cat-medium-0-rl/info.json\n","data/classif-cat-medium-0-rl/READY\n","data/classif-cat-medium-0-rl/X_bin_test.npy\n","data/classif-cat-medium-0-rl/X_num_test.npy\n","data/classif-cat-medium-0-rl/Y_test.npy\n","data/classif-cat-medium-0-rl/Y_train.npy\n","data/regression-num-medium-2-cpu_act/\n","data/regression-num-medium-2-cpu_act/X_num_val.npy\n","data/regression-num-medium-2-cpu_act/Y_val.npy\n","data/regression-num-medium-2-cpu_act/X_num_train.npy\n","data/regression-num-medium-2-cpu_act/info.json\n","data/regression-num-medium-2-cpu_act/READY\n","data/regression-num-medium-2-cpu_act/X_num_test.npy\n","data/regression-num-medium-2-cpu_act/Y_test.npy\n","data/regression-num-medium-2-cpu_act/Y_train.npy\n","data/otto/\n","data/otto/X_num_val.npy\n","data/otto/Y_val.npy\n","data/otto/X_num_train.npy\n","data/otto/info.json\n","data/otto/READY\n","data/otto/X_num_test.npy\n","data/otto/Y_test.npy\n","data/otto/Y_train.npy\n","data/regression-cat-medium-0-yprop_4_1/\n","data/regression-cat-medium-0-yprop_4_1/X_num_val.npy\n","data/regression-cat-medium-0-yprop_4_1/Y_val.npy\n","data/regression-cat-medium-0-yprop_4_1/X_bin_val.npy\n","data/regression-cat-medium-0-yprop_4_1/X_num_train.npy\n","data/regression-cat-medium-0-yprop_4_1/X_bin_train.npy\n","data/regression-cat-medium-0-yprop_4_1/info.json\n","data/regression-cat-medium-0-yprop_4_1/READY\n","data/regression-cat-medium-0-yprop_4_1/X_bin_test.npy\n","data/regression-cat-medium-0-yprop_4_1/X_num_test.npy\n","data/regression-cat-medium-0-yprop_4_1/Y_test.npy\n","data/regression-cat-medium-0-yprop_4_1/Y_train.npy\n","data/classif-cat-large-0-covertype/\n","data/classif-cat-large-0-covertype/X_num_val.npy\n","data/classif-cat-large-0-covertype/Y_val.npy\n","data/classif-cat-large-0-covertype/X_bin_val.npy\n","data/classif-cat-large-0-covertype/X_num_train.npy\n","data/classif-cat-large-0-covertype/X_bin_train.npy\n","data/classif-cat-large-0-covertype/info.json\n","data/classif-cat-large-0-covertype/READY\n","data/classif-cat-large-0-covertype/X_bin_test.npy\n","data/classif-cat-large-0-covertype/X_num_test.npy\n","data/classif-cat-large-0-covertype/Y_test.npy\n","data/classif-cat-large-0-covertype/Y_train.npy\n","data/regression-cat-medium-1-Bike_Sharing_Demand/\n","data/regression-cat-medium-1-Bike_Sharing_Demand/X_cat_val.npy\n","data/regression-cat-medium-1-Bike_Sharing_Demand/X_num_val.npy\n","data/regression-cat-medium-1-Bike_Sharing_Demand/Y_val.npy\n","data/regression-cat-medium-1-Bike_Sharing_Demand/X_bin_val.npy\n","data/regression-cat-medium-1-Bike_Sharing_Demand/X_num_train.npy\n","data/regression-cat-medium-1-Bike_Sharing_Demand/X_cat_test.npy\n","data/regression-cat-medium-1-Bike_Sharing_Demand/X_bin_train.npy\n","data/regression-cat-medium-1-Bike_Sharing_Demand/X_cat_train.npy\n","data/regression-cat-medium-1-Bike_Sharing_Demand/info.json\n","data/regression-cat-medium-1-Bike_Sharing_Demand/READY\n","data/regression-cat-medium-1-Bike_Sharing_Demand/X_bin_test.npy\n","data/regression-cat-medium-1-Bike_Sharing_Demand/X_num_test.npy\n","data/regression-cat-medium-1-Bike_Sharing_Demand/Y_test.npy\n","data/regression-cat-medium-1-Bike_Sharing_Demand/Y_train.npy\n","data/classif-cat-medium-0-electricity/\n","data/classif-cat-medium-0-electricity/X_cat_val.npy\n","data/classif-cat-medium-0-electricity/X_num_val.npy\n","data/classif-cat-medium-0-electricity/Y_val.npy\n","data/classif-cat-medium-0-electricity/X_num_train.npy\n","data/classif-cat-medium-0-electricity/X_cat_test.npy\n","data/classif-cat-medium-0-electricity/X_cat_train.npy\n","data/classif-cat-medium-0-electricity/info.json\n","data/classif-cat-medium-0-electricity/READY\n","data/classif-cat-medium-0-electricity/X_num_test.npy\n","data/classif-cat-medium-0-electricity/Y_test.npy\n","data/classif-cat-medium-0-electricity/Y_train.npy\n","data/regression-cat-medium-2-visualizing_soil/\n","data/regression-cat-medium-2-visualizing_soil/X_num_val.npy\n","data/regression-cat-medium-2-visualizing_soil/Y_val.npy\n","data/regression-cat-medium-2-visualizing_soil/X_bin_val.npy\n","data/regression-cat-medium-2-visualizing_soil/X_num_train.npy\n","data/regression-cat-medium-2-visualizing_soil/X_bin_train.npy\n","data/regression-cat-medium-2-visualizing_soil/info.json\n","data/regression-cat-medium-2-visualizing_soil/READY\n","data/regression-cat-medium-2-visualizing_soil/X_bin_test.npy\n","data/regression-cat-medium-2-visualizing_soil/X_num_test.npy\n","data/regression-cat-medium-2-visualizing_soil/Y_test.npy\n","data/regression-cat-medium-2-visualizing_soil/Y_train.npy\n","data/regression-cat-medium-1-yprop_4_1/\n","data/regression-cat-medium-1-yprop_4_1/X_num_val.npy\n","data/regression-cat-medium-1-yprop_4_1/Y_val.npy\n","data/regression-cat-medium-1-yprop_4_1/X_bin_val.npy\n","data/regression-cat-medium-1-yprop_4_1/X_num_train.npy\n","data/regression-cat-medium-1-yprop_4_1/X_bin_train.npy\n","data/regression-cat-medium-1-yprop_4_1/info.json\n","data/regression-cat-medium-1-yprop_4_1/READY\n","data/regression-cat-medium-1-yprop_4_1/X_bin_test.npy\n","data/regression-cat-medium-1-yprop_4_1/X_num_test.npy\n","data/regression-cat-medium-1-yprop_4_1/Y_test.npy\n","data/regression-cat-medium-1-yprop_4_1/Y_train.npy\n","data/classif-num-medium-1-bank-marketing/\n","data/classif-num-medium-1-bank-marketing/X_num_val.npy\n","data/classif-num-medium-1-bank-marketing/Y_val.npy\n","data/classif-num-medium-1-bank-marketing/X_num_train.npy\n","data/classif-num-medium-1-bank-marketing/info.json\n","data/classif-num-medium-1-bank-marketing/READY\n","data/classif-num-medium-1-bank-marketing/X_num_test.npy\n","data/classif-num-medium-1-bank-marketing/Y_test.npy\n","data/classif-num-medium-1-bank-marketing/Y_train.npy\n","data/classif-num-medium-1-credit/\n","data/classif-num-medium-1-credit/X_num_val.npy\n","data/classif-num-medium-1-credit/Y_val.npy\n","data/classif-num-medium-1-credit/X_num_train.npy\n","data/classif-num-medium-1-credit/info.json\n","data/classif-num-medium-1-credit/READY\n","data/classif-num-medium-1-credit/X_num_test.npy\n","data/classif-num-medium-1-credit/Y_test.npy\n","data/classif-num-medium-1-credit/Y_train.npy\n"]}]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-glTe-NrxA3S","executionInfo":{"status":"ok","timestamp":1728996387078,"user_tz":-480,"elapsed":5156,"user":{"displayName":"Jonindo Pasaribu","userId":"10958990953097471082"}},"outputId":"927b82a1-af75-4493-cdbe-7f0dc112ab59"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pytorch-tabnet\n","  Downloading pytorch_tabnet-4.1.0-py3-none-any.whl.metadata (15 kB)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from pytorch-tabnet) (1.26.4)\n","Requirement already satisfied: scikit_learn>0.21 in /usr/local/lib/python3.10/dist-packages (from pytorch-tabnet) (1.5.2)\n","Requirement already satisfied: scipy>1.4 in /usr/local/lib/python3.10/dist-packages (from pytorch-tabnet) (1.13.1)\n","Requirement already satisfied: torch>=1.3 in /usr/local/lib/python3.10/dist-packages (from pytorch-tabnet) (2.4.1+cu121)\n","Requirement already satisfied: tqdm>=4.36 in /usr/local/lib/python3.10/dist-packages (from pytorch-tabnet) (4.66.5)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit_learn>0.21->pytorch-tabnet) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit_learn>0.21->pytorch-tabnet) (3.5.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (3.16.1)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (1.13.3)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (3.4)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (2024.6.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.3->pytorch-tabnet) (3.0.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.3->pytorch-tabnet) (1.3.0)\n","Downloading pytorch_tabnet-4.1.0-py3-none-any.whl (44 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.5/44.5 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: pytorch-tabnet\n","Successfully installed pytorch-tabnet-4.1.0\n"]}],"source":["!pip install pytorch-tabnet"]},{"cell_type":"code","source":["!pip install optuna"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T3kebgsowkp0","executionInfo":{"status":"ok","timestamp":1728996390187,"user_tz":-480,"elapsed":3112,"user":{"displayName":"Jonindo Pasaribu","userId":"10958990953097471082"}},"outputId":"5c8cf9d3-9960-44f8-bedb-66fd3943633e"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting optuna\n","  Downloading optuna-4.0.0-py3-none-any.whl.metadata (16 kB)\n","Collecting alembic>=1.5.0 (from optuna)\n","  Downloading alembic-1.13.3-py3-none-any.whl.metadata (7.4 kB)\n","Collecting colorlog (from optuna)\n","  Downloading colorlog-6.8.2-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (24.1)\n","Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.35)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.66.5)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0.2)\n","Collecting Mako (from alembic>=1.5.0->optuna)\n","  Downloading Mako-1.3.5-py3-none-any.whl.metadata (2.9 kB)\n","Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.12.2)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna) (3.1.1)\n","Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna) (3.0.1)\n","Downloading optuna-4.0.0-py3-none-any.whl (362 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m362.8/362.8 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading alembic-1.13.3-py3-none-any.whl (233 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.2/233.2 kB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading colorlog-6.8.2-py3-none-any.whl (11 kB)\n","Downloading Mako-1.3.5-py3-none-any.whl (78 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: Mako, colorlog, alembic, optuna\n","Successfully installed Mako-1.3.5 alembic-1.13.3 colorlog-6.8.2 optuna-4.0.0\n"]}]},{"cell_type":"code","source":["!pip install psutil"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1AlZ_9btlf9J","executionInfo":{"status":"ok","timestamp":1728996392437,"user_tz":-480,"elapsed":2254,"user":{"displayName":"Jonindo Pasaribu","userId":"10958990953097471082"}},"outputId":"9c605eea-ab71-457a-f602-4dde39578bb6"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (5.9.5)\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import optuna\n","import torch.optim\n","import psutil\n","\n","from pytorch_tabnet.tab_model import TabNetRegressor\n","from sklearn.preprocessing import QuantileTransformer"],"metadata":{"id":"085aiY1dzlHG","executionInfo":{"status":"ok","timestamp":1728996398792,"user_tz":-480,"elapsed":6357,"user":{"displayName":"Jonindo Pasaribu","userId":"10958990953097471082"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["tnr = TabNetRegressor()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pr7k2hel51eb","executionInfo":{"status":"ok","timestamp":1728996398792,"user_tz":-480,"elapsed":14,"user":{"displayName":"Jonindo Pasaribu","userId":"10958990953097471082"}},"outputId":"9aa31f09-345a-4186-9faa-83545ad5b45b"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]}]},{"cell_type":"code","source":["X_train = np.load('/content/data/regression-num-medium-0-pol/X_num_train.npy')\n","y_train = np.load('/content/data/regression-num-medium-0-pol/Y_train.npy').reshape(-1, 1)\n","\n","X_valid = np.load('/content/data/regression-num-medium-0-pol/X_num_val.npy')\n","y_valid = np.load('/content/data/regression-num-medium-0-pol/Y_val.npy').reshape(-1, 1)\n","\n","X_test = np.load('/content/data/regression-num-medium-0-pol/X_num_test.npy')\n","y_test = np.load('/content/data/regression-num-medium-0-pol/Y_test.npy').reshape(-1, 1)"],"metadata":{"id":"ml0RPc_76dZx","executionInfo":{"status":"ok","timestamp":1728996398792,"user_tz":-480,"elapsed":10,"user":{"displayName":"Jonindo Pasaribu","userId":"10958990953097471082"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["normalizer = QuantileTransformer(\n","            output_distribution='normal',\n","            n_quantiles=max(min(X_train.shape[0] // 30, 1000), 10),\n","            subsample=1_000_000_000,\n","            )\n","normalizer.fit_transform(X_train)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"19PUhYavmHsh","executionInfo":{"status":"ok","timestamp":1728996398793,"user_tz":-480,"elapsed":10,"user":{"displayName":"Jonindo Pasaribu","userId":"10958990953097471082"}},"outputId":"9c236510-ed99-4003-ca87-50b86c4cab93"},"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[-0.67448974,  1.458952  ,  0.6603392 , ..., -5.1993375 ,\n","        -5.1993375 , -5.1993375 ],\n","       [-0.15539995,  1.4925991 ,  0.61865354, ..., -5.1993375 ,\n","        -5.1993375 , -5.1993375 ],\n","       [ 0.26740587,  1.3572593 , -0.525267  , ..., -5.1993375 ,\n","        -5.1993375 , -5.1993375 ],\n","       ...,\n","       [ 0.8513439 ,  0.44874668,  1.2430338 , ..., -5.1993375 ,\n","        -5.1993375 , -5.1993375 ],\n","       [-0.3828821 , -1.0210539 , -0.525267  , ..., -5.1993375 ,\n","        -5.1993375 , -5.1993375 ],\n","       [ 0.09072527, -1.0210539 , -0.525267  , ..., -5.1993375 ,\n","        -5.1993375 , -5.1993375 ]], dtype=float32)"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["#Baseline\n","tnr.fit(\n","    X_train=X_train, y_train=y_train,\n","    eval_set=[(X_train, y_train), (X_valid, y_valid)],\n","    eval_name=['train', 'valid'],\n","    eval_metric=['mae', 'rmse'],\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dmadZ12j7CO_","executionInfo":{"status":"ok","timestamp":1728996416443,"user_tz":-480,"elapsed":17656,"user":{"displayName":"Jonindo Pasaribu","userId":"10958990953097471082"}},"outputId":"cd91bbc1-c2d8-4a63-8ab9-51818abd70cc"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 2411.72149| train_mae: 35.088871002197266| train_rmse: 49.3012809753418| valid_mae: 35.72658157348633| valid_rmse: 50.287200927734375|  0:00:02s\n","epoch 1  | loss: 1985.40853| train_mae: 31.64381980895996| train_rmse: 48.144798278808594| valid_mae: 32.89820098876953| valid_rmse: 49.36539840698242|  0:00:03s\n","epoch 2  | loss: 1404.05988| train_mae: 30.289499282836914| train_rmse: 48.33028030395508| valid_mae: 31.795379638671875| valid_rmse: 49.73981857299805|  0:00:04s\n","epoch 3  | loss: 777.71606| train_mae: 30.578449249267578| train_rmse: 47.386478424072266| valid_mae: 32.36983871459961| valid_rmse: 48.95083999633789|  0:00:05s\n","epoch 4  | loss: 419.53994| train_mae: 30.268659591674805| train_rmse: 47.295841217041016| valid_mae: 31.765140533447266| valid_rmse: 48.69675827026367|  0:00:06s\n","epoch 5  | loss: 306.59574| train_mae: 29.520200729370117| train_rmse: 49.05690002441406| valid_mae: 31.157800674438477| valid_rmse: 50.53242111206055|  0:00:06s\n","epoch 6  | loss: 259.39505| train_mae: 32.9776611328125| train_rmse: 52.82822036743164| valid_mae: 34.69401931762695| valid_rmse: 54.429161071777344|  0:00:07s\n","epoch 7  | loss: 194.95847| train_mae: 29.621570587158203| train_rmse: 50.089439392089844| valid_mae: 31.27046012878418| valid_rmse: 51.655548095703125|  0:00:08s\n","epoch 8  | loss: 173.08135| train_mae: 29.91777992248535| train_rmse: 50.52317810058594| valid_mae: 31.532480239868164| valid_rmse: 51.98963928222656|  0:00:08s\n","epoch 9  | loss: 154.03471| train_mae: 30.10951042175293| train_rmse: 50.83732986450195| valid_mae: 31.73118019104004| valid_rmse: 52.40007019042969|  0:00:09s\n","epoch 10 | loss: 133.94824| train_mae: 29.400680541992188| train_rmse: 49.549381256103516| valid_mae: 30.92841911315918| valid_rmse: 51.00379943847656|  0:00:10s\n","epoch 11 | loss: 138.60198| train_mae: 29.33930015563965| train_rmse: 49.402408599853516| valid_mae: 30.856050491333008| valid_rmse: 50.83528137207031|  0:00:11s\n","epoch 12 | loss: 123.41055| train_mae: 29.055540084838867| train_rmse: 49.404659271240234| valid_mae: 30.62141990661621| valid_rmse: 50.85586166381836|  0:00:11s\n","epoch 13 | loss: 132.13345| train_mae: 29.01181983947754| train_rmse: 49.07389831542969| valid_mae: 30.580720901489258| valid_rmse: 50.530181884765625|  0:00:12s\n","epoch 14 | loss: 126.39762| train_mae: 29.37228012084961| train_rmse: 48.115840911865234| valid_mae: 30.810890197753906| valid_rmse: 49.511878967285156|  0:00:13s\n","\n","Early stopping occurred at epoch 14 with best_epoch = 4 and best_valid_rmse = 48.69675827026367\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n"]}]},{"cell_type":"code","source":["def objective(trial):\n","    params = {\n","        'n_d': trial.suggest_int('n_d', 8, 64),\n","        'n_steps': trial.suggest_int('n_steps', 3, 10),\n","        'gamma': trial.suggest_float('gamma', 1.0, 2.0),\n","        'n_independent': trial.suggest_int('n_independent', 1, 5),\n","        'n_shared': trial.suggest_int('n_shared', 1, 5),\n","        'momentum': trial.suggest_float('momentum', 0.01, 0.4),\n","    }\n","\n","    model = TabNetRegressor(**params, n_a=params['n_d'])\n","    model.fit(X_train, y_train, eval_set=[(X_valid, y_valid)], patience=10)\n","\n","    # Evaluate model performance\n","    score = model.best_cost  # or any other metric\n","\n","    return score\n","\n","study = optuna.create_study(direction='minimize')\n","study.optimize(objective, n_trials=100)\n","\n","best_params = study.best_params"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rKJAw0W-w7sc","executionInfo":{"status":"ok","timestamp":1729000680859,"user_tz":-480,"elapsed":4264422,"user":{"displayName":"Jonindo Pasaribu","userId":"10958990953097471082"}},"outputId":"7f0be98c-d19d-4e65-ec86-d04e0782d97f"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stderr","text":["[I 2024-10-15 12:46:56,040] A new study created in memory with name: no-name-329fd49b-bb13-478f-a268-c9d7f7415c7d\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 2219.45223| val_0_mse: 41317.6328125|  0:00:01s\n","epoch 1  | loss: 1717.04655| val_0_mse: 17305.005859375|  0:00:03s\n","epoch 2  | loss: 1339.92917| val_0_mse: 34813.94140625|  0:00:04s\n","epoch 3  | loss: 974.25113| val_0_mse: 13146.154296875|  0:00:06s\n","epoch 4  | loss: 837.40539| val_0_mse: 6440.380859375|  0:00:07s\n","epoch 5  | loss: 845.30596| val_0_mse: 6199.044921875|  0:00:09s\n","epoch 6  | loss: 726.5095| val_0_mse: 7857.84423828125|  0:00:10s\n","epoch 7  | loss: 636.37576| val_0_mse: 2726.2451171875|  0:00:12s\n","epoch 8  | loss: 676.63704| val_0_mse: 2789.93310546875|  0:00:13s\n","epoch 9  | loss: 626.39558| val_0_mse: 4564.498046875|  0:00:15s\n","epoch 10 | loss: 671.17735| val_0_mse: 2488.026123046875|  0:00:16s\n","epoch 11 | loss: 702.37476| val_0_mse: 2365.308837890625|  0:00:18s\n","epoch 12 | loss: 704.97997| val_0_mse: 2670.452392578125|  0:00:20s\n","epoch 13 | loss: 586.67644| val_0_mse: 3008.337890625|  0:00:21s\n","epoch 14 | loss: 548.82031| val_0_mse: 2178.6904296875|  0:00:23s\n","epoch 15 | loss: 781.67287| val_0_mse: 2690.094970703125|  0:00:24s\n","epoch 16 | loss: 712.06171| val_0_mse: 1932.4649658203125|  0:00:26s\n","epoch 17 | loss: 538.30107| val_0_mse: 1624.1031494140625|  0:00:27s\n","epoch 18 | loss: 611.23513| val_0_mse: 1526.5413818359375|  0:00:29s\n","epoch 19 | loss: 564.42774| val_0_mse: 1552.3258056640625|  0:00:31s\n","epoch 20 | loss: 459.79584| val_0_mse: 1042.745849609375|  0:00:32s\n","epoch 21 | loss: 397.68541| val_0_mse: 903.8741455078125|  0:00:34s\n","epoch 22 | loss: 306.35303| val_0_mse: 650.9495849609375|  0:00:35s\n","epoch 23 | loss: 253.01438| val_0_mse: 410.6151123046875|  0:00:37s\n","epoch 24 | loss: 255.69324| val_0_mse: 607.080078125|  0:00:38s\n","epoch 25 | loss: 217.58222| val_0_mse: 783.3193359375|  0:00:40s\n","epoch 26 | loss: 200.33814| val_0_mse: 476.649169921875|  0:00:41s\n","epoch 27 | loss: 260.99421| val_0_mse: 322.4584045410156|  0:00:43s\n","epoch 28 | loss: 162.35231| val_0_mse: 260.8290710449219|  0:00:44s\n","epoch 29 | loss: 131.81459| val_0_mse: 369.71746826171875|  0:00:46s\n","epoch 30 | loss: 143.59064| val_0_mse: 318.84326171875|  0:00:48s\n","epoch 31 | loss: 143.62867| val_0_mse: 230.54849243164062|  0:00:49s\n","epoch 32 | loss: 126.72885| val_0_mse: 477.7409973144531|  0:00:51s\n","epoch 33 | loss: 139.03826| val_0_mse: 385.5086364746094|  0:00:53s\n","epoch 34 | loss: 129.22192| val_0_mse: 143.48545837402344|  0:00:54s\n","epoch 35 | loss: 106.77506| val_0_mse: 203.38194274902344|  0:00:56s\n","epoch 36 | loss: 100.14437| val_0_mse: 236.3587646484375|  0:00:57s\n","epoch 37 | loss: 103.11004| val_0_mse: 210.1725616455078|  0:00:59s\n","epoch 38 | loss: 116.39579| val_0_mse: 68.68000793457031|  0:01:01s\n","epoch 39 | loss: 96.9367 | val_0_mse: 88.72386169433594|  0:01:02s\n","epoch 40 | loss: 87.57027| val_0_mse: 148.94635009765625|  0:01:04s\n","epoch 41 | loss: 104.5417| val_0_mse: 109.9681167602539|  0:01:05s\n","epoch 42 | loss: 89.77857| val_0_mse: 89.30645751953125|  0:01:07s\n","epoch 43 | loss: 143.47439| val_0_mse: 133.39366149902344|  0:01:09s\n","epoch 44 | loss: 96.61502| val_0_mse: 43.88644027709961|  0:01:10s\n","epoch 45 | loss: 99.50262| val_0_mse: 99.94497680664062|  0:01:12s\n","epoch 46 | loss: 104.76745| val_0_mse: 118.31771087646484|  0:01:13s\n","epoch 47 | loss: 99.4131 | val_0_mse: 62.63264083862305|  0:01:15s\n","epoch 48 | loss: 99.03835| val_0_mse: 93.14187622070312|  0:01:16s\n","epoch 49 | loss: 102.59393| val_0_mse: 36.785499572753906|  0:01:18s\n","epoch 50 | loss: 102.04736| val_0_mse: 82.34741973876953|  0:01:19s\n","epoch 51 | loss: 107.03662| val_0_mse: 96.54517364501953|  0:01:21s\n","epoch 52 | loss: 111.71482| val_0_mse: 47.64794158935547|  0:01:23s\n","epoch 53 | loss: 107.88904| val_0_mse: 79.6030502319336|  0:01:24s\n","epoch 54 | loss: 109.18545| val_0_mse: 78.90596008300781|  0:01:26s\n","epoch 55 | loss: 103.65951| val_0_mse: 57.928138732910156|  0:01:27s\n","epoch 56 | loss: 97.6416 | val_0_mse: 44.16228103637695|  0:01:29s\n","epoch 57 | loss: 86.85658| val_0_mse: 31.03873062133789|  0:01:30s\n","epoch 58 | loss: 112.03606| val_0_mse: 52.12879180908203|  0:01:32s\n","epoch 59 | loss: 105.01839| val_0_mse: 43.86162185668945|  0:01:34s\n","epoch 60 | loss: 93.0239 | val_0_mse: 44.666221618652344|  0:01:35s\n","epoch 61 | loss: 86.23867| val_0_mse: 38.5842399597168|  0:01:37s\n","epoch 62 | loss: 98.35599| val_0_mse: 79.65471649169922|  0:01:38s\n","epoch 63 | loss: 95.86633| val_0_mse: 51.7835807800293|  0:01:40s\n","epoch 64 | loss: 88.66339| val_0_mse: 35.246219635009766|  0:01:42s\n","epoch 65 | loss: 85.1866 | val_0_mse: 49.158241271972656|  0:01:43s\n","epoch 66 | loss: 94.03184| val_0_mse: 35.267818450927734|  0:01:45s\n","epoch 67 | loss: 96.83901| val_0_mse: 40.893959045410156|  0:01:46s\n","\n","Early stopping occurred at epoch 67 with best_epoch = 57 and best_val_0_mse = 31.03873062133789\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 12:48:43,866] Trial 0 finished with value: 31.038728713989258 and parameters: {'n_d': 53, 'n_steps': 7, 'gamma': 1.4946754396401558, 'n_independent': 5, 'n_shared': 5, 'momentum': 0.38586591745674137}. Best is trial 0 with value: 31.038728713989258.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 2094.27261| val_0_mse: 9366.7958984375|  0:00:01s\n","epoch 1  | loss: 1155.88697| val_0_mse: 27676.892578125|  0:00:02s\n","epoch 2  | loss: 497.77387| val_0_mse: 7090.92333984375|  0:00:04s\n","epoch 3  | loss: 373.67362| val_0_mse: 7428.0625|  0:00:05s\n","epoch 4  | loss: 379.09599| val_0_mse: 9185.833984375|  0:00:07s\n","epoch 5  | loss: 302.99995| val_0_mse: 4712.23876953125|  0:00:08s\n","epoch 6  | loss: 287.41612| val_0_mse: 3975.71337890625|  0:00:10s\n","epoch 7  | loss: 248.53988| val_0_mse: 2586.561767578125|  0:00:11s\n","epoch 8  | loss: 272.20215| val_0_mse: 2961.70068359375|  0:00:13s\n","epoch 9  | loss: 257.0952| val_0_mse: 2744.458251953125|  0:00:14s\n","epoch 10 | loss: 203.43401| val_0_mse: 2631.988037109375|  0:00:15s\n","epoch 11 | loss: 173.54884| val_0_mse: 2440.183349609375|  0:00:17s\n","epoch 12 | loss: 174.69852| val_0_mse: 2254.763916015625|  0:00:18s\n","epoch 13 | loss: 173.24511| val_0_mse: 2271.833984375|  0:00:20s\n","epoch 14 | loss: 184.46362| val_0_mse: 2269.446044921875|  0:00:21s\n","epoch 15 | loss: 237.17304| val_0_mse: 2369.114501953125|  0:00:23s\n","epoch 16 | loss: 197.84468| val_0_mse: 2455.90478515625|  0:00:24s\n","epoch 17 | loss: 159.26688| val_0_mse: 2515.6123046875|  0:00:26s\n","epoch 18 | loss: 173.17996| val_0_mse: 2172.6728515625|  0:00:27s\n","epoch 19 | loss: 142.47849| val_0_mse: 1486.9759521484375|  0:00:29s\n","epoch 20 | loss: 156.19809| val_0_mse: 1722.635498046875|  0:00:30s\n","epoch 21 | loss: 140.25988| val_0_mse: 1185.367919921875|  0:00:32s\n","epoch 22 | loss: 135.72077| val_0_mse: 806.4219970703125|  0:00:33s\n","epoch 23 | loss: 147.9154| val_0_mse: 371.35968017578125|  0:00:35s\n","epoch 24 | loss: 178.85824| val_0_mse: 602.3323364257812|  0:00:36s\n","epoch 25 | loss: 141.28368| val_0_mse: 513.2084350585938|  0:00:38s\n","epoch 26 | loss: 132.99694| val_0_mse: 431.7674255371094|  0:00:39s\n","epoch 27 | loss: 127.64862| val_0_mse: 461.7721862792969|  0:00:41s\n","epoch 28 | loss: 122.63887| val_0_mse: 395.1639099121094|  0:00:42s\n","epoch 29 | loss: 134.10049| val_0_mse: 436.6375732421875|  0:00:44s\n","epoch 30 | loss: 136.83748| val_0_mse: 257.44488525390625|  0:00:45s\n","epoch 31 | loss: 133.64699| val_0_mse: 294.00140380859375|  0:00:46s\n","epoch 32 | loss: 123.17617| val_0_mse: 243.52688598632812|  0:00:48s\n","epoch 33 | loss: 120.94437| val_0_mse: 215.87892150878906|  0:00:49s\n","epoch 34 | loss: 106.65575| val_0_mse: 246.8957061767578|  0:00:51s\n","epoch 35 | loss: 99.55938| val_0_mse: 131.21995544433594|  0:00:52s\n","epoch 36 | loss: 90.51773| val_0_mse: 157.83779907226562|  0:00:54s\n","epoch 37 | loss: 84.54903| val_0_mse: 157.5545196533203|  0:00:55s\n","epoch 38 | loss: 106.57299| val_0_mse: 83.28045654296875|  0:00:57s\n","epoch 39 | loss: 95.11313| val_0_mse: 80.38159942626953|  0:00:58s\n","epoch 40 | loss: 109.50685| val_0_mse: 133.29905700683594|  0:01:00s\n","epoch 41 | loss: 115.58515| val_0_mse: 123.681396484375|  0:01:01s\n","epoch 42 | loss: 85.14658| val_0_mse: 78.3584213256836|  0:01:03s\n","epoch 43 | loss: 75.98774| val_0_mse: 81.08934020996094|  0:01:04s\n","epoch 44 | loss: 82.23124| val_0_mse: 92.89230346679688|  0:01:06s\n","epoch 45 | loss: 86.86945| val_0_mse: 99.34075164794922|  0:01:07s\n","epoch 46 | loss: 66.13622| val_0_mse: 80.74162292480469|  0:01:09s\n","epoch 47 | loss: 70.26076| val_0_mse: 73.9476318359375|  0:01:10s\n","epoch 48 | loss: 91.68518| val_0_mse: 47.829078674316406|  0:01:12s\n","epoch 49 | loss: 79.08902| val_0_mse: 76.58702087402344|  0:01:13s\n","epoch 50 | loss: 69.83009| val_0_mse: 39.813720703125|  0:01:15s\n","epoch 51 | loss: 65.09951| val_0_mse: 51.6254997253418|  0:01:16s\n","epoch 52 | loss: 74.51366| val_0_mse: 61.40364074707031|  0:01:18s\n","epoch 53 | loss: 97.94181| val_0_mse: 60.65755844116211|  0:01:19s\n","epoch 54 | loss: 89.44861| val_0_mse: 61.91844177246094|  0:01:21s\n","epoch 55 | loss: 83.62906| val_0_mse: 60.2153205871582|  0:01:22s\n","epoch 56 | loss: 72.89106| val_0_mse: 36.49774169921875|  0:01:24s\n","epoch 57 | loss: 70.26759| val_0_mse: 50.31700134277344|  0:01:25s\n","epoch 58 | loss: 63.32875| val_0_mse: 45.4822998046875|  0:01:27s\n","epoch 59 | loss: 74.18342| val_0_mse: 44.42816162109375|  0:01:28s\n","epoch 60 | loss: 72.09969| val_0_mse: 54.54990005493164|  0:01:30s\n","epoch 61 | loss: 68.65809| val_0_mse: 56.26995849609375|  0:01:31s\n","epoch 62 | loss: 61.35373| val_0_mse: 37.13716125488281|  0:01:33s\n","epoch 63 | loss: 60.70084| val_0_mse: 35.32801818847656|  0:01:34s\n","epoch 64 | loss: 63.88109| val_0_mse: 53.8632698059082|  0:01:36s\n","epoch 65 | loss: 97.17157| val_0_mse: 50.13087844848633|  0:01:37s\n","epoch 66 | loss: 73.82978| val_0_mse: 59.064361572265625|  0:01:39s\n","epoch 67 | loss: 73.86653| val_0_mse: 31.113229751586914|  0:01:40s\n","epoch 68 | loss: 57.29565| val_0_mse: 41.481658935546875|  0:01:42s\n","epoch 69 | loss: 59.66545| val_0_mse: 33.4540901184082|  0:01:44s\n","epoch 70 | loss: 81.85706| val_0_mse: 32.84497833251953|  0:01:45s\n","epoch 71 | loss: 61.8257 | val_0_mse: 43.363380432128906|  0:01:47s\n","epoch 72 | loss: 74.32038| val_0_mse: 49.95396041870117|  0:01:48s\n","epoch 73 | loss: 89.20553| val_0_mse: 37.23788070678711|  0:01:50s\n","epoch 74 | loss: 49.85635| val_0_mse: 34.83525085449219|  0:01:51s\n","epoch 75 | loss: 56.26714| val_0_mse: 36.464088439941406|  0:01:53s\n","epoch 76 | loss: 50.51599| val_0_mse: 29.274850845336914|  0:01:54s\n","epoch 77 | loss: 71.31642| val_0_mse: 36.48823928833008|  0:01:56s\n","epoch 78 | loss: 63.32039| val_0_mse: 40.333431243896484|  0:01:57s\n","epoch 79 | loss: 52.671  | val_0_mse: 28.667930603027344|  0:01:58s\n","epoch 80 | loss: 58.25249| val_0_mse: 41.90578079223633|  0:02:00s\n","epoch 81 | loss: 54.49965| val_0_mse: 33.52172088623047|  0:02:01s\n","epoch 82 | loss: 55.74292| val_0_mse: 27.67099952697754|  0:02:03s\n","epoch 83 | loss: 62.19393| val_0_mse: 36.721168518066406|  0:02:05s\n","epoch 84 | loss: 51.88248| val_0_mse: 30.299259185791016|  0:02:06s\n","epoch 85 | loss: 57.69004| val_0_mse: 30.642160415649414|  0:02:08s\n","epoch 86 | loss: 58.50651| val_0_mse: 41.856300354003906|  0:02:09s\n","epoch 87 | loss: 52.15661| val_0_mse: 32.837928771972656|  0:02:11s\n","epoch 88 | loss: 67.35199| val_0_mse: 59.10955810546875|  0:02:12s\n","epoch 89 | loss: 58.97053| val_0_mse: 70.03482055664062|  0:02:14s\n","epoch 90 | loss: 81.42576| val_0_mse: 53.43593978881836|  0:02:15s\n","epoch 91 | loss: 74.60698| val_0_mse: 34.296321868896484|  0:02:17s\n","epoch 92 | loss: 75.41077| val_0_mse: 39.444618225097656|  0:02:18s\n","\n","Early stopping occurred at epoch 92 with best_epoch = 82 and best_val_0_mse = 27.67099952697754\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 12:51:03,510] Trial 1 finished with value: 27.671005249023438 and parameters: {'n_d': 54, 'n_steps': 7, 'gamma': 1.1263034774035177, 'n_independent': 5, 'n_shared': 4, 'momentum': 0.19893395138619854}. Best is trial 1 with value: 27.671005249023438.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 2107.42776| val_0_mse: 2928.263427734375|  0:00:00s\n","epoch 1  | loss: 1082.14003| val_0_mse: 3139.253662109375|  0:00:00s\n","epoch 2  | loss: 561.84361| val_0_mse: 4194.08642578125|  0:00:01s\n","epoch 3  | loss: 323.94707| val_0_mse: 4187.0166015625|  0:00:01s\n","epoch 4  | loss: 232.55055| val_0_mse: 3705.568603515625|  0:00:02s\n","epoch 5  | loss: 194.67239| val_0_mse: 2775.554443359375|  0:00:02s\n","epoch 6  | loss: 144.22457| val_0_mse: 2874.062744140625|  0:00:03s\n","epoch 7  | loss: 126.15786| val_0_mse: 2546.133544921875|  0:00:03s\n","epoch 8  | loss: 112.89862| val_0_mse: 2680.944091796875|  0:00:04s\n","epoch 9  | loss: 104.40947| val_0_mse: 2697.01171875|  0:00:04s\n","epoch 10 | loss: 90.00082| val_0_mse: 2653.46044921875|  0:00:05s\n","epoch 11 | loss: 80.42106| val_0_mse: 2586.065185546875|  0:00:05s\n","epoch 12 | loss: 79.2565 | val_0_mse: 2632.44921875|  0:00:06s\n","epoch 13 | loss: 84.97291| val_0_mse: 2629.292724609375|  0:00:06s\n","epoch 14 | loss: 67.27125| val_0_mse: 2570.10791015625|  0:00:07s\n","epoch 15 | loss: 77.51921| val_0_mse: 2576.92041015625|  0:00:07s\n","epoch 16 | loss: 77.02952| val_0_mse: 2499.412841796875|  0:00:08s\n","epoch 17 | loss: 73.74336| val_0_mse: 2527.81591796875|  0:00:08s\n","epoch 18 | loss: 76.99443| val_0_mse: 1814.7213134765625|  0:00:09s\n","epoch 19 | loss: 67.71107| val_0_mse: 2338.759765625|  0:00:09s\n","epoch 20 | loss: 55.11515| val_0_mse: 1436.9041748046875|  0:00:10s\n","epoch 21 | loss: 58.40758| val_0_mse: 1425.797607421875|  0:00:10s\n","epoch 22 | loss: 74.24595| val_0_mse: 1074.65869140625|  0:00:11s\n","epoch 23 | loss: 66.25005| val_0_mse: 938.8905029296875|  0:00:11s\n","epoch 24 | loss: 69.31056| val_0_mse: 868.018310546875|  0:00:11s\n","epoch 25 | loss: 75.09526| val_0_mse: 535.3269653320312|  0:00:12s\n","epoch 26 | loss: 73.49481| val_0_mse: 450.271240234375|  0:00:12s\n","epoch 27 | loss: 51.20472| val_0_mse: 490.2186279296875|  0:00:13s\n","epoch 28 | loss: 55.68131| val_0_mse: 267.4363708496094|  0:00:13s\n","epoch 29 | loss: 58.70111| val_0_mse: 327.6929626464844|  0:00:14s\n","epoch 30 | loss: 53.04323| val_0_mse: 230.86680603027344|  0:00:14s\n","epoch 31 | loss: 61.93671| val_0_mse: 114.93639373779297|  0:00:15s\n","epoch 32 | loss: 71.73491| val_0_mse: 218.3883056640625|  0:00:15s\n","epoch 33 | loss: 63.36881| val_0_mse: 135.65757751464844|  0:00:16s\n","epoch 34 | loss: 49.51603| val_0_mse: 163.42222595214844|  0:00:16s\n","epoch 35 | loss: 51.02089| val_0_mse: 117.16610717773438|  0:00:17s\n","epoch 36 | loss: 39.8049 | val_0_mse: 154.7057342529297|  0:00:17s\n","epoch 37 | loss: 41.56483| val_0_mse: 58.824241638183594|  0:00:18s\n","epoch 38 | loss: 44.44943| val_0_mse: 77.49662017822266|  0:00:18s\n","epoch 39 | loss: 46.65998| val_0_mse: 45.256099700927734|  0:00:19s\n","epoch 40 | loss: 45.94442| val_0_mse: 49.783538818359375|  0:00:19s\n","epoch 41 | loss: 42.24746| val_0_mse: 52.7806396484375|  0:00:20s\n","epoch 42 | loss: 53.98422| val_0_mse: 61.14841842651367|  0:00:20s\n","epoch 43 | loss: 46.77285| val_0_mse: 46.12934112548828|  0:00:21s\n","epoch 44 | loss: 46.89639| val_0_mse: 31.655559539794922|  0:00:21s\n","epoch 45 | loss: 45.55583| val_0_mse: 26.872739791870117|  0:00:22s\n","epoch 46 | loss: 37.27222| val_0_mse: 39.82872009277344|  0:00:22s\n","epoch 47 | loss: 38.94763| val_0_mse: 30.10873031616211|  0:00:22s\n","epoch 48 | loss: 36.06755| val_0_mse: 45.98957824707031|  0:00:23s\n","epoch 49 | loss: 35.11776| val_0_mse: 31.962339401245117|  0:00:23s\n","epoch 50 | loss: 43.77145| val_0_mse: 44.74692153930664|  0:00:24s\n","epoch 51 | loss: 35.34411| val_0_mse: 23.584579467773438|  0:00:24s\n","epoch 52 | loss: 30.36715| val_0_mse: 21.173259735107422|  0:00:25s\n","epoch 53 | loss: 32.98992| val_0_mse: 56.78548812866211|  0:00:25s\n","epoch 54 | loss: 46.38275| val_0_mse: 38.088958740234375|  0:00:26s\n","epoch 55 | loss: 38.24542| val_0_mse: 23.938919067382812|  0:00:26s\n","epoch 56 | loss: 52.08625| val_0_mse: 42.480079650878906|  0:00:27s\n","epoch 57 | loss: 37.62475| val_0_mse: 34.51274871826172|  0:00:27s\n","epoch 58 | loss: 35.78688| val_0_mse: 20.633060455322266|  0:00:28s\n","epoch 59 | loss: 39.60886| val_0_mse: 27.663959503173828|  0:00:28s\n","epoch 60 | loss: 31.64224| val_0_mse: 26.542430877685547|  0:00:29s\n","epoch 61 | loss: 33.85406| val_0_mse: 20.515199661254883|  0:00:29s\n","epoch 62 | loss: 33.99155| val_0_mse: 21.633869171142578|  0:00:30s\n","epoch 63 | loss: 35.17242| val_0_mse: 27.430219650268555|  0:00:30s\n","epoch 64 | loss: 37.8201 | val_0_mse: 21.65414047241211|  0:00:31s\n","epoch 65 | loss: 35.02086| val_0_mse: 26.959020614624023|  0:00:31s\n","epoch 66 | loss: 40.30917| val_0_mse: 24.160900115966797|  0:00:32s\n","epoch 67 | loss: 39.5252 | val_0_mse: 23.15597915649414|  0:00:32s\n","epoch 68 | loss: 38.09963| val_0_mse: 24.537540435791016|  0:00:33s\n","epoch 69 | loss: 41.6156 | val_0_mse: 26.75242042541504|  0:00:33s\n","epoch 70 | loss: 37.20357| val_0_mse: 22.391559600830078|  0:00:33s\n","epoch 71 | loss: 30.42117| val_0_mse: 20.190269470214844|  0:00:34s\n","epoch 72 | loss: 35.68485| val_0_mse: 23.888439178466797|  0:00:34s\n","epoch 73 | loss: 36.1555 | val_0_mse: 38.737911224365234|  0:00:35s\n","epoch 74 | loss: 47.11685| val_0_mse: 24.693740844726562|  0:00:35s\n","epoch 75 | loss: 35.55061| val_0_mse: 21.639480590820312|  0:00:36s\n","epoch 76 | loss: 45.95699| val_0_mse: 23.34391975402832|  0:00:37s\n","epoch 77 | loss: 34.73073| val_0_mse: 22.369089126586914|  0:00:37s\n","epoch 78 | loss: 32.07767| val_0_mse: 28.30875015258789|  0:00:37s\n","epoch 79 | loss: 31.22172| val_0_mse: 23.37274932861328|  0:00:38s\n","epoch 80 | loss: 29.55883| val_0_mse: 22.666189193725586|  0:00:38s\n","epoch 81 | loss: 34.52869| val_0_mse: 21.50177001953125|  0:00:39s\n","\n","Early stopping occurred at epoch 81 with best_epoch = 71 and best_val_0_mse = 20.190269470214844\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 12:51:43,144] Trial 2 finished with value: 20.19026756286621 and parameters: {'n_d': 54, 'n_steps': 4, 'gamma': 1.3389492297235739, 'n_independent': 1, 'n_shared': 2, 'momentum': 0.2959368653730601}. Best is trial 2 with value: 20.19026756286621.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 2275.62667| val_0_mse: 2878.53076171875|  0:00:00s\n","epoch 1  | loss: 1761.21682| val_0_mse: 4388.173828125|  0:00:01s\n","epoch 2  | loss: 1326.09814| val_0_mse: 4031.118408203125|  0:00:02s\n","epoch 3  | loss: 1107.33668| val_0_mse: 10002.927734375|  0:00:02s\n","epoch 4  | loss: 902.46872| val_0_mse: 9106.0732421875|  0:00:03s\n","epoch 5  | loss: 689.63098| val_0_mse: 7918.6904296875|  0:00:04s\n","epoch 6  | loss: 552.99204| val_0_mse: 8732.0517578125|  0:00:05s\n","epoch 7  | loss: 477.69967| val_0_mse: 3574.481689453125|  0:00:05s\n","epoch 8  | loss: 372.63668| val_0_mse: 3877.3447265625|  0:00:06s\n","epoch 9  | loss: 309.92782| val_0_mse: 4748.27197265625|  0:00:07s\n","epoch 10 | loss: 254.93965| val_0_mse: 3366.771728515625|  0:00:07s\n","\n","Early stopping occurred at epoch 10 with best_epoch = 0 and best_val_0_mse = 2878.53076171875\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 12:51:51,452] Trial 3 finished with value: 2878.531005859375 and parameters: {'n_d': 29, 'n_steps': 7, 'gamma': 1.894385980416327, 'n_independent': 2, 'n_shared': 1, 'momentum': 0.11429576377039026}. Best is trial 2 with value: 20.19026756286621.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 2194.59966| val_0_mse: 4855.88232421875|  0:00:00s\n","epoch 1  | loss: 1589.92874| val_0_mse: 17532.029296875|  0:00:01s\n","epoch 2  | loss: 1150.11209| val_0_mse: 46924.69140625|  0:00:02s\n","epoch 3  | loss: 924.36544| val_0_mse: 6955.134765625|  0:00:02s\n","epoch 4  | loss: 632.00058| val_0_mse: 6492.185546875|  0:00:03s\n","epoch 5  | loss: 458.49081| val_0_mse: 6923.60009765625|  0:00:04s\n","epoch 6  | loss: 317.1706| val_0_mse: 3389.086669921875|  0:00:04s\n","epoch 7  | loss: 237.73637| val_0_mse: 3702.542724609375|  0:00:05s\n","epoch 8  | loss: 239.52235| val_0_mse: 3335.875244140625|  0:00:06s\n","epoch 9  | loss: 188.60057| val_0_mse: 3519.61962890625|  0:00:06s\n","epoch 10 | loss: 162.54101| val_0_mse: 2727.880859375|  0:00:07s\n","epoch 11 | loss: 124.72521| val_0_mse: 2510.489501953125|  0:00:08s\n","epoch 12 | loss: 133.95794| val_0_mse: 2820.295654296875|  0:00:09s\n","epoch 13 | loss: 117.70978| val_0_mse: 2879.3642578125|  0:00:09s\n","epoch 14 | loss: 111.0379| val_0_mse: 2227.741455078125|  0:00:10s\n","epoch 15 | loss: 107.29159| val_0_mse: 2285.220458984375|  0:00:11s\n","epoch 16 | loss: 92.37402| val_0_mse: 1768.052001953125|  0:00:11s\n","epoch 17 | loss: 87.42987| val_0_mse: 1687.2037353515625|  0:00:12s\n","epoch 18 | loss: 83.82497| val_0_mse: 1336.4493408203125|  0:00:13s\n","epoch 19 | loss: 91.89267| val_0_mse: 900.1246948242188|  0:00:13s\n","epoch 20 | loss: 95.89042| val_0_mse: 893.5414428710938|  0:00:14s\n","epoch 21 | loss: 107.44305| val_0_mse: 807.4853515625|  0:00:15s\n","epoch 22 | loss: 93.04965| val_0_mse: 728.81298828125|  0:00:16s\n","epoch 23 | loss: 78.82514| val_0_mse: 529.0925903320312|  0:00:16s\n","epoch 24 | loss: 82.64769| val_0_mse: 509.1555480957031|  0:00:17s\n","epoch 25 | loss: 104.11916| val_0_mse: 669.8358154296875|  0:00:18s\n","epoch 26 | loss: 102.00717| val_0_mse: 454.3254089355469|  0:00:19s\n","epoch 27 | loss: 75.03561| val_0_mse: 382.2342834472656|  0:00:19s\n","epoch 28 | loss: 89.65604| val_0_mse: 423.1905517578125|  0:00:20s\n","epoch 29 | loss: 74.02044| val_0_mse: 345.19696044921875|  0:00:21s\n","epoch 30 | loss: 88.064  | val_0_mse: 232.70379638671875|  0:00:21s\n","epoch 31 | loss: 80.58467| val_0_mse: 277.6145324707031|  0:00:22s\n","epoch 32 | loss: 87.21044| val_0_mse: 246.96493530273438|  0:00:23s\n","epoch 33 | loss: 80.63395| val_0_mse: 124.8826904296875|  0:00:24s\n","epoch 34 | loss: 84.04734| val_0_mse: 163.45852661132812|  0:00:24s\n","epoch 35 | loss: 60.46566| val_0_mse: 232.77520751953125|  0:00:25s\n","epoch 36 | loss: 88.03974| val_0_mse: 180.02557373046875|  0:00:26s\n","epoch 37 | loss: 69.9736 | val_0_mse: 136.8797607421875|  0:00:26s\n","epoch 38 | loss: 70.10298| val_0_mse: 130.4610137939453|  0:00:27s\n","epoch 39 | loss: 86.88411| val_0_mse: 103.05648803710938|  0:00:28s\n","epoch 40 | loss: 69.93188| val_0_mse: 111.45722198486328|  0:00:28s\n","epoch 41 | loss: 79.5307 | val_0_mse: 41.29848098754883|  0:00:29s\n","epoch 42 | loss: 85.2384 | val_0_mse: 88.07050323486328|  0:00:30s\n","epoch 43 | loss: 78.08021| val_0_mse: 56.322689056396484|  0:00:31s\n","epoch 44 | loss: 66.24208| val_0_mse: 46.217159271240234|  0:00:31s\n","epoch 45 | loss: 75.74468| val_0_mse: 32.60765075683594|  0:00:32s\n","epoch 46 | loss: 73.24869| val_0_mse: 50.989601135253906|  0:00:33s\n","epoch 47 | loss: 97.04547| val_0_mse: 48.46979904174805|  0:00:33s\n","epoch 48 | loss: 71.78204| val_0_mse: 59.45281982421875|  0:00:34s\n","epoch 49 | loss: 76.67526| val_0_mse: 40.53445816040039|  0:00:35s\n","epoch 50 | loss: 65.91225| val_0_mse: 65.6893310546875|  0:00:35s\n","epoch 51 | loss: 74.86665| val_0_mse: 45.84474182128906|  0:00:36s\n","epoch 52 | loss: 62.90868| val_0_mse: 30.749719619750977|  0:00:37s\n","epoch 53 | loss: 73.96938| val_0_mse: 49.83599853515625|  0:00:37s\n","epoch 54 | loss: 74.96158| val_0_mse: 33.76068115234375|  0:00:38s\n","epoch 55 | loss: 58.86437| val_0_mse: 38.674869537353516|  0:00:39s\n","epoch 56 | loss: 61.88656| val_0_mse: 34.35068130493164|  0:00:40s\n","epoch 57 | loss: 70.09401| val_0_mse: 30.963520050048828|  0:00:40s\n","epoch 58 | loss: 61.66175| val_0_mse: 47.551998138427734|  0:00:41s\n","epoch 59 | loss: 61.36471| val_0_mse: 33.05226135253906|  0:00:42s\n","epoch 60 | loss: 76.0071 | val_0_mse: 36.359798431396484|  0:00:43s\n","epoch 61 | loss: 57.77826| val_0_mse: 34.407718658447266|  0:00:43s\n","epoch 62 | loss: 57.28252| val_0_mse: 24.753299713134766|  0:00:44s\n","epoch 63 | loss: 62.46366| val_0_mse: 40.362239837646484|  0:00:45s\n","epoch 64 | loss: 68.77191| val_0_mse: 32.26137924194336|  0:00:45s\n","epoch 65 | loss: 56.04233| val_0_mse: 25.09235954284668|  0:00:46s\n","epoch 66 | loss: 53.42516| val_0_mse: 33.37881851196289|  0:00:47s\n","epoch 67 | loss: 66.49282| val_0_mse: 29.950639724731445|  0:00:48s\n","epoch 68 | loss: 61.22826| val_0_mse: 26.813180923461914|  0:00:48s\n","epoch 69 | loss: 56.17176| val_0_mse: 28.50507926940918|  0:00:49s\n","epoch 70 | loss: 51.69996| val_0_mse: 26.680879592895508|  0:00:50s\n","epoch 71 | loss: 59.69806| val_0_mse: 36.66468048095703|  0:00:50s\n","epoch 72 | loss: 62.56663| val_0_mse: 29.349319458007812|  0:00:51s\n","\n","Early stopping occurred at epoch 72 with best_epoch = 62 and best_val_0_mse = 24.753299713134766\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 12:52:43,373] Trial 4 finished with value: 24.7533016204834 and parameters: {'n_d': 64, 'n_steps': 7, 'gamma': 1.836920678545483, 'n_independent': 2, 'n_shared': 1, 'momentum': 0.3060750857366477}. Best is trial 2 with value: 20.19026756286621.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 1930.62703| val_0_mse: 18873.189453125|  0:00:00s\n","epoch 1  | loss: 655.25196| val_0_mse: 4033.2666015625|  0:00:01s\n","epoch 2  | loss: 351.9369| val_0_mse: 7589.5224609375|  0:00:02s\n","epoch 3  | loss: 277.59568| val_0_mse: 3084.76123046875|  0:00:02s\n","epoch 4  | loss: 209.22234| val_0_mse: 3451.5400390625|  0:00:03s\n","epoch 5  | loss: 171.14633| val_0_mse: 2615.4140625|  0:00:04s\n","epoch 6  | loss: 136.21186| val_0_mse: 2933.7236328125|  0:00:04s\n","epoch 7  | loss: 161.07149| val_0_mse: 2487.58642578125|  0:00:05s\n","epoch 8  | loss: 135.07842| val_0_mse: 2772.554443359375|  0:00:05s\n","epoch 9  | loss: 109.42356| val_0_mse: 2714.59765625|  0:00:06s\n","epoch 10 | loss: 114.7967| val_0_mse: 2609.85498046875|  0:00:07s\n","epoch 11 | loss: 121.95037| val_0_mse: 2563.471435546875|  0:00:07s\n","epoch 12 | loss: 111.23368| val_0_mse: 2577.035888671875|  0:00:08s\n","epoch 13 | loss: 86.87268| val_0_mse: 2614.397216796875|  0:00:09s\n","epoch 14 | loss: 89.78048| val_0_mse: 2635.03466796875|  0:00:09s\n","epoch 15 | loss: 87.4189 | val_0_mse: 2644.790283203125|  0:00:10s\n","epoch 16 | loss: 65.96409| val_0_mse: 2487.240234375|  0:00:11s\n","epoch 17 | loss: 70.96971| val_0_mse: 2106.1669921875|  0:00:11s\n","epoch 18 | loss: 69.52814| val_0_mse: 2261.9482421875|  0:00:12s\n","epoch 19 | loss: 73.79944| val_0_mse: 1766.91162109375|  0:00:13s\n","epoch 20 | loss: 70.98467| val_0_mse: 1227.8328857421875|  0:00:13s\n","epoch 21 | loss: 71.29594| val_0_mse: 1001.5757446289062|  0:00:14s\n","epoch 22 | loss: 70.23285| val_0_mse: 715.3193359375|  0:00:15s\n","epoch 23 | loss: 67.65619| val_0_mse: 643.0729370117188|  0:00:15s\n","epoch 24 | loss: 78.03809| val_0_mse: 633.3922729492188|  0:00:16s\n","epoch 25 | loss: 72.62708| val_0_mse: 386.45709228515625|  0:00:17s\n","epoch 26 | loss: 78.93567| val_0_mse: 367.4148254394531|  0:00:17s\n","epoch 27 | loss: 100.40439| val_0_mse: 453.2000732421875|  0:00:18s\n","epoch 28 | loss: 71.29961| val_0_mse: 419.1075744628906|  0:00:18s\n","epoch 29 | loss: 65.38173| val_0_mse: 319.58477783203125|  0:00:19s\n","epoch 30 | loss: 82.575  | val_0_mse: 256.7540283203125|  0:00:20s\n","epoch 31 | loss: 82.41852| val_0_mse: 252.7923126220703|  0:00:20s\n","epoch 32 | loss: 94.28423| val_0_mse: 259.4556579589844|  0:00:21s\n","epoch 33 | loss: 114.88881| val_0_mse: 173.2676239013672|  0:00:22s\n","epoch 34 | loss: 87.59799| val_0_mse: 117.1518325805664|  0:00:22s\n","epoch 35 | loss: 74.61242| val_0_mse: 135.37623596191406|  0:00:23s\n","epoch 36 | loss: 85.59775| val_0_mse: 54.455039978027344|  0:00:24s\n","epoch 37 | loss: 67.21777| val_0_mse: 116.82530975341797|  0:00:24s\n","epoch 38 | loss: 69.51592| val_0_mse: 87.85415649414062|  0:00:25s\n","epoch 39 | loss: 59.39778| val_0_mse: 69.48677825927734|  0:00:26s\n","epoch 40 | loss: 75.08583| val_0_mse: 70.7082290649414|  0:00:26s\n","epoch 41 | loss: 71.25513| val_0_mse: 115.02591705322266|  0:00:27s\n","epoch 42 | loss: 72.75743| val_0_mse: 74.52825164794922|  0:00:28s\n","epoch 43 | loss: 63.33187| val_0_mse: 51.69384002685547|  0:00:28s\n","epoch 44 | loss: 52.91833| val_0_mse: 62.84117126464844|  0:00:29s\n","epoch 45 | loss: 65.91566| val_0_mse: 43.5702018737793|  0:00:30s\n","epoch 46 | loss: 65.37769| val_0_mse: 41.40340042114258|  0:00:30s\n","epoch 47 | loss: 53.87915| val_0_mse: 51.716880798339844|  0:00:31s\n","epoch 48 | loss: 65.94095| val_0_mse: 78.39341735839844|  0:00:32s\n","epoch 49 | loss: 68.66645| val_0_mse: 69.41104888916016|  0:00:32s\n","epoch 50 | loss: 60.09632| val_0_mse: 38.0843505859375|  0:00:33s\n","epoch 51 | loss: 53.38227| val_0_mse: 41.77465057373047|  0:00:34s\n","epoch 52 | loss: 54.94169| val_0_mse: 46.4703483581543|  0:00:34s\n","epoch 53 | loss: 58.92002| val_0_mse: 53.75067901611328|  0:00:35s\n","epoch 54 | loss: 74.78269| val_0_mse: 37.39323043823242|  0:00:35s\n","epoch 55 | loss: 52.58515| val_0_mse: 34.84954071044922|  0:00:36s\n","epoch 56 | loss: 43.15212| val_0_mse: 35.743900299072266|  0:00:37s\n","epoch 57 | loss: 48.24364| val_0_mse: 36.72264099121094|  0:00:37s\n","epoch 58 | loss: 53.98503| val_0_mse: 38.2406005859375|  0:00:38s\n","epoch 59 | loss: 64.12859| val_0_mse: 33.61819839477539|  0:00:39s\n","epoch 60 | loss: 50.45486| val_0_mse: 35.818031311035156|  0:00:39s\n","epoch 61 | loss: 41.86328| val_0_mse: 24.392929077148438|  0:00:40s\n","epoch 62 | loss: 47.15237| val_0_mse: 29.31846046447754|  0:00:41s\n","epoch 63 | loss: 59.32682| val_0_mse: 40.519161224365234|  0:00:41s\n","epoch 64 | loss: 51.35811| val_0_mse: 31.49720001220703|  0:00:42s\n","epoch 65 | loss: 53.32286| val_0_mse: 36.574928283691406|  0:00:43s\n","epoch 66 | loss: 48.21353| val_0_mse: 31.45948028564453|  0:00:43s\n","epoch 67 | loss: 51.66131| val_0_mse: 44.05295181274414|  0:00:44s\n","epoch 68 | loss: 42.54415| val_0_mse: 29.72471046447754|  0:00:44s\n","epoch 69 | loss: 48.21449| val_0_mse: 43.88589859008789|  0:00:45s\n","epoch 70 | loss: 55.03133| val_0_mse: 30.809659957885742|  0:00:46s\n","epoch 71 | loss: 46.44911| val_0_mse: 25.395299911499023|  0:00:46s\n","\n","Early stopping occurred at epoch 71 with best_epoch = 61 and best_val_0_mse = 24.392929077148438\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 12:53:30,617] Trial 5 finished with value: 24.392932891845703 and parameters: {'n_d': 51, 'n_steps': 3, 'gamma': 1.527093977515829, 'n_independent': 4, 'n_shared': 3, 'momentum': 0.1268392761452271}. Best is trial 2 with value: 20.19026756286621.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 2234.63422| val_0_mse: 2530.35009765625|  0:00:00s\n","epoch 1  | loss: 1827.79439| val_0_mse: 2326.835693359375|  0:00:01s\n","epoch 2  | loss: 1572.49009| val_0_mse: 2696.433349609375|  0:00:02s\n","epoch 3  | loss: 1356.05214| val_0_mse: 3541.11572265625|  0:00:03s\n","epoch 4  | loss: 1118.0595| val_0_mse: 4780.87060546875|  0:00:03s\n","epoch 5  | loss: 1011.15936| val_0_mse: 5053.28125|  0:00:04s\n","epoch 6  | loss: 820.80034| val_0_mse: 6085.009765625|  0:00:05s\n","epoch 7  | loss: 766.97837| val_0_mse: 4827.90966796875|  0:00:06s\n","epoch 8  | loss: 713.63652| val_0_mse: 5026.34326171875|  0:00:06s\n","epoch 9  | loss: 694.26816| val_0_mse: 5335.22119140625|  0:00:07s\n","epoch 10 | loss: 844.66364| val_0_mse: 4418.32763671875|  0:00:08s\n","epoch 11 | loss: 635.6292| val_0_mse: 3653.278076171875|  0:00:09s\n","\n","Early stopping occurred at epoch 11 with best_epoch = 1 and best_val_0_mse = 2326.835693359375\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 12:53:40,208] Trial 6 finished with value: 2326.835693359375 and parameters: {'n_d': 26, 'n_steps': 10, 'gamma': 1.3792420253349373, 'n_independent': 1, 'n_shared': 1, 'momentum': 0.32648905614521095}. Best is trial 2 with value: 20.19026756286621.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 2234.22891| val_0_mse: 5271.75244140625|  0:00:01s\n","epoch 1  | loss: 1534.9911| val_0_mse: 4014.134765625|  0:00:02s\n","epoch 2  | loss: 1005.67057| val_0_mse: 6111.21484375|  0:00:03s\n","epoch 3  | loss: 666.39052| val_0_mse: 31891.251953125|  0:00:04s\n","epoch 4  | loss: 522.81026| val_0_mse: 7801.634765625|  0:00:05s\n","epoch 5  | loss: 485.20867| val_0_mse: 6974.46337890625|  0:00:06s\n","epoch 6  | loss: 468.17928| val_0_mse: 4133.05322265625|  0:00:07s\n","epoch 7  | loss: 410.59381| val_0_mse: 5165.15283203125|  0:00:08s\n","epoch 8  | loss: 392.40976| val_0_mse: 5159.115234375|  0:00:09s\n","epoch 9  | loss: 363.47973| val_0_mse: 3586.998291015625|  0:00:10s\n","epoch 10 | loss: 351.99265| val_0_mse: 5232.96142578125|  0:00:11s\n","epoch 11 | loss: 328.38549| val_0_mse: 3809.497802734375|  0:00:12s\n","epoch 12 | loss: 285.20979| val_0_mse: 2747.7978515625|  0:00:14s\n","epoch 13 | loss: 291.54614| val_0_mse: 2305.9736328125|  0:00:15s\n","epoch 14 | loss: 253.95  | val_0_mse: 2637.82470703125|  0:00:16s\n","epoch 15 | loss: 254.41517| val_0_mse: 2875.232421875|  0:00:17s\n","epoch 16 | loss: 240.4064| val_0_mse: 2764.88427734375|  0:00:18s\n","epoch 17 | loss: 234.47594| val_0_mse: 2261.335693359375|  0:00:19s\n","epoch 18 | loss: 219.78295| val_0_mse: 2099.644287109375|  0:00:20s\n","epoch 19 | loss: 225.50572| val_0_mse: 1920.5096435546875|  0:00:21s\n","epoch 20 | loss: 215.77282| val_0_mse: 1578.0911865234375|  0:00:22s\n","epoch 21 | loss: 176.24785| val_0_mse: 1835.625|  0:00:23s\n","epoch 22 | loss: 150.75076| val_0_mse: 2295.8056640625|  0:00:24s\n","epoch 23 | loss: 152.96285| val_0_mse: 1838.9002685546875|  0:00:25s\n","epoch 24 | loss: 147.64547| val_0_mse: 1323.4691162109375|  0:00:26s\n","epoch 25 | loss: 151.66225| val_0_mse: 1090.63330078125|  0:00:28s\n","epoch 26 | loss: 149.21092| val_0_mse: 972.589111328125|  0:00:29s\n","epoch 27 | loss: 165.57434| val_0_mse: 755.04736328125|  0:00:30s\n","epoch 28 | loss: 138.34744| val_0_mse: 675.4254150390625|  0:00:31s\n","epoch 29 | loss: 145.08535| val_0_mse: 765.355224609375|  0:00:32s\n","epoch 30 | loss: 162.54998| val_0_mse: 294.58154296875|  0:00:33s\n","epoch 31 | loss: 153.30072| val_0_mse: 409.7992858886719|  0:00:34s\n","epoch 32 | loss: 140.58755| val_0_mse: 388.19854736328125|  0:00:35s\n","epoch 33 | loss: 123.72219| val_0_mse: 284.7076110839844|  0:00:36s\n","epoch 34 | loss: 109.40154| val_0_mse: 297.8847961425781|  0:00:37s\n","epoch 35 | loss: 129.02585| val_0_mse: 275.6859436035156|  0:00:38s\n","epoch 36 | loss: 132.50463| val_0_mse: 149.94068908691406|  0:00:39s\n","epoch 37 | loss: 120.7761| val_0_mse: 178.70387268066406|  0:00:40s\n","epoch 38 | loss: 122.05767| val_0_mse: 153.55958557128906|  0:00:41s\n","epoch 39 | loss: 112.28335| val_0_mse: 131.4331512451172|  0:00:43s\n","epoch 40 | loss: 125.00153| val_0_mse: 140.0387725830078|  0:00:44s\n","epoch 41 | loss: 126.14606| val_0_mse: 144.53713989257812|  0:00:45s\n","epoch 42 | loss: 117.86968| val_0_mse: 90.65583038330078|  0:00:46s\n","epoch 43 | loss: 118.49623| val_0_mse: 123.63141632080078|  0:00:47s\n","epoch 44 | loss: 117.4405| val_0_mse: 101.3708267211914|  0:00:48s\n","epoch 45 | loss: 94.57371| val_0_mse: 73.7841796875|  0:00:49s\n","epoch 46 | loss: 114.93327| val_0_mse: 97.10172271728516|  0:00:50s\n","epoch 47 | loss: 104.91792| val_0_mse: 92.5144271850586|  0:00:51s\n","epoch 48 | loss: 152.51401| val_0_mse: 93.81590270996094|  0:00:52s\n","epoch 49 | loss: 122.66881| val_0_mse: 128.3064727783203|  0:00:53s\n","epoch 50 | loss: 103.70128| val_0_mse: 76.26714324951172|  0:00:54s\n","epoch 51 | loss: 116.06083| val_0_mse: 69.01203918457031|  0:00:55s\n","epoch 52 | loss: 101.41933| val_0_mse: 75.93292999267578|  0:00:56s\n","epoch 53 | loss: 106.55442| val_0_mse: 92.80078125|  0:00:57s\n","epoch 54 | loss: 94.67328| val_0_mse: 75.49848937988281|  0:00:59s\n","epoch 55 | loss: 80.49748| val_0_mse: 67.86029815673828|  0:01:00s\n","epoch 56 | loss: 106.3722| val_0_mse: 70.46064758300781|  0:01:01s\n","epoch 57 | loss: 90.43565| val_0_mse: 60.2181396484375|  0:01:02s\n","epoch 58 | loss: 91.8248 | val_0_mse: 53.198638916015625|  0:01:03s\n","epoch 59 | loss: 84.8317 | val_0_mse: 59.137779235839844|  0:01:04s\n","epoch 60 | loss: 88.52913| val_0_mse: 55.881038665771484|  0:01:05s\n","epoch 61 | loss: 99.11234| val_0_mse: 48.69517135620117|  0:01:06s\n","epoch 62 | loss: 82.78018| val_0_mse: 73.3858413696289|  0:01:07s\n","epoch 63 | loss: 82.72134| val_0_mse: 54.43376159667969|  0:01:09s\n","epoch 64 | loss: 78.07818| val_0_mse: 66.7425765991211|  0:01:10s\n","epoch 65 | loss: 85.03574| val_0_mse: 57.877559661865234|  0:01:11s\n","epoch 66 | loss: 86.20566| val_0_mse: 67.7498779296875|  0:01:12s\n","epoch 67 | loss: 74.08119| val_0_mse: 68.236572265625|  0:01:13s\n","epoch 68 | loss: 84.00873| val_0_mse: 61.427398681640625|  0:01:14s\n","epoch 69 | loss: 105.69171| val_0_mse: 55.950679779052734|  0:01:15s\n","epoch 70 | loss: 77.69547| val_0_mse: 45.389068603515625|  0:01:16s\n","epoch 71 | loss: 89.80226| val_0_mse: 53.078060150146484|  0:01:17s\n","epoch 72 | loss: 66.95416| val_0_mse: 41.78623962402344|  0:01:19s\n","epoch 73 | loss: 96.38097| val_0_mse: 48.00497817993164|  0:01:20s\n","epoch 74 | loss: 102.60546| val_0_mse: 42.79793930053711|  0:01:21s\n","epoch 75 | loss: 81.55846| val_0_mse: 68.26334381103516|  0:01:22s\n","epoch 76 | loss: 86.33095| val_0_mse: 56.07495880126953|  0:01:23s\n","epoch 77 | loss: 90.72733| val_0_mse: 55.23952865600586|  0:01:24s\n","epoch 78 | loss: 110.60515| val_0_mse: 57.621219635009766|  0:01:25s\n","epoch 79 | loss: 85.58957| val_0_mse: 46.77777099609375|  0:01:26s\n","epoch 80 | loss: 72.58653| val_0_mse: 54.6973991394043|  0:01:27s\n","epoch 81 | loss: 107.80864| val_0_mse: 90.99095153808594|  0:01:28s\n","epoch 82 | loss: 100.98094| val_0_mse: 51.514198303222656|  0:01:29s\n","\n","Early stopping occurred at epoch 82 with best_epoch = 72 and best_val_0_mse = 41.78623962402344\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 12:55:10,537] Trial 7 finished with value: 41.78623962402344 and parameters: {'n_d': 38, 'n_steps': 6, 'gamma': 1.2248643758105615, 'n_independent': 3, 'n_shared': 4, 'momentum': 0.3449712944517078}. Best is trial 2 with value: 20.19026756286621.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 2198.28539| val_0_mse: 7189.35595703125|  0:00:01s\n","epoch 1  | loss: 1173.4158| val_0_mse: 12547.74609375|  0:00:02s\n","epoch 2  | loss: 572.09332| val_0_mse: 13633.900390625|  0:00:03s\n","epoch 3  | loss: 323.44849| val_0_mse: 3815.133056640625|  0:00:04s\n","epoch 4  | loss: 273.56821| val_0_mse: 2558.674560546875|  0:00:05s\n","epoch 5  | loss: 205.45303| val_0_mse: 3265.47900390625|  0:00:06s\n","epoch 6  | loss: 208.63657| val_0_mse: 2953.662109375|  0:00:07s\n","epoch 7  | loss: 171.26471| val_0_mse: 2560.138427734375|  0:00:08s\n","epoch 8  | loss: 157.35125| val_0_mse: 2741.291748046875|  0:00:09s\n","epoch 9  | loss: 146.62724| val_0_mse: 3073.390625|  0:00:10s\n","epoch 10 | loss: 140.66267| val_0_mse: 2441.1494140625|  0:00:11s\n","epoch 11 | loss: 138.23112| val_0_mse: 2537.513671875|  0:00:12s\n","epoch 12 | loss: 155.9203| val_0_mse: 2525.265625|  0:00:13s\n","epoch 13 | loss: 119.33907| val_0_mse: 2521.05126953125|  0:00:14s\n","epoch 14 | loss: 107.02851| val_0_mse: 2496.677978515625|  0:00:15s\n","epoch 15 | loss: 113.98395| val_0_mse: 2605.74169921875|  0:00:16s\n","epoch 16 | loss: 113.45512| val_0_mse: 2754.61767578125|  0:00:17s\n","epoch 17 | loss: 112.30024| val_0_mse: 2667.385009765625|  0:00:19s\n","epoch 18 | loss: 114.84597| val_0_mse: 2342.32421875|  0:00:20s\n","epoch 19 | loss: 134.60965| val_0_mse: 1840.5263671875|  0:00:21s\n","epoch 20 | loss: 122.59504| val_0_mse: 1649.310546875|  0:00:22s\n","epoch 21 | loss: 116.425 | val_0_mse: 1266.925537109375|  0:00:23s\n","epoch 22 | loss: 126.93442| val_0_mse: 1139.2449951171875|  0:00:24s\n","epoch 23 | loss: 144.04763| val_0_mse: 1126.123779296875|  0:00:25s\n","epoch 24 | loss: 110.21806| val_0_mse: 893.5349731445312|  0:00:26s\n","epoch 25 | loss: 97.60446| val_0_mse: 978.3583374023438|  0:00:27s\n","epoch 26 | loss: 93.0686 | val_0_mse: 900.4509887695312|  0:00:28s\n","epoch 27 | loss: 94.73307| val_0_mse: 565.1773071289062|  0:00:29s\n","epoch 28 | loss: 95.66854| val_0_mse: 536.6072387695312|  0:00:30s\n","epoch 29 | loss: 86.44248| val_0_mse: 392.9859313964844|  0:00:31s\n","epoch 30 | loss: 89.59758| val_0_mse: 377.61883544921875|  0:00:32s\n","epoch 31 | loss: 88.95395| val_0_mse: 340.5150451660156|  0:00:33s\n","epoch 32 | loss: 87.10675| val_0_mse: 217.14683532714844|  0:00:34s\n","epoch 33 | loss: 91.55639| val_0_mse: 229.033935546875|  0:00:35s\n","epoch 34 | loss: 87.22571| val_0_mse: 166.81951904296875|  0:00:36s\n","epoch 35 | loss: 94.16198| val_0_mse: 159.66160583496094|  0:00:37s\n","epoch 36 | loss: 85.02462| val_0_mse: 150.65176391601562|  0:00:39s\n","epoch 37 | loss: 86.18216| val_0_mse: 124.95868682861328|  0:00:40s\n","epoch 38 | loss: 72.96663| val_0_mse: 89.57787322998047|  0:00:41s\n","epoch 39 | loss: 66.95441| val_0_mse: 84.1610336303711|  0:00:42s\n","epoch 40 | loss: 90.46391| val_0_mse: 85.15347290039062|  0:00:43s\n","epoch 41 | loss: 84.88538| val_0_mse: 66.97821807861328|  0:00:44s\n","epoch 42 | loss: 68.61828| val_0_mse: 75.19351196289062|  0:00:45s\n","epoch 43 | loss: 75.91088| val_0_mse: 81.8656997680664|  0:00:46s\n","epoch 44 | loss: 77.31808| val_0_mse: 61.61494827270508|  0:00:47s\n","epoch 45 | loss: 86.16579| val_0_mse: 77.41474151611328|  0:00:48s\n","epoch 46 | loss: 83.89633| val_0_mse: 57.141849517822266|  0:00:49s\n","epoch 47 | loss: 67.67577| val_0_mse: 48.847599029541016|  0:00:50s\n","epoch 48 | loss: 74.96006| val_0_mse: 40.52544021606445|  0:00:51s\n","epoch 49 | loss: 63.37053| val_0_mse: 32.79648971557617|  0:00:52s\n","epoch 50 | loss: 60.00534| val_0_mse: 96.02526092529297|  0:00:53s\n","epoch 51 | loss: 62.07054| val_0_mse: 54.59865951538086|  0:00:54s\n","epoch 52 | loss: 63.77673| val_0_mse: 63.83279037475586|  0:00:55s\n","epoch 53 | loss: 79.059  | val_0_mse: 36.862159729003906|  0:00:56s\n","epoch 54 | loss: 76.49687| val_0_mse: 66.99884796142578|  0:00:57s\n","epoch 55 | loss: 81.69814| val_0_mse: 53.741458892822266|  0:00:58s\n","epoch 56 | loss: 92.79735| val_0_mse: 55.201698303222656|  0:00:59s\n","epoch 57 | loss: 80.67755| val_0_mse: 35.873931884765625|  0:01:00s\n","epoch 58 | loss: 60.821  | val_0_mse: 41.17647933959961|  0:01:01s\n","epoch 59 | loss: 63.4748 | val_0_mse: 30.042089462280273|  0:01:02s\n","epoch 60 | loss: 54.96593| val_0_mse: 62.97919845581055|  0:01:03s\n","epoch 61 | loss: 68.29601| val_0_mse: 45.93363952636719|  0:01:04s\n","epoch 62 | loss: 55.58748| val_0_mse: 32.588218688964844|  0:01:05s\n","epoch 63 | loss: 66.53082| val_0_mse: 42.124900817871094|  0:01:06s\n","epoch 64 | loss: 58.83048| val_0_mse: 32.943580627441406|  0:01:07s\n","epoch 65 | loss: 58.07192| val_0_mse: 37.02204132080078|  0:01:08s\n","epoch 66 | loss: 55.27644| val_0_mse: 40.962608337402344|  0:01:09s\n","epoch 67 | loss: 60.34712| val_0_mse: 42.28955841064453|  0:01:10s\n","epoch 68 | loss: 58.82119| val_0_mse: 38.126991271972656|  0:01:11s\n","epoch 69 | loss: 55.47718| val_0_mse: 42.57712173461914|  0:01:12s\n","\n","Early stopping occurred at epoch 69 with best_epoch = 59 and best_val_0_mse = 30.042089462280273\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 12:56:23,213] Trial 8 finished with value: 30.042089462280273 and parameters: {'n_d': 64, 'n_steps': 4, 'gamma': 1.7052985911136433, 'n_independent': 5, 'n_shared': 5, 'momentum': 0.1842154308738535}. Best is trial 2 with value: 20.19026756286621.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 2482.73522| val_0_mse: 4462.6044921875|  0:00:01s\n","epoch 1  | loss: 2078.51095| val_0_mse: 12993.6240234375|  0:00:03s\n","epoch 2  | loss: 1751.42396| val_0_mse: 3838.09130859375|  0:00:04s\n","epoch 3  | loss: 1586.92786| val_0_mse: 8229.0595703125|  0:00:06s\n","epoch 4  | loss: 1415.50195| val_0_mse: 4237.40771484375|  0:00:08s\n","epoch 5  | loss: 1342.70345| val_0_mse: 4765.021484375|  0:00:09s\n","epoch 6  | loss: 1164.57103| val_0_mse: 2818.27197265625|  0:00:11s\n","epoch 7  | loss: 1277.1494| val_0_mse: 3349.622314453125|  0:00:12s\n","epoch 8  | loss: 1134.17486| val_0_mse: 4002.291748046875|  0:00:14s\n","epoch 9  | loss: 1035.3281| val_0_mse: 2833.133544921875|  0:00:16s\n","epoch 10 | loss: 870.52141| val_0_mse: 3384.53076171875|  0:00:17s\n","epoch 11 | loss: 768.32157| val_0_mse: 1941.55322265625|  0:00:19s\n","epoch 12 | loss: 718.97213| val_0_mse: 1881.026611328125|  0:00:20s\n","epoch 13 | loss: 883.44911| val_0_mse: 1901.5985107421875|  0:00:22s\n","epoch 14 | loss: 791.64755| val_0_mse: 1484.09521484375|  0:00:24s\n","epoch 15 | loss: 690.24554| val_0_mse: 1659.7227783203125|  0:00:25s\n","epoch 16 | loss: 676.13269| val_0_mse: 1663.283203125|  0:00:27s\n","epoch 17 | loss: 679.64197| val_0_mse: 2034.8297119140625|  0:00:28s\n","epoch 18 | loss: 696.03383| val_0_mse: 1474.15380859375|  0:00:30s\n","epoch 19 | loss: 576.16059| val_0_mse: 1584.57470703125|  0:00:32s\n","epoch 20 | loss: 580.8635| val_0_mse: 1459.177490234375|  0:00:33s\n","epoch 21 | loss: 760.47734| val_0_mse: 860.9755859375|  0:00:35s\n","epoch 22 | loss: 759.50077| val_0_mse: 993.0064697265625|  0:00:37s\n","epoch 23 | loss: 721.48831| val_0_mse: 968.6680908203125|  0:00:38s\n","epoch 24 | loss: 698.80844| val_0_mse: 902.751708984375|  0:00:40s\n","epoch 25 | loss: 597.0667| val_0_mse: 778.1535034179688|  0:00:42s\n","epoch 26 | loss: 517.27928| val_0_mse: 1027.787109375|  0:00:43s\n","epoch 27 | loss: 498.33739| val_0_mse: 602.3533935546875|  0:00:45s\n","epoch 28 | loss: 424.48225| val_0_mse: 504.0953063964844|  0:00:46s\n","epoch 29 | loss: 338.73297| val_0_mse: 447.8720703125|  0:00:48s\n","epoch 30 | loss: 287.99021| val_0_mse: 329.8448791503906|  0:00:50s\n","epoch 31 | loss: 240.94597| val_0_mse: 351.27166748046875|  0:00:51s\n","epoch 32 | loss: 195.90822| val_0_mse: 280.2352600097656|  0:00:53s\n","epoch 33 | loss: 170.23713| val_0_mse: 214.04696655273438|  0:00:54s\n","epoch 34 | loss: 146.57722| val_0_mse: 237.79722595214844|  0:00:56s\n","epoch 35 | loss: 177.46371| val_0_mse: 229.89649963378906|  0:00:58s\n","epoch 36 | loss: 145.8415| val_0_mse: 227.40911865234375|  0:00:59s\n","epoch 37 | loss: 145.4586| val_0_mse: 144.09829711914062|  0:01:01s\n","epoch 38 | loss: 146.29177| val_0_mse: 136.51174926757812|  0:01:02s\n","epoch 39 | loss: 135.85551| val_0_mse: 138.70681762695312|  0:01:04s\n","epoch 40 | loss: 123.71777| val_0_mse: 176.03907775878906|  0:01:06s\n","epoch 41 | loss: 141.93924| val_0_mse: 82.88522338867188|  0:01:07s\n","epoch 42 | loss: 126.32149| val_0_mse: 110.48094940185547|  0:01:09s\n","epoch 43 | loss: 121.88927| val_0_mse: 61.61423873901367|  0:01:10s\n","epoch 44 | loss: 111.62256| val_0_mse: 96.48301696777344|  0:01:12s\n","epoch 45 | loss: 99.99673| val_0_mse: 68.97260284423828|  0:01:14s\n","epoch 46 | loss: 117.35526| val_0_mse: 56.27008819580078|  0:01:15s\n","epoch 47 | loss: 121.17108| val_0_mse: 73.92247772216797|  0:01:17s\n","epoch 48 | loss: 138.34442| val_0_mse: 64.97962188720703|  0:01:19s\n","epoch 49 | loss: 114.07738| val_0_mse: 53.9603385925293|  0:01:20s\n","epoch 50 | loss: 102.51721| val_0_mse: 83.98136138916016|  0:01:22s\n","epoch 51 | loss: 115.72151| val_0_mse: 164.7353515625|  0:01:23s\n","epoch 52 | loss: 110.67305| val_0_mse: 79.9256591796875|  0:01:25s\n","epoch 53 | loss: 105.64523| val_0_mse: 60.99367141723633|  0:01:27s\n","epoch 54 | loss: 113.92494| val_0_mse: 69.72857666015625|  0:01:28s\n","epoch 55 | loss: 117.07629| val_0_mse: 83.28230285644531|  0:01:30s\n","epoch 56 | loss: 115.72071| val_0_mse: 78.75076293945312|  0:01:31s\n","epoch 57 | loss: 105.00603| val_0_mse: 65.93630981445312|  0:01:33s\n","epoch 58 | loss: 101.04913| val_0_mse: 84.16368865966797|  0:01:35s\n","epoch 59 | loss: 135.14749| val_0_mse: 116.47074127197266|  0:01:36s\n","\n","Early stopping occurred at epoch 59 with best_epoch = 49 and best_val_0_mse = 53.9603385925293\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 12:58:00,709] Trial 9 finished with value: 53.96034240722656 and parameters: {'n_d': 27, 'n_steps': 10, 'gamma': 1.7675770205040182, 'n_independent': 5, 'n_shared': 2, 'momentum': 0.3711408617553165}. Best is trial 2 with value: 20.19026756286621.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 2381.66197| val_0_mse: 2428.87890625|  0:00:00s\n","epoch 1  | loss: 1886.56638| val_0_mse: 2465.60205078125|  0:00:01s\n","epoch 2  | loss: 1084.18064| val_0_mse: 2275.5107421875|  0:00:01s\n","epoch 3  | loss: 543.08404| val_0_mse: 2341.847900390625|  0:00:02s\n","epoch 4  | loss: 390.44669| val_0_mse: 2272.105712890625|  0:00:02s\n","epoch 5  | loss: 314.98811| val_0_mse: 2338.500244140625|  0:00:03s\n","epoch 6  | loss: 246.49868| val_0_mse: 2557.083740234375|  0:00:03s\n","epoch 7  | loss: 199.24162| val_0_mse: 2693.57861328125|  0:00:04s\n","epoch 8  | loss: 178.80358| val_0_mse: 2639.47412109375|  0:00:04s\n","epoch 9  | loss: 164.69183| val_0_mse: 2681.386962890625|  0:00:05s\n","epoch 10 | loss: 151.50188| val_0_mse: 2558.577392578125|  0:00:05s\n","epoch 11 | loss: 135.43664| val_0_mse: 2590.278076171875|  0:00:06s\n","epoch 12 | loss: 130.41467| val_0_mse: 2643.633056640625|  0:00:06s\n","epoch 13 | loss: 116.76826| val_0_mse: 2599.237060546875|  0:00:07s\n","epoch 14 | loss: 106.19852| val_0_mse: 2587.027587890625|  0:00:07s\n","\n","Early stopping occurred at epoch 14 with best_epoch = 4 and best_val_0_mse = 2272.105712890625\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 12:58:08,993] Trial 10 finished with value: 2272.105712890625 and parameters: {'n_d': 12, 'n_steps': 5, 'gamma': 1.0446238255966858, 'n_independent': 1, 'n_shared': 2, 'momentum': 0.015836610377209376}. Best is trial 2 with value: 20.19026756286621.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 2218.12485| val_0_mse: 5489.87890625|  0:00:00s\n","epoch 1  | loss: 997.28217| val_0_mse: 2807.30810546875|  0:00:01s\n","epoch 2  | loss: 298.62759| val_0_mse: 7706.2548828125|  0:00:01s\n","epoch 3  | loss: 220.93631| val_0_mse: 3133.775390625|  0:00:02s\n","epoch 4  | loss: 181.65975| val_0_mse: 2795.27197265625|  0:00:03s\n","epoch 5  | loss: 163.56915| val_0_mse: 2610.4853515625|  0:00:03s\n","epoch 6  | loss: 139.19081| val_0_mse: 2811.459228515625|  0:00:04s\n","epoch 7  | loss: 125.73019| val_0_mse: 2727.59130859375|  0:00:05s\n","epoch 8  | loss: 128.42967| val_0_mse: 2928.646728515625|  0:00:05s\n","epoch 9  | loss: 117.2346| val_0_mse: 2729.14208984375|  0:00:06s\n","epoch 10 | loss: 118.43725| val_0_mse: 2781.709228515625|  0:00:06s\n","epoch 11 | loss: 100.66156| val_0_mse: 2698.774169921875|  0:00:07s\n","epoch 12 | loss: 83.8347 | val_0_mse: 2691.54443359375|  0:00:08s\n","epoch 13 | loss: 79.83581| val_0_mse: 2602.7607421875|  0:00:08s\n","epoch 14 | loss: 82.01193| val_0_mse: 2612.087646484375|  0:00:09s\n","epoch 15 | loss: 95.22776| val_0_mse: 2417.866455078125|  0:00:10s\n","epoch 16 | loss: 88.06469| val_0_mse: 2105.59521484375|  0:00:10s\n","epoch 17 | loss: 77.69252| val_0_mse: 2264.043701171875|  0:00:11s\n","epoch 18 | loss: 78.58018| val_0_mse: 2068.244873046875|  0:00:12s\n","epoch 19 | loss: 80.94867| val_0_mse: 2079.446533203125|  0:00:12s\n","epoch 20 | loss: 65.50099| val_0_mse: 1590.542724609375|  0:00:13s\n","epoch 21 | loss: 65.90949| val_0_mse: 861.8919067382812|  0:00:13s\n","epoch 22 | loss: 68.52906| val_0_mse: 781.3779296875|  0:00:14s\n","epoch 23 | loss: 76.12715| val_0_mse: 739.1170654296875|  0:00:15s\n","epoch 24 | loss: 69.69861| val_0_mse: 822.1651000976562|  0:00:15s\n","epoch 25 | loss: 71.70586| val_0_mse: 612.2843627929688|  0:00:16s\n","epoch 26 | loss: 56.47326| val_0_mse: 572.7615966796875|  0:00:17s\n","epoch 27 | loss: 68.50714| val_0_mse: 416.5329284667969|  0:00:17s\n","epoch 28 | loss: 59.60368| val_0_mse: 348.8971252441406|  0:00:18s\n","epoch 29 | loss: 68.8261 | val_0_mse: 269.5551452636719|  0:00:19s\n","epoch 30 | loss: 64.80305| val_0_mse: 234.12100219726562|  0:00:19s\n","epoch 31 | loss: 55.81397| val_0_mse: 219.88168334960938|  0:00:20s\n","epoch 32 | loss: 46.91052| val_0_mse: 172.38873291015625|  0:00:20s\n","epoch 33 | loss: 38.9213 | val_0_mse: 211.2801055908203|  0:00:21s\n","epoch 34 | loss: 55.74796| val_0_mse: 139.77587890625|  0:00:22s\n","epoch 35 | loss: 55.3763 | val_0_mse: 113.19007110595703|  0:00:22s\n","epoch 36 | loss: 63.79087| val_0_mse: 98.2228012084961|  0:00:23s\n","epoch 37 | loss: 79.66824| val_0_mse: 121.80137634277344|  0:00:24s\n","epoch 38 | loss: 57.30974| val_0_mse: 79.98480987548828|  0:00:24s\n","epoch 39 | loss: 49.23522| val_0_mse: 89.08540344238281|  0:00:25s\n","epoch 40 | loss: 48.10208| val_0_mse: 50.20201873779297|  0:00:26s\n","epoch 41 | loss: 46.8151 | val_0_mse: 76.52395629882812|  0:00:26s\n","epoch 42 | loss: 60.97918| val_0_mse: 47.42361831665039|  0:00:27s\n","epoch 43 | loss: 45.42802| val_0_mse: 60.3884391784668|  0:00:27s\n","epoch 44 | loss: 48.11665| val_0_mse: 75.13056945800781|  0:00:28s\n","epoch 45 | loss: 51.24516| val_0_mse: 35.8155517578125|  0:00:29s\n","epoch 46 | loss: 55.93093| val_0_mse: 37.20460891723633|  0:00:29s\n","epoch 47 | loss: 41.09793| val_0_mse: 75.3354721069336|  0:00:30s\n","epoch 48 | loss: 57.35893| val_0_mse: 39.74972152709961|  0:00:31s\n","epoch 49 | loss: 47.82636| val_0_mse: 40.00218963623047|  0:00:31s\n","epoch 50 | loss: 40.17531| val_0_mse: 41.42137145996094|  0:00:32s\n","epoch 51 | loss: 53.33407| val_0_mse: 37.187801361083984|  0:00:33s\n","epoch 52 | loss: 64.12166| val_0_mse: 51.76987838745117|  0:00:33s\n","epoch 53 | loss: 50.11913| val_0_mse: 49.210121154785156|  0:00:34s\n","epoch 54 | loss: 42.2399 | val_0_mse: 35.06721115112305|  0:00:35s\n","epoch 55 | loss: 37.00142| val_0_mse: 31.007659912109375|  0:00:35s\n","epoch 56 | loss: 42.31125| val_0_mse: 44.958961486816406|  0:00:36s\n","epoch 57 | loss: 46.3221 | val_0_mse: 47.79732131958008|  0:00:37s\n","epoch 58 | loss: 58.20914| val_0_mse: 42.315101623535156|  0:00:37s\n","epoch 59 | loss: 55.5589 | val_0_mse: 32.85614013671875|  0:00:38s\n","epoch 60 | loss: 38.63326| val_0_mse: 30.1285400390625|  0:00:39s\n","epoch 61 | loss: 40.19332| val_0_mse: 26.212060928344727|  0:00:39s\n","epoch 62 | loss: 45.24825| val_0_mse: 31.263839721679688|  0:00:40s\n","epoch 63 | loss: 47.28121| val_0_mse: 35.226280212402344|  0:00:40s\n","epoch 64 | loss: 47.80659| val_0_mse: 39.31769943237305|  0:00:41s\n","epoch 65 | loss: 45.4432 | val_0_mse: 40.699501037597656|  0:00:42s\n","epoch 66 | loss: 41.64068| val_0_mse: 27.250789642333984|  0:00:42s\n","epoch 67 | loss: 32.30499| val_0_mse: 26.843509674072266|  0:00:43s\n","epoch 68 | loss: 54.02536| val_0_mse: 28.676610946655273|  0:00:44s\n","epoch 69 | loss: 35.7038 | val_0_mse: 34.16423034667969|  0:00:44s\n","epoch 70 | loss: 36.73833| val_0_mse: 39.07088088989258|  0:00:45s\n","epoch 71 | loss: 37.15348| val_0_mse: 29.266620635986328|  0:00:46s\n","\n","Early stopping occurred at epoch 71 with best_epoch = 61 and best_val_0_mse = 26.212060928344727\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 12:58:55,493] Trial 11 finished with value: 26.212064743041992 and parameters: {'n_d': 46, 'n_steps': 3, 'gamma': 1.576510716589495, 'n_independent': 4, 'n_shared': 3, 'momentum': 0.2690164610649735}. Best is trial 2 with value: 20.19026756286621.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 2002.04342| val_0_mse: 3209.44677734375|  0:00:00s\n","epoch 1  | loss: 864.29476| val_0_mse: 2885.499267578125|  0:00:01s\n","epoch 2  | loss: 375.74191| val_0_mse: 4811.17822265625|  0:00:01s\n","epoch 3  | loss: 213.3057| val_0_mse: 3153.56298828125|  0:00:02s\n","epoch 4  | loss: 187.51714| val_0_mse: 2869.557373046875|  0:00:02s\n","epoch 5  | loss: 164.43926| val_0_mse: 2630.25 |  0:00:03s\n","epoch 6  | loss: 145.22289| val_0_mse: 2617.16943359375|  0:00:04s\n","epoch 7  | loss: 115.58617| val_0_mse: 2746.05126953125|  0:00:04s\n","epoch 8  | loss: 99.74919| val_0_mse: 2862.86376953125|  0:00:05s\n","epoch 9  | loss: 101.41086| val_0_mse: 2803.42138671875|  0:00:05s\n","epoch 10 | loss: 111.87002| val_0_mse: 2564.474609375|  0:00:06s\n","epoch 11 | loss: 100.77289| val_0_mse: 2693.1943359375|  0:00:06s\n","epoch 12 | loss: 99.64378| val_0_mse: 2616.071044921875|  0:00:07s\n","epoch 13 | loss: 83.58347| val_0_mse: 2473.81640625|  0:00:08s\n","epoch 14 | loss: 75.84341| val_0_mse: 2592.779052734375|  0:00:08s\n","epoch 15 | loss: 69.10748| val_0_mse: 2576.971435546875|  0:00:09s\n","epoch 16 | loss: 73.31005| val_0_mse: 2506.34326171875|  0:00:09s\n","epoch 17 | loss: 78.58634| val_0_mse: 2304.765869140625|  0:00:10s\n","epoch 18 | loss: 75.87774| val_0_mse: 2112.03125|  0:00:11s\n","epoch 19 | loss: 87.44428| val_0_mse: 1892.0870361328125|  0:00:11s\n","epoch 20 | loss: 74.20003| val_0_mse: 1038.00830078125|  0:00:12s\n","epoch 21 | loss: 69.71625| val_0_mse: 1434.7791748046875|  0:00:12s\n","epoch 22 | loss: 69.86113| val_0_mse: 938.9899291992188|  0:00:13s\n","epoch 23 | loss: 66.23359| val_0_mse: 852.0947265625|  0:00:14s\n","epoch 24 | loss: 73.42405| val_0_mse: 604.8054809570312|  0:00:14s\n","epoch 25 | loss: 59.52804| val_0_mse: 586.3681030273438|  0:00:15s\n","epoch 26 | loss: 61.59303| val_0_mse: 390.5304870605469|  0:00:15s\n","epoch 27 | loss: 52.38311| val_0_mse: 370.86395263671875|  0:00:16s\n","epoch 28 | loss: 51.28283| val_0_mse: 302.1834716796875|  0:00:16s\n","epoch 29 | loss: 53.94195| val_0_mse: 211.62054443359375|  0:00:17s\n","epoch 30 | loss: 73.77047| val_0_mse: 213.91769409179688|  0:00:18s\n","epoch 31 | loss: 58.87397| val_0_mse: 179.1576385498047|  0:00:18s\n","epoch 32 | loss: 71.75513| val_0_mse: 115.30036163330078|  0:00:19s\n","epoch 33 | loss: 44.63037| val_0_mse: 161.63946533203125|  0:00:19s\n","epoch 34 | loss: 64.70409| val_0_mse: 117.53988647460938|  0:00:20s\n","epoch 35 | loss: 52.05852| val_0_mse: 92.16338348388672|  0:00:21s\n","epoch 36 | loss: 48.09198| val_0_mse: 77.98681640625|  0:00:21s\n","epoch 37 | loss: 47.56443| val_0_mse: 120.26335144042969|  0:00:22s\n","epoch 38 | loss: 60.06027| val_0_mse: 165.3954315185547|  0:00:22s\n","epoch 39 | loss: 72.99962| val_0_mse: 96.11451721191406|  0:00:23s\n","epoch 40 | loss: 59.53781| val_0_mse: 62.1550407409668|  0:00:23s\n","epoch 41 | loss: 62.89326| val_0_mse: 75.51676177978516|  0:00:24s\n","epoch 42 | loss: 51.70163| val_0_mse: 48.57965850830078|  0:00:25s\n","epoch 43 | loss: 49.84425| val_0_mse: 60.5873908996582|  0:00:25s\n","epoch 44 | loss: 45.18741| val_0_mse: 45.9217414855957|  0:00:26s\n","epoch 45 | loss: 44.43383| val_0_mse: 48.562808990478516|  0:00:26s\n","epoch 46 | loss: 38.82564| val_0_mse: 34.0900993347168|  0:00:27s\n","epoch 47 | loss: 37.36587| val_0_mse: 28.660879135131836|  0:00:28s\n","epoch 48 | loss: 35.26381| val_0_mse: 47.88264846801758|  0:00:28s\n","epoch 49 | loss: 54.29911| val_0_mse: 26.508880615234375|  0:00:29s\n","epoch 50 | loss: 46.76486| val_0_mse: 35.09321975708008|  0:00:29s\n","epoch 51 | loss: 42.54392| val_0_mse: 22.44729995727539|  0:00:30s\n","epoch 52 | loss: 38.29659| val_0_mse: 27.029300689697266|  0:00:31s\n","epoch 53 | loss: 41.21443| val_0_mse: 29.899620056152344|  0:00:31s\n","epoch 54 | loss: 33.58279| val_0_mse: 32.23870849609375|  0:00:32s\n","epoch 55 | loss: 49.03672| val_0_mse: 40.86288833618164|  0:00:32s\n","epoch 56 | loss: 51.00916| val_0_mse: 36.948158264160156|  0:00:33s\n","epoch 57 | loss: 39.40698| val_0_mse: 51.76102828979492|  0:00:33s\n","epoch 58 | loss: 42.11026| val_0_mse: 22.792339324951172|  0:00:34s\n","epoch 59 | loss: 38.596  | val_0_mse: 31.880260467529297|  0:00:35s\n","epoch 60 | loss: 39.29691| val_0_mse: 20.09079933166504|  0:00:35s\n","epoch 61 | loss: 42.29034| val_0_mse: 18.554779052734375|  0:00:36s\n","epoch 62 | loss: 44.17154| val_0_mse: 49.40550994873047|  0:00:36s\n","epoch 63 | loss: 54.76969| val_0_mse: 42.755859375|  0:00:37s\n","epoch 64 | loss: 37.17392| val_0_mse: 22.848539352416992|  0:00:38s\n","epoch 65 | loss: 43.58396| val_0_mse: 28.73267936706543|  0:00:38s\n","epoch 66 | loss: 35.18728| val_0_mse: 30.429880142211914|  0:00:39s\n","epoch 67 | loss: 37.88809| val_0_mse: 26.632240295410156|  0:00:39s\n","epoch 68 | loss: 40.49655| val_0_mse: 36.800209045410156|  0:00:40s\n","epoch 69 | loss: 38.20431| val_0_mse: 18.687700271606445|  0:00:40s\n","epoch 70 | loss: 32.76361| val_0_mse: 17.820999145507812|  0:00:41s\n","epoch 71 | loss: 39.07437| val_0_mse: 25.597320556640625|  0:00:41s\n","epoch 72 | loss: 36.07399| val_0_mse: 30.408260345458984|  0:00:42s\n","epoch 73 | loss: 33.05113| val_0_mse: 25.0106201171875|  0:00:43s\n","epoch 74 | loss: 30.63989| val_0_mse: 19.313180923461914|  0:00:43s\n","epoch 75 | loss: 31.80963| val_0_mse: 19.996370315551758|  0:00:44s\n","epoch 76 | loss: 37.36353| val_0_mse: 27.815019607543945|  0:00:44s\n","epoch 77 | loss: 29.38365| val_0_mse: 20.593299865722656|  0:00:45s\n","epoch 78 | loss: 33.99555| val_0_mse: 26.62125015258789|  0:00:45s\n","epoch 79 | loss: 41.92309| val_0_mse: 24.997419357299805|  0:00:46s\n","epoch 80 | loss: 26.47032| val_0_mse: 19.07501983642578|  0:00:47s\n","\n","Early stopping occurred at epoch 80 with best_epoch = 70 and best_val_0_mse = 17.820999145507812\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 12:59:42,887] Trial 12 finished with value: 17.820995330810547 and parameters: {'n_d': 48, 'n_steps': 3, 'gamma': 1.313234553663059, 'n_independent': 3, 'n_shared': 3, 'momentum': 0.1200476192926042}. Best is trial 12 with value: 17.820995330810547.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 2146.43083| val_0_mse: 3121.3447265625|  0:00:00s\n","epoch 1  | loss: 958.29198| val_0_mse: 2931.822998046875|  0:00:01s\n","epoch 2  | loss: 396.51657| val_0_mse: 3895.99072265625|  0:00:01s\n","epoch 3  | loss: 340.46013| val_0_mse: 2953.91259765625|  0:00:02s\n","epoch 4  | loss: 335.05398| val_0_mse: 2676.949462890625|  0:00:02s\n","epoch 5  | loss: 293.30722| val_0_mse: 2892.63330078125|  0:00:03s\n","epoch 6  | loss: 225.8615| val_0_mse: 2751.644775390625|  0:00:03s\n","epoch 7  | loss: 186.62808| val_0_mse: 2494.70458984375|  0:00:04s\n","epoch 8  | loss: 174.12198| val_0_mse: 2416.43994140625|  0:00:04s\n","epoch 9  | loss: 161.16727| val_0_mse: 2604.46142578125|  0:00:05s\n","epoch 10 | loss: 146.04979| val_0_mse: 2544.575439453125|  0:00:05s\n","epoch 11 | loss: 133.27285| val_0_mse: 2669.450927734375|  0:00:06s\n","epoch 12 | loss: 133.69146| val_0_mse: 2624.64990234375|  0:00:07s\n","epoch 13 | loss: 133.81566| val_0_mse: 2724.658935546875|  0:00:07s\n","epoch 14 | loss: 136.82971| val_0_mse: 2732.558349609375|  0:00:08s\n","epoch 15 | loss: 122.86913| val_0_mse: 2477.166015625|  0:00:08s\n","epoch 16 | loss: 118.2584| val_0_mse: 2308.639404296875|  0:00:09s\n","epoch 17 | loss: 91.06466| val_0_mse: 2139.915771484375|  0:00:09s\n","epoch 18 | loss: 104.23599| val_0_mse: 1800.33935546875|  0:00:10s\n","epoch 19 | loss: 89.38193| val_0_mse: 1569.583984375|  0:00:10s\n","epoch 20 | loss: 108.01588| val_0_mse: 1437.21044921875|  0:00:11s\n","epoch 21 | loss: 80.03547| val_0_mse: 1328.0196533203125|  0:00:11s\n","epoch 22 | loss: 83.14354| val_0_mse: 1235.640380859375|  0:00:12s\n","epoch 23 | loss: 84.35392| val_0_mse: 1084.01220703125|  0:00:12s\n","epoch 24 | loss: 77.78468| val_0_mse: 963.8694458007812|  0:00:13s\n","epoch 25 | loss: 76.70108| val_0_mse: 574.8662719726562|  0:00:14s\n","epoch 26 | loss: 68.35798| val_0_mse: 654.8717651367188|  0:00:14s\n","epoch 27 | loss: 71.44475| val_0_mse: 511.95379638671875|  0:00:15s\n","epoch 28 | loss: 72.05553| val_0_mse: 509.60699462890625|  0:00:15s\n","epoch 29 | loss: 67.80959| val_0_mse: 608.9427490234375|  0:00:16s\n","epoch 30 | loss: 67.20641| val_0_mse: 310.8097229003906|  0:00:17s\n","epoch 31 | loss: 68.39271| val_0_mse: 304.9252014160156|  0:00:17s\n","epoch 32 | loss: 58.74251| val_0_mse: 302.7919616699219|  0:00:18s\n","epoch 33 | loss: 59.09452| val_0_mse: 233.05035400390625|  0:00:18s\n","epoch 34 | loss: 54.35283| val_0_mse: 152.08828735351562|  0:00:19s\n","epoch 35 | loss: 53.76603| val_0_mse: 181.22030639648438|  0:00:19s\n","epoch 36 | loss: 60.17776| val_0_mse: 155.48927307128906|  0:00:20s\n","epoch 37 | loss: 54.2808 | val_0_mse: 141.488525390625|  0:00:20s\n","epoch 38 | loss: 82.21593| val_0_mse: 162.074951171875|  0:00:21s\n","epoch 39 | loss: 56.41449| val_0_mse: 69.36451721191406|  0:00:21s\n","epoch 40 | loss: 56.78333| val_0_mse: 83.30835723876953|  0:00:22s\n","epoch 41 | loss: 47.59151| val_0_mse: 83.99967956542969|  0:00:22s\n","epoch 42 | loss: 57.18236| val_0_mse: 82.75863647460938|  0:00:23s\n","epoch 43 | loss: 56.65205| val_0_mse: 95.29853057861328|  0:00:23s\n","epoch 44 | loss: 56.42195| val_0_mse: 83.79547882080078|  0:00:24s\n","epoch 45 | loss: 50.37143| val_0_mse: 65.83740234375|  0:00:24s\n","epoch 46 | loss: 61.37275| val_0_mse: 59.79880905151367|  0:00:25s\n","epoch 47 | loss: 42.80626| val_0_mse: 46.89337921142578|  0:00:26s\n","epoch 48 | loss: 44.70279| val_0_mse: 47.45362091064453|  0:00:26s\n","epoch 49 | loss: 39.32266| val_0_mse: 41.97407913208008|  0:00:27s\n","epoch 50 | loss: 47.62289| val_0_mse: 27.042739868164062|  0:00:27s\n","epoch 51 | loss: 47.9319 | val_0_mse: 35.66307830810547|  0:00:28s\n","epoch 52 | loss: 54.80676| val_0_mse: 38.86613845825195|  0:00:28s\n","epoch 53 | loss: 46.52219| val_0_mse: 29.917739868164062|  0:00:29s\n","epoch 54 | loss: 35.50732| val_0_mse: 24.04680061340332|  0:00:29s\n","epoch 55 | loss: 39.97327| val_0_mse: 37.4445686340332|  0:00:30s\n","epoch 56 | loss: 54.65533| val_0_mse: 56.892799377441406|  0:00:30s\n","epoch 57 | loss: 53.37185| val_0_mse: 25.828550338745117|  0:00:31s\n","epoch 58 | loss: 34.98756| val_0_mse: 34.12852096557617|  0:00:31s\n","epoch 59 | loss: 41.61864| val_0_mse: 26.095670700073242|  0:00:32s\n","epoch 60 | loss: 36.17267| val_0_mse: 24.201040267944336|  0:00:32s\n","epoch 61 | loss: 39.58196| val_0_mse: 28.59600067138672|  0:00:33s\n","epoch 62 | loss: 31.85117| val_0_mse: 23.491010665893555|  0:00:33s\n","epoch 63 | loss: 36.08718| val_0_mse: 30.54166030883789|  0:00:34s\n","epoch 64 | loss: 32.59349| val_0_mse: 21.800140380859375|  0:00:35s\n","epoch 65 | loss: 35.19963| val_0_mse: 24.30113983154297|  0:00:35s\n","epoch 66 | loss: 46.85611| val_0_mse: 41.329498291015625|  0:00:36s\n","epoch 67 | loss: 49.64335| val_0_mse: 56.269161224365234|  0:00:36s\n","epoch 68 | loss: 48.92385| val_0_mse: 26.947750091552734|  0:00:37s\n","epoch 69 | loss: 43.94673| val_0_mse: 27.115440368652344|  0:00:37s\n","epoch 70 | loss: 35.63568| val_0_mse: 31.936349868774414|  0:00:38s\n","epoch 71 | loss: 49.13384| val_0_mse: 29.733280181884766|  0:00:38s\n","epoch 72 | loss: 36.85825| val_0_mse: 21.32636070251465|  0:00:39s\n","epoch 73 | loss: 34.99233| val_0_mse: 43.500389099121094|  0:00:39s\n","epoch 74 | loss: 49.97386| val_0_mse: 31.513309478759766|  0:00:40s\n","epoch 75 | loss: 42.79436| val_0_mse: 33.20524978637695|  0:00:40s\n","epoch 76 | loss: 37.73324| val_0_mse: 23.3518009185791|  0:00:41s\n","epoch 77 | loss: 49.71437| val_0_mse: 49.6285400390625|  0:00:42s\n","epoch 78 | loss: 47.92417| val_0_mse: 28.559179306030273|  0:00:42s\n","epoch 79 | loss: 33.34504| val_0_mse: 18.020370483398438|  0:00:43s\n","epoch 80 | loss: 32.43313| val_0_mse: 22.38705062866211|  0:00:43s\n","epoch 81 | loss: 29.36582| val_0_mse: 24.16781997680664|  0:00:44s\n","epoch 82 | loss: 32.72504| val_0_mse: 30.276180267333984|  0:00:44s\n","epoch 83 | loss: 37.65189| val_0_mse: 27.948139190673828|  0:00:45s\n","epoch 84 | loss: 38.59676| val_0_mse: 25.649330139160156|  0:00:45s\n","epoch 85 | loss: 31.24521| val_0_mse: 20.96286964416504|  0:00:46s\n","epoch 86 | loss: 37.4416 | val_0_mse: 20.537099838256836|  0:00:46s\n","epoch 87 | loss: 36.85435| val_0_mse: 37.29439163208008|  0:00:47s\n","epoch 88 | loss: 35.18525| val_0_mse: 23.907459259033203|  0:00:47s\n","epoch 89 | loss: 33.20408| val_0_mse: 23.797529220581055|  0:00:48s\n","\n","Early stopping occurred at epoch 89 with best_epoch = 79 and best_val_0_mse = 18.020370483398438\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 13:00:31,718] Trial 13 finished with value: 18.02037239074707 and parameters: {'n_d': 41, 'n_steps': 4, 'gamma': 1.296212670682716, 'n_independent': 2, 'n_shared': 2, 'momentum': 0.24511627304126654}. Best is trial 12 with value: 17.820995330810547.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 2120.89365| val_0_mse: 6441.50341796875|  0:00:00s\n","epoch 1  | loss: 1224.23167| val_0_mse: 5487.15087890625|  0:00:01s\n","epoch 2  | loss: 556.8251| val_0_mse: 17838.380859375|  0:00:02s\n","epoch 3  | loss: 387.92005| val_0_mse: 2778.50048828125|  0:00:03s\n","epoch 4  | loss: 372.31428| val_0_mse: 3043.13671875|  0:00:04s\n","epoch 5  | loss: 330.52177| val_0_mse: 3248.29541015625|  0:00:04s\n","epoch 6  | loss: 311.42589| val_0_mse: 4155.48388671875|  0:00:05s\n","epoch 7  | loss: 316.18273| val_0_mse: 4010.3515625|  0:00:06s\n","epoch 8  | loss: 269.13657| val_0_mse: 4444.09814453125|  0:00:07s\n","epoch 9  | loss: 245.30579| val_0_mse: 2644.023193359375|  0:00:08s\n","epoch 10 | loss: 259.65419| val_0_mse: 2751.887451171875|  0:00:08s\n","epoch 11 | loss: 229.11106| val_0_mse: 2754.458984375|  0:00:09s\n","epoch 12 | loss: 189.40018| val_0_mse: 2655.1513671875|  0:00:10s\n","epoch 13 | loss: 164.73276| val_0_mse: 2762.19677734375|  0:00:11s\n","epoch 14 | loss: 168.48057| val_0_mse: 2440.332763671875|  0:00:11s\n","epoch 15 | loss: 142.68046| val_0_mse: 2333.15673828125|  0:00:12s\n","epoch 16 | loss: 144.26003| val_0_mse: 2170.66796875|  0:00:13s\n","epoch 17 | loss: 125.47993| val_0_mse: 1777.775146484375|  0:00:14s\n","epoch 18 | loss: 124.24644| val_0_mse: 1481.4697265625|  0:00:15s\n","epoch 19 | loss: 121.06654| val_0_mse: 1230.6429443359375|  0:00:16s\n","epoch 20 | loss: 111.79366| val_0_mse: 946.8546142578125|  0:00:16s\n","epoch 21 | loss: 107.97488| val_0_mse: 883.10986328125|  0:00:17s\n","epoch 22 | loss: 117.99015| val_0_mse: 832.734130859375|  0:00:18s\n","epoch 23 | loss: 93.0835 | val_0_mse: 700.1810302734375|  0:00:19s\n","epoch 24 | loss: 94.06406| val_0_mse: 639.3120727539062|  0:00:20s\n","epoch 25 | loss: 99.36596| val_0_mse: 476.8189697265625|  0:00:21s\n","epoch 26 | loss: 85.30986| val_0_mse: 443.99334716796875|  0:00:21s\n","epoch 27 | loss: 86.14118| val_0_mse: 412.2876281738281|  0:00:22s\n","epoch 28 | loss: 83.7987 | val_0_mse: 361.73223876953125|  0:00:23s\n","epoch 29 | loss: 78.27138| val_0_mse: 301.67431640625|  0:00:24s\n","epoch 30 | loss: 80.78371| val_0_mse: 237.96185302734375|  0:00:25s\n","epoch 31 | loss: 73.62644| val_0_mse: 233.45970153808594|  0:00:25s\n","epoch 32 | loss: 66.91787| val_0_mse: 123.89412689208984|  0:00:26s\n","epoch 33 | loss: 69.07466| val_0_mse: 108.98209381103516|  0:00:27s\n","epoch 34 | loss: 86.35167| val_0_mse: 135.60006713867188|  0:00:28s\n","epoch 35 | loss: 64.66938| val_0_mse: 76.77487182617188|  0:00:29s\n","epoch 36 | loss: 69.93305| val_0_mse: 104.6761703491211|  0:00:30s\n","epoch 37 | loss: 86.71102| val_0_mse: 61.5161018371582|  0:00:30s\n","epoch 38 | loss: 80.79596| val_0_mse: 75.44538116455078|  0:00:31s\n","epoch 39 | loss: 72.81503| val_0_mse: 63.6973991394043|  0:00:32s\n","epoch 40 | loss: 67.98372| val_0_mse: 71.48133087158203|  0:00:33s\n","epoch 41 | loss: 75.02561| val_0_mse: 63.554561614990234|  0:00:34s\n","epoch 42 | loss: 76.44268| val_0_mse: 84.10684204101562|  0:00:34s\n","epoch 43 | loss: 78.62982| val_0_mse: 52.06509017944336|  0:00:35s\n","epoch 44 | loss: 69.67372| val_0_mse: 34.67047882080078|  0:00:36s\n","epoch 45 | loss: 86.2143 | val_0_mse: 58.54561996459961|  0:00:37s\n","epoch 46 | loss: 70.90452| val_0_mse: 47.93281936645508|  0:00:38s\n","epoch 47 | loss: 66.62433| val_0_mse: 47.046539306640625|  0:00:39s\n","epoch 48 | loss: 58.71688| val_0_mse: 59.63249969482422|  0:00:39s\n","epoch 49 | loss: 66.02749| val_0_mse: 33.04119873046875|  0:00:40s\n","epoch 50 | loss: 63.91468| val_0_mse: 42.0301513671875|  0:00:41s\n","epoch 51 | loss: 50.36826| val_0_mse: 37.678199768066406|  0:00:42s\n","epoch 52 | loss: 52.26271| val_0_mse: 48.29594039916992|  0:00:43s\n","epoch 53 | loss: 53.07583| val_0_mse: 31.764089584350586|  0:00:43s\n","epoch 54 | loss: 48.62704| val_0_mse: 31.556320190429688|  0:00:44s\n","epoch 55 | loss: 58.21492| val_0_mse: 36.019779205322266|  0:00:45s\n","epoch 56 | loss: 47.66824| val_0_mse: 46.06713104248047|  0:00:46s\n","epoch 57 | loss: 51.97956| val_0_mse: 30.501249313354492|  0:00:47s\n","epoch 58 | loss: 51.19448| val_0_mse: 45.38600158691406|  0:00:47s\n","epoch 59 | loss: 61.08603| val_0_mse: 31.721389770507812|  0:00:48s\n","epoch 60 | loss: 53.86052| val_0_mse: 36.45281982421875|  0:00:49s\n","epoch 61 | loss: 41.65807| val_0_mse: 22.415260314941406|  0:00:50s\n","epoch 62 | loss: 42.56276| val_0_mse: 32.62369155883789|  0:00:51s\n","epoch 63 | loss: 50.96909| val_0_mse: 33.36140060424805|  0:00:52s\n","epoch 64 | loss: 46.35873| val_0_mse: 35.49898147583008|  0:00:52s\n","epoch 65 | loss: 67.13264| val_0_mse: 56.41543960571289|  0:00:53s\n","epoch 66 | loss: 56.2161 | val_0_mse: 31.44182014465332|  0:00:54s\n","epoch 67 | loss: 52.71979| val_0_mse: 38.22264099121094|  0:00:55s\n","epoch 68 | loss: 49.68428| val_0_mse: 25.47180938720703|  0:00:55s\n","epoch 69 | loss: 51.43333| val_0_mse: 35.40304183959961|  0:00:56s\n","epoch 70 | loss: 48.79492| val_0_mse: 37.556129455566406|  0:00:57s\n","epoch 71 | loss: 41.40468| val_0_mse: 29.90097999572754|  0:00:58s\n","\n","Early stopping occurred at epoch 71 with best_epoch = 61 and best_val_0_mse = 22.415260314941406\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 13:01:30,559] Trial 14 finished with value: 22.415254592895508 and parameters: {'n_d': 40, 'n_steps': 5, 'gamma': 1.2612292384880732, 'n_independent': 3, 'n_shared': 3, 'momentum': 0.08763753039670363}. Best is trial 12 with value: 17.820995330810547.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 2162.91371| val_0_mse: 9369.7548828125|  0:00:00s\n","epoch 1  | loss: 977.75059| val_0_mse: 2784.57666015625|  0:00:01s\n","epoch 2  | loss: 472.72254| val_0_mse: 4360.44921875|  0:00:01s\n","epoch 3  | loss: 283.08535| val_0_mse: 3614.026123046875|  0:00:02s\n","epoch 4  | loss: 200.20603| val_0_mse: 2614.68359375|  0:00:02s\n","epoch 5  | loss: 178.23326| val_0_mse: 2798.206787109375|  0:00:03s\n","epoch 6  | loss: 142.63707| val_0_mse: 2976.677978515625|  0:00:03s\n","epoch 7  | loss: 118.9387| val_0_mse: 2770.017822265625|  0:00:04s\n","epoch 8  | loss: 119.33513| val_0_mse: 2871.4599609375|  0:00:05s\n","epoch 9  | loss: 132.21249| val_0_mse: 2733.98876953125|  0:00:05s\n","epoch 10 | loss: 103.59746| val_0_mse: 2614.977294921875|  0:00:06s\n","epoch 11 | loss: 95.60259| val_0_mse: 2722.4677734375|  0:00:06s\n","epoch 12 | loss: 82.08398| val_0_mse: 2680.72705078125|  0:00:07s\n","epoch 13 | loss: 73.88787| val_0_mse: 2686.46484375|  0:00:07s\n","epoch 14 | loss: 75.50337| val_0_mse: 2379.090576171875|  0:00:08s\n","epoch 15 | loss: 67.43874| val_0_mse: 2559.374267578125|  0:00:08s\n","epoch 16 | loss: 67.75451| val_0_mse: 2423.227783203125|  0:00:09s\n","epoch 17 | loss: 60.06962| val_0_mse: 2583.195068359375|  0:00:10s\n","epoch 18 | loss: 67.00976| val_0_mse: 2199.84228515625|  0:00:10s\n","epoch 19 | loss: 70.97476| val_0_mse: 2123.07421875|  0:00:11s\n","epoch 20 | loss: 69.13626| val_0_mse: 1781.9859619140625|  0:00:11s\n","epoch 21 | loss: 58.89231| val_0_mse: 1236.1063232421875|  0:00:12s\n","epoch 22 | loss: 56.78448| val_0_mse: 1098.7125244140625|  0:00:12s\n","epoch 23 | loss: 53.16361| val_0_mse: 844.5161743164062|  0:00:13s\n","epoch 24 | loss: 49.37373| val_0_mse: 815.0256958007812|  0:00:14s\n","epoch 25 | loss: 59.1112 | val_0_mse: 550.8078002929688|  0:00:14s\n","epoch 26 | loss: 52.73137| val_0_mse: 455.0175476074219|  0:00:15s\n","epoch 27 | loss: 58.79258| val_0_mse: 553.3281860351562|  0:00:15s\n","epoch 28 | loss: 69.1933 | val_0_mse: 312.345703125|  0:00:16s\n","epoch 29 | loss: 53.12415| val_0_mse: 295.070068359375|  0:00:16s\n","epoch 30 | loss: 48.26765| val_0_mse: 298.4401550292969|  0:00:17s\n","epoch 31 | loss: 46.12794| val_0_mse: 192.35679626464844|  0:00:18s\n","epoch 32 | loss: 52.58701| val_0_mse: 287.6220703125|  0:00:18s\n","epoch 33 | loss: 48.27009| val_0_mse: 178.1806640625|  0:00:19s\n","epoch 34 | loss: 44.25065| val_0_mse: 114.6875|  0:00:19s\n","epoch 35 | loss: 53.33586| val_0_mse: 110.94062805175781|  0:00:20s\n","epoch 36 | loss: 44.31236| val_0_mse: 82.51586151123047|  0:00:20s\n","epoch 37 | loss: 39.52394| val_0_mse: 93.23882293701172|  0:00:21s\n","epoch 38 | loss: 41.79343| val_0_mse: 71.18901824951172|  0:00:22s\n","epoch 39 | loss: 37.87342| val_0_mse: 53.72924041748047|  0:00:22s\n","epoch 40 | loss: 64.37907| val_0_mse: 95.47010040283203|  0:00:23s\n","epoch 41 | loss: 62.65993| val_0_mse: 76.65879821777344|  0:00:23s\n","epoch 42 | loss: 47.6797 | val_0_mse: 55.80078125|  0:00:24s\n","epoch 43 | loss: 47.55681| val_0_mse: 56.672119140625|  0:00:24s\n","epoch 44 | loss: 38.51267| val_0_mse: 78.25811767578125|  0:00:25s\n","epoch 45 | loss: 33.66337| val_0_mse: 40.32244873046875|  0:00:25s\n","epoch 46 | loss: 41.90158| val_0_mse: 53.979000091552734|  0:00:26s\n","epoch 47 | loss: 43.64173| val_0_mse: 26.717529296875|  0:00:27s\n","epoch 48 | loss: 47.98975| val_0_mse: 22.965290069580078|  0:00:27s\n","epoch 49 | loss: 40.68407| val_0_mse: 46.11766815185547|  0:00:28s\n","epoch 50 | loss: 38.16059| val_0_mse: 43.65876007080078|  0:00:28s\n","epoch 51 | loss: 33.45526| val_0_mse: 32.24538040161133|  0:00:29s\n","epoch 52 | loss: 33.17592| val_0_mse: 24.854389190673828|  0:00:29s\n","epoch 53 | loss: 32.42568| val_0_mse: 24.311460494995117|  0:00:30s\n","epoch 54 | loss: 36.03366| val_0_mse: 36.4958610534668|  0:00:30s\n","epoch 55 | loss: 29.14813| val_0_mse: 22.32493019104004|  0:00:31s\n","epoch 56 | loss: 38.85881| val_0_mse: 27.713319778442383|  0:00:32s\n","epoch 57 | loss: 33.01777| val_0_mse: 23.797069549560547|  0:00:32s\n","epoch 58 | loss: 36.31439| val_0_mse: 40.7872314453125|  0:00:33s\n","epoch 59 | loss: 42.49246| val_0_mse: 21.03367042541504|  0:00:33s\n","epoch 60 | loss: 39.22666| val_0_mse: 32.09724044799805|  0:00:34s\n","epoch 61 | loss: 41.84924| val_0_mse: 34.43864059448242|  0:00:34s\n","epoch 62 | loss: 44.34222| val_0_mse: 28.4531192779541|  0:00:35s\n","epoch 63 | loss: 41.84699| val_0_mse: 19.26251983642578|  0:00:36s\n","epoch 64 | loss: 34.89512| val_0_mse: 35.90761947631836|  0:00:36s\n","epoch 65 | loss: 44.33613| val_0_mse: 30.418819427490234|  0:00:37s\n","epoch 66 | loss: 38.99799| val_0_mse: 22.397050857543945|  0:00:37s\n","epoch 67 | loss: 28.55394| val_0_mse: 22.934419631958008|  0:00:38s\n","epoch 68 | loss: 41.41228| val_0_mse: 27.002960205078125|  0:00:38s\n","epoch 69 | loss: 45.63504| val_0_mse: 24.060550689697266|  0:00:39s\n","epoch 70 | loss: 35.44882| val_0_mse: 24.34630012512207|  0:00:39s\n","epoch 71 | loss: 44.60254| val_0_mse: 27.65403938293457|  0:00:40s\n","epoch 72 | loss: 41.79052| val_0_mse: 23.808000564575195|  0:00:40s\n","epoch 73 | loss: 33.595  | val_0_mse: 19.548620223999023|  0:00:41s\n","\n","Early stopping occurred at epoch 73 with best_epoch = 63 and best_val_0_mse = 19.26251983642578\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 13:02:12,410] Trial 15 finished with value: 19.26251983642578 and parameters: {'n_d': 45, 'n_steps': 3, 'gamma': 1.4266612935074265, 'n_independent': 2, 'n_shared': 4, 'momentum': 0.24056902069352876}. Best is trial 12 with value: 17.820995330810547.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 2145.34273| val_0_mse: 3087.245849609375|  0:00:00s\n","epoch 1  | loss: 1084.11328| val_0_mse: 3376.088623046875|  0:00:01s\n","epoch 2  | loss: 546.58486| val_0_mse: 5291.88720703125|  0:00:02s\n","epoch 3  | loss: 307.25479| val_0_mse: 3668.8056640625|  0:00:02s\n","epoch 4  | loss: 241.90688| val_0_mse: 3107.6572265625|  0:00:03s\n","epoch 5  | loss: 186.87274| val_0_mse: 2784.4599609375|  0:00:04s\n","epoch 6  | loss: 165.85064| val_0_mse: 2777.727294921875|  0:00:05s\n","epoch 7  | loss: 161.6342| val_0_mse: 2622.715087890625|  0:00:05s\n","epoch 8  | loss: 136.03713| val_0_mse: 2534.63671875|  0:00:06s\n","epoch 9  | loss: 119.31256| val_0_mse: 2704.640869140625|  0:00:07s\n","epoch 10 | loss: 137.43675| val_0_mse: 2651.8388671875|  0:00:07s\n","epoch 11 | loss: 134.54424| val_0_mse: 2525.1435546875|  0:00:08s\n","epoch 12 | loss: 111.34165| val_0_mse: 2469.4765625|  0:00:09s\n","epoch 13 | loss: 103.15997| val_0_mse: 2566.312255859375|  0:00:09s\n","epoch 14 | loss: 107.43983| val_0_mse: 2418.712646484375|  0:00:10s\n","epoch 15 | loss: 137.8909| val_0_mse: 2356.01513671875|  0:00:11s\n","epoch 16 | loss: 107.51724| val_0_mse: 2146.980224609375|  0:00:12s\n","epoch 17 | loss: 98.13347| val_0_mse: 1862.8436279296875|  0:00:12s\n","epoch 18 | loss: 96.9666 | val_0_mse: 1537.7705078125|  0:00:13s\n","epoch 19 | loss: 94.47821| val_0_mse: 1599.459716796875|  0:00:14s\n","epoch 20 | loss: 106.95088| val_0_mse: 1365.2039794921875|  0:00:14s\n","epoch 21 | loss: 94.31347| val_0_mse: 1284.10595703125|  0:00:15s\n","epoch 22 | loss: 103.03758| val_0_mse: 720.3375244140625|  0:00:16s\n","epoch 23 | loss: 87.16913| val_0_mse: 669.379638671875|  0:00:17s\n","epoch 24 | loss: 78.92894| val_0_mse: 769.4814453125|  0:00:17s\n","epoch 25 | loss: 77.07672| val_0_mse: 601.9205932617188|  0:00:18s\n","epoch 26 | loss: 74.01366| val_0_mse: 464.1341552734375|  0:00:19s\n","epoch 27 | loss: 87.16126| val_0_mse: 376.9254150390625|  0:00:19s\n","epoch 28 | loss: 85.41385| val_0_mse: 372.544921875|  0:00:20s\n","epoch 29 | loss: 76.97374| val_0_mse: 226.85333251953125|  0:00:21s\n","epoch 30 | loss: 62.11229| val_0_mse: 274.157470703125|  0:00:21s\n","epoch 31 | loss: 67.07728| val_0_mse: 209.65016174316406|  0:00:22s\n","epoch 32 | loss: 69.71297| val_0_mse: 177.65293884277344|  0:00:23s\n","epoch 33 | loss: 72.51611| val_0_mse: 157.8103790283203|  0:00:24s\n","epoch 34 | loss: 69.44368| val_0_mse: 184.95216369628906|  0:00:24s\n","epoch 35 | loss: 66.05862| val_0_mse: 116.47174835205078|  0:00:25s\n","epoch 36 | loss: 56.58293| val_0_mse: 83.71968841552734|  0:00:26s\n","epoch 37 | loss: 52.05099| val_0_mse: 93.30032348632812|  0:00:26s\n","epoch 38 | loss: 54.11102| val_0_mse: 107.80489349365234|  0:00:27s\n","epoch 39 | loss: 55.11084| val_0_mse: 82.16787719726562|  0:00:28s\n","epoch 40 | loss: 64.30173| val_0_mse: 80.58432006835938|  0:00:29s\n","epoch 41 | loss: 50.37891| val_0_mse: 75.85469818115234|  0:00:29s\n","epoch 42 | loss: 58.29418| val_0_mse: 55.17782974243164|  0:00:30s\n","epoch 43 | loss: 51.39835| val_0_mse: 52.70758056640625|  0:00:31s\n","epoch 44 | loss: 48.83803| val_0_mse: 45.154998779296875|  0:00:32s\n","epoch 45 | loss: 57.84547| val_0_mse: 58.72111892700195|  0:00:32s\n","epoch 46 | loss: 54.38651| val_0_mse: 39.0088996887207|  0:00:33s\n","epoch 47 | loss: 45.41016| val_0_mse: 36.2929801940918|  0:00:34s\n","epoch 48 | loss: 55.97473| val_0_mse: 30.252099990844727|  0:00:34s\n","epoch 49 | loss: 49.41249| val_0_mse: 44.870811462402344|  0:00:35s\n","epoch 50 | loss: 54.84674| val_0_mse: 43.015220642089844|  0:00:36s\n","epoch 51 | loss: 52.57348| val_0_mse: 42.817298889160156|  0:00:37s\n","epoch 52 | loss: 52.57776| val_0_mse: 33.263328552246094|  0:00:37s\n","epoch 53 | loss: 57.6969 | val_0_mse: 56.5991096496582|  0:00:38s\n","epoch 54 | loss: 42.9604 | val_0_mse: 28.363269805908203|  0:00:39s\n","epoch 55 | loss: 53.53283| val_0_mse: 40.028839111328125|  0:00:39s\n","epoch 56 | loss: 76.65204| val_0_mse: 43.4658203125|  0:00:40s\n","epoch 57 | loss: 52.45827| val_0_mse: 36.93526077270508|  0:00:41s\n","epoch 58 | loss: 45.01085| val_0_mse: 28.29616928100586|  0:00:42s\n","epoch 59 | loss: 49.94943| val_0_mse: 37.45840072631836|  0:00:42s\n","epoch 60 | loss: 47.71687| val_0_mse: 28.638500213623047|  0:00:43s\n","epoch 61 | loss: 49.32515| val_0_mse: 46.135921478271484|  0:00:44s\n","epoch 62 | loss: 55.79713| val_0_mse: 33.176578521728516|  0:00:44s\n","epoch 63 | loss: 51.20538| val_0_mse: 33.0394287109375|  0:00:45s\n","epoch 64 | loss: 48.3121 | val_0_mse: 24.931039810180664|  0:00:46s\n","epoch 65 | loss: 44.10784| val_0_mse: 36.320411682128906|  0:00:46s\n","epoch 66 | loss: 47.65005| val_0_mse: 38.01601028442383|  0:00:47s\n","epoch 67 | loss: 57.68038| val_0_mse: 32.78974914550781|  0:00:48s\n","epoch 68 | loss: 41.31938| val_0_mse: 29.143980026245117|  0:00:48s\n","epoch 69 | loss: 54.22962| val_0_mse: 42.28493881225586|  0:00:49s\n","epoch 70 | loss: 53.49753| val_0_mse: 32.08811950683594|  0:00:50s\n","epoch 71 | loss: 57.76285| val_0_mse: 30.80624008178711|  0:00:51s\n","epoch 72 | loss: 45.84272| val_0_mse: 29.991779327392578|  0:00:51s\n","epoch 73 | loss: 44.57653| val_0_mse: 32.10639953613281|  0:00:52s\n","epoch 74 | loss: 56.49436| val_0_mse: 29.245580673217773|  0:00:53s\n","\n","Early stopping occurred at epoch 74 with best_epoch = 64 and best_val_0_mse = 24.931039810180664\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 13:03:06,087] Trial 16 finished with value: 24.93104362487793 and parameters: {'n_d': 32, 'n_steps': 5, 'gamma': 1.196776292911567, 'n_independent': 3, 'n_shared': 2, 'momentum': 0.1586182324793113}. Best is trial 12 with value: 17.820995330810547.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 2394.45025| val_0_mse: 3018.77783203125|  0:00:00s\n","epoch 1  | loss: 1879.80644| val_0_mse: 2297.68212890625|  0:00:01s\n","epoch 2  | loss: 985.46126| val_0_mse: 2309.846435546875|  0:00:01s\n","epoch 3  | loss: 391.62395| val_0_mse: 2471.82958984375|  0:00:02s\n","epoch 4  | loss: 306.47867| val_0_mse: 2562.04150390625|  0:00:02s\n","epoch 5  | loss: 284.94718| val_0_mse: 2748.450439453125|  0:00:03s\n","epoch 6  | loss: 214.81873| val_0_mse: 2583.443603515625|  0:00:03s\n","epoch 7  | loss: 187.01779| val_0_mse: 2451.965087890625|  0:00:04s\n","epoch 8  | loss: 183.28055| val_0_mse: 2712.22021484375|  0:00:04s\n","epoch 9  | loss: 137.94252| val_0_mse: 2453.014404296875|  0:00:05s\n","epoch 10 | loss: 139.99966| val_0_mse: 2568.12890625|  0:00:05s\n","epoch 11 | loss: 156.58485| val_0_mse: 2730.67529296875|  0:00:06s\n","\n","Early stopping occurred at epoch 11 with best_epoch = 1 and best_val_0_mse = 2297.68212890625\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 13:03:12,694] Trial 17 finished with value: 2297.68212890625 and parameters: {'n_d': 18, 'n_steps': 4, 'gamma': 1.0936486972989274, 'n_independent': 2, 'n_shared': 2, 'momentum': 0.053015912708889584}. Best is trial 12 with value: 17.820995330810547.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 2199.33023| val_0_mse: 4621.333984375|  0:00:01s\n","epoch 1  | loss: 1498.48714| val_0_mse: 15406.05859375|  0:00:02s\n","epoch 2  | loss: 1178.00949| val_0_mse: 25719.744140625|  0:00:03s\n","epoch 3  | loss: 1018.5262| val_0_mse: 4985.63623046875|  0:00:04s\n","epoch 4  | loss: 811.73746| val_0_mse: 5121.67236328125|  0:00:05s\n","epoch 5  | loss: 838.58324| val_0_mse: 6445.685546875|  0:00:06s\n","epoch 6  | loss: 850.81577| val_0_mse: 4838.033203125|  0:00:07s\n","epoch 7  | loss: 716.61421| val_0_mse: 4534.26513671875|  0:00:08s\n","epoch 8  | loss: 571.4647| val_0_mse: 4602.9775390625|  0:00:09s\n","epoch 9  | loss: 464.44228| val_0_mse: 3386.39892578125|  0:00:10s\n","epoch 10 | loss: 358.87637| val_0_mse: 2957.049560546875|  0:00:11s\n","epoch 11 | loss: 287.42538| val_0_mse: 2725.923095703125|  0:00:12s\n","epoch 12 | loss: 210.46105| val_0_mse: 2128.7109375|  0:00:13s\n","epoch 13 | loss: 182.76115| val_0_mse: 2173.30224609375|  0:00:14s\n","epoch 14 | loss: 176.06369| val_0_mse: 2240.222412109375|  0:00:15s\n","epoch 15 | loss: 145.22372| val_0_mse: 2360.79296875|  0:00:16s\n","epoch 16 | loss: 134.99499| val_0_mse: 2366.52490234375|  0:00:17s\n","epoch 17 | loss: 143.89246| val_0_mse: 2232.96630859375|  0:00:18s\n","epoch 18 | loss: 133.65449| val_0_mse: 2106.945556640625|  0:00:19s\n","epoch 19 | loss: 110.24666| val_0_mse: 2069.80078125|  0:00:20s\n","epoch 20 | loss: 106.40679| val_0_mse: 1632.1700439453125|  0:00:21s\n","epoch 21 | loss: 104.30834| val_0_mse: 1498.9166259765625|  0:00:22s\n","epoch 22 | loss: 116.06077| val_0_mse: 1303.7484130859375|  0:00:23s\n","epoch 23 | loss: 107.73354| val_0_mse: 1090.8453369140625|  0:00:24s\n","epoch 24 | loss: 112.89767| val_0_mse: 966.3671875|  0:00:25s\n","epoch 25 | loss: 102.5142| val_0_mse: 516.79150390625|  0:00:27s\n","epoch 26 | loss: 103.62911| val_0_mse: 384.15399169921875|  0:00:28s\n","epoch 27 | loss: 88.29637| val_0_mse: 436.6661682128906|  0:00:29s\n","epoch 28 | loss: 79.19651| val_0_mse: 363.1422424316406|  0:00:30s\n","epoch 29 | loss: 75.95524| val_0_mse: 330.6006164550781|  0:00:31s\n","epoch 30 | loss: 76.22293| val_0_mse: 272.1683044433594|  0:00:32s\n","epoch 31 | loss: 81.50536| val_0_mse: 341.473388671875|  0:00:33s\n","epoch 32 | loss: 76.52772| val_0_mse: 161.6432342529297|  0:00:34s\n","epoch 33 | loss: 94.26121| val_0_mse: 165.77296447753906|  0:00:35s\n","epoch 34 | loss: 96.3276 | val_0_mse: 183.53158569335938|  0:00:36s\n","epoch 35 | loss: 71.70615| val_0_mse: 188.31558227539062|  0:00:37s\n","epoch 36 | loss: 70.69641| val_0_mse: 147.91860961914062|  0:00:38s\n","epoch 37 | loss: 62.1035 | val_0_mse: 131.4735565185547|  0:00:39s\n","epoch 38 | loss: 76.06373| val_0_mse: 101.92835235595703|  0:00:40s\n","epoch 39 | loss: 79.66952| val_0_mse: 66.40361785888672|  0:00:41s\n","epoch 40 | loss: 69.59747| val_0_mse: 76.50006103515625|  0:00:42s\n","epoch 41 | loss: 61.52711| val_0_mse: 69.28388214111328|  0:00:43s\n","epoch 42 | loss: 67.20097| val_0_mse: 74.61541748046875|  0:00:44s\n","epoch 43 | loss: 59.42336| val_0_mse: 41.821720123291016|  0:00:45s\n","epoch 44 | loss: 59.33911| val_0_mse: 90.05793762207031|  0:00:46s\n","epoch 45 | loss: 59.90151| val_0_mse: 34.27439880371094|  0:00:47s\n","epoch 46 | loss: 56.90833| val_0_mse: 57.638389587402344|  0:00:48s\n","epoch 47 | loss: 57.1026 | val_0_mse: 37.22623062133789|  0:00:49s\n","epoch 48 | loss: 60.63812| val_0_mse: 81.03240203857422|  0:00:50s\n","epoch 49 | loss: 68.80853| val_0_mse: 68.05856323242188|  0:00:51s\n","epoch 50 | loss: 58.8286 | val_0_mse: 48.64284133911133|  0:00:53s\n","epoch 51 | loss: 66.02227| val_0_mse: 52.556678771972656|  0:00:54s\n","epoch 52 | loss: 64.66556| val_0_mse: 60.57925033569336|  0:00:55s\n","epoch 53 | loss: 65.4801 | val_0_mse: 44.99013900756836|  0:00:56s\n","epoch 54 | loss: 49.87162| val_0_mse: 41.6150016784668|  0:00:57s\n","epoch 55 | loss: 59.37236| val_0_mse: 39.801780700683594|  0:00:58s\n","\n","Early stopping occurred at epoch 55 with best_epoch = 45 and best_val_0_mse = 34.27439880371094\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 13:04:11,557] Trial 18 finished with value: 34.27439880371094 and parameters: {'n_d': 45, 'n_steps': 6, 'gamma': 1.9816215378363151, 'n_independent': 4, 'n_shared': 3, 'momentum': 0.24961375316676335}. Best is trial 12 with value: 17.820995330810547.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 2314.58038| val_0_mse: 4229.14990234375|  0:00:01s\n","epoch 1  | loss: 1887.81936| val_0_mse: 4011.94140625|  0:00:02s\n","epoch 2  | loss: 1525.63098| val_0_mse: 2716.179443359375|  0:00:03s\n","epoch 3  | loss: 1258.91254| val_0_mse: 4194.5625|  0:00:04s\n","epoch 4  | loss: 1185.31337| val_0_mse: 5869.5517578125|  0:00:05s\n","epoch 5  | loss: 1141.9597| val_0_mse: 5057.35595703125|  0:00:07s\n","epoch 6  | loss: 1116.20182| val_0_mse: 5619.615234375|  0:00:08s\n","epoch 7  | loss: 1021.99875| val_0_mse: 5265.4287109375|  0:00:09s\n","epoch 8  | loss: 808.31937| val_0_mse: 5516.96533203125|  0:00:10s\n","epoch 9  | loss: 624.75159| val_0_mse: 4269.08349609375|  0:00:11s\n","epoch 10 | loss: 439.92094| val_0_mse: 3025.972900390625|  0:00:12s\n","epoch 11 | loss: 366.02044| val_0_mse: 2957.455322265625|  0:00:13s\n","epoch 12 | loss: 268.71513| val_0_mse: 2634.25341796875|  0:00:15s\n","epoch 13 | loss: 233.99939| val_0_mse: 2269.920654296875|  0:00:16s\n","epoch 14 | loss: 231.27196| val_0_mse: 2123.688232421875|  0:00:17s\n","epoch 15 | loss: 182.17687| val_0_mse: 1837.5181884765625|  0:00:18s\n","epoch 16 | loss: 179.2535| val_0_mse: 1838.616943359375|  0:00:19s\n","epoch 17 | loss: 133.67299| val_0_mse: 1685.9666748046875|  0:00:20s\n","epoch 18 | loss: 142.50068| val_0_mse: 1250.601806640625|  0:00:22s\n","epoch 19 | loss: 120.67215| val_0_mse: 1161.592041015625|  0:00:23s\n","epoch 20 | loss: 102.03092| val_0_mse: 1024.8992919921875|  0:00:24s\n","epoch 21 | loss: 111.71522| val_0_mse: 849.4368286132812|  0:00:25s\n","epoch 22 | loss: 94.55199| val_0_mse: 829.5258178710938|  0:00:26s\n","epoch 23 | loss: 108.33841| val_0_mse: 674.6041870117188|  0:00:28s\n","epoch 24 | loss: 90.31647| val_0_mse: 516.5352172851562|  0:00:29s\n","epoch 25 | loss: 117.19982| val_0_mse: 598.5833740234375|  0:00:30s\n","epoch 26 | loss: 116.48494| val_0_mse: 310.5550842285156|  0:00:31s\n","epoch 27 | loss: 103.06419| val_0_mse: 361.0775146484375|  0:00:32s\n","epoch 28 | loss: 126.54841| val_0_mse: 261.6090393066406|  0:00:34s\n","epoch 29 | loss: 102.92618| val_0_mse: 378.73675537109375|  0:00:35s\n","epoch 30 | loss: 87.66546| val_0_mse: 233.591796875|  0:00:36s\n","epoch 31 | loss: 95.36678| val_0_mse: 238.97433471679688|  0:00:37s\n","epoch 32 | loss: 84.23142| val_0_mse: 186.23733520507812|  0:00:38s\n","epoch 33 | loss: 88.35716| val_0_mse: 135.30538940429688|  0:00:39s\n","epoch 34 | loss: 69.83503| val_0_mse: 110.00382232666016|  0:00:41s\n","epoch 35 | loss: 70.9425 | val_0_mse: 94.38986206054688|  0:00:42s\n","epoch 36 | loss: 77.50897| val_0_mse: 178.53207397460938|  0:00:43s\n","epoch 37 | loss: 76.56251| val_0_mse: 75.21864318847656|  0:00:44s\n","epoch 38 | loss: 75.20552| val_0_mse: 95.91020965576172|  0:00:45s\n","epoch 39 | loss: 75.43951| val_0_mse: 89.90650177001953|  0:00:46s\n","epoch 40 | loss: 77.49656| val_0_mse: 75.79535675048828|  0:00:48s\n","epoch 41 | loss: 88.03198| val_0_mse: 57.377418518066406|  0:00:49s\n","epoch 42 | loss: 69.31069| val_0_mse: 38.643218994140625|  0:00:50s\n","epoch 43 | loss: 78.4598 | val_0_mse: 43.36043930053711|  0:00:51s\n","epoch 44 | loss: 75.22896| val_0_mse: 105.1759262084961|  0:00:52s\n","epoch 45 | loss: 73.78772| val_0_mse: 46.997718811035156|  0:00:54s\n","epoch 46 | loss: 70.08157| val_0_mse: 68.24333953857422|  0:00:55s\n","epoch 47 | loss: 72.56201| val_0_mse: 55.5130615234375|  0:00:56s\n","epoch 48 | loss: 69.19906| val_0_mse: 53.878910064697266|  0:00:57s\n","epoch 49 | loss: 70.73272| val_0_mse: 53.46424865722656|  0:00:58s\n","epoch 50 | loss: 62.64848| val_0_mse: 36.27394104003906|  0:00:59s\n","epoch 51 | loss: 70.85002| val_0_mse: 27.372880935668945|  0:01:01s\n","epoch 52 | loss: 71.59649| val_0_mse: 31.58138084411621|  0:01:02s\n","epoch 53 | loss: 63.43071| val_0_mse: 32.13759994506836|  0:01:03s\n","epoch 54 | loss: 62.74305| val_0_mse: 38.12889099121094|  0:01:04s\n","epoch 55 | loss: 63.77872| val_0_mse: 36.535858154296875|  0:01:05s\n","epoch 56 | loss: 71.19052| val_0_mse: 58.342140197753906|  0:01:07s\n","epoch 57 | loss: 73.01507| val_0_mse: 53.36552047729492|  0:01:08s\n","epoch 58 | loss: 70.53978| val_0_mse: 29.056289672851562|  0:01:09s\n","epoch 59 | loss: 51.75432| val_0_mse: 35.47074890136719|  0:01:10s\n","epoch 60 | loss: 67.72557| val_0_mse: 34.369598388671875|  0:01:11s\n","epoch 61 | loss: 52.43217| val_0_mse: 28.7891902923584|  0:01:13s\n","\n","Early stopping occurred at epoch 61 with best_epoch = 51 and best_val_0_mse = 27.372880935668945\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 13:05:25,301] Trial 19 finished with value: 27.372875213623047 and parameters: {'n_d': 35, 'n_steps': 8, 'gamma': 1.6483272244201341, 'n_independent': 2, 'n_shared': 4, 'momentum': 0.1520154136803959}. Best is trial 12 with value: 17.820995330810547.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 2383.43085| val_0_mse: 2722.1572265625|  0:00:00s\n","epoch 1  | loss: 1645.80039| val_0_mse: 4064.658447265625|  0:00:01s\n","epoch 2  | loss: 611.76748| val_0_mse: 2885.8798828125|  0:00:02s\n","epoch 3  | loss: 382.06169| val_0_mse: 3724.8232421875|  0:00:02s\n","epoch 4  | loss: 291.90576| val_0_mse: 3366.2080078125|  0:00:03s\n","epoch 5  | loss: 231.92053| val_0_mse: 3180.580078125|  0:00:04s\n","epoch 6  | loss: 194.94338| val_0_mse: 2531.351318359375|  0:00:04s\n","epoch 7  | loss: 158.28865| val_0_mse: 2562.876220703125|  0:00:05s\n","epoch 8  | loss: 131.22609| val_0_mse: 2711.0244140625|  0:00:06s\n","epoch 9  | loss: 139.21609| val_0_mse: 2623.567138671875|  0:00:06s\n","epoch 10 | loss: 119.21894| val_0_mse: 2582.247314453125|  0:00:07s\n","epoch 11 | loss: 110.59439| val_0_mse: 2569.6630859375|  0:00:08s\n","epoch 12 | loss: 130.83575| val_0_mse: 2553.11328125|  0:00:08s\n","epoch 13 | loss: 125.87983| val_0_mse: 2600.097900390625|  0:00:09s\n","epoch 14 | loss: 117.22945| val_0_mse: 2518.625732421875|  0:00:10s\n","epoch 15 | loss: 96.74223| val_0_mse: 2503.350341796875|  0:00:10s\n","epoch 16 | loss: 95.01646| val_0_mse: 2565.607666015625|  0:00:11s\n","epoch 17 | loss: 95.39819| val_0_mse: 2465.2822265625|  0:00:12s\n","epoch 18 | loss: 81.66567| val_0_mse: 2465.31689453125|  0:00:13s\n","epoch 19 | loss: 95.87715| val_0_mse: 1970.21728515625|  0:00:13s\n","epoch 20 | loss: 88.09987| val_0_mse: 1572.2099609375|  0:00:14s\n","epoch 21 | loss: 76.27958| val_0_mse: 1269.1634521484375|  0:00:15s\n","epoch 22 | loss: 72.90929| val_0_mse: 1225.967529296875|  0:00:15s\n","epoch 23 | loss: 80.76244| val_0_mse: 990.5989379882812|  0:00:16s\n","epoch 24 | loss: 78.30861| val_0_mse: 657.2171630859375|  0:00:17s\n","epoch 25 | loss: 76.84259| val_0_mse: 665.1472778320312|  0:00:17s\n","epoch 26 | loss: 75.26258| val_0_mse: 688.7214965820312|  0:00:18s\n","epoch 27 | loss: 68.52837| val_0_mse: 448.2947082519531|  0:00:19s\n","epoch 28 | loss: 81.07285| val_0_mse: 322.9245910644531|  0:00:19s\n","epoch 29 | loss: 60.98302| val_0_mse: 374.1563720703125|  0:00:20s\n","epoch 30 | loss: 59.11697| val_0_mse: 303.4936218261719|  0:00:21s\n","epoch 31 | loss: 65.03198| val_0_mse: 299.893798828125|  0:00:21s\n","epoch 32 | loss: 67.96333| val_0_mse: 279.1469421386719|  0:00:22s\n","epoch 33 | loss: 76.45982| val_0_mse: 118.66251373291016|  0:00:23s\n","epoch 34 | loss: 72.34218| val_0_mse: 87.13741302490234|  0:00:24s\n","epoch 35 | loss: 61.20357| val_0_mse: 107.8724365234375|  0:00:24s\n","epoch 36 | loss: 56.80997| val_0_mse: 153.29635620117188|  0:00:25s\n","epoch 37 | loss: 75.91366| val_0_mse: 103.1902084350586|  0:00:26s\n","epoch 38 | loss: 88.1796 | val_0_mse: 71.5939712524414|  0:00:26s\n","epoch 39 | loss: 57.23672| val_0_mse: 67.67835998535156|  0:00:27s\n","epoch 40 | loss: 55.4439 | val_0_mse: 150.98248291015625|  0:00:28s\n","epoch 41 | loss: 63.01896| val_0_mse: 98.2203369140625|  0:00:28s\n","epoch 42 | loss: 65.50265| val_0_mse: 46.860801696777344|  0:00:29s\n","epoch 43 | loss: 82.18463| val_0_mse: 45.77177810668945|  0:00:30s\n","epoch 44 | loss: 86.30992| val_0_mse: 111.12761688232422|  0:00:31s\n","epoch 45 | loss: 69.97976| val_0_mse: 49.3878288269043|  0:00:31s\n","epoch 46 | loss: 64.57136| val_0_mse: 57.31378173828125|  0:00:32s\n","epoch 47 | loss: 56.39409| val_0_mse: 33.83039855957031|  0:00:33s\n","epoch 48 | loss: 51.84669| val_0_mse: 31.979280471801758|  0:00:33s\n","epoch 49 | loss: 54.46512| val_0_mse: 38.35483169555664|  0:00:34s\n","epoch 50 | loss: 55.1258 | val_0_mse: 34.71063995361328|  0:00:35s\n","epoch 51 | loss: 48.50043| val_0_mse: 31.494609832763672|  0:00:35s\n","epoch 52 | loss: 69.50714| val_0_mse: 50.09880065917969|  0:00:36s\n","epoch 53 | loss: 37.99307| val_0_mse: 26.546579360961914|  0:00:37s\n","epoch 54 | loss: 47.849  | val_0_mse: 32.32447052001953|  0:00:37s\n","epoch 55 | loss: 68.08463| val_0_mse: 24.85791015625|  0:00:38s\n","epoch 56 | loss: 65.64778| val_0_mse: 45.47808074951172|  0:00:39s\n","epoch 57 | loss: 57.63098| val_0_mse: 56.1578483581543|  0:00:39s\n","epoch 58 | loss: 49.70917| val_0_mse: 33.445838928222656|  0:00:40s\n","epoch 59 | loss: 58.65223| val_0_mse: 45.83649826049805|  0:00:41s\n","epoch 60 | loss: 56.05283| val_0_mse: 41.84727096557617|  0:00:41s\n","epoch 61 | loss: 58.63764| val_0_mse: 50.049259185791016|  0:00:42s\n","epoch 62 | loss: 54.49028| val_0_mse: 39.91012954711914|  0:00:43s\n","epoch 63 | loss: 58.11975| val_0_mse: 27.187179565429688|  0:00:44s\n","epoch 64 | loss: 44.21437| val_0_mse: 37.55495834350586|  0:00:44s\n","epoch 65 | loss: 55.8417 | val_0_mse: 55.06425094604492|  0:00:45s\n","\n","Early stopping occurred at epoch 65 with best_epoch = 55 and best_val_0_mse = 24.85791015625\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 13:06:11,164] Trial 20 finished with value: 24.857906341552734 and parameters: {'n_d': 21, 'n_steps': 4, 'gamma': 1.305279728559376, 'n_independent': 3, 'n_shared': 3, 'momentum': 0.23270089461888405}. Best is trial 12 with value: 17.820995330810547.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 2180.20383| val_0_mse: 5935.9326171875|  0:00:00s\n","epoch 1  | loss: 933.06763| val_0_mse: 1805.2703857421875|  0:00:01s\n","epoch 2  | loss: 368.19965| val_0_mse: 2456.923583984375|  0:00:01s\n","epoch 3  | loss: 245.94102| val_0_mse: 3375.916259765625|  0:00:02s\n","epoch 4  | loss: 193.14667| val_0_mse: 2833.970947265625|  0:00:02s\n","epoch 5  | loss: 195.13596| val_0_mse: 2250.040283203125|  0:00:03s\n","epoch 6  | loss: 151.10631| val_0_mse: 2613.681396484375|  0:00:03s\n","epoch 7  | loss: 133.5456| val_0_mse: 2533.94580078125|  0:00:04s\n","epoch 8  | loss: 124.31462| val_0_mse: 2599.99169921875|  0:00:04s\n","epoch 9  | loss: 94.34059| val_0_mse: 2823.395751953125|  0:00:05s\n","epoch 10 | loss: 94.41937| val_0_mse: 2645.370361328125|  0:00:06s\n","epoch 11 | loss: 86.6256 | val_0_mse: 2531.063720703125|  0:00:06s\n","\n","Early stopping occurred at epoch 11 with best_epoch = 1 and best_val_0_mse = 1805.2703857421875\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 13:06:18,276] Trial 21 finished with value: 1805.2703857421875 and parameters: {'n_d': 44, 'n_steps': 3, 'gamma': 1.441645337357475, 'n_independent': 2, 'n_shared': 4, 'momentum': 0.2193770797815741}. Best is trial 12 with value: 17.820995330810547.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 2039.9675| val_0_mse: 7020.98388671875|  0:00:00s\n","epoch 1  | loss: 713.31989| val_0_mse: 2255.371337890625|  0:00:01s\n","epoch 2  | loss: 437.11948| val_0_mse: 2662.152587890625|  0:00:01s\n","epoch 3  | loss: 271.5802| val_0_mse: 2691.747802734375|  0:00:02s\n","epoch 4  | loss: 232.01361| val_0_mse: 3118.0712890625|  0:00:02s\n","epoch 5  | loss: 184.38015| val_0_mse: 2726.490234375|  0:00:03s\n","epoch 6  | loss: 166.10942| val_0_mse: 2621.486572265625|  0:00:04s\n","epoch 7  | loss: 146.71378| val_0_mse: 2463.736572265625|  0:00:04s\n","epoch 8  | loss: 131.73131| val_0_mse: 2598.212890625|  0:00:05s\n","epoch 9  | loss: 108.8833| val_0_mse: 2734.58740234375|  0:00:05s\n","epoch 10 | loss: 116.05728| val_0_mse: 2651.5458984375|  0:00:06s\n","epoch 11 | loss: 104.60365| val_0_mse: 2790.677001953125|  0:00:06s\n","\n","Early stopping occurred at epoch 11 with best_epoch = 1 and best_val_0_mse = 2255.371337890625\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 13:06:25,403] Trial 22 finished with value: 2255.371337890625 and parameters: {'n_d': 49, 'n_steps': 3, 'gamma': 1.39543453498543, 'n_independent': 2, 'n_shared': 4, 'momentum': 0.2612152757414732}. Best is trial 12 with value: 17.820995330810547.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 2022.67479| val_0_mse: 2637.167236328125|  0:00:00s\n","epoch 1  | loss: 533.17127| val_0_mse: 2557.1552734375|  0:00:01s\n","epoch 2  | loss: 251.38098| val_0_mse: 2943.52001953125|  0:00:01s\n","epoch 3  | loss: 176.14334| val_0_mse: 2906.717529296875|  0:00:02s\n","epoch 4  | loss: 154.69464| val_0_mse: 3275.8740234375|  0:00:02s\n","epoch 5  | loss: 146.53539| val_0_mse: 2648.830078125|  0:00:03s\n","epoch 6  | loss: 160.70559| val_0_mse: 2811.440673828125|  0:00:03s\n","epoch 7  | loss: 113.90344| val_0_mse: 2802.568115234375|  0:00:04s\n","epoch 8  | loss: 136.05237| val_0_mse: 2684.12548828125|  0:00:05s\n","epoch 9  | loss: 105.59215| val_0_mse: 2629.919921875|  0:00:05s\n","epoch 10 | loss: 88.99372| val_0_mse: 2493.818603515625|  0:00:06s\n","epoch 11 | loss: 94.38357| val_0_mse: 2458.704833984375|  0:00:06s\n","epoch 12 | loss: 79.97331| val_0_mse: 2629.217041015625|  0:00:07s\n","epoch 13 | loss: 79.9692 | val_0_mse: 2524.0185546875|  0:00:07s\n","epoch 14 | loss: 70.25382| val_0_mse: 2573.15673828125|  0:00:08s\n","epoch 15 | loss: 76.58743| val_0_mse: 2534.876220703125|  0:00:09s\n","epoch 16 | loss: 67.86527| val_0_mse: 2516.302978515625|  0:00:09s\n","epoch 17 | loss: 64.70786| val_0_mse: 2109.84326171875|  0:00:10s\n","epoch 18 | loss: 69.4208 | val_0_mse: 2079.051025390625|  0:00:10s\n","epoch 19 | loss: 67.38112| val_0_mse: 1744.5858154296875|  0:00:11s\n","epoch 20 | loss: 72.33894| val_0_mse: 1308.26904296875|  0:00:11s\n","epoch 21 | loss: 67.74282| val_0_mse: 1293.1707763671875|  0:00:12s\n","epoch 22 | loss: 66.95614| val_0_mse: 874.510986328125|  0:00:12s\n","epoch 23 | loss: 83.7993 | val_0_mse: 875.47607421875|  0:00:13s\n","epoch 24 | loss: 89.38058| val_0_mse: 640.1686401367188|  0:00:14s\n","epoch 25 | loss: 79.07245| val_0_mse: 661.8673095703125|  0:00:14s\n","epoch 26 | loss: 52.99216| val_0_mse: 658.5738525390625|  0:00:15s\n","epoch 27 | loss: 53.01358| val_0_mse: 610.337158203125|  0:00:15s\n","epoch 28 | loss: 49.33406| val_0_mse: 461.3792419433594|  0:00:16s\n","epoch 29 | loss: 61.31781| val_0_mse: 306.7334289550781|  0:00:17s\n","epoch 30 | loss: 51.63083| val_0_mse: 317.7117919921875|  0:00:17s\n","epoch 31 | loss: 54.46575| val_0_mse: 223.77743530273438|  0:00:18s\n","epoch 32 | loss: 51.66774| val_0_mse: 225.70425415039062|  0:00:18s\n","epoch 33 | loss: 53.11103| val_0_mse: 209.37939453125|  0:00:19s\n","epoch 34 | loss: 53.12114| val_0_mse: 138.24424743652344|  0:00:19s\n","epoch 35 | loss: 55.05348| val_0_mse: 105.2865219116211|  0:00:20s\n","epoch 36 | loss: 49.41817| val_0_mse: 90.62088775634766|  0:00:21s\n","epoch 37 | loss: 59.92793| val_0_mse: 144.56385803222656|  0:00:21s\n","epoch 38 | loss: 57.12146| val_0_mse: 66.288330078125|  0:00:22s\n","epoch 39 | loss: 53.20258| val_0_mse: 60.89036178588867|  0:00:22s\n","epoch 40 | loss: 59.4145 | val_0_mse: 47.67226028442383|  0:00:23s\n","epoch 41 | loss: 66.64424| val_0_mse: 93.55306243896484|  0:00:23s\n","epoch 42 | loss: 50.38586| val_0_mse: 71.91036224365234|  0:00:24s\n","epoch 43 | loss: 44.98847| val_0_mse: 65.94731140136719|  0:00:25s\n","epoch 44 | loss: 43.26292| val_0_mse: 27.55647087097168|  0:00:25s\n","epoch 45 | loss: 36.78835| val_0_mse: 40.59904098510742|  0:00:26s\n","epoch 46 | loss: 41.93106| val_0_mse: 26.445430755615234|  0:00:26s\n","epoch 47 | loss: 57.46759| val_0_mse: 28.088180541992188|  0:00:27s\n","epoch 48 | loss: 48.78165| val_0_mse: 49.15380096435547|  0:00:27s\n","epoch 49 | loss: 55.9401 | val_0_mse: 47.466880798339844|  0:00:28s\n","epoch 50 | loss: 39.87542| val_0_mse: 31.60017967224121|  0:00:29s\n","epoch 51 | loss: 44.55812| val_0_mse: 33.01251983642578|  0:00:29s\n","epoch 52 | loss: 43.49168| val_0_mse: 25.016050338745117|  0:00:30s\n","epoch 53 | loss: 47.34196| val_0_mse: 28.811809539794922|  0:00:30s\n","epoch 54 | loss: 40.05681| val_0_mse: 27.85388946533203|  0:00:31s\n","epoch 55 | loss: 40.18041| val_0_mse: 43.71841812133789|  0:00:31s\n","epoch 56 | loss: 37.31567| val_0_mse: 33.324459075927734|  0:00:32s\n","epoch 57 | loss: 46.98893| val_0_mse: 39.892059326171875|  0:00:33s\n","epoch 58 | loss: 60.18492| val_0_mse: 57.93505859375|  0:00:33s\n","epoch 59 | loss: 44.13443| val_0_mse: 21.23944091796875|  0:00:34s\n","epoch 60 | loss: 34.53767| val_0_mse: 27.437530517578125|  0:00:34s\n","epoch 61 | loss: 49.80524| val_0_mse: 61.21438980102539|  0:00:35s\n","epoch 62 | loss: 64.53328| val_0_mse: 42.455379486083984|  0:00:35s\n","epoch 63 | loss: 62.6333 | val_0_mse: 75.21859741210938|  0:00:36s\n","epoch 64 | loss: 65.19946| val_0_mse: 34.150360107421875|  0:00:36s\n","epoch 65 | loss: 54.2215 | val_0_mse: 28.734180450439453|  0:00:37s\n","epoch 66 | loss: 47.74696| val_0_mse: 27.882400512695312|  0:00:38s\n","epoch 67 | loss: 38.46485| val_0_mse: 27.29254913330078|  0:00:38s\n","epoch 68 | loss: 40.439  | val_0_mse: 28.642980575561523|  0:00:39s\n","epoch 69 | loss: 34.05707| val_0_mse: 40.25642013549805|  0:00:39s\n","\n","Early stopping occurred at epoch 69 with best_epoch = 59 and best_val_0_mse = 21.23944091796875\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 13:07:05,478] Trial 23 finished with value: 21.239444732666016 and parameters: {'n_d': 58, 'n_steps': 3, 'gamma': 1.166845006341993, 'n_independent': 3, 'n_shared': 3, 'momentum': 0.1797659954601624}. Best is trial 12 with value: 17.820995330810547.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 2344.79768| val_0_mse: 3001.68994140625|  0:00:00s\n","epoch 1  | loss: 1603.28312| val_0_mse: 3833.907958984375|  0:00:01s\n","epoch 2  | loss: 673.55626| val_0_mse: 8502.7080078125|  0:00:02s\n","epoch 3  | loss: 397.14631| val_0_mse: 3382.4306640625|  0:00:02s\n","epoch 4  | loss: 348.36275| val_0_mse: 3604.56005859375|  0:00:03s\n","epoch 5  | loss: 232.01736| val_0_mse: 2618.390625|  0:00:04s\n","epoch 6  | loss: 213.59384| val_0_mse: 2575.4892578125|  0:00:04s\n","epoch 7  | loss: 202.70987| val_0_mse: 2990.96533203125|  0:00:05s\n","epoch 8  | loss: 163.96746| val_0_mse: 2666.250244140625|  0:00:06s\n","epoch 9  | loss: 142.34235| val_0_mse: 2748.419921875|  0:00:06s\n","epoch 10 | loss: 124.63523| val_0_mse: 2560.40625|  0:00:07s\n","epoch 11 | loss: 122.33799| val_0_mse: 2572.76416015625|  0:00:08s\n","epoch 12 | loss: 118.49996| val_0_mse: 2502.28271484375|  0:00:08s\n","epoch 13 | loss: 94.96784| val_0_mse: 2605.465576171875|  0:00:09s\n","epoch 14 | loss: 89.84702| val_0_mse: 2524.385498046875|  0:00:10s\n","epoch 15 | loss: 78.09107| val_0_mse: 2438.329345703125|  0:00:11s\n","epoch 16 | loss: 90.68659| val_0_mse: 2459.40673828125|  0:00:11s\n","epoch 17 | loss: 79.28228| val_0_mse: 2180.9990234375|  0:00:12s\n","epoch 18 | loss: 83.09807| val_0_mse: 1570.420654296875|  0:00:13s\n","epoch 19 | loss: 59.94344| val_0_mse: 1580.823974609375|  0:00:13s\n","epoch 20 | loss: 55.98899| val_0_mse: 1387.7779541015625|  0:00:14s\n","epoch 21 | loss: 92.34204| val_0_mse: 1232.80859375|  0:00:15s\n","epoch 22 | loss: 86.62833| val_0_mse: 856.9625854492188|  0:00:15s\n","epoch 23 | loss: 85.12172| val_0_mse: 597.2423095703125|  0:00:16s\n","epoch 24 | loss: 86.09168| val_0_mse: 688.8334350585938|  0:00:17s\n","epoch 25 | loss: 75.37096| val_0_mse: 536.8737182617188|  0:00:17s\n","epoch 26 | loss: 71.01903| val_0_mse: 533.9755249023438|  0:00:18s\n","epoch 27 | loss: 90.41696| val_0_mse: 302.95599365234375|  0:00:19s\n","epoch 28 | loss: 73.88449| val_0_mse: 292.9015808105469|  0:00:19s\n","epoch 29 | loss: 70.58683| val_0_mse: 208.7149658203125|  0:00:20s\n","epoch 30 | loss: 87.18446| val_0_mse: 266.838134765625|  0:00:21s\n","epoch 31 | loss: 59.73956| val_0_mse: 143.30764770507812|  0:00:21s\n","epoch 32 | loss: 77.82953| val_0_mse: 177.99229431152344|  0:00:22s\n","epoch 33 | loss: 75.29031| val_0_mse: 139.62518310546875|  0:00:23s\n","epoch 34 | loss: 58.22804| val_0_mse: 170.6242218017578|  0:00:24s\n","epoch 35 | loss: 56.06108| val_0_mse: 125.7515869140625|  0:00:24s\n","epoch 36 | loss: 70.43681| val_0_mse: 66.26531219482422|  0:00:25s\n","epoch 37 | loss: 74.10246| val_0_mse: 92.54524993896484|  0:00:26s\n","epoch 38 | loss: 53.13196| val_0_mse: 83.79592895507812|  0:00:26s\n","epoch 39 | loss: 75.14231| val_0_mse: 64.45755767822266|  0:00:27s\n","epoch 40 | loss: 46.8052 | val_0_mse: 61.776458740234375|  0:00:28s\n","epoch 41 | loss: 54.68404| val_0_mse: 48.48603820800781|  0:00:29s\n","epoch 42 | loss: 53.01759| val_0_mse: 69.49115753173828|  0:00:29s\n","epoch 43 | loss: 68.9369 | val_0_mse: 40.42913818359375|  0:00:30s\n","epoch 44 | loss: 48.32521| val_0_mse: 52.76803970336914|  0:00:31s\n","epoch 45 | loss: 66.08945| val_0_mse: 37.242340087890625|  0:00:31s\n","epoch 46 | loss: 64.86986| val_0_mse: 35.57456970214844|  0:00:32s\n","epoch 47 | loss: 48.52731| val_0_mse: 44.066688537597656|  0:00:33s\n","epoch 48 | loss: 52.01397| val_0_mse: 56.88005828857422|  0:00:33s\n","epoch 49 | loss: 45.47374| val_0_mse: 30.108430862426758|  0:00:34s\n","epoch 50 | loss: 59.23988| val_0_mse: 70.22274780273438|  0:00:35s\n","epoch 51 | loss: 44.24459| val_0_mse: 45.60308074951172|  0:00:35s\n","epoch 52 | loss: 64.96672| val_0_mse: 61.220829010009766|  0:00:36s\n","epoch 53 | loss: 50.8481 | val_0_mse: 38.47050857543945|  0:00:37s\n","epoch 54 | loss: 58.68268| val_0_mse: 33.37725067138672|  0:00:37s\n","epoch 55 | loss: 45.77064| val_0_mse: 32.37102127075195|  0:00:38s\n","epoch 56 | loss: 56.02811| val_0_mse: 37.87820816040039|  0:00:39s\n","epoch 57 | loss: 54.3683 | val_0_mse: 49.323951721191406|  0:00:39s\n","epoch 58 | loss: 49.12417| val_0_mse: 27.49496078491211|  0:00:40s\n","epoch 59 | loss: 47.92463| val_0_mse: 69.96082305908203|  0:00:41s\n","epoch 60 | loss: 68.89518| val_0_mse: 47.762760162353516|  0:00:42s\n","epoch 61 | loss: 49.94345| val_0_mse: 34.070438385009766|  0:00:42s\n","epoch 62 | loss: 61.52198| val_0_mse: 49.80302810668945|  0:00:43s\n","epoch 63 | loss: 49.96147| val_0_mse: 58.34368133544922|  0:00:43s\n","epoch 64 | loss: 44.52372| val_0_mse: 23.01304054260254|  0:00:44s\n","epoch 65 | loss: 43.81325| val_0_mse: 28.280479431152344|  0:00:45s\n","epoch 66 | loss: 54.70793| val_0_mse: 36.254539489746094|  0:00:46s\n","epoch 67 | loss: 53.51593| val_0_mse: 74.68419647216797|  0:00:46s\n","epoch 68 | loss: 81.11423| val_0_mse: 39.95838928222656|  0:00:47s\n","epoch 69 | loss: 52.02438| val_0_mse: 32.2287712097168|  0:00:48s\n","epoch 70 | loss: 40.14083| val_0_mse: 25.638349533081055|  0:00:48s\n","epoch 71 | loss: 37.07091| val_0_mse: 20.829919815063477|  0:00:49s\n","epoch 72 | loss: 48.77898| val_0_mse: 32.212398529052734|  0:00:50s\n","epoch 73 | loss: 43.32216| val_0_mse: 22.223220825195312|  0:00:50s\n","epoch 74 | loss: 34.4537 | val_0_mse: 23.36370086669922|  0:00:51s\n","epoch 75 | loss: 28.68006| val_0_mse: 24.275150299072266|  0:00:52s\n","epoch 76 | loss: 61.65147| val_0_mse: 37.4901008605957|  0:00:52s\n","epoch 77 | loss: 46.97008| val_0_mse: 22.609710693359375|  0:00:53s\n","epoch 78 | loss: 46.71564| val_0_mse: 33.11869812011719|  0:00:54s\n","epoch 79 | loss: 40.05961| val_0_mse: 26.575000762939453|  0:00:54s\n","epoch 80 | loss: 41.88679| val_0_mse: 19.280330657958984|  0:00:55s\n","epoch 81 | loss: 45.70351| val_0_mse: 22.6718807220459|  0:00:56s\n","epoch 82 | loss: 33.84933| val_0_mse: 20.342300415039062|  0:00:57s\n","epoch 83 | loss: 44.22359| val_0_mse: 17.431190490722656|  0:00:57s\n","epoch 84 | loss: 43.0684 | val_0_mse: 22.66390037536621|  0:00:58s\n","epoch 85 | loss: 34.54557| val_0_mse: 23.624469757080078|  0:00:59s\n","epoch 86 | loss: 44.5397 | val_0_mse: 26.237640380859375|  0:00:59s\n","epoch 87 | loss: 52.3418 | val_0_mse: 20.576749801635742|  0:01:00s\n","epoch 88 | loss: 45.27097| val_0_mse: 18.01156997680664|  0:01:01s\n","epoch 89 | loss: 33.33248| val_0_mse: 22.56538963317871|  0:01:01s\n","epoch 90 | loss: 39.2694 | val_0_mse: 29.9548397064209|  0:01:02s\n","epoch 91 | loss: 38.99474| val_0_mse: 24.868379592895508|  0:01:03s\n","epoch 92 | loss: 35.57469| val_0_mse: 20.051830291748047|  0:01:03s\n","epoch 93 | loss: 37.43961| val_0_mse: 20.94832992553711|  0:01:04s\n","\n","Early stopping occurred at epoch 93 with best_epoch = 83 and best_val_0_mse = 17.431190490722656\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 13:08:10,518] Trial 24 finished with value: 17.43118667602539 and parameters: {'n_d': 40, 'n_steps': 4, 'gamma': 1.449494132839827, 'n_independent': 1, 'n_shared': 5, 'momentum': 0.07299507011455417}. Best is trial 24 with value: 17.43118667602539.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 2275.36323| val_0_mse: 3139.810302734375|  0:00:00s\n","epoch 1  | loss: 1658.8568| val_0_mse: 4352.30810546875|  0:00:01s\n","epoch 2  | loss: 1090.34494| val_0_mse: 3070.360595703125|  0:00:02s\n","epoch 3  | loss: 723.51113| val_0_mse: 4264.87451171875|  0:00:03s\n","epoch 4  | loss: 494.16104| val_0_mse: 3219.825927734375|  0:00:04s\n","epoch 5  | loss: 383.90333| val_0_mse: 3266.00390625|  0:00:04s\n","epoch 6  | loss: 327.16045| val_0_mse: 2503.891357421875|  0:00:05s\n","epoch 7  | loss: 268.12795| val_0_mse: 2492.495361328125|  0:00:06s\n","epoch 8  | loss: 275.05206| val_0_mse: 2323.72705078125|  0:00:07s\n","epoch 9  | loss: 329.62132| val_0_mse: 2558.6298828125|  0:00:08s\n","epoch 10 | loss: 257.07509| val_0_mse: 3244.42333984375|  0:00:08s\n","epoch 11 | loss: 206.98137| val_0_mse: 3368.6982421875|  0:00:09s\n","epoch 12 | loss: 197.32001| val_0_mse: 2693.6767578125|  0:00:10s\n","epoch 13 | loss: 178.82962| val_0_mse: 2594.0693359375|  0:00:11s\n","epoch 14 | loss: 180.6635| val_0_mse: 2357.29541015625|  0:00:11s\n","epoch 15 | loss: 236.59624| val_0_mse: 2339.4208984375|  0:00:12s\n","epoch 16 | loss: 178.14182| val_0_mse: 2101.322021484375|  0:00:13s\n","epoch 17 | loss: 151.70396| val_0_mse: 2122.530029296875|  0:00:14s\n","epoch 18 | loss: 142.08422| val_0_mse: 1900.9840087890625|  0:00:15s\n","epoch 19 | loss: 162.4097| val_0_mse: 2095.700927734375|  0:00:16s\n","epoch 20 | loss: 148.1871| val_0_mse: 1379.962890625|  0:00:16s\n","epoch 21 | loss: 131.93701| val_0_mse: 1236.4573974609375|  0:00:17s\n","epoch 22 | loss: 143.20918| val_0_mse: 1160.167724609375|  0:00:18s\n","epoch 23 | loss: 120.05022| val_0_mse: 877.5294189453125|  0:00:19s\n","epoch 24 | loss: 137.35154| val_0_mse: 502.17803955078125|  0:00:20s\n","epoch 25 | loss: 145.83915| val_0_mse: 585.9370727539062|  0:00:20s\n","epoch 26 | loss: 135.72111| val_0_mse: 603.697509765625|  0:00:21s\n","epoch 27 | loss: 116.64009| val_0_mse: 563.0947265625|  0:00:22s\n","epoch 28 | loss: 106.31282| val_0_mse: 374.6347351074219|  0:00:23s\n","epoch 29 | loss: 96.75434| val_0_mse: 274.6966552734375|  0:00:24s\n","epoch 30 | loss: 111.8454| val_0_mse: 296.69647216796875|  0:00:24s\n","epoch 31 | loss: 91.46013| val_0_mse: 215.0697784423828|  0:00:25s\n","epoch 32 | loss: 100.44783| val_0_mse: 220.64837646484375|  0:00:26s\n","epoch 33 | loss: 95.15537| val_0_mse: 164.40927124023438|  0:00:27s\n","epoch 34 | loss: 84.63879| val_0_mse: 143.65798950195312|  0:00:28s\n","epoch 35 | loss: 76.54634| val_0_mse: 104.49858093261719|  0:00:29s\n","epoch 36 | loss: 70.54512| val_0_mse: 99.31635284423828|  0:00:29s\n","epoch 37 | loss: 84.61462| val_0_mse: 109.76286315917969|  0:00:30s\n","epoch 38 | loss: 98.2148 | val_0_mse: 105.82308197021484|  0:00:31s\n","epoch 39 | loss: 100.89668| val_0_mse: 88.62200164794922|  0:00:32s\n","epoch 40 | loss: 78.57883| val_0_mse: 75.8375015258789|  0:00:33s\n","epoch 41 | loss: 91.10146| val_0_mse: 105.29756164550781|  0:00:33s\n","epoch 42 | loss: 82.9794 | val_0_mse: 72.72308349609375|  0:00:34s\n","epoch 43 | loss: 79.52786| val_0_mse: 77.80342102050781|  0:00:35s\n","epoch 44 | loss: 84.33036| val_0_mse: 92.87663269042969|  0:00:36s\n","epoch 45 | loss: 86.20035| val_0_mse: 106.97952270507812|  0:00:37s\n","epoch 46 | loss: 97.97882| val_0_mse: 81.08795928955078|  0:00:37s\n","epoch 47 | loss: 110.73048| val_0_mse: 58.925899505615234|  0:00:38s\n","epoch 48 | loss: 83.56352| val_0_mse: 60.143959045410156|  0:00:39s\n","epoch 49 | loss: 80.33311| val_0_mse: 97.63543701171875|  0:00:40s\n","epoch 50 | loss: 116.92496| val_0_mse: 66.59513092041016|  0:00:41s\n","epoch 51 | loss: 79.61593| val_0_mse: 51.270240783691406|  0:00:41s\n","epoch 52 | loss: 67.16267| val_0_mse: 44.91897964477539|  0:00:42s\n","epoch 53 | loss: 71.74665| val_0_mse: 50.898040771484375|  0:00:43s\n","epoch 54 | loss: 75.34093| val_0_mse: 52.38639831542969|  0:00:44s\n","epoch 55 | loss: 75.29992| val_0_mse: 44.85886001586914|  0:00:45s\n","epoch 56 | loss: 70.82942| val_0_mse: 38.2859992980957|  0:00:45s\n","epoch 57 | loss: 76.362  | val_0_mse: 53.83259963989258|  0:00:46s\n","epoch 58 | loss: 71.11363| val_0_mse: 36.389488220214844|  0:00:47s\n","epoch 59 | loss: 59.29415| val_0_mse: 49.96889114379883|  0:00:48s\n","epoch 60 | loss: 72.77112| val_0_mse: 42.31364059448242|  0:00:49s\n","epoch 61 | loss: 65.94984| val_0_mse: 38.61528015136719|  0:00:49s\n","epoch 62 | loss: 78.98353| val_0_mse: 31.676149368286133|  0:00:50s\n","epoch 63 | loss: 68.75853| val_0_mse: 36.409278869628906|  0:00:51s\n","epoch 64 | loss: 60.26713| val_0_mse: 38.60163879394531|  0:00:52s\n","epoch 65 | loss: 70.07291| val_0_mse: 39.277198791503906|  0:00:53s\n","epoch 66 | loss: 63.318  | val_0_mse: 33.589839935302734|  0:00:53s\n","epoch 67 | loss: 68.28424| val_0_mse: 41.637779235839844|  0:00:54s\n","epoch 68 | loss: 62.50665| val_0_mse: 31.633150100708008|  0:00:55s\n","epoch 69 | loss: 49.09756| val_0_mse: 33.78628158569336|  0:00:56s\n","epoch 70 | loss: 64.19961| val_0_mse: 32.99684143066406|  0:00:57s\n","epoch 71 | loss: 53.89383| val_0_mse: 32.431678771972656|  0:00:57s\n","epoch 72 | loss: 59.36983| val_0_mse: 35.6539192199707|  0:00:58s\n","epoch 73 | loss: 66.10306| val_0_mse: 44.90802001953125|  0:00:59s\n","epoch 74 | loss: 79.8905 | val_0_mse: 66.98081970214844|  0:01:00s\n","epoch 75 | loss: 69.8556 | val_0_mse: 40.42869186401367|  0:01:01s\n","epoch 76 | loss: 63.49595| val_0_mse: 49.04261016845703|  0:01:01s\n","epoch 77 | loss: 70.23337| val_0_mse: 44.67961120605469|  0:01:02s\n","epoch 78 | loss: 60.88016| val_0_mse: 33.84865951538086|  0:01:03s\n","\n","Early stopping occurred at epoch 78 with best_epoch = 68 and best_val_0_mse = 31.633150100708008\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 13:09:14,594] Trial 25 finished with value: 31.633146286010742 and parameters: {'n_d': 41, 'n_steps': 5, 'gamma': 1.2974965339888411, 'n_independent': 1, 'n_shared': 5, 'momentum': 0.059929060188110506}. Best is trial 24 with value: 17.43118667602539.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 2358.78399| val_0_mse: 2103.8310546875|  0:00:00s\n","epoch 1  | loss: 1806.52159| val_0_mse: 2985.21533203125|  0:00:00s\n","epoch 2  | loss: 1104.96237| val_0_mse: 3171.798828125|  0:00:01s\n","epoch 3  | loss: 588.90588| val_0_mse: 5526.384765625|  0:00:01s\n","epoch 4  | loss: 382.10335| val_0_mse: 4508.9453125|  0:00:02s\n","epoch 5  | loss: 261.62223| val_0_mse: 3735.783935546875|  0:00:02s\n","epoch 6  | loss: 192.36703| val_0_mse: 2999.5400390625|  0:00:03s\n","epoch 7  | loss: 162.62748| val_0_mse: 2737.205078125|  0:00:03s\n","epoch 8  | loss: 144.67961| val_0_mse: 2519.9072265625|  0:00:03s\n","epoch 9  | loss: 133.71138| val_0_mse: 2626.30908203125|  0:00:04s\n","epoch 10 | loss: 101.92121| val_0_mse: 2696.8876953125|  0:00:04s\n","\n","Early stopping occurred at epoch 10 with best_epoch = 0 and best_val_0_mse = 2103.8310546875\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 13:09:19,736] Trial 26 finished with value: 2103.8310546875 and parameters: {'n_d': 34, 'n_steps': 4, 'gamma': 1.5841490704748855, 'n_independent': 1, 'n_shared': 2, 'momentum': 0.023236392126828355}. Best is trial 24 with value: 17.43118667602539.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 2194.36857| val_0_mse: 4760.1181640625|  0:00:01s\n","epoch 1  | loss: 1662.36689| val_0_mse: 7413.2607421875|  0:00:02s\n","epoch 2  | loss: 1287.80097| val_0_mse: 23018.3046875|  0:00:03s\n","epoch 3  | loss: 1106.1875| val_0_mse: 9793.8837890625|  0:00:05s\n","epoch 4  | loss: 984.88797| val_0_mse: 7392.07958984375|  0:00:06s\n","epoch 5  | loss: 858.82152| val_0_mse: 5852.9619140625|  0:00:07s\n","epoch 6  | loss: 782.09594| val_0_mse: 5084.2001953125|  0:00:08s\n","epoch 7  | loss: 636.48379| val_0_mse: 4844.6728515625|  0:00:10s\n","epoch 8  | loss: 671.6026| val_0_mse: 4550.20068359375|  0:00:11s\n","epoch 9  | loss: 697.84114| val_0_mse: 3684.0068359375|  0:00:12s\n","epoch 10 | loss: 688.47346| val_0_mse: 3481.55078125|  0:00:14s\n","epoch 11 | loss: 666.07176| val_0_mse: 3780.426025390625|  0:00:15s\n","epoch 12 | loss: 761.12854| val_0_mse: 2683.776611328125|  0:00:16s\n","epoch 13 | loss: 669.58356| val_0_mse: 2131.244384765625|  0:00:18s\n","epoch 14 | loss: 649.8258| val_0_mse: 1865.3819580078125|  0:00:19s\n","epoch 15 | loss: 614.44423| val_0_mse: 1775.1488037109375|  0:00:20s\n","epoch 16 | loss: 583.97538| val_0_mse: 1967.2916259765625|  0:00:22s\n","epoch 17 | loss: 551.49934| val_0_mse: 1372.2684326171875|  0:00:23s\n","epoch 18 | loss: 489.47088| val_0_mse: 1086.928955078125|  0:00:24s\n","epoch 19 | loss: 449.33353| val_0_mse: 1043.8905029296875|  0:00:25s\n","epoch 20 | loss: 483.96208| val_0_mse: 1042.6353759765625|  0:00:27s\n","epoch 21 | loss: 535.39423| val_0_mse: 782.8475952148438|  0:00:28s\n","epoch 22 | loss: 749.10307| val_0_mse: 2020.28369140625|  0:00:30s\n","epoch 23 | loss: 885.76423| val_0_mse: 697.7428588867188|  0:00:31s\n","epoch 24 | loss: 581.24973| val_0_mse: 1187.575439453125|  0:00:32s\n","epoch 25 | loss: 558.57134| val_0_mse: 795.45849609375|  0:00:33s\n","epoch 26 | loss: 875.94524| val_0_mse: 606.592041015625|  0:00:35s\n","epoch 27 | loss: 579.79089| val_0_mse: 762.76123046875|  0:00:36s\n","epoch 28 | loss: 601.30035| val_0_mse: 607.0255126953125|  0:00:37s\n","epoch 29 | loss: 512.49888| val_0_mse: 515.9449462890625|  0:00:39s\n","epoch 30 | loss: 453.45905| val_0_mse: 498.739013671875|  0:00:40s\n","epoch 31 | loss: 459.60571| val_0_mse: 499.2145080566406|  0:00:41s\n","epoch 32 | loss: 415.90595| val_0_mse: 399.8153076171875|  0:00:43s\n","epoch 33 | loss: 354.57734| val_0_mse: 391.9233093261719|  0:00:44s\n","epoch 34 | loss: 328.94866| val_0_mse: 448.8057556152344|  0:00:45s\n","epoch 35 | loss: 275.07533| val_0_mse: 323.7206726074219|  0:00:47s\n","epoch 36 | loss: 252.12206| val_0_mse: 218.79891967773438|  0:00:48s\n","epoch 37 | loss: 230.24838| val_0_mse: 202.3438262939453|  0:00:49s\n","epoch 38 | loss: 194.14535| val_0_mse: 176.51620483398438|  0:00:51s\n","epoch 39 | loss: 180.97478| val_0_mse: 178.60629272460938|  0:00:52s\n","epoch 40 | loss: 171.56652| val_0_mse: 145.2743377685547|  0:00:53s\n","epoch 41 | loss: 139.14028| val_0_mse: 131.98831176757812|  0:00:55s\n","epoch 42 | loss: 156.78964| val_0_mse: 138.994873046875|  0:00:56s\n","epoch 43 | loss: 129.7679| val_0_mse: 98.65106201171875|  0:00:57s\n","epoch 44 | loss: 125.23215| val_0_mse: 87.59042358398438|  0:00:59s\n","epoch 45 | loss: 116.19899| val_0_mse: 118.25385284423828|  0:01:00s\n","epoch 46 | loss: 117.0244| val_0_mse: 100.73185729980469|  0:01:01s\n","epoch 47 | loss: 117.29206| val_0_mse: 72.46266174316406|  0:01:03s\n","epoch 48 | loss: 135.54905| val_0_mse: 116.73932647705078|  0:01:04s\n","epoch 49 | loss: 128.66993| val_0_mse: 66.6693115234375|  0:01:05s\n","epoch 50 | loss: 93.05834| val_0_mse: 59.273250579833984|  0:01:07s\n","epoch 51 | loss: 97.31307| val_0_mse: 103.98607635498047|  0:01:08s\n","epoch 52 | loss: 97.79361| val_0_mse: 69.12898254394531|  0:01:09s\n","epoch 53 | loss: 98.98182| val_0_mse: 73.77613067626953|  0:01:10s\n","epoch 54 | loss: 87.82147| val_0_mse: 52.49412155151367|  0:01:12s\n","epoch 55 | loss: 96.91377| val_0_mse: 73.93192291259766|  0:01:13s\n","epoch 56 | loss: 84.53743| val_0_mse: 53.29253005981445|  0:01:14s\n","epoch 57 | loss: 79.55819| val_0_mse: 77.82330322265625|  0:01:16s\n","epoch 58 | loss: 83.0271 | val_0_mse: 47.25157165527344|  0:01:17s\n","epoch 59 | loss: 71.31041| val_0_mse: 51.00334930419922|  0:01:18s\n","epoch 60 | loss: 70.99465| val_0_mse: 44.31821823120117|  0:01:19s\n","epoch 61 | loss: 66.15254| val_0_mse: 42.706581115722656|  0:01:21s\n","epoch 62 | loss: 61.64652| val_0_mse: 46.024539947509766|  0:01:22s\n","epoch 63 | loss: 66.39519| val_0_mse: 40.82514190673828|  0:01:23s\n","epoch 64 | loss: 65.36521| val_0_mse: 48.25400161743164|  0:01:25s\n","epoch 65 | loss: 71.65319| val_0_mse: 40.45180130004883|  0:01:26s\n","epoch 66 | loss: 71.13242| val_0_mse: 56.791358947753906|  0:01:27s\n","epoch 67 | loss: 65.11393| val_0_mse: 46.60205841064453|  0:01:29s\n","epoch 68 | loss: 61.33066| val_0_mse: 36.77286148071289|  0:01:30s\n","epoch 69 | loss: 92.8738 | val_0_mse: 38.66682815551758|  0:01:31s\n","epoch 70 | loss: 57.69891| val_0_mse: 35.43709945678711|  0:01:32s\n","epoch 71 | loss: 56.72642| val_0_mse: 33.74314880371094|  0:01:34s\n","epoch 72 | loss: 52.78702| val_0_mse: 47.85176086425781|  0:01:35s\n","epoch 73 | loss: 67.79669| val_0_mse: 57.01482009887695|  0:01:37s\n","epoch 74 | loss: 68.55827| val_0_mse: 38.634010314941406|  0:01:38s\n","epoch 75 | loss: 66.32414| val_0_mse: 34.62458038330078|  0:01:39s\n","epoch 76 | loss: 56.56353| val_0_mse: 28.36764907836914|  0:01:40s\n","epoch 77 | loss: 58.05025| val_0_mse: 27.5362606048584|  0:01:42s\n","epoch 78 | loss: 48.14626| val_0_mse: 30.543319702148438|  0:01:43s\n","epoch 79 | loss: 49.58048| val_0_mse: 35.001991271972656|  0:01:44s\n","epoch 80 | loss: 53.57293| val_0_mse: 29.67375946044922|  0:01:46s\n","epoch 81 | loss: 55.26898| val_0_mse: 43.736000061035156|  0:01:47s\n","epoch 82 | loss: 64.9047 | val_0_mse: 39.5161018371582|  0:01:48s\n","epoch 83 | loss: 56.03201| val_0_mse: 37.89387893676758|  0:01:50s\n","epoch 84 | loss: 59.9167 | val_0_mse: 34.866798400878906|  0:01:51s\n","epoch 85 | loss: 52.25926| val_0_mse: 27.85572052001953|  0:01:52s\n","epoch 86 | loss: 45.49911| val_0_mse: 26.58625030517578|  0:01:54s\n","epoch 87 | loss: 47.70472| val_0_mse: 30.47882080078125|  0:01:55s\n","epoch 88 | loss: 47.17175| val_0_mse: 30.544300079345703|  0:01:56s\n","epoch 89 | loss: 60.66094| val_0_mse: 33.261348724365234|  0:01:57s\n","epoch 90 | loss: 45.22528| val_0_mse: 27.30340003967285|  0:01:59s\n","epoch 91 | loss: 42.80984| val_0_mse: 22.238040924072266|  0:02:00s\n","epoch 92 | loss: 75.06402| val_0_mse: 40.12179946899414|  0:02:01s\n","epoch 93 | loss: 55.64523| val_0_mse: 28.231420516967773|  0:02:03s\n","epoch 94 | loss: 77.67851| val_0_mse: 48.287540435791016|  0:02:04s\n","epoch 95 | loss: 80.85055| val_0_mse: 43.561180114746094|  0:02:05s\n","epoch 96 | loss: 55.81814| val_0_mse: 31.68429946899414|  0:02:06s\n","epoch 97 | loss: 53.38183| val_0_mse: 32.24979019165039|  0:02:08s\n","epoch 98 | loss: 66.95034| val_0_mse: 29.306549072265625|  0:02:09s\n","epoch 99 | loss: 45.60314| val_0_mse: 49.604530334472656|  0:02:10s\n","Stop training because you reached max_epochs = 100 with best_epoch = 91 and best_val_0_mse = 22.238040924072266\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 13:11:31,493] Trial 27 finished with value: 22.238040924072266 and parameters: {'n_d': 59, 'n_steps': 9, 'gamma': 1.4677752398941477, 'n_independent': 1, 'n_shared': 5, 'momentum': 0.09563861925134046}. Best is trial 24 with value: 17.43118667602539.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 2124.09444| val_0_mse: 6613.28076171875|  0:00:00s\n","epoch 1  | loss: 1079.3426| val_0_mse: 4318.7490234375|  0:00:02s\n","epoch 2  | loss: 500.72931| val_0_mse: 11746.677734375|  0:00:02s\n","epoch 3  | loss: 322.31307| val_0_mse: 4769.66455078125|  0:00:03s\n","epoch 4  | loss: 296.98919| val_0_mse: 3856.305908203125|  0:00:04s\n","epoch 5  | loss: 283.86294| val_0_mse: 3237.99267578125|  0:00:05s\n","epoch 6  | loss: 237.63429| val_0_mse: 3020.746337890625|  0:00:06s\n","epoch 7  | loss: 210.9348| val_0_mse: 2481.44580078125|  0:00:07s\n","epoch 8  | loss: 197.05153| val_0_mse: 2412.0234375|  0:00:08s\n","epoch 9  | loss: 182.70208| val_0_mse: 2523.721923828125|  0:00:09s\n","epoch 10 | loss: 129.41385| val_0_mse: 2617.65234375|  0:00:10s\n","epoch 11 | loss: 126.41628| val_0_mse: 2603.6845703125|  0:00:11s\n","epoch 12 | loss: 136.52094| val_0_mse: 2704.981201171875|  0:00:12s\n","epoch 13 | loss: 119.59731| val_0_mse: 2420.79443359375|  0:00:13s\n","epoch 14 | loss: 115.43869| val_0_mse: 2492.121337890625|  0:00:14s\n","epoch 15 | loss: 105.40644| val_0_mse: 2504.8955078125|  0:00:15s\n","epoch 16 | loss: 102.03491| val_0_mse: 2551.589599609375|  0:00:16s\n","epoch 17 | loss: 110.29473| val_0_mse: 2415.34130859375|  0:00:16s\n","epoch 18 | loss: 97.7828 | val_0_mse: 2430.194580078125|  0:00:17s\n","\n","Early stopping occurred at epoch 18 with best_epoch = 8 and best_val_0_mse = 2412.0234375\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 13:11:49,916] Trial 28 finished with value: 2412.0234375 and parameters: {'n_d': 41, 'n_steps': 6, 'gamma': 1.0002418329260028, 'n_independent': 3, 'n_shared': 3, 'momentum': 0.13929080508949038}. Best is trial 24 with value: 17.43118667602539.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 2263.36605| val_0_mse: 3436.38037109375|  0:00:00s\n","epoch 1  | loss: 1199.42007| val_0_mse: 5454.0205078125|  0:00:01s\n","epoch 2  | loss: 519.2066| val_0_mse: 5867.43603515625|  0:00:02s\n","epoch 3  | loss: 416.06177| val_0_mse: 3977.454833984375|  0:00:03s\n","epoch 4  | loss: 368.72295| val_0_mse: 2562.6767578125|  0:00:04s\n","epoch 5  | loss: 285.02794| val_0_mse: 3038.712646484375|  0:00:05s\n","epoch 6  | loss: 263.22328| val_0_mse: 3423.332275390625|  0:00:06s\n","epoch 7  | loss: 268.61751| val_0_mse: 2731.607666015625|  0:00:07s\n","epoch 8  | loss: 253.03417| val_0_mse: 2720.283935546875|  0:00:08s\n","epoch 9  | loss: 240.7613| val_0_mse: 2868.59521484375|  0:00:09s\n","epoch 10 | loss: 238.29696| val_0_mse: 3093.458984375|  0:00:10s\n","epoch 11 | loss: 227.94904| val_0_mse: 2543.400634765625|  0:00:11s\n","epoch 12 | loss: 200.76675| val_0_mse: 2839.0712890625|  0:00:11s\n","epoch 13 | loss: 175.06794| val_0_mse: 2202.36767578125|  0:00:13s\n","epoch 14 | loss: 177.06093| val_0_mse: 2430.22998046875|  0:00:13s\n","epoch 15 | loss: 161.01328| val_0_mse: 2293.962646484375|  0:00:14s\n","epoch 16 | loss: 169.11509| val_0_mse: 2222.30126953125|  0:00:15s\n","epoch 17 | loss: 147.52134| val_0_mse: 1887.955322265625|  0:00:16s\n","epoch 18 | loss: 134.00548| val_0_mse: 1566.599365234375|  0:00:17s\n","epoch 19 | loss: 133.96543| val_0_mse: 1365.0140380859375|  0:00:18s\n","epoch 20 | loss: 142.26708| val_0_mse: 1320.7259521484375|  0:00:19s\n","epoch 21 | loss: 152.08168| val_0_mse: 1235.9715576171875|  0:00:20s\n","epoch 22 | loss: 128.32606| val_0_mse: 1216.580322265625|  0:00:21s\n","epoch 23 | loss: 138.70463| val_0_mse: 1173.5201416015625|  0:00:22s\n","epoch 24 | loss: 133.92177| val_0_mse: 665.0079956054688|  0:00:23s\n","epoch 25 | loss: 125.87427| val_0_mse: 592.3040161132812|  0:00:24s\n","epoch 26 | loss: 124.87637| val_0_mse: 580.9764404296875|  0:00:25s\n","epoch 27 | loss: 111.32435| val_0_mse: 590.2060546875|  0:00:26s\n","epoch 28 | loss: 131.19077| val_0_mse: 310.544189453125|  0:00:26s\n","epoch 29 | loss: 124.26036| val_0_mse: 463.3537902832031|  0:00:27s\n","epoch 30 | loss: 125.45091| val_0_mse: 480.4510498046875|  0:00:28s\n","epoch 31 | loss: 123.51349| val_0_mse: 360.03717041015625|  0:00:29s\n","epoch 32 | loss: 103.44096| val_0_mse: 270.54486083984375|  0:00:30s\n","epoch 33 | loss: 101.91421| val_0_mse: 356.2242431640625|  0:00:31s\n","epoch 34 | loss: 116.86938| val_0_mse: 247.82591247558594|  0:00:32s\n","epoch 35 | loss: 107.34792| val_0_mse: 166.19322204589844|  0:00:33s\n","epoch 36 | loss: 103.06977| val_0_mse: 177.19992065429688|  0:00:34s\n","epoch 37 | loss: 106.68429| val_0_mse: 140.8922882080078|  0:00:35s\n","epoch 38 | loss: 120.93219| val_0_mse: 92.90042877197266|  0:00:36s\n","epoch 39 | loss: 100.82315| val_0_mse: 113.0797119140625|  0:00:37s\n","epoch 40 | loss: 108.07426| val_0_mse: 120.57623291015625|  0:00:38s\n","epoch 41 | loss: 121.20195| val_0_mse: 129.6085205078125|  0:00:39s\n","epoch 42 | loss: 118.50247| val_0_mse: 96.86414337158203|  0:00:40s\n","epoch 43 | loss: 99.892  | val_0_mse: 65.55735778808594|  0:00:41s\n","epoch 44 | loss: 115.31942| val_0_mse: 115.20024871826172|  0:00:42s\n","epoch 45 | loss: 109.24518| val_0_mse: 93.47904205322266|  0:00:43s\n","epoch 46 | loss: 97.43006| val_0_mse: 104.90666961669922|  0:00:44s\n","epoch 47 | loss: 100.48125| val_0_mse: 92.45375061035156|  0:00:44s\n","epoch 48 | loss: 99.39884| val_0_mse: 99.98648071289062|  0:00:45s\n","epoch 49 | loss: 84.87552| val_0_mse: 151.97035217285156|  0:00:46s\n","epoch 50 | loss: 160.20434| val_0_mse: 110.75623321533203|  0:00:47s\n","epoch 51 | loss: 97.32805| val_0_mse: 55.463600158691406|  0:00:48s\n","epoch 52 | loss: 99.41869| val_0_mse: 75.77539825439453|  0:00:49s\n","epoch 53 | loss: 111.70064| val_0_mse: 66.49472045898438|  0:00:50s\n","epoch 54 | loss: 83.55239| val_0_mse: 63.6945686340332|  0:00:51s\n","epoch 55 | loss: 103.46367| val_0_mse: 78.2358169555664|  0:00:52s\n","epoch 56 | loss: 93.28957| val_0_mse: 63.561859130859375|  0:00:53s\n","epoch 57 | loss: 96.6348 | val_0_mse: 92.50373077392578|  0:00:54s\n","epoch 58 | loss: 88.30168| val_0_mse: 61.20146179199219|  0:00:55s\n","epoch 59 | loss: 87.86894| val_0_mse: 138.51026916503906|  0:00:56s\n","epoch 60 | loss: 113.10053| val_0_mse: 69.42845916748047|  0:00:56s\n","epoch 61 | loss: 101.00561| val_0_mse: 100.41648864746094|  0:00:57s\n","\n","Early stopping occurred at epoch 61 with best_epoch = 51 and best_val_0_mse = 55.463600158691406\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 13:12:48,269] Trial 29 finished with value: 55.46360397338867 and parameters: {'n_d': 49, 'n_steps': 4, 'gamma': 1.5379178479259707, 'n_independent': 4, 'n_shared': 5, 'momentum': 0.060290751509516495}. Best is trial 24 with value: 17.43118667602539.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 2288.23036| val_0_mse: 4393.76220703125|  0:00:00s\n","epoch 1  | loss: 1628.85666| val_0_mse: 3117.449951171875|  0:00:01s\n","epoch 2  | loss: 1139.70591| val_0_mse: 10436.765625|  0:00:01s\n","epoch 3  | loss: 723.10838| val_0_mse: 8126.04248046875|  0:00:02s\n","epoch 4  | loss: 474.61037| val_0_mse: 3995.897216796875|  0:00:02s\n","epoch 5  | loss: 364.69487| val_0_mse: 3606.658935546875|  0:00:03s\n","epoch 6  | loss: 306.54428| val_0_mse: 3498.00341796875|  0:00:03s\n","epoch 7  | loss: 270.30082| val_0_mse: 2886.201171875|  0:00:04s\n","epoch 8  | loss: 245.84106| val_0_mse: 2664.72998046875|  0:00:04s\n","epoch 9  | loss: 234.77542| val_0_mse: 2269.550048828125|  0:00:05s\n","epoch 10 | loss: 223.37896| val_0_mse: 2151.424072265625|  0:00:06s\n","epoch 11 | loss: 186.17722| val_0_mse: 2390.815673828125|  0:00:06s\n","epoch 12 | loss: 174.98925| val_0_mse: 2319.47607421875|  0:00:07s\n","epoch 13 | loss: 162.22948| val_0_mse: 2494.97119140625|  0:00:07s\n","epoch 14 | loss: 142.71259| val_0_mse: 2339.235595703125|  0:00:08s\n","epoch 15 | loss: 136.64232| val_0_mse: 1981.44970703125|  0:00:08s\n","epoch 16 | loss: 122.27532| val_0_mse: 1616.149169921875|  0:00:09s\n","epoch 17 | loss: 132.15533| val_0_mse: 1506.4818115234375|  0:00:09s\n","epoch 18 | loss: 141.16449| val_0_mse: 1246.46435546875|  0:00:10s\n","epoch 19 | loss: 112.69311| val_0_mse: 1171.394775390625|  0:00:10s\n","epoch 20 | loss: 106.1711| val_0_mse: 1006.2199096679688|  0:00:11s\n","epoch 21 | loss: 104.4376| val_0_mse: 818.5958251953125|  0:00:12s\n","epoch 22 | loss: 108.13225| val_0_mse: 729.024169921875|  0:00:12s\n","epoch 23 | loss: 109.86149| val_0_mse: 513.855712890625|  0:00:13s\n","epoch 24 | loss: 93.75805| val_0_mse: 471.5262145996094|  0:00:13s\n","epoch 25 | loss: 104.48388| val_0_mse: 385.2390441894531|  0:00:14s\n","epoch 26 | loss: 101.91731| val_0_mse: 254.49220275878906|  0:00:14s\n","epoch 27 | loss: 96.97474| val_0_mse: 495.2184143066406|  0:00:15s\n","epoch 28 | loss: 122.26206| val_0_mse: 303.2802429199219|  0:00:15s\n","epoch 29 | loss: 86.41447| val_0_mse: 297.9725036621094|  0:00:16s\n","epoch 30 | loss: 101.15107| val_0_mse: 220.7673797607422|  0:00:16s\n","epoch 31 | loss: 97.62651| val_0_mse: 238.747314453125|  0:00:17s\n","epoch 32 | loss: 107.96901| val_0_mse: 101.52191925048828|  0:00:17s\n","epoch 33 | loss: 108.92328| val_0_mse: 215.07127380371094|  0:00:18s\n","epoch 34 | loss: 94.71904| val_0_mse: 217.16070556640625|  0:00:18s\n","epoch 35 | loss: 95.65186| val_0_mse: 114.45233154296875|  0:00:19s\n","epoch 36 | loss: 99.38029| val_0_mse: 74.5649185180664|  0:00:20s\n","epoch 37 | loss: 90.72872| val_0_mse: 88.72049713134766|  0:00:20s\n","epoch 38 | loss: 84.24658| val_0_mse: 84.07388305664062|  0:00:21s\n","epoch 39 | loss: 79.44951| val_0_mse: 116.39217376708984|  0:00:21s\n","epoch 40 | loss: 76.61592| val_0_mse: 62.12363815307617|  0:00:22s\n","epoch 41 | loss: 71.22755| val_0_mse: 42.09354019165039|  0:00:22s\n","epoch 42 | loss: 74.80427| val_0_mse: 61.51496887207031|  0:00:23s\n","epoch 43 | loss: 78.64201| val_0_mse: 90.8669204711914|  0:00:23s\n","epoch 44 | loss: 65.59001| val_0_mse: 47.10762023925781|  0:00:24s\n","epoch 45 | loss: 71.55221| val_0_mse: 51.487701416015625|  0:00:24s\n","epoch 46 | loss: 67.51642| val_0_mse: 50.896141052246094|  0:00:25s\n","epoch 47 | loss: 63.14215| val_0_mse: 55.65248107910156|  0:00:26s\n","epoch 48 | loss: 71.34155| val_0_mse: 57.863800048828125|  0:00:26s\n","epoch 49 | loss: 69.39782| val_0_mse: 45.78971862792969|  0:00:27s\n","epoch 50 | loss: 71.106  | val_0_mse: 54.31943893432617|  0:00:27s\n","epoch 51 | loss: 69.63922| val_0_mse: 58.953468322753906|  0:00:28s\n","\n","Early stopping occurred at epoch 51 with best_epoch = 41 and best_val_0_mse = 42.09354019165039\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 13:13:16,801] Trial 30 finished with value: 42.09353256225586 and parameters: {'n_d': 37, 'n_steps': 5, 'gamma': 1.3630486008365665, 'n_independent': 2, 'n_shared': 1, 'momentum': 0.09668856013096169}. Best is trial 24 with value: 17.43118667602539.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 2146.62145| val_0_mse: 5591.00146484375|  0:00:00s\n","epoch 1  | loss: 839.04969| val_0_mse: 3072.285400390625|  0:00:01s\n","epoch 2  | loss: 336.57081| val_0_mse: 3492.46337890625|  0:00:01s\n","epoch 3  | loss: 202.46901| val_0_mse: 2940.048095703125|  0:00:02s\n","epoch 4  | loss: 159.16998| val_0_mse: 7139.2998046875|  0:00:02s\n","epoch 5  | loss: 150.0397| val_0_mse: 3038.606201171875|  0:00:03s\n","epoch 6  | loss: 139.00161| val_0_mse: 2841.075927734375|  0:00:04s\n","epoch 7  | loss: 112.56631| val_0_mse: 2970.847412109375|  0:00:04s\n","epoch 8  | loss: 118.60305| val_0_mse: 2721.591796875|  0:00:05s\n","epoch 9  | loss: 119.64297| val_0_mse: 2595.113037109375|  0:00:05s\n","epoch 10 | loss: 110.67248| val_0_mse: 2580.8857421875|  0:00:06s\n","epoch 11 | loss: 94.14714| val_0_mse: 2571.742431640625|  0:00:07s\n","epoch 12 | loss: 74.99797| val_0_mse: 2658.604736328125|  0:00:07s\n","epoch 13 | loss: 86.42423| val_0_mse: 2428.427734375|  0:00:08s\n","epoch 14 | loss: 73.25024| val_0_mse: 2567.1435546875|  0:00:08s\n","epoch 15 | loss: 65.47576| val_0_mse: 2523.61962890625|  0:00:09s\n","epoch 16 | loss: 76.14033| val_0_mse: 2339.404296875|  0:00:10s\n","epoch 17 | loss: 62.8134 | val_0_mse: 1917.201171875|  0:00:10s\n","epoch 18 | loss: 63.70931| val_0_mse: 1575.1378173828125|  0:00:11s\n","epoch 19 | loss: 72.58951| val_0_mse: 1428.36962890625|  0:00:11s\n","epoch 20 | loss: 61.59772| val_0_mse: 2123.252197265625|  0:00:12s\n","epoch 21 | loss: 70.00309| val_0_mse: 808.5797729492188|  0:00:12s\n","epoch 22 | loss: 73.00679| val_0_mse: 845.496826171875|  0:00:13s\n","epoch 23 | loss: 67.42074| val_0_mse: 827.1200561523438|  0:00:14s\n","epoch 24 | loss: 45.97673| val_0_mse: 996.1971435546875|  0:00:14s\n","epoch 25 | loss: 46.84303| val_0_mse: 425.5232849121094|  0:00:15s\n","epoch 26 | loss: 42.20406| val_0_mse: 378.803466796875|  0:00:15s\n","epoch 27 | loss: 49.71359| val_0_mse: 442.04754638671875|  0:00:16s\n","epoch 28 | loss: 59.17252| val_0_mse: 292.50048828125|  0:00:16s\n","epoch 29 | loss: 48.13639| val_0_mse: 273.19854736328125|  0:00:17s\n","epoch 30 | loss: 47.75935| val_0_mse: 192.0380859375|  0:00:18s\n","epoch 31 | loss: 40.45345| val_0_mse: 229.45968627929688|  0:00:18s\n","epoch 32 | loss: 42.16483| val_0_mse: 235.8356475830078|  0:00:19s\n","epoch 33 | loss: 41.48075| val_0_mse: 153.33102416992188|  0:00:19s\n","epoch 34 | loss: 41.25115| val_0_mse: 131.18722534179688|  0:00:20s\n","epoch 35 | loss: 50.20067| val_0_mse: 89.72750091552734|  0:00:20s\n","epoch 36 | loss: 43.77936| val_0_mse: 82.25949096679688|  0:00:21s\n","epoch 37 | loss: 45.50321| val_0_mse: 113.35188293457031|  0:00:21s\n","epoch 38 | loss: 39.53253| val_0_mse: 56.1031608581543|  0:00:22s\n","epoch 39 | loss: 37.34242| val_0_mse: 62.51552963256836|  0:00:23s\n","epoch 40 | loss: 59.18763| val_0_mse: 75.16410064697266|  0:00:23s\n","epoch 41 | loss: 65.82637| val_0_mse: 62.8961181640625|  0:00:24s\n","epoch 42 | loss: 48.75681| val_0_mse: 45.24243927001953|  0:00:24s\n","epoch 43 | loss: 47.23424| val_0_mse: 55.4964599609375|  0:00:25s\n","epoch 44 | loss: 41.30349| val_0_mse: 53.87919998168945|  0:00:25s\n","epoch 45 | loss: 35.67348| val_0_mse: 63.349708557128906|  0:00:26s\n","epoch 46 | loss: 41.08178| val_0_mse: 43.38364028930664|  0:00:27s\n","epoch 47 | loss: 44.543  | val_0_mse: 56.32714080810547|  0:00:27s\n","epoch 48 | loss: 49.02624| val_0_mse: 25.92011070251465|  0:00:28s\n","epoch 49 | loss: 48.38577| val_0_mse: 25.159420013427734|  0:00:28s\n","epoch 50 | loss: 40.7508 | val_0_mse: 35.03165054321289|  0:00:29s\n","epoch 51 | loss: 34.19972| val_0_mse: 45.195919036865234|  0:00:29s\n","epoch 52 | loss: 41.03197| val_0_mse: 26.459869384765625|  0:00:30s\n","epoch 53 | loss: 44.06362| val_0_mse: 21.254819869995117|  0:00:30s\n","epoch 54 | loss: 31.72572| val_0_mse: 21.93280029296875|  0:00:31s\n","epoch 55 | loss: 28.77329| val_0_mse: 18.03343963623047|  0:00:32s\n","epoch 56 | loss: 37.96375| val_0_mse: 22.788999557495117|  0:00:32s\n","epoch 57 | loss: 34.02116| val_0_mse: 18.785619735717773|  0:00:33s\n","epoch 58 | loss: 33.72377| val_0_mse: 35.90330123901367|  0:00:33s\n","epoch 59 | loss: 38.3844 | val_0_mse: 22.083080291748047|  0:00:34s\n","epoch 60 | loss: 33.98671| val_0_mse: 20.657609939575195|  0:00:35s\n","epoch 61 | loss: 35.7099 | val_0_mse: 32.01557922363281|  0:00:35s\n","epoch 62 | loss: 38.46417| val_0_mse: 21.89965057373047|  0:00:36s\n","epoch 63 | loss: 38.85409| val_0_mse: 21.252880096435547|  0:00:36s\n","epoch 64 | loss: 30.16606| val_0_mse: 24.550670623779297|  0:00:37s\n","epoch 65 | loss: 38.19182| val_0_mse: 30.53148078918457|  0:00:37s\n","\n","Early stopping occurred at epoch 65 with best_epoch = 55 and best_val_0_mse = 18.03343963623047\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 13:13:55,014] Trial 31 finished with value: 18.033435821533203 and parameters: {'n_d': 45, 'n_steps': 3, 'gamma': 1.4264918646535951, 'n_independent': 2, 'n_shared': 4, 'momentum': 0.27994405499809094}. Best is trial 24 with value: 17.43118667602539.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 2273.20641| val_0_mse: 5256.82080078125|  0:00:00s\n","epoch 1  | loss: 1092.75449| val_0_mse: 2480.272216796875|  0:00:01s\n","epoch 2  | loss: 332.78026| val_0_mse: 6055.974609375|  0:00:01s\n","epoch 3  | loss: 201.40649| val_0_mse: 5097.8056640625|  0:00:02s\n","epoch 4  | loss: 134.3393| val_0_mse: 3880.615966796875|  0:00:02s\n","epoch 5  | loss: 145.35888| val_0_mse: 2932.3037109375|  0:00:03s\n","epoch 6  | loss: 109.81291| val_0_mse: 2861.021240234375|  0:00:04s\n","epoch 7  | loss: 90.60247| val_0_mse: 2688.72119140625|  0:00:04s\n","epoch 8  | loss: 93.6291 | val_0_mse: 2717.562255859375|  0:00:05s\n","epoch 9  | loss: 126.27117| val_0_mse: 2539.18896484375|  0:00:05s\n","epoch 10 | loss: 78.15959| val_0_mse: 2750.853759765625|  0:00:06s\n","epoch 11 | loss: 89.0426 | val_0_mse: 2610.283935546875|  0:00:06s\n","\n","Early stopping occurred at epoch 11 with best_epoch = 1 and best_val_0_mse = 2480.272216796875\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 13:14:02,129] Trial 32 finished with value: 2480.272216796875 and parameters: {'n_d': 49, 'n_steps': 3, 'gamma': 1.4907842547716144, 'n_independent': 1, 'n_shared': 5, 'momentum': 0.1928590464774577}. Best is trial 24 with value: 17.43118667602539.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 1973.14317| val_0_mse: 5192.7177734375|  0:00:00s\n","epoch 1  | loss: 910.4266| val_0_mse: 6241.18408203125|  0:00:01s\n","epoch 2  | loss: 353.62929| val_0_mse: 4324.21728515625|  0:00:02s\n","epoch 3  | loss: 218.03384| val_0_mse: 3293.06005859375|  0:00:02s\n","epoch 4  | loss: 196.82463| val_0_mse: 3260.68310546875|  0:00:03s\n","epoch 5  | loss: 193.25211| val_0_mse: 2944.287353515625|  0:00:04s\n","epoch 6  | loss: 184.37255| val_0_mse: 2766.427001953125|  0:00:04s\n","epoch 7  | loss: 142.67356| val_0_mse: 3166.87255859375|  0:00:05s\n","epoch 8  | loss: 125.97662| val_0_mse: 2770.712890625|  0:00:06s\n","epoch 9  | loss: 117.72692| val_0_mse: 2734.387451171875|  0:00:07s\n","epoch 10 | loss: 111.79791| val_0_mse: 2704.56201171875|  0:00:07s\n","epoch 11 | loss: 132.44834| val_0_mse: 3274.026611328125|  0:00:08s\n","epoch 12 | loss: 111.83954| val_0_mse: 2550.66357421875|  0:00:09s\n","epoch 13 | loss: 104.0758| val_0_mse: 2576.4521484375|  0:00:09s\n","epoch 14 | loss: 98.51897| val_0_mse: 2465.27197265625|  0:00:10s\n","epoch 15 | loss: 85.03398| val_0_mse: 2311.748291015625|  0:00:11s\n","epoch 16 | loss: 104.77343| val_0_mse: 2076.88623046875|  0:00:11s\n","epoch 17 | loss: 105.24853| val_0_mse: 1991.026611328125|  0:00:12s\n","epoch 18 | loss: 105.37975| val_0_mse: 1513.15380859375|  0:00:13s\n","epoch 19 | loss: 92.007  | val_0_mse: 1438.8863525390625|  0:00:14s\n","epoch 20 | loss: 92.46387| val_0_mse: 1834.879638671875|  0:00:15s\n","epoch 21 | loss: 76.92232| val_0_mse: 1433.3250732421875|  0:00:15s\n","epoch 22 | loss: 70.60287| val_0_mse: 1301.3626708984375|  0:00:16s\n","epoch 23 | loss: 82.64042| val_0_mse: 1220.1873779296875|  0:00:17s\n","epoch 24 | loss: 88.95662| val_0_mse: 973.180908203125|  0:00:17s\n","epoch 25 | loss: 75.16729| val_0_mse: 1302.8302001953125|  0:00:18s\n","epoch 26 | loss: 74.05128| val_0_mse: 599.6881103515625|  0:00:19s\n","epoch 27 | loss: 75.41526| val_0_mse: 629.8466796875|  0:00:20s\n","epoch 28 | loss: 82.92896| val_0_mse: 640.6607666015625|  0:00:20s\n","epoch 29 | loss: 73.74776| val_0_mse: 339.7022399902344|  0:00:21s\n","epoch 30 | loss: 79.90849| val_0_mse: 237.14483642578125|  0:00:22s\n","epoch 31 | loss: 74.34   | val_0_mse: 214.4825439453125|  0:00:22s\n","epoch 32 | loss: 67.16358| val_0_mse: 242.938232421875|  0:00:23s\n","epoch 33 | loss: 66.18598| val_0_mse: 113.89119720458984|  0:00:24s\n","epoch 34 | loss: 53.11737| val_0_mse: 159.2798614501953|  0:00:24s\n","epoch 35 | loss: 51.06473| val_0_mse: 186.9837646484375|  0:00:25s\n","epoch 36 | loss: 55.42124| val_0_mse: 117.94090270996094|  0:00:26s\n","epoch 37 | loss: 69.10983| val_0_mse: 121.25525665283203|  0:00:27s\n","epoch 38 | loss: 57.51825| val_0_mse: 70.4923095703125|  0:00:27s\n","epoch 39 | loss: 69.12507| val_0_mse: 62.86602020263672|  0:00:28s\n","epoch 40 | loss: 61.28702| val_0_mse: 47.24148941040039|  0:00:29s\n","epoch 41 | loss: 66.85832| val_0_mse: 84.66496276855469|  0:00:29s\n","epoch 42 | loss: 53.10607| val_0_mse: 82.37345886230469|  0:00:30s\n","epoch 43 | loss: 69.82777| val_0_mse: 74.37904357910156|  0:00:31s\n","epoch 44 | loss: 58.55413| val_0_mse: 44.47917938232422|  0:00:31s\n","epoch 45 | loss: 54.30038| val_0_mse: 48.688201904296875|  0:00:32s\n","epoch 46 | loss: 54.65373| val_0_mse: 37.70553970336914|  0:00:33s\n","epoch 47 | loss: 50.38095| val_0_mse: 44.39918899536133|  0:00:34s\n","epoch 48 | loss: 51.48965| val_0_mse: 46.808509826660156|  0:00:34s\n","epoch 49 | loss: 61.71032| val_0_mse: 43.050540924072266|  0:00:35s\n","epoch 50 | loss: 54.1109 | val_0_mse: 61.71828842163086|  0:00:36s\n","epoch 51 | loss: 59.40839| val_0_mse: 71.20732879638672|  0:00:36s\n","epoch 52 | loss: 56.90183| val_0_mse: 49.91423034667969|  0:00:37s\n","epoch 53 | loss: 46.11985| val_0_mse: 57.75197982788086|  0:00:38s\n","epoch 54 | loss: 45.94773| val_0_mse: 39.34564971923828|  0:00:38s\n","epoch 55 | loss: 50.84544| val_0_mse: 35.68220138549805|  0:00:39s\n","epoch 56 | loss: 51.24514| val_0_mse: 35.31045913696289|  0:00:40s\n","epoch 57 | loss: 52.88828| val_0_mse: 59.683040618896484|  0:00:40s\n","epoch 58 | loss: 74.6901 | val_0_mse: 31.181900024414062|  0:00:41s\n","epoch 59 | loss: 45.33818| val_0_mse: 29.15273094177246|  0:00:42s\n","epoch 60 | loss: 47.44831| val_0_mse: 34.87538146972656|  0:00:43s\n","epoch 61 | loss: 72.28031| val_0_mse: 51.56364059448242|  0:00:43s\n","epoch 62 | loss: 64.62872| val_0_mse: 46.975738525390625|  0:00:44s\n","epoch 63 | loss: 50.14961| val_0_mse: 36.58665084838867|  0:00:45s\n","epoch 64 | loss: 48.85154| val_0_mse: 43.54111099243164|  0:00:45s\n","epoch 65 | loss: 41.20968| val_0_mse: 30.430259704589844|  0:00:46s\n","epoch 66 | loss: 42.27482| val_0_mse: 24.640899658203125|  0:00:47s\n","epoch 67 | loss: 47.0283 | val_0_mse: 41.88570022583008|  0:00:48s\n","epoch 68 | loss: 56.27209| val_0_mse: 37.51531982421875|  0:00:48s\n","epoch 69 | loss: 56.80542| val_0_mse: 33.06761169433594|  0:00:49s\n","epoch 70 | loss: 56.96605| val_0_mse: 31.07291030883789|  0:00:50s\n","epoch 71 | loss: 44.11247| val_0_mse: 29.047420501708984|  0:00:50s\n","epoch 72 | loss: 37.49935| val_0_mse: 42.55451965332031|  0:00:51s\n","epoch 73 | loss: 40.44308| val_0_mse: 33.41408157348633|  0:00:52s\n","epoch 74 | loss: 42.86186| val_0_mse: 51.845970153808594|  0:00:52s\n","epoch 75 | loss: 60.8564 | val_0_mse: 35.82633972167969|  0:00:53s\n","epoch 76 | loss: 44.64114| val_0_mse: 29.822280883789062|  0:00:54s\n","\n","Early stopping occurred at epoch 76 with best_epoch = 66 and best_val_0_mse = 24.640899658203125\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 13:14:56,941] Trial 33 finished with value: 24.64089584350586 and parameters: {'n_d': 56, 'n_steps': 4, 'gamma': 1.3167048492811901, 'n_independent': 2, 'n_shared': 4, 'momentum': 0.2855527344480259}. Best is trial 24 with value: 17.43118667602539.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 2175.19132| val_0_mse: 3710.99560546875|  0:00:00s\n","epoch 1  | loss: 1194.69205| val_0_mse: 19492.90234375|  0:00:01s\n","epoch 2  | loss: 562.884 | val_0_mse: 54643.00390625|  0:00:02s\n","epoch 3  | loss: 335.91042| val_0_mse: 4823.4560546875|  0:00:03s\n","epoch 4  | loss: 274.04241| val_0_mse: 5116.25732421875|  0:00:03s\n","epoch 5  | loss: 245.23664| val_0_mse: 3522.63818359375|  0:00:04s\n","epoch 6  | loss: 207.76809| val_0_mse: 2771.90869140625|  0:00:05s\n","epoch 7  | loss: 193.66515| val_0_mse: 3084.957763671875|  0:00:06s\n","epoch 8  | loss: 158.35902| val_0_mse: 2723.77685546875|  0:00:07s\n","epoch 9  | loss: 151.99982| val_0_mse: 2897.821533203125|  0:00:07s\n","epoch 10 | loss: 145.54009| val_0_mse: 2802.72412109375|  0:00:08s\n","epoch 11 | loss: 135.14221| val_0_mse: 2758.74169921875|  0:00:09s\n","epoch 12 | loss: 117.28106| val_0_mse: 2644.822021484375|  0:00:10s\n","epoch 13 | loss: 105.07148| val_0_mse: 2701.395751953125|  0:00:10s\n","epoch 14 | loss: 97.71011| val_0_mse: 2557.41357421875|  0:00:11s\n","epoch 15 | loss: 102.65061| val_0_mse: 2412.447021484375|  0:00:12s\n","epoch 16 | loss: 104.33997| val_0_mse: 2316.380859375|  0:00:13s\n","epoch 17 | loss: 110.79144| val_0_mse: 2537.015380859375|  0:00:13s\n","epoch 18 | loss: 86.05636| val_0_mse: 1900.948974609375|  0:00:14s\n","epoch 19 | loss: 83.09047| val_0_mse: 1436.3812255859375|  0:00:15s\n","epoch 20 | loss: 77.80116| val_0_mse: 1467.850341796875|  0:00:16s\n","epoch 21 | loss: 86.339  | val_0_mse: 1159.8680419921875|  0:00:17s\n","epoch 22 | loss: 75.41638| val_0_mse: 1047.23486328125|  0:00:17s\n","epoch 23 | loss: 79.99585| val_0_mse: 575.172119140625|  0:00:18s\n","epoch 24 | loss: 70.15891| val_0_mse: 568.2442626953125|  0:00:19s\n","epoch 25 | loss: 85.8715 | val_0_mse: 489.5838317871094|  0:00:20s\n","epoch 26 | loss: 67.59184| val_0_mse: 538.9217529296875|  0:00:21s\n","epoch 27 | loss: 76.43499| val_0_mse: 497.6681213378906|  0:00:21s\n","epoch 28 | loss: 71.66525| val_0_mse: 285.27984619140625|  0:00:22s\n","epoch 29 | loss: 67.00879| val_0_mse: 329.4544677734375|  0:00:23s\n","epoch 30 | loss: 62.98212| val_0_mse: 259.3340148925781|  0:00:24s\n","epoch 31 | loss: 65.09676| val_0_mse: 132.56422424316406|  0:00:25s\n","epoch 32 | loss: 64.51328| val_0_mse: 147.30300903320312|  0:00:25s\n","epoch 33 | loss: 56.12122| val_0_mse: 138.17967224121094|  0:00:26s\n","epoch 34 | loss: 73.15937| val_0_mse: 124.30814361572266|  0:00:27s\n","epoch 35 | loss: 60.19932| val_0_mse: 89.3447494506836|  0:00:28s\n","epoch 36 | loss: 70.43146| val_0_mse: 120.25871276855469|  0:00:28s\n","epoch 37 | loss: 66.07681| val_0_mse: 82.63159942626953|  0:00:29s\n","epoch 38 | loss: 53.93997| val_0_mse: 69.42044830322266|  0:00:30s\n","epoch 39 | loss: 56.69398| val_0_mse: 89.3587417602539|  0:00:31s\n","epoch 40 | loss: 54.93588| val_0_mse: 63.223018646240234|  0:00:31s\n","epoch 41 | loss: 56.42881| val_0_mse: 67.60530090332031|  0:00:32s\n","epoch 42 | loss: 63.85613| val_0_mse: 58.051780700683594|  0:00:33s\n","epoch 43 | loss: 49.25558| val_0_mse: 32.52762985229492|  0:00:34s\n","epoch 44 | loss: 47.43297| val_0_mse: 51.83190155029297|  0:00:35s\n","epoch 45 | loss: 44.96335| val_0_mse: 32.77391815185547|  0:00:35s\n","epoch 46 | loss: 35.31195| val_0_mse: 28.912519454956055|  0:00:36s\n","epoch 47 | loss: 45.10779| val_0_mse: 30.15683937072754|  0:00:37s\n","epoch 48 | loss: 41.04723| val_0_mse: 36.001461029052734|  0:00:38s\n","epoch 49 | loss: 41.59253| val_0_mse: 28.13633918762207|  0:00:38s\n","epoch 50 | loss: 50.42893| val_0_mse: 56.70124053955078|  0:00:39s\n","epoch 51 | loss: 44.11689| val_0_mse: 42.2705192565918|  0:00:40s\n","epoch 52 | loss: 36.52706| val_0_mse: 31.89434051513672|  0:00:41s\n","epoch 53 | loss: 43.31401| val_0_mse: 33.83580017089844|  0:00:41s\n","epoch 54 | loss: 48.38354| val_0_mse: 31.099580764770508|  0:00:42s\n","epoch 55 | loss: 47.34641| val_0_mse: 39.47740936279297|  0:00:43s\n","epoch 56 | loss: 38.25128| val_0_mse: 35.708778381347656|  0:00:44s\n","epoch 57 | loss: 43.54298| val_0_mse: 47.500938415527344|  0:00:44s\n","epoch 58 | loss: 51.53196| val_0_mse: 64.543701171875|  0:00:45s\n","epoch 59 | loss: 49.63913| val_0_mse: 23.12261962890625|  0:00:46s\n","epoch 60 | loss: 43.51805| val_0_mse: 30.819059371948242|  0:00:47s\n","epoch 61 | loss: 44.57202| val_0_mse: 24.82345962524414|  0:00:48s\n","epoch 62 | loss: 43.56549| val_0_mse: 38.7159309387207|  0:00:48s\n","epoch 63 | loss: 46.82377| val_0_mse: 29.731199264526367|  0:00:49s\n","epoch 64 | loss: 36.52222| val_0_mse: 25.899879455566406|  0:00:50s\n","epoch 65 | loss: 36.99164| val_0_mse: 27.832599639892578|  0:00:51s\n","epoch 66 | loss: 48.62121| val_0_mse: 24.23188018798828|  0:00:51s\n","epoch 67 | loss: 43.6667 | val_0_mse: 35.1297607421875|  0:00:52s\n","epoch 68 | loss: 42.5494 | val_0_mse: 31.933759689331055|  0:00:53s\n","epoch 69 | loss: 33.22811| val_0_mse: 22.904159545898438|  0:00:54s\n","epoch 70 | loss: 36.60543| val_0_mse: 21.152639389038086|  0:00:54s\n","epoch 71 | loss: 32.07252| val_0_mse: 56.35850143432617|  0:00:55s\n","epoch 72 | loss: 47.42741| val_0_mse: 21.149099349975586|  0:00:56s\n","epoch 73 | loss: 39.93502| val_0_mse: 18.072059631347656|  0:00:57s\n","epoch 74 | loss: 34.00435| val_0_mse: 22.7747802734375|  0:00:58s\n","epoch 75 | loss: 39.70556| val_0_mse: 18.32634925842285|  0:00:58s\n","epoch 76 | loss: 40.06776| val_0_mse: 21.39764976501465|  0:00:59s\n","epoch 77 | loss: 34.67847| val_0_mse: 20.929750442504883|  0:01:00s\n","epoch 78 | loss: 35.08313| val_0_mse: 19.270809173583984|  0:01:01s\n","epoch 79 | loss: 33.11594| val_0_mse: 25.166709899902344|  0:01:01s\n","epoch 80 | loss: 29.66915| val_0_mse: 32.784358978271484|  0:01:02s\n","epoch 81 | loss: 43.11199| val_0_mse: 29.070829391479492|  0:01:03s\n","epoch 82 | loss: 38.9338 | val_0_mse: 23.04595947265625|  0:01:04s\n","epoch 83 | loss: 34.10668| val_0_mse: 21.460790634155273|  0:01:05s\n","\n","Early stopping occurred at epoch 83 with best_epoch = 73 and best_val_0_mse = 18.072059631347656\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 13:16:02,564] Trial 34 finished with value: 18.072063446044922 and parameters: {'n_d': 43, 'n_steps': 4, 'gamma': 1.2433324594036514, 'n_independent': 3, 'n_shared': 4, 'momentum': 0.3183401625585074}. Best is trial 24 with value: 17.43118667602539.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 2324.96718| val_0_mse: 3392.25341796875|  0:00:00s\n","epoch 1  | loss: 1413.56503| val_0_mse: 2170.9482421875|  0:00:01s\n","epoch 2  | loss: 533.8999| val_0_mse: 2435.414794921875|  0:00:01s\n","epoch 3  | loss: 338.44999| val_0_mse: 2352.627685546875|  0:00:02s\n","epoch 4  | loss: 256.74212| val_0_mse: 2491.702880859375|  0:00:02s\n","epoch 5  | loss: 255.48462| val_0_mse: 2588.064453125|  0:00:03s\n","epoch 6  | loss: 216.26152| val_0_mse: 2491.927978515625|  0:00:04s\n","epoch 7  | loss: 171.39975| val_0_mse: 2454.12109375|  0:00:04s\n","epoch 8  | loss: 128.88921| val_0_mse: 2586.750732421875|  0:00:05s\n","epoch 9  | loss: 132.10873| val_0_mse: 2547.44921875|  0:00:05s\n","epoch 10 | loss: 117.4911| val_0_mse: 2543.49755859375|  0:00:06s\n","epoch 11 | loss: 93.36441| val_0_mse: 2593.385986328125|  0:00:06s\n","\n","Early stopping occurred at epoch 11 with best_epoch = 1 and best_val_0_mse = 2170.9482421875\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 13:16:09,821] Trial 35 finished with value: 2170.9482421875 and parameters: {'n_d': 32, 'n_steps': 3, 'gamma': 1.1415801992096755, 'n_independent': 1, 'n_shared': 5, 'momentum': 0.036962362481216544}. Best is trial 24 with value: 17.43118667602539.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 2208.74426| val_0_mse: 4973.75390625|  0:00:00s\n","epoch 1  | loss: 1378.38141| val_0_mse: 4279.8251953125|  0:00:01s\n","epoch 2  | loss: 564.01937| val_0_mse: 6315.96142578125|  0:00:02s\n","epoch 3  | loss: 312.10712| val_0_mse: 2546.88427734375|  0:00:02s\n","epoch 4  | loss: 214.83367| val_0_mse: 2652.672119140625|  0:00:03s\n","epoch 5  | loss: 169.07924| val_0_mse: 2766.61962890625|  0:00:04s\n","epoch 6  | loss: 162.22164| val_0_mse: 2696.540771484375|  0:00:05s\n","epoch 7  | loss: 157.44192| val_0_mse: 2848.140380859375|  0:00:05s\n","epoch 8  | loss: 127.51051| val_0_mse: 2697.881591796875|  0:00:06s\n","epoch 9  | loss: 138.12484| val_0_mse: 2650.77294921875|  0:00:07s\n","epoch 10 | loss: 134.69908| val_0_mse: 2779.42431640625|  0:00:07s\n","epoch 11 | loss: 113.80468| val_0_mse: 2759.010009765625|  0:00:08s\n","epoch 12 | loss: 131.96377| val_0_mse: 2498.39794921875|  0:00:09s\n","epoch 13 | loss: 132.41426| val_0_mse: 2728.3427734375|  0:00:10s\n","epoch 14 | loss: 105.10368| val_0_mse: 2501.928955078125|  0:00:10s\n","epoch 15 | loss: 112.80442| val_0_mse: 2183.003173828125|  0:00:11s\n","epoch 16 | loss: 97.55977| val_0_mse: 1824.056640625|  0:00:12s\n","epoch 17 | loss: 108.69843| val_0_mse: 1747.837646484375|  0:00:12s\n","epoch 18 | loss: 91.56762| val_0_mse: 1562.40234375|  0:00:13s\n","epoch 19 | loss: 111.32112| val_0_mse: 1117.0821533203125|  0:00:14s\n","epoch 20 | loss: 132.21833| val_0_mse: 1027.44580078125|  0:00:14s\n","epoch 21 | loss: 93.16617| val_0_mse: 1058.452880859375|  0:00:15s\n","epoch 22 | loss: 95.03021| val_0_mse: 896.7855224609375|  0:00:16s\n","epoch 23 | loss: 104.25109| val_0_mse: 744.1085815429688|  0:00:17s\n","epoch 24 | loss: 83.80882| val_0_mse: 705.496337890625|  0:00:17s\n","epoch 25 | loss: 101.25777| val_0_mse: 605.8538818359375|  0:00:18s\n","epoch 26 | loss: 88.50176| val_0_mse: 397.6242370605469|  0:00:19s\n","epoch 27 | loss: 86.54152| val_0_mse: 275.0364990234375|  0:00:19s\n","epoch 28 | loss: 85.03321| val_0_mse: 253.64329528808594|  0:00:20s\n","epoch 29 | loss: 72.23063| val_0_mse: 464.2646789550781|  0:00:21s\n","epoch 30 | loss: 97.85858| val_0_mse: 149.57615661621094|  0:00:22s\n","epoch 31 | loss: 90.80015| val_0_mse: 184.67799377441406|  0:00:22s\n","epoch 32 | loss: 77.04483| val_0_mse: 198.3656463623047|  0:00:23s\n","epoch 33 | loss: 82.55609| val_0_mse: 127.54289245605469|  0:00:24s\n","epoch 34 | loss: 80.04728| val_0_mse: 172.17730712890625|  0:00:24s\n","epoch 35 | loss: 78.62539| val_0_mse: 175.87533569335938|  0:00:25s\n","epoch 36 | loss: 113.69322| val_0_mse: 85.82872772216797|  0:00:26s\n","epoch 37 | loss: 114.28104| val_0_mse: 162.48269653320312|  0:00:27s\n","epoch 38 | loss: 72.73221| val_0_mse: 121.89460754394531|  0:00:27s\n","epoch 39 | loss: 88.08228| val_0_mse: 52.92034149169922|  0:00:28s\n","epoch 40 | loss: 67.40248| val_0_mse: 38.002071380615234|  0:00:29s\n","epoch 41 | loss: 81.4897 | val_0_mse: 55.94477844238281|  0:00:30s\n","epoch 42 | loss: 86.14914| val_0_mse: 111.06012725830078|  0:00:30s\n","epoch 43 | loss: 89.15772| val_0_mse: 43.5336799621582|  0:00:31s\n","epoch 44 | loss: 79.02494| val_0_mse: 44.317691802978516|  0:00:32s\n","epoch 45 | loss: 64.22174| val_0_mse: 56.63711929321289|  0:00:32s\n","epoch 46 | loss: 66.02713| val_0_mse: 41.12044143676758|  0:00:33s\n","epoch 47 | loss: 75.38464| val_0_mse: 80.6189193725586|  0:00:34s\n","epoch 48 | loss: 73.75318| val_0_mse: 46.01911926269531|  0:00:34s\n","epoch 49 | loss: 63.79847| val_0_mse: 36.890560150146484|  0:00:35s\n","epoch 50 | loss: 59.1671 | val_0_mse: 51.964080810546875|  0:00:36s\n","epoch 51 | loss: 60.50783| val_0_mse: 64.3079833984375|  0:00:37s\n","epoch 52 | loss: 62.61735| val_0_mse: 44.95207977294922|  0:00:38s\n","epoch 53 | loss: 51.03329| val_0_mse: 49.662811279296875|  0:00:38s\n","epoch 54 | loss: 59.86615| val_0_mse: 45.956459045410156|  0:00:39s\n","epoch 55 | loss: 56.19576| val_0_mse: 47.30350875854492|  0:00:40s\n","epoch 56 | loss: 63.75666| val_0_mse: 42.235958099365234|  0:00:40s\n","epoch 57 | loss: 62.15645| val_0_mse: 43.439659118652344|  0:00:41s\n","epoch 58 | loss: 54.40289| val_0_mse: 31.464019775390625|  0:00:42s\n","epoch 59 | loss: 51.16546| val_0_mse: 35.78617858886719|  0:00:42s\n","epoch 60 | loss: 62.73552| val_0_mse: 31.034839630126953|  0:00:43s\n","epoch 61 | loss: 48.384  | val_0_mse: 39.932159423828125|  0:00:44s\n","epoch 62 | loss: 64.16606| val_0_mse: 36.42073059082031|  0:00:45s\n","epoch 63 | loss: 57.84988| val_0_mse: 34.0620002746582|  0:00:45s\n","epoch 64 | loss: 51.28462| val_0_mse: 34.87889099121094|  0:00:46s\n","epoch 65 | loss: 54.43261| val_0_mse: 29.66230010986328|  0:00:47s\n","epoch 66 | loss: 51.99233| val_0_mse: 57.73836898803711|  0:00:47s\n","epoch 67 | loss: 56.93848| val_0_mse: 34.00830841064453|  0:00:48s\n","epoch 68 | loss: 44.8461 | val_0_mse: 28.789379119873047|  0:00:49s\n","epoch 69 | loss: 61.21168| val_0_mse: 44.15687942504883|  0:00:49s\n","epoch 70 | loss: 50.62978| val_0_mse: 34.948299407958984|  0:00:50s\n","epoch 71 | loss: 44.03412| val_0_mse: 27.867420196533203|  0:00:51s\n","epoch 72 | loss: 58.72302| val_0_mse: 33.467529296875|  0:00:52s\n","epoch 73 | loss: 48.41663| val_0_mse: 36.8956298828125|  0:00:52s\n","epoch 74 | loss: 60.63706| val_0_mse: 30.890899658203125|  0:00:53s\n","epoch 75 | loss: 46.13817| val_0_mse: 33.73094940185547|  0:00:54s\n","epoch 76 | loss: 41.45974| val_0_mse: 36.15858840942383|  0:00:54s\n","epoch 77 | loss: 51.62658| val_0_mse: 28.736360549926758|  0:00:55s\n","epoch 78 | loss: 42.93839| val_0_mse: 30.62306022644043|  0:00:56s\n","epoch 79 | loss: 38.42939| val_0_mse: 23.81559944152832|  0:00:56s\n","epoch 80 | loss: 40.90646| val_0_mse: 29.163299560546875|  0:00:57s\n","epoch 81 | loss: 52.09064| val_0_mse: 71.70899200439453|  0:00:58s\n","epoch 82 | loss: 62.17694| val_0_mse: 47.75727081298828|  0:00:58s\n","epoch 83 | loss: 48.18441| val_0_mse: 40.75437927246094|  0:00:59s\n","epoch 84 | loss: 57.05246| val_0_mse: 68.03337860107422|  0:01:00s\n","epoch 85 | loss: 62.13249| val_0_mse: 34.82217025756836|  0:01:00s\n","epoch 86 | loss: 57.58958| val_0_mse: 31.936830520629883|  0:01:01s\n","epoch 87 | loss: 52.50954| val_0_mse: 26.255250930786133|  0:01:02s\n","epoch 88 | loss: 33.25306| val_0_mse: 25.139699935913086|  0:01:03s\n","epoch 89 | loss: 34.5215 | val_0_mse: 21.983360290527344|  0:01:03s\n","epoch 90 | loss: 41.04249| val_0_mse: 24.620649337768555|  0:01:04s\n","epoch 91 | loss: 44.41479| val_0_mse: 28.72340965270996|  0:01:05s\n","epoch 92 | loss: 50.72128| val_0_mse: 25.285579681396484|  0:01:05s\n","epoch 93 | loss: 32.39413| val_0_mse: 27.03837013244629|  0:01:06s\n","epoch 94 | loss: 47.07146| val_0_mse: 25.43531036376953|  0:01:07s\n","epoch 95 | loss: 39.22935| val_0_mse: 23.48480987548828|  0:01:07s\n","epoch 96 | loss: 38.79912| val_0_mse: 25.028459548950195|  0:01:08s\n","epoch 97 | loss: 40.7453 | val_0_mse: 29.19066047668457|  0:01:09s\n","epoch 98 | loss: 38.86894| val_0_mse: 40.954071044921875|  0:01:09s\n","epoch 99 | loss: 41.5486 | val_0_mse: 37.73863983154297|  0:01:10s\n","\n","Early stopping occurred at epoch 99 with best_epoch = 89 and best_val_0_mse = 21.983360290527344\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 13:17:20,878] Trial 36 finished with value: 21.98336410522461 and parameters: {'n_d': 38, 'n_steps': 4, 'gamma': 1.4145530799036108, 'n_independent': 2, 'n_shared': 4, 'momentum': 0.21144247215979736}. Best is trial 24 with value: 17.43118667602539.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 2134.78255| val_0_mse: 7858.11669921875|  0:00:01s\n","epoch 1  | loss: 1590.91413| val_0_mse: 11821.0146484375|  0:00:02s\n","epoch 2  | loss: 1314.16299| val_0_mse: 16397.5703125|  0:00:03s\n","epoch 3  | loss: 1136.47115| val_0_mse: 9665.73046875|  0:00:04s\n","epoch 4  | loss: 997.72609| val_0_mse: 11106.451171875|  0:00:05s\n","epoch 5  | loss: 951.96288| val_0_mse: 6963.33642578125|  0:00:06s\n","epoch 6  | loss: 876.95133| val_0_mse: 9607.7119140625|  0:00:07s\n","epoch 7  | loss: 785.60341| val_0_mse: 5533.96142578125|  0:00:08s\n","epoch 8  | loss: 680.02011| val_0_mse: 4144.4091796875|  0:00:09s\n","epoch 9  | loss: 571.04053| val_0_mse: 5218.80126953125|  0:00:10s\n","epoch 10 | loss: 596.18427| val_0_mse: 3825.451904296875|  0:00:11s\n","epoch 11 | loss: 594.3777| val_0_mse: 4225.12890625|  0:00:12s\n","epoch 12 | loss: 553.37652| val_0_mse: 4047.73095703125|  0:00:13s\n","epoch 13 | loss: 615.22245| val_0_mse: 3044.520751953125|  0:00:14s\n","epoch 14 | loss: 566.04785| val_0_mse: 2701.319580078125|  0:00:15s\n","epoch 15 | loss: 475.74402| val_0_mse: 3112.426025390625|  0:00:16s\n","epoch 16 | loss: 390.23266| val_0_mse: 1729.1939697265625|  0:00:17s\n","epoch 17 | loss: 304.83528| val_0_mse: 2123.568359375|  0:00:18s\n","epoch 18 | loss: 283.01114| val_0_mse: 1718.9576416015625|  0:00:19s\n","epoch 19 | loss: 234.7861| val_0_mse: 1504.84765625|  0:00:20s\n","epoch 20 | loss: 215.94985| val_0_mse: 1368.3924560546875|  0:00:21s\n","epoch 21 | loss: 225.99572| val_0_mse: 1321.983642578125|  0:00:22s\n","epoch 22 | loss: 161.1217| val_0_mse: 1101.4732666015625|  0:00:23s\n","epoch 23 | loss: 155.67026| val_0_mse: 1078.150390625|  0:00:24s\n","epoch 24 | loss: 140.30763| val_0_mse: 703.5989379882812|  0:00:25s\n","epoch 25 | loss: 139.22367| val_0_mse: 709.0272216796875|  0:00:26s\n","epoch 26 | loss: 117.78612| val_0_mse: 572.1491088867188|  0:00:28s\n","epoch 27 | loss: 140.44675| val_0_mse: 339.7113342285156|  0:00:29s\n","epoch 28 | loss: 130.96614| val_0_mse: 328.0189514160156|  0:00:30s\n","epoch 29 | loss: 118.53721| val_0_mse: 284.5019226074219|  0:00:31s\n","epoch 30 | loss: 125.92583| val_0_mse: 330.06787109375|  0:00:32s\n","epoch 31 | loss: 105.20341| val_0_mse: 214.7620391845703|  0:00:33s\n","epoch 32 | loss: 105.76364| val_0_mse: 221.64707946777344|  0:00:34s\n","epoch 33 | loss: 89.41321| val_0_mse: 195.57522583007812|  0:00:35s\n","epoch 34 | loss: 108.21503| val_0_mse: 298.7577819824219|  0:00:36s\n","epoch 35 | loss: 83.59891| val_0_mse: 114.79918670654297|  0:00:37s\n","epoch 36 | loss: 112.03244| val_0_mse: 97.41716003417969|  0:00:38s\n","epoch 37 | loss: 95.95033| val_0_mse: 55.80931091308594|  0:00:39s\n","epoch 38 | loss: 91.66662| val_0_mse: 131.6753387451172|  0:00:40s\n","epoch 39 | loss: 99.18175| val_0_mse: 47.529361724853516|  0:00:41s\n","epoch 40 | loss: 101.35115| val_0_mse: 77.2867431640625|  0:00:42s\n","epoch 41 | loss: 86.71876| val_0_mse: 63.95825958251953|  0:00:43s\n","epoch 42 | loss: 82.51072| val_0_mse: 60.76620864868164|  0:00:44s\n","epoch 43 | loss: 107.48579| val_0_mse: 59.0272216796875|  0:00:45s\n","epoch 44 | loss: 99.45663| val_0_mse: 46.82920837402344|  0:00:46s\n","epoch 45 | loss: 91.08506| val_0_mse: 33.405738830566406|  0:00:47s\n","epoch 46 | loss: 76.1205 | val_0_mse: 65.94609832763672|  0:00:48s\n","epoch 47 | loss: 74.12945| val_0_mse: 78.13558197021484|  0:00:49s\n","epoch 48 | loss: 93.15422| val_0_mse: 53.28348922729492|  0:00:50s\n","epoch 49 | loss: 93.25277| val_0_mse: 78.81294250488281|  0:00:51s\n","epoch 50 | loss: 77.2303 | val_0_mse: 52.118770599365234|  0:00:52s\n","epoch 51 | loss: 72.48014| val_0_mse: 50.37202072143555|  0:00:53s\n","epoch 52 | loss: 81.24805| val_0_mse: 69.47956085205078|  0:00:54s\n","epoch 53 | loss: 100.58144| val_0_mse: 71.63432312011719|  0:00:55s\n","epoch 54 | loss: 85.55101| val_0_mse: 28.756980895996094|  0:00:56s\n","epoch 55 | loss: 75.95756| val_0_mse: 64.44631958007812|  0:00:57s\n","epoch 56 | loss: 77.66114| val_0_mse: 42.683311462402344|  0:00:58s\n","epoch 57 | loss: 83.48996| val_0_mse: 48.55937957763672|  0:01:00s\n","epoch 58 | loss: 68.60086| val_0_mse: 26.381439208984375|  0:01:01s\n","epoch 59 | loss: 62.31116| val_0_mse: 26.17943000793457|  0:01:02s\n","epoch 60 | loss: 71.64616| val_0_mse: 40.571258544921875|  0:01:03s\n","epoch 61 | loss: 75.50714| val_0_mse: 29.282039642333984|  0:01:04s\n","epoch 62 | loss: 69.41598| val_0_mse: 31.315040588378906|  0:01:05s\n","epoch 63 | loss: 86.15371| val_0_mse: 29.55824089050293|  0:01:06s\n","epoch 64 | loss: 96.90652| val_0_mse: 34.76100158691406|  0:01:07s\n","epoch 65 | loss: 71.58547| val_0_mse: 22.056209564208984|  0:01:08s\n","epoch 66 | loss: 78.61784| val_0_mse: 97.77105712890625|  0:01:09s\n","epoch 67 | loss: 114.1545| val_0_mse: 39.43402862548828|  0:01:10s\n","epoch 68 | loss: 83.33626| val_0_mse: 24.2275390625|  0:01:11s\n","epoch 69 | loss: 68.33727| val_0_mse: 35.98664093017578|  0:01:12s\n","epoch 70 | loss: 64.68589| val_0_mse: 45.843048095703125|  0:01:13s\n","epoch 71 | loss: 73.46385| val_0_mse: 27.55069923400879|  0:01:14s\n","epoch 72 | loss: 64.33447| val_0_mse: 39.34482955932617|  0:01:15s\n","epoch 73 | loss: 61.94737| val_0_mse: 58.823299407958984|  0:01:16s\n","epoch 74 | loss: 80.97137| val_0_mse: 26.282320022583008|  0:01:17s\n","epoch 75 | loss: 75.20516| val_0_mse: 34.93893051147461|  0:01:18s\n","\n","Early stopping occurred at epoch 75 with best_epoch = 65 and best_val_0_mse = 22.056209564208984\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 13:18:39,914] Trial 37 finished with value: 22.056211471557617 and parameters: {'n_d': 52, 'n_steps': 8, 'gamma': 1.6281311568497085, 'n_independent': 2, 'n_shared': 3, 'momentum': 0.39950082463899533}. Best is trial 24 with value: 17.43118667602539.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 2089.63839| val_0_mse: 3737.974609375|  0:00:00s\n","epoch 1  | loss: 871.2098| val_0_mse: 2404.88525390625|  0:00:00s\n","epoch 2  | loss: 395.59587| val_0_mse: 2704.70751953125|  0:00:01s\n","epoch 3  | loss: 275.11745| val_0_mse: 3236.2509765625|  0:00:01s\n","epoch 4  | loss: 201.99585| val_0_mse: 3083.563720703125|  0:00:01s\n","epoch 5  | loss: 171.38529| val_0_mse: 3236.03369140625|  0:00:02s\n","epoch 6  | loss: 149.41071| val_0_mse: 3286.42333984375|  0:00:02s\n","epoch 7  | loss: 124.23695| val_0_mse: 3495.27734375|  0:00:02s\n","epoch 8  | loss: 108.45287| val_0_mse: 2970.88671875|  0:00:03s\n","epoch 9  | loss: 111.27188| val_0_mse: 2855.296875|  0:00:03s\n","epoch 10 | loss: 81.49038| val_0_mse: 2743.972412109375|  0:00:04s\n","epoch 11 | loss: 80.42765| val_0_mse: 2688.3564453125|  0:00:04s\n","\n","Early stopping occurred at epoch 11 with best_epoch = 1 and best_val_0_mse = 2404.88525390625\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 13:18:44,687] Trial 38 finished with value: 2404.88525390625 and parameters: {'n_d': 47, 'n_steps': 3, 'gamma': 1.3578040538270566, 'n_independent': 1, 'n_shared': 2, 'momentum': 0.2825082393956058}. Best is trial 24 with value: 17.43118667602539.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 2291.23216| val_0_mse: 3762.20263671875|  0:00:00s\n","epoch 1  | loss: 1497.24829| val_0_mse: 9392.5478515625|  0:00:02s\n","epoch 2  | loss: 785.17448| val_0_mse: 10050.2470703125|  0:00:03s\n","epoch 3  | loss: 433.92414| val_0_mse: 3932.46826171875|  0:00:04s\n","epoch 4  | loss: 338.84798| val_0_mse: 4281.9921875|  0:00:05s\n","epoch 5  | loss: 363.25177| val_0_mse: 4173.8916015625|  0:00:06s\n","epoch 6  | loss: 326.98961| val_0_mse: 3030.208740234375|  0:00:07s\n","epoch 7  | loss: 255.65849| val_0_mse: 3054.979736328125|  0:00:08s\n","epoch 8  | loss: 275.36191| val_0_mse: 3539.587890625|  0:00:09s\n","epoch 9  | loss: 187.55491| val_0_mse: 3450.389404296875|  0:00:10s\n","epoch 10 | loss: 172.68562| val_0_mse: 3003.72802734375|  0:00:11s\n","epoch 11 | loss: 178.59411| val_0_mse: 2765.69384765625|  0:00:12s\n","epoch 12 | loss: 158.7462| val_0_mse: 2841.96875|  0:00:13s\n","epoch 13 | loss: 162.77886| val_0_mse: 2783.77587890625|  0:00:14s\n","epoch 14 | loss: 132.39111| val_0_mse: 2508.562255859375|  0:00:15s\n","epoch 15 | loss: 130.95673| val_0_mse: 2444.7646484375|  0:00:16s\n","epoch 16 | loss: 108.67586| val_0_mse: 2072.14794921875|  0:00:17s\n","epoch 17 | loss: 121.3889| val_0_mse: 1919.234375|  0:00:18s\n","epoch 18 | loss: 99.27137| val_0_mse: 1755.29150390625|  0:00:19s\n","epoch 19 | loss: 84.62027| val_0_mse: 1671.973876953125|  0:00:20s\n","epoch 20 | loss: 98.99106| val_0_mse: 1662.9583740234375|  0:00:21s\n","epoch 21 | loss: 94.53253| val_0_mse: 1539.0447998046875|  0:00:22s\n","epoch 22 | loss: 83.83836| val_0_mse: 1167.3023681640625|  0:00:23s\n","epoch 23 | loss: 81.79357| val_0_mse: 1189.3231201171875|  0:00:24s\n","epoch 24 | loss: 71.84791| val_0_mse: 880.0809326171875|  0:00:25s\n","epoch 25 | loss: 72.12242| val_0_mse: 1003.028564453125|  0:00:26s\n","epoch 26 | loss: 73.21338| val_0_mse: 769.01318359375|  0:00:27s\n","epoch 27 | loss: 81.67726| val_0_mse: 497.9293212890625|  0:00:28s\n","epoch 28 | loss: 71.25878| val_0_mse: 627.2213134765625|  0:00:29s\n","epoch 29 | loss: 81.34644| val_0_mse: 566.512939453125|  0:00:30s\n","epoch 30 | loss: 68.74313| val_0_mse: 519.6965942382812|  0:00:31s\n","epoch 31 | loss: 83.05664| val_0_mse: 472.8948059082031|  0:00:32s\n","epoch 32 | loss: 69.23603| val_0_mse: 458.9073181152344|  0:00:33s\n","epoch 33 | loss: 76.69571| val_0_mse: 215.92027282714844|  0:00:34s\n","epoch 34 | loss: 74.01837| val_0_mse: 252.27684020996094|  0:00:35s\n","epoch 35 | loss: 61.98735| val_0_mse: 167.68487548828125|  0:00:36s\n","epoch 36 | loss: 68.1633 | val_0_mse: 108.28954315185547|  0:00:37s\n","epoch 37 | loss: 59.8472 | val_0_mse: 160.39749145507812|  0:00:38s\n","epoch 38 | loss: 51.04327| val_0_mse: 103.76788330078125|  0:00:39s\n","epoch 39 | loss: 55.55823| val_0_mse: 98.18096160888672|  0:00:40s\n","epoch 40 | loss: 57.65703| val_0_mse: 47.37234115600586|  0:00:41s\n","epoch 41 | loss: 54.91031| val_0_mse: 101.06526184082031|  0:00:42s\n","epoch 42 | loss: 61.24167| val_0_mse: 86.22219848632812|  0:00:43s\n","epoch 43 | loss: 73.24353| val_0_mse: 70.39778137207031|  0:00:44s\n","epoch 44 | loss: 54.74401| val_0_mse: 38.35750961303711|  0:00:45s\n","epoch 45 | loss: 50.24738| val_0_mse: 34.377540588378906|  0:00:46s\n","epoch 46 | loss: 47.968  | val_0_mse: 45.58647918701172|  0:00:47s\n","epoch 47 | loss: 51.38814| val_0_mse: 47.48651885986328|  0:00:48s\n","epoch 48 | loss: 43.52708| val_0_mse: 33.502079010009766|  0:00:49s\n","epoch 49 | loss: 63.25625| val_0_mse: 63.10049819946289|  0:00:50s\n","epoch 50 | loss: 50.81183| val_0_mse: 39.59162902832031|  0:00:51s\n","epoch 51 | loss: 48.50878| val_0_mse: 43.233551025390625|  0:00:52s\n","epoch 52 | loss: 40.93766| val_0_mse: 34.278541564941406|  0:00:53s\n","epoch 53 | loss: 61.88977| val_0_mse: 35.88774871826172|  0:00:54s\n","epoch 54 | loss: 62.87581| val_0_mse: 28.926000595092773|  0:00:55s\n","epoch 55 | loss: 53.95565| val_0_mse: 28.481609344482422|  0:00:56s\n","epoch 56 | loss: 59.60479| val_0_mse: 38.46207809448242|  0:00:57s\n","epoch 57 | loss: 47.19249| val_0_mse: 53.158050537109375|  0:00:58s\n","epoch 58 | loss: 41.68639| val_0_mse: 36.06700134277344|  0:00:59s\n","epoch 59 | loss: 54.74249| val_0_mse: 23.074499130249023|  0:01:00s\n","epoch 60 | loss: 51.22138| val_0_mse: 28.839540481567383|  0:01:01s\n","epoch 61 | loss: 49.64521| val_0_mse: 31.615079879760742|  0:01:02s\n","epoch 62 | loss: 42.55365| val_0_mse: 27.995019912719727|  0:01:03s\n","epoch 63 | loss: 39.33315| val_0_mse: 24.102670669555664|  0:01:04s\n","epoch 64 | loss: 47.26794| val_0_mse: 20.408039093017578|  0:01:05s\n","epoch 65 | loss: 46.92181| val_0_mse: 26.129499435424805|  0:01:06s\n","epoch 66 | loss: 49.00463| val_0_mse: 20.610240936279297|  0:01:07s\n","epoch 67 | loss: 43.36325| val_0_mse: 23.426809310913086|  0:01:08s\n","epoch 68 | loss: 41.47743| val_0_mse: 26.024309158325195|  0:01:09s\n","epoch 69 | loss: 46.07937| val_0_mse: 22.25242042541504|  0:01:10s\n","epoch 70 | loss: 36.10209| val_0_mse: 20.114110946655273|  0:01:11s\n","epoch 71 | loss: 31.92008| val_0_mse: 23.425050735473633|  0:01:12s\n","epoch 72 | loss: 51.37028| val_0_mse: 21.280550003051758|  0:01:13s\n","epoch 73 | loss: 45.16936| val_0_mse: 26.998050689697266|  0:01:15s\n","epoch 74 | loss: 37.81567| val_0_mse: 20.63838005065918|  0:01:16s\n","epoch 75 | loss: 53.9172 | val_0_mse: 33.8928108215332|  0:01:17s\n","epoch 76 | loss: 40.93722| val_0_mse: 14.346969604492188|  0:01:18s\n","epoch 77 | loss: 31.89868| val_0_mse: 32.62757110595703|  0:01:19s\n","epoch 78 | loss: 47.80236| val_0_mse: 18.461429595947266|  0:01:20s\n","epoch 79 | loss: 32.12797| val_0_mse: 19.300460815429688|  0:01:21s\n","epoch 80 | loss: 35.46942| val_0_mse: 19.159690856933594|  0:01:22s\n","epoch 81 | loss: 41.84061| val_0_mse: 24.985809326171875|  0:01:23s\n","epoch 82 | loss: 42.31067| val_0_mse: 25.151660919189453|  0:01:24s\n","epoch 83 | loss: 38.75095| val_0_mse: 27.17222023010254|  0:01:25s\n","epoch 84 | loss: 41.38573| val_0_mse: 28.002119064331055|  0:01:26s\n","epoch 85 | loss: 37.59258| val_0_mse: 18.565719604492188|  0:01:27s\n","epoch 86 | loss: 41.30291| val_0_mse: 29.45256996154785|  0:01:28s\n","\n","Early stopping occurred at epoch 86 with best_epoch = 76 and best_val_0_mse = 14.346969604492188\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 13:20:13,528] Trial 39 finished with value: 14.34697437286377 and parameters: {'n_d': 54, 'n_steps': 5, 'gamma': 1.2681179124642246, 'n_independent': 3, 'n_shared': 5, 'momentum': 0.12173958197141824}. Best is trial 39 with value: 14.34697437286377.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 1868.3651| val_0_mse: 7828.97216796875|  0:00:00s\n","epoch 1  | loss: 606.71434| val_0_mse: 6078.7998046875|  0:00:01s\n","epoch 2  | loss: 340.82781| val_0_mse: 5516.83447265625|  0:00:02s\n","epoch 3  | loss: 249.27095| val_0_mse: 3686.0068359375|  0:00:02s\n","epoch 4  | loss: 183.5848| val_0_mse: 4193.55029296875|  0:00:03s\n","epoch 5  | loss: 181.80776| val_0_mse: 3754.9033203125|  0:00:04s\n","epoch 6  | loss: 162.16822| val_0_mse: 3334.52099609375|  0:00:04s\n","epoch 7  | loss: 132.61706| val_0_mse: 3430.244384765625|  0:00:05s\n","epoch 8  | loss: 128.31218| val_0_mse: 2896.06689453125|  0:00:05s\n","epoch 9  | loss: 128.00555| val_0_mse: 2737.88330078125|  0:00:06s\n","epoch 10 | loss: 116.40688| val_0_mse: 2588.772216796875|  0:00:07s\n","epoch 11 | loss: 109.40794| val_0_mse: 2552.43994140625|  0:00:08s\n","epoch 12 | loss: 98.11637| val_0_mse: 2362.746826171875|  0:00:08s\n","epoch 13 | loss: 90.77958| val_0_mse: 2285.583251953125|  0:00:09s\n","epoch 14 | loss: 83.56475| val_0_mse: 2190.53466796875|  0:00:09s\n","epoch 15 | loss: 89.23756| val_0_mse: 2178.87255859375|  0:00:10s\n","epoch 16 | loss: 72.47247| val_0_mse: 2218.186767578125|  0:00:11s\n","epoch 17 | loss: 68.66518| val_0_mse: 2014.07861328125|  0:00:11s\n","epoch 18 | loss: 77.19981| val_0_mse: 1734.355712890625|  0:00:12s\n","epoch 19 | loss: 86.41385| val_0_mse: 1256.12548828125|  0:00:13s\n","epoch 20 | loss: 71.96518| val_0_mse: 1152.1348876953125|  0:00:13s\n","epoch 21 | loss: 66.6374 | val_0_mse: 1074.9410400390625|  0:00:14s\n","epoch 22 | loss: 60.49401| val_0_mse: 944.6640014648438|  0:00:15s\n","epoch 23 | loss: 56.92789| val_0_mse: 888.0010986328125|  0:00:15s\n","epoch 24 | loss: 64.23214| val_0_mse: 729.9873046875|  0:00:16s\n","epoch 25 | loss: 61.89521| val_0_mse: 632.1365966796875|  0:00:17s\n","epoch 26 | loss: 66.61341| val_0_mse: 475.3879089355469|  0:00:17s\n","epoch 27 | loss: 64.01258| val_0_mse: 384.94384765625|  0:00:18s\n","epoch 28 | loss: 56.45101| val_0_mse: 325.615966796875|  0:00:19s\n","epoch 29 | loss: 52.84303| val_0_mse: 259.57415771484375|  0:00:19s\n","epoch 30 | loss: 50.62359| val_0_mse: 178.4716033935547|  0:00:20s\n","epoch 31 | loss: 54.70428| val_0_mse: 318.1441955566406|  0:00:21s\n","epoch 32 | loss: 50.34139| val_0_mse: 157.44354248046875|  0:00:21s\n","epoch 33 | loss: 43.66862| val_0_mse: 95.75975036621094|  0:00:22s\n","epoch 34 | loss: 57.43249| val_0_mse: 144.53515625|  0:00:22s\n","epoch 35 | loss: 52.08421| val_0_mse: 102.1058578491211|  0:00:23s\n","epoch 36 | loss: 48.97351| val_0_mse: 95.4400634765625|  0:00:24s\n","epoch 37 | loss: 48.11169| val_0_mse: 101.73023223876953|  0:00:24s\n","epoch 38 | loss: 58.60317| val_0_mse: 90.66248321533203|  0:00:25s\n","epoch 39 | loss: 52.50715| val_0_mse: 98.16133117675781|  0:00:26s\n","epoch 40 | loss: 43.1528 | val_0_mse: 51.05126190185547|  0:00:26s\n","epoch 41 | loss: 61.66524| val_0_mse: 107.9517822265625|  0:00:27s\n","epoch 42 | loss: 41.01208| val_0_mse: 41.52156066894531|  0:00:28s\n","epoch 43 | loss: 46.63875| val_0_mse: 66.2039794921875|  0:00:28s\n","epoch 44 | loss: 41.37791| val_0_mse: 36.19684982299805|  0:00:29s\n","epoch 45 | loss: 46.96411| val_0_mse: 34.01525115966797|  0:00:29s\n","epoch 46 | loss: 40.98343| val_0_mse: 35.74156188964844|  0:00:30s\n","epoch 47 | loss: 32.65748| val_0_mse: 25.776460647583008|  0:00:31s\n","epoch 48 | loss: 30.42522| val_0_mse: 38.796451568603516|  0:00:31s\n","epoch 49 | loss: 35.3395 | val_0_mse: 29.974750518798828|  0:00:32s\n","epoch 50 | loss: 47.75342| val_0_mse: 38.2175407409668|  0:00:33s\n","epoch 51 | loss: 42.50142| val_0_mse: 21.06467056274414|  0:00:33s\n","epoch 52 | loss: 42.16336| val_0_mse: 28.4477596282959|  0:00:34s\n","epoch 53 | loss: 37.60503| val_0_mse: 29.10651969909668|  0:00:35s\n","epoch 54 | loss: 40.06555| val_0_mse: 30.60264015197754|  0:00:35s\n","epoch 55 | loss: 49.95934| val_0_mse: 49.069339752197266|  0:00:36s\n","epoch 56 | loss: 41.00144| val_0_mse: 21.473060607910156|  0:00:36s\n","epoch 57 | loss: 40.49692| val_0_mse: 22.061620712280273|  0:00:37s\n","epoch 58 | loss: 33.33344| val_0_mse: 24.6273193359375|  0:00:38s\n","epoch 59 | loss: 36.63182| val_0_mse: 22.093990325927734|  0:00:38s\n","epoch 60 | loss: 32.22181| val_0_mse: 22.564359664916992|  0:00:39s\n","epoch 61 | loss: 35.63612| val_0_mse: 29.65135955810547|  0:00:40s\n","\n","Early stopping occurred at epoch 61 with best_epoch = 51 and best_val_0_mse = 21.06467056274414\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 13:20:54,063] Trial 40 finished with value: 21.064666748046875 and parameters: {'n_d': 54, 'n_steps': 5, 'gamma': 1.1001620217339552, 'n_independent': 3, 'n_shared': 1, 'momentum': 0.12527170668263718}. Best is trial 39 with value: 14.34697437286377.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 2070.55417| val_0_mse: 19277.43359375|  0:00:00s\n","epoch 1  | loss: 1027.66985| val_0_mse: 5408.17236328125|  0:00:01s\n","epoch 2  | loss: 397.6704| val_0_mse: 4854.77685546875|  0:00:02s\n","epoch 3  | loss: 293.31595| val_0_mse: 3736.337158203125|  0:00:03s\n","epoch 4  | loss: 210.62839| val_0_mse: 3870.427001953125|  0:00:04s\n","epoch 5  | loss: 169.57147| val_0_mse: 3159.89306640625|  0:00:05s\n","epoch 6  | loss: 177.01723| val_0_mse: 2719.4501953125|  0:00:05s\n","epoch 7  | loss: 179.34442| val_0_mse: 2503.304931640625|  0:00:06s\n","epoch 8  | loss: 139.55582| val_0_mse: 2578.271240234375|  0:00:07s\n","epoch 9  | loss: 125.25474| val_0_mse: 2630.135986328125|  0:00:08s\n","epoch 10 | loss: 109.43093| val_0_mse: 2568.8154296875|  0:00:09s\n","epoch 11 | loss: 115.43509| val_0_mse: 2556.044677734375|  0:00:10s\n","epoch 12 | loss: 99.14327| val_0_mse: 2543.231201171875|  0:00:11s\n","epoch 13 | loss: 96.84653| val_0_mse: 2319.853271484375|  0:00:12s\n","epoch 14 | loss: 112.71824| val_0_mse: 2094.424560546875|  0:00:12s\n","epoch 15 | loss: 103.67145| val_0_mse: 2187.497314453125|  0:00:13s\n","epoch 16 | loss: 83.15719| val_0_mse: 2536.728759765625|  0:00:14s\n","epoch 17 | loss: 73.87413| val_0_mse: 1906.1695556640625|  0:00:15s\n","epoch 18 | loss: 90.10511| val_0_mse: 1468.9326171875|  0:00:16s\n","epoch 19 | loss: 71.1081 | val_0_mse: 1408.261962890625|  0:00:17s\n","epoch 20 | loss: 71.0159 | val_0_mse: 1255.8179931640625|  0:00:18s\n","epoch 21 | loss: 68.84393| val_0_mse: 975.56201171875|  0:00:18s\n","epoch 22 | loss: 76.76856| val_0_mse: 1064.359375|  0:00:19s\n","epoch 23 | loss: 62.77235| val_0_mse: 900.4341430664062|  0:00:20s\n","epoch 24 | loss: 95.93527| val_0_mse: 966.4989013671875|  0:00:21s\n","epoch 25 | loss: 66.11782| val_0_mse: 263.81396484375|  0:00:22s\n","epoch 26 | loss: 69.92435| val_0_mse: 344.7157897949219|  0:00:23s\n","epoch 27 | loss: 82.82055| val_0_mse: 268.4476318359375|  0:00:24s\n","epoch 28 | loss: 72.79273| val_0_mse: 309.9271545410156|  0:00:25s\n","epoch 29 | loss: 67.1015 | val_0_mse: 260.18609619140625|  0:00:25s\n","epoch 30 | loss: 65.93039| val_0_mse: 143.3185272216797|  0:00:26s\n","epoch 31 | loss: 63.52691| val_0_mse: 102.02394104003906|  0:00:27s\n","epoch 32 | loss: 63.75557| val_0_mse: 151.93556213378906|  0:00:28s\n","epoch 33 | loss: 64.44401| val_0_mse: 164.5850067138672|  0:00:29s\n","epoch 34 | loss: 56.53332| val_0_mse: 157.28469848632812|  0:00:30s\n","epoch 35 | loss: 48.2634 | val_0_mse: 54.973960876464844|  0:00:31s\n","epoch 36 | loss: 62.84566| val_0_mse: 148.75709533691406|  0:00:31s\n","epoch 37 | loss: 61.45928| val_0_mse: 93.07853698730469|  0:00:32s\n","epoch 38 | loss: 53.13919| val_0_mse: 68.12821197509766|  0:00:33s\n","epoch 39 | loss: 58.94489| val_0_mse: 81.28822326660156|  0:00:34s\n","epoch 40 | loss: 51.96886| val_0_mse: 36.763790130615234|  0:00:35s\n","epoch 41 | loss: 51.29836| val_0_mse: 102.88070678710938|  0:00:36s\n","epoch 42 | loss: 60.52393| val_0_mse: 56.79838180541992|  0:00:36s\n","epoch 43 | loss: 54.23372| val_0_mse: 90.69544982910156|  0:00:37s\n","epoch 44 | loss: 55.56099| val_0_mse: 59.99538040161133|  0:00:38s\n","epoch 45 | loss: 66.87352| val_0_mse: 56.64973068237305|  0:00:39s\n","epoch 46 | loss: 51.41307| val_0_mse: 39.215728759765625|  0:00:40s\n","epoch 47 | loss: 62.604  | val_0_mse: 32.974571228027344|  0:00:41s\n","epoch 48 | loss: 43.57544| val_0_mse: 53.89820098876953|  0:00:42s\n","epoch 49 | loss: 52.61491| val_0_mse: 38.7653694152832|  0:00:42s\n","epoch 50 | loss: 50.68845| val_0_mse: 35.3932991027832|  0:00:43s\n","epoch 51 | loss: 48.42278| val_0_mse: 37.14476013183594|  0:00:44s\n","epoch 52 | loss: 42.22675| val_0_mse: 35.47135925292969|  0:00:45s\n","epoch 53 | loss: 41.18454| val_0_mse: 30.748899459838867|  0:00:46s\n","epoch 54 | loss: 52.62323| val_0_mse: 36.06623840332031|  0:00:47s\n","epoch 55 | loss: 51.45047| val_0_mse: 37.22684097290039|  0:00:48s\n","epoch 56 | loss: 47.58058| val_0_mse: 49.163700103759766|  0:00:48s\n","epoch 57 | loss: 67.60309| val_0_mse: 35.41611099243164|  0:00:49s\n","epoch 58 | loss: 60.70822| val_0_mse: 32.08649826049805|  0:00:50s\n","epoch 59 | loss: 55.58685| val_0_mse: 33.794979095458984|  0:00:51s\n","epoch 60 | loss: 42.83811| val_0_mse: 24.572900772094727|  0:00:52s\n","epoch 61 | loss: 45.39379| val_0_mse: 32.28620147705078|  0:00:53s\n","epoch 62 | loss: 43.67675| val_0_mse: 30.823989868164062|  0:00:53s\n","epoch 63 | loss: 74.3549 | val_0_mse: 51.51274108886719|  0:00:54s\n","epoch 64 | loss: 46.64003| val_0_mse: 39.94670104980469|  0:00:55s\n","epoch 65 | loss: 52.29157| val_0_mse: 29.094640731811523|  0:00:56s\n","epoch 66 | loss: 64.19957| val_0_mse: 73.01448059082031|  0:00:57s\n","epoch 67 | loss: 77.6629 | val_0_mse: 43.127620697021484|  0:00:58s\n","epoch 68 | loss: 57.08004| val_0_mse: 37.17631912231445|  0:00:59s\n","epoch 69 | loss: 53.10636| val_0_mse: 27.564199447631836|  0:00:59s\n","epoch 70 | loss: 37.86263| val_0_mse: 26.28447914123535|  0:01:00s\n","\n","Early stopping occurred at epoch 70 with best_epoch = 60 and best_val_0_mse = 24.572900772094727\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 13:21:55,514] Trial 41 finished with value: 24.572900772094727 and parameters: {'n_d': 60, 'n_steps': 4, 'gamma': 1.271396060570067, 'n_independent': 3, 'n_shared': 5, 'momentum': 0.1098856263310288}. Best is trial 39 with value: 14.34697437286377.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 2237.2235| val_0_mse: 4064.575439453125|  0:00:01s\n","epoch 1  | loss: 1427.13437| val_0_mse: 25399.779296875|  0:00:02s\n","epoch 2  | loss: 922.42542| val_0_mse: 18849.6328125|  0:00:03s\n","epoch 3  | loss: 623.75959| val_0_mse: 16780.568359375|  0:00:05s\n","epoch 4  | loss: 599.85769| val_0_mse: 8751.111328125|  0:00:06s\n","epoch 5  | loss: 574.61033| val_0_mse: 36066.08203125|  0:00:07s\n","epoch 6  | loss: 485.77889| val_0_mse: 40819.77734375|  0:00:08s\n","epoch 7  | loss: 455.85318| val_0_mse: 13575.6494140625|  0:00:10s\n","epoch 8  | loss: 425.37925| val_0_mse: 5142.94384765625|  0:00:11s\n","epoch 9  | loss: 366.62514| val_0_mse: 4742.34521484375|  0:00:12s\n","epoch 10 | loss: 325.15439| val_0_mse: 3527.810546875|  0:00:13s\n","epoch 11 | loss: 347.33048| val_0_mse: 3915.842041015625|  0:00:15s\n","epoch 12 | loss: 308.22688| val_0_mse: 3456.565673828125|  0:00:16s\n","epoch 13 | loss: 283.11064| val_0_mse: 2899.6728515625|  0:00:17s\n","epoch 14 | loss: 258.57212| val_0_mse: 2645.14306640625|  0:00:18s\n","epoch 15 | loss: 220.25784| val_0_mse: 2559.278564453125|  0:00:20s\n","epoch 16 | loss: 202.15874| val_0_mse: 2767.197021484375|  0:00:21s\n","epoch 17 | loss: 192.24946| val_0_mse: 2832.975341796875|  0:00:22s\n","epoch 18 | loss: 180.95471| val_0_mse: 2380.9140625|  0:00:23s\n","epoch 19 | loss: 184.60626| val_0_mse: 2134.514892578125|  0:00:25s\n","epoch 20 | loss: 211.62396| val_0_mse: 2017.67626953125|  0:00:26s\n","epoch 21 | loss: 169.14784| val_0_mse: 1672.234130859375|  0:00:27s\n","epoch 22 | loss: 163.04577| val_0_mse: 1567.2742919921875|  0:00:29s\n","epoch 23 | loss: 148.79844| val_0_mse: 1298.5186767578125|  0:00:30s\n","epoch 24 | loss: 162.15324| val_0_mse: 1010.490234375|  0:00:31s\n","epoch 25 | loss: 144.442 | val_0_mse: 1077.825439453125|  0:00:32s\n","epoch 26 | loss: 129.31501| val_0_mse: 853.2283935546875|  0:00:34s\n","epoch 27 | loss: 122.8954| val_0_mse: 631.8628540039062|  0:00:35s\n","epoch 28 | loss: 135.19532| val_0_mse: 728.2713623046875|  0:00:36s\n","epoch 29 | loss: 130.81444| val_0_mse: 290.2464294433594|  0:00:37s\n","epoch 30 | loss: 125.93  | val_0_mse: 628.3428955078125|  0:00:39s\n","epoch 31 | loss: 138.47127| val_0_mse: 265.5290832519531|  0:00:40s\n","epoch 32 | loss: 101.47431| val_0_mse: 459.5094299316406|  0:00:41s\n","epoch 33 | loss: 116.87702| val_0_mse: 307.7180480957031|  0:00:43s\n","epoch 34 | loss: 96.18965| val_0_mse: 174.55784606933594|  0:00:44s\n","epoch 35 | loss: 95.81429| val_0_mse: 113.21481323242188|  0:00:45s\n","epoch 36 | loss: 85.87128| val_0_mse: 166.43603515625|  0:00:46s\n","epoch 37 | loss: 94.65564| val_0_mse: 112.99993896484375|  0:00:48s\n","epoch 38 | loss: 79.14041| val_0_mse: 95.9497299194336|  0:00:49s\n","epoch 39 | loss: 77.7563 | val_0_mse: 110.84443664550781|  0:00:50s\n","epoch 40 | loss: 108.68252| val_0_mse: 84.78865051269531|  0:00:52s\n","epoch 41 | loss: 74.06506| val_0_mse: 66.00666809082031|  0:00:53s\n","epoch 42 | loss: 78.01414| val_0_mse: 58.94715118408203|  0:00:54s\n","epoch 43 | loss: 79.84184| val_0_mse: 66.07621002197266|  0:00:55s\n","epoch 44 | loss: 77.44664| val_0_mse: 80.697021484375|  0:00:57s\n","epoch 45 | loss: 81.23105| val_0_mse: 77.3055419921875|  0:00:58s\n","epoch 46 | loss: 71.67274| val_0_mse: 79.12006378173828|  0:00:59s\n","epoch 47 | loss: 104.89437| val_0_mse: 65.99506378173828|  0:01:00s\n","epoch 48 | loss: 63.34872| val_0_mse: 50.98004150390625|  0:01:02s\n","epoch 49 | loss: 66.80691| val_0_mse: 47.40367889404297|  0:01:03s\n","epoch 50 | loss: 65.0963 | val_0_mse: 68.02088165283203|  0:01:04s\n","epoch 51 | loss: 72.04134| val_0_mse: 54.78464126586914|  0:01:06s\n","epoch 52 | loss: 72.86224| val_0_mse: 33.792198181152344|  0:01:07s\n","epoch 53 | loss: 60.39973| val_0_mse: 35.71112823486328|  0:01:08s\n","epoch 54 | loss: 55.61407| val_0_mse: 43.98394012451172|  0:01:09s\n","epoch 55 | loss: 58.33893| val_0_mse: 31.866559982299805|  0:01:11s\n","epoch 56 | loss: 68.90718| val_0_mse: 44.03342056274414|  0:01:12s\n","epoch 57 | loss: 63.98663| val_0_mse: 34.938438415527344|  0:01:13s\n","epoch 58 | loss: 58.22792| val_0_mse: 48.604270935058594|  0:01:14s\n","epoch 59 | loss: 62.44793| val_0_mse: 58.96821975708008|  0:01:16s\n","epoch 60 | loss: 59.63261| val_0_mse: 31.503389358520508|  0:01:17s\n","epoch 61 | loss: 60.84623| val_0_mse: 53.860328674316406|  0:01:18s\n","epoch 62 | loss: 63.80125| val_0_mse: 40.359920501708984|  0:01:19s\n","epoch 63 | loss: 55.05347| val_0_mse: 52.72475814819336|  0:01:21s\n","epoch 64 | loss: 59.70564| val_0_mse: 39.1007194519043|  0:01:22s\n","epoch 65 | loss: 56.60806| val_0_mse: 30.551559448242188|  0:01:23s\n","epoch 66 | loss: 44.86006| val_0_mse: 25.969030380249023|  0:01:24s\n","epoch 67 | loss: 44.96659| val_0_mse: 26.638229370117188|  0:01:26s\n","epoch 68 | loss: 54.8393 | val_0_mse: 22.84391975402832|  0:01:27s\n","epoch 69 | loss: 50.20964| val_0_mse: 27.5338191986084|  0:01:28s\n","epoch 70 | loss: 49.7085 | val_0_mse: 32.953468322753906|  0:01:29s\n","epoch 71 | loss: 54.42692| val_0_mse: 39.771881103515625|  0:01:31s\n","epoch 72 | loss: 57.31764| val_0_mse: 33.88507080078125|  0:01:32s\n","epoch 73 | loss: 64.23106| val_0_mse: 36.08610153198242|  0:01:33s\n","epoch 74 | loss: 86.89331| val_0_mse: 69.01634216308594|  0:01:34s\n","epoch 75 | loss: 72.16528| val_0_mse: 56.25828170776367|  0:01:36s\n","epoch 76 | loss: 56.42508| val_0_mse: 33.79066848754883|  0:01:37s\n","epoch 77 | loss: 57.94369| val_0_mse: 28.58930015563965|  0:01:38s\n","epoch 78 | loss: 63.569  | val_0_mse: 50.70452117919922|  0:01:39s\n","\n","Early stopping occurred at epoch 78 with best_epoch = 68 and best_val_0_mse = 22.84391975402832\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 13:23:36,009] Trial 42 finished with value: 22.843921661376953 and parameters: {'n_d': 52, 'n_steps': 6, 'gamma': 1.346433077310622, 'n_independent': 4, 'n_shared': 5, 'momentum': 0.07914808541724402}. Best is trial 39 with value: 14.34697437286377.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 2217.1998| val_0_mse: 2904.459228515625|  0:00:00s\n","epoch 1  | loss: 1031.19051| val_0_mse: 2680.791748046875|  0:00:01s\n","epoch 2  | loss: 360.37154| val_0_mse: 5027.56689453125|  0:00:02s\n","epoch 3  | loss: 218.24341| val_0_mse: 2672.0048828125|  0:00:02s\n","epoch 4  | loss: 188.9568| val_0_mse: 2547.525390625|  0:00:03s\n","epoch 5  | loss: 147.74396| val_0_mse: 2579.71484375|  0:00:04s\n","epoch 6  | loss: 130.1839| val_0_mse: 2637.3662109375|  0:00:04s\n","epoch 7  | loss: 144.09888| val_0_mse: 2615.87744140625|  0:00:05s\n","epoch 8  | loss: 131.78771| val_0_mse: 2631.8291015625|  0:00:06s\n","epoch 9  | loss: 118.52678| val_0_mse: 2568.72802734375|  0:00:06s\n","epoch 10 | loss: 108.42419| val_0_mse: 2608.320556640625|  0:00:07s\n","epoch 11 | loss: 114.56597| val_0_mse: 2546.148193359375|  0:00:08s\n","epoch 12 | loss: 96.25906| val_0_mse: 2565.20556640625|  0:00:09s\n","epoch 13 | loss: 109.56608| val_0_mse: 2533.118896484375|  0:00:09s\n","epoch 14 | loss: 83.06906| val_0_mse: 2561.3486328125|  0:00:10s\n","epoch 15 | loss: 79.62438| val_0_mse: 2535.06689453125|  0:00:11s\n","epoch 16 | loss: 86.48128| val_0_mse: 2525.120361328125|  0:00:11s\n","epoch 17 | loss: 79.48904| val_0_mse: 2545.47119140625|  0:00:12s\n","epoch 18 | loss: 66.41127| val_0_mse: 2594.119384765625|  0:00:13s\n","epoch 19 | loss: 63.44827| val_0_mse: 2255.69970703125|  0:00:13s\n","epoch 20 | loss: 59.6332 | val_0_mse: 2149.986083984375|  0:00:14s\n","epoch 21 | loss: 55.522  | val_0_mse: 2092.52392578125|  0:00:15s\n","epoch 22 | loss: 57.80521| val_0_mse: 1857.2769775390625|  0:00:15s\n","epoch 23 | loss: 63.18028| val_0_mse: 1655.3824462890625|  0:00:16s\n","epoch 24 | loss: 61.34148| val_0_mse: 1401.298828125|  0:00:17s\n","epoch 25 | loss: 72.18936| val_0_mse: 1137.3427734375|  0:00:18s\n","epoch 26 | loss: 85.96614| val_0_mse: 965.8821411132812|  0:00:18s\n","epoch 27 | loss: 65.74933| val_0_mse: 868.9436645507812|  0:00:19s\n","epoch 28 | loss: 54.7741 | val_0_mse: 696.7167358398438|  0:00:20s\n","epoch 29 | loss: 65.59632| val_0_mse: 489.0033874511719|  0:00:20s\n","epoch 30 | loss: 59.06152| val_0_mse: 351.35430908203125|  0:00:21s\n","epoch 31 | loss: 48.71695| val_0_mse: 283.3158264160156|  0:00:22s\n","epoch 32 | loss: 47.91971| val_0_mse: 312.8321228027344|  0:00:22s\n","epoch 33 | loss: 50.10529| val_0_mse: 170.74505615234375|  0:00:23s\n","epoch 34 | loss: 48.47049| val_0_mse: 215.27716064453125|  0:00:24s\n","epoch 35 | loss: 51.74905| val_0_mse: 144.9497833251953|  0:00:24s\n","epoch 36 | loss: 41.14679| val_0_mse: 123.990966796875|  0:00:25s\n","epoch 37 | loss: 43.06546| val_0_mse: 94.69583129882812|  0:00:26s\n","epoch 38 | loss: 53.98984| val_0_mse: 91.66246795654297|  0:00:27s\n","epoch 39 | loss: 53.04727| val_0_mse: 104.9368667602539|  0:00:27s\n","epoch 40 | loss: 49.80771| val_0_mse: 78.59480285644531|  0:00:28s\n","epoch 41 | loss: 45.84442| val_0_mse: 76.6740493774414|  0:00:29s\n","epoch 42 | loss: 38.27113| val_0_mse: 74.45982360839844|  0:00:29s\n","epoch 43 | loss: 44.80668| val_0_mse: 65.71742248535156|  0:00:30s\n","epoch 44 | loss: 66.18701| val_0_mse: 67.65313720703125|  0:00:31s\n","epoch 45 | loss: 50.32329| val_0_mse: 44.76110076904297|  0:00:32s\n","epoch 46 | loss: 42.61742| val_0_mse: 27.91827964782715|  0:00:32s\n","epoch 47 | loss: 45.60175| val_0_mse: 23.184919357299805|  0:00:33s\n","epoch 48 | loss: 39.049  | val_0_mse: 26.213529586791992|  0:00:34s\n","epoch 49 | loss: 33.21955| val_0_mse: 31.960920333862305|  0:00:34s\n","epoch 50 | loss: 42.75014| val_0_mse: 60.33750915527344|  0:00:35s\n","epoch 51 | loss: 48.5554 | val_0_mse: 36.42533874511719|  0:00:36s\n","epoch 52 | loss: 45.82829| val_0_mse: 26.626659393310547|  0:00:36s\n","epoch 53 | loss: 36.8437 | val_0_mse: 33.36661148071289|  0:00:37s\n","epoch 54 | loss: 37.69809| val_0_mse: 27.34695053100586|  0:00:38s\n","epoch 55 | loss: 34.67325| val_0_mse: 33.09832000732422|  0:00:38s\n","epoch 56 | loss: 30.10493| val_0_mse: 27.753400802612305|  0:00:39s\n","epoch 57 | loss: 42.45104| val_0_mse: 36.96937942504883|  0:00:40s\n","\n","Early stopping occurred at epoch 57 with best_epoch = 47 and best_val_0_mse = 23.184919357299805\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 13:24:16,579] Trial 43 finished with value: 23.184925079345703 and parameters: {'n_d': 42, 'n_steps': 3, 'gamma': 1.1865096406953055, 'n_independent': 3, 'n_shared': 5, 'momentum': 0.16174420772052164}. Best is trial 39 with value: 14.34697437286377.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 2325.32484| val_0_mse: 5570.9755859375|  0:00:00s\n","epoch 1  | loss: 1682.98805| val_0_mse: 4919.92822265625|  0:00:01s\n","epoch 2  | loss: 1183.21144| val_0_mse: 9131.9150390625|  0:00:02s\n","epoch 3  | loss: 757.16056| val_0_mse: 8295.7001953125|  0:00:03s\n","epoch 4  | loss: 442.67722| val_0_mse: 4903.5009765625|  0:00:04s\n","epoch 5  | loss: 354.8064| val_0_mse: 7984.65869140625|  0:00:05s\n","epoch 6  | loss: 281.99657| val_0_mse: 3781.387939453125|  0:00:06s\n","epoch 7  | loss: 246.83328| val_0_mse: 3605.57861328125|  0:00:07s\n","epoch 8  | loss: 271.13411| val_0_mse: 2927.656982421875|  0:00:08s\n","epoch 9  | loss: 228.90757| val_0_mse: 2795.297607421875|  0:00:08s\n","epoch 10 | loss: 173.03482| val_0_mse: 2991.470703125|  0:00:09s\n","epoch 11 | loss: 146.07717| val_0_mse: 2614.137451171875|  0:00:10s\n","epoch 12 | loss: 139.3155| val_0_mse: 2481.3671875|  0:00:11s\n","epoch 13 | loss: 129.19045| val_0_mse: 2363.80712890625|  0:00:12s\n","epoch 14 | loss: 150.3327| val_0_mse: 2758.54443359375|  0:00:13s\n","epoch 15 | loss: 147.54682| val_0_mse: 2382.90673828125|  0:00:14s\n","epoch 16 | loss: 142.38471| val_0_mse: 2164.395751953125|  0:00:15s\n","epoch 17 | loss: 110.38988| val_0_mse: 2167.457275390625|  0:00:16s\n","epoch 18 | loss: 95.88447| val_0_mse: 1935.978515625|  0:00:17s\n","epoch 19 | loss: 110.60376| val_0_mse: 1829.2786865234375|  0:00:17s\n","epoch 20 | loss: 92.96365| val_0_mse: 1687.1800537109375|  0:00:18s\n","epoch 21 | loss: 93.04558| val_0_mse: 1369.7197265625|  0:00:19s\n","epoch 22 | loss: 79.57413| val_0_mse: 1321.8472900390625|  0:00:20s\n","epoch 23 | loss: 85.94848| val_0_mse: 1276.068359375|  0:00:21s\n","epoch 24 | loss: 86.93148| val_0_mse: 1053.06298828125|  0:00:22s\n","epoch 25 | loss: 68.24359| val_0_mse: 807.8444213867188|  0:00:23s\n","epoch 26 | loss: 92.13948| val_0_mse: 625.327392578125|  0:00:24s\n","epoch 27 | loss: 91.88457| val_0_mse: 500.8499450683594|  0:00:25s\n","epoch 28 | loss: 94.23423| val_0_mse: 639.8206787109375|  0:00:26s\n","epoch 29 | loss: 107.36936| val_0_mse: 454.6885681152344|  0:00:27s\n","epoch 30 | loss: 109.63171| val_0_mse: 462.15740966796875|  0:00:28s\n","epoch 31 | loss: 96.40971| val_0_mse: 492.9305725097656|  0:00:28s\n","epoch 32 | loss: 101.10563| val_0_mse: 317.0527648925781|  0:00:29s\n","epoch 33 | loss: 94.10443| val_0_mse: 180.678466796875|  0:00:30s\n","epoch 34 | loss: 106.33176| val_0_mse: 270.7061462402344|  0:00:31s\n","epoch 35 | loss: 88.9444 | val_0_mse: 152.41737365722656|  0:00:32s\n","epoch 36 | loss: 85.30265| val_0_mse: 168.16473388671875|  0:00:33s\n","epoch 37 | loss: 78.7912 | val_0_mse: 71.11953735351562|  0:00:34s\n","epoch 38 | loss: 83.48563| val_0_mse: 126.6312026977539|  0:00:35s\n","epoch 39 | loss: 80.01423| val_0_mse: 64.53124237060547|  0:00:36s\n","epoch 40 | loss: 77.88322| val_0_mse: 125.59013366699219|  0:00:37s\n","epoch 41 | loss: 67.40679| val_0_mse: 95.94013214111328|  0:00:37s\n","epoch 42 | loss: 70.11316| val_0_mse: 57.72507858276367|  0:00:38s\n","epoch 43 | loss: 88.81504| val_0_mse: 99.6095962524414|  0:00:39s\n","epoch 44 | loss: 73.33417| val_0_mse: 60.23529052734375|  0:00:40s\n","epoch 45 | loss: 62.44032| val_0_mse: 46.432579040527344|  0:00:41s\n","epoch 46 | loss: 57.29969| val_0_mse: 53.5836296081543|  0:00:42s\n","epoch 47 | loss: 70.63942| val_0_mse: 71.35449981689453|  0:00:43s\n","epoch 48 | loss: 66.0642 | val_0_mse: 41.65156936645508|  0:00:44s\n","epoch 49 | loss: 76.59551| val_0_mse: 33.808311462402344|  0:00:45s\n","epoch 50 | loss: 59.19978| val_0_mse: 31.683080673217773|  0:00:46s\n","epoch 51 | loss: 55.69516| val_0_mse: 46.1131591796875|  0:00:47s\n","epoch 52 | loss: 56.05881| val_0_mse: 30.52651023864746|  0:00:48s\n","epoch 53 | loss: 53.91533| val_0_mse: 49.181400299072266|  0:00:48s\n","epoch 54 | loss: 70.74269| val_0_mse: 33.685359954833984|  0:00:49s\n","epoch 55 | loss: 69.15824| val_0_mse: 55.883419036865234|  0:00:50s\n","epoch 56 | loss: 72.37508| val_0_mse: 56.01102066040039|  0:00:51s\n","epoch 57 | loss: 53.86158| val_0_mse: 27.15648078918457|  0:00:52s\n","epoch 58 | loss: 52.24653| val_0_mse: 24.89859962463379|  0:00:53s\n","epoch 59 | loss: 56.09723| val_0_mse: 44.72703170776367|  0:00:54s\n","epoch 60 | loss: 53.9393 | val_0_mse: 49.306480407714844|  0:00:55s\n","epoch 61 | loss: 61.1556 | val_0_mse: 37.11861038208008|  0:00:56s\n","epoch 62 | loss: 59.41623| val_0_mse: 46.38587188720703|  0:00:57s\n","epoch 63 | loss: 63.8329 | val_0_mse: 30.720849990844727|  0:00:58s\n","epoch 64 | loss: 58.20154| val_0_mse: 39.158748626708984|  0:00:58s\n","epoch 65 | loss: 59.15668| val_0_mse: 37.43782043457031|  0:00:59s\n","epoch 66 | loss: 60.17509| val_0_mse: 27.493860244750977|  0:01:00s\n","epoch 67 | loss: 46.46432| val_0_mse: 34.419830322265625|  0:01:01s\n","epoch 68 | loss: 51.46656| val_0_mse: 27.774009704589844|  0:01:02s\n","\n","Early stopping occurred at epoch 68 with best_epoch = 58 and best_val_0_mse = 24.89859962463379\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 13:25:19,554] Trial 44 finished with value: 24.89859962463379 and parameters: {'n_d': 55, 'n_steps': 5, 'gamma': 1.5180464398609392, 'n_independent': 2, 'n_shared': 5, 'momentum': 0.300425125461118}. Best is trial 39 with value: 14.34697437286377.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 2088.78845| val_0_mse: 7244.97021484375|  0:00:00s\n","epoch 1  | loss: 912.88875| val_0_mse: 11267.1787109375|  0:00:01s\n","epoch 2  | loss: 384.18428| val_0_mse: 8767.8173828125|  0:00:02s\n","epoch 3  | loss: 250.73962| val_0_mse: 3942.03369140625|  0:00:03s\n","epoch 4  | loss: 209.35583| val_0_mse: 3401.5703125|  0:00:04s\n","epoch 5  | loss: 211.52803| val_0_mse: 2682.591552734375|  0:00:05s\n","epoch 6  | loss: 170.54929| val_0_mse: 2635.34423828125|  0:00:05s\n","epoch 7  | loss: 156.72276| val_0_mse: 2972.212890625|  0:00:06s\n","epoch 8  | loss: 162.9595| val_0_mse: 2970.5341796875|  0:00:07s\n","epoch 9  | loss: 158.54563| val_0_mse: 2855.40673828125|  0:00:08s\n","epoch 10 | loss: 154.3744| val_0_mse: 3015.028076171875|  0:00:09s\n","epoch 11 | loss: 109.39524| val_0_mse: 2771.52001953125|  0:00:10s\n","epoch 12 | loss: 123.78633| val_0_mse: 2698.970458984375|  0:00:10s\n","epoch 13 | loss: 123.90396| val_0_mse: 2835.010986328125|  0:00:11s\n","epoch 14 | loss: 111.70399| val_0_mse: 2370.498779296875|  0:00:12s\n","epoch 15 | loss: 122.2212| val_0_mse: 2258.80810546875|  0:00:13s\n","epoch 16 | loss: 106.19219| val_0_mse: 2336.56201171875|  0:00:14s\n","epoch 17 | loss: 83.18326| val_0_mse: 1961.841552734375|  0:00:15s\n","epoch 18 | loss: 89.31852| val_0_mse: 1733.97802734375|  0:00:15s\n","epoch 19 | loss: 83.01018| val_0_mse: 1726.0670166015625|  0:00:16s\n","epoch 20 | loss: 73.44024| val_0_mse: 1373.87548828125|  0:00:17s\n","epoch 21 | loss: 78.17658| val_0_mse: 1026.637451171875|  0:00:18s\n","epoch 22 | loss: 91.06959| val_0_mse: 999.338134765625|  0:00:19s\n","epoch 23 | loss: 87.1385 | val_0_mse: 887.7760009765625|  0:00:20s\n","epoch 24 | loss: 92.71153| val_0_mse: 516.8316040039062|  0:00:21s\n","epoch 25 | loss: 89.10236| val_0_mse: 453.8854675292969|  0:00:21s\n","epoch 26 | loss: 78.52074| val_0_mse: 511.2003479003906|  0:00:22s\n","epoch 27 | loss: 78.59359| val_0_mse: 459.5562438964844|  0:00:23s\n","epoch 28 | loss: 67.51562| val_0_mse: 348.1683349609375|  0:00:24s\n","epoch 29 | loss: 59.85229| val_0_mse: 275.1767883300781|  0:00:25s\n","epoch 30 | loss: 65.31847| val_0_mse: 266.31719970703125|  0:00:26s\n","epoch 31 | loss: 58.76647| val_0_mse: 187.1255340576172|  0:00:27s\n","epoch 32 | loss: 58.19391| val_0_mse: 144.35511779785156|  0:00:28s\n","epoch 33 | loss: 58.51896| val_0_mse: 168.3568572998047|  0:00:28s\n","epoch 34 | loss: 69.33371| val_0_mse: 151.4063720703125|  0:00:29s\n","epoch 35 | loss: 55.23699| val_0_mse: 77.82166290283203|  0:00:30s\n","epoch 36 | loss: 51.44433| val_0_mse: 125.9558334350586|  0:00:31s\n","epoch 37 | loss: 53.69333| val_0_mse: 106.81816864013672|  0:00:32s\n","epoch 38 | loss: 61.22874| val_0_mse: 68.60186004638672|  0:00:33s\n","epoch 39 | loss: 60.88354| val_0_mse: 73.8250503540039|  0:00:34s\n","epoch 40 | loss: 55.77809| val_0_mse: 105.49227142333984|  0:00:34s\n","epoch 41 | loss: 62.95615| val_0_mse: 72.16963195800781|  0:00:35s\n","epoch 42 | loss: 64.38599| val_0_mse: 72.05876922607422|  0:00:36s\n","epoch 43 | loss: 56.77329| val_0_mse: 65.65142822265625|  0:00:37s\n","epoch 44 | loss: 53.10347| val_0_mse: 64.35086822509766|  0:00:38s\n","epoch 45 | loss: 62.25091| val_0_mse: 55.391441345214844|  0:00:39s\n","epoch 46 | loss: 53.73713| val_0_mse: 29.09752082824707|  0:00:40s\n","epoch 47 | loss: 56.34072| val_0_mse: 58.66592025756836|  0:00:41s\n","epoch 48 | loss: 47.69281| val_0_mse: 30.320039749145508|  0:00:41s\n","epoch 49 | loss: 45.93899| val_0_mse: 40.695308685302734|  0:00:42s\n","epoch 50 | loss: 43.5947 | val_0_mse: 37.66331100463867|  0:00:43s\n","epoch 51 | loss: 50.86173| val_0_mse: 35.6301383972168|  0:00:44s\n","epoch 52 | loss: 51.80116| val_0_mse: 43.71385955810547|  0:00:45s\n","epoch 53 | loss: 57.04527| val_0_mse: 54.7635383605957|  0:00:46s\n","epoch 54 | loss: 54.17861| val_0_mse: 30.49835968017578|  0:00:47s\n","epoch 55 | loss: 42.12594| val_0_mse: 37.14073944091797|  0:00:47s\n","epoch 56 | loss: 60.68959| val_0_mse: 48.90938186645508|  0:00:48s\n","\n","Early stopping occurred at epoch 56 with best_epoch = 46 and best_val_0_mse = 29.09752082824707\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 13:26:08,917] Trial 45 finished with value: 29.097515106201172 and parameters: {'n_d': 48, 'n_steps': 4, 'gamma': 1.2328643115730864, 'n_independent': 4, 'n_shared': 4, 'momentum': 0.36244048728017836}. Best is trial 39 with value: 14.34697437286377.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 2276.24272| val_0_mse: 4168.400390625|  0:00:00s\n","epoch 1  | loss: 1217.24213| val_0_mse: 3486.43701171875|  0:00:01s\n","epoch 2  | loss: 507.18066| val_0_mse: 4156.685546875|  0:00:02s\n","epoch 3  | loss: 343.23931| val_0_mse: 3120.00341796875|  0:00:03s\n","epoch 4  | loss: 287.45221| val_0_mse: 3256.896728515625|  0:00:04s\n","epoch 5  | loss: 206.89981| val_0_mse: 2674.89794921875|  0:00:05s\n","epoch 6  | loss: 187.44779| val_0_mse: 2600.07421875|  0:00:05s\n","epoch 7  | loss: 190.26508| val_0_mse: 2680.193115234375|  0:00:06s\n","epoch 8  | loss: 192.13075| val_0_mse: 2655.00146484375|  0:00:07s\n","epoch 9  | loss: 185.44408| val_0_mse: 2781.35595703125|  0:00:08s\n","epoch 10 | loss: 176.61657| val_0_mse: 2667.04638671875|  0:00:09s\n","epoch 11 | loss: 148.63209| val_0_mse: 2764.021240234375|  0:00:10s\n","epoch 12 | loss: 162.47963| val_0_mse: 2587.8916015625|  0:00:11s\n","epoch 13 | loss: 143.86009| val_0_mse: 2589.811767578125|  0:00:11s\n","epoch 14 | loss: 134.60873| val_0_mse: 2448.03759765625|  0:00:12s\n","epoch 15 | loss: 126.80197| val_0_mse: 2488.47509765625|  0:00:13s\n","epoch 16 | loss: 137.00106| val_0_mse: 2496.06640625|  0:00:14s\n","epoch 17 | loss: 119.74882| val_0_mse: 2091.22998046875|  0:00:15s\n","epoch 18 | loss: 117.69069| val_0_mse: 1846.5401611328125|  0:00:16s\n","epoch 19 | loss: 128.50858| val_0_mse: 1781.6551513671875|  0:00:17s\n","epoch 20 | loss: 122.51348| val_0_mse: 1836.684326171875|  0:00:17s\n","epoch 21 | loss: 120.99473| val_0_mse: 1757.15234375|  0:00:18s\n","epoch 22 | loss: 101.3445| val_0_mse: 1109.529541015625|  0:00:19s\n","epoch 23 | loss: 109.76736| val_0_mse: 826.4108276367188|  0:00:20s\n","epoch 24 | loss: 98.50105| val_0_mse: 746.8673095703125|  0:00:21s\n","epoch 25 | loss: 85.47422| val_0_mse: 528.4271850585938|  0:00:22s\n","epoch 26 | loss: 83.92201| val_0_mse: 482.71759033203125|  0:00:22s\n","epoch 27 | loss: 105.48478| val_0_mse: 406.0048522949219|  0:00:23s\n","epoch 28 | loss: 86.30176| val_0_mse: 338.9363708496094|  0:00:24s\n","epoch 29 | loss: 84.54872| val_0_mse: 416.46807861328125|  0:00:25s\n","epoch 30 | loss: 92.0864 | val_0_mse: 281.5400695800781|  0:00:26s\n","epoch 31 | loss: 85.82644| val_0_mse: 372.99462890625|  0:00:27s\n","epoch 32 | loss: 90.91421| val_0_mse: 227.6072540283203|  0:00:28s\n","epoch 33 | loss: 87.68668| val_0_mse: 144.28407287597656|  0:00:28s\n","epoch 34 | loss: 73.33372| val_0_mse: 152.18699645996094|  0:00:29s\n","epoch 35 | loss: 70.15492| val_0_mse: 162.32655334472656|  0:00:30s\n","epoch 36 | loss: 77.6558 | val_0_mse: 132.3675537109375|  0:00:31s\n","epoch 37 | loss: 77.94382| val_0_mse: 127.78938293457031|  0:00:32s\n","epoch 38 | loss: 76.1105 | val_0_mse: 123.51283264160156|  0:00:33s\n","epoch 39 | loss: 63.6156 | val_0_mse: 69.69132232666016|  0:00:33s\n","epoch 40 | loss: 76.49806| val_0_mse: 74.4049301147461|  0:00:34s\n","epoch 41 | loss: 61.64962| val_0_mse: 60.57305145263672|  0:00:35s\n","epoch 42 | loss: 63.34882| val_0_mse: 72.98787689208984|  0:00:36s\n","epoch 43 | loss: 65.30342| val_0_mse: 59.688480377197266|  0:00:37s\n","epoch 44 | loss: 61.6207 | val_0_mse: 81.7808609008789|  0:00:38s\n","epoch 45 | loss: 80.15536| val_0_mse: 60.7387809753418|  0:00:38s\n","epoch 46 | loss: 57.22272| val_0_mse: 50.67789840698242|  0:00:39s\n","epoch 47 | loss: 52.21549| val_0_mse: 51.77653884887695|  0:00:40s\n","epoch 48 | loss: 51.2831 | val_0_mse: 51.17911911010742|  0:00:41s\n","epoch 49 | loss: 55.41862| val_0_mse: 46.202980041503906|  0:00:42s\n","epoch 50 | loss: 67.68435| val_0_mse: 82.0785903930664|  0:00:43s\n","epoch 51 | loss: 66.94416| val_0_mse: 53.44559860229492|  0:00:44s\n","epoch 52 | loss: 56.9099 | val_0_mse: 61.89155960083008|  0:00:44s\n","epoch 53 | loss: 63.66069| val_0_mse: 61.72793960571289|  0:00:45s\n","epoch 54 | loss: 64.17597| val_0_mse: 89.34520721435547|  0:00:46s\n","epoch 55 | loss: 91.64261| val_0_mse: 96.21399688720703|  0:00:47s\n","epoch 56 | loss: 90.6612 | val_0_mse: 73.15274047851562|  0:00:48s\n","epoch 57 | loss: 70.41326| val_0_mse: 51.083038330078125|  0:00:49s\n","epoch 58 | loss: 66.15094| val_0_mse: 52.109161376953125|  0:00:49s\n","epoch 59 | loss: 87.4715 | val_0_mse: 78.40492248535156|  0:00:50s\n","\n","Early stopping occurred at epoch 59 with best_epoch = 49 and best_val_0_mse = 46.202980041503906\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 13:27:00,219] Trial 46 finished with value: 46.202980041503906 and parameters: {'n_d': 39, 'n_steps': 4, 'gamma': 1.4683515706498367, 'n_independent': 3, 'n_shared': 5, 'momentum': 0.12142965881144696}. Best is trial 39 with value: 14.34697437286377.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 2250.84802| val_0_mse: 2599.015869140625|  0:00:00s\n","epoch 1  | loss: 1013.92716| val_0_mse: 3046.41064453125|  0:00:01s\n","epoch 2  | loss: 355.92865| val_0_mse: 4188.37060546875|  0:00:01s\n","epoch 3  | loss: 233.3322| val_0_mse: 2416.031005859375|  0:00:02s\n","epoch 4  | loss: 188.09127| val_0_mse: 2984.63671875|  0:00:02s\n","epoch 5  | loss: 143.10924| val_0_mse: 2723.207275390625|  0:00:03s\n","epoch 6  | loss: 150.08418| val_0_mse: 2487.807373046875|  0:00:04s\n","epoch 7  | loss: 126.94203| val_0_mse: 2554.243896484375|  0:00:04s\n","epoch 8  | loss: 115.83839| val_0_mse: 2616.225830078125|  0:00:05s\n","epoch 9  | loss: 117.07003| val_0_mse: 2794.957763671875|  0:00:05s\n","epoch 10 | loss: 111.19319| val_0_mse: 2579.966552734375|  0:00:06s\n","epoch 11 | loss: 107.90096| val_0_mse: 2528.57421875|  0:00:06s\n","epoch 12 | loss: 85.22575| val_0_mse: 2553.67431640625|  0:00:07s\n","epoch 13 | loss: 91.97795| val_0_mse: 2515.34912109375|  0:00:08s\n","\n","Early stopping occurred at epoch 13 with best_epoch = 3 and best_val_0_mse = 2416.031005859375\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 13:27:08,652] Trial 47 finished with value: 2416.031005859375 and parameters: {'n_d': 50, 'n_steps': 3, 'gamma': 1.3927221882925125, 'n_independent': 2, 'n_shared': 4, 'momentum': 0.08078877756360363}. Best is trial 39 with value: 14.34697437286377.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 2133.99512| val_0_mse: 4415.654296875|  0:00:00s\n","epoch 1  | loss: 1130.02517| val_0_mse: 3151.37890625|  0:00:01s\n","epoch 2  | loss: 584.622 | val_0_mse: 4947.95068359375|  0:00:01s\n","epoch 3  | loss: 340.82125| val_0_mse: 3192.663330078125|  0:00:02s\n","epoch 4  | loss: 278.98131| val_0_mse: 3063.314453125|  0:00:03s\n","epoch 5  | loss: 198.88002| val_0_mse: 2704.558349609375|  0:00:03s\n","epoch 6  | loss: 166.03568| val_0_mse: 2824.095458984375|  0:00:04s\n","epoch 7  | loss: 164.7413| val_0_mse: 2508.57373046875|  0:00:05s\n","epoch 8  | loss: 132.77945| val_0_mse: 2607.352294921875|  0:00:05s\n","epoch 9  | loss: 135.35856| val_0_mse: 2453.194580078125|  0:00:06s\n","epoch 10 | loss: 111.33942| val_0_mse: 2410.21044921875|  0:00:06s\n","epoch 11 | loss: 113.62393| val_0_mse: 2584.193603515625|  0:00:07s\n","epoch 12 | loss: 97.40343| val_0_mse: 2493.475341796875|  0:00:08s\n","epoch 13 | loss: 92.97145| val_0_mse: 2489.9814453125|  0:00:08s\n","epoch 14 | loss: 85.77607| val_0_mse: 2441.91259765625|  0:00:09s\n","epoch 15 | loss: 87.74078| val_0_mse: 2280.037109375|  0:00:09s\n","epoch 16 | loss: 75.76483| val_0_mse: 2084.438232421875|  0:00:10s\n","epoch 17 | loss: 76.41562| val_0_mse: 1992.327392578125|  0:00:11s\n","epoch 18 | loss: 73.81526| val_0_mse: 1864.1396484375|  0:00:11s\n","epoch 19 | loss: 74.08278| val_0_mse: 1707.2708740234375|  0:00:12s\n","epoch 20 | loss: 61.91085| val_0_mse: 1484.709716796875|  0:00:13s\n","epoch 21 | loss: 66.43151| val_0_mse: 1311.9605712890625|  0:00:13s\n","epoch 22 | loss: 59.52746| val_0_mse: 987.7894287109375|  0:00:14s\n","epoch 23 | loss: 64.24256| val_0_mse: 912.1041870117188|  0:00:15s\n","epoch 24 | loss: 69.11782| val_0_mse: 713.56982421875|  0:00:15s\n","epoch 25 | loss: 83.20977| val_0_mse: 653.7818603515625|  0:00:16s\n","epoch 26 | loss: 66.63585| val_0_mse: 456.3643493652344|  0:00:17s\n","epoch 27 | loss: 60.03375| val_0_mse: 389.1664123535156|  0:00:17s\n","epoch 28 | loss: 57.05536| val_0_mse: 391.4180908203125|  0:00:18s\n","epoch 29 | loss: 52.60686| val_0_mse: 325.53277587890625|  0:00:18s\n","epoch 30 | loss: 52.4733 | val_0_mse: 245.4032745361328|  0:00:19s\n","epoch 31 | loss: 50.65605| val_0_mse: 230.6109619140625|  0:00:20s\n","epoch 32 | loss: 66.55095| val_0_mse: 114.436767578125|  0:00:20s\n","epoch 33 | loss: 51.96913| val_0_mse: 160.32247924804688|  0:00:21s\n","epoch 34 | loss: 56.27044| val_0_mse: 127.47110748291016|  0:00:22s\n","epoch 35 | loss: 47.85011| val_0_mse: 88.46013641357422|  0:00:22s\n","epoch 36 | loss: 50.57642| val_0_mse: 96.70414733886719|  0:00:23s\n","epoch 37 | loss: 55.49649| val_0_mse: 123.87014770507812|  0:00:23s\n","epoch 38 | loss: 59.52548| val_0_mse: 110.92498779296875|  0:00:24s\n","epoch 39 | loss: 53.63251| val_0_mse: 65.27143859863281|  0:00:25s\n","epoch 40 | loss: 52.94499| val_0_mse: 79.25647735595703|  0:00:25s\n","epoch 41 | loss: 51.46439| val_0_mse: 72.5672836303711|  0:00:26s\n","epoch 42 | loss: 48.07681| val_0_mse: 52.822898864746094|  0:00:27s\n","epoch 43 | loss: 45.08033| val_0_mse: 42.70920181274414|  0:00:27s\n","epoch 44 | loss: 38.58646| val_0_mse: 41.57619094848633|  0:00:28s\n","epoch 45 | loss: 40.68762| val_0_mse: 54.97637176513672|  0:00:28s\n","epoch 46 | loss: 46.26024| val_0_mse: 56.87984085083008|  0:00:29s\n","epoch 47 | loss: 44.21038| val_0_mse: 68.20036315917969|  0:00:30s\n","epoch 48 | loss: 38.03601| val_0_mse: 43.03982162475586|  0:00:30s\n","epoch 49 | loss: 42.13346| val_0_mse: 39.28247833251953|  0:00:31s\n","epoch 50 | loss: 51.6696 | val_0_mse: 25.105789184570312|  0:00:32s\n","epoch 51 | loss: 44.06604| val_0_mse: 24.319580078125|  0:00:32s\n","epoch 52 | loss: 44.94702| val_0_mse: 38.4133186340332|  0:00:33s\n","epoch 53 | loss: 50.30349| val_0_mse: 24.877349853515625|  0:00:33s\n","epoch 54 | loss: 36.66144| val_0_mse: 25.63450050354004|  0:00:34s\n","epoch 55 | loss: 44.97835| val_0_mse: 27.789840698242188|  0:00:35s\n","epoch 56 | loss: 39.77969| val_0_mse: 28.404600143432617|  0:00:35s\n","epoch 57 | loss: 49.13334| val_0_mse: 41.66408920288086|  0:00:36s\n","epoch 58 | loss: 44.34795| val_0_mse: 37.93782043457031|  0:00:37s\n","epoch 59 | loss: 42.55397| val_0_mse: 41.2831916809082|  0:00:37s\n","epoch 60 | loss: 56.21814| val_0_mse: 32.822959899902344|  0:00:38s\n","epoch 61 | loss: 37.87246| val_0_mse: 28.85926055908203|  0:00:39s\n","\n","Early stopping occurred at epoch 61 with best_epoch = 51 and best_val_0_mse = 24.319580078125\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 13:27:48,054] Trial 48 finished with value: 24.319578170776367 and parameters: {'n_d': 62, 'n_steps': 5, 'gamma': 1.2940062910563028, 'n_independent': 1, 'n_shared': 3, 'momentum': 0.1763073336867147}. Best is trial 39 with value: 14.34697437286377.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 2490.15367| val_0_mse: 2547.703125|  0:00:00s\n","epoch 1  | loss: 2232.19222| val_0_mse: 2540.979248046875|  0:00:01s\n","epoch 2  | loss: 1740.83887| val_0_mse: 2580.3828125|  0:00:01s\n","epoch 3  | loss: 1102.74811| val_0_mse: 2488.547119140625|  0:00:02s\n","epoch 4  | loss: 531.12498| val_0_mse: 2528.42626953125|  0:00:02s\n","epoch 5  | loss: 281.22546| val_0_mse: 2142.3994140625|  0:00:03s\n","epoch 6  | loss: 252.15122| val_0_mse: 2337.5654296875|  0:00:04s\n","epoch 7  | loss: 208.27981| val_0_mse: 2896.39306640625|  0:00:04s\n","epoch 8  | loss: 174.57556| val_0_mse: 3100.612548828125|  0:00:05s\n","epoch 9  | loss: 173.42125| val_0_mse: 2677.399658203125|  0:00:05s\n","epoch 10 | loss: 138.42149| val_0_mse: 2671.947998046875|  0:00:06s\n","epoch 11 | loss: 136.11144| val_0_mse: 2558.919921875|  0:00:06s\n","epoch 12 | loss: 122.28715| val_0_mse: 2482.9013671875|  0:00:07s\n","epoch 13 | loss: 127.96643| val_0_mse: 2255.97607421875|  0:00:08s\n","epoch 14 | loss: 105.41696| val_0_mse: 2115.144287109375|  0:00:08s\n","epoch 15 | loss: 102.78012| val_0_mse: 2021.4052734375|  0:00:09s\n","epoch 16 | loss: 101.16127| val_0_mse: 1681.3355712890625|  0:00:09s\n","epoch 17 | loss: 83.83392| val_0_mse: 1832.1190185546875|  0:00:10s\n","epoch 18 | loss: 87.71382| val_0_mse: 1474.185791015625|  0:00:10s\n","epoch 19 | loss: 100.57814| val_0_mse: 1189.6719970703125|  0:00:11s\n","epoch 20 | loss: 85.62961| val_0_mse: 1281.34033203125|  0:00:12s\n","epoch 21 | loss: 85.31674| val_0_mse: 951.9782104492188|  0:00:12s\n","epoch 22 | loss: 89.22596| val_0_mse: 814.8998413085938|  0:00:13s\n","epoch 23 | loss: 77.29742| val_0_mse: 853.6591796875|  0:00:13s\n","epoch 24 | loss: 72.39988| val_0_mse: 611.6862182617188|  0:00:14s\n","epoch 25 | loss: 71.75439| val_0_mse: 588.348388671875|  0:00:14s\n","epoch 26 | loss: 75.35369| val_0_mse: 443.7402648925781|  0:00:15s\n","epoch 27 | loss: 63.7536 | val_0_mse: 403.91241455078125|  0:00:16s\n","epoch 28 | loss: 82.14518| val_0_mse: 355.53973388671875|  0:00:16s\n","epoch 29 | loss: 78.45232| val_0_mse: 351.8047180175781|  0:00:17s\n","epoch 30 | loss: 53.35593| val_0_mse: 237.04437255859375|  0:00:17s\n","epoch 31 | loss: 64.27939| val_0_mse: 213.1200408935547|  0:00:18s\n","epoch 32 | loss: 70.59628| val_0_mse: 224.2117156982422|  0:00:19s\n","epoch 33 | loss: 56.11294| val_0_mse: 185.8004608154297|  0:00:19s\n","epoch 34 | loss: 66.97315| val_0_mse: 124.38221740722656|  0:00:20s\n","epoch 35 | loss: 61.13033| val_0_mse: 139.4322967529297|  0:00:20s\n","epoch 36 | loss: 63.54112| val_0_mse: 138.52578735351562|  0:00:21s\n","epoch 37 | loss: 65.89474| val_0_mse: 117.0419692993164|  0:00:21s\n","epoch 38 | loss: 53.60128| val_0_mse: 135.55160522460938|  0:00:22s\n","epoch 39 | loss: 52.96019| val_0_mse: 90.74059295654297|  0:00:22s\n","epoch 40 | loss: 55.40764| val_0_mse: 44.702720642089844|  0:00:23s\n","epoch 41 | loss: 46.31283| val_0_mse: 55.5076789855957|  0:00:24s\n","epoch 42 | loss: 54.27213| val_0_mse: 53.22380065917969|  0:00:24s\n","epoch 43 | loss: 44.55826| val_0_mse: 68.10250091552734|  0:00:25s\n","epoch 44 | loss: 54.20441| val_0_mse: 55.95441818237305|  0:00:25s\n","epoch 45 | loss: 63.40369| val_0_mse: 80.63600158691406|  0:00:26s\n","epoch 46 | loss: 45.86759| val_0_mse: 53.33243942260742|  0:00:27s\n","epoch 47 | loss: 47.22995| val_0_mse: 45.8301887512207|  0:00:27s\n","epoch 48 | loss: 54.0516 | val_0_mse: 37.04676818847656|  0:00:28s\n","epoch 49 | loss: 41.93361| val_0_mse: 39.4863395690918|  0:00:28s\n","epoch 50 | loss: 45.58126| val_0_mse: 47.41276931762695|  0:00:29s\n","epoch 51 | loss: 44.59388| val_0_mse: 38.96788024902344|  0:00:30s\n","epoch 52 | loss: 51.60244| val_0_mse: 31.094839096069336|  0:00:30s\n","epoch 53 | loss: 39.42618| val_0_mse: 23.469030380249023|  0:00:31s\n","epoch 54 | loss: 43.89545| val_0_mse: 42.7127799987793|  0:00:31s\n","epoch 55 | loss: 52.9391 | val_0_mse: 42.35675811767578|  0:00:32s\n","epoch 56 | loss: 60.39415| val_0_mse: 26.563459396362305|  0:00:32s\n","epoch 57 | loss: 41.70855| val_0_mse: 28.352710723876953|  0:00:33s\n","epoch 58 | loss: 40.21495| val_0_mse: 31.935800552368164|  0:00:34s\n","epoch 59 | loss: 44.74055| val_0_mse: 32.23115921020508|  0:00:34s\n","epoch 60 | loss: 42.17638| val_0_mse: 26.54339027404785|  0:00:35s\n","epoch 61 | loss: 52.46479| val_0_mse: 24.86779022216797|  0:00:35s\n","epoch 62 | loss: 59.67008| val_0_mse: 31.356510162353516|  0:00:36s\n","epoch 63 | loss: 57.86783| val_0_mse: 41.2005615234375|  0:00:36s\n","\n","Early stopping occurred at epoch 63 with best_epoch = 53 and best_val_0_mse = 23.469030380249023\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 13:28:25,176] Trial 49 finished with value: 23.469030380249023 and parameters: {'n_d': 8, 'n_steps': 3, 'gamma': 1.218469475702993, 'n_independent': 4, 'n_shared': 2, 'momentum': 0.13757809316973774}. Best is trial 39 with value: 14.34697437286377.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 2330.63236| val_0_mse: 3460.639892578125|  0:00:00s\n","epoch 1  | loss: 1753.12137| val_0_mse: 2600.87939453125|  0:00:01s\n","epoch 2  | loss: 848.59982| val_0_mse: 2442.537841796875|  0:00:02s\n","epoch 3  | loss: 501.52696| val_0_mse: 4029.105224609375|  0:00:03s\n","epoch 4  | loss: 353.22863| val_0_mse: 3228.201171875|  0:00:03s\n","epoch 5  | loss: 350.35722| val_0_mse: 2071.25537109375|  0:00:04s\n","epoch 6  | loss: 251.89762| val_0_mse: 2337.591796875|  0:00:05s\n","epoch 7  | loss: 278.04487| val_0_mse: 2695.677734375|  0:00:06s\n","epoch 8  | loss: 238.90106| val_0_mse: 2352.295654296875|  0:00:06s\n","epoch 9  | loss: 230.76981| val_0_mse: 2608.892822265625|  0:00:07s\n","epoch 10 | loss: 187.77138| val_0_mse: 2696.87109375|  0:00:08s\n","epoch 11 | loss: 167.97657| val_0_mse: 2515.45361328125|  0:00:09s\n","epoch 12 | loss: 168.04331| val_0_mse: 2500.7373046875|  0:00:09s\n","epoch 13 | loss: 145.90096| val_0_mse: 2429.46533203125|  0:00:10s\n","epoch 14 | loss: 130.45618| val_0_mse: 2454.07373046875|  0:00:11s\n","epoch 15 | loss: 120.0318| val_0_mse: 2513.2470703125|  0:00:12s\n","\n","Early stopping occurred at epoch 15 with best_epoch = 5 and best_val_0_mse = 2071.25537109375\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 13:28:37,829] Trial 50 finished with value: 2071.25537109375 and parameters: {'n_d': 30, 'n_steps': 4, 'gamma': 1.3354319315139218, 'n_independent': 5, 'n_shared': 2, 'momentum': 0.34320936050843254}. Best is trial 39 with value: 14.34697437286377.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 2239.81359| val_0_mse: 4247.2060546875|  0:00:00s\n","epoch 1  | loss: 1016.10945| val_0_mse: 3390.825927734375|  0:00:01s\n","epoch 2  | loss: 388.32777| val_0_mse: 3622.214599609375|  0:00:02s\n","epoch 3  | loss: 276.80545| val_0_mse: 2690.5966796875|  0:00:03s\n","epoch 4  | loss: 226.62408| val_0_mse: 4599.3818359375|  0:00:04s\n","epoch 5  | loss: 222.19697| val_0_mse: 2734.72412109375|  0:00:04s\n","epoch 6  | loss: 162.54927| val_0_mse: 2750.84228515625|  0:00:05s\n","epoch 7  | loss: 161.9768| val_0_mse: 2921.318603515625|  0:00:06s\n","epoch 8  | loss: 145.06531| val_0_mse: 2808.4150390625|  0:00:07s\n","epoch 9  | loss: 135.78575| val_0_mse: 2764.35302734375|  0:00:07s\n","epoch 10 | loss: 130.29865| val_0_mse: 2790.028564453125|  0:00:08s\n","epoch 11 | loss: 121.39083| val_0_mse: 2733.92724609375|  0:00:09s\n","epoch 12 | loss: 116.3734| val_0_mse: 2654.20263671875|  0:00:10s\n","epoch 13 | loss: 99.30633| val_0_mse: 2730.065185546875|  0:00:10s\n","epoch 14 | loss: 105.32765| val_0_mse: 2595.147216796875|  0:00:11s\n","epoch 15 | loss: 88.11974| val_0_mse: 2578.60400390625|  0:00:12s\n","epoch 16 | loss: 88.73287| val_0_mse: 2558.592529296875|  0:00:13s\n","epoch 17 | loss: 89.61529| val_0_mse: 2671.452392578125|  0:00:14s\n","epoch 18 | loss: 81.02033| val_0_mse: 2286.46923828125|  0:00:14s\n","epoch 19 | loss: 82.07615| val_0_mse: 2201.697265625|  0:00:15s\n","epoch 20 | loss: 70.36931| val_0_mse: 2243.889404296875|  0:00:16s\n","epoch 21 | loss: 63.83941| val_0_mse: 1909.6800537109375|  0:00:17s\n","epoch 22 | loss: 68.94393| val_0_mse: 1706.23828125|  0:00:17s\n","epoch 23 | loss: 60.32609| val_0_mse: 1384.4483642578125|  0:00:18s\n","epoch 24 | loss: 59.67944| val_0_mse: 1189.505126953125|  0:00:19s\n","epoch 25 | loss: 60.31308| val_0_mse: 1245.3619384765625|  0:00:20s\n","epoch 26 | loss: 70.18294| val_0_mse: 934.74072265625|  0:00:21s\n","epoch 27 | loss: 64.84506| val_0_mse: 858.5081787109375|  0:00:21s\n","epoch 28 | loss: 51.56047| val_0_mse: 703.996826171875|  0:00:22s\n","epoch 29 | loss: 52.89959| val_0_mse: 454.8797607421875|  0:00:23s\n","epoch 30 | loss: 49.75753| val_0_mse: 321.5777587890625|  0:00:24s\n","epoch 31 | loss: 54.44266| val_0_mse: 264.1919860839844|  0:00:25s\n","epoch 32 | loss: 50.64321| val_0_mse: 244.7743377685547|  0:00:25s\n","epoch 33 | loss: 59.12901| val_0_mse: 179.11422729492188|  0:00:26s\n","epoch 34 | loss: 63.45163| val_0_mse: 184.80642700195312|  0:00:27s\n","epoch 35 | loss: 72.67496| val_0_mse: 128.1709747314453|  0:00:28s\n","epoch 36 | loss: 64.50457| val_0_mse: 117.6877670288086|  0:00:29s\n","epoch 37 | loss: 64.9335 | val_0_mse: 112.51029205322266|  0:00:29s\n","epoch 38 | loss: 57.34739| val_0_mse: 77.6038818359375|  0:00:30s\n","epoch 39 | loss: 59.63072| val_0_mse: 59.956459045410156|  0:00:31s\n","epoch 40 | loss: 61.63562| val_0_mse: 78.20992279052734|  0:00:32s\n","epoch 41 | loss: 55.4591 | val_0_mse: 60.493621826171875|  0:00:33s\n","epoch 42 | loss: 44.93267| val_0_mse: 40.48957061767578|  0:00:33s\n","epoch 43 | loss: 45.6425 | val_0_mse: 31.235809326171875|  0:00:34s\n","epoch 44 | loss: 53.87353| val_0_mse: 73.40637969970703|  0:00:35s\n","epoch 45 | loss: 51.89226| val_0_mse: 27.4077205657959|  0:00:36s\n","epoch 46 | loss: 43.05327| val_0_mse: 37.7841911315918|  0:00:36s\n","epoch 47 | loss: 49.70045| val_0_mse: 41.86785888671875|  0:00:37s\n","epoch 48 | loss: 40.55133| val_0_mse: 42.863861083984375|  0:00:38s\n","epoch 49 | loss: 43.75727| val_0_mse: 41.47032165527344|  0:00:39s\n","epoch 50 | loss: 33.34016| val_0_mse: 24.273609161376953|  0:00:39s\n","epoch 51 | loss: 38.17112| val_0_mse: 25.304040908813477|  0:00:40s\n","epoch 52 | loss: 49.18143| val_0_mse: 40.207061767578125|  0:00:41s\n","epoch 53 | loss: 52.49113| val_0_mse: 32.81858825683594|  0:00:42s\n","epoch 54 | loss: 54.99774| val_0_mse: 40.15446090698242|  0:00:43s\n","epoch 55 | loss: 41.46982| val_0_mse: 33.23175811767578|  0:00:43s\n","epoch 56 | loss: 44.88096| val_0_mse: 31.432090759277344|  0:00:44s\n","epoch 57 | loss: 41.24929| val_0_mse: 41.823848724365234|  0:00:45s\n","epoch 58 | loss: 42.09919| val_0_mse: 30.353090286254883|  0:00:46s\n","epoch 59 | loss: 36.89936| val_0_mse: 39.4487190246582|  0:00:46s\n","epoch 60 | loss: 47.05306| val_0_mse: 35.346710205078125|  0:00:47s\n","\n","Early stopping occurred at epoch 60 with best_epoch = 50 and best_val_0_mse = 24.273609161376953\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 13:29:25,852] Trial 51 finished with value: 24.273609161376953 and parameters: {'n_d': 44, 'n_steps': 4, 'gamma': 1.2524045910637835, 'n_independent': 3, 'n_shared': 4, 'momentum': 0.2625751661602539}. Best is trial 39 with value: 14.34697437286377.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 2115.3843| val_0_mse: 4757.40869140625|  0:00:00s\n","epoch 1  | loss: 1480.98176| val_0_mse: 4478.32080078125|  0:00:01s\n","epoch 2  | loss: 1088.23065| val_0_mse: 8841.3916015625|  0:00:02s\n","epoch 3  | loss: 869.90927| val_0_mse: 4111.10595703125|  0:00:03s\n","epoch 4  | loss: 618.70357| val_0_mse: 3299.856201171875|  0:00:04s\n","epoch 5  | loss: 482.01045| val_0_mse: 5045.94873046875|  0:00:04s\n","epoch 6  | loss: 435.38178| val_0_mse: 5109.14794921875|  0:00:05s\n","epoch 7  | loss: 416.83484| val_0_mse: 3700.190185546875|  0:00:06s\n","epoch 8  | loss: 390.01288| val_0_mse: 5310.62109375|  0:00:07s\n","epoch 9  | loss: 344.75057| val_0_mse: 3456.585693359375|  0:00:08s\n","epoch 10 | loss: 346.23085| val_0_mse: 2852.252685546875|  0:00:08s\n","epoch 11 | loss: 300.13784| val_0_mse: 2915.529296875|  0:00:09s\n","epoch 12 | loss: 251.93487| val_0_mse: 2690.78955078125|  0:00:10s\n","epoch 13 | loss: 222.64454| val_0_mse: 2971.506591796875|  0:00:11s\n","epoch 14 | loss: 219.12049| val_0_mse: 2562.0361328125|  0:00:12s\n","epoch 15 | loss: 167.20818| val_0_mse: 1793.6837158203125|  0:00:13s\n","epoch 16 | loss: 157.66831| val_0_mse: 1834.45068359375|  0:00:13s\n","epoch 17 | loss: 176.57516| val_0_mse: 1849.0526123046875|  0:00:14s\n","epoch 18 | loss: 148.80328| val_0_mse: 1267.669189453125|  0:00:15s\n","epoch 19 | loss: 148.46471| val_0_mse: 1179.091552734375|  0:00:16s\n","epoch 20 | loss: 130.92584| val_0_mse: 1088.85498046875|  0:00:17s\n","epoch 21 | loss: 144.21461| val_0_mse: 786.5682983398438|  0:00:18s\n","epoch 22 | loss: 171.66766| val_0_mse: 733.39697265625|  0:00:18s\n","epoch 23 | loss: 134.30847| val_0_mse: 723.6231079101562|  0:00:19s\n","epoch 24 | loss: 119.05175| val_0_mse: 583.96875|  0:00:20s\n","epoch 25 | loss: 109.44172| val_0_mse: 489.2116394042969|  0:00:21s\n","epoch 26 | loss: 107.16725| val_0_mse: 361.68438720703125|  0:00:22s\n","epoch 27 | loss: 105.21505| val_0_mse: 250.0704345703125|  0:00:23s\n","epoch 28 | loss: 118.27249| val_0_mse: 305.9244689941406|  0:00:23s\n","epoch 29 | loss: 98.39582| val_0_mse: 218.27963256835938|  0:00:24s\n","epoch 30 | loss: 99.36059| val_0_mse: 205.71864318847656|  0:00:25s\n","epoch 31 | loss: 118.88788| val_0_mse: 175.55258178710938|  0:00:26s\n","epoch 32 | loss: 108.01063| val_0_mse: 146.71446228027344|  0:00:27s\n","epoch 33 | loss: 111.29916| val_0_mse: 134.80735778808594|  0:00:27s\n","epoch 34 | loss: 124.06079| val_0_mse: 205.68756103515625|  0:00:28s\n","epoch 35 | loss: 112.65046| val_0_mse: 93.0453872680664|  0:00:29s\n","epoch 36 | loss: 98.98521| val_0_mse: 163.78741455078125|  0:00:30s\n","epoch 37 | loss: 92.74342| val_0_mse: 136.06410217285156|  0:00:31s\n","epoch 38 | loss: 90.89152| val_0_mse: 85.88597106933594|  0:00:31s\n","epoch 39 | loss: 98.27575| val_0_mse: 84.13497161865234|  0:00:32s\n","epoch 40 | loss: 88.505  | val_0_mse: 117.33963775634766|  0:00:33s\n","epoch 41 | loss: 86.76383| val_0_mse: 107.6948471069336|  0:00:34s\n","epoch 42 | loss: 80.23887| val_0_mse: 81.03336334228516|  0:00:35s\n","epoch 43 | loss: 79.85469| val_0_mse: 99.40770721435547|  0:00:35s\n","epoch 44 | loss: 94.4311 | val_0_mse: 48.239078521728516|  0:00:36s\n","epoch 45 | loss: 81.15742| val_0_mse: 54.5959587097168|  0:00:37s\n","epoch 46 | loss: 86.02093| val_0_mse: 108.92986297607422|  0:00:38s\n","epoch 47 | loss: 115.42981| val_0_mse: 85.52995300292969|  0:00:39s\n","epoch 48 | loss: 74.29783| val_0_mse: 42.74544143676758|  0:00:40s\n","epoch 49 | loss: 72.31919| val_0_mse: 52.60773849487305|  0:00:41s\n","epoch 50 | loss: 78.83812| val_0_mse: 37.56787872314453|  0:00:41s\n","epoch 51 | loss: 83.46933| val_0_mse: 42.86001968383789|  0:00:42s\n","epoch 52 | loss: 75.80267| val_0_mse: 71.30493927001953|  0:00:43s\n","epoch 53 | loss: 63.87443| val_0_mse: 56.91059875488281|  0:00:44s\n","epoch 54 | loss: 77.34563| val_0_mse: 46.82973861694336|  0:00:45s\n","epoch 55 | loss: 56.92325| val_0_mse: 69.22892761230469|  0:00:45s\n","epoch 56 | loss: 111.25561| val_0_mse: 98.80037689208984|  0:00:46s\n","epoch 57 | loss: 84.8633 | val_0_mse: 49.20391082763672|  0:00:47s\n","epoch 58 | loss: 101.44707| val_0_mse: 45.623878479003906|  0:00:48s\n","epoch 59 | loss: 70.54147| val_0_mse: 42.18009948730469|  0:00:49s\n","epoch 60 | loss: 65.6794 | val_0_mse: 44.403141021728516|  0:00:50s\n","\n","Early stopping occurred at epoch 60 with best_epoch = 50 and best_val_0_mse = 37.56787872314453\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 13:30:16,339] Trial 52 finished with value: 37.56787872314453 and parameters: {'n_d': 43, 'n_steps': 5, 'gamma': 1.44511214287346, 'n_independent': 3, 'n_shared': 3, 'momentum': 0.3191436016451934}. Best is trial 39 with value: 14.34697437286377.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 2153.48124| val_0_mse: 2806.3828125|  0:00:00s\n","epoch 1  | loss: 955.12398| val_0_mse: 2926.414306640625|  0:00:01s\n","epoch 2  | loss: 548.84069| val_0_mse: 13095.8203125|  0:00:02s\n","epoch 3  | loss: 366.73503| val_0_mse: 7681.22216796875|  0:00:03s\n","epoch 4  | loss: 282.8096| val_0_mse: 3476.13525390625|  0:00:03s\n","epoch 5  | loss: 205.68724| val_0_mse: 3439.716064453125|  0:00:04s\n","epoch 6  | loss: 190.73867| val_0_mse: 3148.22998046875|  0:00:05s\n","epoch 7  | loss: 180.1607| val_0_mse: 3171.876220703125|  0:00:06s\n","epoch 8  | loss: 168.13916| val_0_mse: 2759.19873046875|  0:00:06s\n","epoch 9  | loss: 147.85715| val_0_mse: 2851.934814453125|  0:00:07s\n","epoch 10 | loss: 126.16322| val_0_mse: 2747.67333984375|  0:00:08s\n","epoch 11 | loss: 117.17834| val_0_mse: 2699.253662109375|  0:00:09s\n","epoch 12 | loss: 129.67396| val_0_mse: 2669.284423828125|  0:00:09s\n","epoch 13 | loss: 121.3882| val_0_mse: 2714.8056640625|  0:00:10s\n","epoch 14 | loss: 112.39881| val_0_mse: 2482.19775390625|  0:00:11s\n","epoch 15 | loss: 103.87713| val_0_mse: 2577.07177734375|  0:00:12s\n","epoch 16 | loss: 106.58592| val_0_mse: 2593.24072265625|  0:00:13s\n","epoch 17 | loss: 93.32261| val_0_mse: 2481.8623046875|  0:00:13s\n","epoch 18 | loss: 110.54421| val_0_mse: 2220.0595703125|  0:00:14s\n","epoch 19 | loss: 119.37192| val_0_mse: 2609.292724609375|  0:00:15s\n","epoch 20 | loss: 133.94454| val_0_mse: 1856.7777099609375|  0:00:16s\n","epoch 21 | loss: 111.11413| val_0_mse: 1963.62548828125|  0:00:16s\n","epoch 22 | loss: 99.22955| val_0_mse: 1385.6221923828125|  0:00:17s\n","epoch 23 | loss: 85.08646| val_0_mse: 1178.1597900390625|  0:00:18s\n","epoch 24 | loss: 88.51012| val_0_mse: 954.7195434570312|  0:00:19s\n","epoch 25 | loss: 86.96356| val_0_mse: 833.2876586914062|  0:00:19s\n","epoch 26 | loss: 92.83198| val_0_mse: 612.9915161132812|  0:00:20s\n","epoch 27 | loss: 86.94758| val_0_mse: 381.8870544433594|  0:00:21s\n","epoch 28 | loss: 77.4537 | val_0_mse: 384.27203369140625|  0:00:22s\n","epoch 29 | loss: 73.20538| val_0_mse: 295.9284973144531|  0:00:23s\n","epoch 30 | loss: 72.54713| val_0_mse: 261.9936218261719|  0:00:23s\n","epoch 31 | loss: 66.53003| val_0_mse: 256.0527648925781|  0:00:24s\n","epoch 32 | loss: 61.48706| val_0_mse: 263.44183349609375|  0:00:25s\n","epoch 33 | loss: 61.23701| val_0_mse: 205.81153869628906|  0:00:26s\n","epoch 34 | loss: 53.14456| val_0_mse: 142.56097412109375|  0:00:26s\n","epoch 35 | loss: 55.70027| val_0_mse: 179.98321533203125|  0:00:27s\n","epoch 36 | loss: 57.72876| val_0_mse: 151.30502319335938|  0:00:28s\n","epoch 37 | loss: 51.47969| val_0_mse: 142.3415985107422|  0:00:29s\n","epoch 38 | loss: 47.6581 | val_0_mse: 95.38783264160156|  0:00:30s\n","epoch 39 | loss: 58.35975| val_0_mse: 76.08036804199219|  0:00:30s\n","epoch 40 | loss: 57.64183| val_0_mse: 67.10012817382812|  0:00:31s\n","epoch 41 | loss: 62.01142| val_0_mse: 82.0338363647461|  0:00:32s\n","epoch 42 | loss: 55.33689| val_0_mse: 84.69856262207031|  0:00:33s\n","epoch 43 | loss: 53.31973| val_0_mse: 58.942901611328125|  0:00:33s\n","epoch 44 | loss: 41.84321| val_0_mse: 48.64741897583008|  0:00:34s\n","epoch 45 | loss: 44.77902| val_0_mse: 39.18946075439453|  0:00:35s\n","epoch 46 | loss: 40.97337| val_0_mse: 67.09259796142578|  0:00:36s\n","epoch 47 | loss: 44.94481| val_0_mse: 43.105281829833984|  0:00:37s\n","epoch 48 | loss: 45.77036| val_0_mse: 42.70362091064453|  0:00:37s\n","epoch 49 | loss: 54.43692| val_0_mse: 37.963661193847656|  0:00:38s\n","epoch 50 | loss: 41.49701| val_0_mse: 53.22101974487305|  0:00:39s\n","epoch 51 | loss: 42.75302| val_0_mse: 31.97410011291504|  0:00:40s\n","epoch 52 | loss: 53.87279| val_0_mse: 40.021949768066406|  0:00:41s\n","epoch 53 | loss: 51.68532| val_0_mse: 38.96577835083008|  0:00:41s\n","epoch 54 | loss: 46.25913| val_0_mse: 63.668338775634766|  0:00:42s\n","epoch 55 | loss: 57.50661| val_0_mse: 35.63138961791992|  0:00:43s\n","epoch 56 | loss: 36.49362| val_0_mse: 36.55651092529297|  0:00:44s\n","epoch 57 | loss: 43.80905| val_0_mse: 39.670631408691406|  0:00:45s\n","epoch 58 | loss: 41.90662| val_0_mse: 64.92086029052734|  0:00:45s\n","epoch 59 | loss: 43.75083| val_0_mse: 45.59524154663086|  0:00:46s\n","epoch 60 | loss: 45.91452| val_0_mse: 35.990318298339844|  0:00:47s\n","epoch 61 | loss: 33.27451| val_0_mse: 35.29914855957031|  0:00:48s\n","\n","Early stopping occurred at epoch 61 with best_epoch = 51 and best_val_0_mse = 31.97410011291504\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 13:31:05,019] Trial 53 finished with value: 31.974098205566406 and parameters: {'n_d': 47, 'n_steps': 4, 'gamma': 1.2560022993733058, 'n_independent': 3, 'n_shared': 4, 'momentum': 0.31766121736587727}. Best is trial 39 with value: 14.34697437286377.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 2082.02681| val_0_mse: 3020.667724609375|  0:00:00s\n","epoch 1  | loss: 741.19589| val_0_mse: 3266.8642578125|  0:00:01s\n","epoch 2  | loss: 348.25123| val_0_mse: 2944.99560546875|  0:00:01s\n","epoch 3  | loss: 268.4024| val_0_mse: 2602.65478515625|  0:00:02s\n","epoch 4  | loss: 210.02132| val_0_mse: 2699.99365234375|  0:00:03s\n","epoch 5  | loss: 190.77222| val_0_mse: 2574.725341796875|  0:00:03s\n","epoch 6  | loss: 169.54667| val_0_mse: 2871.357421875|  0:00:04s\n","epoch 7  | loss: 153.16247| val_0_mse: 2923.09130859375|  0:00:04s\n","epoch 8  | loss: 135.81524| val_0_mse: 2888.7763671875|  0:00:05s\n","epoch 9  | loss: 136.34718| val_0_mse: 2895.44921875|  0:00:06s\n","epoch 10 | loss: 138.2766| val_0_mse: 2876.186767578125|  0:00:06s\n","epoch 11 | loss: 132.56082| val_0_mse: 2868.621337890625|  0:00:07s\n","epoch 12 | loss: 118.2396| val_0_mse: 2744.6357421875|  0:00:07s\n","epoch 13 | loss: 133.48865| val_0_mse: 2589.252685546875|  0:00:08s\n","epoch 14 | loss: 112.64149| val_0_mse: 2635.10302734375|  0:00:08s\n","epoch 15 | loss: 115.92934| val_0_mse: 2580.014404296875|  0:00:09s\n","\n","Early stopping occurred at epoch 15 with best_epoch = 5 and best_val_0_mse = 2574.725341796875\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 13:31:14,920] Trial 54 finished with value: 2574.725341796875 and parameters: {'n_d': 46, 'n_steps': 3, 'gamma': 1.1478411664283052, 'n_independent': 2, 'n_shared': 4, 'momentum': 0.22852873300410664}. Best is trial 39 with value: 14.34697437286377.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 2228.80001| val_0_mse: 5548.24267578125|  0:00:01s\n","epoch 1  | loss: 1338.58122| val_0_mse: 5280.92529296875|  0:00:02s\n","epoch 2  | loss: 678.66928| val_0_mse: 4656.5595703125|  0:00:03s\n","epoch 3  | loss: 502.14796| val_0_mse: 5029.28466796875|  0:00:04s\n","epoch 4  | loss: 339.79331| val_0_mse: 3429.59326171875|  0:00:05s\n","epoch 5  | loss: 305.83638| val_0_mse: 10000.9365234375|  0:00:06s\n","epoch 6  | loss: 259.24093| val_0_mse: 3463.391357421875|  0:00:07s\n","epoch 7  | loss: 227.2723| val_0_mse: 2795.337158203125|  0:00:08s\n","epoch 8  | loss: 225.2774| val_0_mse: 2926.958984375|  0:00:09s\n","epoch 9  | loss: 203.62208| val_0_mse: 2973.3427734375|  0:00:10s\n","epoch 10 | loss: 177.19865| val_0_mse: 3091.11328125|  0:00:11s\n","epoch 11 | loss: 154.12554| val_0_mse: 2950.867919921875|  0:00:12s\n","epoch 12 | loss: 146.17849| val_0_mse: 2615.953857421875|  0:00:13s\n","epoch 13 | loss: 138.32432| val_0_mse: 2792.171142578125|  0:00:14s\n","epoch 14 | loss: 153.40988| val_0_mse: 2789.087158203125|  0:00:15s\n","epoch 15 | loss: 114.8975| val_0_mse: 2171.53564453125|  0:00:17s\n","epoch 16 | loss: 113.52106| val_0_mse: 1928.6968994140625|  0:00:18s\n","epoch 17 | loss: 103.75407| val_0_mse: 1961.558837890625|  0:00:19s\n","epoch 18 | loss: 117.08101| val_0_mse: 1844.241455078125|  0:00:20s\n","epoch 19 | loss: 114.20523| val_0_mse: 1638.59130859375|  0:00:21s\n","epoch 20 | loss: 93.04044| val_0_mse: 1521.441162109375|  0:00:22s\n","epoch 21 | loss: 101.86978| val_0_mse: 1452.52099609375|  0:00:23s\n","epoch 22 | loss: 105.63238| val_0_mse: 1510.2933349609375|  0:00:24s\n","epoch 23 | loss: 105.07444| val_0_mse: 1405.256591796875|  0:00:25s\n","epoch 24 | loss: 99.08576| val_0_mse: 1234.8831787109375|  0:00:26s\n","epoch 25 | loss: 87.28352| val_0_mse: 1046.47900390625|  0:00:27s\n","epoch 26 | loss: 97.81484| val_0_mse: 771.1190185546875|  0:00:28s\n","epoch 27 | loss: 85.83273| val_0_mse: 560.7199096679688|  0:00:29s\n","epoch 28 | loss: 84.33437| val_0_mse: 467.03485107421875|  0:00:30s\n","epoch 29 | loss: 87.51871| val_0_mse: 537.2642822265625|  0:00:31s\n","epoch 30 | loss: 92.10221| val_0_mse: 397.5070495605469|  0:00:32s\n","epoch 31 | loss: 90.62724| val_0_mse: 272.9200744628906|  0:00:34s\n","epoch 32 | loss: 85.78397| val_0_mse: 234.32928466796875|  0:00:35s\n","epoch 33 | loss: 74.53234| val_0_mse: 210.10365295410156|  0:00:36s\n","epoch 34 | loss: 75.67433| val_0_mse: 187.45701599121094|  0:00:37s\n","epoch 35 | loss: 79.98681| val_0_mse: 159.32614135742188|  0:00:38s\n","epoch 36 | loss: 76.82713| val_0_mse: 115.46878814697266|  0:00:39s\n","epoch 37 | loss: 67.27085| val_0_mse: 91.15258026123047|  0:00:40s\n","epoch 38 | loss: 73.49632| val_0_mse: 115.9322509765625|  0:00:41s\n","epoch 39 | loss: 75.47827| val_0_mse: 196.98707580566406|  0:00:42s\n","epoch 40 | loss: 63.19828| val_0_mse: 89.05844116210938|  0:00:43s\n","epoch 41 | loss: 67.24822| val_0_mse: 113.83685302734375|  0:00:44s\n","epoch 42 | loss: 51.67609| val_0_mse: 55.91460037231445|  0:00:45s\n","epoch 43 | loss: 58.40953| val_0_mse: 60.11516189575195|  0:00:46s\n","epoch 44 | loss: 68.89111| val_0_mse: 90.76814270019531|  0:00:47s\n","epoch 45 | loss: 70.01673| val_0_mse: 55.488319396972656|  0:00:48s\n","epoch 46 | loss: 51.5742 | val_0_mse: 78.98854064941406|  0:00:49s\n","epoch 47 | loss: 75.51995| val_0_mse: 54.39984130859375|  0:00:50s\n","epoch 48 | loss: 67.6293 | val_0_mse: 63.73141860961914|  0:00:51s\n","epoch 49 | loss: 58.73564| val_0_mse: 67.87740325927734|  0:00:53s\n","epoch 50 | loss: 54.43423| val_0_mse: 41.6102409362793|  0:00:54s\n","epoch 51 | loss: 53.03007| val_0_mse: 42.76932144165039|  0:00:55s\n","epoch 52 | loss: 54.75443| val_0_mse: 38.21072006225586|  0:00:56s\n","epoch 53 | loss: 57.69964| val_0_mse: 59.663909912109375|  0:00:57s\n","epoch 54 | loss: 57.82177| val_0_mse: 33.70069885253906|  0:00:58s\n","epoch 55 | loss: 64.4647 | val_0_mse: 72.90276336669922|  0:00:59s\n","epoch 56 | loss: 68.56275| val_0_mse: 61.06248092651367|  0:01:00s\n","epoch 57 | loss: 63.78509| val_0_mse: 65.1911392211914|  0:01:01s\n","epoch 58 | loss: 69.45073| val_0_mse: 30.641010284423828|  0:01:02s\n","epoch 59 | loss: 60.37981| val_0_mse: 37.513031005859375|  0:01:03s\n","epoch 60 | loss: 48.93512| val_0_mse: 49.39707946777344|  0:01:04s\n","epoch 61 | loss: 54.52093| val_0_mse: 38.52336120605469|  0:01:05s\n","epoch 62 | loss: 49.52333| val_0_mse: 30.228029251098633|  0:01:06s\n","epoch 63 | loss: 61.36232| val_0_mse: 36.61627960205078|  0:01:07s\n","epoch 64 | loss: 55.3487 | val_0_mse: 40.04233169555664|  0:01:08s\n","epoch 65 | loss: 47.40139| val_0_mse: 27.415719985961914|  0:01:09s\n","epoch 66 | loss: 43.46455| val_0_mse: 31.196720123291016|  0:01:10s\n","epoch 67 | loss: 56.47646| val_0_mse: 27.523500442504883|  0:01:11s\n","epoch 68 | loss: 42.45395| val_0_mse: 23.17119026184082|  0:01:12s\n","epoch 69 | loss: 41.48127| val_0_mse: 31.30289077758789|  0:01:14s\n","epoch 70 | loss: 47.1026 | val_0_mse: 25.798919677734375|  0:01:15s\n","epoch 71 | loss: 41.16708| val_0_mse: 26.05242919921875|  0:01:16s\n","epoch 72 | loss: 62.09487| val_0_mse: 31.45602035522461|  0:01:17s\n","epoch 73 | loss: 70.22703| val_0_mse: 27.889570236206055|  0:01:18s\n","epoch 74 | loss: 63.02239| val_0_mse: 33.490989685058594|  0:01:19s\n","epoch 75 | loss: 57.29641| val_0_mse: 49.29204177856445|  0:01:20s\n","epoch 76 | loss: 59.84049| val_0_mse: 56.98775863647461|  0:01:21s\n","epoch 77 | loss: 52.33846| val_0_mse: 35.13962936401367|  0:01:22s\n","epoch 78 | loss: 53.21507| val_0_mse: 45.14801025390625|  0:01:23s\n","\n","Early stopping occurred at epoch 78 with best_epoch = 68 and best_val_0_mse = 23.17119026184082\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 13:32:38,885] Trial 55 finished with value: 23.171192169189453 and parameters: {'n_d': 36, 'n_steps': 5, 'gamma': 1.3717013230947142, 'n_independent': 3, 'n_shared': 5, 'momentum': 0.27692709930114634}. Best is trial 39 with value: 14.34697437286377.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 2154.16036| val_0_mse: 2491.187744140625|  0:00:00s\n","epoch 1  | loss: 943.33828| val_0_mse: 2796.73974609375|  0:00:01s\n","epoch 2  | loss: 463.65275| val_0_mse: 2835.498291015625|  0:00:01s\n","epoch 3  | loss: 328.60164| val_0_mse: 3296.47607421875|  0:00:02s\n","epoch 4  | loss: 247.22814| val_0_mse: 2733.01513671875|  0:00:02s\n","epoch 5  | loss: 188.90675| val_0_mse: 2880.67333984375|  0:00:03s\n","epoch 6  | loss: 167.02797| val_0_mse: 2489.785888671875|  0:00:03s\n","epoch 7  | loss: 138.26703| val_0_mse: 2801.119140625|  0:00:04s\n","epoch 8  | loss: 118.13826| val_0_mse: 2696.207763671875|  0:00:05s\n","epoch 9  | loss: 104.19215| val_0_mse: 2525.215087890625|  0:00:05s\n","epoch 10 | loss: 94.47145| val_0_mse: 2474.113037109375|  0:00:06s\n","epoch 11 | loss: 81.94661| val_0_mse: 2553.286376953125|  0:00:06s\n","epoch 12 | loss: 88.7191 | val_0_mse: 2429.759521484375|  0:00:07s\n","epoch 13 | loss: 80.92597| val_0_mse: 2356.52001953125|  0:00:07s\n","epoch 14 | loss: 71.95142| val_0_mse: 2442.17919921875|  0:00:08s\n","epoch 15 | loss: 72.12839| val_0_mse: 2244.34033203125|  0:00:09s\n","epoch 16 | loss: 68.55863| val_0_mse: 2164.59228515625|  0:00:09s\n","epoch 17 | loss: 76.40142| val_0_mse: 1749.9473876953125|  0:00:10s\n","epoch 18 | loss: 71.7738 | val_0_mse: 1738.00732421875|  0:00:10s\n","epoch 19 | loss: 62.71744| val_0_mse: 1476.435546875|  0:00:11s\n","epoch 20 | loss: 58.55037| val_0_mse: 1263.232177734375|  0:00:12s\n","epoch 21 | loss: 61.55752| val_0_mse: 1404.33837890625|  0:00:12s\n","epoch 22 | loss: 58.48697| val_0_mse: 743.6107788085938|  0:00:13s\n","epoch 23 | loss: 59.99036| val_0_mse: 786.7151489257812|  0:00:13s\n","epoch 24 | loss: 58.20461| val_0_mse: 768.624267578125|  0:00:14s\n","epoch 25 | loss: 51.79614| val_0_mse: 494.6120910644531|  0:00:14s\n","epoch 26 | loss: 52.56759| val_0_mse: 478.7279052734375|  0:00:15s\n","epoch 27 | loss: 44.09986| val_0_mse: 363.33392333984375|  0:00:15s\n","epoch 28 | loss: 47.75462| val_0_mse: 337.1429748535156|  0:00:16s\n","epoch 29 | loss: 52.01741| val_0_mse: 317.2212829589844|  0:00:17s\n","epoch 30 | loss: 58.12364| val_0_mse: 346.7237854003906|  0:00:17s\n","epoch 31 | loss: 64.8544 | val_0_mse: 159.05780029296875|  0:00:18s\n","epoch 32 | loss: 51.72953| val_0_mse: 227.35751342773438|  0:00:18s\n","epoch 33 | loss: 56.97321| val_0_mse: 113.8298568725586|  0:00:19s\n","epoch 34 | loss: 48.42786| val_0_mse: 119.97579193115234|  0:00:19s\n","epoch 35 | loss: 50.82759| val_0_mse: 89.12989807128906|  0:00:20s\n","epoch 36 | loss: 59.79673| val_0_mse: 70.67125701904297|  0:00:21s\n","epoch 37 | loss: 51.31556| val_0_mse: 81.12557220458984|  0:00:21s\n","epoch 38 | loss: 43.98531| val_0_mse: 71.03739929199219|  0:00:22s\n","epoch 39 | loss: 41.74653| val_0_mse: 62.27080154418945|  0:00:22s\n","epoch 40 | loss: 50.45885| val_0_mse: 74.26448822021484|  0:00:23s\n","epoch 41 | loss: 46.2652 | val_0_mse: 82.07254028320312|  0:00:23s\n","epoch 42 | loss: 46.92818| val_0_mse: 110.71623229980469|  0:00:24s\n","epoch 43 | loss: 46.91615| val_0_mse: 38.95016098022461|  0:00:24s\n","epoch 44 | loss: 41.91003| val_0_mse: 57.270938873291016|  0:00:25s\n","epoch 45 | loss: 44.13069| val_0_mse: 42.833038330078125|  0:00:26s\n","epoch 46 | loss: 39.19775| val_0_mse: 35.25434875488281|  0:00:26s\n","epoch 47 | loss: 48.2629 | val_0_mse: 23.33102035522461|  0:00:27s\n","epoch 48 | loss: 44.3774 | val_0_mse: 45.458919525146484|  0:00:27s\n","epoch 49 | loss: 42.75309| val_0_mse: 33.10272979736328|  0:00:28s\n","epoch 50 | loss: 38.88862| val_0_mse: 35.27724075317383|  0:00:28s\n","epoch 51 | loss: 48.57713| val_0_mse: 48.985469818115234|  0:00:29s\n","epoch 52 | loss: 33.40931| val_0_mse: 29.225040435791016|  0:00:29s\n","epoch 53 | loss: 37.61709| val_0_mse: 30.4976806640625|  0:00:30s\n","epoch 54 | loss: 48.97225| val_0_mse: 31.780710220336914|  0:00:31s\n","epoch 55 | loss: 37.40457| val_0_mse: 26.06509017944336|  0:00:31s\n","epoch 56 | loss: 38.13733| val_0_mse: 32.44776916503906|  0:00:32s\n","epoch 57 | loss: 43.68218| val_0_mse: 23.586429595947266|  0:00:32s\n","\n","Early stopping occurred at epoch 57 with best_epoch = 47 and best_val_0_mse = 23.33102035522461\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 13:33:11,999] Trial 56 finished with value: 23.331016540527344 and parameters: {'n_d': 40, 'n_steps': 4, 'gamma': 1.197462602914825, 'n_independent': 3, 'n_shared': 1, 'momentum': 0.24757713217167135}. Best is trial 39 with value: 14.34697437286377.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 1903.51935| val_0_mse: 3541.72607421875|  0:00:00s\n","epoch 1  | loss: 537.43706| val_0_mse: 5483.478515625|  0:00:01s\n","epoch 2  | loss: 299.32665| val_0_mse: 4133.74609375|  0:00:01s\n","epoch 3  | loss: 202.24808| val_0_mse: 3080.43017578125|  0:00:02s\n","epoch 4  | loss: 163.67917| val_0_mse: 4509.95556640625|  0:00:02s\n","epoch 5  | loss: 153.76319| val_0_mse: 2882.6640625|  0:00:03s\n","epoch 6  | loss: 129.16278| val_0_mse: 3263.726806640625|  0:00:03s\n","epoch 7  | loss: 113.74702| val_0_mse: 2816.374755859375|  0:00:04s\n","epoch 8  | loss: 116.53226| val_0_mse: 2646.111328125|  0:00:04s\n","epoch 9  | loss: 101.52085| val_0_mse: 2662.40087890625|  0:00:05s\n","epoch 10 | loss: 92.10189| val_0_mse: 2623.728271484375|  0:00:06s\n","epoch 11 | loss: 90.34496| val_0_mse: 2622.89501953125|  0:00:06s\n","epoch 12 | loss: 86.08919| val_0_mse: 2717.6201171875|  0:00:07s\n","epoch 13 | loss: 104.49348| val_0_mse: 2524.981689453125|  0:00:07s\n","epoch 14 | loss: 110.72481| val_0_mse: 2802.390625|  0:00:08s\n","epoch 15 | loss: 87.99316| val_0_mse: 2575.185302734375|  0:00:08s\n","epoch 16 | loss: 74.71233| val_0_mse: 2130.888427734375|  0:00:09s\n","epoch 17 | loss: 84.74354| val_0_mse: 2234.440673828125|  0:00:09s\n","epoch 18 | loss: 74.08898| val_0_mse: 2055.9921875|  0:00:10s\n","epoch 19 | loss: 65.31734| val_0_mse: 1667.3275146484375|  0:00:10s\n","epoch 20 | loss: 63.98646| val_0_mse: 1432.683349609375|  0:00:11s\n","epoch 21 | loss: 68.0308 | val_0_mse: 1116.2496337890625|  0:00:11s\n","epoch 22 | loss: 60.23753| val_0_mse: 1058.3475341796875|  0:00:12s\n","epoch 23 | loss: 53.25742| val_0_mse: 1051.8907470703125|  0:00:12s\n","epoch 24 | loss: 66.73826| val_0_mse: 767.5773315429688|  0:00:13s\n","epoch 25 | loss: 59.50189| val_0_mse: 550.3163452148438|  0:00:14s\n","epoch 26 | loss: 67.58075| val_0_mse: 222.4203338623047|  0:00:14s\n","epoch 27 | loss: 49.2911 | val_0_mse: 523.176513671875|  0:00:15s\n","epoch 28 | loss: 47.66871| val_0_mse: 354.5368347167969|  0:00:15s\n","epoch 29 | loss: 50.78217| val_0_mse: 275.9095764160156|  0:00:16s\n","epoch 30 | loss: 52.21066| val_0_mse: 293.3100280761719|  0:00:16s\n","epoch 31 | loss: 51.16069| val_0_mse: 227.85748291015625|  0:00:17s\n","epoch 32 | loss: 54.9796 | val_0_mse: 214.55233764648438|  0:00:17s\n","epoch 33 | loss: 49.418  | val_0_mse: 211.05592346191406|  0:00:18s\n","epoch 34 | loss: 60.37923| val_0_mse: 146.42689514160156|  0:00:18s\n","epoch 35 | loss: 52.49726| val_0_mse: 126.42768859863281|  0:00:19s\n","epoch 36 | loss: 60.3125 | val_0_mse: 117.39768981933594|  0:00:19s\n","epoch 37 | loss: 47.20187| val_0_mse: 98.01764678955078|  0:00:20s\n","epoch 38 | loss: 54.17765| val_0_mse: 81.06018829345703|  0:00:20s\n","epoch 39 | loss: 46.58816| val_0_mse: 82.02005004882812|  0:00:21s\n","epoch 40 | loss: 45.81107| val_0_mse: 63.93632125854492|  0:00:21s\n","epoch 41 | loss: 44.81357| val_0_mse: 63.62675094604492|  0:00:22s\n","epoch 42 | loss: 50.52513| val_0_mse: 79.29731750488281|  0:00:23s\n","epoch 43 | loss: 43.21246| val_0_mse: 63.725860595703125|  0:00:23s\n","epoch 44 | loss: 48.25093| val_0_mse: 60.36751937866211|  0:00:24s\n","epoch 45 | loss: 52.00887| val_0_mse: 63.06126022338867|  0:00:24s\n","epoch 46 | loss: 61.17127| val_0_mse: 54.57038879394531|  0:00:25s\n","epoch 47 | loss: 58.98793| val_0_mse: 68.16143798828125|  0:00:25s\n","epoch 48 | loss: 44.26021| val_0_mse: 40.15055847167969|  0:00:26s\n","epoch 49 | loss: 36.91968| val_0_mse: 27.258670806884766|  0:00:26s\n","epoch 50 | loss: 37.92594| val_0_mse: 36.84090042114258|  0:00:27s\n","epoch 51 | loss: 41.86925| val_0_mse: 27.724130630493164|  0:00:28s\n","epoch 52 | loss: 56.92353| val_0_mse: 29.689210891723633|  0:00:28s\n","epoch 53 | loss: 39.75098| val_0_mse: 48.99028015136719|  0:00:29s\n","epoch 54 | loss: 47.62258| val_0_mse: 40.04853057861328|  0:00:29s\n","epoch 55 | loss: 37.18782| val_0_mse: 34.19715881347656|  0:00:30s\n","epoch 56 | loss: 38.0751 | val_0_mse: 38.051979064941406|  0:00:30s\n","epoch 57 | loss: 49.87621| val_0_mse: 41.58729934692383|  0:00:31s\n","epoch 58 | loss: 46.91378| val_0_mse: 44.75197982788086|  0:00:31s\n","epoch 59 | loss: 39.80197| val_0_mse: 47.19607925415039|  0:00:32s\n","\n","Early stopping occurred at epoch 59 with best_epoch = 49 and best_val_0_mse = 27.258670806884766\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 13:33:44,520] Trial 57 finished with value: 27.2586727142334 and parameters: {'n_d': 57, 'n_steps': 3, 'gamma': 1.2835589745736813, 'n_independent': 2, 'n_shared': 3, 'momentum': 0.33634197024700835}. Best is trial 39 with value: 14.34697437286377.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 2340.45624| val_0_mse: 2995.302001953125|  0:00:00s\n","epoch 1  | loss: 1304.8309| val_0_mse: 4849.466796875|  0:00:01s\n","epoch 2  | loss: 465.88873| val_0_mse: 3452.189453125|  0:00:02s\n","epoch 3  | loss: 331.29377| val_0_mse: 3914.35595703125|  0:00:03s\n","epoch 4  | loss: 286.94672| val_0_mse: 3120.398193359375|  0:00:04s\n","epoch 5  | loss: 236.12618| val_0_mse: 3499.80126953125|  0:00:05s\n","epoch 6  | loss: 208.12078| val_0_mse: 2623.97119140625|  0:00:06s\n","epoch 7  | loss: 195.75432| val_0_mse: 2766.536865234375|  0:00:07s\n","epoch 8  | loss: 177.27984| val_0_mse: 2416.121337890625|  0:00:08s\n","epoch 9  | loss: 216.42552| val_0_mse: 2615.945068359375|  0:00:08s\n","epoch 10 | loss: 196.20369| val_0_mse: 2740.38037109375|  0:00:09s\n","epoch 11 | loss: 180.96625| val_0_mse: 2322.213623046875|  0:00:10s\n","epoch 12 | loss: 150.27214| val_0_mse: 2432.795166015625|  0:00:11s\n","epoch 13 | loss: 106.95268| val_0_mse: 2576.982666015625|  0:00:12s\n","epoch 14 | loss: 112.42465| val_0_mse: 2269.5830078125|  0:00:13s\n","epoch 15 | loss: 101.48605| val_0_mse: 2355.7265625|  0:00:14s\n","epoch 16 | loss: 98.2053 | val_0_mse: 2473.999755859375|  0:00:15s\n","epoch 17 | loss: 99.55398| val_0_mse: 1956.6436767578125|  0:00:16s\n","epoch 18 | loss: 91.64825| val_0_mse: 1497.9027099609375|  0:00:16s\n","epoch 19 | loss: 94.01316| val_0_mse: 1336.1639404296875|  0:00:17s\n","epoch 20 | loss: 81.61849| val_0_mse: 1250.845947265625|  0:00:18s\n","epoch 21 | loss: 83.41069| val_0_mse: 1067.388427734375|  0:00:19s\n","epoch 22 | loss: 74.13196| val_0_mse: 871.5579223632812|  0:00:20s\n","epoch 23 | loss: 84.77382| val_0_mse: 561.0943603515625|  0:00:21s\n","epoch 24 | loss: 85.43054| val_0_mse: 663.105712890625|  0:00:22s\n","epoch 25 | loss: 76.5752 | val_0_mse: 465.1422119140625|  0:00:23s\n","epoch 26 | loss: 64.91061| val_0_mse: 515.9798583984375|  0:00:24s\n","epoch 27 | loss: 72.27971| val_0_mse: 470.20208740234375|  0:00:25s\n","epoch 28 | loss: 81.06572| val_0_mse: 476.8396911621094|  0:00:26s\n","epoch 29 | loss: 62.19953| val_0_mse: 273.9726867675781|  0:00:27s\n","epoch 30 | loss: 59.73375| val_0_mse: 190.93003845214844|  0:00:27s\n","epoch 31 | loss: 62.71183| val_0_mse: 247.2165069580078|  0:00:28s\n","epoch 32 | loss: 71.02093| val_0_mse: 150.78761291503906|  0:00:29s\n","epoch 33 | loss: 72.40564| val_0_mse: 159.5896453857422|  0:00:30s\n","epoch 34 | loss: 62.44305| val_0_mse: 128.97427368164062|  0:00:31s\n","epoch 35 | loss: 81.65702| val_0_mse: 214.06546020507812|  0:00:32s\n","epoch 36 | loss: 65.99718| val_0_mse: 107.38320922851562|  0:00:33s\n","epoch 37 | loss: 75.97135| val_0_mse: 157.09385681152344|  0:00:34s\n","epoch 38 | loss: 78.71563| val_0_mse: 77.6624984741211|  0:00:35s\n","epoch 39 | loss: 100.4654| val_0_mse: 152.58383178710938|  0:00:35s\n","epoch 40 | loss: 112.10458| val_0_mse: 93.13861083984375|  0:00:36s\n","epoch 41 | loss: 58.77116| val_0_mse: 45.119300842285156|  0:00:37s\n","epoch 42 | loss: 75.15858| val_0_mse: 86.89334869384766|  0:00:38s\n","epoch 43 | loss: 64.42312| val_0_mse: 78.73078155517578|  0:00:39s\n","epoch 44 | loss: 62.32724| val_0_mse: 79.3216781616211|  0:00:40s\n","epoch 45 | loss: 66.59374| val_0_mse: 54.068721771240234|  0:00:41s\n","epoch 46 | loss: 72.46609| val_0_mse: 114.79907989501953|  0:00:42s\n","epoch 47 | loss: 66.39192| val_0_mse: 62.25743865966797|  0:00:43s\n","epoch 48 | loss: 66.67658| val_0_mse: 49.49679183959961|  0:00:44s\n","epoch 49 | loss: 55.64024| val_0_mse: 52.29227828979492|  0:00:44s\n","epoch 50 | loss: 53.4084 | val_0_mse: 40.23434066772461|  0:00:45s\n","epoch 51 | loss: 77.46568| val_0_mse: 43.8485107421875|  0:00:46s\n","epoch 52 | loss: 61.18502| val_0_mse: 48.250858306884766|  0:00:47s\n","epoch 53 | loss: 49.0003 | val_0_mse: 48.080848693847656|  0:00:48s\n","epoch 54 | loss: 60.66177| val_0_mse: 39.814178466796875|  0:00:49s\n","epoch 55 | loss: 51.32057| val_0_mse: 50.948299407958984|  0:00:50s\n","epoch 56 | loss: 51.14469| val_0_mse: 47.46263885498047|  0:00:51s\n","epoch 57 | loss: 60.35372| val_0_mse: 47.614158630371094|  0:00:52s\n","epoch 58 | loss: 52.42506| val_0_mse: 39.260719299316406|  0:00:52s\n","epoch 59 | loss: 60.2513 | val_0_mse: 73.47318267822266|  0:00:53s\n","epoch 60 | loss: 61.36308| val_0_mse: 58.16535186767578|  0:00:54s\n","epoch 61 | loss: 65.64373| val_0_mse: 34.577178955078125|  0:00:55s\n","epoch 62 | loss: 46.31093| val_0_mse: 45.4493408203125|  0:00:56s\n","epoch 63 | loss: 76.04603| val_0_mse: 74.17442321777344|  0:00:57s\n","epoch 64 | loss: 63.11191| val_0_mse: 37.55794906616211|  0:00:58s\n","epoch 65 | loss: 48.51826| val_0_mse: 43.094181060791016|  0:00:59s\n","epoch 66 | loss: 43.82235| val_0_mse: 40.23368835449219|  0:01:00s\n","epoch 67 | loss: 46.4843 | val_0_mse: 42.560150146484375|  0:01:01s\n","epoch 68 | loss: 56.29263| val_0_mse: 32.14038848876953|  0:01:01s\n","epoch 69 | loss: 42.78603| val_0_mse: 34.21923828125|  0:01:02s\n","epoch 70 | loss: 48.3482 | val_0_mse: 29.977760314941406|  0:01:03s\n","epoch 71 | loss: 41.07544| val_0_mse: 43.376068115234375|  0:01:04s\n","epoch 72 | loss: 46.0997 | val_0_mse: 31.671049118041992|  0:01:05s\n","epoch 73 | loss: 40.41689| val_0_mse: 29.528579711914062|  0:01:06s\n","epoch 74 | loss: 44.11042| val_0_mse: 24.932830810546875|  0:01:07s\n","epoch 75 | loss: 37.20578| val_0_mse: 22.352500915527344|  0:01:08s\n","epoch 76 | loss: 34.43075| val_0_mse: 20.795299530029297|  0:01:09s\n","epoch 77 | loss: 47.10846| val_0_mse: 25.528459548950195|  0:01:09s\n","epoch 78 | loss: 37.64671| val_0_mse: 31.1765193939209|  0:01:10s\n","epoch 79 | loss: 47.60546| val_0_mse: 29.317079544067383|  0:01:11s\n","epoch 80 | loss: 38.33867| val_0_mse: 26.302879333496094|  0:01:12s\n","epoch 81 | loss: 44.60272| val_0_mse: 34.13671875|  0:01:13s\n","epoch 82 | loss: 41.89079| val_0_mse: 36.80466079711914|  0:01:14s\n","epoch 83 | loss: 37.99583| val_0_mse: 19.873619079589844|  0:01:15s\n","epoch 84 | loss: 34.22939| val_0_mse: 25.45404052734375|  0:01:16s\n","epoch 85 | loss: 41.32397| val_0_mse: 25.760469436645508|  0:01:17s\n","epoch 86 | loss: 37.16091| val_0_mse: 26.456600189208984|  0:01:18s\n","epoch 87 | loss: 36.44569| val_0_mse: 51.92301940917969|  0:01:18s\n","epoch 88 | loss: 48.18699| val_0_mse: 26.88503074645996|  0:01:19s\n","epoch 89 | loss: 44.15076| val_0_mse: 27.19675064086914|  0:01:20s\n","epoch 90 | loss: 49.09319| val_0_mse: 41.53010177612305|  0:01:21s\n","epoch 91 | loss: 43.15369| val_0_mse: 23.833309173583984|  0:01:22s\n","epoch 92 | loss: 34.14266| val_0_mse: 22.80154037475586|  0:01:23s\n","epoch 93 | loss: 36.29508| val_0_mse: 31.129039764404297|  0:01:24s\n","\n","Early stopping occurred at epoch 93 with best_epoch = 83 and best_val_0_mse = 19.873619079589844\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 13:35:09,323] Trial 58 finished with value: 19.87362289428711 and parameters: {'n_d': 43, 'n_steps': 4, 'gamma': 1.4144376335328925, 'n_independent': 4, 'n_shared': 4, 'momentum': 0.30142433990000506}. Best is trial 39 with value: 14.34697437286377.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 2159.60666| val_0_mse: 5319.37451171875|  0:00:01s\n","epoch 1  | loss: 1529.69466| val_0_mse: 19351.9140625|  0:00:02s\n","epoch 2  | loss: 1090.39499| val_0_mse: 32433.060546875|  0:00:03s\n","epoch 3  | loss: 814.09286| val_0_mse: 11446.4189453125|  0:00:04s\n","epoch 4  | loss: 686.42695| val_0_mse: 5434.11669921875|  0:00:05s\n","epoch 5  | loss: 563.69113| val_0_mse: 7787.087890625|  0:00:06s\n","epoch 6  | loss: 656.58816| val_0_mse: 6478.56982421875|  0:00:07s\n","epoch 7  | loss: 582.5653| val_0_mse: 4458.4541015625|  0:00:08s\n","epoch 8  | loss: 479.71007| val_0_mse: 4181.1015625|  0:00:09s\n","epoch 9  | loss: 429.73189| val_0_mse: 3054.3466796875|  0:00:10s\n","epoch 10 | loss: 442.8041| val_0_mse: 3534.30810546875|  0:00:12s\n","epoch 11 | loss: 425.08379| val_0_mse: 4806.87255859375|  0:00:13s\n","epoch 12 | loss: 440.5692| val_0_mse: 3387.58837890625|  0:00:14s\n","epoch 13 | loss: 473.33743| val_0_mse: 2583.19384765625|  0:00:15s\n","epoch 14 | loss: 417.96271| val_0_mse: 2408.235595703125|  0:00:16s\n","epoch 15 | loss: 398.81064| val_0_mse: 2550.500732421875|  0:00:17s\n","epoch 16 | loss: 411.07898| val_0_mse: 2133.596435546875|  0:00:18s\n","epoch 17 | loss: 378.95204| val_0_mse: 2339.982666015625|  0:00:19s\n","epoch 18 | loss: 391.25765| val_0_mse: 2436.968017578125|  0:00:20s\n","epoch 19 | loss: 363.69039| val_0_mse: 2876.501708984375|  0:00:21s\n","epoch 20 | loss: 294.78526| val_0_mse: 2427.540771484375|  0:00:23s\n","epoch 21 | loss: 255.82867| val_0_mse: 1598.869873046875|  0:00:24s\n","epoch 22 | loss: 247.79313| val_0_mse: 1014.4774169921875|  0:00:25s\n","epoch 23 | loss: 279.61589| val_0_mse: 961.2975463867188|  0:00:26s\n","epoch 24 | loss: 277.72163| val_0_mse: 1094.276123046875|  0:00:27s\n","epoch 25 | loss: 281.66019| val_0_mse: 885.10205078125|  0:00:28s\n","epoch 26 | loss: 245.92385| val_0_mse: 687.0728759765625|  0:00:29s\n","epoch 27 | loss: 251.54364| val_0_mse: 622.8145751953125|  0:00:30s\n","epoch 28 | loss: 276.93708| val_0_mse: 796.8444213867188|  0:00:31s\n","epoch 29 | loss: 451.66671| val_0_mse: 868.2986450195312|  0:00:33s\n","epoch 30 | loss: 332.06454| val_0_mse: 431.9012451171875|  0:00:34s\n","epoch 31 | loss: 260.44727| val_0_mse: 309.0443420410156|  0:00:35s\n","epoch 32 | loss: 257.99429| val_0_mse: 277.91815185546875|  0:00:36s\n","epoch 33 | loss: 192.13962| val_0_mse: 265.6634216308594|  0:00:37s\n","epoch 34 | loss: 150.90649| val_0_mse: 194.82626342773438|  0:00:38s\n","epoch 35 | loss: 141.36241| val_0_mse: 165.66575622558594|  0:00:39s\n","epoch 36 | loss: 117.52433| val_0_mse: 144.51271057128906|  0:00:40s\n","epoch 37 | loss: 128.75311| val_0_mse: 173.95831298828125|  0:00:41s\n","epoch 38 | loss: 136.80147| val_0_mse: 130.85511779785156|  0:00:43s\n","epoch 39 | loss: 179.69491| val_0_mse: 211.85104370117188|  0:00:44s\n","epoch 40 | loss: 166.58724| val_0_mse: 112.02837371826172|  0:00:45s\n","epoch 41 | loss: 128.86825| val_0_mse: 85.34723663330078|  0:00:46s\n","epoch 42 | loss: 108.33921| val_0_mse: 118.73777770996094|  0:00:47s\n","epoch 43 | loss: 114.78103| val_0_mse: 74.64028930664062|  0:00:48s\n","epoch 44 | loss: 98.58041| val_0_mse: 63.94921875|  0:00:49s\n","epoch 45 | loss: 102.54858| val_0_mse: 76.1343002319336|  0:00:50s\n","epoch 46 | loss: 117.33109| val_0_mse: 61.40034103393555|  0:00:51s\n","epoch 47 | loss: 115.9993| val_0_mse: 161.0304718017578|  0:00:53s\n","epoch 48 | loss: 141.63115| val_0_mse: 82.7999496459961|  0:00:54s\n","epoch 49 | loss: 124.14459| val_0_mse: 65.84600067138672|  0:00:55s\n","epoch 50 | loss: 115.31962| val_0_mse: 56.16054153442383|  0:00:56s\n","epoch 51 | loss: 90.07774| val_0_mse: 67.55818176269531|  0:00:57s\n","epoch 52 | loss: 107.14825| val_0_mse: 73.01998138427734|  0:00:58s\n","epoch 53 | loss: 94.16013| val_0_mse: 47.70246887207031|  0:00:59s\n","epoch 54 | loss: 97.39371| val_0_mse: 60.14582061767578|  0:01:00s\n","epoch 55 | loss: 91.21652| val_0_mse: 65.17761993408203|  0:01:01s\n","epoch 56 | loss: 101.5142| val_0_mse: 57.55060958862305|  0:01:03s\n","epoch 57 | loss: 111.40702| val_0_mse: 54.639869689941406|  0:01:04s\n","epoch 58 | loss: 111.03716| val_0_mse: 58.97201156616211|  0:01:05s\n","epoch 59 | loss: 104.24251| val_0_mse: 44.35070037841797|  0:01:06s\n","epoch 60 | loss: 111.25192| val_0_mse: 44.70996856689453|  0:01:07s\n","epoch 61 | loss: 90.83091| val_0_mse: 43.753631591796875|  0:01:08s\n","epoch 62 | loss: 84.85572| val_0_mse: 31.60886001586914|  0:01:09s\n","epoch 63 | loss: 79.31234| val_0_mse: 42.89104080200195|  0:01:10s\n","epoch 64 | loss: 194.98607| val_0_mse: 170.59254455566406|  0:01:11s\n","epoch 65 | loss: 122.70595| val_0_mse: 74.44403839111328|  0:01:12s\n","epoch 66 | loss: 96.21086| val_0_mse: 45.8367805480957|  0:01:13s\n","epoch 67 | loss: 82.09542| val_0_mse: 45.95875930786133|  0:01:15s\n","epoch 68 | loss: 70.65319| val_0_mse: 39.97547912597656|  0:01:16s\n","epoch 69 | loss: 75.56395| val_0_mse: 33.29050064086914|  0:01:17s\n","epoch 70 | loss: 81.24744| val_0_mse: 29.31747055053711|  0:01:18s\n","epoch 71 | loss: 83.40594| val_0_mse: 35.932559967041016|  0:01:19s\n","epoch 72 | loss: 103.24394| val_0_mse: 53.90800094604492|  0:01:20s\n","epoch 73 | loss: 111.84247| val_0_mse: 48.513938903808594|  0:01:21s\n","epoch 74 | loss: 77.82047| val_0_mse: 39.69807815551758|  0:01:22s\n","epoch 75 | loss: 71.20294| val_0_mse: 43.273841857910156|  0:01:24s\n","epoch 76 | loss: 78.96827| val_0_mse: 38.75727081298828|  0:01:25s\n","epoch 77 | loss: 79.45097| val_0_mse: 40.6515998840332|  0:01:26s\n","epoch 78 | loss: 82.16679| val_0_mse: 33.921241760253906|  0:01:27s\n","epoch 79 | loss: 87.31115| val_0_mse: 31.621440887451172|  0:01:28s\n","epoch 80 | loss: 91.417  | val_0_mse: 52.71393966674805|  0:01:29s\n","\n","Early stopping occurred at epoch 80 with best_epoch = 70 and best_val_0_mse = 29.31747055053711\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 13:36:39,380] Trial 59 finished with value: 29.31747055053711 and parameters: {'n_d': 52, 'n_steps': 6, 'gamma': 1.554458755414206, 'n_independent': 2, 'n_shared': 5, 'momentum': 0.10761922269553227}. Best is trial 39 with value: 14.34697437286377.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 2195.47458| val_0_mse: 5327.6787109375|  0:00:01s\n","epoch 1  | loss: 1484.14167| val_0_mse: 5273.201171875|  0:00:02s\n","epoch 2  | loss: 905.32516| val_0_mse: 9738.888671875|  0:00:03s\n","epoch 3  | loss: 546.48581| val_0_mse: 10815.5537109375|  0:00:05s\n","epoch 4  | loss: 421.78499| val_0_mse: 4967.7177734375|  0:00:06s\n","epoch 5  | loss: 356.24273| val_0_mse: 4253.8408203125|  0:00:07s\n","epoch 6  | loss: 328.40034| val_0_mse: 4970.24755859375|  0:00:08s\n","epoch 7  | loss: 292.57911| val_0_mse: 4630.87158203125|  0:00:09s\n","epoch 8  | loss: 271.76817| val_0_mse: 3682.78076171875|  0:00:11s\n","epoch 9  | loss: 297.16301| val_0_mse: 3456.641357421875|  0:00:12s\n","epoch 10 | loss: 272.64424| val_0_mse: 3286.959716796875|  0:00:13s\n","epoch 11 | loss: 252.25749| val_0_mse: 2821.3056640625|  0:00:15s\n","epoch 12 | loss: 223.26643| val_0_mse: 2810.29833984375|  0:00:16s\n","epoch 13 | loss: 192.52931| val_0_mse: 2732.84521484375|  0:00:17s\n","epoch 14 | loss: 196.5132| val_0_mse: 2620.7880859375|  0:00:18s\n","epoch 15 | loss: 194.99995| val_0_mse: 2529.523193359375|  0:00:20s\n","epoch 16 | loss: 181.74906| val_0_mse: 2309.802001953125|  0:00:21s\n","epoch 17 | loss: 170.61729| val_0_mse: 2376.312255859375|  0:00:22s\n","epoch 18 | loss: 186.12881| val_0_mse: 2195.39501953125|  0:00:24s\n","epoch 19 | loss: 172.05005| val_0_mse: 2667.5126953125|  0:00:25s\n","epoch 20 | loss: 141.09962| val_0_mse: 2051.20166015625|  0:00:26s\n","epoch 21 | loss: 127.12045| val_0_mse: 1627.5789794921875|  0:00:27s\n","epoch 22 | loss: 131.8452| val_0_mse: 1103.53369140625|  0:00:29s\n","epoch 23 | loss: 113.25162| val_0_mse: 1319.4873046875|  0:00:30s\n","epoch 24 | loss: 117.59978| val_0_mse: 1160.7322998046875|  0:00:31s\n","epoch 25 | loss: 115.37704| val_0_mse: 1090.93603515625|  0:00:32s\n","epoch 26 | loss: 109.36062| val_0_mse: 739.6732788085938|  0:00:33s\n","epoch 27 | loss: 101.74159| val_0_mse: 650.358154296875|  0:00:35s\n","epoch 28 | loss: 96.27875| val_0_mse: 675.7719116210938|  0:00:36s\n","epoch 29 | loss: 100.92629| val_0_mse: 444.719970703125|  0:00:37s\n","epoch 30 | loss: 94.60781| val_0_mse: 563.48681640625|  0:00:39s\n","epoch 31 | loss: 101.16774| val_0_mse: 345.705810546875|  0:00:40s\n","epoch 32 | loss: 85.10686| val_0_mse: 453.6895751953125|  0:00:41s\n","epoch 33 | loss: 104.97987| val_0_mse: 244.41726684570312|  0:00:42s\n","epoch 34 | loss: 84.7745 | val_0_mse: 208.37466430664062|  0:00:43s\n","epoch 35 | loss: 79.05133| val_0_mse: 134.8260040283203|  0:00:45s\n","epoch 36 | loss: 86.12119| val_0_mse: 133.89346313476562|  0:00:46s\n","epoch 37 | loss: 104.45394| val_0_mse: 202.45924377441406|  0:00:47s\n","epoch 38 | loss: 84.85423| val_0_mse: 167.00563049316406|  0:00:49s\n","epoch 39 | loss: 78.63201| val_0_mse: 147.83987426757812|  0:00:50s\n","epoch 40 | loss: 83.81643| val_0_mse: 76.46192169189453|  0:00:51s\n","epoch 41 | loss: 77.86174| val_0_mse: 94.04676818847656|  0:00:52s\n","epoch 42 | loss: 71.95663| val_0_mse: 142.929443359375|  0:00:54s\n","epoch 43 | loss: 75.14208| val_0_mse: 71.80789947509766|  0:00:55s\n","epoch 44 | loss: 91.06822| val_0_mse: 75.1941909790039|  0:00:56s\n","epoch 45 | loss: 77.33647| val_0_mse: 74.39573669433594|  0:00:57s\n","epoch 46 | loss: 78.7558 | val_0_mse: 90.64276885986328|  0:00:59s\n","epoch 47 | loss: 80.91879| val_0_mse: 48.08749008178711|  0:01:00s\n","epoch 48 | loss: 82.83374| val_0_mse: 52.08258056640625|  0:01:01s\n","epoch 49 | loss: 81.54219| val_0_mse: 69.80206298828125|  0:01:02s\n","epoch 50 | loss: 72.31475| val_0_mse: 54.232261657714844|  0:01:04s\n","epoch 51 | loss: 72.93599| val_0_mse: 61.274269104003906|  0:01:05s\n","epoch 52 | loss: 79.92805| val_0_mse: 114.61325073242188|  0:01:06s\n","epoch 53 | loss: 91.67014| val_0_mse: 75.85343933105469|  0:01:07s\n","epoch 54 | loss: 76.2221 | val_0_mse: 55.84458923339844|  0:01:09s\n","epoch 55 | loss: 86.68171| val_0_mse: 53.684898376464844|  0:01:10s\n","epoch 56 | loss: 70.97135| val_0_mse: 43.7860107421875|  0:01:11s\n","epoch 57 | loss: 62.05236| val_0_mse: 44.43550109863281|  0:01:13s\n","epoch 58 | loss: 64.37477| val_0_mse: 48.476741790771484|  0:01:14s\n","epoch 59 | loss: 55.87924| val_0_mse: 47.029178619384766|  0:01:15s\n","epoch 60 | loss: 78.53942| val_0_mse: 60.692378997802734|  0:01:16s\n","epoch 61 | loss: 64.39333| val_0_mse: 60.16239929199219|  0:01:18s\n","epoch 62 | loss: 51.92503| val_0_mse: 51.135398864746094|  0:01:19s\n","epoch 63 | loss: 57.0959 | val_0_mse: 62.35078048706055|  0:01:20s\n","epoch 64 | loss: 57.39167| val_0_mse: 39.86486053466797|  0:01:21s\n","epoch 65 | loss: 51.9756 | val_0_mse: 46.98741912841797|  0:01:22s\n","epoch 66 | loss: 61.82694| val_0_mse: 66.49826049804688|  0:01:24s\n","epoch 67 | loss: 56.53773| val_0_mse: 41.96876907348633|  0:01:25s\n","epoch 68 | loss: 45.816  | val_0_mse: 42.19417190551758|  0:01:26s\n","epoch 69 | loss: 47.88251| val_0_mse: 31.678680419921875|  0:01:27s\n","epoch 70 | loss: 40.15724| val_0_mse: 36.75381088256836|  0:01:29s\n","epoch 71 | loss: 47.6037 | val_0_mse: 27.73419952392578|  0:01:30s\n","epoch 72 | loss: 41.56196| val_0_mse: 33.49232864379883|  0:01:31s\n","epoch 73 | loss: 43.66969| val_0_mse: 26.7048397064209|  0:01:32s\n","epoch 74 | loss: 38.69856| val_0_mse: 33.700740814208984|  0:01:34s\n","epoch 75 | loss: 43.64701| val_0_mse: 30.841419219970703|  0:01:35s\n","epoch 76 | loss: 38.34087| val_0_mse: 24.348560333251953|  0:01:36s\n","epoch 77 | loss: 43.49621| val_0_mse: 36.90945053100586|  0:01:38s\n","epoch 78 | loss: 45.6851 | val_0_mse: 28.384740829467773|  0:01:39s\n","epoch 79 | loss: 34.87156| val_0_mse: 26.231660842895508|  0:01:40s\n","epoch 80 | loss: 42.39647| val_0_mse: 23.219629287719727|  0:01:41s\n","epoch 81 | loss: 47.83905| val_0_mse: 31.26091957092285|  0:01:42s\n","epoch 82 | loss: 34.64574| val_0_mse: 31.594879150390625|  0:01:43s\n","epoch 83 | loss: 38.97378| val_0_mse: 26.897480010986328|  0:01:45s\n","epoch 84 | loss: 52.37244| val_0_mse: 42.99325942993164|  0:01:46s\n","epoch 85 | loss: 59.255  | val_0_mse: 51.35808181762695|  0:01:47s\n","epoch 86 | loss: 60.73328| val_0_mse: 28.73077964782715|  0:01:48s\n","epoch 87 | loss: 36.8007 | val_0_mse: 29.9406795501709|  0:01:49s\n","epoch 88 | loss: 37.8697 | val_0_mse: 41.511451721191406|  0:01:51s\n","epoch 89 | loss: 37.14947| val_0_mse: 29.607879638671875|  0:01:52s\n","epoch 90 | loss: 38.75553| val_0_mse: 28.287879943847656|  0:01:53s\n","\n","Early stopping occurred at epoch 90 with best_epoch = 80 and best_val_0_mse = 23.219629287719727\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 13:38:33,471] Trial 60 finished with value: 23.219629287719727 and parameters: {'n_d': 35, 'n_steps': 7, 'gamma': 1.074039219863626, 'n_independent': 3, 'n_shared': 4, 'momentum': 0.04110343526488591}. Best is trial 39 with value: 14.34697437286377.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 2091.82971| val_0_mse: 8345.0791015625|  0:00:00s\n","epoch 1  | loss: 879.83514| val_0_mse: 2298.78466796875|  0:00:01s\n","epoch 2  | loss: 422.86676| val_0_mse: 2741.6279296875|  0:00:01s\n","epoch 3  | loss: 277.25166| val_0_mse: 2812.97607421875|  0:00:02s\n","epoch 4  | loss: 206.91034| val_0_mse: 2734.181640625|  0:00:02s\n","epoch 5  | loss: 162.14173| val_0_mse: 2583.42041015625|  0:00:03s\n","epoch 6  | loss: 146.42421| val_0_mse: 2707.859619140625|  0:00:04s\n","epoch 7  | loss: 115.80788| val_0_mse: 2551.58056640625|  0:00:04s\n","epoch 8  | loss: 112.14913| val_0_mse: 2659.35791015625|  0:00:05s\n","epoch 9  | loss: 121.29426| val_0_mse: 2675.614990234375|  0:00:05s\n","epoch 10 | loss: 95.06484| val_0_mse: 2599.1923828125|  0:00:06s\n","epoch 11 | loss: 90.92953| val_0_mse: 2611.922119140625|  0:00:06s\n","\n","Early stopping occurred at epoch 11 with best_epoch = 1 and best_val_0_mse = 2298.78466796875\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 13:38:40,652] Trial 61 finished with value: 2298.78466796875 and parameters: {'n_d': 45, 'n_steps': 3, 'gamma': 1.3282300765260846, 'n_independent': 2, 'n_shared': 4, 'momentum': 0.24788718521214312}. Best is trial 39 with value: 14.34697437286377.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 2245.91185| val_0_mse: 3108.52197265625|  0:00:00s\n","epoch 1  | loss: 1030.16685| val_0_mse: 2381.075439453125|  0:00:01s\n","epoch 2  | loss: 390.86884| val_0_mse: 2733.217529296875|  0:00:01s\n","epoch 3  | loss: 224.99875| val_0_mse: 2712.515625|  0:00:02s\n","epoch 4  | loss: 180.44161| val_0_mse: 2470.966064453125|  0:00:02s\n","epoch 5  | loss: 140.24172| val_0_mse: 2939.038818359375|  0:00:03s\n","epoch 6  | loss: 123.53728| val_0_mse: 2656.130615234375|  0:00:03s\n","epoch 7  | loss: 111.1006| val_0_mse: 2594.248046875|  0:00:04s\n","epoch 8  | loss: 100.10124| val_0_mse: 2492.72265625|  0:00:04s\n","epoch 9  | loss: 95.44556| val_0_mse: 2534.875244140625|  0:00:05s\n","epoch 10 | loss: 92.176  | val_0_mse: 2715.7529296875|  0:00:05s\n","epoch 11 | loss: 93.74536| val_0_mse: 2535.791748046875|  0:00:06s\n","\n","Early stopping occurred at epoch 11 with best_epoch = 1 and best_val_0_mse = 2381.075439453125\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 13:38:47,189] Trial 62 finished with value: 2381.075439453125 and parameters: {'n_d': 41, 'n_steps': 3, 'gamma': 1.4349137699544154, 'n_independent': 2, 'n_shared': 3, 'momentum': 0.20299912603244374}. Best is trial 39 with value: 14.34697437286377.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 2192.85602| val_0_mse: 2851.609619140625|  0:00:00s\n","epoch 1  | loss: 954.86841| val_0_mse: 3246.63037109375|  0:00:01s\n","epoch 2  | loss: 445.72175| val_0_mse: 4064.544677734375|  0:00:01s\n","epoch 3  | loss: 271.54658| val_0_mse: 4277.75732421875|  0:00:02s\n","epoch 4  | loss: 189.27647| val_0_mse: 2690.82666015625|  0:00:02s\n","epoch 5  | loss: 136.5447| val_0_mse: 3104.225341796875|  0:00:03s\n","epoch 6  | loss: 110.05681| val_0_mse: 2774.99658203125|  0:00:03s\n","epoch 7  | loss: 95.55247| val_0_mse: 2768.490234375|  0:00:04s\n","epoch 8  | loss: 90.34111| val_0_mse: 2693.318115234375|  0:00:04s\n","epoch 9  | loss: 80.47885| val_0_mse: 2608.78466796875|  0:00:05s\n","epoch 10 | loss: 80.86394| val_0_mse: 2732.6669921875|  0:00:05s\n","epoch 11 | loss: 75.40772| val_0_mse: 2706.453369140625|  0:00:06s\n","epoch 12 | loss: 68.44164| val_0_mse: 2580.70263671875|  0:00:06s\n","epoch 13 | loss: 76.05781| val_0_mse: 2426.470458984375|  0:00:07s\n","epoch 14 | loss: 73.87424| val_0_mse: 2362.85205078125|  0:00:07s\n","epoch 15 | loss: 74.02733| val_0_mse: 2326.36962890625|  0:00:08s\n","epoch 16 | loss: 69.30971| val_0_mse: 2156.6376953125|  0:00:08s\n","epoch 17 | loss: 62.32013| val_0_mse: 1822.5416259765625|  0:00:09s\n","epoch 18 | loss: 58.72697| val_0_mse: 1825.652099609375|  0:00:09s\n","epoch 19 | loss: 70.61918| val_0_mse: 1664.4326171875|  0:00:10s\n","epoch 20 | loss: 55.17139| val_0_mse: 1243.9703369140625|  0:00:10s\n","epoch 21 | loss: 65.39861| val_0_mse: 1118.3548583984375|  0:00:11s\n","epoch 22 | loss: 58.65411| val_0_mse: 1182.7738037109375|  0:00:11s\n","epoch 23 | loss: 55.89966| val_0_mse: 793.1534423828125|  0:00:12s\n","epoch 24 | loss: 59.63681| val_0_mse: 781.8434448242188|  0:00:12s\n","epoch 25 | loss: 47.29456| val_0_mse: 651.6854858398438|  0:00:13s\n","epoch 26 | loss: 52.82999| val_0_mse: 646.5481567382812|  0:00:13s\n","epoch 27 | loss: 57.98107| val_0_mse: 376.5122375488281|  0:00:14s\n","epoch 28 | loss: 61.87734| val_0_mse: 443.3414306640625|  0:00:14s\n","epoch 29 | loss: 61.25637| val_0_mse: 326.0547180175781|  0:00:15s\n","epoch 30 | loss: 48.72574| val_0_mse: 254.59927368164062|  0:00:15s\n","epoch 31 | loss: 45.20553| val_0_mse: 140.34994506835938|  0:00:16s\n","epoch 32 | loss: 56.30152| val_0_mse: 168.29544067382812|  0:00:16s\n","epoch 33 | loss: 52.73956| val_0_mse: 210.9375|  0:00:17s\n","epoch 34 | loss: 49.38311| val_0_mse: 140.41993713378906|  0:00:18s\n","epoch 35 | loss: 54.99603| val_0_mse: 80.63645935058594|  0:00:18s\n","epoch 36 | loss: 48.66465| val_0_mse: 152.774169921875|  0:00:19s\n","epoch 37 | loss: 52.92854| val_0_mse: 63.505001068115234|  0:00:19s\n","epoch 38 | loss: 41.27637| val_0_mse: 87.60315704345703|  0:00:20s\n","epoch 39 | loss: 45.88364| val_0_mse: 93.3099594116211|  0:00:20s\n","epoch 40 | loss: 44.75423| val_0_mse: 75.43572235107422|  0:00:21s\n","epoch 41 | loss: 42.76823| val_0_mse: 79.70745086669922|  0:00:21s\n","epoch 42 | loss: 54.93701| val_0_mse: 84.68885040283203|  0:00:22s\n","epoch 43 | loss: 62.02923| val_0_mse: 60.74763870239258|  0:00:22s\n","epoch 44 | loss: 47.51417| val_0_mse: 40.9729118347168|  0:00:23s\n","epoch 45 | loss: 50.17681| val_0_mse: 32.33140182495117|  0:00:23s\n","epoch 46 | loss: 37.12708| val_0_mse: 34.51594161987305|  0:00:24s\n","epoch 47 | loss: 34.23838| val_0_mse: 45.425140380859375|  0:00:25s\n","epoch 48 | loss: 43.57206| val_0_mse: 25.858909606933594|  0:00:25s\n","epoch 49 | loss: 41.87272| val_0_mse: 23.50882911682129|  0:00:26s\n","epoch 50 | loss: 45.69024| val_0_mse: 32.067901611328125|  0:00:26s\n","epoch 51 | loss: 31.87436| val_0_mse: 36.15718078613281|  0:00:27s\n","epoch 52 | loss: 35.73392| val_0_mse: 42.50764083862305|  0:00:27s\n","epoch 53 | loss: 33.62959| val_0_mse: 20.635780334472656|  0:00:28s\n","epoch 54 | loss: 51.57637| val_0_mse: 32.525779724121094|  0:00:28s\n","epoch 55 | loss: 42.19861| val_0_mse: 29.78622055053711|  0:00:29s\n","epoch 56 | loss: 36.54473| val_0_mse: 20.50827980041504|  0:00:29s\n","epoch 57 | loss: 47.60778| val_0_mse: 19.43408966064453|  0:00:30s\n","epoch 58 | loss: 55.43231| val_0_mse: 74.16336822509766|  0:00:30s\n","epoch 59 | loss: 41.25913| val_0_mse: 31.36404037475586|  0:00:31s\n","epoch 60 | loss: 41.68016| val_0_mse: 23.537660598754883|  0:00:31s\n","epoch 61 | loss: 42.69642| val_0_mse: 39.39474105834961|  0:00:32s\n","epoch 62 | loss: 40.59628| val_0_mse: 22.517379760742188|  0:00:32s\n","epoch 63 | loss: 36.95461| val_0_mse: 25.091320037841797|  0:00:32s\n","epoch 64 | loss: 33.20444| val_0_mse: 16.860109329223633|  0:00:33s\n","epoch 65 | loss: 33.6985 | val_0_mse: 19.48155975341797|  0:00:33s\n","epoch 66 | loss: 34.83225| val_0_mse: 20.404399871826172|  0:00:34s\n","epoch 67 | loss: 32.58093| val_0_mse: 23.234460830688477|  0:00:35s\n","epoch 68 | loss: 34.91177| val_0_mse: 23.417890548706055|  0:00:35s\n","epoch 69 | loss: 34.20348| val_0_mse: 47.241371154785156|  0:00:36s\n","epoch 70 | loss: 48.43895| val_0_mse: 32.19633865356445|  0:00:36s\n","epoch 71 | loss: 49.21058| val_0_mse: 55.15155029296875|  0:00:36s\n","epoch 72 | loss: 46.35183| val_0_mse: 53.219139099121094|  0:00:37s\n","epoch 73 | loss: 51.85418| val_0_mse: 37.91788864135742|  0:00:37s\n","epoch 74 | loss: 38.67887| val_0_mse: 35.78187942504883|  0:00:38s\n","\n","Early stopping occurred at epoch 74 with best_epoch = 64 and best_val_0_mse = 16.860109329223633\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 13:39:25,952] Trial 63 finished with value: 16.860107421875 and parameters: {'n_d': 46, 'n_steps': 3, 'gamma': 1.395672886948799, 'n_independent': 1, 'n_shared': 4, 'momentum': 0.23844183016744233}. Best is trial 39 with value: 14.34697437286377.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 2169.87887| val_0_mse: 3386.376708984375|  0:00:00s\n","epoch 1  | loss: 978.61097| val_0_mse: 2537.94677734375|  0:00:00s\n","epoch 2  | loss: 381.85681| val_0_mse: 3162.762451171875|  0:00:01s\n","epoch 3  | loss: 210.73465| val_0_mse: 3298.391357421875|  0:00:01s\n","epoch 4  | loss: 174.71157| val_0_mse: 2139.7216796875|  0:00:02s\n","epoch 5  | loss: 152.85637| val_0_mse: 2708.228271484375|  0:00:02s\n","epoch 6  | loss: 129.92772| val_0_mse: 2520.283935546875|  0:00:03s\n","epoch 7  | loss: 104.87643| val_0_mse: 2644.8955078125|  0:00:03s\n","epoch 8  | loss: 97.7668 | val_0_mse: 2882.810546875|  0:00:04s\n","epoch 9  | loss: 110.62134| val_0_mse: 2651.259765625|  0:00:04s\n","epoch 10 | loss: 96.21972| val_0_mse: 2571.765625|  0:00:05s\n","epoch 11 | loss: 74.59094| val_0_mse: 2495.9267578125|  0:00:06s\n","epoch 12 | loss: 84.47022| val_0_mse: 2757.262939453125|  0:00:06s\n","epoch 13 | loss: 89.80596| val_0_mse: 2506.728759765625|  0:00:07s\n","epoch 14 | loss: 94.3985 | val_0_mse: 2621.75 |  0:00:07s\n","\n","Early stopping occurred at epoch 14 with best_epoch = 4 and best_val_0_mse = 2139.7216796875\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 13:39:33,916] Trial 64 finished with value: 2139.7216796875 and parameters: {'n_d': 50, 'n_steps': 3, 'gamma': 1.4798694954885405, 'n_independent': 1, 'n_shared': 4, 'momentum': 0.21915253924431782}. Best is trial 39 with value: 14.34697437286377.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 2169.12013| val_0_mse: 2715.654052734375|  0:00:00s\n","epoch 1  | loss: 1359.88402| val_0_mse: 2266.617431640625|  0:00:01s\n","epoch 2  | loss: 894.68578| val_0_mse: 2882.00732421875|  0:00:01s\n","epoch 3  | loss: 651.23142| val_0_mse: 3981.8291015625|  0:00:02s\n","epoch 4  | loss: 383.29961| val_0_mse: 5021.99853515625|  0:00:02s\n","epoch 5  | loss: 255.25332| val_0_mse: 3447.14599609375|  0:00:03s\n","epoch 6  | loss: 205.53153| val_0_mse: 3184.652099609375|  0:00:03s\n","epoch 7  | loss: 169.53243| val_0_mse: 3188.3525390625|  0:00:04s\n","epoch 8  | loss: 160.45102| val_0_mse: 2910.08203125|  0:00:04s\n","epoch 9  | loss: 135.39343| val_0_mse: 2510.1943359375|  0:00:05s\n","epoch 10 | loss: 110.51995| val_0_mse: 2734.99755859375|  0:00:05s\n","epoch 11 | loss: 120.50615| val_0_mse: 2632.153076171875|  0:00:06s\n","\n","Early stopping occurred at epoch 11 with best_epoch = 1 and best_val_0_mse = 2266.617431640625\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 13:39:40,616] Trial 65 finished with value: 2266.617431640625 and parameters: {'n_d': 38, 'n_steps': 4, 'gamma': 1.3939208679020534, 'n_independent': 1, 'n_shared': 3, 'momentum': 0.2894805218962584}. Best is trial 39 with value: 14.34697437286377.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 2190.23604| val_0_mse: 5608.646484375|  0:00:00s\n","epoch 1  | loss: 783.33626| val_0_mse: 3425.580078125|  0:00:01s\n","epoch 2  | loss: 291.2573| val_0_mse: 2764.030517578125|  0:00:01s\n","epoch 3  | loss: 203.6232| val_0_mse: 2858.384521484375|  0:00:02s\n","epoch 4  | loss: 148.4988| val_0_mse: 2487.117919921875|  0:00:02s\n","epoch 5  | loss: 150.20296| val_0_mse: 2638.10498046875|  0:00:03s\n","epoch 6  | loss: 140.38216| val_0_mse: 2636.444580078125|  0:00:04s\n","epoch 7  | loss: 107.14212| val_0_mse: 2728.58837890625|  0:00:04s\n","epoch 8  | loss: 105.69459| val_0_mse: 2772.61083984375|  0:00:05s\n","epoch 9  | loss: 89.20052| val_0_mse: 2625.592041015625|  0:00:05s\n","epoch 10 | loss: 82.5205 | val_0_mse: 2676.9814453125|  0:00:06s\n","epoch 11 | loss: 84.61406| val_0_mse: 2609.80322265625|  0:00:06s\n","epoch 12 | loss: 81.96982| val_0_mse: 2653.494384765625|  0:00:07s\n","epoch 13 | loss: 79.47692| val_0_mse: 2598.993408203125|  0:00:08s\n","epoch 14 | loss: 82.02868| val_0_mse: 2653.19677734375|  0:00:08s\n","\n","Early stopping occurred at epoch 14 with best_epoch = 4 and best_val_0_mse = 2487.117919921875\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 13:39:49,727] Trial 66 finished with value: 2487.117919921875 and parameters: {'n_d': 45, 'n_steps': 3, 'gamma': 1.3112360605203064, 'n_independent': 1, 'n_shared': 5, 'momentum': 0.26797400007225936}. Best is trial 39 with value: 14.34697437286377.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 2235.69396| val_0_mse: 2864.71337890625|  0:00:00s\n","epoch 1  | loss: 1434.97918| val_0_mse: 4329.7080078125|  0:00:01s\n","epoch 2  | loss: 746.82191| val_0_mse: 9910.203125|  0:00:01s\n","epoch 3  | loss: 415.34179| val_0_mse: 4276.89404296875|  0:00:02s\n","epoch 4  | loss: 322.50527| val_0_mse: 3514.238037109375|  0:00:03s\n","epoch 5  | loss: 307.15366| val_0_mse: 3391.68603515625|  0:00:03s\n","epoch 6  | loss: 306.82447| val_0_mse: 2999.511962890625|  0:00:04s\n","epoch 7  | loss: 261.35207| val_0_mse: 2728.977294921875|  0:00:05s\n","epoch 8  | loss: 231.58606| val_0_mse: 3032.6533203125|  0:00:05s\n","epoch 9  | loss: 191.76426| val_0_mse: 3021.261962890625|  0:00:06s\n","epoch 10 | loss: 176.77065| val_0_mse: 2734.781982421875|  0:00:07s\n","epoch 11 | loss: 157.11044| val_0_mse: 2368.801513671875|  0:00:07s\n","epoch 12 | loss: 140.42958| val_0_mse: 2560.077880859375|  0:00:08s\n","epoch 13 | loss: 146.25719| val_0_mse: 2249.71435546875|  0:00:09s\n","epoch 14 | loss: 127.93857| val_0_mse: 2021.1492919921875|  0:00:09s\n","epoch 15 | loss: 129.45087| val_0_mse: 1976.5892333984375|  0:00:10s\n","epoch 16 | loss: 126.86875| val_0_mse: 2194.045654296875|  0:00:11s\n","epoch 17 | loss: 95.96442| val_0_mse: 1605.017333984375|  0:00:11s\n","epoch 18 | loss: 100.77493| val_0_mse: 1344.7113037109375|  0:00:12s\n","epoch 19 | loss: 98.88011| val_0_mse: 899.0919189453125|  0:00:13s\n","epoch 20 | loss: 94.44621| val_0_mse: 881.2034912109375|  0:00:13s\n","epoch 21 | loss: 109.4349| val_0_mse: 713.7533569335938|  0:00:14s\n","epoch 22 | loss: 92.87335| val_0_mse: 758.579833984375|  0:00:14s\n","epoch 23 | loss: 114.54938| val_0_mse: 633.5506591796875|  0:00:15s\n","epoch 24 | loss: 98.96492| val_0_mse: 531.5485229492188|  0:00:16s\n","epoch 25 | loss: 96.643  | val_0_mse: 449.26849365234375|  0:00:16s\n","epoch 26 | loss: 97.86712| val_0_mse: 377.7087097167969|  0:00:17s\n","epoch 27 | loss: 67.5715 | val_0_mse: 305.10614013671875|  0:00:18s\n","epoch 28 | loss: 95.8413 | val_0_mse: 331.14019775390625|  0:00:18s\n","epoch 29 | loss: 69.38689| val_0_mse: 347.70611572265625|  0:00:19s\n","epoch 30 | loss: 90.14954| val_0_mse: 227.15016174316406|  0:00:20s\n","epoch 31 | loss: 77.10445| val_0_mse: 144.8949737548828|  0:00:20s\n","epoch 32 | loss: 65.50765| val_0_mse: 200.9752655029297|  0:00:21s\n","epoch 33 | loss: 72.37948| val_0_mse: 182.60171508789062|  0:00:22s\n","epoch 34 | loss: 66.50789| val_0_mse: 106.08125305175781|  0:00:22s\n","epoch 35 | loss: 82.5506 | val_0_mse: 138.01058959960938|  0:00:23s\n","epoch 36 | loss: 73.17499| val_0_mse: 152.02232360839844|  0:00:24s\n","epoch 37 | loss: 68.53858| val_0_mse: 103.07592010498047|  0:00:24s\n","epoch 38 | loss: 66.13724| val_0_mse: 64.98090362548828|  0:00:25s\n","epoch 39 | loss: 74.93915| val_0_mse: 66.17868041992188|  0:00:26s\n","epoch 40 | loss: 77.61662| val_0_mse: 166.7963409423828|  0:00:26s\n","epoch 41 | loss: 75.96101| val_0_mse: 43.026790618896484|  0:00:27s\n","epoch 42 | loss: 77.86177| val_0_mse: 86.01078796386719|  0:00:28s\n","epoch 43 | loss: 67.93255| val_0_mse: 40.69649887084961|  0:00:28s\n","epoch 44 | loss: 60.10151| val_0_mse: 40.85451889038086|  0:00:29s\n","epoch 45 | loss: 56.2845 | val_0_mse: 57.57585906982422|  0:00:30s\n","epoch 46 | loss: 61.0471 | val_0_mse: 48.74967956542969|  0:00:30s\n","epoch 47 | loss: 63.9516 | val_0_mse: 26.9560604095459|  0:00:31s\n","epoch 48 | loss: 76.03398| val_0_mse: 45.69697952270508|  0:00:32s\n","epoch 49 | loss: 60.6352 | val_0_mse: 54.16107940673828|  0:00:32s\n","epoch 50 | loss: 60.5646 | val_0_mse: 51.210899353027344|  0:00:33s\n","epoch 51 | loss: 61.94459| val_0_mse: 36.58000183105469|  0:00:33s\n","epoch 52 | loss: 64.68908| val_0_mse: 43.02838134765625|  0:00:34s\n","epoch 53 | loss: 58.58235| val_0_mse: 49.37599182128906|  0:00:35s\n","epoch 54 | loss: 48.84379| val_0_mse: 45.66749954223633|  0:00:35s\n","epoch 55 | loss: 60.35138| val_0_mse: 36.67620086669922|  0:00:36s\n","epoch 56 | loss: 45.51007| val_0_mse: 25.653430938720703|  0:00:37s\n","epoch 57 | loss: 57.53677| val_0_mse: 32.420318603515625|  0:00:37s\n","epoch 58 | loss: 49.24069| val_0_mse: 28.115400314331055|  0:00:38s\n","epoch 59 | loss: 47.14954| val_0_mse: 32.71255111694336|  0:00:39s\n","epoch 60 | loss: 47.10143| val_0_mse: 23.377599716186523|  0:00:39s\n","epoch 61 | loss: 44.57842| val_0_mse: 23.328449249267578|  0:00:40s\n","epoch 62 | loss: 44.93094| val_0_mse: 26.678020477294922|  0:00:41s\n","epoch 63 | loss: 39.73521| val_0_mse: 32.595340728759766|  0:00:41s\n","epoch 64 | loss: 53.65982| val_0_mse: 52.01390075683594|  0:00:42s\n","epoch 65 | loss: 46.1556 | val_0_mse: 22.242279052734375|  0:00:42s\n","epoch 66 | loss: 44.91318| val_0_mse: 33.694618225097656|  0:00:43s\n","epoch 67 | loss: 58.32978| val_0_mse: 24.45846939086914|  0:00:44s\n","epoch 68 | loss: 53.38751| val_0_mse: 29.882579803466797|  0:00:44s\n","epoch 69 | loss: 55.52313| val_0_mse: 27.468870162963867|  0:00:45s\n","epoch 70 | loss: 51.16186| val_0_mse: 28.383710861206055|  0:00:46s\n","epoch 71 | loss: 53.80206| val_0_mse: 33.756961822509766|  0:00:46s\n","epoch 72 | loss: 50.69228| val_0_mse: 28.3612003326416|  0:00:47s\n","epoch 73 | loss: 58.78379| val_0_mse: 54.75362014770508|  0:00:48s\n","epoch 74 | loss: 59.79589| val_0_mse: 46.872520446777344|  0:00:48s\n","epoch 75 | loss: 63.7619 | val_0_mse: 33.33768081665039|  0:00:49s\n","\n","Early stopping occurred at epoch 75 with best_epoch = 65 and best_val_0_mse = 22.242279052734375\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 13:40:39,454] Trial 67 finished with value: 22.242284774780273 and parameters: {'n_d': 47, 'n_steps': 4, 'gamma': 1.8057947138901642, 'n_independent': 1, 'n_shared': 4, 'momentum': 0.07208874089625224}. Best is trial 39 with value: 14.34697437286377.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 2086.47781| val_0_mse: 4817.80810546875|  0:00:00s\n","epoch 1  | loss: 900.60718| val_0_mse: 3165.310302734375|  0:00:01s\n","epoch 2  | loss: 351.48162| val_0_mse: 2926.607666015625|  0:00:01s\n","epoch 3  | loss: 200.81455| val_0_mse: 2947.189453125|  0:00:02s\n","epoch 4  | loss: 174.61998| val_0_mse: 2657.632080078125|  0:00:03s\n","epoch 5  | loss: 156.8466| val_0_mse: 2693.550048828125|  0:00:03s\n","epoch 6  | loss: 144.48136| val_0_mse: 2717.0966796875|  0:00:04s\n","epoch 7  | loss: 111.1636| val_0_mse: 2726.861083984375|  0:00:04s\n","epoch 8  | loss: 97.48259| val_0_mse: 2711.94921875|  0:00:05s\n","epoch 9  | loss: 97.84013| val_0_mse: 2723.2021484375|  0:00:05s\n","epoch 10 | loss: 97.74632| val_0_mse: 2611.2119140625|  0:00:06s\n","epoch 11 | loss: 87.10192| val_0_mse: 2640.354248046875|  0:00:07s\n","epoch 12 | loss: 95.53834| val_0_mse: 2609.191650390625|  0:00:07s\n","epoch 13 | loss: 92.41529| val_0_mse: 2530.130859375|  0:00:08s\n","epoch 14 | loss: 65.47709| val_0_mse: 2604.93359375|  0:00:09s\n","epoch 15 | loss: 68.70027| val_0_mse: 2614.5595703125|  0:00:09s\n","epoch 16 | loss: 69.12073| val_0_mse: 2622.0546875|  0:00:10s\n","epoch 17 | loss: 78.51902| val_0_mse: 2648.013427734375|  0:00:10s\n","epoch 18 | loss: 96.95276| val_0_mse: 2419.033447265625|  0:00:11s\n","epoch 19 | loss: 61.03393| val_0_mse: 1975.4547119140625|  0:00:12s\n","epoch 20 | loss: 54.54756| val_0_mse: 1712.9864501953125|  0:00:12s\n","epoch 21 | loss: 57.71311| val_0_mse: 1658.9674072265625|  0:00:13s\n","epoch 22 | loss: 51.60216| val_0_mse: 1245.9144287109375|  0:00:13s\n","epoch 23 | loss: 67.08538| val_0_mse: 1046.4078369140625|  0:00:14s\n","epoch 24 | loss: 70.58566| val_0_mse: 889.0430908203125|  0:00:15s\n","epoch 25 | loss: 57.56033| val_0_mse: 701.5098266601562|  0:00:15s\n","epoch 26 | loss: 51.92413| val_0_mse: 649.872802734375|  0:00:16s\n","epoch 27 | loss: 56.25196| val_0_mse: 547.6251831054688|  0:00:16s\n","epoch 28 | loss: 48.12368| val_0_mse: 406.5873718261719|  0:00:17s\n","epoch 29 | loss: 59.23044| val_0_mse: 371.97528076171875|  0:00:18s\n","epoch 30 | loss: 44.08545| val_0_mse: 306.9669494628906|  0:00:18s\n","epoch 31 | loss: 49.79185| val_0_mse: 296.3985290527344|  0:00:19s\n","epoch 32 | loss: 61.80324| val_0_mse: 189.4851531982422|  0:00:19s\n","epoch 33 | loss: 55.58729| val_0_mse: 244.67855834960938|  0:00:20s\n","epoch 34 | loss: 60.65285| val_0_mse: 195.33929443359375|  0:00:21s\n","epoch 35 | loss: 61.93254| val_0_mse: 132.29522705078125|  0:00:21s\n","epoch 36 | loss: 51.6201 | val_0_mse: 148.83216857910156|  0:00:22s\n","epoch 37 | loss: 52.04583| val_0_mse: 82.81510162353516|  0:00:22s\n","epoch 38 | loss: 49.19779| val_0_mse: 112.96930694580078|  0:00:23s\n","epoch 39 | loss: 41.9346 | val_0_mse: 94.63562774658203|  0:00:24s\n","epoch 40 | loss: 48.02284| val_0_mse: 60.58330154418945|  0:00:24s\n","epoch 41 | loss: 58.1262 | val_0_mse: 74.0199203491211|  0:00:25s\n","epoch 42 | loss: 59.00733| val_0_mse: 48.610721588134766|  0:00:25s\n","epoch 43 | loss: 51.68432| val_0_mse: 57.419410705566406|  0:00:26s\n","epoch 44 | loss: 42.18267| val_0_mse: 51.24169158935547|  0:00:27s\n","epoch 45 | loss: 47.59863| val_0_mse: 56.36650085449219|  0:00:27s\n","epoch 46 | loss: 52.85454| val_0_mse: 48.95463943481445|  0:00:28s\n","epoch 47 | loss: 42.48933| val_0_mse: 43.0540885925293|  0:00:28s\n","epoch 48 | loss: 52.01143| val_0_mse: 47.54161834716797|  0:00:29s\n","epoch 49 | loss: 45.61568| val_0_mse: 39.98395919799805|  0:00:30s\n","epoch 50 | loss: 43.10278| val_0_mse: 25.144920349121094|  0:00:30s\n","epoch 51 | loss: 44.35494| val_0_mse: 45.00897979736328|  0:00:31s\n","epoch 52 | loss: 45.94182| val_0_mse: 44.939640045166016|  0:00:31s\n","epoch 53 | loss: 44.38073| val_0_mse: 39.25284957885742|  0:00:32s\n","epoch 54 | loss: 46.50782| val_0_mse: 32.601600646972656|  0:00:33s\n","epoch 55 | loss: 37.2198 | val_0_mse: 35.82865905761719|  0:00:33s\n","epoch 56 | loss: 41.35074| val_0_mse: 25.158720016479492|  0:00:34s\n","epoch 57 | loss: 37.55268| val_0_mse: 24.033599853515625|  0:00:34s\n","epoch 58 | loss: 42.11206| val_0_mse: 35.736328125|  0:00:35s\n","epoch 59 | loss: 48.14011| val_0_mse: 39.532840728759766|  0:00:35s\n","epoch 60 | loss: 31.9579 | val_0_mse: 34.77220153808594|  0:00:36s\n","epoch 61 | loss: 41.02185| val_0_mse: 28.673599243164062|  0:00:37s\n","epoch 62 | loss: 37.7887 | val_0_mse: 33.70608139038086|  0:00:37s\n","epoch 63 | loss: 40.85392| val_0_mse: 35.639610290527344|  0:00:38s\n","epoch 64 | loss: 38.44438| val_0_mse: 31.367599487304688|  0:00:39s\n","epoch 65 | loss: 48.97201| val_0_mse: 29.489500045776367|  0:00:39s\n","epoch 66 | loss: 52.97048| val_0_mse: 30.78782081604004|  0:00:40s\n","epoch 67 | loss: 41.00823| val_0_mse: 36.95492172241211|  0:00:40s\n","\n","Early stopping occurred at epoch 67 with best_epoch = 57 and best_val_0_mse = 24.033599853515625\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 13:41:20,696] Trial 68 finished with value: 24.033594131469727 and parameters: {'n_d': 42, 'n_steps': 3, 'gamma': 1.5048101228442998, 'n_independent': 1, 'n_shared': 5, 'momentum': 0.17042246137454392}. Best is trial 39 with value: 14.34697437286377.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 2125.16211| val_0_mse: 4986.7734375|  0:00:00s\n","epoch 1  | loss: 1466.53331| val_0_mse: 2076.34912109375|  0:00:01s\n","epoch 2  | loss: 1072.86386| val_0_mse: 2984.967041015625|  0:00:02s\n","epoch 3  | loss: 623.79513| val_0_mse: 5245.115234375|  0:00:03s\n","epoch 4  | loss: 457.64256| val_0_mse: 7236.25 |  0:00:03s\n","epoch 5  | loss: 428.96262| val_0_mse: 6299.09716796875|  0:00:04s\n","epoch 6  | loss: 356.28138| val_0_mse: 6199.03125|  0:00:05s\n","epoch 7  | loss: 304.1632| val_0_mse: 5896.2392578125|  0:00:05s\n","epoch 8  | loss: 292.68155| val_0_mse: 6136.1015625|  0:00:06s\n","epoch 9  | loss: 249.0639| val_0_mse: 5045.58349609375|  0:00:07s\n","epoch 10 | loss: 226.21596| val_0_mse: 3870.775634765625|  0:00:08s\n","epoch 11 | loss: 259.87348| val_0_mse: 3050.186279296875|  0:00:08s\n","\n","Early stopping occurred at epoch 11 with best_epoch = 1 and best_val_0_mse = 2076.34912109375\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 13:41:30,121] Trial 69 finished with value: 2076.34912109375 and parameters: {'n_d': 39, 'n_steps': 5, 'gamma': 1.3713555265419246, 'n_independent': 3, 'n_shared': 2, 'momentum': 0.2365086332866365}. Best is trial 39 with value: 14.34697437286377.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 2038.17567| val_0_mse: 4624.658203125|  0:00:00s\n","epoch 1  | loss: 875.01224| val_0_mse: 3585.854736328125|  0:00:01s\n","epoch 2  | loss: 398.04326| val_0_mse: 1951.2239990234375|  0:00:01s\n","epoch 3  | loss: 247.07806| val_0_mse: 3619.5986328125|  0:00:02s\n","epoch 4  | loss: 174.83408| val_0_mse: 4617.20263671875|  0:00:02s\n","epoch 5  | loss: 132.10867| val_0_mse: 3553.882568359375|  0:00:03s\n","epoch 6  | loss: 116.86264| val_0_mse: 3055.47412109375|  0:00:03s\n","epoch 7  | loss: 102.285 | val_0_mse: 2781.258544921875|  0:00:04s\n","epoch 8  | loss: 110.78568| val_0_mse: 2751.84228515625|  0:00:05s\n","epoch 9  | loss: 100.02548| val_0_mse: 2781.509765625|  0:00:05s\n","epoch 10 | loss: 96.25658| val_0_mse: 2463.974365234375|  0:00:06s\n","epoch 11 | loss: 92.8047 | val_0_mse: 2424.629150390625|  0:00:06s\n","epoch 12 | loss: 99.01326| val_0_mse: 2367.924072265625|  0:00:07s\n","\n","Early stopping occurred at epoch 12 with best_epoch = 2 and best_val_0_mse = 1951.2239990234375\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 13:41:37,649] Trial 70 finished with value: 1951.2239990234375 and parameters: {'n_d': 53, 'n_steps': 4, 'gamma': 1.2281166435157815, 'n_independent': 1, 'n_shared': 3, 'momentum': 0.36288451355199375}. Best is trial 39 with value: 14.34697437286377.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 2125.33921| val_0_mse: 3973.47265625|  0:00:00s\n","epoch 1  | loss: 904.04306| val_0_mse: 2260.65576171875|  0:00:01s\n","epoch 2  | loss: 426.37743| val_0_mse: 2282.216552734375|  0:00:01s\n","epoch 3  | loss: 306.89457| val_0_mse: 2450.69921875|  0:00:02s\n","epoch 4  | loss: 214.09222| val_0_mse: 2568.609619140625|  0:00:02s\n","epoch 5  | loss: 208.46485| val_0_mse: 2621.5849609375|  0:00:03s\n","epoch 6  | loss: 182.84613| val_0_mse: 2541.683349609375|  0:00:04s\n","epoch 7  | loss: 154.81901| val_0_mse: 2484.736572265625|  0:00:04s\n","epoch 8  | loss: 128.66642| val_0_mse: 2626.514892578125|  0:00:05s\n","epoch 9  | loss: 113.042 | val_0_mse: 2380.44189453125|  0:00:06s\n","epoch 10 | loss: 104.54901| val_0_mse: 2692.369384765625|  0:00:06s\n","epoch 11 | loss: 109.82807| val_0_mse: 2490.17529296875|  0:00:07s\n","\n","Early stopping occurred at epoch 11 with best_epoch = 1 and best_val_0_mse = 2260.65576171875\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 13:41:45,282] Trial 71 finished with value: 2260.65576171875 and parameters: {'n_d': 43, 'n_steps': 3, 'gamma': 1.4269514127073186, 'n_independent': 2, 'n_shared': 4, 'momentum': 0.24155866521615327}. Best is trial 39 with value: 14.34697437286377.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 2335.05724| val_0_mse: 2756.888427734375|  0:00:00s\n","epoch 1  | loss: 1200.72877| val_0_mse: 2873.244384765625|  0:00:01s\n","epoch 2  | loss: 401.61901| val_0_mse: 2587.325927734375|  0:00:01s\n","epoch 3  | loss: 300.87955| val_0_mse: 2713.827880859375|  0:00:02s\n","epoch 4  | loss: 218.95866| val_0_mse: 2752.857177734375|  0:00:03s\n","epoch 5  | loss: 167.31606| val_0_mse: 2749.5908203125|  0:00:03s\n","epoch 6  | loss: 161.44117| val_0_mse: 2728.528076171875|  0:00:04s\n","epoch 7  | loss: 145.78853| val_0_mse: 2554.42578125|  0:00:04s\n","epoch 8  | loss: 140.84819| val_0_mse: 2780.376953125|  0:00:05s\n","epoch 9  | loss: 135.93009| val_0_mse: 2644.6708984375|  0:00:06s\n","epoch 10 | loss: 130.80692| val_0_mse: 2642.474609375|  0:00:06s\n","epoch 11 | loss: 133.42833| val_0_mse: 2558.2802734375|  0:00:07s\n","epoch 12 | loss: 115.62522| val_0_mse: 2711.572265625|  0:00:07s\n","epoch 13 | loss: 110.67061| val_0_mse: 2618.16650390625|  0:00:08s\n","epoch 14 | loss: 99.64519| val_0_mse: 2615.59423828125|  0:00:08s\n","epoch 15 | loss: 107.75323| val_0_mse: 2708.850341796875|  0:00:09s\n","epoch 16 | loss: 100.6761| val_0_mse: 2579.728759765625|  0:00:10s\n","epoch 17 | loss: 82.34379| val_0_mse: 2573.666259765625|  0:00:10s\n","\n","Early stopping occurred at epoch 17 with best_epoch = 7 and best_val_0_mse = 2554.42578125\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 13:41:56,316] Trial 72 finished with value: 2554.42578125 and parameters: {'n_d': 48, 'n_steps': 3, 'gamma': 1.4504713490398033, 'n_independent': 2, 'n_shared': 4, 'momentum': 0.195442612508814}. Best is trial 39 with value: 14.34697437286377.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 1993.70904| val_0_mse: 2401.92333984375|  0:00:00s\n","epoch 1  | loss: 662.49155| val_0_mse: 2387.169677734375|  0:00:01s\n","epoch 2  | loss: 379.34816| val_0_mse: 3706.980712890625|  0:00:02s\n","epoch 3  | loss: 253.99392| val_0_mse: 2524.513916015625|  0:00:02s\n","epoch 4  | loss: 180.02377| val_0_mse: 2436.77001953125|  0:00:03s\n","epoch 5  | loss: 158.56893| val_0_mse: 2670.54833984375|  0:00:04s\n","epoch 6  | loss: 149.60079| val_0_mse: 2487.66455078125|  0:00:04s\n","epoch 7  | loss: 141.38268| val_0_mse: 2644.71533203125|  0:00:05s\n","epoch 8  | loss: 130.71671| val_0_mse: 2501.9384765625|  0:00:05s\n","epoch 9  | loss: 124.43071| val_0_mse: 2608.14306640625|  0:00:06s\n","epoch 10 | loss: 116.02812| val_0_mse: 2539.8740234375|  0:00:07s\n","epoch 11 | loss: 88.82459| val_0_mse: 2585.5908203125|  0:00:07s\n","\n","Early stopping occurred at epoch 11 with best_epoch = 1 and best_val_0_mse = 2387.169677734375\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 13:42:04,646] Trial 73 finished with value: 2387.169677734375 and parameters: {'n_d': 45, 'n_steps': 3, 'gamma': 1.3394402958655887, 'n_independent': 3, 'n_shared': 4, 'momentum': 0.2545106216959806}. Best is trial 39 with value: 14.34697437286377.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 2055.80728| val_0_mse: 6769.03466796875|  0:00:00s\n","epoch 1  | loss: 920.14444| val_0_mse: 6997.583984375|  0:00:01s\n","epoch 2  | loss: 391.71734| val_0_mse: 6183.32470703125|  0:00:02s\n","epoch 3  | loss: 322.23068| val_0_mse: 3381.783935546875|  0:00:02s\n","epoch 4  | loss: 229.1662| val_0_mse: 2850.74462890625|  0:00:03s\n","epoch 5  | loss: 225.0485| val_0_mse: 2299.296142578125|  0:00:04s\n","epoch 6  | loss: 204.98136| val_0_mse: 2703.218017578125|  0:00:05s\n","epoch 7  | loss: 170.67178| val_0_mse: 2625.381591796875|  0:00:05s\n","epoch 8  | loss: 169.98189| val_0_mse: 2792.1279296875|  0:00:06s\n","epoch 9  | loss: 149.97235| val_0_mse: 2698.411865234375|  0:00:07s\n","epoch 10 | loss: 142.33364| val_0_mse: 2630.56689453125|  0:00:08s\n","epoch 11 | loss: 133.92255| val_0_mse: 2522.84912109375|  0:00:08s\n","epoch 12 | loss: 109.13634| val_0_mse: 2677.818603515625|  0:00:09s\n","epoch 13 | loss: 124.41345| val_0_mse: 2616.932373046875|  0:00:10s\n","epoch 14 | loss: 112.66955| val_0_mse: 2710.214599609375|  0:00:10s\n","epoch 15 | loss: 98.16456| val_0_mse: 2564.66064453125|  0:00:11s\n","\n","Early stopping occurred at epoch 15 with best_epoch = 5 and best_val_0_mse = 2299.296142578125\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 13:42:16,716] Trial 74 finished with value: 2299.296142578125 and parameters: {'n_d': 51, 'n_steps': 4, 'gamma': 1.4082717508906422, 'n_independent': 2, 'n_shared': 4, 'momentum': 0.27373972684595266}. Best is trial 39 with value: 14.34697437286377.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 2346.61418| val_0_mse: 3488.513916015625|  0:00:01s\n","epoch 1  | loss: 1837.38559| val_0_mse: 6943.02001953125|  0:00:02s\n","epoch 2  | loss: 1477.26686| val_0_mse: 13536.509765625|  0:00:03s\n","epoch 3  | loss: 1313.23273| val_0_mse: 20070.810546875|  0:00:04s\n","epoch 4  | loss: 1311.43509| val_0_mse: 22245.521484375|  0:00:06s\n","epoch 5  | loss: 1229.47397| val_0_mse: 12691.0595703125|  0:00:07s\n","epoch 6  | loss: 1245.49335| val_0_mse: 8313.0322265625|  0:00:08s\n","epoch 7  | loss: 1243.023| val_0_mse: 5837.34033203125|  0:00:09s\n","epoch 8  | loss: 1169.72605| val_0_mse: 5219.2529296875|  0:00:11s\n","epoch 9  | loss: 1036.63218| val_0_mse: 4105.63427734375|  0:00:12s\n","epoch 10 | loss: 881.63037| val_0_mse: 4008.6923828125|  0:00:13s\n","\n","Early stopping occurred at epoch 10 with best_epoch = 0 and best_val_0_mse = 3488.513916015625\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 13:42:30,837] Trial 75 finished with value: 3488.513916015625 and parameters: {'n_d': 41, 'n_steps': 8, 'gamma': 1.9229755152355548, 'n_independent': 1, 'n_shared': 5, 'momentum': 0.22106188630923923}. Best is trial 39 with value: 14.34697437286377.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 2023.45732| val_0_mse: 4704.01708984375|  0:00:00s\n","epoch 1  | loss: 800.8149| val_0_mse: 3230.300048828125|  0:00:01s\n","epoch 2  | loss: 415.34834| val_0_mse: 2868.39111328125|  0:00:01s\n","epoch 3  | loss: 278.69239| val_0_mse: 3837.184326171875|  0:00:02s\n","epoch 4  | loss: 228.83208| val_0_mse: 2711.222412109375|  0:00:03s\n","epoch 5  | loss: 178.54849| val_0_mse: 2747.574951171875|  0:00:03s\n","epoch 6  | loss: 175.52554| val_0_mse: 2647.43896484375|  0:00:04s\n","epoch 7  | loss: 153.30293| val_0_mse: 2589.70458984375|  0:00:04s\n","epoch 8  | loss: 118.55919| val_0_mse: 2773.348388671875|  0:00:05s\n","epoch 9  | loss: 115.46307| val_0_mse: 2636.330078125|  0:00:06s\n","epoch 10 | loss: 123.29609| val_0_mse: 2751.094482421875|  0:00:06s\n","epoch 11 | loss: 124.83667| val_0_mse: 2625.25439453125|  0:00:07s\n","epoch 12 | loss: 99.02106| val_0_mse: 2615.6689453125|  0:00:07s\n","epoch 13 | loss: 109.50004| val_0_mse: 2640.034423828125|  0:00:08s\n","epoch 14 | loss: 93.52454| val_0_mse: 2666.251220703125|  0:00:09s\n","epoch 15 | loss: 90.77819| val_0_mse: 2411.696044921875|  0:00:09s\n","epoch 16 | loss: 89.61649| val_0_mse: 2112.26171875|  0:00:10s\n","epoch 17 | loss: 97.19141| val_0_mse: 1958.640625|  0:00:10s\n","epoch 18 | loss: 104.03573| val_0_mse: 1813.8070068359375|  0:00:11s\n","epoch 19 | loss: 95.88881| val_0_mse: 1301.8326416015625|  0:00:12s\n","epoch 20 | loss: 115.03172| val_0_mse: 1041.7286376953125|  0:00:12s\n","epoch 21 | loss: 110.9365| val_0_mse: 1009.4131469726562|  0:00:13s\n","epoch 22 | loss: 89.25739| val_0_mse: 1042.314697265625|  0:00:13s\n","epoch 23 | loss: 100.39452| val_0_mse: 900.8167724609375|  0:00:14s\n","epoch 24 | loss: 106.48758| val_0_mse: 1009.095703125|  0:00:15s\n","epoch 25 | loss: 83.30291| val_0_mse: 557.7727661132812|  0:00:15s\n","epoch 26 | loss: 94.43692| val_0_mse: 576.789794921875|  0:00:16s\n","epoch 27 | loss: 90.08448| val_0_mse: 619.83984375|  0:00:16s\n","epoch 28 | loss: 91.88848| val_0_mse: 529.5819702148438|  0:00:17s\n","epoch 29 | loss: 121.64022| val_0_mse: 387.69207763671875|  0:00:18s\n","epoch 30 | loss: 102.34194| val_0_mse: 347.000732421875|  0:00:18s\n","epoch 31 | loss: 83.53617| val_0_mse: 366.73175048828125|  0:00:19s\n","epoch 32 | loss: 81.90078| val_0_mse: 210.33787536621094|  0:00:19s\n","epoch 33 | loss: 78.90358| val_0_mse: 248.3946533203125|  0:00:20s\n","epoch 34 | loss: 86.1663 | val_0_mse: 98.80769348144531|  0:00:21s\n","epoch 35 | loss: 71.37384| val_0_mse: 107.15059661865234|  0:00:21s\n","epoch 36 | loss: 71.77095| val_0_mse: 75.85952758789062|  0:00:22s\n","epoch 37 | loss: 75.31919| val_0_mse: 161.1685028076172|  0:00:22s\n","epoch 38 | loss: 71.34128| val_0_mse: 75.4103012084961|  0:00:23s\n","epoch 39 | loss: 59.25618| val_0_mse: 78.10092163085938|  0:00:24s\n","epoch 40 | loss: 69.71139| val_0_mse: 78.4619369506836|  0:00:24s\n","epoch 41 | loss: 69.56951| val_0_mse: 66.72518157958984|  0:00:25s\n","epoch 42 | loss: 63.08426| val_0_mse: 68.00524139404297|  0:00:25s\n","epoch 43 | loss: 74.61832| val_0_mse: 52.125160217285156|  0:00:26s\n","epoch 44 | loss: 59.16163| val_0_mse: 78.22718048095703|  0:00:27s\n","epoch 45 | loss: 61.57122| val_0_mse: 52.39434051513672|  0:00:27s\n","epoch 46 | loss: 74.37198| val_0_mse: 70.3139419555664|  0:00:28s\n","epoch 47 | loss: 53.42567| val_0_mse: 32.542518615722656|  0:00:28s\n","epoch 48 | loss: 62.1128 | val_0_mse: 44.18368911743164|  0:00:29s\n","epoch 49 | loss: 77.37866| val_0_mse: 44.818199157714844|  0:00:30s\n","epoch 50 | loss: 70.423  | val_0_mse: 43.31306076049805|  0:00:30s\n","epoch 51 | loss: 61.28697| val_0_mse: 40.98427963256836|  0:00:31s\n","epoch 52 | loss: 52.41592| val_0_mse: 43.9344596862793|  0:00:31s\n","epoch 53 | loss: 66.6851 | val_0_mse: 31.85770034790039|  0:00:32s\n","epoch 54 | loss: 67.38371| val_0_mse: 46.30268859863281|  0:00:33s\n","epoch 55 | loss: 64.86771| val_0_mse: 30.928180694580078|  0:00:33s\n","epoch 56 | loss: 69.17476| val_0_mse: 49.44377136230469|  0:00:34s\n","epoch 57 | loss: 61.9073 | val_0_mse: 39.31513977050781|  0:00:34s\n","epoch 58 | loss: 63.81482| val_0_mse: 41.599178314208984|  0:00:35s\n","epoch 59 | loss: 77.66666| val_0_mse: 63.58219909667969|  0:00:36s\n","epoch 60 | loss: 65.27685| val_0_mse: 34.312599182128906|  0:00:36s\n","epoch 61 | loss: 63.20883| val_0_mse: 31.83492088317871|  0:00:37s\n","epoch 62 | loss: 58.05236| val_0_mse: 49.29835891723633|  0:00:37s\n","epoch 63 | loss: 62.3243 | val_0_mse: 32.272518157958984|  0:00:38s\n","epoch 64 | loss: 65.01583| val_0_mse: 64.15406036376953|  0:00:39s\n","epoch 65 | loss: 68.24606| val_0_mse: 48.60182189941406|  0:00:39s\n","\n","Early stopping occurred at epoch 65 with best_epoch = 55 and best_val_0_mse = 30.928180694580078\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 13:43:10,927] Trial 76 finished with value: 30.928176879882812 and parameters: {'n_d': 46, 'n_steps': 3, 'gamma': 1.5776484978170255, 'n_independent': 2, 'n_shared': 4, 'momentum': 0.257786456534045}. Best is trial 39 with value: 14.34697437286377.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 2069.23341| val_0_mse: 33996.89453125|  0:00:00s\n","epoch 1  | loss: 941.49354| val_0_mse: 76254.859375|  0:00:01s\n","epoch 2  | loss: 440.16679| val_0_mse: 4530.50537109375|  0:00:02s\n","epoch 3  | loss: 321.14744| val_0_mse: 9584.3349609375|  0:00:03s\n","epoch 4  | loss: 242.18225| val_0_mse: 6651.39990234375|  0:00:04s\n","epoch 5  | loss: 204.66058| val_0_mse: 2789.924072265625|  0:00:05s\n","epoch 6  | loss: 168.72136| val_0_mse: 3171.63818359375|  0:00:06s\n","epoch 7  | loss: 169.64622| val_0_mse: 2815.72607421875|  0:00:07s\n","epoch 8  | loss: 166.17889| val_0_mse: 3180.347412109375|  0:00:07s\n","epoch 9  | loss: 165.9948| val_0_mse: 2923.55126953125|  0:00:08s\n","epoch 10 | loss: 148.18168| val_0_mse: 2865.97509765625|  0:00:09s\n","epoch 11 | loss: 125.38132| val_0_mse: 3222.640625|  0:00:10s\n","epoch 12 | loss: 136.60383| val_0_mse: 3404.1298828125|  0:00:11s\n","epoch 13 | loss: 124.03253| val_0_mse: 3122.32763671875|  0:00:12s\n","epoch 14 | loss: 120.77517| val_0_mse: 3083.556884765625|  0:00:13s\n","epoch 15 | loss: 120.29926| val_0_mse: 2890.055419921875|  0:00:14s\n","\n","Early stopping occurred at epoch 15 with best_epoch = 5 and best_val_0_mse = 2789.924072265625\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 13:43:25,595] Trial 77 finished with value: 2789.924072265625 and parameters: {'n_d': 54, 'n_steps': 4, 'gamma': 1.2874324534167236, 'n_independent': 3, 'n_shared': 5, 'momentum': 0.14114571606739573}. Best is trial 39 with value: 14.34697437286377.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 2061.85756| val_0_mse: 4871.1416015625|  0:00:00s\n","epoch 1  | loss: 827.95467| val_0_mse: 9188.2802734375|  0:00:01s\n","epoch 2  | loss: 310.75155| val_0_mse: 2748.021240234375|  0:00:01s\n","epoch 3  | loss: 218.61808| val_0_mse: 2736.25 |  0:00:02s\n","epoch 4  | loss: 184.19418| val_0_mse: 2657.605712890625|  0:00:02s\n","epoch 5  | loss: 157.24829| val_0_mse: 2868.1630859375|  0:00:03s\n","epoch 6  | loss: 151.06227| val_0_mse: 2751.815673828125|  0:00:04s\n","epoch 7  | loss: 137.95486| val_0_mse: 2672.054443359375|  0:00:04s\n","epoch 8  | loss: 124.73026| val_0_mse: 2592.19140625|  0:00:05s\n","epoch 9  | loss: 121.95684| val_0_mse: 2476.314697265625|  0:00:05s\n","epoch 10 | loss: 119.8662| val_0_mse: 2639.816650390625|  0:00:06s\n","epoch 11 | loss: 95.15572| val_0_mse: 2574.629150390625|  0:00:07s\n","epoch 12 | loss: 90.8917 | val_0_mse: 2626.208984375|  0:00:07s\n","epoch 13 | loss: 89.95605| val_0_mse: 2473.65625|  0:00:08s\n","epoch 14 | loss: 75.35549| val_0_mse: 2410.11962890625|  0:00:08s\n","epoch 15 | loss: 79.23916| val_0_mse: 2509.126220703125|  0:00:09s\n","epoch 16 | loss: 76.77528| val_0_mse: 2455.7490234375|  0:00:10s\n","epoch 17 | loss: 88.43412| val_0_mse: 2464.417724609375|  0:00:10s\n","epoch 18 | loss: 77.93647| val_0_mse: 2275.45263671875|  0:00:11s\n","epoch 19 | loss: 60.93802| val_0_mse: 2027.7471923828125|  0:00:12s\n","epoch 20 | loss: 68.26699| val_0_mse: 1752.74267578125|  0:00:12s\n","epoch 21 | loss: 62.46953| val_0_mse: 1745.0950927734375|  0:00:13s\n","epoch 22 | loss: 55.35591| val_0_mse: 1259.7998046875|  0:00:13s\n","epoch 23 | loss: 59.67691| val_0_mse: 1151.884521484375|  0:00:14s\n","epoch 24 | loss: 53.29171| val_0_mse: 1072.5858154296875|  0:00:14s\n","epoch 25 | loss: 57.7784 | val_0_mse: 696.0725708007812|  0:00:15s\n","epoch 26 | loss: 69.8776 | val_0_mse: 629.9639282226562|  0:00:16s\n","epoch 27 | loss: 60.55674| val_0_mse: 625.3729248046875|  0:00:16s\n","epoch 28 | loss: 55.6994 | val_0_mse: 419.9868469238281|  0:00:17s\n","epoch 29 | loss: 52.43464| val_0_mse: 397.74346923828125|  0:00:18s\n","epoch 30 | loss: 51.2006 | val_0_mse: 345.2760314941406|  0:00:18s\n","epoch 31 | loss: 45.45477| val_0_mse: 274.7021179199219|  0:00:19s\n","epoch 32 | loss: 53.07765| val_0_mse: 221.39285278320312|  0:00:19s\n","epoch 33 | loss: 54.59731| val_0_mse: 137.0790252685547|  0:00:20s\n","epoch 34 | loss: 55.98238| val_0_mse: 167.65960693359375|  0:00:21s\n","epoch 35 | loss: 50.24408| val_0_mse: 171.6107940673828|  0:00:21s\n","epoch 36 | loss: 50.76275| val_0_mse: 133.5331268310547|  0:00:22s\n","epoch 37 | loss: 55.62929| val_0_mse: 84.22637176513672|  0:00:22s\n","epoch 38 | loss: 51.2581 | val_0_mse: 125.11189270019531|  0:00:23s\n","epoch 39 | loss: 45.00424| val_0_mse: 58.46664047241211|  0:00:24s\n","epoch 40 | loss: 45.72918| val_0_mse: 70.35128784179688|  0:00:24s\n","epoch 41 | loss: 42.22693| val_0_mse: 60.682899475097656|  0:00:25s\n","epoch 42 | loss: 45.58071| val_0_mse: 77.63971710205078|  0:00:25s\n","epoch 43 | loss: 56.06197| val_0_mse: 73.6721420288086|  0:00:26s\n","epoch 44 | loss: 48.93155| val_0_mse: 54.55112075805664|  0:00:26s\n","epoch 45 | loss: 54.42414| val_0_mse: 50.93452072143555|  0:00:27s\n","epoch 46 | loss: 48.97263| val_0_mse: 44.781288146972656|  0:00:28s\n","epoch 47 | loss: 46.52261| val_0_mse: 27.399009704589844|  0:00:28s\n","epoch 48 | loss: 40.37021| val_0_mse: 37.50331115722656|  0:00:29s\n","epoch 49 | loss: 41.70942| val_0_mse: 33.368778228759766|  0:00:30s\n","epoch 50 | loss: 45.76596| val_0_mse: 39.195640563964844|  0:00:30s\n","epoch 51 | loss: 43.44177| val_0_mse: 48.00891876220703|  0:00:31s\n","epoch 52 | loss: 54.58275| val_0_mse: 28.000959396362305|  0:00:31s\n","epoch 53 | loss: 41.56213| val_0_mse: 52.5324592590332|  0:00:32s\n","epoch 54 | loss: 62.8717 | val_0_mse: 31.761899948120117|  0:00:33s\n","epoch 55 | loss: 36.17308| val_0_mse: 29.533449172973633|  0:00:33s\n","epoch 56 | loss: 38.95737| val_0_mse: 23.366609573364258|  0:00:34s\n","epoch 57 | loss: 45.79856| val_0_mse: 28.320430755615234|  0:00:34s\n","epoch 58 | loss: 36.49115| val_0_mse: 39.01573944091797|  0:00:35s\n","epoch 59 | loss: 45.08624| val_0_mse: 26.733640670776367|  0:00:36s\n","epoch 60 | loss: 49.31521| val_0_mse: 56.7529182434082|  0:00:36s\n","epoch 61 | loss: 45.2867 | val_0_mse: 45.720279693603516|  0:00:37s\n","epoch 62 | loss: 42.66247| val_0_mse: 31.096399307250977|  0:00:37s\n","epoch 63 | loss: 37.25397| val_0_mse: 23.95792007446289|  0:00:38s\n","epoch 64 | loss: 53.30454| val_0_mse: 37.820640563964844|  0:00:39s\n","epoch 65 | loss: 42.25275| val_0_mse: 33.22962951660156|  0:00:39s\n","epoch 66 | loss: 33.15526| val_0_mse: 27.72484016418457|  0:00:40s\n","\n","Early stopping occurred at epoch 66 with best_epoch = 56 and best_val_0_mse = 23.366609573364258\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 13:44:06,314] Trial 78 finished with value: 23.366609573364258 and parameters: {'n_d': 33, 'n_steps': 3, 'gamma': 1.3578852234396301, 'n_independent': 4, 'n_shared': 2, 'momentum': 0.09807408181198723}. Best is trial 39 with value: 14.34697437286377.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 2181.29135| val_0_mse: 5608.212890625|  0:00:00s\n","epoch 1  | loss: 1244.58259| val_0_mse: 3170.83740234375|  0:00:01s\n","epoch 2  | loss: 602.7067| val_0_mse: 6260.75732421875|  0:00:01s\n","epoch 3  | loss: 396.6307| val_0_mse: 3593.05419921875|  0:00:02s\n","epoch 4  | loss: 221.54454| val_0_mse: 2846.141845703125|  0:00:02s\n","epoch 5  | loss: 182.69296| val_0_mse: 2631.978759765625|  0:00:03s\n","epoch 6  | loss: 166.48055| val_0_mse: 3015.668212890625|  0:00:03s\n","epoch 7  | loss: 163.79648| val_0_mse: 2881.19287109375|  0:00:04s\n","epoch 8  | loss: 128.78312| val_0_mse: 2648.1689453125|  0:00:05s\n","epoch 9  | loss: 116.06188| val_0_mse: 2726.0693359375|  0:00:05s\n","epoch 10 | loss: 104.61171| val_0_mse: 2660.05078125|  0:00:06s\n","epoch 11 | loss: 95.10433| val_0_mse: 2655.818603515625|  0:00:06s\n","epoch 12 | loss: 93.33572| val_0_mse: 2624.0966796875|  0:00:07s\n","epoch 13 | loss: 88.22719| val_0_mse: 2693.767333984375|  0:00:07s\n","epoch 14 | loss: 85.93352| val_0_mse: 2489.0126953125|  0:00:08s\n","epoch 15 | loss: 107.41423| val_0_mse: 2510.12158203125|  0:00:08s\n","epoch 16 | loss: 84.61539| val_0_mse: 2433.81396484375|  0:00:09s\n","epoch 17 | loss: 81.59791| val_0_mse: 2522.19091796875|  0:00:10s\n","epoch 18 | loss: 87.7933 | val_0_mse: 2457.3642578125|  0:00:10s\n","epoch 19 | loss: 84.3196 | val_0_mse: 2283.5654296875|  0:00:11s\n","epoch 20 | loss: 71.00762| val_0_mse: 1812.4097900390625|  0:00:11s\n","epoch 21 | loss: 72.87167| val_0_mse: 1653.7861328125|  0:00:12s\n","epoch 22 | loss: 71.48262| val_0_mse: 1246.2490234375|  0:00:12s\n","epoch 23 | loss: 66.49311| val_0_mse: 1180.9375|  0:00:13s\n","epoch 24 | loss: 64.82569| val_0_mse: 804.7391967773438|  0:00:13s\n","epoch 25 | loss: 79.77797| val_0_mse: 654.3555908203125|  0:00:14s\n","epoch 26 | loss: 64.84479| val_0_mse: 596.7877197265625|  0:00:15s\n","epoch 27 | loss: 76.05535| val_0_mse: 444.40008544921875|  0:00:15s\n","epoch 28 | loss: 65.7313 | val_0_mse: 454.6815490722656|  0:00:16s\n","epoch 29 | loss: 67.02891| val_0_mse: 286.4893798828125|  0:00:16s\n","epoch 30 | loss: 68.46937| val_0_mse: 349.5415954589844|  0:00:17s\n","epoch 31 | loss: 63.28986| val_0_mse: 206.6467742919922|  0:00:17s\n","epoch 32 | loss: 58.92555| val_0_mse: 256.5368347167969|  0:00:18s\n","epoch 33 | loss: 79.86506| val_0_mse: 100.85257720947266|  0:00:19s\n","epoch 34 | loss: 74.39588| val_0_mse: 147.87232971191406|  0:00:19s\n","epoch 35 | loss: 66.55922| val_0_mse: 89.96930694580078|  0:00:20s\n","epoch 36 | loss: 64.41188| val_0_mse: 104.25440979003906|  0:00:20s\n","epoch 37 | loss: 57.63058| val_0_mse: 127.00833129882812|  0:00:21s\n","epoch 38 | loss: 76.06239| val_0_mse: 77.94994354248047|  0:00:21s\n","epoch 39 | loss: 68.82051| val_0_mse: 72.21102142333984|  0:00:22s\n","epoch 40 | loss: 62.10793| val_0_mse: 87.59964752197266|  0:00:23s\n","epoch 41 | loss: 53.97077| val_0_mse: 58.976318359375|  0:00:23s\n","epoch 42 | loss: 54.00012| val_0_mse: 57.46202850341797|  0:00:24s\n","epoch 43 | loss: 54.43884| val_0_mse: 43.83055877685547|  0:00:24s\n","epoch 44 | loss: 58.4685 | val_0_mse: 55.9475212097168|  0:00:25s\n","epoch 45 | loss: 59.23172| val_0_mse: 63.965599060058594|  0:00:25s\n","epoch 46 | loss: 61.4556 | val_0_mse: 59.807029724121094|  0:00:26s\n","epoch 47 | loss: 76.64593| val_0_mse: 48.52394104003906|  0:00:27s\n","epoch 48 | loss: 54.06743| val_0_mse: 51.49243927001953|  0:00:27s\n","epoch 49 | loss: 53.45702| val_0_mse: 55.53889083862305|  0:00:28s\n","epoch 50 | loss: 74.20556| val_0_mse: 44.449100494384766|  0:00:28s\n","epoch 51 | loss: 62.99429| val_0_mse: 41.86603927612305|  0:00:29s\n","epoch 52 | loss: 54.59758| val_0_mse: 49.57701110839844|  0:00:29s\n","epoch 53 | loss: 72.28396| val_0_mse: 27.821210861206055|  0:00:30s\n","epoch 54 | loss: 65.44576| val_0_mse: 35.352638244628906|  0:00:30s\n","epoch 55 | loss: 63.42018| val_0_mse: 37.89202117919922|  0:00:31s\n","epoch 56 | loss: 55.2027 | val_0_mse: 46.159400939941406|  0:00:31s\n","epoch 57 | loss: 54.82065| val_0_mse: 36.348960876464844|  0:00:32s\n","epoch 58 | loss: 56.00602| val_0_mse: 31.571319580078125|  0:00:33s\n","epoch 59 | loss: 49.03143| val_0_mse: 30.274919509887695|  0:00:33s\n","epoch 60 | loss: 55.11895| val_0_mse: 27.907970428466797|  0:00:34s\n","epoch 61 | loss: 53.16994| val_0_mse: 33.991539001464844|  0:00:34s\n","epoch 62 | loss: 61.43505| val_0_mse: 40.667110443115234|  0:00:35s\n","epoch 63 | loss: 59.09229| val_0_mse: 34.006980895996094|  0:00:35s\n","\n","Early stopping occurred at epoch 63 with best_epoch = 53 and best_val_0_mse = 27.821210861206055\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 13:44:42,526] Trial 79 finished with value: 27.821208953857422 and parameters: {'n_d': 49, 'n_steps': 4, 'gamma': 1.6165555056046899, 'n_independent': 1, 'n_shared': 3, 'momentum': 0.3153586097456957}. Best is trial 39 with value: 14.34697437286377.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 2042.01331| val_0_mse: 7427.43212890625|  0:00:00s\n","epoch 1  | loss: 900.516 | val_0_mse: 15997.33203125|  0:00:01s\n","epoch 2  | loss: 546.32557| val_0_mse: 17807.861328125|  0:00:02s\n","epoch 3  | loss: 314.68139| val_0_mse: 9065.83984375|  0:00:02s\n","epoch 4  | loss: 263.53032| val_0_mse: 3606.574951171875|  0:00:03s\n","epoch 5  | loss: 255.99062| val_0_mse: 3319.85400390625|  0:00:03s\n","epoch 6  | loss: 216.77635| val_0_mse: 3226.791259765625|  0:00:04s\n","epoch 7  | loss: 198.87454| val_0_mse: 3595.593017578125|  0:00:05s\n","epoch 8  | loss: 145.92753| val_0_mse: 3489.305908203125|  0:00:05s\n","epoch 9  | loss: 135.01775| val_0_mse: 3053.6064453125|  0:00:06s\n","epoch 10 | loss: 115.31423| val_0_mse: 3236.4208984375|  0:00:07s\n","epoch 11 | loss: 108.62237| val_0_mse: 2671.35302734375|  0:00:07s\n","epoch 12 | loss: 94.67506| val_0_mse: 2745.06201171875|  0:00:08s\n","epoch 13 | loss: 83.89035| val_0_mse: 2883.998779296875|  0:00:09s\n","epoch 14 | loss: 86.0057 | val_0_mse: 2719.367431640625|  0:00:09s\n","epoch 15 | loss: 80.88034| val_0_mse: 2682.943115234375|  0:00:10s\n","epoch 16 | loss: 84.76638| val_0_mse: 2565.514404296875|  0:00:11s\n","epoch 17 | loss: 75.10518| val_0_mse: 2420.748046875|  0:00:11s\n","epoch 18 | loss: 80.19977| val_0_mse: 2144.489990234375|  0:00:12s\n","epoch 19 | loss: 68.93838| val_0_mse: 1599.8922119140625|  0:00:13s\n","epoch 20 | loss: 75.67652| val_0_mse: 1282.7957763671875|  0:00:13s\n","epoch 21 | loss: 76.1891 | val_0_mse: 1063.883544921875|  0:00:14s\n","epoch 22 | loss: 68.9699 | val_0_mse: 1124.814208984375|  0:00:15s\n","epoch 23 | loss: 56.44474| val_0_mse: 979.3506469726562|  0:00:15s\n","epoch 24 | loss: 71.0127 | val_0_mse: 872.234375|  0:00:16s\n","epoch 25 | loss: 68.40223| val_0_mse: 859.8197021484375|  0:00:17s\n","epoch 26 | loss: 72.07728| val_0_mse: 552.8713989257812|  0:00:17s\n","epoch 27 | loss: 70.72034| val_0_mse: 372.8847351074219|  0:00:18s\n","epoch 28 | loss: 70.06228| val_0_mse: 304.7431945800781|  0:00:18s\n","epoch 29 | loss: 52.9214 | val_0_mse: 270.3851318359375|  0:00:19s\n","epoch 30 | loss: 60.57363| val_0_mse: 261.2725524902344|  0:00:20s\n","epoch 31 | loss: 50.16855| val_0_mse: 191.26617431640625|  0:00:20s\n","epoch 32 | loss: 55.57349| val_0_mse: 243.53915405273438|  0:00:21s\n","epoch 33 | loss: 59.20395| val_0_mse: 84.1606674194336|  0:00:22s\n","epoch 34 | loss: 53.73761| val_0_mse: 159.7769317626953|  0:00:22s\n","epoch 35 | loss: 52.65209| val_0_mse: 115.5942611694336|  0:00:23s\n","epoch 36 | loss: 56.53269| val_0_mse: 122.37979125976562|  0:00:24s\n","epoch 37 | loss: 58.41666| val_0_mse: 119.12667846679688|  0:00:24s\n","epoch 38 | loss: 53.74575| val_0_mse: 95.3844985961914|  0:00:25s\n","epoch 39 | loss: 58.56373| val_0_mse: 71.12079620361328|  0:00:26s\n","epoch 40 | loss: 41.91124| val_0_mse: 49.44960021972656|  0:00:26s\n","epoch 41 | loss: 43.61901| val_0_mse: 48.94112014770508|  0:00:27s\n","epoch 42 | loss: 57.10504| val_0_mse: 42.8297004699707|  0:00:28s\n","epoch 43 | loss: 49.48391| val_0_mse: 55.20402145385742|  0:00:28s\n","epoch 44 | loss: 42.98978| val_0_mse: 38.49433898925781|  0:00:29s\n","epoch 45 | loss: 54.86372| val_0_mse: 39.12982177734375|  0:00:30s\n","epoch 46 | loss: 55.30686| val_0_mse: 83.48162841796875|  0:00:30s\n","epoch 47 | loss: 45.3623 | val_0_mse: 33.82326126098633|  0:00:31s\n","epoch 48 | loss: 52.13195| val_0_mse: 55.137420654296875|  0:00:32s\n","epoch 49 | loss: 39.00843| val_0_mse: 27.41465950012207|  0:00:32s\n","epoch 50 | loss: 48.2286 | val_0_mse: 33.10451889038086|  0:00:33s\n","epoch 51 | loss: 40.68043| val_0_mse: 26.370790481567383|  0:00:34s\n","epoch 52 | loss: 44.64219| val_0_mse: 33.70745849609375|  0:00:34s\n","epoch 53 | loss: 48.10641| val_0_mse: 38.690250396728516|  0:00:35s\n","epoch 54 | loss: 48.44813| val_0_mse: 32.419410705566406|  0:00:36s\n","epoch 55 | loss: 43.04414| val_0_mse: 47.84954071044922|  0:00:36s\n","epoch 56 | loss: 42.50642| val_0_mse: 29.631000518798828|  0:00:37s\n","epoch 57 | loss: 39.07193| val_0_mse: 23.899070739746094|  0:00:38s\n","epoch 58 | loss: 39.46128| val_0_mse: 28.065059661865234|  0:00:38s\n","epoch 59 | loss: 39.31734| val_0_mse: 48.39421844482422|  0:00:39s\n","epoch 60 | loss: 42.18939| val_0_mse: 32.99794006347656|  0:00:40s\n","epoch 61 | loss: 39.35611| val_0_mse: 27.261140823364258|  0:00:40s\n","epoch 62 | loss: 38.62209| val_0_mse: 21.832059860229492|  0:00:41s\n","epoch 63 | loss: 37.36726| val_0_mse: 33.58618927001953|  0:00:42s\n","epoch 64 | loss: 53.37325| val_0_mse: 30.720979690551758|  0:00:42s\n","epoch 65 | loss: 50.44683| val_0_mse: 29.687719345092773|  0:00:43s\n","epoch 66 | loss: 39.69155| val_0_mse: 34.2841911315918|  0:00:43s\n","epoch 67 | loss: 38.18847| val_0_mse: 38.2099494934082|  0:00:44s\n","epoch 68 | loss: 38.82553| val_0_mse: 29.79694938659668|  0:00:45s\n","epoch 69 | loss: 36.61379| val_0_mse: 27.628990173339844|  0:00:45s\n","epoch 70 | loss: 36.56486| val_0_mse: 22.54659080505371|  0:00:46s\n","epoch 71 | loss: 39.9211 | val_0_mse: 31.596790313720703|  0:00:47s\n","epoch 72 | loss: 42.76142| val_0_mse: 25.130779266357422|  0:00:47s\n","\n","Early stopping occurred at epoch 72 with best_epoch = 62 and best_val_0_mse = 21.832059860229492\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 13:45:30,891] Trial 80 finished with value: 21.832054138183594 and parameters: {'n_d': 37, 'n_steps': 5, 'gamma': 1.2495340609600685, 'n_independent': 3, 'n_shared': 1, 'momentum': 0.2905639380935151}. Best is trial 39 with value: 14.34697437286377.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 2231.46136| val_0_mse: 3526.993896484375|  0:00:00s\n","epoch 1  | loss: 1237.27854| val_0_mse: 9206.9150390625|  0:00:01s\n","epoch 2  | loss: 495.2986| val_0_mse: 11130.806640625|  0:00:02s\n","epoch 3  | loss: 396.07989| val_0_mse: 6738.54248046875|  0:00:03s\n","epoch 4  | loss: 358.0559| val_0_mse: 3168.081298828125|  0:00:04s\n","epoch 5  | loss: 294.57177| val_0_mse: 3640.101318359375|  0:00:05s\n","epoch 6  | loss: 245.83908| val_0_mse: 2751.501220703125|  0:00:06s\n","epoch 7  | loss: 258.83055| val_0_mse: 2404.2314453125|  0:00:07s\n","epoch 8  | loss: 253.94019| val_0_mse: 2489.1298828125|  0:00:08s\n","epoch 9  | loss: 221.93828| val_0_mse: 2807.005859375|  0:00:09s\n","epoch 10 | loss: 214.5262| val_0_mse: 2676.09423828125|  0:00:10s\n","epoch 11 | loss: 269.75238| val_0_mse: 2373.35400390625|  0:00:11s\n","epoch 12 | loss: 237.98406| val_0_mse: 2371.91162109375|  0:00:12s\n","epoch 13 | loss: 223.67028| val_0_mse: 2217.921142578125|  0:00:13s\n","epoch 14 | loss: 195.40684| val_0_mse: 2492.5869140625|  0:00:14s\n","epoch 15 | loss: 181.47907| val_0_mse: 2338.135498046875|  0:00:15s\n","epoch 16 | loss: 168.77543| val_0_mse: 2498.317626953125|  0:00:16s\n","epoch 17 | loss: 173.8253| val_0_mse: 2335.108154296875|  0:00:17s\n","epoch 18 | loss: 174.63264| val_0_mse: 2552.465576171875|  0:00:18s\n","epoch 19 | loss: 154.32592| val_0_mse: 2408.92529296875|  0:00:19s\n","epoch 20 | loss: 158.75908| val_0_mse: 2110.863037109375|  0:00:20s\n","epoch 21 | loss: 131.64277| val_0_mse: 1904.9300537109375|  0:00:21s\n","epoch 22 | loss: 117.01578| val_0_mse: 1635.1435546875|  0:00:22s\n","epoch 23 | loss: 133.31392| val_0_mse: 1353.8265380859375|  0:00:23s\n","epoch 24 | loss: 128.2462| val_0_mse: 925.97216796875|  0:00:24s\n","epoch 25 | loss: 116.47562| val_0_mse: 796.2195434570312|  0:00:25s\n","epoch 26 | loss: 120.75582| val_0_mse: 720.205810546875|  0:00:26s\n","epoch 27 | loss: 155.3066| val_0_mse: 1004.9290161132812|  0:00:27s\n","epoch 28 | loss: 122.54181| val_0_mse: 848.8923950195312|  0:00:28s\n","epoch 29 | loss: 113.3407| val_0_mse: 442.1077880859375|  0:00:29s\n","epoch 30 | loss: 115.24162| val_0_mse: 487.760009765625|  0:00:30s\n","epoch 31 | loss: 112.91852| val_0_mse: 409.1766662597656|  0:00:31s\n","epoch 32 | loss: 91.96945| val_0_mse: 426.35015869140625|  0:00:32s\n","epoch 33 | loss: 92.233  | val_0_mse: 347.945068359375|  0:00:33s\n","epoch 34 | loss: 104.82115| val_0_mse: 195.8967742919922|  0:00:34s\n","epoch 35 | loss: 103.37593| val_0_mse: 325.4323425292969|  0:00:35s\n","epoch 36 | loss: 106.10754| val_0_mse: 169.1025390625|  0:00:36s\n","epoch 37 | loss: 116.68517| val_0_mse: 176.6544952392578|  0:00:37s\n","epoch 38 | loss: 102.98439| val_0_mse: 93.93905639648438|  0:00:38s\n","epoch 39 | loss: 92.14048| val_0_mse: 125.71991729736328|  0:00:39s\n","epoch 40 | loss: 98.7588 | val_0_mse: 104.3526382446289|  0:00:39s\n","epoch 41 | loss: 98.96549| val_0_mse: 102.39317321777344|  0:00:40s\n","epoch 42 | loss: 91.28037| val_0_mse: 130.11328125|  0:00:41s\n","epoch 43 | loss: 105.69628| val_0_mse: 69.5925521850586|  0:00:42s\n","epoch 44 | loss: 109.15182| val_0_mse: 178.05235290527344|  0:00:43s\n","epoch 45 | loss: 150.72027| val_0_mse: 146.74884033203125|  0:00:44s\n","epoch 46 | loss: 90.52007| val_0_mse: 110.08585357666016|  0:00:45s\n","epoch 47 | loss: 95.48262| val_0_mse: 72.56146240234375|  0:00:46s\n","epoch 48 | loss: 71.23222| val_0_mse: 67.4096908569336|  0:00:47s\n","epoch 49 | loss: 64.24827| val_0_mse: 70.3975830078125|  0:00:48s\n","epoch 50 | loss: 94.44717| val_0_mse: 129.9991912841797|  0:00:49s\n","epoch 51 | loss: 109.76774| val_0_mse: 110.0899429321289|  0:00:50s\n","epoch 52 | loss: 92.41808| val_0_mse: 57.313438415527344|  0:00:51s\n","epoch 53 | loss: 101.48099| val_0_mse: 58.61777877807617|  0:00:52s\n","epoch 54 | loss: 96.58035| val_0_mse: 49.556129455566406|  0:00:53s\n","epoch 55 | loss: 86.0031 | val_0_mse: 98.9605712890625|  0:00:54s\n","epoch 56 | loss: 142.41519| val_0_mse: 115.97476959228516|  0:00:55s\n","epoch 57 | loss: 95.59123| val_0_mse: 51.25823974609375|  0:00:56s\n","epoch 58 | loss: 100.42831| val_0_mse: 53.59965133666992|  0:00:57s\n","epoch 59 | loss: 106.90536| val_0_mse: 68.7527084350586|  0:00:58s\n","epoch 60 | loss: 84.99308| val_0_mse: 83.54134368896484|  0:00:59s\n","epoch 61 | loss: 97.47259| val_0_mse: 62.04558181762695|  0:01:00s\n","epoch 62 | loss: 83.41765| val_0_mse: 47.013179779052734|  0:01:01s\n","epoch 63 | loss: 78.5173 | val_0_mse: 41.9222297668457|  0:01:02s\n","epoch 64 | loss: 81.58769| val_0_mse: 58.33845138549805|  0:01:03s\n","epoch 65 | loss: 70.91657| val_0_mse: 46.03239822387695|  0:01:04s\n","epoch 66 | loss: 83.50945| val_0_mse: 55.81101989746094|  0:01:04s\n","epoch 67 | loss: 76.64234| val_0_mse: 45.74721908569336|  0:01:05s\n","epoch 68 | loss: 94.08694| val_0_mse: 52.181739807128906|  0:01:06s\n","epoch 69 | loss: 76.33446| val_0_mse: 52.60150146484375|  0:01:07s\n","epoch 70 | loss: 76.52386| val_0_mse: 56.091880798339844|  0:01:08s\n","epoch 71 | loss: 80.0335 | val_0_mse: 46.2147216796875|  0:01:09s\n","epoch 72 | loss: 75.37232| val_0_mse: 39.99309158325195|  0:01:10s\n","epoch 73 | loss: 78.08768| val_0_mse: 84.69686889648438|  0:01:11s\n","epoch 74 | loss: 72.36286| val_0_mse: 47.757720947265625|  0:01:12s\n","epoch 75 | loss: 67.38074| val_0_mse: 41.570411682128906|  0:01:13s\n","epoch 76 | loss: 68.7064 | val_0_mse: 44.50996017456055|  0:01:14s\n","epoch 77 | loss: 69.74253| val_0_mse: 39.753719329833984|  0:01:15s\n","epoch 78 | loss: 69.69633| val_0_mse: 35.219520568847656|  0:01:16s\n","epoch 79 | loss: 65.91855| val_0_mse: 35.737030029296875|  0:01:17s\n","epoch 80 | loss: 84.00565| val_0_mse: 56.94858169555664|  0:01:18s\n","epoch 81 | loss: 60.54285| val_0_mse: 80.9114990234375|  0:01:19s\n","epoch 82 | loss: 80.12673| val_0_mse: 51.83380126953125|  0:01:20s\n","epoch 83 | loss: 66.42342| val_0_mse: 54.967681884765625|  0:01:21s\n","epoch 84 | loss: 65.94048| val_0_mse: 64.61460876464844|  0:01:22s\n","epoch 85 | loss: 72.93715| val_0_mse: 43.7835807800293|  0:01:23s\n","epoch 86 | loss: 81.43702| val_0_mse: 59.91082000732422|  0:01:24s\n","epoch 87 | loss: 72.01413| val_0_mse: 65.35848999023438|  0:01:25s\n","epoch 88 | loss: 66.1344 | val_0_mse: 49.37234115600586|  0:01:26s\n","\n","Early stopping occurred at epoch 88 with best_epoch = 78 and best_val_0_mse = 35.219520568847656\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 13:46:57,744] Trial 81 finished with value: 35.21951675415039 and parameters: {'n_d': 44, 'n_steps': 4, 'gamma': 1.419175756057199, 'n_independent': 5, 'n_shared': 4, 'momentum': 0.3033779242278331}. Best is trial 39 with value: 14.34697437286377.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 2244.63337| val_0_mse: 3159.658447265625|  0:00:00s\n","epoch 1  | loss: 940.29853| val_0_mse: 2974.58154296875|  0:00:01s\n","epoch 2  | loss: 375.90593| val_0_mse: 2674.49169921875|  0:00:02s\n","epoch 3  | loss: 245.95102| val_0_mse: 2669.835693359375|  0:00:02s\n","epoch 4  | loss: 207.89614| val_0_mse: 2894.076904296875|  0:00:03s\n","epoch 5  | loss: 162.64996| val_0_mse: 2837.64404296875|  0:00:04s\n","epoch 6  | loss: 142.29493| val_0_mse: 2786.856689453125|  0:00:05s\n","epoch 7  | loss: 146.4619| val_0_mse: 2642.249755859375|  0:00:05s\n","epoch 8  | loss: 105.96364| val_0_mse: 2539.53955078125|  0:00:06s\n","epoch 9  | loss: 109.55705| val_0_mse: 2544.773681640625|  0:00:07s\n","epoch 10 | loss: 116.62877| val_0_mse: 2389.548583984375|  0:00:07s\n","epoch 11 | loss: 97.68872| val_0_mse: 2479.568603515625|  0:00:08s\n","epoch 12 | loss: 78.06646| val_0_mse: 2493.45556640625|  0:00:09s\n","epoch 13 | loss: 95.99711| val_0_mse: 2167.982666015625|  0:00:10s\n","epoch 14 | loss: 68.62392| val_0_mse: 2105.250732421875|  0:00:10s\n","epoch 15 | loss: 80.79445| val_0_mse: 1664.4019775390625|  0:00:11s\n","epoch 16 | loss: 76.28893| val_0_mse: 1238.5450439453125|  0:00:12s\n","epoch 17 | loss: 79.33452| val_0_mse: 1166.7333984375|  0:00:12s\n","epoch 18 | loss: 70.18095| val_0_mse: 975.3926391601562|  0:00:13s\n","epoch 19 | loss: 67.26967| val_0_mse: 778.1909790039062|  0:00:14s\n","epoch 20 | loss: 65.07559| val_0_mse: 825.380615234375|  0:00:15s\n","epoch 21 | loss: 59.27936| val_0_mse: 834.6769409179688|  0:00:15s\n","epoch 22 | loss: 65.74594| val_0_mse: 585.1459350585938|  0:00:16s\n","epoch 23 | loss: 60.59127| val_0_mse: 598.7515258789062|  0:00:17s\n","epoch 24 | loss: 52.81543| val_0_mse: 334.9973449707031|  0:00:17s\n","epoch 25 | loss: 66.70093| val_0_mse: 434.2684020996094|  0:00:18s\n","epoch 26 | loss: 59.21693| val_0_mse: 319.80169677734375|  0:00:19s\n","epoch 27 | loss: 55.02486| val_0_mse: 376.0496520996094|  0:00:20s\n","epoch 28 | loss: 59.18532| val_0_mse: 164.515869140625|  0:00:20s\n","epoch 29 | loss: 46.34272| val_0_mse: 213.8447265625|  0:00:21s\n","epoch 30 | loss: 47.95715| val_0_mse: 189.55430603027344|  0:00:22s\n","epoch 31 | loss: 43.4832 | val_0_mse: 85.47274017333984|  0:00:23s\n","epoch 32 | loss: 44.2523 | val_0_mse: 112.35746002197266|  0:00:23s\n","epoch 33 | loss: 49.7422 | val_0_mse: 136.10397338867188|  0:00:24s\n","epoch 34 | loss: 57.92544| val_0_mse: 162.90866088867188|  0:00:25s\n","epoch 35 | loss: 55.93266| val_0_mse: 91.44241333007812|  0:00:25s\n","epoch 36 | loss: 93.56077| val_0_mse: 87.89335632324219|  0:00:26s\n","epoch 37 | loss: 70.22167| val_0_mse: 111.9510726928711|  0:00:27s\n","epoch 38 | loss: 60.79748| val_0_mse: 74.58843994140625|  0:00:28s\n","epoch 39 | loss: 70.12933| val_0_mse: 66.16565704345703|  0:00:28s\n","epoch 40 | loss: 55.93555| val_0_mse: 56.59370040893555|  0:00:29s\n","epoch 41 | loss: 47.64482| val_0_mse: 91.11461639404297|  0:00:30s\n","epoch 42 | loss: 46.72897| val_0_mse: 46.009239196777344|  0:00:30s\n","epoch 43 | loss: 48.0579 | val_0_mse: 35.18437957763672|  0:00:31s\n","epoch 44 | loss: 46.30131| val_0_mse: 49.383121490478516|  0:00:32s\n","epoch 45 | loss: 37.87689| val_0_mse: 32.05405044555664|  0:00:33s\n","epoch 46 | loss: 36.50347| val_0_mse: 41.84086990356445|  0:00:33s\n","epoch 47 | loss: 42.06177| val_0_mse: 43.03506851196289|  0:00:34s\n","epoch 48 | loss: 45.55328| val_0_mse: 34.76382827758789|  0:00:35s\n","epoch 49 | loss: 43.96848| val_0_mse: 32.476219177246094|  0:00:35s\n","epoch 50 | loss: 71.05245| val_0_mse: 32.5855712890625|  0:00:36s\n","epoch 51 | loss: 53.16508| val_0_mse: 30.146520614624023|  0:00:37s\n","epoch 52 | loss: 40.13909| val_0_mse: 32.023109436035156|  0:00:38s\n","epoch 53 | loss: 42.80622| val_0_mse: 27.336589813232422|  0:00:38s\n","epoch 54 | loss: 47.13176| val_0_mse: 35.579898834228516|  0:00:39s\n","epoch 55 | loss: 56.42238| val_0_mse: 46.06801986694336|  0:00:40s\n","epoch 56 | loss: 39.33932| val_0_mse: 26.4183406829834|  0:00:40s\n","epoch 57 | loss: 36.84048| val_0_mse: 28.401790618896484|  0:00:41s\n","epoch 58 | loss: 42.6949 | val_0_mse: 30.336790084838867|  0:00:42s\n","epoch 59 | loss: 43.32184| val_0_mse: 46.58794021606445|  0:00:42s\n","epoch 60 | loss: 38.00374| val_0_mse: 46.096641540527344|  0:00:43s\n","epoch 61 | loss: 52.02834| val_0_mse: 45.22867965698242|  0:00:44s\n","epoch 62 | loss: 37.82232| val_0_mse: 52.37202072143555|  0:00:45s\n","epoch 63 | loss: 47.25648| val_0_mse: 35.456581115722656|  0:00:45s\n","epoch 64 | loss: 40.71816| val_0_mse: 28.449899673461914|  0:00:46s\n","epoch 65 | loss: 37.17639| val_0_mse: 26.745689392089844|  0:00:47s\n","epoch 66 | loss: 30.36815| val_0_mse: 21.43651008605957|  0:00:47s\n","epoch 67 | loss: 30.76529| val_0_mse: 26.10696029663086|  0:00:48s\n","epoch 68 | loss: 39.33285| val_0_mse: 24.654939651489258|  0:00:49s\n","epoch 69 | loss: 32.17436| val_0_mse: 27.174089431762695|  0:00:50s\n","epoch 70 | loss: 34.87962| val_0_mse: 36.897491455078125|  0:00:50s\n","epoch 71 | loss: 29.16269| val_0_mse: 27.99452018737793|  0:00:51s\n","epoch 72 | loss: 32.18695| val_0_mse: 44.820899963378906|  0:00:52s\n","epoch 73 | loss: 49.1812 | val_0_mse: 32.293460845947266|  0:00:53s\n","epoch 74 | loss: 38.86158| val_0_mse: 31.416439056396484|  0:00:53s\n","epoch 75 | loss: 33.89755| val_0_mse: 21.4000301361084|  0:00:54s\n","epoch 76 | loss: 33.52243| val_0_mse: 21.629690170288086|  0:00:55s\n","epoch 77 | loss: 32.09312| val_0_mse: 19.708009719848633|  0:00:55s\n","epoch 78 | loss: 33.61309| val_0_mse: 34.70640182495117|  0:00:56s\n","epoch 79 | loss: 31.99504| val_0_mse: 29.30129051208496|  0:00:57s\n","epoch 80 | loss: 37.09647| val_0_mse: 49.09783935546875|  0:00:58s\n","epoch 81 | loss: 29.39101| val_0_mse: 27.822019577026367|  0:00:58s\n","epoch 82 | loss: 27.57914| val_0_mse: 25.959449768066406|  0:00:59s\n","epoch 83 | loss: 32.92214| val_0_mse: 28.403430938720703|  0:01:00s\n","epoch 84 | loss: 34.10076| val_0_mse: 23.84783935546875|  0:01:01s\n","epoch 85 | loss: 26.04139| val_0_mse: 20.095069885253906|  0:01:01s\n","epoch 86 | loss: 39.44747| val_0_mse: 24.042449951171875|  0:01:02s\n","epoch 87 | loss: 28.96636| val_0_mse: 19.942880630493164|  0:01:03s\n","\n","Early stopping occurred at epoch 87 with best_epoch = 77 and best_val_0_mse = 19.708009719848633\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 13:48:01,286] Trial 82 finished with value: 19.708011627197266 and parameters: {'n_d': 43, 'n_steps': 3, 'gamma': 1.3840518680797005, 'n_independent': 4, 'n_shared': 4, 'momentum': 0.2096279201874257}. Best is trial 39 with value: 14.34697437286377.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 2222.31691| val_0_mse: 3691.1376953125|  0:00:00s\n","epoch 1  | loss: 982.34722| val_0_mse: 2383.008544921875|  0:00:01s\n","epoch 2  | loss: 394.84484| val_0_mse: 2617.378662109375|  0:00:02s\n","epoch 3  | loss: 289.96267| val_0_mse: 3500.2236328125|  0:00:02s\n","epoch 4  | loss: 206.28611| val_0_mse: 3219.9873046875|  0:00:03s\n","epoch 5  | loss: 200.88993| val_0_mse: 3014.70458984375|  0:00:04s\n","epoch 6  | loss: 173.65732| val_0_mse: 3072.613525390625|  0:00:04s\n","epoch 7  | loss: 164.89755| val_0_mse: 2697.510498046875|  0:00:05s\n","epoch 8  | loss: 161.30603| val_0_mse: 2796.7666015625|  0:00:06s\n","epoch 9  | loss: 144.22259| val_0_mse: 2673.31494140625|  0:00:07s\n","epoch 10 | loss: 131.26624| val_0_mse: 2618.0322265625|  0:00:07s\n","epoch 11 | loss: 116.7874| val_0_mse: 2572.35888671875|  0:00:08s\n","\n","Early stopping occurred at epoch 11 with best_epoch = 1 and best_val_0_mse = 2383.008544921875\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 13:48:10,340] Trial 83 finished with value: 2383.008544921875 and parameters: {'n_d': 39, 'n_steps': 3, 'gamma': 1.307419578862803, 'n_independent': 4, 'n_shared': 4, 'momentum': 0.18759728936195158}. Best is trial 39 with value: 14.34697437286377.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 2214.16847| val_0_mse: 4007.115234375|  0:00:00s\n","epoch 1  | loss: 942.74668| val_0_mse: 5276.83544921875|  0:00:01s\n","epoch 2  | loss: 329.03307| val_0_mse: 3331.873291015625|  0:00:02s\n","epoch 3  | loss: 238.30701| val_0_mse: 3276.618896484375|  0:00:03s\n","epoch 4  | loss: 202.29579| val_0_mse: 2643.68505859375|  0:00:03s\n","epoch 5  | loss: 147.99968| val_0_mse: 2790.3583984375|  0:00:04s\n","epoch 6  | loss: 138.61669| val_0_mse: 2806.709228515625|  0:00:05s\n","epoch 7  | loss: 148.03998| val_0_mse: 2686.12255859375|  0:00:06s\n","epoch 8  | loss: 127.69869| val_0_mse: 2749.680419921875|  0:00:06s\n","epoch 9  | loss: 109.54796| val_0_mse: 2630.94189453125|  0:00:07s\n","epoch 10 | loss: 118.59703| val_0_mse: 2531.30126953125|  0:00:08s\n","epoch 11 | loss: 102.01634| val_0_mse: 2407.32177734375|  0:00:09s\n","epoch 12 | loss: 105.3805| val_0_mse: 2490.984619140625|  0:00:10s\n","epoch 13 | loss: 92.90728| val_0_mse: 2388.3662109375|  0:00:11s\n","epoch 14 | loss: 89.00287| val_0_mse: 2231.382568359375|  0:00:11s\n","epoch 15 | loss: 85.00276| val_0_mse: 2191.3876953125|  0:00:12s\n","epoch 16 | loss: 87.17049| val_0_mse: 2137.06298828125|  0:00:13s\n","epoch 17 | loss: 75.75972| val_0_mse: 2201.24462890625|  0:00:14s\n","epoch 18 | loss: 86.75468| val_0_mse: 1666.9161376953125|  0:00:14s\n","epoch 19 | loss: 76.31818| val_0_mse: 1472.412841796875|  0:00:15s\n","epoch 20 | loss: 93.10194| val_0_mse: 1245.0347900390625|  0:00:16s\n","epoch 21 | loss: 107.26525| val_0_mse: 1344.5616455078125|  0:00:17s\n","epoch 22 | loss: 88.76248| val_0_mse: 1004.8330688476562|  0:00:18s\n","epoch 23 | loss: 86.63312| val_0_mse: 819.769775390625|  0:00:18s\n","epoch 24 | loss: 75.92191| val_0_mse: 630.3593139648438|  0:00:19s\n","epoch 25 | loss: 72.8308 | val_0_mse: 626.3218383789062|  0:00:20s\n","epoch 26 | loss: 73.51344| val_0_mse: 341.5355529785156|  0:00:21s\n","epoch 27 | loss: 91.77438| val_0_mse: 273.8608703613281|  0:00:22s\n","epoch 28 | loss: 95.64684| val_0_mse: 287.19354248046875|  0:00:22s\n","epoch 29 | loss: 65.52595| val_0_mse: 263.5440979003906|  0:00:23s\n","epoch 30 | loss: 61.27722| val_0_mse: 421.5448303222656|  0:00:24s\n","epoch 31 | loss: 68.25622| val_0_mse: 353.4882507324219|  0:00:25s\n","epoch 32 | loss: 72.27271| val_0_mse: 249.75393676757812|  0:00:25s\n","epoch 33 | loss: 89.25876| val_0_mse: 101.1384506225586|  0:00:26s\n","epoch 34 | loss: 73.32749| val_0_mse: 94.58564758300781|  0:00:27s\n","epoch 35 | loss: 68.97656| val_0_mse: 112.93480682373047|  0:00:28s\n","epoch 36 | loss: 65.43292| val_0_mse: 89.86302947998047|  0:00:29s\n","epoch 37 | loss: 62.76266| val_0_mse: 87.3111572265625|  0:00:29s\n","epoch 38 | loss: 58.57869| val_0_mse: 70.95494079589844|  0:00:30s\n","epoch 39 | loss: 60.95859| val_0_mse: 144.7545623779297|  0:00:31s\n","epoch 40 | loss: 70.19042| val_0_mse: 148.97549438476562|  0:00:32s\n","epoch 41 | loss: 86.09654| val_0_mse: 66.64541625976562|  0:00:32s\n","epoch 42 | loss: 56.63486| val_0_mse: 58.86320114135742|  0:00:33s\n","epoch 43 | loss: 64.60044| val_0_mse: 50.66582107543945|  0:00:34s\n","epoch 44 | loss: 60.68551| val_0_mse: 90.57649993896484|  0:00:35s\n","epoch 45 | loss: 51.83776| val_0_mse: 43.57101821899414|  0:00:36s\n","epoch 46 | loss: 53.97629| val_0_mse: 41.21244812011719|  0:00:36s\n","epoch 47 | loss: 68.71945| val_0_mse: 29.487089157104492|  0:00:37s\n","epoch 48 | loss: 55.98117| val_0_mse: 31.830829620361328|  0:00:38s\n","epoch 49 | loss: 55.20783| val_0_mse: 30.2268009185791|  0:00:39s\n","epoch 50 | loss: 48.2611 | val_0_mse: 36.27753829956055|  0:00:39s\n","epoch 51 | loss: 64.6272 | val_0_mse: 34.957000732421875|  0:00:40s\n","epoch 52 | loss: 59.36203| val_0_mse: 46.621978759765625|  0:00:41s\n","epoch 53 | loss: 78.39952| val_0_mse: 53.145118713378906|  0:00:42s\n","epoch 54 | loss: 46.22921| val_0_mse: 33.504180908203125|  0:00:43s\n","epoch 55 | loss: 54.09465| val_0_mse: 43.98318862915039|  0:00:43s\n","epoch 56 | loss: 42.38508| val_0_mse: 54.402320861816406|  0:00:44s\n","epoch 57 | loss: 43.62286| val_0_mse: 25.443500518798828|  0:00:45s\n","epoch 58 | loss: 54.18412| val_0_mse: 31.335920333862305|  0:00:46s\n","epoch 59 | loss: 71.23925| val_0_mse: 40.20766830444336|  0:00:47s\n","epoch 60 | loss: 46.15463| val_0_mse: 25.45638084411621|  0:00:47s\n","epoch 61 | loss: 51.12124| val_0_mse: 35.894691467285156|  0:00:48s\n","epoch 62 | loss: 39.54325| val_0_mse: 30.333999633789062|  0:00:49s\n","epoch 63 | loss: 44.33282| val_0_mse: 20.42889976501465|  0:00:50s\n","epoch 64 | loss: 47.48515| val_0_mse: 39.38045883178711|  0:00:50s\n","epoch 65 | loss: 46.11148| val_0_mse: 21.085039138793945|  0:00:51s\n","epoch 66 | loss: 42.74192| val_0_mse: 26.060949325561523|  0:00:52s\n","epoch 67 | loss: 51.46861| val_0_mse: 26.8116397857666|  0:00:53s\n","epoch 68 | loss: 67.48159| val_0_mse: 35.566341400146484|  0:00:53s\n","epoch 69 | loss: 61.36978| val_0_mse: 62.740379333496094|  0:00:54s\n","epoch 70 | loss: 48.85376| val_0_mse: 38.23630142211914|  0:00:55s\n","epoch 71 | loss: 41.79294| val_0_mse: 22.5592098236084|  0:00:55s\n","epoch 72 | loss: 40.87041| val_0_mse: 23.097810745239258|  0:00:56s\n","epoch 73 | loss: 64.70308| val_0_mse: 34.280338287353516|  0:00:57s\n","\n","Early stopping occurred at epoch 73 with best_epoch = 63 and best_val_0_mse = 20.42889976501465\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 13:49:08,261] Trial 84 finished with value: 20.428905487060547 and parameters: {'n_d': 42, 'n_steps': 3, 'gamma': 1.3818909721246493, 'n_independent': 5, 'n_shared': 4, 'momentum': 0.2107714341383338}. Best is trial 39 with value: 14.34697437286377.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 2366.17533| val_0_mse: 6627.42333984375|  0:00:01s\n","epoch 1  | loss: 1929.1945| val_0_mse: 3296.337890625|  0:00:03s\n","epoch 2  | loss: 1445.07391| val_0_mse: 18238.373046875|  0:00:04s\n","epoch 3  | loss: 940.48042| val_0_mse: 16490.33203125|  0:00:06s\n","epoch 4  | loss: 801.69069| val_0_mse: 15051.638671875|  0:00:07s\n","epoch 5  | loss: 722.80228| val_0_mse: 7216.47998046875|  0:00:09s\n","epoch 6  | loss: 619.78596| val_0_mse: 5992.30078125|  0:00:11s\n","epoch 7  | loss: 683.65064| val_0_mse: 5016.78857421875|  0:00:12s\n","epoch 8  | loss: 592.40616| val_0_mse: 6380.13134765625|  0:00:14s\n","epoch 9  | loss: 728.18091| val_0_mse: 4391.31884765625|  0:00:15s\n","epoch 10 | loss: 701.1656| val_0_mse: 3522.193359375|  0:00:17s\n","epoch 11 | loss: 704.29765| val_0_mse: 3663.69189453125|  0:00:18s\n","\n","Early stopping occurred at epoch 11 with best_epoch = 1 and best_val_0_mse = 3296.337890625\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 13:49:28,275] Trial 85 finished with value: 3296.337890625 and parameters: {'n_d': 40, 'n_steps': 10, 'gamma': 1.326812280071632, 'n_independent': 3, 'n_shared': 4, 'momentum': 0.22983503436027858}. Best is trial 39 with value: 14.34697437286377.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 2117.99601| val_0_mse: 4869.9462890625|  0:00:00s\n","epoch 1  | loss: 595.98663| val_0_mse: 3326.189697265625|  0:00:01s\n","epoch 2  | loss: 257.43813| val_0_mse: 6102.67333984375|  0:00:02s\n","epoch 3  | loss: 193.84023| val_0_mse: 2315.49169921875|  0:00:03s\n","epoch 4  | loss: 147.20566| val_0_mse: 2622.26904296875|  0:00:03s\n","epoch 5  | loss: 149.66163| val_0_mse: 2811.58154296875|  0:00:04s\n","epoch 6  | loss: 119.70694| val_0_mse: 2607.34814453125|  0:00:05s\n","epoch 7  | loss: 135.40836| val_0_mse: 2556.465576171875|  0:00:06s\n","epoch 8  | loss: 118.55347| val_0_mse: 2687.72265625|  0:00:06s\n","epoch 9  | loss: 91.54692| val_0_mse: 2820.965087890625|  0:00:07s\n","epoch 10 | loss: 99.78549| val_0_mse: 2814.906005859375|  0:00:08s\n","epoch 11 | loss: 78.06753| val_0_mse: 2825.450439453125|  0:00:09s\n","epoch 12 | loss: 71.95389| val_0_mse: 2549.955078125|  0:00:09s\n","epoch 13 | loss: 75.27366| val_0_mse: 2547.80712890625|  0:00:10s\n","\n","Early stopping occurred at epoch 13 with best_epoch = 3 and best_val_0_mse = 2315.49169921875\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 13:49:39,204] Trial 86 finished with value: 2315.49169921875 and parameters: {'n_d': 47, 'n_steps': 3, 'gamma': 1.4574896484542061, 'n_independent': 4, 'n_shared': 5, 'momentum': 0.20928664068459726}. Best is trial 39 with value: 14.34697437286377.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 2184.85023| val_0_mse: 5479.1259765625|  0:00:00s\n","epoch 1  | loss: 816.97703| val_0_mse: 4005.7373046875|  0:00:01s\n","epoch 2  | loss: 267.75041| val_0_mse: 3089.617919921875|  0:00:02s\n","epoch 3  | loss: 189.96815| val_0_mse: 2776.302734375|  0:00:02s\n","epoch 4  | loss: 139.43139| val_0_mse: 2663.702880859375|  0:00:03s\n","epoch 5  | loss: 110.84847| val_0_mse: 2632.443603515625|  0:00:04s\n","epoch 6  | loss: 119.7096| val_0_mse: 2533.798095703125|  0:00:04s\n","epoch 7  | loss: 100.80643| val_0_mse: 2401.140380859375|  0:00:05s\n","epoch 8  | loss: 86.88314| val_0_mse: 2488.202392578125|  0:00:06s\n","epoch 9  | loss: 94.2668 | val_0_mse: 2377.123291015625|  0:00:07s\n","epoch 10 | loss: 89.57829| val_0_mse: 2310.107666015625|  0:00:07s\n","epoch 11 | loss: 72.72724| val_0_mse: 2606.6943359375|  0:00:08s\n","epoch 12 | loss: 87.40546| val_0_mse: 2429.839111328125|  0:00:09s\n","epoch 13 | loss: 80.32565| val_0_mse: 2481.242431640625|  0:00:09s\n","epoch 14 | loss: 74.63121| val_0_mse: 2481.25830078125|  0:00:10s\n","epoch 15 | loss: 67.9154 | val_0_mse: 2590.61767578125|  0:00:11s\n","epoch 16 | loss: 86.84987| val_0_mse: 2425.482421875|  0:00:11s\n","epoch 17 | loss: 80.57619| val_0_mse: 2511.615478515625|  0:00:12s\n","epoch 18 | loss: 87.38628| val_0_mse: 2325.44970703125|  0:00:13s\n","epoch 19 | loss: 62.2337 | val_0_mse: 2080.0537109375|  0:00:13s\n","epoch 20 | loss: 71.18966| val_0_mse: 1363.1558837890625|  0:00:14s\n","epoch 21 | loss: 60.29135| val_0_mse: 1297.019287109375|  0:00:15s\n","epoch 22 | loss: 69.01341| val_0_mse: 954.0853881835938|  0:00:16s\n","epoch 23 | loss: 58.25019| val_0_mse: 915.8709716796875|  0:00:16s\n","epoch 24 | loss: 49.071  | val_0_mse: 682.0639038085938|  0:00:17s\n","epoch 25 | loss: 45.39732| val_0_mse: 625.16015625|  0:00:18s\n","epoch 26 | loss: 53.53508| val_0_mse: 547.4176635742188|  0:00:19s\n","epoch 27 | loss: 51.55454| val_0_mse: 382.24481201171875|  0:00:19s\n","epoch 28 | loss: 66.35378| val_0_mse: 372.00048828125|  0:00:20s\n","epoch 29 | loss: 56.59235| val_0_mse: 364.35546875|  0:00:21s\n","epoch 30 | loss: 53.85887| val_0_mse: 325.2217712402344|  0:00:21s\n","epoch 31 | loss: 46.5865 | val_0_mse: 188.11070251464844|  0:00:22s\n","epoch 32 | loss: 55.55943| val_0_mse: 133.68460083007812|  0:00:23s\n","epoch 33 | loss: 45.47134| val_0_mse: 204.49403381347656|  0:00:23s\n","epoch 34 | loss: 48.39145| val_0_mse: 211.11480712890625|  0:00:24s\n","epoch 35 | loss: 54.4154 | val_0_mse: 156.46646118164062|  0:00:25s\n","epoch 36 | loss: 60.05351| val_0_mse: 97.59425354003906|  0:00:26s\n","epoch 37 | loss: 45.62111| val_0_mse: 80.52642059326172|  0:00:26s\n","epoch 38 | loss: 46.41502| val_0_mse: 75.31623840332031|  0:00:27s\n","epoch 39 | loss: 46.17409| val_0_mse: 89.79624938964844|  0:00:28s\n","epoch 40 | loss: 49.63935| val_0_mse: 71.40457153320312|  0:00:28s\n","epoch 41 | loss: 53.93736| val_0_mse: 57.12443161010742|  0:00:29s\n","epoch 42 | loss: 59.55476| val_0_mse: 35.89390182495117|  0:00:30s\n","epoch 43 | loss: 49.31694| val_0_mse: 30.045339584350586|  0:00:30s\n","epoch 44 | loss: 51.2709 | val_0_mse: 55.942081451416016|  0:00:31s\n","epoch 45 | loss: 45.92515| val_0_mse: 37.377410888671875|  0:00:32s\n","epoch 46 | loss: 39.42444| val_0_mse: 34.55693817138672|  0:00:33s\n","epoch 47 | loss: 40.08663| val_0_mse: 45.914268493652344|  0:00:33s\n","epoch 48 | loss: 49.01949| val_0_mse: 42.5949592590332|  0:00:34s\n","epoch 49 | loss: 52.19532| val_0_mse: 42.203800201416016|  0:00:35s\n","epoch 50 | loss: 51.89303| val_0_mse: 27.882400512695312|  0:00:35s\n","epoch 51 | loss: 39.8504 | val_0_mse: 44.33285140991211|  0:00:36s\n","epoch 52 | loss: 54.40975| val_0_mse: 28.538240432739258|  0:00:37s\n","epoch 53 | loss: 53.96342| val_0_mse: 37.655391693115234|  0:00:37s\n","epoch 54 | loss: 41.23278| val_0_mse: 25.13964080810547|  0:00:38s\n","epoch 55 | loss: 35.33827| val_0_mse: 27.363229751586914|  0:00:39s\n","epoch 56 | loss: 38.44123| val_0_mse: 37.215911865234375|  0:00:39s\n","epoch 57 | loss: 49.25647| val_0_mse: 24.732969284057617|  0:00:40s\n","epoch 58 | loss: 69.3403 | val_0_mse: 43.86444854736328|  0:00:41s\n","epoch 59 | loss: 42.14691| val_0_mse: 30.708690643310547|  0:00:41s\n","epoch 60 | loss: 38.00849| val_0_mse: 18.44062042236328|  0:00:42s\n","epoch 61 | loss: 42.53343| val_0_mse: 42.55397033691406|  0:00:43s\n","epoch 62 | loss: 38.53903| val_0_mse: 39.212371826171875|  0:00:44s\n","epoch 63 | loss: 36.7185 | val_0_mse: 43.610740661621094|  0:00:44s\n","epoch 64 | loss: 44.93421| val_0_mse: 29.105119705200195|  0:00:45s\n","epoch 65 | loss: 51.93324| val_0_mse: 24.647890090942383|  0:00:46s\n","epoch 66 | loss: 45.48745| val_0_mse: 29.694860458374023|  0:00:47s\n","epoch 67 | loss: 42.02677| val_0_mse: 26.179330825805664|  0:00:47s\n","epoch 68 | loss: 32.40401| val_0_mse: 26.743980407714844|  0:00:48s\n","epoch 69 | loss: 41.13234| val_0_mse: 28.592809677124023|  0:00:49s\n","epoch 70 | loss: 31.0865 | val_0_mse: 19.3204402923584|  0:00:49s\n","\n","Early stopping occurred at epoch 70 with best_epoch = 60 and best_val_0_mse = 18.44062042236328\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 13:50:29,589] Trial 87 finished with value: 18.440624237060547 and parameters: {'n_d': 43, 'n_steps': 3, 'gamma': 1.1834288556223294, 'n_independent': 3, 'n_shared': 5, 'momentum': 0.24014741138365128}. Best is trial 39 with value: 14.34697437286377.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 2168.27737| val_0_mse: 3666.530029296875|  0:00:00s\n","epoch 1  | loss: 1119.14845| val_0_mse: 9223.841796875|  0:00:01s\n","epoch 2  | loss: 457.21672| val_0_mse: 16578.59375|  0:00:02s\n","epoch 3  | loss: 357.72746| val_0_mse: 3058.698974609375|  0:00:03s\n","epoch 4  | loss: 281.08054| val_0_mse: 3357.63623046875|  0:00:04s\n","epoch 5  | loss: 259.46362| val_0_mse: 3288.539306640625|  0:00:05s\n","epoch 6  | loss: 233.15633| val_0_mse: 2959.11669921875|  0:00:05s\n","epoch 7  | loss: 176.76186| val_0_mse: 2952.94091796875|  0:00:06s\n","epoch 8  | loss: 158.74805| val_0_mse: 2730.291748046875|  0:00:07s\n","epoch 9  | loss: 204.6353| val_0_mse: 2668.757080078125|  0:00:08s\n","epoch 10 | loss: 165.80434| val_0_mse: 2518.037353515625|  0:00:09s\n","epoch 11 | loss: 154.8247| val_0_mse: 2443.189697265625|  0:00:10s\n","epoch 12 | loss: 129.99452| val_0_mse: 2495.144775390625|  0:00:11s\n","epoch 13 | loss: 128.07633| val_0_mse: 2640.78759765625|  0:00:11s\n","epoch 14 | loss: 148.398 | val_0_mse: 2418.4716796875|  0:00:12s\n","epoch 15 | loss: 126.50885| val_0_mse: 2383.57666015625|  0:00:13s\n","epoch 16 | loss: 118.90898| val_0_mse: 2391.510009765625|  0:00:14s\n","epoch 17 | loss: 115.55954| val_0_mse: 2269.966552734375|  0:00:15s\n","epoch 18 | loss: 119.26917| val_0_mse: 2371.713623046875|  0:00:15s\n","epoch 19 | loss: 102.33931| val_0_mse: 2427.909912109375|  0:00:16s\n","epoch 20 | loss: 111.49271| val_0_mse: 2391.31103515625|  0:00:17s\n","epoch 21 | loss: 102.25081| val_0_mse: 2061.09765625|  0:00:18s\n","epoch 22 | loss: 117.80604| val_0_mse: 1807.4530029296875|  0:00:19s\n","epoch 23 | loss: 87.08366| val_0_mse: 1410.7738037109375|  0:00:20s\n","epoch 24 | loss: 96.45709| val_0_mse: 1302.786376953125|  0:00:21s\n","epoch 25 | loss: 119.38128| val_0_mse: 1343.0101318359375|  0:00:21s\n","epoch 26 | loss: 95.91517| val_0_mse: 753.7675170898438|  0:00:22s\n","epoch 27 | loss: 80.50788| val_0_mse: 823.3673095703125|  0:00:23s\n","epoch 28 | loss: 86.69621| val_0_mse: 869.0927734375|  0:00:24s\n","epoch 29 | loss: 85.738  | val_0_mse: 436.5157165527344|  0:00:25s\n","epoch 30 | loss: 77.7769 | val_0_mse: 351.7412414550781|  0:00:26s\n","epoch 31 | loss: 73.48446| val_0_mse: 238.74461364746094|  0:00:26s\n","epoch 32 | loss: 85.33861| val_0_mse: 373.682373046875|  0:00:27s\n","epoch 33 | loss: 85.02353| val_0_mse: 394.674072265625|  0:00:28s\n","epoch 34 | loss: 68.85578| val_0_mse: 99.10527038574219|  0:00:29s\n","epoch 35 | loss: 69.17037| val_0_mse: 155.48350524902344|  0:00:30s\n","epoch 36 | loss: 62.63836| val_0_mse: 202.88453674316406|  0:00:31s\n","epoch 37 | loss: 66.24432| val_0_mse: 127.7464370727539|  0:00:32s\n","epoch 38 | loss: 71.37014| val_0_mse: 91.55603790283203|  0:00:32s\n","epoch 39 | loss: 65.69291| val_0_mse: 92.09705352783203|  0:00:33s\n","epoch 40 | loss: 60.68574| val_0_mse: 87.30782318115234|  0:00:34s\n","epoch 41 | loss: 68.66828| val_0_mse: 62.06687927246094|  0:00:35s\n","epoch 42 | loss: 54.9769 | val_0_mse: 62.75944137573242|  0:00:36s\n","epoch 43 | loss: 53.30534| val_0_mse: 74.51725769042969|  0:00:37s\n","epoch 44 | loss: 55.11227| val_0_mse: 52.677791595458984|  0:00:37s\n","epoch 45 | loss: 55.27508| val_0_mse: 75.08908081054688|  0:00:38s\n","epoch 46 | loss: 57.98967| val_0_mse: 45.496551513671875|  0:00:39s\n","epoch 47 | loss: 54.35814| val_0_mse: 62.939659118652344|  0:00:40s\n","epoch 48 | loss: 55.60393| val_0_mse: 76.86775207519531|  0:00:41s\n","epoch 49 | loss: 64.03946| val_0_mse: 40.77648162841797|  0:00:42s\n","epoch 50 | loss: 49.37697| val_0_mse: 36.04029846191406|  0:00:43s\n","epoch 51 | loss: 53.31675| val_0_mse: 53.750919342041016|  0:00:43s\n","epoch 52 | loss: 48.93364| val_0_mse: 39.329410552978516|  0:00:44s\n","epoch 53 | loss: 64.5938 | val_0_mse: 31.29482078552246|  0:00:45s\n","epoch 54 | loss: 62.6521 | val_0_mse: 59.653961181640625|  0:00:46s\n","epoch 55 | loss: 50.015  | val_0_mse: 35.46125030517578|  0:00:47s\n","epoch 56 | loss: 60.78955| val_0_mse: 48.01314163208008|  0:00:48s\n","epoch 57 | loss: 49.21043| val_0_mse: 41.215980529785156|  0:00:48s\n","epoch 58 | loss: 53.07826| val_0_mse: 53.71189880371094|  0:00:49s\n","epoch 59 | loss: 55.81811| val_0_mse: 46.00518035888672|  0:00:50s\n","epoch 60 | loss: 60.52482| val_0_mse: 45.34080123901367|  0:00:51s\n","epoch 61 | loss: 52.49173| val_0_mse: 30.557859420776367|  0:00:52s\n","epoch 62 | loss: 38.25967| val_0_mse: 29.723630905151367|  0:00:53s\n","epoch 63 | loss: 52.23549| val_0_mse: 29.77634048461914|  0:00:53s\n","epoch 64 | loss: 45.8517 | val_0_mse: 37.13093948364258|  0:00:54s\n","epoch 65 | loss: 48.48028| val_0_mse: 30.069299697875977|  0:00:55s\n","epoch 66 | loss: 36.97006| val_0_mse: 33.780460357666016|  0:00:56s\n","epoch 67 | loss: 43.26634| val_0_mse: 43.80537033081055|  0:00:57s\n","epoch 68 | loss: 61.53898| val_0_mse: 29.57908058166504|  0:00:58s\n","epoch 69 | loss: 48.05318| val_0_mse: 26.02511978149414|  0:00:59s\n","epoch 70 | loss: 41.68149| val_0_mse: 39.19464111328125|  0:00:59s\n","epoch 71 | loss: 49.39201| val_0_mse: 30.59733009338379|  0:01:00s\n","epoch 72 | loss: 45.65459| val_0_mse: 28.903779983520508|  0:01:01s\n","epoch 73 | loss: 43.62749| val_0_mse: 34.46892166137695|  0:01:02s\n","epoch 74 | loss: 38.30067| val_0_mse: 28.58782958984375|  0:01:03s\n","epoch 75 | loss: 51.80745| val_0_mse: 42.07107925415039|  0:01:04s\n","epoch 76 | loss: 47.97207| val_0_mse: 47.11817932128906|  0:01:05s\n","epoch 77 | loss: 50.2008 | val_0_mse: 26.460960388183594|  0:01:05s\n","epoch 78 | loss: 43.14575| val_0_mse: 26.156330108642578|  0:01:06s\n","epoch 79 | loss: 42.78307| val_0_mse: 28.013620376586914|  0:01:07s\n","\n","Early stopping occurred at epoch 79 with best_epoch = 69 and best_val_0_mse = 26.02511978149414\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 13:51:37,820] Trial 88 finished with value: 26.025117874145508 and parameters: {'n_d': 50, 'n_steps': 4, 'gamma': 1.2054360460141744, 'n_independent': 3, 'n_shared': 5, 'momentum': 0.24098531409038038}. Best is trial 39 with value: 14.34697437286377.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 2204.71563| val_0_mse: 14134.4248046875|  0:00:00s\n","epoch 1  | loss: 1107.49516| val_0_mse: 12345.302734375|  0:00:01s\n","epoch 2  | loss: 418.98405| val_0_mse: 3197.903564453125|  0:00:02s\n","epoch 3  | loss: 257.00906| val_0_mse: 4227.77783203125|  0:00:02s\n","epoch 4  | loss: 182.49777| val_0_mse: 2924.856689453125|  0:00:03s\n","epoch 5  | loss: 174.52416| val_0_mse: 2743.517333984375|  0:00:04s\n","epoch 6  | loss: 162.12962| val_0_mse: 2526.023681640625|  0:00:04s\n","epoch 7  | loss: 119.44211| val_0_mse: 2528.44482421875|  0:00:05s\n","epoch 8  | loss: 107.87273| val_0_mse: 2669.32373046875|  0:00:06s\n","epoch 9  | loss: 97.50587| val_0_mse: 2617.639404296875|  0:00:06s\n","epoch 10 | loss: 100.82601| val_0_mse: 2454.39501953125|  0:00:07s\n","epoch 11 | loss: 95.65857| val_0_mse: 2475.427734375|  0:00:08s\n","epoch 12 | loss: 105.62081| val_0_mse: 2445.165771484375|  0:00:08s\n","epoch 13 | loss: 87.1121 | val_0_mse: 2520.270751953125|  0:00:09s\n","epoch 14 | loss: 98.89267| val_0_mse: 2548.716064453125|  0:00:10s\n","epoch 15 | loss: 71.44865| val_0_mse: 2526.010009765625|  0:00:10s\n","epoch 16 | loss: 84.85411| val_0_mse: 2555.08544921875|  0:00:11s\n","epoch 17 | loss: 76.30472| val_0_mse: 2501.968505859375|  0:00:12s\n","epoch 18 | loss: 82.17896| val_0_mse: 2193.867431640625|  0:00:12s\n","epoch 19 | loss: 72.59867| val_0_mse: 2154.005615234375|  0:00:13s\n","epoch 20 | loss: 85.083  | val_0_mse: 1300.7236328125|  0:00:14s\n","epoch 21 | loss: 66.03396| val_0_mse: 1318.7088623046875|  0:00:14s\n","epoch 22 | loss: 56.96646| val_0_mse: 1217.810546875|  0:00:15s\n","epoch 23 | loss: 64.30044| val_0_mse: 952.069091796875|  0:00:16s\n","epoch 24 | loss: 73.12709| val_0_mse: 718.8851928710938|  0:00:17s\n","epoch 25 | loss: 70.33825| val_0_mse: 678.4153442382812|  0:00:17s\n","epoch 26 | loss: 66.65954| val_0_mse: 635.2564697265625|  0:00:18s\n","epoch 27 | loss: 70.39321| val_0_mse: 530.424560546875|  0:00:19s\n","epoch 28 | loss: 51.42808| val_0_mse: 555.9852294921875|  0:00:19s\n","epoch 29 | loss: 68.18749| val_0_mse: 314.87359619140625|  0:00:20s\n","epoch 30 | loss: 66.88954| val_0_mse: 302.54486083984375|  0:00:21s\n","epoch 31 | loss: 59.24822| val_0_mse: 333.8830871582031|  0:00:21s\n","epoch 32 | loss: 52.25541| val_0_mse: 217.4488525390625|  0:00:22s\n","epoch 33 | loss: 52.57021| val_0_mse: 143.02569580078125|  0:00:23s\n","epoch 34 | loss: 51.33012| val_0_mse: 129.1598358154297|  0:00:23s\n","epoch 35 | loss: 51.71696| val_0_mse: 90.94872283935547|  0:00:24s\n","epoch 36 | loss: 57.45192| val_0_mse: 78.3036117553711|  0:00:25s\n","epoch 37 | loss: 58.62584| val_0_mse: 106.29399108886719|  0:00:26s\n","epoch 38 | loss: 49.78563| val_0_mse: 127.88668060302734|  0:00:26s\n","epoch 39 | loss: 51.06943| val_0_mse: 90.62864685058594|  0:00:27s\n","epoch 40 | loss: 63.53077| val_0_mse: 50.99549865722656|  0:00:28s\n","epoch 41 | loss: 66.22767| val_0_mse: 71.42584228515625|  0:00:28s\n","epoch 42 | loss: 47.72285| val_0_mse: 76.81346130371094|  0:00:29s\n","epoch 43 | loss: 63.333  | val_0_mse: 43.72206115722656|  0:00:30s\n","epoch 44 | loss: 55.74319| val_0_mse: 49.70772171020508|  0:00:30s\n","epoch 45 | loss: 60.80364| val_0_mse: 40.7446403503418|  0:00:31s\n","epoch 46 | loss: 40.57257| val_0_mse: 31.90644073486328|  0:00:32s\n","epoch 47 | loss: 47.58433| val_0_mse: 25.22003936767578|  0:00:33s\n","epoch 48 | loss: 52.78527| val_0_mse: 43.83073043823242|  0:00:33s\n","epoch 49 | loss: 48.52709| val_0_mse: 33.8936882019043|  0:00:34s\n","epoch 50 | loss: 58.36316| val_0_mse: 39.780799865722656|  0:00:35s\n","epoch 51 | loss: 44.10406| val_0_mse: 44.22037887573242|  0:00:35s\n","epoch 52 | loss: 46.50482| val_0_mse: 34.81378936767578|  0:00:36s\n","epoch 53 | loss: 40.38594| val_0_mse: 30.916419982910156|  0:00:37s\n","epoch 54 | loss: 36.29533| val_0_mse: 22.297210693359375|  0:00:37s\n","epoch 55 | loss: 37.46638| val_0_mse: 35.96821975708008|  0:00:38s\n","epoch 56 | loss: 42.25264| val_0_mse: 28.569580078125|  0:00:39s\n","epoch 57 | loss: 35.75583| val_0_mse: 33.31966018676758|  0:00:40s\n","epoch 58 | loss: 38.87051| val_0_mse: 29.105440139770508|  0:00:40s\n","epoch 59 | loss: 46.11433| val_0_mse: 26.024869918823242|  0:00:41s\n","epoch 60 | loss: 50.35929| val_0_mse: 37.0477294921875|  0:00:42s\n","epoch 61 | loss: 40.35449| val_0_mse: 40.038421630859375|  0:00:42s\n","epoch 62 | loss: 47.91762| val_0_mse: 21.926029205322266|  0:00:43s\n","epoch 63 | loss: 42.8383 | val_0_mse: 29.59008026123047|  0:00:44s\n","epoch 64 | loss: 44.08108| val_0_mse: 21.814409255981445|  0:00:44s\n","epoch 65 | loss: 38.74451| val_0_mse: 23.238330841064453|  0:00:45s\n","epoch 66 | loss: 32.9477 | val_0_mse: 20.118549346923828|  0:00:46s\n","epoch 67 | loss: 39.16017| val_0_mse: 25.30620002746582|  0:00:47s\n","epoch 68 | loss: 39.40589| val_0_mse: 32.22092819213867|  0:00:47s\n","epoch 69 | loss: 34.93445| val_0_mse: 22.015499114990234|  0:00:48s\n","epoch 70 | loss: 41.32746| val_0_mse: 38.17665100097656|  0:00:49s\n","epoch 71 | loss: 54.68823| val_0_mse: 34.44179916381836|  0:00:49s\n","epoch 72 | loss: 40.99941| val_0_mse: 28.233570098876953|  0:00:50s\n","epoch 73 | loss: 43.2813 | val_0_mse: 27.64613914489746|  0:00:51s\n","epoch 74 | loss: 35.94954| val_0_mse: 23.15443992614746|  0:00:51s\n","epoch 75 | loss: 32.05461| val_0_mse: 24.421579360961914|  0:00:52s\n","epoch 76 | loss: 33.49993| val_0_mse: 21.112180709838867|  0:00:53s\n","\n","Early stopping occurred at epoch 76 with best_epoch = 66 and best_val_0_mse = 20.118549346923828\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 13:52:31,507] Trial 89 finished with value: 20.11855125427246 and parameters: {'n_d': 36, 'n_steps': 3, 'gamma': 1.1196261310413693, 'n_independent': 3, 'n_shared': 5, 'momentum': 0.01940465224362692}. Best is trial 39 with value: 14.34697437286377.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 2258.47279| val_0_mse: 4334.48193359375|  0:00:00s\n","epoch 1  | loss: 1203.40477| val_0_mse: 2536.804443359375|  0:00:01s\n","epoch 2  | loss: 337.36998| val_0_mse: 2643.759765625|  0:00:02s\n","epoch 3  | loss: 202.76618| val_0_mse: 2561.13720703125|  0:00:02s\n","epoch 4  | loss: 162.21136| val_0_mse: 3003.762451171875|  0:00:03s\n","epoch 5  | loss: 128.74363| val_0_mse: 2833.400634765625|  0:00:04s\n","epoch 6  | loss: 108.82085| val_0_mse: 2673.929931640625|  0:00:05s\n","epoch 7  | loss: 100.89545| val_0_mse: 2726.433837890625|  0:00:05s\n","epoch 8  | loss: 129.08296| val_0_mse: 2691.7978515625|  0:00:06s\n","epoch 9  | loss: 103.04215| val_0_mse: 2665.368896484375|  0:00:07s\n","epoch 10 | loss: 87.54124| val_0_mse: 2610.503662109375|  0:00:07s\n","epoch 11 | loss: 96.30276| val_0_mse: 2566.767578125|  0:00:08s\n","\n","Early stopping occurred at epoch 11 with best_epoch = 1 and best_val_0_mse = 2536.804443359375\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 13:52:40,335] Trial 90 finished with value: 2536.804443359375 and parameters: {'n_d': 44, 'n_steps': 3, 'gamma': 1.1716442553745667, 'n_independent': 3, 'n_shared': 5, 'momentum': 0.221245764793805}. Best is trial 39 with value: 14.34697437286377.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 2194.30671| val_0_mse: 3282.119384765625|  0:00:00s\n","epoch 1  | loss: 814.60257| val_0_mse: 3022.79931640625|  0:00:01s\n","epoch 2  | loss: 264.96647| val_0_mse: 4123.359375|  0:00:02s\n","epoch 3  | loss: 179.28817| val_0_mse: 2811.11865234375|  0:00:02s\n","epoch 4  | loss: 161.7482| val_0_mse: 2782.40380859375|  0:00:03s\n","epoch 5  | loss: 124.38765| val_0_mse: 2682.129150390625|  0:00:04s\n","epoch 6  | loss: 117.3534| val_0_mse: 3095.21435546875|  0:00:04s\n","epoch 7  | loss: 117.12048| val_0_mse: 3167.88134765625|  0:00:05s\n","epoch 8  | loss: 96.15174| val_0_mse: 2908.537353515625|  0:00:06s\n","epoch 9  | loss: 90.72146| val_0_mse: 2636.2177734375|  0:00:06s\n","epoch 10 | loss: 78.90146| val_0_mse: 2637.632080078125|  0:00:07s\n","epoch 11 | loss: 86.17055| val_0_mse: 2622.66357421875|  0:00:08s\n","epoch 12 | loss: 85.65516| val_0_mse: 2718.029541015625|  0:00:09s\n","epoch 13 | loss: 82.00034| val_0_mse: 2635.87646484375|  0:00:09s\n","epoch 14 | loss: 70.05348| val_0_mse: 2598.56689453125|  0:00:10s\n","epoch 15 | loss: 62.78027| val_0_mse: 2299.10400390625|  0:00:11s\n","epoch 16 | loss: 68.57499| val_0_mse: 2436.255126953125|  0:00:11s\n","epoch 17 | loss: 66.84565| val_0_mse: 1981.404296875|  0:00:12s\n","epoch 18 | loss: 64.8071 | val_0_mse: 2035.0938720703125|  0:00:13s\n","epoch 19 | loss: 57.44554| val_0_mse: 1873.7545166015625|  0:00:13s\n","epoch 20 | loss: 57.11154| val_0_mse: 1480.5338134765625|  0:00:14s\n","epoch 21 | loss: 65.19143| val_0_mse: 1219.042236328125|  0:00:15s\n","epoch 22 | loss: 66.45814| val_0_mse: 1094.1600341796875|  0:00:16s\n","epoch 23 | loss: 71.31988| val_0_mse: 890.8995971679688|  0:00:16s\n","epoch 24 | loss: 63.97378| val_0_mse: 992.6056518554688|  0:00:17s\n","epoch 25 | loss: 71.52123| val_0_mse: 552.1788940429688|  0:00:18s\n","epoch 26 | loss: 71.65956| val_0_mse: 488.52484130859375|  0:00:19s\n","epoch 27 | loss: 56.80744| val_0_mse: 395.0120544433594|  0:00:19s\n","epoch 28 | loss: 50.70532| val_0_mse: 399.7239685058594|  0:00:20s\n","epoch 29 | loss: 67.77659| val_0_mse: 348.9659118652344|  0:00:21s\n","epoch 30 | loss: 55.53065| val_0_mse: 252.4407958984375|  0:00:22s\n","epoch 31 | loss: 56.24963| val_0_mse: 192.14332580566406|  0:00:22s\n","epoch 32 | loss: 44.49876| val_0_mse: 217.26980590820312|  0:00:23s\n","epoch 33 | loss: 50.51845| val_0_mse: 154.71798706054688|  0:00:24s\n","epoch 34 | loss: 52.22134| val_0_mse: 229.69346618652344|  0:00:24s\n","epoch 35 | loss: 39.95571| val_0_mse: 175.37957763671875|  0:00:25s\n","epoch 36 | loss: 49.5056 | val_0_mse: 131.4604949951172|  0:00:26s\n","epoch 37 | loss: 39.96968| val_0_mse: 124.13851928710938|  0:00:27s\n","epoch 38 | loss: 47.05004| val_0_mse: 115.44300079345703|  0:00:27s\n","epoch 39 | loss: 63.36972| val_0_mse: 135.9121856689453|  0:00:28s\n","epoch 40 | loss: 63.8024 | val_0_mse: 63.1821403503418|  0:00:29s\n","epoch 41 | loss: 59.80435| val_0_mse: 89.79170989990234|  0:00:30s\n","epoch 42 | loss: 55.59809| val_0_mse: 77.49832153320312|  0:00:30s\n","epoch 43 | loss: 52.54693| val_0_mse: 52.922420501708984|  0:00:31s\n","epoch 44 | loss: 46.69251| val_0_mse: 44.76940155029297|  0:00:32s\n","epoch 45 | loss: 44.94658| val_0_mse: 46.85457992553711|  0:00:32s\n","epoch 46 | loss: 44.20052| val_0_mse: 38.30445861816406|  0:00:33s\n","epoch 47 | loss: 51.25234| val_0_mse: 55.75577163696289|  0:00:34s\n","epoch 48 | loss: 48.27535| val_0_mse: 47.15153884887695|  0:00:34s\n","epoch 49 | loss: 40.19647| val_0_mse: 62.53316116333008|  0:00:35s\n","epoch 50 | loss: 46.32532| val_0_mse: 61.36383819580078|  0:00:36s\n","epoch 51 | loss: 40.80968| val_0_mse: 53.30418014526367|  0:00:37s\n","epoch 52 | loss: 45.82274| val_0_mse: 35.37894821166992|  0:00:37s\n","epoch 53 | loss: 36.02656| val_0_mse: 29.909549713134766|  0:00:38s\n","epoch 54 | loss: 49.42545| val_0_mse: 48.67644119262695|  0:00:39s\n","epoch 55 | loss: 36.82034| val_0_mse: 28.762399673461914|  0:00:39s\n","epoch 56 | loss: 37.45343| val_0_mse: 24.381389617919922|  0:00:40s\n","epoch 57 | loss: 37.66306| val_0_mse: 27.927480697631836|  0:00:41s\n","epoch 58 | loss: 29.78195| val_0_mse: 20.63357925415039|  0:00:41s\n","epoch 59 | loss: 28.38713| val_0_mse: 29.289630889892578|  0:00:42s\n","epoch 60 | loss: 36.8244 | val_0_mse: 31.36471939086914|  0:00:43s\n","epoch 61 | loss: 43.69009| val_0_mse: 39.84061813354492|  0:00:44s\n","epoch 62 | loss: 43.40476| val_0_mse: 30.57073974609375|  0:00:44s\n","epoch 63 | loss: 27.93485| val_0_mse: 20.820819854736328|  0:00:45s\n","epoch 64 | loss: 43.92898| val_0_mse: 53.65943908691406|  0:00:46s\n","epoch 65 | loss: 56.71575| val_0_mse: 66.26901245117188|  0:00:46s\n","epoch 66 | loss: 46.6879 | val_0_mse: 74.9468994140625|  0:00:47s\n","epoch 67 | loss: 53.06004| val_0_mse: 44.0177001953125|  0:00:48s\n","epoch 68 | loss: 35.26947| val_0_mse: 29.721960067749023|  0:00:48s\n","\n","Early stopping occurred at epoch 68 with best_epoch = 58 and best_val_0_mse = 20.63357925415039\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 13:53:29,594] Trial 91 finished with value: 20.633583068847656 and parameters: {'n_d': 42, 'n_steps': 3, 'gamma': 1.2709448650964092, 'n_independent': 3, 'n_shared': 5, 'momentum': 0.26472514453059726}. Best is trial 39 with value: 14.34697437286377.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 2056.49288| val_0_mse: 2616.081787109375|  0:00:00s\n","epoch 1  | loss: 726.06116| val_0_mse: 3635.099609375|  0:00:01s\n","epoch 2  | loss: 287.84348| val_0_mse: 3383.06005859375|  0:00:02s\n","epoch 3  | loss: 230.56258| val_0_mse: 2877.529296875|  0:00:02s\n","epoch 4  | loss: 210.03911| val_0_mse: 2622.85693359375|  0:00:03s\n","epoch 5  | loss: 219.37562| val_0_mse: 2847.573974609375|  0:00:03s\n","epoch 6  | loss: 187.59511| val_0_mse: 2681.303955078125|  0:00:04s\n","epoch 7  | loss: 176.41703| val_0_mse: 2621.441650390625|  0:00:05s\n","epoch 8  | loss: 149.96063| val_0_mse: 2514.0146484375|  0:00:05s\n","epoch 9  | loss: 142.81563| val_0_mse: 2689.98486328125|  0:00:06s\n","epoch 10 | loss: 135.7014| val_0_mse: 2630.843017578125|  0:00:07s\n","epoch 11 | loss: 116.64666| val_0_mse: 2722.431884765625|  0:00:07s\n","epoch 12 | loss: 113.63377| val_0_mse: 2554.7646484375|  0:00:08s\n","epoch 13 | loss: 107.18989| val_0_mse: 2594.408447265625|  0:00:08s\n","epoch 14 | loss: 94.4022 | val_0_mse: 2511.641357421875|  0:00:09s\n","epoch 15 | loss: 103.48059| val_0_mse: 2563.807373046875|  0:00:10s\n","epoch 16 | loss: 107.58041| val_0_mse: 2425.142822265625|  0:00:10s\n","epoch 17 | loss: 75.28168| val_0_mse: 2402.2333984375|  0:00:11s\n","epoch 18 | loss: 75.6173 | val_0_mse: 2123.2109375|  0:00:12s\n","epoch 19 | loss: 67.19399| val_0_mse: 1959.82666015625|  0:00:12s\n","epoch 20 | loss: 75.56646| val_0_mse: 1549.61962890625|  0:00:13s\n","epoch 21 | loss: 79.4385 | val_0_mse: 1347.40478515625|  0:00:14s\n","epoch 22 | loss: 62.15653| val_0_mse: 926.6506958007812|  0:00:14s\n","epoch 23 | loss: 59.30904| val_0_mse: 1144.38134765625|  0:00:15s\n","epoch 24 | loss: 64.25564| val_0_mse: 1077.859619140625|  0:00:16s\n","epoch 25 | loss: 54.39276| val_0_mse: 477.80084228515625|  0:00:16s\n","epoch 26 | loss: 61.40826| val_0_mse: 575.1702270507812|  0:00:17s\n","epoch 27 | loss: 54.33593| val_0_mse: 391.5556945800781|  0:00:17s\n","epoch 28 | loss: 61.94539| val_0_mse: 467.3000793457031|  0:00:18s\n","epoch 29 | loss: 50.68143| val_0_mse: 293.1325988769531|  0:00:19s\n","epoch 30 | loss: 64.23013| val_0_mse: 262.2982177734375|  0:00:19s\n","epoch 31 | loss: 52.18597| val_0_mse: 155.8328094482422|  0:00:20s\n","epoch 32 | loss: 54.7476 | val_0_mse: 146.53652954101562|  0:00:21s\n","epoch 33 | loss: 48.05858| val_0_mse: 122.55962371826172|  0:00:21s\n","epoch 34 | loss: 57.12418| val_0_mse: 169.96116638183594|  0:00:22s\n","epoch 35 | loss: 48.30591| val_0_mse: 94.6474609375|  0:00:23s\n","epoch 36 | loss: 53.86184| val_0_mse: 116.54741668701172|  0:00:23s\n","epoch 37 | loss: 59.73202| val_0_mse: 123.15773010253906|  0:00:24s\n","epoch 38 | loss: 52.00623| val_0_mse: 80.5791015625|  0:00:25s\n","epoch 39 | loss: 53.19248| val_0_mse: 74.8751220703125|  0:00:25s\n","epoch 40 | loss: 55.36541| val_0_mse: 45.03496170043945|  0:00:26s\n","epoch 41 | loss: 57.25551| val_0_mse: 72.24262237548828|  0:00:27s\n","epoch 42 | loss: 40.42683| val_0_mse: 45.682159423828125|  0:00:27s\n","epoch 43 | loss: 43.47155| val_0_mse: 66.31607818603516|  0:00:28s\n","epoch 44 | loss: 45.44862| val_0_mse: 47.531890869140625|  0:00:29s\n","epoch 45 | loss: 48.50746| val_0_mse: 98.63043975830078|  0:00:29s\n","epoch 46 | loss: 50.15145| val_0_mse: 33.665218353271484|  0:00:30s\n","epoch 47 | loss: 47.15069| val_0_mse: 30.52985954284668|  0:00:31s\n","epoch 48 | loss: 49.23771| val_0_mse: 59.146419525146484|  0:00:31s\n","epoch 49 | loss: 46.06843| val_0_mse: 27.28190040588379|  0:00:32s\n","epoch 50 | loss: 45.30613| val_0_mse: 30.017810821533203|  0:00:32s\n","epoch 51 | loss: 48.9964 | val_0_mse: 67.28153991699219|  0:00:33s\n","epoch 52 | loss: 54.40882| val_0_mse: 35.718589782714844|  0:00:34s\n","epoch 53 | loss: 44.63051| val_0_mse: 27.881019592285156|  0:00:34s\n","epoch 54 | loss: 41.27903| val_0_mse: 31.583690643310547|  0:00:35s\n","epoch 55 | loss: 38.71972| val_0_mse: 35.322669982910156|  0:00:36s\n","epoch 56 | loss: 39.79311| val_0_mse: 34.705928802490234|  0:00:36s\n","epoch 57 | loss: 35.58983| val_0_mse: 21.251949310302734|  0:00:37s\n","epoch 58 | loss: 39.0974 | val_0_mse: 18.26721954345703|  0:00:38s\n","epoch 59 | loss: 42.31984| val_0_mse: 19.24534034729004|  0:00:38s\n","epoch 60 | loss: 48.55729| val_0_mse: 25.22587013244629|  0:00:39s\n","epoch 61 | loss: 34.68804| val_0_mse: 33.13526153564453|  0:00:40s\n","epoch 62 | loss: 41.69798| val_0_mse: 32.633060455322266|  0:00:40s\n","epoch 63 | loss: 49.98398| val_0_mse: 59.68259811401367|  0:00:41s\n","epoch 64 | loss: 47.14913| val_0_mse: 29.391300201416016|  0:00:41s\n","epoch 65 | loss: 75.55869| val_0_mse: 24.597909927368164|  0:00:42s\n","epoch 66 | loss: 37.40605| val_0_mse: 18.83926010131836|  0:00:43s\n","epoch 67 | loss: 37.18705| val_0_mse: 37.85675048828125|  0:00:43s\n","epoch 68 | loss: 43.01024| val_0_mse: 37.00371170043945|  0:00:44s\n","\n","Early stopping occurred at epoch 68 with best_epoch = 58 and best_val_0_mse = 18.26721954345703\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 13:54:14,490] Trial 92 finished with value: 18.267223358154297 and parameters: {'n_d': 48, 'n_steps': 3, 'gamma': 1.5067918654381336, 'n_independent': 3, 'n_shared': 4, 'momentum': 0.22738606993450045}. Best is trial 39 with value: 14.34697437286377.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 2260.34387| val_0_mse: 3508.4287109375|  0:00:00s\n","epoch 1  | loss: 1122.82971| val_0_mse: 2721.949462890625|  0:00:01s\n","epoch 2  | loss: 440.75794| val_0_mse: 3246.9990234375|  0:00:02s\n","epoch 3  | loss: 299.24996| val_0_mse: 2814.27001953125|  0:00:02s\n","epoch 4  | loss: 219.37489| val_0_mse: 3574.132080078125|  0:00:03s\n","epoch 5  | loss: 191.41237| val_0_mse: 2922.290771484375|  0:00:04s\n","epoch 6  | loss: 170.29587| val_0_mse: 2673.700439453125|  0:00:05s\n","epoch 7  | loss: 127.06295| val_0_mse: 2835.544677734375|  0:00:05s\n","epoch 8  | loss: 168.69576| val_0_mse: 2823.145263671875|  0:00:06s\n","epoch 9  | loss: 138.1767| val_0_mse: 2727.939453125|  0:00:07s\n","epoch 10 | loss: 109.88869| val_0_mse: 2643.186279296875|  0:00:07s\n","epoch 11 | loss: 97.6967 | val_0_mse: 2608.695556640625|  0:00:08s\n","epoch 12 | loss: 91.8881 | val_0_mse: 2686.44580078125|  0:00:09s\n","epoch 13 | loss: 76.36402| val_0_mse: 2586.674072265625|  0:00:09s\n","epoch 14 | loss: 92.32205| val_0_mse: 2547.253662109375|  0:00:10s\n","epoch 15 | loss: 97.68559| val_0_mse: 2446.406494140625|  0:00:11s\n","epoch 16 | loss: 100.1882| val_0_mse: 2428.649169921875|  0:00:12s\n","epoch 17 | loss: 89.77303| val_0_mse: 2162.20556640625|  0:00:12s\n","epoch 18 | loss: 80.86023| val_0_mse: 2029.4232177734375|  0:00:13s\n","epoch 19 | loss: 71.48602| val_0_mse: 1773.37109375|  0:00:14s\n","epoch 20 | loss: 88.84562| val_0_mse: 1027.0550537109375|  0:00:15s\n","epoch 21 | loss: 89.37934| val_0_mse: 1031.3590087890625|  0:00:15s\n","epoch 22 | loss: 77.02198| val_0_mse: 954.1073608398438|  0:00:16s\n","epoch 23 | loss: 80.19945| val_0_mse: 944.0418701171875|  0:00:17s\n","epoch 24 | loss: 67.74098| val_0_mse: 700.2509765625|  0:00:17s\n","epoch 25 | loss: 104.28799| val_0_mse: 754.79541015625|  0:00:18s\n","epoch 26 | loss: 75.40023| val_0_mse: 737.1043701171875|  0:00:19s\n","epoch 27 | loss: 84.62311| val_0_mse: 422.52862548828125|  0:00:20s\n","epoch 28 | loss: 68.2617 | val_0_mse: 350.93255615234375|  0:00:20s\n","epoch 29 | loss: 76.38907| val_0_mse: 413.59490966796875|  0:00:21s\n","epoch 30 | loss: 79.12704| val_0_mse: 203.23654174804688|  0:00:22s\n","epoch 31 | loss: 82.42351| val_0_mse: 264.79119873046875|  0:00:22s\n","epoch 32 | loss: 71.13143| val_0_mse: 185.13926696777344|  0:00:23s\n","epoch 33 | loss: 71.88621| val_0_mse: 271.6086120605469|  0:00:24s\n","epoch 34 | loss: 76.97332| val_0_mse: 134.7734832763672|  0:00:24s\n","epoch 35 | loss: 64.2499 | val_0_mse: 145.76327514648438|  0:00:25s\n","epoch 36 | loss: 60.93022| val_0_mse: 84.9648666381836|  0:00:26s\n","epoch 37 | loss: 68.46169| val_0_mse: 122.70086669921875|  0:00:27s\n","epoch 38 | loss: 71.15161| val_0_mse: 156.86097717285156|  0:00:27s\n","epoch 39 | loss: 73.05222| val_0_mse: 71.78721618652344|  0:00:28s\n","epoch 40 | loss: 72.44041| val_0_mse: 71.84928894042969|  0:00:29s\n","epoch 41 | loss: 60.75061| val_0_mse: 82.75077819824219|  0:00:29s\n","epoch 42 | loss: 68.36334| val_0_mse: 83.71727752685547|  0:00:30s\n","epoch 43 | loss: 69.75937| val_0_mse: 58.16432189941406|  0:00:31s\n","epoch 44 | loss: 58.3411 | val_0_mse: 60.630218505859375|  0:00:31s\n","epoch 45 | loss: 58.37022| val_0_mse: 55.975040435791016|  0:00:32s\n","epoch 46 | loss: 64.88864| val_0_mse: 92.9495620727539|  0:00:33s\n","epoch 47 | loss: 62.44056| val_0_mse: 54.422550201416016|  0:00:33s\n","epoch 48 | loss: 55.06147| val_0_mse: 83.45977783203125|  0:00:34s\n","epoch 49 | loss: 58.07056| val_0_mse: 52.724918365478516|  0:00:35s\n","epoch 50 | loss: 81.48203| val_0_mse: 81.89652252197266|  0:00:36s\n","epoch 51 | loss: 60.66664| val_0_mse: 71.87037658691406|  0:00:36s\n","epoch 52 | loss: 54.34706| val_0_mse: 27.66366958618164|  0:00:37s\n","epoch 53 | loss: 56.87032| val_0_mse: 36.36668014526367|  0:00:38s\n","epoch 54 | loss: 55.45612| val_0_mse: 28.429079055786133|  0:00:38s\n","epoch 55 | loss: 54.06392| val_0_mse: 24.092859268188477|  0:00:39s\n","epoch 56 | loss: 48.32449| val_0_mse: 23.372560501098633|  0:00:40s\n","epoch 57 | loss: 55.94275| val_0_mse: 22.400020599365234|  0:00:41s\n","epoch 58 | loss: 51.27288| val_0_mse: 38.612178802490234|  0:00:42s\n","epoch 59 | loss: 70.52284| val_0_mse: 26.496320724487305|  0:00:42s\n","epoch 60 | loss: 48.78525| val_0_mse: 26.570730209350586|  0:00:43s\n","epoch 61 | loss: 50.36809| val_0_mse: 38.83749008178711|  0:00:44s\n","epoch 62 | loss: 48.72752| val_0_mse: 22.445619583129883|  0:00:44s\n","epoch 63 | loss: 59.99643| val_0_mse: 35.45798873901367|  0:00:45s\n","epoch 64 | loss: 49.00445| val_0_mse: 32.77336883544922|  0:00:46s\n","epoch 65 | loss: 60.02703| val_0_mse: 77.26850891113281|  0:00:46s\n","epoch 66 | loss: 68.39677| val_0_mse: 31.56492042541504|  0:00:47s\n","epoch 67 | loss: 45.06582| val_0_mse: 30.213449478149414|  0:00:48s\n","\n","Early stopping occurred at epoch 67 with best_epoch = 57 and best_val_0_mse = 22.400020599365234\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 13:55:03,206] Trial 93 finished with value: 22.400022506713867 and parameters: {'n_d': 48, 'n_steps': 3, 'gamma': 1.5499965563339149, 'n_independent': 3, 'n_shared': 5, 'momentum': 0.2804149713142982}. Best is trial 39 with value: 14.34697437286377.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 2389.27162| val_0_mse: 4664.2255859375|  0:00:00s\n","epoch 1  | loss: 1691.65976| val_0_mse: 3678.922607421875|  0:00:01s\n","epoch 2  | loss: 867.20367| val_0_mse: 2175.811279296875|  0:00:02s\n","epoch 3  | loss: 505.46828| val_0_mse: 2210.205322265625|  0:00:02s\n","epoch 4  | loss: 316.60043| val_0_mse: 2290.6845703125|  0:00:03s\n","epoch 5  | loss: 262.12025| val_0_mse: 2377.266845703125|  0:00:04s\n","epoch 6  | loss: 239.3408| val_0_mse: 2367.133544921875|  0:00:04s\n","epoch 7  | loss: 201.41125| val_0_mse: 2406.44140625|  0:00:05s\n","epoch 8  | loss: 197.72609| val_0_mse: 2601.1796875|  0:00:06s\n","epoch 9  | loss: 179.24933| val_0_mse: 2469.695556640625|  0:00:06s\n","epoch 10 | loss: 175.38992| val_0_mse: 2535.580078125|  0:00:07s\n","epoch 11 | loss: 158.11384| val_0_mse: 2431.964599609375|  0:00:08s\n","epoch 12 | loss: 135.58352| val_0_mse: 2553.81689453125|  0:00:08s\n","\n","Early stopping occurred at epoch 12 with best_epoch = 2 and best_val_0_mse = 2175.811279296875\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 13:55:12,603] Trial 94 finished with value: 2175.811279296875 and parameters: {'n_d': 21, 'n_steps': 4, 'gamma': 1.5123408040019766, 'n_independent': 3, 'n_shared': 3, 'momentum': 0.24926340585915974}. Best is trial 39 with value: 14.34697437286377.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 2236.63532| val_0_mse: 37987.96875|  0:00:00s\n","epoch 1  | loss: 1379.03292| val_0_mse: 5588.23876953125|  0:00:01s\n","epoch 2  | loss: 787.25305| val_0_mse: 5578.22021484375|  0:00:02s\n","epoch 3  | loss: 474.77138| val_0_mse: 3962.983642578125|  0:00:03s\n","epoch 4  | loss: 331.11269| val_0_mse: 3461.048583984375|  0:00:04s\n","epoch 5  | loss: 284.31589| val_0_mse: 3279.15966796875|  0:00:05s\n","epoch 6  | loss: 232.81322| val_0_mse: 2998.696533203125|  0:00:05s\n","epoch 7  | loss: 218.53715| val_0_mse: 2947.31396484375|  0:00:06s\n","epoch 8  | loss: 222.71064| val_0_mse: 2833.738037109375|  0:00:07s\n","epoch 9  | loss: 230.1195| val_0_mse: 2771.04345703125|  0:00:08s\n","epoch 10 | loss: 179.77226| val_0_mse: 2658.76611328125|  0:00:09s\n","epoch 11 | loss: 179.73073| val_0_mse: 2287.482421875|  0:00:10s\n","epoch 12 | loss: 153.71604| val_0_mse: 2531.23828125|  0:00:10s\n","epoch 13 | loss: 150.44365| val_0_mse: 2292.881591796875|  0:00:11s\n","epoch 14 | loss: 145.77939| val_0_mse: 2340.6572265625|  0:00:12s\n","epoch 15 | loss: 126.90063| val_0_mse: 2058.687744140625|  0:00:13s\n","epoch 16 | loss: 138.87243| val_0_mse: 1817.5989990234375|  0:00:14s\n","epoch 17 | loss: 114.53887| val_0_mse: 1746.93115234375|  0:00:15s\n","epoch 18 | loss: 124.18987| val_0_mse: 1464.940673828125|  0:00:16s\n","epoch 19 | loss: 107.18855| val_0_mse: 1347.611572265625|  0:00:16s\n","epoch 20 | loss: 97.61554| val_0_mse: 1214.4969482421875|  0:00:17s\n","epoch 21 | loss: 96.17014| val_0_mse: 956.9771728515625|  0:00:18s\n","epoch 22 | loss: 97.29851| val_0_mse: 720.7093505859375|  0:00:19s\n","epoch 23 | loss: 92.63716| val_0_mse: 641.4051513671875|  0:00:20s\n","epoch 24 | loss: 79.25981| val_0_mse: 561.9177856445312|  0:00:21s\n","epoch 25 | loss: 81.53341| val_0_mse: 562.1104125976562|  0:00:22s\n","epoch 26 | loss: 93.30752| val_0_mse: 528.736328125|  0:00:22s\n","epoch 27 | loss: 66.68713| val_0_mse: 407.901123046875|  0:00:23s\n","epoch 28 | loss: 69.91643| val_0_mse: 347.5459899902344|  0:00:24s\n","epoch 29 | loss: 75.27462| val_0_mse: 431.7702941894531|  0:00:25s\n","epoch 30 | loss: 62.30148| val_0_mse: 276.1924133300781|  0:00:26s\n","epoch 31 | loss: 70.28841| val_0_mse: 214.78439331054688|  0:00:27s\n","epoch 32 | loss: 65.20304| val_0_mse: 150.99208068847656|  0:00:27s\n","epoch 33 | loss: 74.93194| val_0_mse: 160.4436492919922|  0:00:28s\n","epoch 34 | loss: 60.65601| val_0_mse: 141.67691040039062|  0:00:29s\n","epoch 35 | loss: 67.24635| val_0_mse: 119.75739288330078|  0:00:30s\n","epoch 36 | loss: 61.24109| val_0_mse: 117.29857635498047|  0:00:31s\n","epoch 37 | loss: 60.25764| val_0_mse: 94.75908660888672|  0:00:32s\n","epoch 38 | loss: 81.42178| val_0_mse: 111.86772918701172|  0:00:32s\n","epoch 39 | loss: 61.1736 | val_0_mse: 95.88506317138672|  0:00:33s\n","epoch 40 | loss: 67.72998| val_0_mse: 76.10008239746094|  0:00:34s\n","epoch 41 | loss: 68.26293| val_0_mse: 44.827178955078125|  0:00:35s\n","epoch 42 | loss: 63.44058| val_0_mse: 79.14473724365234|  0:00:36s\n","epoch 43 | loss: 55.578  | val_0_mse: 71.64600372314453|  0:00:37s\n","epoch 44 | loss: 56.56657| val_0_mse: 49.17974853515625|  0:00:37s\n","epoch 45 | loss: 52.67639| val_0_mse: 76.14830017089844|  0:00:38s\n","epoch 46 | loss: 56.00899| val_0_mse: 44.18907928466797|  0:00:39s\n","epoch 47 | loss: 54.25301| val_0_mse: 43.89424133300781|  0:00:40s\n","epoch 48 | loss: 64.64465| val_0_mse: 43.55120086669922|  0:00:41s\n","epoch 49 | loss: 44.85267| val_0_mse: 38.573570251464844|  0:00:42s\n","epoch 50 | loss: 44.75509| val_0_mse: 46.487308502197266|  0:00:42s\n","epoch 51 | loss: 54.85783| val_0_mse: 34.369239807128906|  0:00:43s\n","epoch 52 | loss: 49.9948 | val_0_mse: 43.754520416259766|  0:00:44s\n","epoch 53 | loss: 40.3489 | val_0_mse: 47.50088119506836|  0:00:45s\n","epoch 54 | loss: 50.7874 | val_0_mse: 40.97319030761719|  0:00:46s\n","epoch 55 | loss: 45.8064 | val_0_mse: 30.581819534301758|  0:00:47s\n","epoch 56 | loss: 39.38284| val_0_mse: 24.281219482421875|  0:00:48s\n","epoch 57 | loss: 36.13891| val_0_mse: 26.755329132080078|  0:00:48s\n","epoch 58 | loss: 40.30672| val_0_mse: 25.84103012084961|  0:00:49s\n","epoch 59 | loss: 47.83844| val_0_mse: 38.77693176269531|  0:00:50s\n","epoch 60 | loss: 60.85771| val_0_mse: 62.15510177612305|  0:00:51s\n","epoch 61 | loss: 55.65181| val_0_mse: 36.65959930419922|  0:00:52s\n","epoch 62 | loss: 50.11967| val_0_mse: 39.25175094604492|  0:00:53s\n","epoch 63 | loss: 69.87021| val_0_mse: 38.91223907470703|  0:00:53s\n","epoch 64 | loss: 40.4609 | val_0_mse: 33.75539016723633|  0:00:54s\n","epoch 65 | loss: 43.9029 | val_0_mse: 26.447399139404297|  0:00:55s\n","epoch 66 | loss: 37.83139| val_0_mse: 39.06135940551758|  0:00:56s\n","\n","Early stopping occurred at epoch 66 with best_epoch = 56 and best_val_0_mse = 24.281219482421875\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 13:56:09,422] Trial 95 finished with value: 24.28122329711914 and parameters: {'n_d': 46, 'n_steps': 5, 'gamma': 1.166077907076637, 'n_independent': 2, 'n_shared': 4, 'momentum': 0.23229457644611476}. Best is trial 39 with value: 14.34697437286377.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 2119.54441| val_0_mse: 2828.198486328125|  0:00:00s\n","epoch 1  | loss: 682.4071| val_0_mse: 3022.912109375|  0:00:01s\n","epoch 2  | loss: 327.82704| val_0_mse: 7550.896484375|  0:00:01s\n","epoch 3  | loss: 254.51128| val_0_mse: 2720.879150390625|  0:00:02s\n","epoch 4  | loss: 193.75368| val_0_mse: 2772.2099609375|  0:00:03s\n","epoch 5  | loss: 181.44157| val_0_mse: 2727.634765625|  0:00:03s\n","epoch 6  | loss: 146.54778| val_0_mse: 3016.50390625|  0:00:04s\n","epoch 7  | loss: 131.96057| val_0_mse: 2673.434814453125|  0:00:05s\n","epoch 8  | loss: 141.22945| val_0_mse: 2816.8330078125|  0:00:05s\n","epoch 9  | loss: 133.79315| val_0_mse: 2516.71337890625|  0:00:06s\n","epoch 10 | loss: 115.51426| val_0_mse: 2586.525390625|  0:00:07s\n","epoch 11 | loss: 106.04451| val_0_mse: 2609.728271484375|  0:00:07s\n","epoch 12 | loss: 98.10671| val_0_mse: 2442.010009765625|  0:00:08s\n","epoch 13 | loss: 84.91994| val_0_mse: 2642.937255859375|  0:00:09s\n","epoch 14 | loss: 119.04953| val_0_mse: 2361.578125|  0:00:09s\n","epoch 15 | loss: 104.81672| val_0_mse: 2353.568603515625|  0:00:10s\n","epoch 16 | loss: 89.68056| val_0_mse: 2362.2490234375|  0:00:11s\n","epoch 17 | loss: 74.3538 | val_0_mse: 2361.2265625|  0:00:11s\n","epoch 18 | loss: 79.1337 | val_0_mse: 2477.939208984375|  0:00:12s\n","epoch 19 | loss: 68.07948| val_0_mse: 2043.84228515625|  0:00:13s\n","epoch 20 | loss: 71.36401| val_0_mse: 1655.66845703125|  0:00:13s\n","epoch 21 | loss: 69.62369| val_0_mse: 1438.025390625|  0:00:14s\n","epoch 22 | loss: 63.9935 | val_0_mse: 1214.71142578125|  0:00:15s\n","epoch 23 | loss: 65.86902| val_0_mse: 918.0801391601562|  0:00:15s\n","epoch 24 | loss: 67.89035| val_0_mse: 884.822021484375|  0:00:16s\n","epoch 25 | loss: 68.04909| val_0_mse: 772.6920166015625|  0:00:17s\n","epoch 26 | loss: 56.62243| val_0_mse: 683.6941528320312|  0:00:17s\n","epoch 27 | loss: 76.72932| val_0_mse: 607.210693359375|  0:00:18s\n","epoch 28 | loss: 71.7309 | val_0_mse: 517.5122680664062|  0:00:19s\n","epoch 29 | loss: 51.20705| val_0_mse: 337.67352294921875|  0:00:19s\n","epoch 30 | loss: 57.37739| val_0_mse: 361.12469482421875|  0:00:20s\n","epoch 31 | loss: 51.58133| val_0_mse: 314.2333068847656|  0:00:21s\n","epoch 32 | loss: 56.97229| val_0_mse: 263.69012451171875|  0:00:21s\n","epoch 33 | loss: 59.85205| val_0_mse: 214.8592987060547|  0:00:22s\n","epoch 34 | loss: 74.38719| val_0_mse: 262.79730224609375|  0:00:23s\n","epoch 35 | loss: 59.07433| val_0_mse: 200.88998413085938|  0:00:23s\n","epoch 36 | loss: 49.21064| val_0_mse: 186.98313903808594|  0:00:24s\n","epoch 37 | loss: 55.94336| val_0_mse: 124.44403076171875|  0:00:25s\n","epoch 38 | loss: 47.82739| val_0_mse: 86.4787368774414|  0:00:25s\n","epoch 39 | loss: 53.82515| val_0_mse: 77.72530364990234|  0:00:26s\n","epoch 40 | loss: 51.30293| val_0_mse: 112.01856994628906|  0:00:27s\n","epoch 41 | loss: 48.83513| val_0_mse: 52.62261962890625|  0:00:27s\n","epoch 42 | loss: 47.33322| val_0_mse: 91.69174194335938|  0:00:28s\n","epoch 43 | loss: 48.84039| val_0_mse: 69.20478057861328|  0:00:29s\n","epoch 44 | loss: 40.48927| val_0_mse: 52.16944122314453|  0:00:29s\n","epoch 45 | loss: 43.33692| val_0_mse: 41.04008865356445|  0:00:30s\n","epoch 46 | loss: 55.70598| val_0_mse: 67.50627899169922|  0:00:31s\n","epoch 47 | loss: 56.64089| val_0_mse: 58.626800537109375|  0:00:31s\n","epoch 48 | loss: 46.72329| val_0_mse: 38.90534973144531|  0:00:32s\n","epoch 49 | loss: 38.39484| val_0_mse: 24.726520538330078|  0:00:33s\n","epoch 50 | loss: 35.98266| val_0_mse: 25.857080459594727|  0:00:33s\n","epoch 51 | loss: 37.01939| val_0_mse: 36.54729080200195|  0:00:34s\n","epoch 52 | loss: 39.48608| val_0_mse: 36.82693862915039|  0:00:34s\n","epoch 53 | loss: 40.69064| val_0_mse: 26.86743927001953|  0:00:35s\n","epoch 54 | loss: 54.74006| val_0_mse: 32.28221893310547|  0:00:36s\n","epoch 55 | loss: 43.90723| val_0_mse: 26.38079071044922|  0:00:37s\n","epoch 56 | loss: 35.61644| val_0_mse: 36.51810073852539|  0:00:37s\n","epoch 57 | loss: 54.43345| val_0_mse: 48.84672164916992|  0:00:38s\n","epoch 58 | loss: 55.60885| val_0_mse: 36.75971984863281|  0:00:38s\n","epoch 59 | loss: 43.63925| val_0_mse: 40.73046875|  0:00:39s\n","\n","Early stopping occurred at epoch 59 with best_epoch = 49 and best_val_0_mse = 24.726520538330078\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 13:56:49,371] Trial 96 finished with value: 24.72651481628418 and parameters: {'n_d': 56, 'n_steps': 3, 'gamma': 1.483443628880556, 'n_independent': 3, 'n_shared': 4, 'momentum': 0.05967636175346422}. Best is trial 39 with value: 14.34697437286377.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 2135.90313| val_0_mse: 2985.545654296875|  0:00:00s\n","epoch 1  | loss: 1039.76788| val_0_mse: 9844.240234375|  0:00:01s\n","epoch 2  | loss: 560.10408| val_0_mse: 6772.98193359375|  0:00:02s\n","epoch 3  | loss: 386.88459| val_0_mse: 3573.53076171875|  0:00:03s\n","epoch 4  | loss: 336.63205| val_0_mse: 3532.601806640625|  0:00:04s\n","epoch 5  | loss: 300.06675| val_0_mse: 2575.510986328125|  0:00:05s\n","epoch 6  | loss: 258.93574| val_0_mse: 2866.352294921875|  0:00:06s\n","epoch 7  | loss: 231.0749| val_0_mse: 2478.606689453125|  0:00:06s\n","epoch 8  | loss: 235.65404| val_0_mse: 2517.367919921875|  0:00:08s\n","epoch 9  | loss: 193.88852| val_0_mse: 2500.343017578125|  0:00:08s\n","epoch 10 | loss: 183.42459| val_0_mse: 2788.14794921875|  0:00:09s\n","epoch 11 | loss: 157.28366| val_0_mse: 2815.670654296875|  0:00:10s\n","epoch 12 | loss: 166.12334| val_0_mse: 2782.722900390625|  0:00:11s\n","epoch 13 | loss: 143.24221| val_0_mse: 2687.922119140625|  0:00:12s\n","epoch 14 | loss: 127.57689| val_0_mse: 2630.937744140625|  0:00:13s\n","epoch 15 | loss: 129.64321| val_0_mse: 2531.9814453125|  0:00:14s\n","epoch 16 | loss: 113.47579| val_0_mse: 2595.3310546875|  0:00:14s\n","epoch 17 | loss: 138.40302| val_0_mse: 1784.022705078125|  0:00:15s\n","epoch 18 | loss: 113.41964| val_0_mse: 1667.808349609375|  0:00:16s\n","epoch 19 | loss: 115.63838| val_0_mse: 1486.8057861328125|  0:00:17s\n","epoch 20 | loss: 110.26998| val_0_mse: 1026.1826171875|  0:00:18s\n","epoch 21 | loss: 94.34546| val_0_mse: 909.0196533203125|  0:00:19s\n","epoch 22 | loss: 102.37699| val_0_mse: 720.9972534179688|  0:00:20s\n","epoch 23 | loss: 105.05133| val_0_mse: 725.5448608398438|  0:00:21s\n","epoch 24 | loss: 112.1476| val_0_mse: 636.5486450195312|  0:00:21s\n","epoch 25 | loss: 107.55955| val_0_mse: 409.2583312988281|  0:00:22s\n","epoch 26 | loss: 94.15917| val_0_mse: 448.44842529296875|  0:00:23s\n","epoch 27 | loss: 99.73603| val_0_mse: 436.4700012207031|  0:00:24s\n","epoch 28 | loss: 80.85689| val_0_mse: 310.39959716796875|  0:00:25s\n","epoch 29 | loss: 87.74841| val_0_mse: 236.67022705078125|  0:00:26s\n","epoch 30 | loss: 80.20582| val_0_mse: 205.99131774902344|  0:00:27s\n","epoch 31 | loss: 85.95169| val_0_mse: 163.10243225097656|  0:00:28s\n","epoch 32 | loss: 79.99787| val_0_mse: 138.0859375|  0:00:28s\n","epoch 33 | loss: 87.45726| val_0_mse: 213.89642333984375|  0:00:29s\n","epoch 34 | loss: 117.11704| val_0_mse: 99.2509536743164|  0:00:30s\n","epoch 35 | loss: 78.47497| val_0_mse: 124.9030532836914|  0:00:31s\n","epoch 36 | loss: 71.51071| val_0_mse: 93.83616638183594|  0:00:32s\n","epoch 37 | loss: 57.27648| val_0_mse: 153.06150817871094|  0:00:33s\n","epoch 38 | loss: 81.65223| val_0_mse: 108.39179229736328|  0:00:34s\n","epoch 39 | loss: 72.94549| val_0_mse: 49.375831604003906|  0:00:35s\n","epoch 40 | loss: 66.14033| val_0_mse: 75.96080017089844|  0:00:35s\n","epoch 41 | loss: 67.64033| val_0_mse: 60.169960021972656|  0:00:36s\n","epoch 42 | loss: 70.08547| val_0_mse: 56.32228088378906|  0:00:37s\n","epoch 43 | loss: 54.36835| val_0_mse: 47.18347930908203|  0:00:38s\n","epoch 44 | loss: 63.12935| val_0_mse: 40.80535888671875|  0:00:39s\n","epoch 45 | loss: 63.14325| val_0_mse: 52.376739501953125|  0:00:40s\n","epoch 46 | loss: 64.01167| val_0_mse: 58.47085189819336|  0:00:41s\n","epoch 47 | loss: 68.71595| val_0_mse: 37.64487075805664|  0:00:41s\n","epoch 48 | loss: 58.20374| val_0_mse: 37.12295150756836|  0:00:42s\n","epoch 49 | loss: 65.40563| val_0_mse: 30.71738052368164|  0:00:43s\n","epoch 50 | loss: 54.08703| val_0_mse: 31.847209930419922|  0:00:44s\n","epoch 51 | loss: 60.39424| val_0_mse: 51.72256851196289|  0:00:45s\n","epoch 52 | loss: 55.69407| val_0_mse: 45.943931579589844|  0:00:46s\n","epoch 53 | loss: 55.50098| val_0_mse: 29.88463020324707|  0:00:47s\n","epoch 54 | loss: 53.25447| val_0_mse: 37.211158752441406|  0:00:48s\n","epoch 55 | loss: 46.77003| val_0_mse: 28.67136001586914|  0:00:48s\n","epoch 56 | loss: 60.2003 | val_0_mse: 45.930580139160156|  0:00:49s\n","epoch 57 | loss: 63.94555| val_0_mse: 47.34843826293945|  0:00:50s\n","epoch 58 | loss: 46.49376| val_0_mse: 30.065780639648438|  0:00:51s\n","epoch 59 | loss: 52.27152| val_0_mse: 53.97148895263672|  0:00:52s\n","epoch 60 | loss: 59.24784| val_0_mse: 48.435699462890625|  0:00:53s\n","epoch 61 | loss: 52.3197 | val_0_mse: 33.95867156982422|  0:00:54s\n","epoch 62 | loss: 52.02124| val_0_mse: 31.46401023864746|  0:00:54s\n","epoch 63 | loss: 54.37602| val_0_mse: 31.29684066772461|  0:00:55s\n","epoch 64 | loss: 57.25782| val_0_mse: 42.52244186401367|  0:00:56s\n","epoch 65 | loss: 47.60204| val_0_mse: 29.077550888061523|  0:00:57s\n","\n","Early stopping occurred at epoch 65 with best_epoch = 55 and best_val_0_mse = 28.67136001586914\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 13:57:47,330] Trial 97 finished with value: 28.671354293823242 and parameters: {'n_d': 51, 'n_steps': 4, 'gamma': 1.2385356334937572, 'n_independent': 3, 'n_shared': 5, 'momentum': 0.22631359672832266}. Best is trial 39 with value: 14.34697437286377.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 2225.06999| val_0_mse: 2658.203125|  0:00:00s\n","epoch 1  | loss: 945.22685| val_0_mse: 2326.6298828125|  0:00:01s\n","epoch 2  | loss: 351.99343| val_0_mse: 2268.165283203125|  0:00:01s\n","epoch 3  | loss: 225.51049| val_0_mse: 2948.329345703125|  0:00:02s\n","epoch 4  | loss: 172.64147| val_0_mse: 2732.457275390625|  0:00:02s\n","epoch 5  | loss: 140.89996| val_0_mse: 2543.092041015625|  0:00:03s\n","epoch 6  | loss: 122.98028| val_0_mse: 2415.942626953125|  0:00:03s\n","epoch 7  | loss: 98.37435| val_0_mse: 2583.140380859375|  0:00:04s\n","epoch 8  | loss: 97.00617| val_0_mse: 2607.78369140625|  0:00:04s\n","epoch 9  | loss: 100.21636| val_0_mse: 2599.248046875|  0:00:04s\n","epoch 10 | loss: 78.82249| val_0_mse: 2595.950927734375|  0:00:05s\n","epoch 11 | loss: 70.59333| val_0_mse: 2560.33642578125|  0:00:05s\n","epoch 12 | loss: 73.80541| val_0_mse: 2597.159912109375|  0:00:06s\n","\n","Early stopping occurred at epoch 12 with best_epoch = 2 and best_val_0_mse = 2268.165283203125\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 13:57:54,149] Trial 98 finished with value: 2268.165283203125 and parameters: {'n_d': 40, 'n_steps': 3, 'gamma': 1.210031234484671, 'n_independent': 2, 'n_shared': 3, 'momentum': 0.15799125361429783}. Best is trial 39 with value: 14.34697437286377.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 2177.51114| val_0_mse: 2430.51123046875|  0:00:00s\n","epoch 1  | loss: 1102.58266| val_0_mse: 2561.916748046875|  0:00:01s\n","epoch 2  | loss: 529.99612| val_0_mse: 3228.367431640625|  0:00:01s\n","epoch 3  | loss: 318.10895| val_0_mse: 4315.43115234375|  0:00:02s\n","epoch 4  | loss: 256.75233| val_0_mse: 2681.16357421875|  0:00:02s\n","epoch 5  | loss: 228.1631| val_0_mse: 2696.953857421875|  0:00:03s\n","epoch 6  | loss: 179.64998| val_0_mse: 2771.921875|  0:00:03s\n","epoch 7  | loss: 147.96431| val_0_mse: 2733.395751953125|  0:00:04s\n","epoch 8  | loss: 129.69283| val_0_mse: 2696.010986328125|  0:00:04s\n","epoch 9  | loss: 106.63377| val_0_mse: 2632.0537109375|  0:00:05s\n","epoch 10 | loss: 99.39158| val_0_mse: 2877.688232421875|  0:00:05s\n","\n","Early stopping occurred at epoch 10 with best_epoch = 0 and best_val_0_mse = 2430.51123046875\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 13:58:00,419] Trial 99 finished with value: 2430.51123046875 and parameters: {'n_d': 48, 'n_steps': 4, 'gamma': 1.5384332915655172, 'n_independent': 2, 'n_shared': 2, 'momentum': 0.3305495904192668}. Best is trial 39 with value: 14.34697437286377.\n"]}]},{"cell_type":"code","source":["best_params"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sg7oYTivFBGe","executionInfo":{"status":"ok","timestamp":1729000680859,"user_tz":-480,"elapsed":76,"user":{"displayName":"Jonindo Pasaribu","userId":"10958990953097471082"}},"outputId":"74c95328-3e55-4e0b-c38f-112549a8a4c9"},"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'n_d': 54,\n"," 'n_steps': 5,\n"," 'gamma': 1.2681179124642246,\n"," 'n_independent': 3,\n"," 'n_shared': 5,\n"," 'momentum': 0.12173958197141824}"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["from pytorch_tabnet.callbacks import Callback\n","\n","def print_memory_usage():\n","    process = psutil.Process()\n","    mem_info = process.memory_info()\n","    print(f\"Memory Usage: {mem_info.rss / (1024 ** 2):.2f} MB\")\n","\n","class MemoryUsageCallback(Callback):\n","    def on_epoch_end(self, epoch, logs=None):\n","        print_memory_usage()"],"metadata":{"id":"Tc2ueju9nSae","executionInfo":{"status":"ok","timestamp":1729000680859,"user_tz":-480,"elapsed":5,"user":{"displayName":"Jonindo Pasaribu","userId":"10958990953097471082"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["# Train final model using best hyperparameters\n","best_model = TabNetRegressor(**best_params,\n","                             n_a=best_params['n_d'],\n","                             optimizer_fn=torch.optim.Adam,\n","                             optimizer_params=dict(lr=2e-2)\n","                             )\n","best_model.fit(\n","    X_train, y_train,\n","    eval_set=[(X_train, y_train), (X_valid, y_valid)],\n","    eval_name=['train', 'valid'],\n","    eval_metric=['mae', 'rmse'],\n","    callbacks=[MemoryUsageCallback()]\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rLdfMkJXw_Xl","executionInfo":{"status":"ok","timestamp":1729000806031,"user_tz":-480,"elapsed":125177,"user":{"displayName":"Jonindo Pasaribu","userId":"10958990953097471082"}},"outputId":"352fcb0a-d5bf-4683-86ab-b925d0aa589e"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 2291.23216| train_mae: 43.84552001953125| train_rmse: 60.14802169799805| valid_mae: 44.939231872558594| valid_rmse: 61.33679962158203|  0:00:01s\n","Memory Usage: 1217.77 MB\n","epoch 1  | loss: 1441.79282| train_mae: 56.212120056152344| train_rmse: 75.02490234375| valid_mae: 57.159400939941406| valid_rmse: 74.84664154052734|  0:00:02s\n","Memory Usage: 1217.77 MB\n","epoch 2  | loss: 889.23913| train_mae: 63.01765823364258| train_rmse: 76.81079864501953| valid_mae: 65.39363861083984| valid_rmse: 80.03688049316406|  0:00:04s\n","Memory Usage: 1217.77 MB\n","epoch 3  | loss: 460.75143| train_mae: 42.557701110839844| train_rmse: 55.93354034423828| valid_mae: 44.86759948730469| valid_rmse: 58.159278869628906|  0:00:05s\n","Memory Usage: 1217.77 MB\n","epoch 4  | loss: 352.48549| train_mae: 48.918819427490234| train_rmse: 69.15757751464844| valid_mae: 50.417301177978516| valid_rmse: 70.4561767578125|  0:00:07s\n","Memory Usage: 1217.77 MB\n","epoch 5  | loss: 320.91063| train_mae: 39.61928176879883| train_rmse: 54.65245819091797| valid_mae: 40.781490325927734| valid_rmse: 55.822669982910156|  0:00:08s\n","Memory Usage: 1217.77 MB\n","epoch 6  | loss: 242.42243| train_mae: 53.42103958129883| train_rmse: 67.7688217163086| valid_mae: 54.95064163208008| valid_rmse: 69.16899871826172|  0:00:10s\n","Memory Usage: 1217.77 MB\n","epoch 7  | loss: 211.48845| train_mae: 44.692501068115234| train_rmse: 59.81568145751953| valid_mae: 46.26353073120117| valid_rmse: 61.46657943725586|  0:00:11s\n","Memory Usage: 1217.77 MB\n","epoch 8  | loss: 212.16813| train_mae: 34.924278259277344| train_rmse: 53.68952178955078| valid_mae: 36.68915939331055| valid_rmse: 55.349788665771484|  0:00:13s\n","Memory Usage: 1217.77 MB\n","epoch 9  | loss: 189.07998| train_mae: 37.89952087402344| train_rmse: 55.8397216796875| valid_mae: 39.79833984375| valid_rmse: 57.6138801574707|  0:00:14s\n","Memory Usage: 1217.77 MB\n","epoch 10 | loss: 165.62802| train_mae: 32.5931282043457| train_rmse: 52.94540023803711| valid_mae: 34.57339859008789| valid_rmse: 54.77872085571289|  0:00:16s\n","Memory Usage: 1217.77 MB\n","epoch 11 | loss: 162.97204| train_mae: 32.95581817626953| train_rmse: 51.54378890991211| valid_mae: 34.65911865234375| valid_rmse: 53.16048812866211|  0:00:17s\n","Memory Usage: 1217.77 MB\n","epoch 12 | loss: 136.40382| train_mae: 29.96278953552246| train_rmse: 48.31209945678711| valid_mae: 31.490819931030273| valid_rmse: 49.84661865234375|  0:00:19s\n","Memory Usage: 1217.77 MB\n","epoch 13 | loss: 123.41787| train_mae: 30.265989303588867| train_rmse: 49.881378173828125| valid_mae: 31.99250030517578| valid_rmse: 51.42407989501953|  0:00:20s\n","Memory Usage: 1217.77 MB\n","epoch 14 | loss: 122.96334| train_mae: 29.819910049438477| train_rmse: 49.22943878173828| valid_mae: 31.452590942382812| valid_rmse: 50.69768142700195|  0:00:22s\n","Memory Usage: 1217.77 MB\n","epoch 15 | loss: 111.75536| train_mae: 27.4194393157959| train_rmse: 46.211360931396484| valid_mae: 28.94145965576172| valid_rmse: 47.65156173706055|  0:00:24s\n","Memory Usage: 1217.77 MB\n","epoch 16 | loss: 88.08292| train_mae: 26.563840866088867| train_rmse: 44.173789978027344| valid_mae: 28.083009719848633| valid_rmse: 45.56304168701172|  0:00:25s\n","Memory Usage: 1217.77 MB\n","epoch 17 | loss: 88.47389| train_mae: 25.27984046936035| train_rmse: 42.51150131225586| valid_mae: 26.77157974243164| valid_rmse: 43.93593978881836|  0:00:27s\n","Memory Usage: 1217.77 MB\n","epoch 18 | loss: 88.23351| train_mae: 24.366920471191406| train_rmse: 41.31520080566406| valid_mae: 25.746360778808594| valid_rmse: 42.64268112182617|  0:00:28s\n","Memory Usage: 1217.77 MB\n","epoch 19 | loss: 79.41905| train_mae: 20.231929779052734| train_rmse: 35.512901306152344| valid_mae: 21.129009246826172| valid_rmse: 36.49348068237305|  0:00:30s\n","Memory Usage: 1217.77 MB\n","epoch 20 | loss: 103.96901| train_mae: 18.427669525146484| train_rmse: 33.07611846923828| valid_mae: 19.399290084838867| valid_rmse: 34.20043182373047|  0:00:31s\n","Memory Usage: 1217.77 MB\n","epoch 21 | loss: 93.89615| train_mae: 17.164060592651367| train_rmse: 32.287818908691406| valid_mae: 18.09295082092285| valid_rmse: 33.257469177246094|  0:00:33s\n","Memory Usage: 1217.77 MB\n","epoch 22 | loss: 92.49112| train_mae: 17.026470184326172| train_rmse: 31.452789306640625| valid_mae: 17.948749542236328| valid_rmse: 32.30561828613281|  0:00:34s\n","Memory Usage: 1217.77 MB\n","epoch 23 | loss: 75.03923| train_mae: 14.027389526367188| train_rmse: 25.660600662231445| valid_mae: 14.735260009765625| valid_rmse: 26.606220245361328|  0:00:36s\n","Memory Usage: 1217.77 MB\n","epoch 24 | loss: 62.16541| train_mae: 13.037460327148438| train_rmse: 24.595260620117188| valid_mae: 13.738730430603027| valid_rmse: 25.39940071105957|  0:00:37s\n","Memory Usage: 1217.77 MB\n","epoch 25 | loss: 63.87566| train_mae: 10.975099563598633| train_rmse: 21.026750564575195| valid_mae: 11.497750282287598| valid_rmse: 21.536970138549805|  0:00:39s\n","Memory Usage: 1217.77 MB\n","epoch 26 | loss: 70.6204 | train_mae: 11.489680290222168| train_rmse: 21.53734016418457| valid_mae: 12.033430099487305| valid_rmse: 22.197219848632812|  0:00:40s\n","Memory Usage: 1217.77 MB\n","epoch 27 | loss: 69.64558| train_mae: 9.671019554138184| train_rmse: 19.042190551757812| valid_mae: 10.209620475769043| valid_rmse: 19.66452980041504|  0:00:42s\n","Memory Usage: 1217.77 MB\n","epoch 28 | loss: 63.68691| train_mae: 8.06344985961914| train_rmse: 16.352590560913086| valid_mae: 8.455320358276367| valid_rmse: 16.94182014465332|  0:00:43s\n","Memory Usage: 1217.77 MB\n","epoch 29 | loss: 70.32923| train_mae: 6.97560977935791| train_rmse: 13.915459632873535| valid_mae: 7.1677398681640625| valid_rmse: 14.274889945983887|  0:00:45s\n","Memory Usage: 1217.77 MB\n","epoch 30 | loss: 71.06821| train_mae: 7.795479774475098| train_rmse: 14.012359619140625| valid_mae: 8.135600090026855| valid_rmse: 14.59607982635498|  0:00:46s\n","Memory Usage: 1217.77 MB\n","epoch 31 | loss: 54.36067| train_mae: 6.693359851837158| train_rmse: 13.139309883117676| valid_mae: 6.867420196533203| valid_rmse: 13.40707015991211|  0:00:48s\n","Memory Usage: 1217.77 MB\n","epoch 32 | loss: 80.54915| train_mae: 6.442599773406982| train_rmse: 12.616880416870117| valid_mae: 6.528570175170898| valid_rmse: 12.821269989013672|  0:00:49s\n","Memory Usage: 1218.02 MB\n","epoch 33 | loss: 64.72697| train_mae: 4.976779937744141| train_rmse: 10.216730117797852| valid_mae: 4.930429935455322| valid_rmse: 10.207039833068848|  0:00:51s\n","Memory Usage: 1218.02 MB\n","epoch 34 | loss: 71.17356| train_mae: 4.978919982910156| train_rmse: 9.653220176696777| valid_mae: 5.180659770965576| valid_rmse: 10.145179748535156|  0:00:52s\n","Memory Usage: 1218.02 MB\n","epoch 35 | loss: 60.97356| train_mae: 4.726349830627441| train_rmse: 9.2153902053833| valid_mae: 4.872580051422119| valid_rmse: 9.480389595031738|  0:00:54s\n","Memory Usage: 1218.02 MB\n","epoch 36 | loss: 60.51213| train_mae: 4.801360130310059| train_rmse: 8.781399726867676| valid_mae: 4.790510177612305| valid_rmse: 8.737919807434082|  0:00:55s\n","Memory Usage: 1218.02 MB\n","epoch 37 | loss: 52.57876| train_mae: 5.282599925994873| train_rmse: 9.125419616699219| valid_mae: 5.348020076751709| valid_rmse: 9.40137004852295|  0:00:57s\n","Memory Usage: 1218.02 MB\n","epoch 38 | loss: 57.80073| train_mae: 5.258019924163818| train_rmse: 9.477669715881348| valid_mae: 5.352630138397217| valid_rmse: 9.68340015411377|  0:00:58s\n","Memory Usage: 1218.02 MB\n","epoch 39 | loss: 60.2041 | train_mae: 4.523749828338623| train_rmse: 9.122639656066895| valid_mae: 4.511340141296387| valid_rmse: 9.078889846801758|  0:01:00s\n","Memory Usage: 1218.02 MB\n","epoch 40 | loss: 59.63937| train_mae: 4.0131402015686035| train_rmse: 7.8359198570251465| valid_mae: 4.013830184936523| valid_rmse: 7.772290229797363|  0:01:02s\n","Memory Usage: 1218.02 MB\n","epoch 41 | loss: 41.90717| train_mae: 4.230140209197998| train_rmse: 7.596250057220459| valid_mae: 4.237339973449707| valid_rmse: 7.3773298263549805|  0:01:03s\n","Memory Usage: 1218.02 MB\n","epoch 42 | loss: 74.86381| train_mae: 5.740779876708984| train_rmse: 9.286100387573242| valid_mae: 6.0784101486206055| valid_rmse: 9.752420425415039|  0:01:05s\n","Memory Usage: 1218.02 MB\n","epoch 43 | loss: 56.75576| train_mae: 5.079529762268066| train_rmse: 8.291250228881836| valid_mae: 5.1786699295043945| valid_rmse: 8.37775993347168|  0:01:06s\n","Memory Usage: 1218.02 MB\n","epoch 44 | loss: 65.75865| train_mae: 4.967239856719971| train_rmse: 8.865019798278809| valid_mae: 5.1196699142456055| valid_rmse: 9.288370132446289|  0:01:08s\n","Memory Usage: 1218.02 MB\n","epoch 45 | loss: 62.86355| train_mae: 3.2421998977661133| train_rmse: 6.315450191497803| valid_mae: 3.3773601055145264| valid_rmse: 7.156239986419678|  0:01:10s\n","Memory Usage: 1218.02 MB\n","epoch 46 | loss: 61.30116| train_mae: 3.6273701190948486| train_rmse: 6.553619861602783| valid_mae: 3.6184799671173096| valid_rmse: 6.7275800704956055|  0:01:11s\n","Memory Usage: 1218.02 MB\n","epoch 47 | loss: 66.15837| train_mae: 4.70173978805542| train_rmse: 8.483880043029785| valid_mae: 4.826600074768066| valid_rmse: 8.636460304260254|  0:01:13s\n","Memory Usage: 1218.02 MB\n","epoch 48 | loss: 77.80111| train_mae: 3.7816500663757324| train_rmse: 6.467899799346924| valid_mae: 3.864069938659668| valid_rmse: 6.657760143280029|  0:01:15s\n","Memory Usage: 1218.02 MB\n","epoch 49 | loss: 77.67374| train_mae: 4.186309814453125| train_rmse: 7.057809829711914| valid_mae: 4.374070167541504| valid_rmse: 7.399320125579834|  0:01:16s\n","Memory Usage: 1218.02 MB\n","epoch 50 | loss: 57.15995| train_mae: 3.756969928741455| train_rmse: 6.456620216369629| valid_mae: 3.8107399940490723| valid_rmse: 6.410240173339844|  0:01:18s\n","Memory Usage: 1218.02 MB\n","epoch 51 | loss: 54.57695| train_mae: 3.047489881515503| train_rmse: 5.576409816741943| valid_mae: 2.995879888534546| valid_rmse: 5.572539806365967|  0:01:19s\n","Memory Usage: 1218.02 MB\n","epoch 52 | loss: 61.55584| train_mae: 2.872529983520508| train_rmse: 5.459010124206543| valid_mae: 2.884779930114746| valid_rmse: 5.623370170593262|  0:01:21s\n","Memory Usage: 1218.02 MB\n","epoch 53 | loss: 50.54374| train_mae: 3.64424991607666| train_rmse: 6.871779918670654| valid_mae: 3.698359966278076| valid_rmse: 7.107399940490723|  0:01:22s\n","Memory Usage: 1218.02 MB\n","epoch 54 | loss: 68.54702| train_mae: 3.041800022125244| train_rmse: 5.680630207061768| valid_mae: 2.969059944152832| valid_rmse: 5.632740020751953|  0:01:24s\n","Memory Usage: 1218.02 MB\n","epoch 55 | loss: 57.0807 | train_mae: 3.4247899055480957| train_rmse: 5.8356499671936035| valid_mae: 3.6169800758361816| valid_rmse: 6.035009860992432|  0:01:26s\n","Memory Usage: 1218.02 MB\n","epoch 56 | loss: 50.8496 | train_mae: 3.0776801109313965| train_rmse: 5.48222017288208| valid_mae: 3.2225100994110107| valid_rmse: 5.838799953460693|  0:01:27s\n","Memory Usage: 1218.02 MB\n","epoch 57 | loss: 48.90599| train_mae: 3.1533100605010986| train_rmse: 5.558819770812988| valid_mae: 3.166559934616089| valid_rmse: 5.784150123596191|  0:01:29s\n","Memory Usage: 1218.02 MB\n","epoch 58 | loss: 59.80511| train_mae: 3.0332300662994385| train_rmse: 6.010439872741699| valid_mae: 3.169980049133301| valid_rmse: 6.1668901443481445|  0:01:30s\n","Memory Usage: 1218.02 MB\n","epoch 59 | loss: 49.11699| train_mae: 3.0024099349975586| train_rmse: 5.499670028686523| valid_mae: 2.9894399642944336| valid_rmse: 5.454500198364258|  0:01:32s\n","Memory Usage: 1218.02 MB\n","epoch 60 | loss: 53.38869| train_mae: 3.1454899311065674| train_rmse: 6.067140102386475| valid_mae: 3.1279499530792236| valid_rmse: 5.861770153045654|  0:01:33s\n","Memory Usage: 1218.02 MB\n","epoch 61 | loss: 52.478  | train_mae: 3.477479934692383| train_rmse: 5.495200157165527| valid_mae: 3.586780071258545| valid_rmse: 5.856750011444092|  0:01:35s\n","Memory Usage: 1218.02 MB\n","epoch 62 | loss: 40.41949| train_mae: 2.610069990158081| train_rmse: 4.985060214996338| valid_mae: 2.6075799465179443| valid_rmse: 5.060190200805664|  0:01:36s\n","Memory Usage: 1218.02 MB\n","epoch 63 | loss: 48.19757| train_mae: 3.5743300914764404| train_rmse: 6.634590148925781| valid_mae: 3.47763991355896| valid_rmse: 6.33951997756958|  0:01:38s\n","Memory Usage: 1218.02 MB\n","epoch 64 | loss: 60.11359| train_mae: 3.064919948577881| train_rmse: 5.593279838562012| valid_mae: 3.134200096130371| valid_rmse: 5.950409889221191|  0:01:40s\n","Memory Usage: 1218.02 MB\n","epoch 65 | loss: 51.00361| train_mae: 3.062069892883301| train_rmse: 5.418379783630371| valid_mae: 3.109339952468872| valid_rmse: 5.598849773406982|  0:01:41s\n","Memory Usage: 1218.02 MB\n","epoch 66 | loss: 54.99667| train_mae: 3.02128005027771| train_rmse: 5.866310119628906| valid_mae: 2.967180013656616| valid_rmse: 5.937960147857666|  0:01:43s\n","Memory Usage: 1218.02 MB\n","epoch 67 | loss: 71.41214| train_mae: 3.6835498809814453| train_rmse: 7.045559883117676| valid_mae: 3.775290012359619| valid_rmse: 7.332129955291748|  0:01:44s\n","Memory Usage: 1218.02 MB\n","epoch 68 | loss: 66.20311| train_mae: 2.5907700061798096| train_rmse: 4.759990215301514| valid_mae: 2.587599992752075| valid_rmse: 5.088180065155029|  0:01:46s\n","Memory Usage: 1218.02 MB\n","epoch 69 | loss: 51.20682| train_mae: 2.912600040435791| train_rmse: 4.902050018310547| valid_mae: 3.0202600955963135| valid_rmse: 5.3313798904418945|  0:01:47s\n","Memory Usage: 1218.02 MB\n","epoch 70 | loss: 41.74953| train_mae: 2.1928999423980713| train_rmse: 4.237880229949951| valid_mae: 2.263859987258911| valid_rmse: 4.808680057525635|  0:01:49s\n","Memory Usage: 1218.02 MB\n","epoch 71 | loss: 45.28418| train_mae: 2.4348599910736084| train_rmse: 4.8590497970581055| valid_mae: 2.5683000087738037| valid_rmse: 5.2218098640441895|  0:01:51s\n","Memory Usage: 1218.02 MB\n","epoch 72 | loss: 38.85951| train_mae: 2.489690065383911| train_rmse: 4.562379837036133| valid_mae: 2.529589891433716| valid_rmse: 4.921150207519531|  0:01:52s\n","Memory Usage: 1218.02 MB\n","epoch 73 | loss: 56.7204 | train_mae: 3.713099956512451| train_rmse: 6.139369964599609| valid_mae: 3.722130060195923| valid_rmse: 6.174799919128418|  0:01:54s\n","Memory Usage: 1218.02 MB\n","epoch 74 | loss: 61.61331| train_mae: 3.203619956970215| train_rmse: 5.5554399490356445| valid_mae: 3.3234798908233643| valid_rmse: 6.0381999015808105|  0:01:55s\n","Memory Usage: 1218.02 MB\n","epoch 75 | loss: 56.06418| train_mae: 3.3213798999786377| train_rmse: 6.264170169830322| valid_mae: 3.4665300846099854| valid_rmse: 6.843170166015625|  0:01:57s\n","Memory Usage: 1218.02 MB\n","epoch 76 | loss: 54.12268| train_mae: 3.0172200202941895| train_rmse: 5.120419979095459| valid_mae: 3.189470052719116| valid_rmse: 5.65339994430542|  0:01:58s\n","Memory Usage: 1218.02 MB\n","epoch 77 | loss: 49.80759| train_mae: 2.798830032348633| train_rmse: 4.84443998336792| valid_mae: 2.768320083618164| valid_rmse: 5.161809921264648|  0:02:00s\n","Memory Usage: 1218.02 MB\n","epoch 78 | loss: 46.97453| train_mae: 2.9644699096679688| train_rmse: 5.075689792633057| valid_mae: 3.1262500286102295| valid_rmse: 5.5241899490356445|  0:02:01s\n","Memory Usage: 1218.02 MB\n","epoch 79 | loss: 46.77916| train_mae: 3.5727601051330566| train_rmse: 5.527719974517822| valid_mae: 3.6648199558258057| valid_rmse: 5.731040000915527|  0:02:03s\n","Memory Usage: 1218.02 MB\n","epoch 80 | loss: 45.07583| train_mae: 3.2341198921203613| train_rmse: 5.10014009475708| valid_mae: 3.201359987258911| valid_rmse: 5.182119846343994|  0:02:04s\n","Memory Usage: 1218.02 MB\n","\n","Early stopping occurred at epoch 80 with best_epoch = 70 and best_valid_rmse = 4.808680057525635\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n"]}]},{"cell_type":"code","source":["from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, classification_report\n","\n","preds = best_model.predict(X_test)\n","y_true = y_test\n","\n","mae_test = mean_absolute_error(y_pred=preds, y_true=y_true)\n","mse = mean_squared_error(y_pred=preds, y_true=y_true)\n","rmse_test = np.sqrt(mean_squared_error(y_true, y_pred=preds))\n","r2_test = r2_score(y_true=y_true, y_pred=preds)\n","\n","print(\"Best Valid RMSE:\", best_model.best_cost)\n","print(\"Test MAE:\", mae_test)\n","print(\"Test RMSE:\", rmse_test)\n","print(\"R-squared:\", r2_test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"o3TYXT_o_6oS","executionInfo":{"status":"ok","timestamp":1729000806665,"user_tz":-480,"elapsed":640,"user":{"displayName":"Jonindo Pasaribu","userId":"10958990953097471082"}},"outputId":"1e3a2039-a0f1-40f9-c640-445239a38641"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Best Valid RMSE: 4.8086843\n","Test MAE: 2.2215762\n","Test RMSE: 4.5151596\n","R-squared: 0.988527238368988\n"]}]},{"cell_type":"code","source":["base_preds = tnr.predict(X_test)\n","\n","base_mae_test = mean_absolute_error(y_pred=base_preds, y_true=y_true)\n","base_mse = mean_squared_error(y_pred=base_preds, y_true=y_true)\n","base_rmse_test = np.sqrt(mean_squared_error(y_true, y_pred=base_preds))\n","\n","print(\"Best Valid Score:\", tnr.best_cost)\n","print(\"Test MAE:\", base_mae_test)\n","print(\"Test RMSE:\", base_rmse_test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8nW4N4ls2O6R","executionInfo":{"status":"ok","timestamp":1719664696571,"user_tz":-420,"elapsed":2,"user":{"displayName":"Jonindo Pasaribu","userId":"10958990953097471082"}},"outputId":"3cc1e26e-afe1-406d-b874-1613ae2452fc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Best Valid Score: 48.696762\n","Test MAE: 31.22412\n","Test RMSE: 48.315136\n"]}]},{"cell_type":"code","source":["from matplotlib import pyplot as plt"],"metadata":{"id":"sxa64ArkAahN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.plot(tnr.history['loss'])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":448},"id":"zqkBaf7btWFx","executionInfo":{"status":"ok","timestamp":1716965025700,"user_tz":-420,"elapsed":705,"user":{"displayName":"Jonindo Pasaribu","userId":"10958990953097471082"}},"outputId":"89efb4b7-f63d-43a3-f190-cfe48cfbc358"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[<matplotlib.lines.Line2D at 0x7c111013a6b0>]"]},"metadata":{},"execution_count":23},{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"code","source":["plt.plot(best_model.history['loss'])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":448},"id":"j7OdxaVNtYNt","executionInfo":{"status":"ok","timestamp":1716965029034,"user_tz":-420,"elapsed":403,"user":{"displayName":"Jonindo Pasaribu","userId":"10958990953097471082"}},"outputId":"30318817-264e-4a1c-84b8-5f4a3431f055"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[<matplotlib.lines.Line2D at 0x7c10c4119f00>]"]},"metadata":{},"execution_count":24},{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]}]}