{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","machine_shape":"hm","authorship_tag":"ABX9TyNR+b8H0WWVt5KT6aeyz7ac"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["!wget https://huggingface.co/datasets/puhsu/tabular-benchmarks/resolve/main/data.tar -O tabular-dl-tabr.tar.gz\n","!tar -xvf tabular-dl-tabr.tar.gz"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pulqlCAgJDEt","executionInfo":{"status":"ok","timestamp":1729007564667,"user_tz":-480,"elapsed":20746,"user":{"displayName":"Jonindo Pasaribu","userId":"10958990953097471082"}},"outputId":"cae58a0b-772b-420c-fc4a-af5e8ee7cad5"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["--2024-10-15 15:52:23--  https://huggingface.co/datasets/puhsu/tabular-benchmarks/resolve/main/data.tar\n","Resolving huggingface.co (huggingface.co)... 13.35.210.77, 13.35.210.66, 13.35.210.61, ...\n","Connecting to huggingface.co (huggingface.co)|13.35.210.77|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://cdn-lfs.hf.co/repos/1b/25/1b25d6e2556c827abfaf6ba9da6021338691cafc39fe9d77986955ae0a69243d/0d74e4b96febb48fbe4dd2d851f8638b5738354f82c3183f92adbd2abf2f256b?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27data.tar%3B+filename%3D%22data.tar%22%3B&response-content-type=application%2Fx-tar&Expires=1729266743&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcyOTI2Njc0M319LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5oZi5jby9yZXBvcy8xYi8yNS8xYjI1ZDZlMjU1NmM4MjdhYmZhZjZiYTlkYTYwMjEzMzg2OTFjYWZjMzlmZTlkNzc5ODY5NTVhZTBhNjkyNDNkLzBkNzRlNGI5NmZlYmI0OGZiZTRkZDJkODUxZjg2MzhiNTczODM1NGY4MmMzMTgzZjkyYWRiZDJhYmYyZjI1NmI%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qJnJlc3BvbnNlLWNvbnRlbnQtdHlwZT0qIn1dfQ__&Signature=jvQtcq-mylFZlNrOP6-IzwH8KFSRwhnN0Daz0B%7EPEkxGUyAd0ZaBaSBVYYrGt4aSxfIHkmR4qz2Hga7c8ZQSuULw9GiFjvpnH9s3bV6SyS7OYPHRiHlUBxbXH9rodjT70JqCgzTKZPtVH8R0j0de97JqtzGtYQH%7ESXnu3r7ZkiNGMoCHnKrKasAhDyGv7keRsvruEcNZvwOqeieB2cc8udcfWITud4jOVQ2nKlhtJY9NbXhhk89U6lETwVuGWlDvZz8bLYgBaTR7xL6lBmeX0v0wyzU6SDvr5EaoqL6WUsItBF72nrv2vAoob442TP%7Eow5Lt8vgHIWvj0H%7E1psujMA__&Key-Pair-Id=K3RPWS32NSSJCE [following]\n","--2024-10-15 15:52:23--  https://cdn-lfs.hf.co/repos/1b/25/1b25d6e2556c827abfaf6ba9da6021338691cafc39fe9d77986955ae0a69243d/0d74e4b96febb48fbe4dd2d851f8638b5738354f82c3183f92adbd2abf2f256b?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27data.tar%3B+filename%3D%22data.tar%22%3B&response-content-type=application%2Fx-tar&Expires=1729266743&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcyOTI2Njc0M319LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5oZi5jby9yZXBvcy8xYi8yNS8xYjI1ZDZlMjU1NmM4MjdhYmZhZjZiYTlkYTYwMjEzMzg2OTFjYWZjMzlmZTlkNzc5ODY5NTVhZTBhNjkyNDNkLzBkNzRlNGI5NmZlYmI0OGZiZTRkZDJkODUxZjg2MzhiNTczODM1NGY4MmMzMTgzZjkyYWRiZDJhYmYyZjI1NmI%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qJnJlc3BvbnNlLWNvbnRlbnQtdHlwZT0qIn1dfQ__&Signature=jvQtcq-mylFZlNrOP6-IzwH8KFSRwhnN0Daz0B%7EPEkxGUyAd0ZaBaSBVYYrGt4aSxfIHkmR4qz2Hga7c8ZQSuULw9GiFjvpnH9s3bV6SyS7OYPHRiHlUBxbXH9rodjT70JqCgzTKZPtVH8R0j0de97JqtzGtYQH%7ESXnu3r7ZkiNGMoCHnKrKasAhDyGv7keRsvruEcNZvwOqeieB2cc8udcfWITud4jOVQ2nKlhtJY9NbXhhk89U6lETwVuGWlDvZz8bLYgBaTR7xL6lBmeX0v0wyzU6SDvr5EaoqL6WUsItBF72nrv2vAoob442TP%7Eow5Lt8vgHIWvj0H%7E1psujMA__&Key-Pair-Id=K3RPWS32NSSJCE\n","Resolving cdn-lfs.hf.co (cdn-lfs.hf.co)... 18.155.68.87, 18.155.68.37, 18.155.68.34, ...\n","Connecting to cdn-lfs.hf.co (cdn-lfs.hf.co)|18.155.68.87|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 3094384640 (2.9G) [application/x-tar]\n","Saving to: ‘tabular-dl-tabr.tar.gz’\n","\n","tabular-dl-tabr.tar 100%[===================>]   2.88G   208MB/s    in 11s     \n","\n","2024-10-15 15:52:34 (277 MB/s) - ‘tabular-dl-tabr.tar.gz’ saved [3094384640/3094384640]\n","\n","data/\n","data/regression-num-medium-0-Ailerons/\n","data/regression-num-medium-0-Ailerons/X_num_val.npy\n","data/regression-num-medium-0-Ailerons/Y_val.npy\n","data/regression-num-medium-0-Ailerons/X_num_train.npy\n","data/regression-num-medium-0-Ailerons/info.json\n","data/regression-num-medium-0-Ailerons/READY\n","data/regression-num-medium-0-Ailerons/X_num_test.npy\n","data/regression-num-medium-0-Ailerons/Y_test.npy\n","data/regression-num-medium-0-Ailerons/Y_train.npy\n","data/regression-cat-medium-0-house_sales/\n","data/regression-cat-medium-0-house_sales/X_num_val.npy\n","data/regression-cat-medium-0-house_sales/Y_val.npy\n","data/regression-cat-medium-0-house_sales/X_bin_val.npy\n","data/regression-cat-medium-0-house_sales/X_num_train.npy\n","data/regression-cat-medium-0-house_sales/X_bin_train.npy\n","data/regression-cat-medium-0-house_sales/info.json\n","data/regression-cat-medium-0-house_sales/READY\n","data/regression-cat-medium-0-house_sales/X_bin_test.npy\n","data/regression-cat-medium-0-house_sales/X_num_test.npy\n","data/regression-cat-medium-0-house_sales/Y_test.npy\n","data/regression-cat-medium-0-house_sales/Y_train.npy\n","data/classif-cat-medium-2-KDDCup09_upselling/\n","data/classif-cat-medium-2-KDDCup09_upselling/X_cat_val.npy\n","data/classif-cat-medium-2-KDDCup09_upselling/X_num_val.npy\n","data/classif-cat-medium-2-KDDCup09_upselling/Y_val.npy\n","data/classif-cat-medium-2-KDDCup09_upselling/X_bin_val.npy\n","data/classif-cat-medium-2-KDDCup09_upselling/X_num_train.npy\n","data/classif-cat-medium-2-KDDCup09_upselling/X_cat_test.npy\n","data/classif-cat-medium-2-KDDCup09_upselling/X_bin_train.npy\n","data/classif-cat-medium-2-KDDCup09_upselling/X_cat_train.npy\n","data/classif-cat-medium-2-KDDCup09_upselling/info.json\n","data/classif-cat-medium-2-KDDCup09_upselling/READY\n","data/classif-cat-medium-2-KDDCup09_upselling/X_bin_test.npy\n","data/classif-cat-medium-2-KDDCup09_upselling/X_num_test.npy\n","data/classif-cat-medium-2-KDDCup09_upselling/Y_test.npy\n","data/classif-cat-medium-2-KDDCup09_upselling/Y_train.npy\n","data/regression-num-medium-2-isolet/\n","data/regression-num-medium-2-isolet/X_num_val.npy\n","data/regression-num-medium-2-isolet/Y_val.npy\n","data/regression-num-medium-2-isolet/X_num_train.npy\n","data/regression-num-medium-2-isolet/info.json\n","data/regression-num-medium-2-isolet/READY\n","data/regression-num-medium-2-isolet/X_num_test.npy\n","data/regression-num-medium-2-isolet/Y_test.npy\n","data/regression-num-medium-2-isolet/Y_train.npy\n","data/regression-cat-medium-1-Brazilian_houses/\n","data/regression-cat-medium-1-Brazilian_houses/X_cat_val.npy\n","data/regression-cat-medium-1-Brazilian_houses/X_num_val.npy\n","data/regression-cat-medium-1-Brazilian_houses/Y_val.npy\n","data/regression-cat-medium-1-Brazilian_houses/X_bin_val.npy\n","data/regression-cat-medium-1-Brazilian_houses/X_num_train.npy\n","data/regression-cat-medium-1-Brazilian_houses/X_cat_test.npy\n","data/regression-cat-medium-1-Brazilian_houses/X_bin_train.npy\n","data/regression-cat-medium-1-Brazilian_houses/X_cat_train.npy\n","data/regression-cat-medium-1-Brazilian_houses/info.json\n","data/regression-cat-medium-1-Brazilian_houses/READY\n","data/regression-cat-medium-1-Brazilian_houses/X_bin_test.npy\n","data/regression-cat-medium-1-Brazilian_houses/X_num_test.npy\n","data/regression-cat-medium-1-Brazilian_houses/Y_test.npy\n","data/regression-cat-medium-1-Brazilian_houses/Y_train.npy\n","data/regression-num-medium-2-wine_quality/\n","data/regression-num-medium-2-wine_quality/X_num_val.npy\n","data/regression-num-medium-2-wine_quality/Y_val.npy\n","data/regression-num-medium-2-wine_quality/X_num_train.npy\n","data/regression-num-medium-2-wine_quality/info.json\n","data/regression-num-medium-2-wine_quality/READY\n","data/regression-num-medium-2-wine_quality/X_num_test.npy\n","data/regression-num-medium-2-wine_quality/Y_test.npy\n","data/regression-num-medium-2-wine_quality/Y_train.npy\n","data/regression-num-medium-0-california/\n","data/regression-num-medium-0-california/X_num_val.npy\n","data/regression-num-medium-0-california/Y_val.npy\n","data/regression-num-medium-0-california/X_num_train.npy\n","data/regression-num-medium-0-california/info.json\n","data/regression-num-medium-0-california/READY\n","data/regression-num-medium-0-california/X_num_test.npy\n","data/regression-num-medium-0-california/Y_test.npy\n","data/regression-num-medium-0-california/Y_train.npy\n","data/classif-num-medium-2-wine/\n","data/classif-num-medium-2-wine/X_num_val.npy\n","data/classif-num-medium-2-wine/Y_val.npy\n","data/classif-num-medium-2-wine/X_num_train.npy\n","data/classif-num-medium-2-wine/info.json\n","data/classif-num-medium-2-wine/READY\n","data/classif-num-medium-2-wine/X_num_test.npy\n","data/classif-num-medium-2-wine/Y_test.npy\n","data/classif-num-medium-2-wine/Y_train.npy\n","data/classif-num-medium-1-phoneme/\n","data/classif-num-medium-1-phoneme/X_num_val.npy\n","data/classif-num-medium-1-phoneme/Y_val.npy\n","data/classif-num-medium-1-phoneme/X_num_train.npy\n","data/classif-num-medium-1-phoneme/info.json\n","data/classif-num-medium-1-phoneme/READY\n","data/classif-num-medium-1-phoneme/X_num_test.npy\n","data/classif-num-medium-1-phoneme/Y_test.npy\n","data/classif-num-medium-1-phoneme/Y_train.npy\n","data/regression-num-medium-1-isolet/\n","data/regression-num-medium-1-isolet/X_num_val.npy\n","data/regression-num-medium-1-isolet/Y_val.npy\n","data/regression-num-medium-1-isolet/X_num_train.npy\n","data/regression-num-medium-1-isolet/info.json\n","data/regression-num-medium-1-isolet/READY\n","data/regression-num-medium-1-isolet/X_num_test.npy\n","data/regression-num-medium-1-isolet/Y_test.npy\n","data/regression-num-medium-1-isolet/Y_train.npy\n","data/churn/\n","data/churn/X_cat_val.npy\n","data/churn/X_num_val.npy\n","data/churn/Y_val.npy\n","data/churn/X_bin_val.npy\n","data/churn/X_num_train.npy\n","data/churn/X_cat_test.npy\n","data/churn/X_bin_train.npy\n","data/churn/X_cat_train.npy\n","data/churn/info.json\n","data/churn/READY\n","data/churn/X_bin_test.npy\n","data/churn/X_num_test.npy\n","data/churn/Y_test.npy\n","data/churn/Y_train.npy\n","data/regression-num-medium-2-sulfur/\n","data/regression-num-medium-2-sulfur/X_num_val.npy\n","data/regression-num-medium-2-sulfur/Y_val.npy\n","data/regression-num-medium-2-sulfur/X_num_train.npy\n","data/regression-num-medium-2-sulfur/info.json\n","data/regression-num-medium-2-sulfur/READY\n","data/regression-num-medium-2-sulfur/X_num_test.npy\n","data/regression-num-medium-2-sulfur/Y_test.npy\n","data/regression-num-medium-2-sulfur/Y_train.npy\n","data/regression-cat-large-0-diamonds/\n","data/regression-cat-large-0-diamonds/X_cat_val.npy\n","data/regression-cat-large-0-diamonds/X_num_val.npy\n","data/regression-cat-large-0-diamonds/Y_val.npy\n","data/regression-cat-large-0-diamonds/X_num_train.npy\n","data/regression-cat-large-0-diamonds/X_cat_test.npy\n","data/regression-cat-large-0-diamonds/X_cat_train.npy\n","data/regression-cat-large-0-diamonds/info.json\n","data/regression-cat-large-0-diamonds/READY\n","data/regression-cat-large-0-diamonds/X_num_test.npy\n","data/regression-cat-large-0-diamonds/Y_test.npy\n","data/regression-cat-large-0-diamonds/Y_train.npy\n","data/classif-cat-large-0-road-safety/\n","data/classif-cat-large-0-road-safety/X_cat_val.npy\n","data/classif-cat-large-0-road-safety/X_num_val.npy\n","data/classif-cat-large-0-road-safety/Y_val.npy\n","data/classif-cat-large-0-road-safety/X_num_train.npy\n","data/classif-cat-large-0-road-safety/X_cat_test.npy\n","data/classif-cat-large-0-road-safety/X_cat_train.npy\n","data/classif-cat-large-0-road-safety/info.json\n","data/classif-cat-large-0-road-safety/READY\n","data/classif-cat-large-0-road-safety/X_num_test.npy\n","data/classif-cat-large-0-road-safety/Y_test.npy\n","data/classif-cat-large-0-road-safety/Y_train.npy\n","data/classif-num-medium-1-MagicTelescope/\n","data/classif-num-medium-1-MagicTelescope/X_num_val.npy\n","data/classif-num-medium-1-MagicTelescope/Y_val.npy\n","data/classif-num-medium-1-MagicTelescope/X_num_train.npy\n","data/classif-num-medium-1-MagicTelescope/info.json\n","data/classif-num-medium-1-MagicTelescope/READY\n","data/classif-num-medium-1-MagicTelescope/X_num_test.npy\n","data/classif-num-medium-1-MagicTelescope/Y_test.npy\n","data/classif-num-medium-1-MagicTelescope/Y_train.npy\n","data/regression-num-medium-0-wine_quality/\n","data/regression-num-medium-0-wine_quality/X_num_val.npy\n","data/regression-num-medium-0-wine_quality/Y_val.npy\n","data/regression-num-medium-0-wine_quality/X_num_train.npy\n","data/regression-num-medium-0-wine_quality/info.json\n","data/regression-num-medium-0-wine_quality/READY\n","data/regression-num-medium-0-wine_quality/X_num_test.npy\n","data/regression-num-medium-0-wine_quality/Y_test.npy\n","data/regression-num-medium-0-wine_quality/Y_train.npy\n","data/adult/\n","data/adult/X_cat_val.npy\n","data/adult/X_num_val.npy\n","data/adult/Y_val.npy\n","data/adult/X_bin_val.npy\n","data/adult/X_num_train.npy\n","data/adult/X_cat_test.npy\n","data/adult/X_bin_train.npy\n","data/adult/X_cat_train.npy\n","data/adult/info.json\n","data/adult/READY\n","data/adult/X_bin_test.npy\n","data/adult/X_num_test.npy\n","data/adult/Y_test.npy\n","data/adult/Y_train.npy\n","data/classif-num-medium-1-kdd_ipums_la_97-small/\n","data/classif-num-medium-1-kdd_ipums_la_97-small/X_num_val.npy\n","data/classif-num-medium-1-kdd_ipums_la_97-small/Y_val.npy\n","data/classif-num-medium-1-kdd_ipums_la_97-small/X_num_train.npy\n","data/classif-num-medium-1-kdd_ipums_la_97-small/info.json\n","data/classif-num-medium-1-kdd_ipums_la_97-small/READY\n","data/classif-num-medium-1-kdd_ipums_la_97-small/X_num_test.npy\n","data/classif-num-medium-1-kdd_ipums_la_97-small/Y_test.npy\n","data/classif-num-medium-1-kdd_ipums_la_97-small/Y_train.npy\n","data/regression-num-medium-0-superconduct/\n","data/regression-num-medium-0-superconduct/X_num_val.npy\n","data/regression-num-medium-0-superconduct/Y_val.npy\n","data/regression-num-medium-0-superconduct/X_num_train.npy\n","data/regression-num-medium-0-superconduct/info.json\n","data/regression-num-medium-0-superconduct/READY\n","data/regression-num-medium-0-superconduct/X_num_test.npy\n","data/regression-num-medium-0-superconduct/Y_test.npy\n","data/regression-num-medium-0-superconduct/Y_train.npy\n","data/regression-num-medium-0-house_16H/\n","data/regression-num-medium-0-house_16H/X_num_val.npy\n","data/regression-num-medium-0-house_16H/Y_val.npy\n","data/regression-num-medium-0-house_16H/X_num_train.npy\n","data/regression-num-medium-0-house_16H/info.json\n","data/regression-num-medium-0-house_16H/READY\n","data/regression-num-medium-0-house_16H/X_num_test.npy\n","data/regression-num-medium-0-house_16H/Y_test.npy\n","data/regression-num-medium-0-house_16H/Y_train.npy\n","data/weather-big/\n","data/weather-big/X_num_val.npy\n","data/weather-big/Y_val.npy\n","data/weather-big/X_bin_val.npy\n","data/weather-big/X_num_train.npy\n","data/weather-big/X_bin_train.npy\n","data/weather-big/LICENSE.md\n","data/weather-big/info.json\n","data/weather-big/READY\n","data/weather-big/X_bin_test.npy\n","data/weather-big/X_num_test.npy\n","data/weather-big/Y_test.npy\n","data/weather-big/Y_train.npy\n","data/classif-num-large-0-Higgs/\n","data/classif-num-large-0-Higgs/X_num_val.npy\n","data/classif-num-large-0-Higgs/Y_val.npy\n","data/classif-num-large-0-Higgs/X_num_train.npy\n","data/classif-num-large-0-Higgs/info.json\n","data/classif-num-large-0-Higgs/READY\n","data/classif-num-large-0-Higgs/X_num_test.npy\n","data/classif-num-large-0-Higgs/Y_test.npy\n","data/classif-num-large-0-Higgs/Y_train.npy\n","data/regression-cat-medium-2-analcatdata_supreme/\n","data/regression-cat-medium-2-analcatdata_supreme/X_num_val.npy\n","data/regression-cat-medium-2-analcatdata_supreme/Y_val.npy\n","data/regression-cat-medium-2-analcatdata_supreme/X_bin_val.npy\n","data/regression-cat-medium-2-analcatdata_supreme/X_num_train.npy\n","data/regression-cat-medium-2-analcatdata_supreme/X_bin_train.npy\n","data/regression-cat-medium-2-analcatdata_supreme/info.json\n","data/regression-cat-medium-2-analcatdata_supreme/READY\n","data/regression-cat-medium-2-analcatdata_supreme/X_bin_test.npy\n","data/regression-cat-medium-2-analcatdata_supreme/X_num_test.npy\n","data/regression-cat-medium-2-analcatdata_supreme/Y_test.npy\n","data/regression-cat-medium-2-analcatdata_supreme/Y_train.npy\n","data/regression-cat-large-0-black_friday/\n","data/regression-cat-large-0-black_friday/X_cat_val.npy\n","data/regression-cat-large-0-black_friday/X_num_val.npy\n","data/regression-cat-large-0-black_friday/Y_val.npy\n","data/regression-cat-large-0-black_friday/X_bin_val.npy\n","data/regression-cat-large-0-black_friday/X_num_train.npy\n","data/regression-cat-large-0-black_friday/X_cat_test.npy\n","data/regression-cat-large-0-black_friday/X_bin_train.npy\n","data/regression-cat-large-0-black_friday/X_cat_train.npy\n","data/regression-cat-large-0-black_friday/info.json\n","data/regression-cat-large-0-black_friday/READY\n","data/regression-cat-large-0-black_friday/X_bin_test.npy\n","data/regression-cat-large-0-black_friday/X_num_test.npy\n","data/regression-cat-large-0-black_friday/Y_test.npy\n","data/regression-cat-large-0-black_friday/Y_train.npy\n","data/classif-num-medium-1-wine/\n","data/classif-num-medium-1-wine/X_num_val.npy\n","data/classif-num-medium-1-wine/Y_val.npy\n","data/classif-num-medium-1-wine/X_num_train.npy\n","data/classif-num-medium-1-wine/info.json\n","data/classif-num-medium-1-wine/READY\n","data/classif-num-medium-1-wine/X_num_test.npy\n","data/classif-num-medium-1-wine/Y_test.npy\n","data/classif-num-medium-1-wine/Y_train.npy\n","data/regression-cat-medium-0-visualizing_soil/\n","data/regression-cat-medium-0-visualizing_soil/X_num_val.npy\n","data/regression-cat-medium-0-visualizing_soil/Y_val.npy\n","data/regression-cat-medium-0-visualizing_soil/X_bin_val.npy\n","data/regression-cat-medium-0-visualizing_soil/X_num_train.npy\n","data/regression-cat-medium-0-visualizing_soil/X_bin_train.npy\n","data/regression-cat-medium-0-visualizing_soil/info.json\n","data/regression-cat-medium-0-visualizing_soil/READY\n","data/regression-cat-medium-0-visualizing_soil/X_bin_test.npy\n","data/regression-cat-medium-0-visualizing_soil/X_num_test.npy\n","data/regression-cat-medium-0-visualizing_soil/Y_test.npy\n","data/regression-cat-medium-0-visualizing_soil/Y_train.npy\n","data/regression-cat-medium-1-Mercedes_Benz_Greener_Manufacturing/\n","data/regression-cat-medium-1-Mercedes_Benz_Greener_Manufacturing/X_cat_val.npy\n","data/regression-cat-medium-1-Mercedes_Benz_Greener_Manufacturing/Y_val.npy\n","data/regression-cat-medium-1-Mercedes_Benz_Greener_Manufacturing/X_bin_val.npy\n","data/regression-cat-medium-1-Mercedes_Benz_Greener_Manufacturing/X_cat_test.npy\n","data/regression-cat-medium-1-Mercedes_Benz_Greener_Manufacturing/X_bin_train.npy\n","data/regression-cat-medium-1-Mercedes_Benz_Greener_Manufacturing/X_cat_train.npy\n","data/regression-cat-medium-1-Mercedes_Benz_Greener_Manufacturing/info.json\n","data/regression-cat-medium-1-Mercedes_Benz_Greener_Manufacturing/READY\n","data/regression-cat-medium-1-Mercedes_Benz_Greener_Manufacturing/X_bin_test.npy\n","data/regression-cat-medium-1-Mercedes_Benz_Greener_Manufacturing/Y_test.npy\n","data/regression-cat-medium-1-Mercedes_Benz_Greener_Manufacturing/Y_train.npy\n","data/classif-num-medium-0-kdd_ipums_la_97-small/\n","data/classif-num-medium-0-kdd_ipums_la_97-small/X_num_val.npy\n","data/classif-num-medium-0-kdd_ipums_la_97-small/Y_val.npy\n","data/classif-num-medium-0-kdd_ipums_la_97-small/X_num_train.npy\n","data/classif-num-medium-0-kdd_ipums_la_97-small/info.json\n","data/classif-num-medium-0-kdd_ipums_la_97-small/READY\n","data/classif-num-medium-0-kdd_ipums_la_97-small/X_num_test.npy\n","data/classif-num-medium-0-kdd_ipums_la_97-small/Y_test.npy\n","data/classif-num-medium-0-kdd_ipums_la_97-small/Y_train.npy\n","data/regression-num-medium-1-MiamiHousing2016/\n","data/regression-num-medium-1-MiamiHousing2016/X_num_val.npy\n","data/regression-num-medium-1-MiamiHousing2016/Y_val.npy\n","data/regression-num-medium-1-MiamiHousing2016/X_num_train.npy\n","data/regression-num-medium-1-MiamiHousing2016/info.json\n","data/regression-num-medium-1-MiamiHousing2016/READY\n","data/regression-num-medium-1-MiamiHousing2016/X_num_test.npy\n","data/regression-num-medium-1-MiamiHousing2016/Y_test.npy\n","data/regression-num-medium-1-MiamiHousing2016/Y_train.npy\n","data/regression-cat-medium-0-OnlineNewsPopularity/\n","data/regression-cat-medium-0-OnlineNewsPopularity/X_num_val.npy\n","data/regression-cat-medium-0-OnlineNewsPopularity/Y_val.npy\n","data/regression-cat-medium-0-OnlineNewsPopularity/X_bin_val.npy\n","data/regression-cat-medium-0-OnlineNewsPopularity/X_num_train.npy\n","data/regression-cat-medium-0-OnlineNewsPopularity/X_bin_train.npy\n","data/regression-cat-medium-0-OnlineNewsPopularity/info.json\n","data/regression-cat-medium-0-OnlineNewsPopularity/READY\n","data/regression-cat-medium-0-OnlineNewsPopularity/X_bin_test.npy\n","data/regression-cat-medium-0-OnlineNewsPopularity/X_num_test.npy\n","data/regression-cat-medium-0-OnlineNewsPopularity/Y_test.npy\n","data/regression-cat-medium-0-OnlineNewsPopularity/Y_train.npy\n","data/regression-num-medium-1-elevators/\n","data/regression-num-medium-1-elevators/X_num_val.npy\n","data/regression-num-medium-1-elevators/Y_val.npy\n","data/regression-num-medium-1-elevators/X_num_train.npy\n","data/regression-num-medium-1-elevators/info.json\n","data/regression-num-medium-1-elevators/READY\n","data/regression-num-medium-1-elevators/X_num_test.npy\n","data/regression-num-medium-1-elevators/Y_test.npy\n","data/regression-num-medium-1-elevators/Y_train.npy\n","data/regression-num-medium-0-pol/\n","data/regression-num-medium-0-pol/X_num_val.npy\n","data/regression-num-medium-0-pol/Y_val.npy\n","data/regression-num-medium-0-pol/X_num_train.npy\n","data/regression-num-medium-0-pol/info.json\n","data/regression-num-medium-0-pol/READY\n","data/regression-num-medium-0-pol/X_num_test.npy\n","data/regression-num-medium-0-pol/Y_test.npy\n","data/regression-num-medium-0-pol/Y_train.npy\n","data/classif-num-medium-2-kdd_ipums_la_97-small/\n","data/classif-num-medium-2-kdd_ipums_la_97-small/X_num_val.npy\n","data/classif-num-medium-2-kdd_ipums_la_97-small/Y_val.npy\n","data/classif-num-medium-2-kdd_ipums_la_97-small/X_num_train.npy\n","data/classif-num-medium-2-kdd_ipums_la_97-small/info.json\n","data/classif-num-medium-2-kdd_ipums_la_97-small/READY\n","data/classif-num-medium-2-kdd_ipums_la_97-small/X_num_test.npy\n","data/classif-num-medium-2-kdd_ipums_la_97-small/Y_test.npy\n","data/classif-num-medium-2-kdd_ipums_la_97-small/Y_train.npy\n","data/classif-num-medium-0-phoneme/\n","data/classif-num-medium-0-phoneme/X_num_val.npy\n","data/classif-num-medium-0-phoneme/Y_val.npy\n","data/classif-num-medium-0-phoneme/X_num_train.npy\n","data/classif-num-medium-0-phoneme/info.json\n","data/classif-num-medium-0-phoneme/READY\n","data/classif-num-medium-0-phoneme/X_num_test.npy\n","data/classif-num-medium-0-phoneme/Y_test.npy\n","data/classif-num-medium-0-phoneme/Y_train.npy\n","data/regression-num-medium-0-sulfur/\n","data/regression-num-medium-0-sulfur/X_num_val.npy\n","data/regression-num-medium-0-sulfur/Y_val.npy\n","data/regression-num-medium-0-sulfur/X_num_train.npy\n","data/regression-num-medium-0-sulfur/info.json\n","data/regression-num-medium-0-sulfur/READY\n","data/regression-num-medium-0-sulfur/X_num_test.npy\n","data/regression-num-medium-0-sulfur/Y_test.npy\n","data/regression-num-medium-0-sulfur/Y_train.npy\n","data/regression-cat-medium-0-analcatdata_supreme/\n","data/regression-cat-medium-0-analcatdata_supreme/X_num_val.npy\n","data/regression-cat-medium-0-analcatdata_supreme/Y_val.npy\n","data/regression-cat-medium-0-analcatdata_supreme/X_bin_val.npy\n","data/regression-cat-medium-0-analcatdata_supreme/X_num_train.npy\n","data/regression-cat-medium-0-analcatdata_supreme/X_bin_train.npy\n","data/regression-cat-medium-0-analcatdata_supreme/info.json\n","data/regression-cat-medium-0-analcatdata_supreme/READY\n","data/regression-cat-medium-0-analcatdata_supreme/X_bin_test.npy\n","data/regression-cat-medium-0-analcatdata_supreme/X_num_test.npy\n","data/regression-cat-medium-0-analcatdata_supreme/Y_test.npy\n","data/regression-cat-medium-0-analcatdata_supreme/Y_train.npy\n","data/classif-num-medium-2-phoneme/\n","data/classif-num-medium-2-phoneme/X_num_val.npy\n","data/classif-num-medium-2-phoneme/Y_val.npy\n","data/classif-num-medium-2-phoneme/X_num_train.npy\n","data/classif-num-medium-2-phoneme/info.json\n","data/classif-num-medium-2-phoneme/READY\n","data/classif-num-medium-2-phoneme/X_num_test.npy\n","data/classif-num-medium-2-phoneme/Y_test.npy\n","data/classif-num-medium-2-phoneme/Y_train.npy\n","data/regression-cat-large-0-SGEMM_GPU_kernel_performance/\n","data/regression-cat-large-0-SGEMM_GPU_kernel_performance/X_num_val.npy\n","data/regression-cat-large-0-SGEMM_GPU_kernel_performance/Y_val.npy\n","data/regression-cat-large-0-SGEMM_GPU_kernel_performance/X_bin_val.npy\n","data/regression-cat-large-0-SGEMM_GPU_kernel_performance/X_num_train.npy\n","data/regression-cat-large-0-SGEMM_GPU_kernel_performance/X_bin_train.npy\n","data/regression-cat-large-0-SGEMM_GPU_kernel_performance/info.json\n","data/regression-cat-large-0-SGEMM_GPU_kernel_performance/READY\n","data/regression-cat-large-0-SGEMM_GPU_kernel_performance/X_bin_test.npy\n","data/regression-cat-large-0-SGEMM_GPU_kernel_performance/X_num_test.npy\n","data/regression-cat-large-0-SGEMM_GPU_kernel_performance/Y_test.npy\n","data/regression-cat-large-0-SGEMM_GPU_kernel_performance/Y_train.npy\n","data/regression-num-medium-1-wine_quality/\n","data/regression-num-medium-1-wine_quality/X_num_val.npy\n","data/regression-num-medium-1-wine_quality/Y_val.npy\n","data/regression-num-medium-1-wine_quality/X_num_train.npy\n","data/regression-num-medium-1-wine_quality/info.json\n","data/regression-num-medium-1-wine_quality/READY\n","data/regression-num-medium-1-wine_quality/X_num_test.npy\n","data/regression-num-medium-1-wine_quality/Y_test.npy\n","data/regression-num-medium-1-wine_quality/Y_train.npy\n","data/regression-num-medium-0-cpu_act/\n","data/regression-num-medium-0-cpu_act/X_num_val.npy\n","data/regression-num-medium-0-cpu_act/Y_val.npy\n","data/regression-num-medium-0-cpu_act/X_num_train.npy\n","data/regression-num-medium-0-cpu_act/info.json\n","data/regression-num-medium-0-cpu_act/READY\n","data/regression-num-medium-0-cpu_act/X_num_test.npy\n","data/regression-num-medium-0-cpu_act/Y_test.npy\n","data/regression-num-medium-0-cpu_act/Y_train.npy\n","data/regression-cat-medium-0-Bike_Sharing_Demand/\n","data/regression-cat-medium-0-Bike_Sharing_Demand/X_cat_val.npy\n","data/regression-cat-medium-0-Bike_Sharing_Demand/X_num_val.npy\n","data/regression-cat-medium-0-Bike_Sharing_Demand/Y_val.npy\n","data/regression-cat-medium-0-Bike_Sharing_Demand/X_bin_val.npy\n","data/regression-cat-medium-0-Bike_Sharing_Demand/X_num_train.npy\n","data/regression-cat-medium-0-Bike_Sharing_Demand/X_cat_test.npy\n","data/regression-cat-medium-0-Bike_Sharing_Demand/X_bin_train.npy\n","data/regression-cat-medium-0-Bike_Sharing_Demand/X_cat_train.npy\n","data/regression-cat-medium-0-Bike_Sharing_Demand/info.json\n","data/regression-cat-medium-0-Bike_Sharing_Demand/READY\n","data/regression-cat-medium-0-Bike_Sharing_Demand/X_bin_test.npy\n","data/regression-cat-medium-0-Bike_Sharing_Demand/X_num_test.npy\n","data/regression-cat-medium-0-Bike_Sharing_Demand/Y_test.npy\n","data/regression-cat-medium-0-Bike_Sharing_Demand/Y_train.npy\n","data/regression-cat-medium-1-visualizing_soil/\n","data/regression-cat-medium-1-visualizing_soil/X_num_val.npy\n","data/regression-cat-medium-1-visualizing_soil/Y_val.npy\n","data/regression-cat-medium-1-visualizing_soil/X_bin_val.npy\n","data/regression-cat-medium-1-visualizing_soil/X_num_train.npy\n","data/regression-cat-medium-1-visualizing_soil/X_bin_train.npy\n","data/regression-cat-medium-1-visualizing_soil/info.json\n","data/regression-cat-medium-1-visualizing_soil/READY\n","data/regression-cat-medium-1-visualizing_soil/X_bin_test.npy\n","data/regression-cat-medium-1-visualizing_soil/X_num_test.npy\n","data/regression-cat-medium-1-visualizing_soil/Y_test.npy\n","data/regression-cat-medium-1-visualizing_soil/Y_train.npy\n","data/classif-num-medium-4-phoneme/\n","data/classif-num-medium-4-phoneme/X_num_val.npy\n","data/classif-num-medium-4-phoneme/Y_val.npy\n","data/classif-num-medium-4-phoneme/X_num_train.npy\n","data/classif-num-medium-4-phoneme/info.json\n","data/classif-num-medium-4-phoneme/READY\n","data/classif-num-medium-4-phoneme/X_num_test.npy\n","data/classif-num-medium-4-phoneme/Y_test.npy\n","data/classif-num-medium-4-phoneme/Y_train.npy\n","data/house/\n","data/house/X_num_val.npy\n","data/house/Y_val.npy\n","data/house/X_num_train.npy\n","data/house/info.json\n","data/house/READY\n","data/house/X_num_test.npy\n","data/house/Y_test.npy\n","data/house/Y_train.npy\n","data/regression-cat-medium-2-Brazilian_houses/\n","data/regression-cat-medium-2-Brazilian_houses/X_cat_val.npy\n","data/regression-cat-medium-2-Brazilian_houses/X_num_val.npy\n","data/regression-cat-medium-2-Brazilian_houses/Y_val.npy\n","data/regression-cat-medium-2-Brazilian_houses/X_bin_val.npy\n","data/regression-cat-medium-2-Brazilian_houses/X_num_train.npy\n","data/regression-cat-medium-2-Brazilian_houses/X_cat_test.npy\n","data/regression-cat-medium-2-Brazilian_houses/X_bin_train.npy\n","data/regression-cat-medium-2-Brazilian_houses/X_cat_train.npy\n","data/regression-cat-medium-2-Brazilian_houses/info.json\n","data/regression-cat-medium-2-Brazilian_houses/READY\n","data/regression-cat-medium-2-Brazilian_houses/X_bin_test.npy\n","data/regression-cat-medium-2-Brazilian_houses/X_num_test.npy\n","data/regression-cat-medium-2-Brazilian_houses/Y_test.npy\n","data/regression-cat-medium-2-Brazilian_houses/Y_train.npy\n","data/regression-cat-large-0-particulate-matter-ukair-2017/\n","data/regression-cat-large-0-particulate-matter-ukair-2017/X_cat_val.npy\n","data/regression-cat-large-0-particulate-matter-ukair-2017/X_num_val.npy\n","data/regression-cat-large-0-particulate-matter-ukair-2017/Y_val.npy\n","data/regression-cat-large-0-particulate-matter-ukair-2017/X_num_train.npy\n","data/regression-cat-large-0-particulate-matter-ukair-2017/X_cat_test.npy\n","data/regression-cat-large-0-particulate-matter-ukair-2017/X_cat_train.npy\n","data/regression-cat-large-0-particulate-matter-ukair-2017/info.json\n","data/regression-cat-large-0-particulate-matter-ukair-2017/READY\n","data/regression-cat-large-0-particulate-matter-ukair-2017/X_num_test.npy\n","data/regression-cat-large-0-particulate-matter-ukair-2017/Y_test.npy\n","data/regression-cat-large-0-particulate-matter-ukair-2017/Y_train.npy\n","data/regression-cat-medium-2-Mercedes_Benz_Greener_Manufacturing/\n","data/regression-cat-medium-2-Mercedes_Benz_Greener_Manufacturing/X_cat_val.npy\n","data/regression-cat-medium-2-Mercedes_Benz_Greener_Manufacturing/Y_val.npy\n","data/regression-cat-medium-2-Mercedes_Benz_Greener_Manufacturing/X_bin_val.npy\n","data/regression-cat-medium-2-Mercedes_Benz_Greener_Manufacturing/X_cat_test.npy\n","data/regression-cat-medium-2-Mercedes_Benz_Greener_Manufacturing/X_bin_train.npy\n","data/regression-cat-medium-2-Mercedes_Benz_Greener_Manufacturing/X_cat_train.npy\n","data/regression-cat-medium-2-Mercedes_Benz_Greener_Manufacturing/info.json\n","data/regression-cat-medium-2-Mercedes_Benz_Greener_Manufacturing/READY\n","data/regression-cat-medium-2-Mercedes_Benz_Greener_Manufacturing/X_bin_test.npy\n","data/regression-cat-medium-2-Mercedes_Benz_Greener_Manufacturing/Y_test.npy\n","data/regression-cat-medium-2-Mercedes_Benz_Greener_Manufacturing/Y_train.npy\n","data/black-friday/\n","data/black-friday/X_cat_val.npy\n","data/black-friday/X_num_val.npy\n","data/black-friday/Y_val.npy\n","data/black-friday/X_bin_val.npy\n","data/black-friday/X_num_train.npy\n","data/black-friday/X_cat_test.npy\n","data/black-friday/X_bin_train.npy\n","data/black-friday/X_cat_train.npy\n","data/black-friday/info.json\n","data/black-friday/X_bin_test.npy\n","data/black-friday/X_num_test.npy\n","data/black-friday/Y_test.npy\n","data/black-friday/Y_train.npy\n","data/regression-num-medium-1-sulfur/\n","data/regression-num-medium-1-sulfur/X_num_val.npy\n","data/regression-num-medium-1-sulfur/Y_val.npy\n","data/regression-num-medium-1-sulfur/X_num_train.npy\n","data/regression-num-medium-1-sulfur/info.json\n","data/regression-num-medium-1-sulfur/READY\n","data/regression-num-medium-1-sulfur/X_num_test.npy\n","data/regression-num-medium-1-sulfur/Y_test.npy\n","data/regression-num-medium-1-sulfur/Y_train.npy\n","data/classif-num-medium-0-wine/\n","data/classif-num-medium-0-wine/X_num_val.npy\n","data/classif-num-medium-0-wine/Y_val.npy\n","data/classif-num-medium-0-wine/X_num_train.npy\n","data/classif-num-medium-0-wine/info.json\n","data/classif-num-medium-0-wine/READY\n","data/classif-num-medium-0-wine/X_num_test.npy\n","data/classif-num-medium-0-wine/Y_test.npy\n","data/classif-num-medium-0-wine/Y_train.npy\n","data/covtype/\n","data/covtype/X_num_val.npy\n","data/covtype/Y_val.npy\n","data/covtype/X_bin_val.npy\n","data/covtype/X_num_train.npy\n","data/covtype/X_bin_train.npy\n","data/covtype/info.json\n","data/covtype/READY\n","data/covtype/X_bin_test.npy\n","data/covtype/X_num_test.npy\n","data/covtype/Y_test.npy\n","data/covtype/Y_train.npy\n","data/regression-cat-large-0-nyc-taxi-green-dec-2016/\n","data/regression-cat-large-0-nyc-taxi-green-dec-2016/X_cat_val.npy\n","data/regression-cat-large-0-nyc-taxi-green-dec-2016/X_num_val.npy\n","data/regression-cat-large-0-nyc-taxi-green-dec-2016/Y_val.npy\n","data/regression-cat-large-0-nyc-taxi-green-dec-2016/X_bin_val.npy\n","data/regression-cat-large-0-nyc-taxi-green-dec-2016/X_num_train.npy\n","data/regression-cat-large-0-nyc-taxi-green-dec-2016/X_cat_test.npy\n","data/regression-cat-large-0-nyc-taxi-green-dec-2016/X_bin_train.npy\n","data/regression-cat-large-0-nyc-taxi-green-dec-2016/X_cat_train.npy\n","data/regression-cat-large-0-nyc-taxi-green-dec-2016/info.json\n","data/regression-cat-large-0-nyc-taxi-green-dec-2016/READY\n","data/regression-cat-large-0-nyc-taxi-green-dec-2016/X_bin_test.npy\n","data/regression-cat-large-0-nyc-taxi-green-dec-2016/X_num_test.npy\n","data/regression-cat-large-0-nyc-taxi-green-dec-2016/Y_test.npy\n","data/regression-cat-large-0-nyc-taxi-green-dec-2016/Y_train.npy\n","data/classif-num-medium-0-MagicTelescope/\n","data/classif-num-medium-0-MagicTelescope/X_num_val.npy\n","data/classif-num-medium-0-MagicTelescope/Y_val.npy\n","data/classif-num-medium-0-MagicTelescope/X_num_train.npy\n","data/classif-num-medium-0-MagicTelescope/info.json\n","data/classif-num-medium-0-MagicTelescope/READY\n","data/classif-num-medium-0-MagicTelescope/X_num_test.npy\n","data/classif-num-medium-0-MagicTelescope/Y_test.npy\n","data/classif-num-medium-0-MagicTelescope/Y_train.npy\n","data/regression-cat-medium-3-analcatdata_supreme/\n","data/regression-cat-medium-3-analcatdata_supreme/X_num_val.npy\n","data/regression-cat-medium-3-analcatdata_supreme/Y_val.npy\n","data/regression-cat-medium-3-analcatdata_supreme/X_bin_val.npy\n","data/regression-cat-medium-3-analcatdata_supreme/X_num_train.npy\n","data/regression-cat-medium-3-analcatdata_supreme/X_bin_train.npy\n","data/regression-cat-medium-3-analcatdata_supreme/info.json\n","data/regression-cat-medium-3-analcatdata_supreme/READY\n","data/regression-cat-medium-3-analcatdata_supreme/X_bin_test.npy\n","data/regression-cat-medium-3-analcatdata_supreme/X_num_test.npy\n","data/regression-cat-medium-3-analcatdata_supreme/Y_test.npy\n","data/regression-cat-medium-3-analcatdata_supreme/Y_train.npy\n","data/regression-cat-medium-0-Mercedes_Benz_Greener_Manufacturing/\n","data/regression-cat-medium-0-Mercedes_Benz_Greener_Manufacturing/X_cat_val.npy\n","data/regression-cat-medium-0-Mercedes_Benz_Greener_Manufacturing/Y_val.npy\n","data/regression-cat-medium-0-Mercedes_Benz_Greener_Manufacturing/X_bin_val.npy\n","data/regression-cat-medium-0-Mercedes_Benz_Greener_Manufacturing/X_cat_test.npy\n","data/regression-cat-medium-0-Mercedes_Benz_Greener_Manufacturing/X_bin_train.npy\n","data/regression-cat-medium-0-Mercedes_Benz_Greener_Manufacturing/X_cat_train.npy\n","data/regression-cat-medium-0-Mercedes_Benz_Greener_Manufacturing/info.json\n","data/regression-cat-medium-0-Mercedes_Benz_Greener_Manufacturing/READY\n","data/regression-cat-medium-0-Mercedes_Benz_Greener_Manufacturing/X_bin_test.npy\n","data/regression-cat-medium-0-Mercedes_Benz_Greener_Manufacturing/Y_test.npy\n","data/regression-cat-medium-0-Mercedes_Benz_Greener_Manufacturing/Y_train.npy\n","data/microsoft/\n","data/microsoft/X_num_val.npy\n","data/microsoft/Y_val.npy\n","data/microsoft/X_bin_val.npy\n","data/microsoft/X_num_train.npy\n","data/microsoft/X_bin_train.npy\n","data/microsoft/info.json\n","data/microsoft/READY\n","data/microsoft/X_bin_test.npy\n","data/microsoft/X_num_test.npy\n","data/microsoft/Y_test.npy\n","data/microsoft/Y_train.npy\n","data/regression-cat-medium-4-analcatdata_supreme/\n","data/regression-cat-medium-4-analcatdata_supreme/X_num_val.npy\n","data/regression-cat-medium-4-analcatdata_supreme/Y_val.npy\n","data/regression-cat-medium-4-analcatdata_supreme/X_bin_val.npy\n","data/regression-cat-medium-4-analcatdata_supreme/X_num_train.npy\n","data/regression-cat-medium-4-analcatdata_supreme/X_bin_train.npy\n","data/regression-cat-medium-4-analcatdata_supreme/info.json\n","data/regression-cat-medium-4-analcatdata_supreme/READY\n","data/regression-cat-medium-4-analcatdata_supreme/X_bin_test.npy\n","data/regression-cat-medium-4-analcatdata_supreme/X_num_test.npy\n","data/regression-cat-medium-4-analcatdata_supreme/Y_test.npy\n","data/regression-cat-medium-4-analcatdata_supreme/Y_train.npy\n","data/regression-num-medium-1-fifa/\n","data/regression-num-medium-1-fifa/X_num_val.npy\n","data/regression-num-medium-1-fifa/Y_val.npy\n","data/regression-num-medium-1-fifa/X_num_train.npy\n","data/regression-num-medium-1-fifa/info.json\n","data/regression-num-medium-1-fifa/READY\n","data/regression-num-medium-1-fifa/X_num_test.npy\n","data/regression-num-medium-1-fifa/Y_test.npy\n","data/regression-num-medium-1-fifa/Y_train.npy\n","data/regression-num-medium-0-isolet/\n","data/regression-num-medium-0-isolet/X_num_val.npy\n","data/regression-num-medium-0-isolet/Y_val.npy\n","data/regression-num-medium-0-isolet/X_num_train.npy\n","data/regression-num-medium-0-isolet/info.json\n","data/regression-num-medium-0-isolet/READY\n","data/regression-num-medium-0-isolet/X_num_test.npy\n","data/regression-num-medium-0-isolet/Y_test.npy\n","data/regression-num-medium-0-isolet/Y_train.npy\n","data/classif-num-medium-3-phoneme/\n","data/classif-num-medium-3-phoneme/X_num_val.npy\n","data/classif-num-medium-3-phoneme/Y_val.npy\n","data/classif-num-medium-3-phoneme/X_num_train.npy\n","data/classif-num-medium-3-phoneme/info.json\n","data/classif-num-medium-3-phoneme/READY\n","data/classif-num-medium-3-phoneme/X_num_test.npy\n","data/classif-num-medium-3-phoneme/Y_test.npy\n","data/classif-num-medium-3-phoneme/Y_train.npy\n","data/regression-cat-medium-3-Mercedes_Benz_Greener_Manufacturing/\n","data/regression-cat-medium-3-Mercedes_Benz_Greener_Manufacturing/X_cat_val.npy\n","data/regression-cat-medium-3-Mercedes_Benz_Greener_Manufacturing/Y_val.npy\n","data/regression-cat-medium-3-Mercedes_Benz_Greener_Manufacturing/X_bin_val.npy\n","data/regression-cat-medium-3-Mercedes_Benz_Greener_Manufacturing/X_cat_test.npy\n","data/regression-cat-medium-3-Mercedes_Benz_Greener_Manufacturing/X_bin_train.npy\n","data/regression-cat-medium-3-Mercedes_Benz_Greener_Manufacturing/X_cat_train.npy\n","data/regression-cat-medium-3-Mercedes_Benz_Greener_Manufacturing/info.json\n","data/regression-cat-medium-3-Mercedes_Benz_Greener_Manufacturing/READY\n","data/regression-cat-medium-3-Mercedes_Benz_Greener_Manufacturing/X_bin_test.npy\n","data/regression-cat-medium-3-Mercedes_Benz_Greener_Manufacturing/Y_test.npy\n","data/regression-cat-medium-3-Mercedes_Benz_Greener_Manufacturing/Y_train.npy\n","data/california/\n","data/california/X_num_val.npy\n","data/california/Y_val.npy\n","data/california/X_num_train.npy\n","data/california/info.json\n","data/california/READY\n","data/california/X_num_test.npy\n","data/california/Y_test.npy\n","data/california/Y_train.npy\n","data/classif-cat-medium-2-rl/\n","data/classif-cat-medium-2-rl/X_cat_val.npy\n","data/classif-cat-medium-2-rl/X_num_val.npy\n","data/classif-cat-medium-2-rl/Y_val.npy\n","data/classif-cat-medium-2-rl/X_bin_val.npy\n","data/classif-cat-medium-2-rl/X_num_train.npy\n","data/classif-cat-medium-2-rl/X_cat_test.npy\n","data/classif-cat-medium-2-rl/X_bin_train.npy\n","data/classif-cat-medium-2-rl/X_cat_train.npy\n","data/classif-cat-medium-2-rl/info.json\n","data/classif-cat-medium-2-rl/READY\n","data/classif-cat-medium-2-rl/X_bin_test.npy\n","data/classif-cat-medium-2-rl/X_num_test.npy\n","data/classif-cat-medium-2-rl/Y_test.npy\n","data/classif-cat-medium-2-rl/Y_train.npy\n","data/regression-cat-medium-0-Brazilian_houses/\n","data/regression-cat-medium-0-Brazilian_houses/X_cat_val.npy\n","data/regression-cat-medium-0-Brazilian_houses/X_num_val.npy\n","data/regression-cat-medium-0-Brazilian_houses/Y_val.npy\n","data/regression-cat-medium-0-Brazilian_houses/X_bin_val.npy\n","data/regression-cat-medium-0-Brazilian_houses/X_num_train.npy\n","data/regression-cat-medium-0-Brazilian_houses/X_cat_test.npy\n","data/regression-cat-medium-0-Brazilian_houses/X_bin_train.npy\n","data/regression-cat-medium-0-Brazilian_houses/X_cat_train.npy\n","data/regression-cat-medium-0-Brazilian_houses/info.json\n","data/regression-cat-medium-0-Brazilian_houses/READY\n","data/regression-cat-medium-0-Brazilian_houses/X_bin_test.npy\n","data/regression-cat-medium-0-Brazilian_houses/X_num_test.npy\n","data/regression-cat-medium-0-Brazilian_houses/Y_test.npy\n","data/regression-cat-medium-0-Brazilian_houses/Y_train.npy\n","data/regression-cat-medium-1-analcatdata_supreme/\n","data/regression-cat-medium-1-analcatdata_supreme/X_num_val.npy\n","data/regression-cat-medium-1-analcatdata_supreme/Y_val.npy\n","data/regression-cat-medium-1-analcatdata_supreme/X_bin_val.npy\n","data/regression-cat-medium-1-analcatdata_supreme/X_num_train.npy\n","data/regression-cat-medium-1-analcatdata_supreme/X_bin_train.npy\n","data/regression-cat-medium-1-analcatdata_supreme/info.json\n","data/regression-cat-medium-1-analcatdata_supreme/READY\n","data/regression-cat-medium-1-analcatdata_supreme/X_bin_test.npy\n","data/regression-cat-medium-1-analcatdata_supreme/X_num_test.npy\n","data/regression-cat-medium-1-analcatdata_supreme/Y_test.npy\n","data/regression-cat-medium-1-analcatdata_supreme/Y_train.npy\n","data/classif-num-medium-2-MagicTelescope/\n","data/classif-num-medium-2-MagicTelescope/X_num_val.npy\n","data/classif-num-medium-2-MagicTelescope/Y_val.npy\n","data/classif-num-medium-2-MagicTelescope/X_num_train.npy\n","data/classif-num-medium-2-MagicTelescope/info.json\n","data/classif-num-medium-2-MagicTelescope/READY\n","data/classif-num-medium-2-MagicTelescope/X_num_test.npy\n","data/classif-num-medium-2-MagicTelescope/Y_test.npy\n","data/classif-num-medium-2-MagicTelescope/Y_train.npy\n","data/classif-cat-medium-1-rl/\n","data/classif-cat-medium-1-rl/X_cat_val.npy\n","data/classif-cat-medium-1-rl/X_num_val.npy\n","data/classif-cat-medium-1-rl/Y_val.npy\n","data/classif-cat-medium-1-rl/X_bin_val.npy\n","data/classif-cat-medium-1-rl/X_num_train.npy\n","data/classif-cat-medium-1-rl/X_cat_test.npy\n","data/classif-cat-medium-1-rl/X_bin_train.npy\n","data/classif-cat-medium-1-rl/X_cat_train.npy\n","data/classif-cat-medium-1-rl/info.json\n","data/classif-cat-medium-1-rl/READY\n","data/classif-cat-medium-1-rl/X_bin_test.npy\n","data/classif-cat-medium-1-rl/X_num_test.npy\n","data/classif-cat-medium-1-rl/Y_test.npy\n","data/classif-cat-medium-1-rl/Y_train.npy\n","data/classif-cat-medium-0-compass/\n","data/classif-cat-medium-0-compass/X_cat_val.npy\n","data/classif-cat-medium-0-compass/X_num_val.npy\n","data/classif-cat-medium-0-compass/Y_val.npy\n","data/classif-cat-medium-0-compass/X_bin_val.npy\n","data/classif-cat-medium-0-compass/X_num_train.npy\n","data/classif-cat-medium-0-compass/X_cat_test.npy\n","data/classif-cat-medium-0-compass/X_bin_train.npy\n","data/classif-cat-medium-0-compass/X_cat_train.npy\n","data/classif-cat-medium-0-compass/info.json\n","data/classif-cat-medium-0-compass/READY\n","data/classif-cat-medium-0-compass/X_bin_test.npy\n","data/classif-cat-medium-0-compass/X_num_test.npy\n","data/classif-cat-medium-0-compass/Y_test.npy\n","data/classif-cat-medium-0-compass/Y_train.npy\n","data/regression-cat-medium-2-yprop_4_1/\n","data/regression-cat-medium-2-yprop_4_1/X_num_val.npy\n","data/regression-cat-medium-2-yprop_4_1/Y_val.npy\n","data/regression-cat-medium-2-yprop_4_1/X_bin_val.npy\n","data/regression-cat-medium-2-yprop_4_1/X_num_train.npy\n","data/regression-cat-medium-2-yprop_4_1/X_bin_train.npy\n","data/regression-cat-medium-2-yprop_4_1/info.json\n","data/regression-cat-medium-2-yprop_4_1/READY\n","data/regression-cat-medium-2-yprop_4_1/X_bin_test.npy\n","data/regression-cat-medium-2-yprop_4_1/X_num_test.npy\n","data/regression-cat-medium-2-yprop_4_1/Y_test.npy\n","data/regression-cat-medium-2-yprop_4_1/Y_train.npy\n","data/weather-small/\n","data/weather-small/X_num_val.npy\n","data/weather-small/Y_val.npy\n","data/weather-small/X_bin_val.npy\n","data/weather-small/X_num_train.npy\n","data/weather-small/X_bin_train.npy\n","data/weather-small/info.json\n","data/weather-small/READY\n","data/weather-small/X_bin_test.npy\n","data/weather-small/X_num_test.npy\n","data/weather-small/Y_test.npy\n","data/weather-small/Y_train.npy\n","data/diamond/\n","data/diamond/X_cat_val.npy\n","data/diamond/X_num_val.npy\n","data/diamond/Y_val.npy\n","data/diamond/X_num_train.npy\n","data/diamond/X_cat_test.npy\n","data/diamond/X_cat_train.npy\n","data/diamond/info.json\n","data/diamond/X_num_test.npy\n","data/diamond/Y_test.npy\n","data/diamond/Y_train.npy\n","data/regression-num-medium-0-fifa/\n","data/regression-num-medium-0-fifa/X_num_val.npy\n","data/regression-num-medium-0-fifa/Y_val.npy\n","data/regression-num-medium-0-fifa/X_num_train.npy\n","data/regression-num-medium-0-fifa/info.json\n","data/regression-num-medium-0-fifa/READY\n","data/regression-num-medium-0-fifa/X_num_test.npy\n","data/regression-num-medium-0-fifa/Y_test.npy\n","data/regression-num-medium-0-fifa/Y_train.npy\n","data/regression-num-medium-1-cpu_act/\n","data/regression-num-medium-1-cpu_act/X_num_val.npy\n","data/regression-num-medium-1-cpu_act/Y_val.npy\n","data/regression-num-medium-1-cpu_act/X_num_train.npy\n","data/regression-num-medium-1-cpu_act/info.json\n","data/regression-num-medium-1-cpu_act/READY\n","data/regression-num-medium-1-cpu_act/X_num_test.npy\n","data/regression-num-medium-1-cpu_act/Y_test.npy\n","data/regression-num-medium-1-cpu_act/Y_train.npy\n","data/regression-num-medium-1-pol/\n","data/regression-num-medium-1-pol/X_num_val.npy\n","data/regression-num-medium-1-pol/Y_val.npy\n","data/regression-num-medium-1-pol/X_num_train.npy\n","data/regression-num-medium-1-pol/info.json\n","data/regression-num-medium-1-pol/READY\n","data/regression-num-medium-1-pol/X_num_test.npy\n","data/regression-num-medium-1-pol/Y_test.npy\n","data/regression-num-medium-1-pol/Y_train.npy\n","data/regression-num-medium-0-elevators/\n","data/regression-num-medium-0-elevators/X_num_val.npy\n","data/regression-num-medium-0-elevators/Y_val.npy\n","data/regression-num-medium-0-elevators/X_num_train.npy\n","data/regression-num-medium-0-elevators/info.json\n","data/regression-num-medium-0-elevators/READY\n","data/regression-num-medium-0-elevators/X_num_test.npy\n","data/regression-num-medium-0-elevators/Y_test.npy\n","data/regression-num-medium-0-elevators/Y_train.npy\n","data/regression-cat-medium-4-Mercedes_Benz_Greener_Manufacturing/\n","data/regression-cat-medium-4-Mercedes_Benz_Greener_Manufacturing/X_cat_val.npy\n","data/regression-cat-medium-4-Mercedes_Benz_Greener_Manufacturing/Y_val.npy\n","data/regression-cat-medium-4-Mercedes_Benz_Greener_Manufacturing/X_bin_val.npy\n","data/regression-cat-medium-4-Mercedes_Benz_Greener_Manufacturing/X_cat_test.npy\n","data/regression-cat-medium-4-Mercedes_Benz_Greener_Manufacturing/X_bin_train.npy\n","data/regression-cat-medium-4-Mercedes_Benz_Greener_Manufacturing/X_cat_train.npy\n","data/regression-cat-medium-4-Mercedes_Benz_Greener_Manufacturing/info.json\n","data/regression-cat-medium-4-Mercedes_Benz_Greener_Manufacturing/READY\n","data/regression-cat-medium-4-Mercedes_Benz_Greener_Manufacturing/X_bin_test.npy\n","data/regression-cat-medium-4-Mercedes_Benz_Greener_Manufacturing/Y_test.npy\n","data/regression-cat-medium-4-Mercedes_Benz_Greener_Manufacturing/Y_train.npy\n","data/regression-num-medium-2-MiamiHousing2016/\n","data/regression-num-medium-2-MiamiHousing2016/X_num_val.npy\n","data/regression-num-medium-2-MiamiHousing2016/Y_val.npy\n","data/regression-num-medium-2-MiamiHousing2016/X_num_train.npy\n","data/regression-num-medium-2-MiamiHousing2016/info.json\n","data/regression-num-medium-2-MiamiHousing2016/READY\n","data/regression-num-medium-2-MiamiHousing2016/X_num_test.npy\n","data/regression-num-medium-2-MiamiHousing2016/Y_test.npy\n","data/regression-num-medium-2-MiamiHousing2016/Y_train.npy\n","data/regression-num-medium-1-Ailerons/\n","data/regression-num-medium-1-Ailerons/X_num_val.npy\n","data/regression-num-medium-1-Ailerons/Y_val.npy\n","data/regression-num-medium-1-Ailerons/X_num_train.npy\n","data/regression-num-medium-1-Ailerons/info.json\n","data/regression-num-medium-1-Ailerons/READY\n","data/regression-num-medium-1-Ailerons/X_num_test.npy\n","data/regression-num-medium-1-Ailerons/Y_test.npy\n","data/regression-num-medium-1-Ailerons/Y_train.npy\n","data/regression-num-medium-0-medical_charges/\n","data/regression-num-medium-0-medical_charges/X_num_val.npy\n","data/regression-num-medium-0-medical_charges/Y_val.npy\n","data/regression-num-medium-0-medical_charges/X_num_train.npy\n","data/regression-num-medium-0-medical_charges/info.json\n","data/regression-num-medium-0-medical_charges/READY\n","data/regression-num-medium-0-medical_charges/X_num_test.npy\n","data/regression-num-medium-0-medical_charges/Y_test.npy\n","data/regression-num-medium-0-medical_charges/Y_train.npy\n","data/classif-num-medium-0-bank-marketing/\n","data/classif-num-medium-0-bank-marketing/X_num_val.npy\n","data/classif-num-medium-0-bank-marketing/Y_val.npy\n","data/classif-num-medium-0-bank-marketing/X_num_train.npy\n","data/classif-num-medium-0-bank-marketing/info.json\n","data/classif-num-medium-0-bank-marketing/READY\n","data/classif-num-medium-0-bank-marketing/X_num_test.npy\n","data/classif-num-medium-0-bank-marketing/Y_test.npy\n","data/classif-num-medium-0-bank-marketing/Y_train.npy\n","data/classif-num-medium-3-wine/\n","data/classif-num-medium-3-wine/X_num_val.npy\n","data/classif-num-medium-3-wine/Y_val.npy\n","data/classif-num-medium-3-wine/X_num_train.npy\n","data/classif-num-medium-3-wine/info.json\n","data/classif-num-medium-3-wine/READY\n","data/classif-num-medium-3-wine/X_num_test.npy\n","data/classif-num-medium-3-wine/Y_test.npy\n","data/classif-num-medium-3-wine/Y_train.npy\n","data/classif-num-medium-2-bank-marketing/\n","data/classif-num-medium-2-bank-marketing/X_num_val.npy\n","data/classif-num-medium-2-bank-marketing/Y_val.npy\n","data/classif-num-medium-2-bank-marketing/X_num_train.npy\n","data/classif-num-medium-2-bank-marketing/info.json\n","data/classif-num-medium-2-bank-marketing/READY\n","data/classif-num-medium-2-bank-marketing/X_num_test.npy\n","data/classif-num-medium-2-bank-marketing/Y_test.npy\n","data/classif-num-medium-2-bank-marketing/Y_train.npy\n","data/classif-num-large-0-jannis/\n","data/classif-num-large-0-jannis/X_num_val.npy\n","data/classif-num-large-0-jannis/Y_val.npy\n","data/classif-num-large-0-jannis/X_num_train.npy\n","data/classif-num-large-0-jannis/info.json\n","data/classif-num-large-0-jannis/READY\n","data/classif-num-large-0-jannis/X_num_test.npy\n","data/classif-num-large-0-jannis/Y_test.npy\n","data/classif-num-large-0-jannis/Y_train.npy\n","data/regression-num-medium-0-houses/\n","data/regression-num-medium-0-houses/X_num_val.npy\n","data/regression-num-medium-0-houses/Y_val.npy\n","data/regression-num-medium-0-houses/X_num_train.npy\n","data/regression-num-medium-0-houses/info.json\n","data/regression-num-medium-0-houses/READY\n","data/regression-num-medium-0-houses/X_num_test.npy\n","data/regression-num-medium-0-houses/Y_test.npy\n","data/regression-num-medium-0-houses/Y_train.npy\n","data/regression-num-large-0-year/\n","data/regression-num-large-0-year/X_num_val.npy\n","data/regression-num-large-0-year/Y_val.npy\n","data/regression-num-large-0-year/X_num_train.npy\n","data/regression-num-large-0-year/info.json\n","data/regression-num-large-0-year/READY\n","data/regression-num-large-0-year/X_num_test.npy\n","data/regression-num-large-0-year/Y_test.npy\n","data/regression-num-large-0-year/Y_train.npy\n","data/classif-cat-medium-1-KDDCup09_upselling/\n","data/classif-cat-medium-1-KDDCup09_upselling/X_cat_val.npy\n","data/classif-cat-medium-1-KDDCup09_upselling/X_num_val.npy\n","data/classif-cat-medium-1-KDDCup09_upselling/Y_val.npy\n","data/classif-cat-medium-1-KDDCup09_upselling/X_bin_val.npy\n","data/classif-cat-medium-1-KDDCup09_upselling/X_num_train.npy\n","data/classif-cat-medium-1-KDDCup09_upselling/X_cat_test.npy\n","data/classif-cat-medium-1-KDDCup09_upselling/X_bin_train.npy\n","data/classif-cat-medium-1-KDDCup09_upselling/X_cat_train.npy\n","data/classif-cat-medium-1-KDDCup09_upselling/info.json\n","data/classif-cat-medium-1-KDDCup09_upselling/READY\n","data/classif-cat-medium-1-KDDCup09_upselling/X_bin_test.npy\n","data/classif-cat-medium-1-KDDCup09_upselling/X_num_test.npy\n","data/classif-cat-medium-1-KDDCup09_upselling/Y_test.npy\n","data/classif-cat-medium-1-KDDCup09_upselling/Y_train.npy\n","data/classif-cat-medium-0-KDDCup09_upselling/\n","data/classif-cat-medium-0-KDDCup09_upselling/X_cat_val.npy\n","data/classif-cat-medium-0-KDDCup09_upselling/X_num_val.npy\n","data/classif-cat-medium-0-KDDCup09_upselling/Y_val.npy\n","data/classif-cat-medium-0-KDDCup09_upselling/X_bin_val.npy\n","data/classif-cat-medium-0-KDDCup09_upselling/X_num_train.npy\n","data/classif-cat-medium-0-KDDCup09_upselling/X_cat_test.npy\n","data/classif-cat-medium-0-KDDCup09_upselling/X_bin_train.npy\n","data/classif-cat-medium-0-KDDCup09_upselling/X_cat_train.npy\n","data/classif-cat-medium-0-KDDCup09_upselling/info.json\n","data/classif-cat-medium-0-KDDCup09_upselling/READY\n","data/classif-cat-medium-0-KDDCup09_upselling/X_bin_test.npy\n","data/classif-cat-medium-0-KDDCup09_upselling/X_num_test.npy\n","data/classif-cat-medium-0-KDDCup09_upselling/Y_test.npy\n","data/classif-cat-medium-0-KDDCup09_upselling/Y_train.npy\n","data/classif-num-large-0-MiniBooNE/\n","data/classif-num-large-0-MiniBooNE/X_num_val.npy\n","data/classif-num-large-0-MiniBooNE/Y_val.npy\n","data/classif-num-large-0-MiniBooNE/X_num_train.npy\n","data/classif-num-large-0-MiniBooNE/info.json\n","data/classif-num-large-0-MiniBooNE/READY\n","data/classif-num-large-0-MiniBooNE/X_num_test.npy\n","data/classif-num-large-0-MiniBooNE/Y_test.npy\n","data/classif-num-large-0-MiniBooNE/Y_train.npy\n","data/regression-num-medium-0-MiamiHousing2016/\n","data/regression-num-medium-0-MiamiHousing2016/X_num_val.npy\n","data/regression-num-medium-0-MiamiHousing2016/Y_val.npy\n","data/regression-num-medium-0-MiamiHousing2016/X_num_train.npy\n","data/regression-num-medium-0-MiamiHousing2016/info.json\n","data/regression-num-medium-0-MiamiHousing2016/READY\n","data/regression-num-medium-0-MiamiHousing2016/X_num_test.npy\n","data/regression-num-medium-0-MiamiHousing2016/Y_test.npy\n","data/regression-num-medium-0-MiamiHousing2016/Y_train.npy\n","data/regression-num-medium-2-Ailerons/\n","data/regression-num-medium-2-Ailerons/X_num_val.npy\n","data/regression-num-medium-2-Ailerons/Y_val.npy\n","data/regression-num-medium-2-Ailerons/X_num_train.npy\n","data/regression-num-medium-2-Ailerons/info.json\n","data/regression-num-medium-2-Ailerons/READY\n","data/regression-num-medium-2-Ailerons/X_num_test.npy\n","data/regression-num-medium-2-Ailerons/Y_test.npy\n","data/regression-num-medium-2-Ailerons/Y_train.npy\n","data/classif-num-medium-0-credit/\n","data/classif-num-medium-0-credit/X_num_val.npy\n","data/classif-num-medium-0-credit/Y_val.npy\n","data/classif-num-medium-0-credit/X_num_train.npy\n","data/classif-num-medium-0-credit/info.json\n","data/classif-num-medium-0-credit/READY\n","data/classif-num-medium-0-credit/X_num_test.npy\n","data/classif-num-medium-0-credit/Y_test.npy\n","data/classif-num-medium-0-credit/Y_train.npy\n","data/classif-num-medium-4-wine/\n","data/classif-num-medium-4-wine/X_num_val.npy\n","data/classif-num-medium-4-wine/Y_val.npy\n","data/classif-num-medium-4-wine/X_num_train.npy\n","data/classif-num-medium-4-wine/info.json\n","data/classif-num-medium-4-wine/READY\n","data/classif-num-medium-4-wine/X_num_test.npy\n","data/classif-num-medium-4-wine/Y_test.npy\n","data/classif-num-medium-4-wine/Y_train.npy\n","data/higgs-small/\n","data/higgs-small/X_num_val.npy\n","data/higgs-small/Y_val.npy\n","data/higgs-small/X_num_train.npy\n","data/higgs-small/info.json\n","data/higgs-small/READY\n","data/higgs-small/X_num_test.npy\n","data/higgs-small/Y_test.npy\n","data/higgs-small/Y_train.npy\n","data/classif-cat-medium-1-compass/\n","data/classif-cat-medium-1-compass/X_cat_val.npy\n","data/classif-cat-medium-1-compass/X_num_val.npy\n","data/classif-cat-medium-1-compass/Y_val.npy\n","data/classif-cat-medium-1-compass/X_bin_val.npy\n","data/classif-cat-medium-1-compass/X_num_train.npy\n","data/classif-cat-medium-1-compass/X_cat_test.npy\n","data/classif-cat-medium-1-compass/X_bin_train.npy\n","data/classif-cat-medium-1-compass/X_cat_train.npy\n","data/classif-cat-medium-1-compass/info.json\n","data/classif-cat-medium-1-compass/READY\n","data/classif-cat-medium-1-compass/X_bin_test.npy\n","data/classif-cat-medium-1-compass/X_num_test.npy\n","data/classif-cat-medium-1-compass/Y_test.npy\n","data/classif-cat-medium-1-compass/Y_train.npy\n","data/classif-cat-medium-0-rl/\n","data/classif-cat-medium-0-rl/X_cat_val.npy\n","data/classif-cat-medium-0-rl/X_num_val.npy\n","data/classif-cat-medium-0-rl/Y_val.npy\n","data/classif-cat-medium-0-rl/X_bin_val.npy\n","data/classif-cat-medium-0-rl/X_num_train.npy\n","data/classif-cat-medium-0-rl/X_cat_test.npy\n","data/classif-cat-medium-0-rl/X_bin_train.npy\n","data/classif-cat-medium-0-rl/X_cat_train.npy\n","data/classif-cat-medium-0-rl/info.json\n","data/classif-cat-medium-0-rl/READY\n","data/classif-cat-medium-0-rl/X_bin_test.npy\n","data/classif-cat-medium-0-rl/X_num_test.npy\n","data/classif-cat-medium-0-rl/Y_test.npy\n","data/classif-cat-medium-0-rl/Y_train.npy\n","data/regression-num-medium-2-cpu_act/\n","data/regression-num-medium-2-cpu_act/X_num_val.npy\n","data/regression-num-medium-2-cpu_act/Y_val.npy\n","data/regression-num-medium-2-cpu_act/X_num_train.npy\n","data/regression-num-medium-2-cpu_act/info.json\n","data/regression-num-medium-2-cpu_act/READY\n","data/regression-num-medium-2-cpu_act/X_num_test.npy\n","data/regression-num-medium-2-cpu_act/Y_test.npy\n","data/regression-num-medium-2-cpu_act/Y_train.npy\n","data/otto/\n","data/otto/X_num_val.npy\n","data/otto/Y_val.npy\n","data/otto/X_num_train.npy\n","data/otto/info.json\n","data/otto/READY\n","data/otto/X_num_test.npy\n","data/otto/Y_test.npy\n","data/otto/Y_train.npy\n","data/regression-cat-medium-0-yprop_4_1/\n","data/regression-cat-medium-0-yprop_4_1/X_num_val.npy\n","data/regression-cat-medium-0-yprop_4_1/Y_val.npy\n","data/regression-cat-medium-0-yprop_4_1/X_bin_val.npy\n","data/regression-cat-medium-0-yprop_4_1/X_num_train.npy\n","data/regression-cat-medium-0-yprop_4_1/X_bin_train.npy\n","data/regression-cat-medium-0-yprop_4_1/info.json\n","data/regression-cat-medium-0-yprop_4_1/READY\n","data/regression-cat-medium-0-yprop_4_1/X_bin_test.npy\n","data/regression-cat-medium-0-yprop_4_1/X_num_test.npy\n","data/regression-cat-medium-0-yprop_4_1/Y_test.npy\n","data/regression-cat-medium-0-yprop_4_1/Y_train.npy\n","data/classif-cat-large-0-covertype/\n","data/classif-cat-large-0-covertype/X_num_val.npy\n","data/classif-cat-large-0-covertype/Y_val.npy\n","data/classif-cat-large-0-covertype/X_bin_val.npy\n","data/classif-cat-large-0-covertype/X_num_train.npy\n","data/classif-cat-large-0-covertype/X_bin_train.npy\n","data/classif-cat-large-0-covertype/info.json\n","data/classif-cat-large-0-covertype/READY\n","data/classif-cat-large-0-covertype/X_bin_test.npy\n","data/classif-cat-large-0-covertype/X_num_test.npy\n","data/classif-cat-large-0-covertype/Y_test.npy\n","data/classif-cat-large-0-covertype/Y_train.npy\n","data/regression-cat-medium-1-Bike_Sharing_Demand/\n","data/regression-cat-medium-1-Bike_Sharing_Demand/X_cat_val.npy\n","data/regression-cat-medium-1-Bike_Sharing_Demand/X_num_val.npy\n","data/regression-cat-medium-1-Bike_Sharing_Demand/Y_val.npy\n","data/regression-cat-medium-1-Bike_Sharing_Demand/X_bin_val.npy\n","data/regression-cat-medium-1-Bike_Sharing_Demand/X_num_train.npy\n","data/regression-cat-medium-1-Bike_Sharing_Demand/X_cat_test.npy\n","data/regression-cat-medium-1-Bike_Sharing_Demand/X_bin_train.npy\n","data/regression-cat-medium-1-Bike_Sharing_Demand/X_cat_train.npy\n","data/regression-cat-medium-1-Bike_Sharing_Demand/info.json\n","data/regression-cat-medium-1-Bike_Sharing_Demand/READY\n","data/regression-cat-medium-1-Bike_Sharing_Demand/X_bin_test.npy\n","data/regression-cat-medium-1-Bike_Sharing_Demand/X_num_test.npy\n","data/regression-cat-medium-1-Bike_Sharing_Demand/Y_test.npy\n","data/regression-cat-medium-1-Bike_Sharing_Demand/Y_train.npy\n","data/classif-cat-medium-0-electricity/\n","data/classif-cat-medium-0-electricity/X_cat_val.npy\n","data/classif-cat-medium-0-electricity/X_num_val.npy\n","data/classif-cat-medium-0-electricity/Y_val.npy\n","data/classif-cat-medium-0-electricity/X_num_train.npy\n","data/classif-cat-medium-0-electricity/X_cat_test.npy\n","data/classif-cat-medium-0-electricity/X_cat_train.npy\n","data/classif-cat-medium-0-electricity/info.json\n","data/classif-cat-medium-0-electricity/READY\n","data/classif-cat-medium-0-electricity/X_num_test.npy\n","data/classif-cat-medium-0-electricity/Y_test.npy\n","data/classif-cat-medium-0-electricity/Y_train.npy\n","data/regression-cat-medium-2-visualizing_soil/\n","data/regression-cat-medium-2-visualizing_soil/X_num_val.npy\n","data/regression-cat-medium-2-visualizing_soil/Y_val.npy\n","data/regression-cat-medium-2-visualizing_soil/X_bin_val.npy\n","data/regression-cat-medium-2-visualizing_soil/X_num_train.npy\n","data/regression-cat-medium-2-visualizing_soil/X_bin_train.npy\n","data/regression-cat-medium-2-visualizing_soil/info.json\n","data/regression-cat-medium-2-visualizing_soil/READY\n","data/regression-cat-medium-2-visualizing_soil/X_bin_test.npy\n","data/regression-cat-medium-2-visualizing_soil/X_num_test.npy\n","data/regression-cat-medium-2-visualizing_soil/Y_test.npy\n","data/regression-cat-medium-2-visualizing_soil/Y_train.npy\n","data/regression-cat-medium-1-yprop_4_1/\n","data/regression-cat-medium-1-yprop_4_1/X_num_val.npy\n","data/regression-cat-medium-1-yprop_4_1/Y_val.npy\n","data/regression-cat-medium-1-yprop_4_1/X_bin_val.npy\n","data/regression-cat-medium-1-yprop_4_1/X_num_train.npy\n","data/regression-cat-medium-1-yprop_4_1/X_bin_train.npy\n","data/regression-cat-medium-1-yprop_4_1/info.json\n","data/regression-cat-medium-1-yprop_4_1/READY\n","data/regression-cat-medium-1-yprop_4_1/X_bin_test.npy\n","data/regression-cat-medium-1-yprop_4_1/X_num_test.npy\n","data/regression-cat-medium-1-yprop_4_1/Y_test.npy\n","data/regression-cat-medium-1-yprop_4_1/Y_train.npy\n","data/classif-num-medium-1-bank-marketing/\n","data/classif-num-medium-1-bank-marketing/X_num_val.npy\n","data/classif-num-medium-1-bank-marketing/Y_val.npy\n","data/classif-num-medium-1-bank-marketing/X_num_train.npy\n","data/classif-num-medium-1-bank-marketing/info.json\n","data/classif-num-medium-1-bank-marketing/READY\n","data/classif-num-medium-1-bank-marketing/X_num_test.npy\n","data/classif-num-medium-1-bank-marketing/Y_test.npy\n","data/classif-num-medium-1-bank-marketing/Y_train.npy\n","data/classif-num-medium-1-credit/\n","data/classif-num-medium-1-credit/X_num_val.npy\n","data/classif-num-medium-1-credit/Y_val.npy\n","data/classif-num-medium-1-credit/X_num_train.npy\n","data/classif-num-medium-1-credit/info.json\n","data/classif-num-medium-1-credit/READY\n","data/classif-num-medium-1-credit/X_num_test.npy\n","data/classif-num-medium-1-credit/Y_test.npy\n","data/classif-num-medium-1-credit/Y_train.npy\n"]}]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-glTe-NrxA3S","executionInfo":{"status":"ok","timestamp":1729007567879,"user_tz":-480,"elapsed":3215,"user":{"displayName":"Jonindo Pasaribu","userId":"10958990953097471082"}},"outputId":"ea4849e0-cbeb-4bbf-9c18-78a9a8b6b83f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pytorch-tabnet\n","  Downloading pytorch_tabnet-4.1.0-py3-none-any.whl.metadata (15 kB)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from pytorch-tabnet) (1.26.4)\n","Requirement already satisfied: scikit_learn>0.21 in /usr/local/lib/python3.10/dist-packages (from pytorch-tabnet) (1.5.2)\n","Requirement already satisfied: scipy>1.4 in /usr/local/lib/python3.10/dist-packages (from pytorch-tabnet) (1.13.1)\n","Requirement already satisfied: torch>=1.3 in /usr/local/lib/python3.10/dist-packages (from pytorch-tabnet) (2.4.1+cu121)\n","Requirement already satisfied: tqdm>=4.36 in /usr/local/lib/python3.10/dist-packages (from pytorch-tabnet) (4.66.5)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit_learn>0.21->pytorch-tabnet) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit_learn>0.21->pytorch-tabnet) (3.5.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (3.16.1)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (1.13.3)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (3.4)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (2024.6.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.3->pytorch-tabnet) (3.0.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.3->pytorch-tabnet) (1.3.0)\n","Downloading pytorch_tabnet-4.1.0-py3-none-any.whl (44 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.5/44.5 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: pytorch-tabnet\n","Successfully installed pytorch-tabnet-4.1.0\n"]}],"source":["!pip install pytorch-tabnet"]},{"cell_type":"code","source":["!pip install optuna"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T3kebgsowkp0","executionInfo":{"status":"ok","timestamp":1729007571764,"user_tz":-480,"elapsed":3891,"user":{"displayName":"Jonindo Pasaribu","userId":"10958990953097471082"}},"outputId":"9fa24eae-3f5a-43f3-d22e-c4411c38b992"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting optuna\n","  Downloading optuna-4.0.0-py3-none-any.whl.metadata (16 kB)\n","Collecting alembic>=1.5.0 (from optuna)\n","  Downloading alembic-1.13.3-py3-none-any.whl.metadata (7.4 kB)\n","Collecting colorlog (from optuna)\n","  Downloading colorlog-6.8.2-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (24.1)\n","Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.35)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.66.5)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0.2)\n","Collecting Mako (from alembic>=1.5.0->optuna)\n","  Downloading Mako-1.3.5-py3-none-any.whl.metadata (2.9 kB)\n","Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.12.2)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna) (3.1.1)\n","Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna) (3.0.1)\n","Downloading optuna-4.0.0-py3-none-any.whl (362 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m362.8/362.8 kB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading alembic-1.13.3-py3-none-any.whl (233 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.2/233.2 kB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading colorlog-6.8.2-py3-none-any.whl (11 kB)\n","Downloading Mako-1.3.5-py3-none-any.whl (78 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: Mako, colorlog, alembic, optuna\n","Successfully installed Mako-1.3.5 alembic-1.13.3 colorlog-6.8.2 optuna-4.0.0\n"]}]},{"cell_type":"code","source":["!pip install psutil"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1AlZ_9btlf9J","executionInfo":{"status":"ok","timestamp":1729007573891,"user_tz":-480,"elapsed":2130,"user":{"displayName":"Jonindo Pasaribu","userId":"10958990953097471082"}},"outputId":"a675a21e-8e51-4645-b564-1f70a99ed5bf"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (5.9.5)\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import optuna\n","import torch.optim\n","import psutil\n","\n","from pytorch_tabnet.tab_model import TabNetRegressor\n","from sklearn.preprocessing import QuantileTransformer"],"metadata":{"id":"085aiY1dzlHG","executionInfo":{"status":"ok","timestamp":1729007580394,"user_tz":-480,"elapsed":6506,"user":{"displayName":"Jonindo Pasaribu","userId":"10958990953097471082"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["tnr = TabNetRegressor()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pr7k2hel51eb","executionInfo":{"status":"ok","timestamp":1729007580394,"user_tz":-480,"elapsed":8,"user":{"displayName":"Jonindo Pasaribu","userId":"10958990953097471082"}},"outputId":"e5bb32c9-58a7-4f72-f199-416b28350fb0"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]}]},{"cell_type":"code","source":["X_train = np.load('/content/data/regression-num-medium-0-wine_quality/X_num_train.npy')\n","y_train = np.load('/content/data/regression-num-medium-0-wine_quality/Y_train.npy').reshape(-1, 1)\n","\n","X_valid = np.load('/content/data/regression-num-medium-0-wine_quality/X_num_val.npy')\n","y_valid = np.load('/content/data/regression-num-medium-0-wine_quality/Y_val.npy').reshape(-1, 1)\n","\n","X_test = np.load('/content/data/regression-num-medium-0-wine_quality/X_num_test.npy')\n","y_test = np.load('/content/data/regression-num-medium-0-wine_quality/Y_test.npy').reshape(-1, 1)"],"metadata":{"id":"ml0RPc_76dZx","executionInfo":{"status":"ok","timestamp":1729007580394,"user_tz":-480,"elapsed":6,"user":{"displayName":"Jonindo Pasaribu","userId":"10958990953097471082"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["normalizer = QuantileTransformer(\n","            output_distribution='normal',\n","            n_quantiles=max(min(X_train.shape[0] // 30, 1000), 10),\n","            subsample=1_000_000_000,\n","            )\n","normalizer.fit_transform(X_train)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"19PUhYavmHsh","executionInfo":{"status":"ok","timestamp":1729007580394,"user_tz":-480,"elapsed":6,"user":{"displayName":"Jonindo Pasaribu","userId":"10958990953097471082"}},"outputId":"bc387d7f-69c6-43c1-b262-8356222ee7b5"},"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[ 0.5927727 , -0.21897869,  0.11724408, ..., -0.9944579 ,\n","         1.1263912 ,  0.13408759],\n","       [-1.361571  , -0.6433454 , -0.73884684, ...,  0.0334279 ,\n","         0.01671162,  0.72791326],\n","       [-1.361571  , -0.9944579 , -0.3054808 , ...,  1.1584837 ,\n","        -0.8656782 ,  0.72791326],\n","       ...,\n","       [-0.9541652 , -0.02506888, -0.82977384, ..., -0.6640369 ,\n","         0.40338284, -0.28801754],\n","       [ 0.4215777 , -1.1263912 ,  0.01671162, ..., -0.72791326,\n","        -0.06689329, -1.1422904 ],\n","       [-0.56314915, -0.7498694 , -0.3054808 , ...,  0.16789399,\n","        -0.8656782 ,  1.1422904 ]], dtype=float32)"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["#Baseline\n","tnr.fit(\n","    X_train=X_train, y_train=y_train,\n","    eval_set=[(X_train, y_train), (X_valid, y_valid)],\n","    eval_name=['train', 'valid'],\n","    eval_metric=['mae', 'rmse'],\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dmadZ12j7CO_","executionInfo":{"status":"ok","timestamp":1729007612957,"user_tz":-480,"elapsed":32567,"user":{"displayName":"Jonindo Pasaribu","userId":"10958990953097471082"}},"outputId":"d68a4fa5-5618-41e0-bd0e-19c352a5fe78"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 20.25212| train_mae: 8.525589942932129| train_rmse: 13.877189636230469| valid_mae: 9.05955982208252| valid_rmse: 15.522290229797363|  0:00:02s\n","epoch 1  | loss: 8.75538 | train_mae: 7.074530124664307| train_rmse: 14.28501033782959| valid_mae: 6.8660101890563965| valid_rmse: 14.858909606933594|  0:00:02s\n","epoch 2  | loss: 3.23983 | train_mae: 7.969649791717529| train_rmse: 15.585000038146973| valid_mae: 7.908289909362793| valid_rmse: 16.172290802001953|  0:00:03s\n","epoch 3  | loss: 2.52254 | train_mae: 8.19314956665039| train_rmse: 11.168560028076172| valid_mae: 7.811870098114014| valid_rmse: 10.700819969177246|  0:00:03s\n","epoch 4  | loss: 1.42859 | train_mae: 3.775739908218384| train_rmse: 6.026860237121582| valid_mae: 3.775599956512451| valid_rmse: 6.165800094604492|  0:00:03s\n","epoch 5  | loss: 0.92525 | train_mae: 2.473259925842285| train_rmse: 3.6284399032592773| valid_mae: 2.374300003051758| valid_rmse: 3.5759100914001465|  0:00:04s\n","epoch 6  | loss: 0.79518 | train_mae: 1.539389967918396| train_rmse: 2.038100004196167| valid_mae: 1.521299958229065| valid_rmse: 2.023099899291992|  0:00:04s\n","epoch 7  | loss: 0.71296 | train_mae: 1.237969994544983| train_rmse: 1.607550024986267| valid_mae: 1.226040005683899| valid_rmse: 1.5818400382995605|  0:00:05s\n","epoch 8  | loss: 0.66504 | train_mae: 1.2103400230407715| train_rmse: 1.5979900360107422| valid_mae: 1.230049967765808| valid_rmse: 1.6046700477600098|  0:00:05s\n","epoch 9  | loss: 0.62499 | train_mae: 1.110949993133545| train_rmse: 1.4610400199890137| valid_mae: 1.1450599431991577| valid_rmse: 1.5466300249099731|  0:00:05s\n","epoch 10 | loss: 0.5968  | train_mae: 1.030269980430603| train_rmse: 1.3226499557495117| valid_mae: 1.0843600034713745| valid_rmse: 1.3838000297546387|  0:00:06s\n","epoch 11 | loss: 0.60253 | train_mae: 0.943120002746582| train_rmse: 1.1839200258255005| valid_mae: 1.0227199792861938| valid_rmse: 1.2988300323486328|  0:00:06s\n","epoch 12 | loss: 0.59056 | train_mae: 0.9223899841308594| train_rmse: 1.171910047531128| valid_mae: 0.9999600052833557| valid_rmse: 1.277109980583191|  0:00:06s\n","epoch 13 | loss: 0.57498 | train_mae: 0.9629999995231628| train_rmse: 1.218709945678711| valid_mae: 1.0389800071716309| valid_rmse: 1.3135700225830078|  0:00:07s\n","epoch 14 | loss: 0.56564 | train_mae: 0.966480016708374| train_rmse: 1.2422599792480469| valid_mae: 1.0265599489212036| valid_rmse: 1.3162200450897217|  0:00:07s\n","epoch 15 | loss: 0.56231 | train_mae: 0.9688299894332886| train_rmse: 1.2297500371932983| valid_mae: 1.031190037727356| valid_rmse: 1.3069100379943848|  0:00:07s\n","epoch 16 | loss: 0.57048 | train_mae: 1.0098899602890015| train_rmse: 1.2655800580978394| valid_mae: 1.0523899793624878| valid_rmse: 1.3313299417495728|  0:00:08s\n","epoch 17 | loss: 0.5619  | train_mae: 0.9584299921989441| train_rmse: 1.1818599700927734| valid_mae: 1.0113099813461304| valid_rmse: 1.25655996799469|  0:00:08s\n","epoch 18 | loss: 0.55377 | train_mae: 0.9743599891662598| train_rmse: 1.203950047492981| valid_mae: 1.0127999782562256| valid_rmse: 1.2699700593948364|  0:00:08s\n","epoch 19 | loss: 0.55115 | train_mae: 0.8846799731254578| train_rmse: 1.1162099838256836| valid_mae: 0.9487299919128418| valid_rmse: 1.1871000528335571|  0:00:08s\n","epoch 20 | loss: 0.549   | train_mae: 0.9039000272750854| train_rmse: 1.1271899938583374| valid_mae: 0.9691799879074097| valid_rmse: 1.1984200477600098|  0:00:09s\n","epoch 21 | loss: 0.53749 | train_mae: 0.8618599772453308| train_rmse: 1.0750000476837158| valid_mae: 0.9205499887466431| valid_rmse: 1.1436699628829956|  0:00:09s\n","epoch 22 | loss: 0.53538 | train_mae: 0.8378900289535522| train_rmse: 1.0436700582504272| valid_mae: 0.8931599855422974| valid_rmse: 1.1131399869918823|  0:00:09s\n","epoch 23 | loss: 0.53053 | train_mae: 0.803879976272583| train_rmse: 1.0073699951171875| valid_mae: 0.851419985294342| valid_rmse: 1.0659099817276|  0:00:10s\n","epoch 24 | loss: 0.53102 | train_mae: 0.7889800071716309| train_rmse: 0.9916499853134155| valid_mae: 0.848800003528595| valid_rmse: 1.0657199621200562|  0:00:10s\n","epoch 25 | loss: 0.52462 | train_mae: 0.8036800026893616| train_rmse: 0.9988399744033813| valid_mae: 0.8512799739837646| valid_rmse: 1.063670039176941|  0:00:10s\n","epoch 26 | loss: 0.52319 | train_mae: 0.7543299794197083| train_rmse: 0.9486799836158752| valid_mae: 0.8140400052070618| valid_rmse: 1.0266300439834595|  0:00:11s\n","epoch 27 | loss: 0.50173 | train_mae: 0.7477399706840515| train_rmse: 0.940280020236969| valid_mae: 0.7972300052642822| valid_rmse: 1.0110299587249756|  0:00:11s\n","epoch 28 | loss: 0.51404 | train_mae: 0.7725499868392944| train_rmse: 0.9635800123214722| valid_mae: 0.8122599720954895| valid_rmse: 1.023859977722168|  0:00:11s\n","epoch 29 | loss: 0.51362 | train_mae: 0.76801997423172| train_rmse: 0.9640300273895264| valid_mae: 0.8200299739837646| valid_rmse: 1.037719964981079|  0:00:12s\n","epoch 30 | loss: 0.50512 | train_mae: 0.8194000124931335| train_rmse: 1.012779951095581| valid_mae: 0.874970018863678| valid_rmse: 1.0846600532531738|  0:00:12s\n","epoch 31 | loss: 0.49924 | train_mae: 0.7500600218772888| train_rmse: 0.9452400207519531| valid_mae: 0.816349983215332| valid_rmse: 1.0235199928283691|  0:00:12s\n","epoch 32 | loss: 0.50679 | train_mae: 0.7536900043487549| train_rmse: 0.9529500007629395| valid_mae: 0.8238199949264526| valid_rmse: 1.0324100255966187|  0:00:13s\n","epoch 33 | loss: 0.49493 | train_mae: 0.7888399958610535| train_rmse: 0.9884899854660034| valid_mae: 0.8510100245475769| valid_rmse: 1.059440016746521|  0:00:13s\n","epoch 34 | loss: 0.49266 | train_mae: 0.8046900033950806| train_rmse: 1.0053800344467163| valid_mae: 0.8661900162696838| valid_rmse: 1.0722800493240356|  0:00:13s\n","epoch 35 | loss: 0.49456 | train_mae: 0.7807400226593018| train_rmse: 0.9703500270843506| valid_mae: 0.8336399793624878| valid_rmse: 1.0342400074005127|  0:00:13s\n","epoch 36 | loss: 0.49367 | train_mae: 0.7760699987411499| train_rmse: 0.9683799743652344| valid_mae: 0.8326200246810913| valid_rmse: 1.0385500192642212|  0:00:14s\n","epoch 37 | loss: 0.48599 | train_mae: 0.7165899872779846| train_rmse: 0.9101399779319763| valid_mae: 0.7717499732971191| valid_rmse: 0.9846799969673157|  0:00:14s\n","epoch 38 | loss: 0.4849  | train_mae: 0.7719399929046631| train_rmse: 0.9804900288581848| valid_mae: 0.8325700163841248| valid_rmse: 1.0554800033569336|  0:00:14s\n","epoch 39 | loss: 0.48706 | train_mae: 0.7088800072669983| train_rmse: 0.9005600214004517| valid_mae: 0.75941002368927| valid_rmse: 0.9659799933433533|  0:00:15s\n","epoch 40 | loss: 0.49217 | train_mae: 0.7320200204849243| train_rmse: 0.9297599792480469| valid_mae: 0.782800018787384| valid_rmse: 0.9895700216293335|  0:00:15s\n","epoch 41 | loss: 0.48478 | train_mae: 0.6914899945259094| train_rmse: 0.8858699798583984| valid_mae: 0.7320899963378906| valid_rmse: 0.9401699900627136|  0:00:15s\n","epoch 42 | loss: 0.48975 | train_mae: 0.6819599866867065| train_rmse: 0.8726599812507629| valid_mae: 0.723580002784729| valid_rmse: 0.9298099875450134|  0:00:16s\n","epoch 43 | loss: 0.48185 | train_mae: 0.6955199837684631| train_rmse: 0.8870499730110168| valid_mae: 0.7428699731826782| valid_rmse: 0.9485200047492981|  0:00:16s\n","epoch 44 | loss: 0.48024 | train_mae: 0.6675999760627747| train_rmse: 0.8522899746894836| valid_mae: 0.7003899812698364| valid_rmse: 0.9071599841117859|  0:00:16s\n","epoch 45 | loss: 0.48619 | train_mae: 0.6762499809265137| train_rmse: 0.8632100224494934| valid_mae: 0.7101200222969055| valid_rmse: 0.9157400131225586|  0:00:16s\n","epoch 46 | loss: 0.46766 | train_mae: 0.6573600172996521| train_rmse: 0.8410400152206421| valid_mae: 0.6861900091171265| valid_rmse: 0.8906599879264832|  0:00:17s\n","epoch 47 | loss: 0.47239 | train_mae: 0.6737300157546997| train_rmse: 0.8583099842071533| valid_mae: 0.7134299874305725| valid_rmse: 0.9185299873352051|  0:00:17s\n","epoch 48 | loss: 0.46507 | train_mae: 0.6604999899864197| train_rmse: 0.8353300094604492| valid_mae: 0.6979900002479553| valid_rmse: 0.8878300189971924|  0:00:17s\n","epoch 49 | loss: 0.46093 | train_mae: 0.6555200219154358| train_rmse: 0.8282600045204163| valid_mae: 0.691569983959198| valid_rmse: 0.87882000207901|  0:00:18s\n","epoch 50 | loss: 0.46006 | train_mae: 0.6521300077438354| train_rmse: 0.8281199932098389| valid_mae: 0.6900699734687805| valid_rmse: 0.8805999755859375|  0:00:18s\n","epoch 51 | loss: 0.46057 | train_mae: 0.6498900055885315| train_rmse: 0.8233000040054321| valid_mae: 0.6861299872398376| valid_rmse: 0.8763499855995178|  0:00:18s\n","epoch 52 | loss: 0.46462 | train_mae: 0.6513100266456604| train_rmse: 0.822920024394989| valid_mae: 0.6857100129127502| valid_rmse: 0.8743699789047241|  0:00:19s\n","epoch 53 | loss: 0.46418 | train_mae: 0.648169994354248| train_rmse: 0.8214899897575378| valid_mae: 0.684469997882843| valid_rmse: 0.876829981803894|  0:00:19s\n","epoch 54 | loss: 0.46144 | train_mae: 0.6468700170516968| train_rmse: 0.8234699964523315| valid_mae: 0.6907600164413452| valid_rmse: 0.8824499845504761|  0:00:19s\n","epoch 55 | loss: 0.46321 | train_mae: 0.6380500197410583| train_rmse: 0.8171799778938293| valid_mae: 0.6807799935340881| valid_rmse: 0.878790020942688|  0:00:19s\n","epoch 56 | loss: 0.47018 | train_mae: 0.6438000202178955| train_rmse: 0.8247699737548828| valid_mae: 0.6971499919891357| valid_rmse: 0.8953099846839905|  0:00:20s\n","epoch 57 | loss: 0.46588 | train_mae: 0.6418099999427795| train_rmse: 0.822629988193512| valid_mae: 0.6998800039291382| valid_rmse: 0.8996700048446655|  0:00:20s\n","epoch 58 | loss: 0.467   | train_mae: 0.637690007686615| train_rmse: 0.8137199878692627| valid_mae: 0.6878899931907654| valid_rmse: 0.8847000002861023|  0:00:20s\n","epoch 59 | loss: 0.45805 | train_mae: 0.6238300204277039| train_rmse: 0.7947400212287903| valid_mae: 0.663349986076355| valid_rmse: 0.8524100184440613|  0:00:21s\n","epoch 60 | loss: 0.46457 | train_mae: 0.6237800121307373| train_rmse: 0.787310004234314| valid_mae: 0.6653800010681152| valid_rmse: 0.8477699756622314|  0:00:21s\n","epoch 61 | loss: 0.46099 | train_mae: 0.6182199716567993| train_rmse: 0.7855499982833862| valid_mae: 0.6628299951553345| valid_rmse: 0.8490300178527832|  0:00:21s\n","epoch 62 | loss: 0.45246 | train_mae: 0.6283299922943115| train_rmse: 0.7937700152397156| valid_mae: 0.6757799983024597| valid_rmse: 0.8619999885559082|  0:00:22s\n","epoch 63 | loss: 0.46323 | train_mae: 0.6135600209236145| train_rmse: 0.7777400016784668| valid_mae: 0.6597999930381775| valid_rmse: 0.8477100133895874|  0:00:22s\n","epoch 64 | loss: 0.46441 | train_mae: 0.6210299730300903| train_rmse: 0.7840999960899353| valid_mae: 0.6712700128555298| valid_rmse: 0.855679988861084|  0:00:22s\n","epoch 65 | loss: 0.45925 | train_mae: 0.6179800033569336| train_rmse: 0.7879899740219116| valid_mae: 0.6686000227928162| valid_rmse: 0.8584200143814087|  0:00:22s\n","epoch 66 | loss: 0.46754 | train_mae: 0.6159899830818176| train_rmse: 0.7869799733161926| valid_mae: 0.6647700071334839| valid_rmse: 0.8525099754333496|  0:00:23s\n","epoch 67 | loss: 0.44342 | train_mae: 0.6267799735069275| train_rmse: 0.8043199777603149| valid_mae: 0.6838200092315674| valid_rmse: 0.8784000277519226|  0:00:23s\n","epoch 68 | loss: 0.44395 | train_mae: 0.6119400262832642| train_rmse: 0.7854899764060974| valid_mae: 0.6690700054168701| valid_rmse: 0.8569599986076355|  0:00:24s\n","epoch 69 | loss: 0.44558 | train_mae: 0.6124399900436401| train_rmse: 0.7834100127220154| valid_mae: 0.6675099730491638| valid_rmse: 0.8558800220489502|  0:00:24s\n","epoch 70 | loss: 0.44871 | train_mae: 0.6061599850654602| train_rmse: 0.7788199782371521| valid_mae: 0.6563599705696106| valid_rmse: 0.8452100157737732|  0:00:24s\n","epoch 71 | loss: 0.44508 | train_mae: 0.6110399961471558| train_rmse: 0.778980016708374| valid_mae: 0.6643199920654297| valid_rmse: 0.8473100066184998|  0:00:24s\n","epoch 72 | loss: 0.43881 | train_mae: 0.6004300117492676| train_rmse: 0.7662500143051147| valid_mae: 0.6510999798774719| valid_rmse: 0.8317899703979492|  0:00:25s\n","epoch 73 | loss: 0.44638 | train_mae: 0.6079699993133545| train_rmse: 0.779770016670227| valid_mae: 0.6606799960136414| valid_rmse: 0.8458700180053711|  0:00:25s\n","epoch 74 | loss: 0.44681 | train_mae: 0.6081799864768982| train_rmse: 0.7784900069236755| valid_mae: 0.6577600240707397| valid_rmse: 0.8413599729537964|  0:00:25s\n","epoch 75 | loss: 0.43797 | train_mae: 0.6211900115013123| train_rmse: 0.8007100224494934| valid_mae: 0.6662600040435791| valid_rmse: 0.8587300181388855|  0:00:26s\n","epoch 76 | loss: 0.43388 | train_mae: 0.6105999946594238| train_rmse: 0.780430018901825| valid_mae: 0.657509982585907| valid_rmse: 0.8359000086784363|  0:00:26s\n","epoch 77 | loss: 0.44113 | train_mae: 0.6162700057029724| train_rmse: 0.7933200001716614| valid_mae: 0.6650599837303162| valid_rmse: 0.8539999723434448|  0:00:26s\n","epoch 78 | loss: 0.44258 | train_mae: 0.613099992275238| train_rmse: 0.7869600057601929| valid_mae: 0.6625300049781799| valid_rmse: 0.8479400277137756|  0:00:26s\n","epoch 79 | loss: 0.44583 | train_mae: 0.6036400198936462| train_rmse: 0.772350013256073| valid_mae: 0.6566299796104431| valid_rmse: 0.8318399786949158|  0:00:27s\n","epoch 80 | loss: 0.44785 | train_mae: 0.6047999858856201| train_rmse: 0.7779099941253662| valid_mae: 0.6549400091171265| valid_rmse: 0.8394700288772583|  0:00:27s\n","epoch 81 | loss: 0.44907 | train_mae: 0.6169700026512146| train_rmse: 0.7930799722671509| valid_mae: 0.6685199737548828| valid_rmse: 0.8530499935150146|  0:00:27s\n","epoch 82 | loss: 0.45494 | train_mae: 0.6126599907875061| train_rmse: 0.7887499928474426| valid_mae: 0.6661900281906128| valid_rmse: 0.8489800095558167|  0:00:28s\n","\n","Early stopping occurred at epoch 82 with best_epoch = 72 and best_valid_rmse = 0.8317899703979492\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n"]}]},{"cell_type":"code","source":["def objective(trial):\n","    n_d = trial.suggest_int('n_d', 8, 64)\n","    n_a = n_d\n","\n","    params = {\n","        #'n_d': trial.suggest_int('n_d', 8, 64),\n","        #'n_a': trial.suggest_int('n_a', 8, 64),\n","        'n_d': n_d,\n","        'n_a': n_a,\n","        'n_steps': trial.suggest_int('n_steps', 3, 10),\n","        'gamma': trial.suggest_float('gamma', 1.0, 2.0),\n","        'n_independent': trial.suggest_int('n_independent', 1, 5),\n","        'n_shared': trial.suggest_int('n_shared', 1, 5),\n","        'momentum': trial.suggest_float('momentum', 0.01, 0.4),\n","    }\n","\n","    model = TabNetRegressor(**params)\n","    model.fit(X_train, y_train, eval_set=[(X_valid, y_valid)], patience=10)\n","\n","    # Evaluate model performance\n","    score = model.best_cost  # or any other metric\n","\n","    return score\n","\n","study = optuna.create_study(direction='minimize')\n","study.optimize(objective, n_trials=100)\n","\n","best_params = study.best_params"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rKJAw0W-w7sc","executionInfo":{"status":"ok","timestamp":1729010909199,"user_tz":-480,"elapsed":3296250,"user":{"displayName":"Jonindo Pasaribu","userId":"10958990953097471082"}},"outputId":"6667959f-4da8-4e2e-dad7-79e7022fad2e"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stderr","text":["[I 2024-10-15 15:53:32,334] A new study created in memory with name: no-name-220e3985-68e9-4323-a6d0-812614dd6276\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 57.03082| val_0_mse: 265.0199279785156|  0:00:00s\n","epoch 1  | loss: 40.41164| val_0_mse: 198.25540161132812|  0:00:00s\n","epoch 2  | loss: 30.40849| val_0_mse: 52.51124954223633|  0:00:01s\n","epoch 3  | loss: 22.13164| val_0_mse: 14.184260368347168|  0:00:01s\n","epoch 4  | loss: 14.69868| val_0_mse: 36.08835983276367|  0:00:01s\n","epoch 5  | loss: 9.09696 | val_0_mse: 41.080299377441406|  0:00:02s\n","epoch 6  | loss: 4.63799 | val_0_mse: 185.90744018554688|  0:00:02s\n","epoch 7  | loss: 2.57659 | val_0_mse: 135.37022399902344|  0:00:03s\n","epoch 8  | loss: 2.07981 | val_0_mse: 71.10034942626953|  0:00:03s\n","epoch 9  | loss: 1.3369  | val_0_mse: 94.33717346191406|  0:00:03s\n","epoch 10 | loss: 1.1472  | val_0_mse: 18.47981071472168|  0:00:04s\n","epoch 11 | loss: 0.97653 | val_0_mse: 25.60919952392578|  0:00:04s\n","epoch 12 | loss: 0.91408 | val_0_mse: 15.413020133972168|  0:00:04s\n","epoch 13 | loss: 0.83018 | val_0_mse: 12.489680290222168|  0:00:05s\n","epoch 14 | loss: 0.79466 | val_0_mse: 11.467499732971191|  0:00:05s\n","epoch 15 | loss: 0.74041 | val_0_mse: 9.966719627380371|  0:00:05s\n","epoch 16 | loss: 0.71041 | val_0_mse: 7.197929859161377|  0:00:06s\n","epoch 17 | loss: 0.67609 | val_0_mse: 4.760270118713379|  0:00:06s\n","epoch 18 | loss: 0.68985 | val_0_mse: 4.650629997253418|  0:00:07s\n","epoch 19 | loss: 0.66843 | val_0_mse: 2.7972400188446045|  0:00:07s\n","epoch 20 | loss: 0.62999 | val_0_mse: 2.3336400985717773|  0:00:07s\n","epoch 21 | loss: 0.6412  | val_0_mse: 2.099400043487549|  0:00:08s\n","epoch 22 | loss: 0.63688 | val_0_mse: 1.9631199836730957|  0:00:08s\n","epoch 23 | loss: 0.63634 | val_0_mse: 1.9013400077819824|  0:00:08s\n","epoch 24 | loss: 0.61344 | val_0_mse: 1.6347800493240356|  0:00:09s\n","epoch 25 | loss: 0.6264  | val_0_mse: 2.6655099391937256|  0:00:09s\n","epoch 26 | loss: 0.60711 | val_0_mse: 2.1218199729919434|  0:00:09s\n","epoch 27 | loss: 0.6099  | val_0_mse: 2.499929904937744|  0:00:10s\n","epoch 28 | loss: 0.61507 | val_0_mse: 1.521340012550354|  0:00:10s\n","epoch 29 | loss: 0.61504 | val_0_mse: 1.3211599588394165|  0:00:11s\n","epoch 30 | loss: 0.61034 | val_0_mse: 0.9880599975585938|  0:00:11s\n","epoch 31 | loss: 0.60061 | val_0_mse: 0.9373700022697449|  0:00:11s\n","epoch 32 | loss: 0.57342 | val_0_mse: 0.9352200031280518|  0:00:12s\n","epoch 33 | loss: 0.57632 | val_0_mse: 1.1071399450302124|  0:00:12s\n","epoch 34 | loss: 0.5745  | val_0_mse: 1.050819993019104|  0:00:12s\n","epoch 35 | loss: 0.55842 | val_0_mse: 1.0221400260925293|  0:00:13s\n","epoch 36 | loss: 0.56439 | val_0_mse: 1.097640037536621|  0:00:13s\n","epoch 37 | loss: 0.57558 | val_0_mse: 1.5214300155639648|  0:00:13s\n","epoch 38 | loss: 0.57226 | val_0_mse: 1.4348399639129639|  0:00:14s\n","epoch 39 | loss: 0.56769 | val_0_mse: 1.006850004196167|  0:00:14s\n","epoch 40 | loss: 0.55682 | val_0_mse: 1.2024600505828857|  0:00:14s\n","epoch 41 | loss: 0.56362 | val_0_mse: 1.2034399509429932|  0:00:15s\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 15:53:48,197] Trial 0 finished with value: 0.9352177977561951 and parameters: {'n_d': 8, 'n_steps': 5, 'gamma': 1.998584749935361, 'n_independent': 1, 'n_shared': 5, 'momentum': 0.010032878531290033}. Best is trial 0 with value: 0.9352177977561951.\n"]},{"output_type":"stream","name":"stdout","text":["epoch 42 | loss: 0.56565 | val_0_mse: 1.0890799760818481|  0:00:15s\n","\n","Early stopping occurred at epoch 42 with best_epoch = 32 and best_val_0_mse = 0.9352200031280518\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 20.09699| val_0_mse: 1039.4954833984375|  0:00:00s\n","epoch 1  | loss: 12.58049| val_0_mse: 2789.6025390625|  0:00:01s\n","epoch 2  | loss: 15.79699| val_0_mse: 188.69322204589844|  0:00:01s\n","epoch 3  | loss: 6.34127 | val_0_mse: 117.68798065185547|  0:00:02s\n","epoch 4  | loss: 7.74854 | val_0_mse: 85.8525390625|  0:00:03s\n","epoch 5  | loss: 3.40469 | val_0_mse: 157.33843994140625|  0:00:03s\n","epoch 6  | loss: 6.33509 | val_0_mse: 144.04519653320312|  0:00:04s\n","epoch 7  | loss: 11.84133| val_0_mse: 45.544498443603516|  0:00:04s\n","epoch 8  | loss: 5.06645 | val_0_mse: 50.49723815917969|  0:00:05s\n","epoch 9  | loss: 2.46617 | val_0_mse: 58.93574142456055|  0:00:05s\n","epoch 10 | loss: 7.74846 | val_0_mse: 27.736080169677734|  0:00:06s\n","epoch 11 | loss: 4.0407  | val_0_mse: 22.09490966796875|  0:00:07s\n","epoch 12 | loss: 3.22658 | val_0_mse: 7.820740222930908|  0:00:07s\n","epoch 13 | loss: 1.55962 | val_0_mse: 45.842079162597656|  0:00:08s\n","epoch 14 | loss: 1.99149 | val_0_mse: 39.01382827758789|  0:00:08s\n","epoch 15 | loss: 1.90545 | val_0_mse: 10.412739753723145|  0:00:09s\n","epoch 16 | loss: 1.71509 | val_0_mse: 16.552230834960938|  0:00:09s\n","epoch 17 | loss: 2.30399 | val_0_mse: 12.374580383300781|  0:00:10s\n","epoch 18 | loss: 1.22037 | val_0_mse: 27.55544090270996|  0:00:10s\n","epoch 19 | loss: 0.87729 | val_0_mse: 14.52068042755127|  0:00:11s\n","epoch 20 | loss: 1.81355 | val_0_mse: 1.5554499626159668|  0:00:12s\n","epoch 21 | loss: 0.71887 | val_0_mse: 2.8227500915527344|  0:00:12s\n","epoch 22 | loss: 0.74011 | val_0_mse: 5.927619934082031|  0:00:13s\n","epoch 23 | loss: 0.80698 | val_0_mse: 2.08378005027771|  0:00:13s\n","epoch 24 | loss: 0.83744 | val_0_mse: 3.828700065612793|  0:00:14s\n","epoch 25 | loss: 0.9072  | val_0_mse: 2.7985999584198|  0:00:15s\n","epoch 26 | loss: 1.05287 | val_0_mse: 2.3026299476623535|  0:00:15s\n","epoch 27 | loss: 0.73811 | val_0_mse: 4.947249889373779|  0:00:16s\n","epoch 28 | loss: 0.64879 | val_0_mse: 1.8248000144958496|  0:00:16s\n","epoch 29 | loss: 0.70053 | val_0_mse: 2.269779920578003|  0:00:17s\n","epoch 30 | loss: 0.73793 | val_0_mse: 1.4416699409484863|  0:00:17s\n","epoch 31 | loss: 0.77412 | val_0_mse: 1.1380300521850586|  0:00:18s\n","epoch 32 | loss: 0.6992  | val_0_mse: 1.5897599458694458|  0:00:18s\n","epoch 33 | loss: 0.74281 | val_0_mse: 1.5989899635314941|  0:00:19s\n","epoch 34 | loss: 0.7524  | val_0_mse: 1.9807000160217285|  0:00:20s\n","epoch 35 | loss: 0.73004 | val_0_mse: 1.5923800468444824|  0:00:20s\n","epoch 36 | loss: 0.7871  | val_0_mse: 1.2493900060653687|  0:00:21s\n","epoch 37 | loss: 0.69945 | val_0_mse: 1.22393000125885|  0:00:21s\n","epoch 38 | loss: 0.62352 | val_0_mse: 0.9711599946022034|  0:00:22s\n","epoch 39 | loss: 0.63111 | val_0_mse: 1.1377500295639038|  0:00:22s\n","epoch 40 | loss: 0.62241 | val_0_mse: 1.1557600498199463|  0:00:23s\n","epoch 41 | loss: 0.68241 | val_0_mse: 1.1080100536346436|  0:00:23s\n","epoch 42 | loss: 0.65573 | val_0_mse: 1.2503999471664429|  0:00:24s\n","epoch 43 | loss: 0.66848 | val_0_mse: 0.9838600158691406|  0:00:25s\n","epoch 44 | loss: 0.64885 | val_0_mse: 0.952049970626831|  0:00:25s\n","epoch 45 | loss: 0.61936 | val_0_mse: 1.017930030822754|  0:00:26s\n","epoch 46 | loss: 0.59129 | val_0_mse: 0.8679800033569336|  0:00:26s\n","epoch 47 | loss: 0.6046  | val_0_mse: 0.9198600053787231|  0:00:27s\n","epoch 48 | loss: 0.73902 | val_0_mse: 0.991890013217926|  0:00:27s\n","epoch 49 | loss: 0.64383 | val_0_mse: 0.808929979801178|  0:00:28s\n","epoch 50 | loss: 0.60421 | val_0_mse: 0.8434799909591675|  0:00:29s\n","epoch 51 | loss: 0.63404 | val_0_mse: 0.8701099753379822|  0:00:29s\n","epoch 52 | loss: 0.58719 | val_0_mse: 0.8281599879264832|  0:00:30s\n","epoch 53 | loss: 0.62184 | val_0_mse: 1.1555500030517578|  0:00:30s\n","epoch 54 | loss: 0.59869 | val_0_mse: 0.8024100065231323|  0:00:31s\n","epoch 55 | loss: 0.58308 | val_0_mse: 0.7674599885940552|  0:00:31s\n","epoch 56 | loss: 0.58324 | val_0_mse: 1.0546900033950806|  0:00:32s\n","epoch 57 | loss: 0.68845 | val_0_mse: 0.7777199745178223|  0:00:32s\n","epoch 58 | loss: 0.78202 | val_0_mse: 1.364400029182434|  0:00:33s\n","epoch 59 | loss: 0.81116 | val_0_mse: 0.8906099796295166|  0:00:34s\n","epoch 60 | loss: 0.71021 | val_0_mse: 0.829230010509491|  0:00:34s\n","epoch 61 | loss: 0.57163 | val_0_mse: 0.7170199751853943|  0:00:35s\n","epoch 62 | loss: 0.54624 | val_0_mse: 0.6998599767684937|  0:00:35s\n","epoch 63 | loss: 0.59052 | val_0_mse: 0.9338700175285339|  0:00:36s\n","epoch 64 | loss: 0.61688 | val_0_mse: 0.9580100178718567|  0:00:37s\n","epoch 65 | loss: 0.695   | val_0_mse: 0.7097499966621399|  0:00:37s\n","epoch 66 | loss: 0.59188 | val_0_mse: 0.8663600087165833|  0:00:38s\n","epoch 67 | loss: 0.56586 | val_0_mse: 0.7689599990844727|  0:00:38s\n","epoch 68 | loss: 0.55162 | val_0_mse: 0.7361099720001221|  0:00:39s\n","epoch 69 | loss: 0.60091 | val_0_mse: 0.6725500226020813|  0:00:39s\n","epoch 70 | loss: 0.5984  | val_0_mse: 0.6342200040817261|  0:00:40s\n","epoch 71 | loss: 0.54397 | val_0_mse: 0.684660017490387|  0:00:40s\n","epoch 72 | loss: 0.54791 | val_0_mse: 0.7365599870681763|  0:00:41s\n","epoch 73 | loss: 0.54651 | val_0_mse: 0.8096399903297424|  0:00:42s\n","epoch 74 | loss: 0.56067 | val_0_mse: 0.6823700070381165|  0:00:42s\n","epoch 75 | loss: 0.5375  | val_0_mse: 0.6589499711990356|  0:00:43s\n","epoch 76 | loss: 0.53135 | val_0_mse: 0.6940100193023682|  0:00:43s\n","epoch 77 | loss: 0.54286 | val_0_mse: 0.679639995098114|  0:00:44s\n","epoch 78 | loss: 0.55196 | val_0_mse: 0.695110023021698|  0:00:44s\n","epoch 79 | loss: 0.6256  | val_0_mse: 0.7082899808883667|  0:00:45s\n","epoch 80 | loss: 0.58126 | val_0_mse: 0.6599699854850769|  0:00:45s\n","\n","Early stopping occurred at epoch 80 with best_epoch = 70 and best_val_0_mse = 0.6342200040817261\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 15:54:34,436] Trial 1 finished with value: 0.6342222094535828 and parameters: {'n_d': 62, 'n_steps': 10, 'gamma': 1.7930465169010819, 'n_independent': 3, 'n_shared': 2, 'momentum': 0.23700897888019876}. Best is trial 1 with value: 0.6342222094535828.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 20.0372 | val_0_mse: 341.31536865234375|  0:00:00s\n","epoch 1  | loss: 2.13918 | val_0_mse: 44.90568161010742|  0:00:00s\n","epoch 2  | loss: 0.981   | val_0_mse: 52.5525016784668|  0:00:00s\n","epoch 3  | loss: 0.73076 | val_0_mse: 75.59616088867188|  0:00:00s\n","epoch 4  | loss: 0.66955 | val_0_mse: 59.257598876953125|  0:00:01s\n","epoch 5  | loss: 0.61708 | val_0_mse: 104.91091918945312|  0:00:01s\n","epoch 6  | loss: 0.60474 | val_0_mse: 133.47605895996094|  0:00:01s\n","epoch 7  | loss: 0.6245  | val_0_mse: 1.4718300104141235|  0:00:01s\n","epoch 8  | loss: 0.58395 | val_0_mse: 1.2523000240325928|  0:00:02s\n","epoch 9  | loss: 0.58132 | val_0_mse: 4.950009822845459|  0:00:02s\n","epoch 10 | loss: 0.55865 | val_0_mse: 4.5684099197387695|  0:00:02s\n","epoch 11 | loss: 0.58251 | val_0_mse: 9.353260040283203|  0:00:02s\n","epoch 12 | loss: 0.56629 | val_0_mse: 4.63293981552124|  0:00:03s\n","epoch 13 | loss: 0.55047 | val_0_mse: 2.815049886703491|  0:00:03s\n","epoch 14 | loss: 0.53554 | val_0_mse: 1.2755299806594849|  0:00:03s\n","epoch 15 | loss: 0.53773 | val_0_mse: 2.823430061340332|  0:00:03s\n","epoch 16 | loss: 0.52551 | val_0_mse: 1.6070599555969238|  0:00:03s\n","epoch 17 | loss: 0.51525 | val_0_mse: 1.8894000053405762|  0:00:04s\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 15:54:38,907] Trial 2 finished with value: 1.2522976398468018 and parameters: {'n_d': 38, 'n_steps': 3, 'gamma': 1.4345274734577227, 'n_independent': 1, 'n_shared': 4, 'momentum': 0.07007139452064448}. Best is trial 1 with value: 0.6342222094535828.\n"]},{"output_type":"stream","name":"stdout","text":["epoch 18 | loss: 0.5149  | val_0_mse: 1.3329600095748901|  0:00:04s\n","\n","Early stopping occurred at epoch 18 with best_epoch = 8 and best_val_0_mse = 1.2523000240325928\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 15.68997| val_0_mse: 283.7288513183594|  0:00:00s\n","epoch 1  | loss: 6.35203 | val_0_mse: 276.593505859375|  0:00:00s\n","epoch 2  | loss: 4.96789 | val_0_mse: 160.7197265625|  0:00:00s\n","epoch 3  | loss: 2.99796 | val_0_mse: 55.28181838989258|  0:00:01s\n","epoch 4  | loss: 2.1794  | val_0_mse: 52.50347900390625|  0:00:01s\n","epoch 5  | loss: 1.71045 | val_0_mse: 32.64265823364258|  0:00:01s\n","epoch 6  | loss: 1.27752 | val_0_mse: 9.872750282287598|  0:00:01s\n","epoch 7  | loss: 1.13875 | val_0_mse: 24.803449630737305|  0:00:02s\n","epoch 8  | loss: 1.18239 | val_0_mse: 13.064430236816406|  0:00:02s\n","epoch 9  | loss: 0.9122  | val_0_mse: 11.613730430603027|  0:00:02s\n","epoch 10 | loss: 0.86429 | val_0_mse: 7.688300132751465|  0:00:02s\n","epoch 11 | loss: 0.70495 | val_0_mse: 6.63484001159668|  0:00:03s\n","epoch 12 | loss: 0.66441 | val_0_mse: 3.3038198947906494|  0:00:03s\n","epoch 13 | loss: 0.68466 | val_0_mse: 6.199319839477539|  0:00:03s\n","epoch 14 | loss: 0.65953 | val_0_mse: 3.8527801036834717|  0:00:03s\n","epoch 15 | loss: 0.60809 | val_0_mse: 3.2070200443267822|  0:00:04s\n","epoch 16 | loss: 0.60603 | val_0_mse: 3.0681700706481934|  0:00:04s\n","epoch 17 | loss: 0.61281 | val_0_mse: 3.3897199630737305|  0:00:04s\n","epoch 18 | loss: 0.58844 | val_0_mse: 2.719630002975464|  0:00:04s\n","epoch 19 | loss: 0.59028 | val_0_mse: 1.9983099699020386|  0:00:05s\n","epoch 20 | loss: 0.59149 | val_0_mse: 1.3703999519348145|  0:00:05s\n","epoch 21 | loss: 0.56887 | val_0_mse: 1.8446300029754639|  0:00:05s\n","epoch 22 | loss: 0.56453 | val_0_mse: 2.3540399074554443|  0:00:05s\n","epoch 23 | loss: 0.58447 | val_0_mse: 2.1785199642181396|  0:00:06s\n","epoch 24 | loss: 0.56961 | val_0_mse: 1.3709499835968018|  0:00:06s\n","epoch 25 | loss: 0.56619 | val_0_mse: 1.3201299905776978|  0:00:06s\n","epoch 26 | loss: 0.57125 | val_0_mse: 1.9937000274658203|  0:00:06s\n","epoch 27 | loss: 0.571   | val_0_mse: 1.701490044593811|  0:00:07s\n","epoch 28 | loss: 0.56794 | val_0_mse: 1.5457899570465088|  0:00:07s\n","epoch 29 | loss: 0.55792 | val_0_mse: 1.5422799587249756|  0:00:07s\n","epoch 30 | loss: 0.56365 | val_0_mse: 1.6853699684143066|  0:00:07s\n","epoch 31 | loss: 0.56132 | val_0_mse: 1.6256099939346313|  0:00:08s\n","epoch 32 | loss: 0.55257 | val_0_mse: 1.299430012702942|  0:00:08s\n","epoch 33 | loss: 0.55393 | val_0_mse: 1.328629970550537|  0:00:08s\n","epoch 34 | loss: 0.56091 | val_0_mse: 1.3312000036239624|  0:00:08s\n","epoch 35 | loss: 0.56809 | val_0_mse: 1.1267900466918945|  0:00:09s\n","epoch 36 | loss: 0.58319 | val_0_mse: 1.5985699892044067|  0:00:09s\n","epoch 37 | loss: 0.56124 | val_0_mse: 1.710569977760315|  0:00:09s\n","epoch 38 | loss: 0.6103  | val_0_mse: 0.9926300048828125|  0:00:09s\n","epoch 39 | loss: 0.64719 | val_0_mse: 1.1274399757385254|  0:00:10s\n","epoch 40 | loss: 0.61797 | val_0_mse: 1.0015699863433838|  0:00:10s\n","epoch 41 | loss: 0.56276 | val_0_mse: 1.1856900453567505|  0:00:10s\n","epoch 42 | loss: 0.54633 | val_0_mse: 0.8755000233650208|  0:00:10s\n","epoch 43 | loss: 0.55633 | val_0_mse: 0.9067400097846985|  0:00:11s\n","epoch 44 | loss: 0.63118 | val_0_mse: 0.9438599944114685|  0:00:11s\n","epoch 45 | loss: 0.64828 | val_0_mse: 1.5974899530410767|  0:00:11s\n","epoch 46 | loss: 0.63283 | val_0_mse: 0.7233099937438965|  0:00:11s\n","epoch 47 | loss: 0.57443 | val_0_mse: 1.0365899801254272|  0:00:12s\n","epoch 48 | loss: 0.54712 | val_0_mse: 0.7670900225639343|  0:00:12s\n","epoch 49 | loss: 0.55775 | val_0_mse: 0.8985199928283691|  0:00:12s\n","epoch 50 | loss: 0.56246 | val_0_mse: 0.8498200178146362|  0:00:12s\n","epoch 51 | loss: 0.57436 | val_0_mse: 0.8850200176239014|  0:00:13s\n","epoch 52 | loss: 0.56604 | val_0_mse: 0.9215800166130066|  0:00:13s\n","epoch 53 | loss: 0.55991 | val_0_mse: 0.725600004196167|  0:00:13s\n","epoch 54 | loss: 0.55569 | val_0_mse: 0.8119000196456909|  0:00:13s\n","epoch 55 | loss: 0.55303 | val_0_mse: 0.715969979763031|  0:00:14s\n","epoch 56 | loss: 0.55893 | val_0_mse: 0.8020200133323669|  0:00:14s\n","epoch 57 | loss: 0.55146 | val_0_mse: 0.8704900145530701|  0:00:14s\n","epoch 58 | loss: 0.56423 | val_0_mse: 0.7362599968910217|  0:00:14s\n","epoch 59 | loss: 0.55184 | val_0_mse: 0.7271999716758728|  0:00:15s\n","epoch 60 | loss: 0.52891 | val_0_mse: 0.6856899857521057|  0:00:15s\n","epoch 61 | loss: 0.5414  | val_0_mse: 0.6515100002288818|  0:00:15s\n","epoch 62 | loss: 0.54583 | val_0_mse: 0.7281500101089478|  0:00:15s\n","epoch 63 | loss: 0.54482 | val_0_mse: 0.6522899866104126|  0:00:16s\n","epoch 64 | loss: 0.58967 | val_0_mse: 0.6212300062179565|  0:00:16s\n","epoch 65 | loss: 0.57072 | val_0_mse: 0.6065800189971924|  0:00:16s\n","epoch 66 | loss: 0.54326 | val_0_mse: 0.6237499713897705|  0:00:16s\n","epoch 67 | loss: 0.52754 | val_0_mse: 0.6579899787902832|  0:00:17s\n","epoch 68 | loss: 0.5382  | val_0_mse: 0.6369199752807617|  0:00:17s\n","epoch 69 | loss: 0.5225  | val_0_mse: 0.6397200226783752|  0:00:17s\n","epoch 70 | loss: 0.53349 | val_0_mse: 0.6489400267601013|  0:00:17s\n","epoch 71 | loss: 0.52789 | val_0_mse: 0.6639400124549866|  0:00:18s\n","epoch 72 | loss: 0.52778 | val_0_mse: 0.6303600072860718|  0:00:18s\n","epoch 73 | loss: 0.52426 | val_0_mse: 0.63086998462677|  0:00:18s\n","epoch 74 | loss: 0.53785 | val_0_mse: 0.6398800015449524|  0:00:18s\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 15:54:58,099] Trial 3 finished with value: 0.6065764427185059 and parameters: {'n_d': 11, 'n_steps': 7, 'gamma': 1.4777751848221259, 'n_independent': 1, 'n_shared': 1, 'momentum': 0.05897638143153876}. Best is trial 3 with value: 0.6065764427185059.\n"]},{"output_type":"stream","name":"stdout","text":["epoch 75 | loss: 0.52564 | val_0_mse: 0.6140400171279907|  0:00:19s\n","\n","Early stopping occurred at epoch 75 with best_epoch = 65 and best_val_0_mse = 0.6065800189971924\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 21.49845| val_0_mse: 248.5722198486328|  0:00:00s\n","epoch 1  | loss: 8.60575 | val_0_mse: 437.959228515625|  0:00:01s\n","epoch 2  | loss: 4.97241 | val_0_mse: 463.1022033691406|  0:00:01s\n","epoch 3  | loss: 5.29889 | val_0_mse: 304.3331604003906|  0:00:01s\n","epoch 4  | loss: 3.65927 | val_0_mse: 38.54669952392578|  0:00:02s\n","epoch 5  | loss: 2.59605 | val_0_mse: 43.7954216003418|  0:00:02s\n","epoch 6  | loss: 1.88455 | val_0_mse: 33.63581848144531|  0:00:03s\n","epoch 7  | loss: 1.71328 | val_0_mse: 35.213829040527344|  0:00:03s\n","epoch 8  | loss: 1.48915 | val_0_mse: 40.824771881103516|  0:00:04s\n","epoch 9  | loss: 1.30307 | val_0_mse: 17.736509323120117|  0:00:04s\n","epoch 10 | loss: 1.06423 | val_0_mse: 8.637419700622559|  0:00:05s\n","epoch 11 | loss: 0.88982 | val_0_mse: 10.04026985168457|  0:00:05s\n","epoch 12 | loss: 1.16688 | val_0_mse: 3.461899995803833|  0:00:06s\n","epoch 13 | loss: 1.14873 | val_0_mse: 10.970549583435059|  0:00:06s\n","epoch 14 | loss: 2.85658 | val_0_mse: 18.303680419921875|  0:00:07s\n","epoch 15 | loss: 1.5639  | val_0_mse: 2.3584399223327637|  0:00:07s\n","epoch 16 | loss: 1.52923 | val_0_mse: 2.7555899620056152|  0:00:08s\n","epoch 17 | loss: 1.25017 | val_0_mse: 2.872080087661743|  0:00:08s\n","epoch 18 | loss: 0.95692 | val_0_mse: 1.7185800075531006|  0:00:09s\n","epoch 19 | loss: 0.83772 | val_0_mse: 2.618259906768799|  0:00:09s\n","epoch 20 | loss: 0.76605 | val_0_mse: 3.205590009689331|  0:00:10s\n","epoch 21 | loss: 0.71267 | val_0_mse: 1.5518100261688232|  0:00:10s\n","epoch 22 | loss: 0.7934  | val_0_mse: 2.6389501094818115|  0:00:11s\n","epoch 23 | loss: 0.66546 | val_0_mse: 5.2434000968933105|  0:00:11s\n","epoch 24 | loss: 0.70755 | val_0_mse: 3.498070001602173|  0:00:12s\n","epoch 25 | loss: 0.73601 | val_0_mse: 3.3896899223327637|  0:00:12s\n","epoch 26 | loss: 0.69671 | val_0_mse: 1.4349199533462524|  0:00:13s\n","epoch 27 | loss: 0.70381 | val_0_mse: 2.482340097427368|  0:00:13s\n","epoch 28 | loss: 0.65664 | val_0_mse: 1.5727499723434448|  0:00:14s\n","epoch 29 | loss: 0.68183 | val_0_mse: 2.5180399417877197|  0:00:14s\n","epoch 30 | loss: 0.68934 | val_0_mse: 1.1474299430847168|  0:00:14s\n","epoch 31 | loss: 0.69426 | val_0_mse: 2.1848599910736084|  0:00:15s\n","epoch 32 | loss: 0.72671 | val_0_mse: 1.2176300287246704|  0:00:15s\n","epoch 33 | loss: 0.68898 | val_0_mse: 2.9466300010681152|  0:00:16s\n","epoch 34 | loss: 0.75566 | val_0_mse: 1.1229699850082397|  0:00:16s\n","epoch 35 | loss: 0.62102 | val_0_mse: 1.5845400094985962|  0:00:17s\n","epoch 36 | loss: 0.62946 | val_0_mse: 0.9934099912643433|  0:00:17s\n","epoch 37 | loss: 0.63805 | val_0_mse: 1.839269995689392|  0:00:18s\n","epoch 38 | loss: 0.67272 | val_0_mse: 0.8521299958229065|  0:00:18s\n","epoch 39 | loss: 0.69834 | val_0_mse: 1.9390000104904175|  0:00:19s\n","epoch 40 | loss: 0.76983 | val_0_mse: 0.776390016078949|  0:00:19s\n","epoch 41 | loss: 0.78505 | val_0_mse: 0.9436399936676025|  0:00:20s\n","epoch 42 | loss: 0.74123 | val_0_mse: 1.3908300399780273|  0:00:20s\n","epoch 43 | loss: 0.70451 | val_0_mse: 0.8582500219345093|  0:00:21s\n","epoch 44 | loss: 0.60837 | val_0_mse: 0.9766600131988525|  0:00:21s\n","epoch 45 | loss: 0.65585 | val_0_mse: 0.9374899864196777|  0:00:22s\n","epoch 46 | loss: 0.63988 | val_0_mse: 0.8358500003814697|  0:00:22s\n","epoch 47 | loss: 0.60982 | val_0_mse: 0.7901099920272827|  0:00:23s\n","epoch 48 | loss: 0.57094 | val_0_mse: 0.8884400129318237|  0:00:23s\n","epoch 49 | loss: 0.60586 | val_0_mse: 0.762660026550293|  0:00:24s\n","epoch 50 | loss: 0.56964 | val_0_mse: 0.7262399792671204|  0:00:24s\n","epoch 51 | loss: 0.61342 | val_0_mse: 0.8418999910354614|  0:00:25s\n","epoch 52 | loss: 0.62165 | val_0_mse: 0.7296900153160095|  0:00:25s\n","epoch 53 | loss: 0.62022 | val_0_mse: 0.8624899983406067|  0:00:26s\n","epoch 54 | loss: 0.61373 | val_0_mse: 0.7921900153160095|  0:00:26s\n","epoch 55 | loss: 0.57772 | val_0_mse: 0.8062599897384644|  0:00:27s\n","epoch 56 | loss: 0.60062 | val_0_mse: 0.7459999918937683|  0:00:27s\n","epoch 57 | loss: 0.56149 | val_0_mse: 0.7104099988937378|  0:00:28s\n","epoch 58 | loss: 0.55346 | val_0_mse: 0.6611800193786621|  0:00:28s\n","epoch 59 | loss: 0.5622  | val_0_mse: 0.7182000279426575|  0:00:28s\n","epoch 60 | loss: 0.55319 | val_0_mse: 0.7238199710845947|  0:00:29s\n","epoch 61 | loss: 0.55173 | val_0_mse: 0.7095800042152405|  0:00:29s\n","epoch 62 | loss: 0.5503  | val_0_mse: 0.6537700295448303|  0:00:30s\n","epoch 63 | loss: 0.55967 | val_0_mse: 0.7235900163650513|  0:00:30s\n","epoch 64 | loss: 0.59764 | val_0_mse: 0.7929800152778625|  0:00:31s\n","epoch 65 | loss: 0.60899 | val_0_mse: 0.7659400105476379|  0:00:31s\n","epoch 66 | loss: 0.59688 | val_0_mse: 0.6696599721908569|  0:00:32s\n","epoch 67 | loss: 0.6525  | val_0_mse: 0.703000009059906|  0:00:32s\n","epoch 68 | loss: 0.70353 | val_0_mse: 0.8694300055503845|  0:00:33s\n","epoch 69 | loss: 0.62615 | val_0_mse: 0.7007399797439575|  0:00:33s\n","epoch 70 | loss: 0.65497 | val_0_mse: 0.6879299879074097|  0:00:34s\n","epoch 71 | loss: 0.64846 | val_0_mse: 0.6566900014877319|  0:00:34s\n","epoch 72 | loss: 0.65848 | val_0_mse: 0.7761899828910828|  0:00:35s\n","\n","Early stopping occurred at epoch 72 with best_epoch = 62 and best_val_0_mse = 0.6537700295448303\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 15:55:33,552] Trial 4 finished with value: 0.653770387172699 and parameters: {'n_d': 8, 'n_steps': 10, 'gamma': 1.965401599395625, 'n_independent': 2, 'n_shared': 2, 'momentum': 0.03074674949384692}. Best is trial 3 with value: 0.6065764427185059.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 13.37235| val_0_mse: 2517.40380859375|  0:00:00s\n","epoch 1  | loss: 3.26788 | val_0_mse: 505.4800109863281|  0:00:01s\n","epoch 2  | loss: 2.10077 | val_0_mse: 109.96051025390625|  0:00:01s\n","epoch 3  | loss: 1.7726  | val_0_mse: 156.59190368652344|  0:00:02s\n","epoch 4  | loss: 1.3069  | val_0_mse: 82.41285705566406|  0:00:02s\n","epoch 5  | loss: 1.05569 | val_0_mse: 9.678589820861816|  0:00:03s\n","epoch 6  | loss: 1.53591 | val_0_mse: 17.72269058227539|  0:00:03s\n","epoch 7  | loss: 1.21519 | val_0_mse: 6.102290153503418|  0:00:04s\n","epoch 8  | loss: 0.94759 | val_0_mse: 51.46773910522461|  0:00:04s\n","epoch 9  | loss: 0.8614  | val_0_mse: 5.014349937438965|  0:00:05s\n","epoch 10 | loss: 0.80006 | val_0_mse: 3.138540029525757|  0:00:05s\n","epoch 11 | loss: 1.17527 | val_0_mse: 8.734720230102539|  0:00:06s\n","epoch 12 | loss: 0.76853 | val_0_mse: 4.531499862670898|  0:00:06s\n","epoch 13 | loss: 0.75633 | val_0_mse: 3.001699924468994|  0:00:07s\n","epoch 14 | loss: 0.7518  | val_0_mse: 2.8636600971221924|  0:00:07s\n","epoch 15 | loss: 0.76393 | val_0_mse: 3.5173499584198|  0:00:08s\n","epoch 16 | loss: 0.72351 | val_0_mse: 10.440099716186523|  0:00:09s\n","epoch 17 | loss: 0.67695 | val_0_mse: 7.424099922180176|  0:00:09s\n","epoch 18 | loss: 0.68619 | val_0_mse: 1.741629958152771|  0:00:10s\n","epoch 19 | loss: 0.65057 | val_0_mse: 3.0311100482940674|  0:00:10s\n","epoch 20 | loss: 0.61875 | val_0_mse: 2.8230700492858887|  0:00:11s\n","epoch 21 | loss: 0.62096 | val_0_mse: 6.614729881286621|  0:00:11s\n","epoch 22 | loss: 0.76753 | val_0_mse: 5.292570114135742|  0:00:12s\n","epoch 23 | loss: 0.70933 | val_0_mse: 8.814149856567383|  0:00:12s\n","epoch 24 | loss: 0.63772 | val_0_mse: 1.2375400066375732|  0:00:13s\n","epoch 25 | loss: 0.68655 | val_0_mse: 4.054440021514893|  0:00:13s\n","epoch 26 | loss: 0.68223 | val_0_mse: 1.2468600273132324|  0:00:14s\n","epoch 27 | loss: 0.69597 | val_0_mse: 3.1877601146698|  0:00:14s\n","epoch 28 | loss: 0.61259 | val_0_mse: 2.6948399543762207|  0:00:15s\n","epoch 29 | loss: 0.69733 | val_0_mse: 1.877769947052002|  0:00:15s\n","epoch 30 | loss: 0.58876 | val_0_mse: 0.9619399905204773|  0:00:16s\n","epoch 31 | loss: 0.58379 | val_0_mse: 1.6925499439239502|  0:00:17s\n","epoch 32 | loss: 0.55508 | val_0_mse: 1.1335500478744507|  0:00:17s\n","epoch 33 | loss: 0.5731  | val_0_mse: 1.3309099674224854|  0:00:18s\n","epoch 34 | loss: 0.60896 | val_0_mse: 1.6049699783325195|  0:00:18s\n","epoch 35 | loss: 0.56041 | val_0_mse: 1.2415800094604492|  0:00:19s\n","epoch 36 | loss: 0.57333 | val_0_mse: 1.4983199834823608|  0:00:19s\n","epoch 37 | loss: 0.55652 | val_0_mse: 1.1098999977111816|  0:00:20s\n","epoch 38 | loss: 0.54548 | val_0_mse: 1.3084100484848022|  0:00:20s\n","epoch 39 | loss: 0.53567 | val_0_mse: 1.0186599493026733|  0:00:21s\n","epoch 40 | loss: 0.56477 | val_0_mse: 1.1242300271987915|  0:00:21s\n","\n","Early stopping occurred at epoch 40 with best_epoch = 30 and best_val_0_mse = 0.9619399905204773\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 15:55:55,689] Trial 5 finished with value: 0.9619372487068176 and parameters: {'n_d': 34, 'n_steps': 8, 'gamma': 1.1953122079985619, 'n_independent': 4, 'n_shared': 2, 'momentum': 0.12867325700622606}. Best is trial 3 with value: 0.6065764427185059.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 31.83272| val_0_mse: 1770.201171875|  0:00:00s\n","epoch 1  | loss: 7.54723 | val_0_mse: 1958.6705322265625|  0:00:01s\n","epoch 2  | loss: 4.40607 | val_0_mse: 1389.8670654296875|  0:00:01s\n","epoch 3  | loss: 2.54211 | val_0_mse: 1044.822265625|  0:00:02s\n","epoch 4  | loss: 1.90118 | val_0_mse: 589.7451171875|  0:00:03s\n","epoch 5  | loss: 1.47301 | val_0_mse: 251.293701171875|  0:00:03s\n","epoch 6  | loss: 1.23782 | val_0_mse: 318.4278869628906|  0:00:04s\n","epoch 7  | loss: 1.4011  | val_0_mse: 371.6029052734375|  0:00:05s\n","epoch 8  | loss: 1.08776 | val_0_mse: 52.28705978393555|  0:00:05s\n","epoch 9  | loss: 1.11832 | val_0_mse: 43.70391845703125|  0:00:06s\n","epoch 10 | loss: 1.24076 | val_0_mse: 9.595179557800293|  0:00:07s\n","epoch 11 | loss: 0.93922 | val_0_mse: 10.834429740905762|  0:00:07s\n","epoch 12 | loss: 1.14331 | val_0_mse: 2.726219892501831|  0:00:08s\n","epoch 13 | loss: 1.52075 | val_0_mse: 25.887420654296875|  0:00:08s\n","epoch 14 | loss: 3.38543 | val_0_mse: 12.960709571838379|  0:00:09s\n","epoch 15 | loss: 0.91508 | val_0_mse: 10.082340240478516|  0:00:10s\n","epoch 16 | loss: 0.99962 | val_0_mse: 7.672440052032471|  0:00:10s\n","epoch 17 | loss: 0.90675 | val_0_mse: 12.382559776306152|  0:00:11s\n","epoch 18 | loss: 1.70295 | val_0_mse: 6.438930034637451|  0:00:12s\n","epoch 19 | loss: 1.25692 | val_0_mse: 1.751960039138794|  0:00:12s\n","epoch 20 | loss: 1.15043 | val_0_mse: 4.937860012054443|  0:00:13s\n","epoch 21 | loss: 0.96011 | val_0_mse: 1.630910038948059|  0:00:14s\n","epoch 22 | loss: 0.99902 | val_0_mse: 10.756580352783203|  0:00:14s\n","epoch 23 | loss: 2.94134 | val_0_mse: 23.603540420532227|  0:00:15s\n","epoch 24 | loss: 3.31547 | val_0_mse: 1.788059949874878|  0:00:15s\n","epoch 25 | loss: 1.79806 | val_0_mse: 1.3831599950790405|  0:00:16s\n","epoch 26 | loss: 0.85267 | val_0_mse: 2.4923501014709473|  0:00:17s\n","epoch 27 | loss: 0.73667 | val_0_mse: 1.0969799757003784|  0:00:17s\n","epoch 28 | loss: 0.6795  | val_0_mse: 1.2999500036239624|  0:00:18s\n","epoch 29 | loss: 0.62992 | val_0_mse: 1.333709955215454|  0:00:19s\n","epoch 30 | loss: 0.62861 | val_0_mse: 1.2493699789047241|  0:00:19s\n","epoch 31 | loss: 0.61254 | val_0_mse: 1.091380000114441|  0:00:20s\n","epoch 32 | loss: 0.61249 | val_0_mse: 1.8627300262451172|  0:00:21s\n","epoch 33 | loss: 0.62849 | val_0_mse: 2.023590087890625|  0:00:21s\n","epoch 34 | loss: 0.60217 | val_0_mse: 1.0469399690628052|  0:00:22s\n","epoch 35 | loss: 0.70656 | val_0_mse: 1.530419945716858|  0:00:22s\n","epoch 36 | loss: 0.7363  | val_0_mse: 0.9649400115013123|  0:00:23s\n","epoch 37 | loss: 0.68421 | val_0_mse: 1.2786200046539307|  0:00:24s\n","epoch 38 | loss: 0.77173 | val_0_mse: 0.7815499901771545|  0:00:24s\n","epoch 39 | loss: 0.84682 | val_0_mse: 2.4911000728607178|  0:00:25s\n","epoch 40 | loss: 0.97077 | val_0_mse: 1.0415699481964111|  0:00:26s\n","epoch 41 | loss: 0.68596 | val_0_mse: 1.5873099565505981|  0:00:26s\n","epoch 42 | loss: 0.8281  | val_0_mse: 0.864359974861145|  0:00:27s\n","epoch 43 | loss: 1.96403 | val_0_mse: 1.0716400146484375|  0:00:27s\n","epoch 44 | loss: 1.07926 | val_0_mse: 1.8712899684906006|  0:00:28s\n","epoch 45 | loss: 0.89252 | val_0_mse: 0.7134100198745728|  0:00:29s\n","epoch 46 | loss: 1.27754 | val_0_mse: 0.8348199725151062|  0:00:30s\n","epoch 47 | loss: 0.83208 | val_0_mse: 1.6279900074005127|  0:00:30s\n","epoch 48 | loss: 0.81121 | val_0_mse: 0.7248899936676025|  0:00:31s\n","epoch 49 | loss: 0.65564 | val_0_mse: 0.7648100256919861|  0:00:31s\n","epoch 50 | loss: 0.59797 | val_0_mse: 0.692579984664917|  0:00:32s\n","epoch 51 | loss: 0.59757 | val_0_mse: 1.358109951019287|  0:00:33s\n","epoch 52 | loss: 0.64431 | val_0_mse: 0.7218400239944458|  0:00:33s\n","epoch 53 | loss: 0.73003 | val_0_mse: 1.3273999691009521|  0:00:34s\n","epoch 54 | loss: 0.71894 | val_0_mse: 0.6800100207328796|  0:00:35s\n","epoch 55 | loss: 0.71674 | val_0_mse: 0.920960009098053|  0:00:35s\n","epoch 56 | loss: 0.62535 | val_0_mse: 0.6484299898147583|  0:00:36s\n","epoch 57 | loss: 0.68418 | val_0_mse: 0.8416200280189514|  0:00:37s\n","epoch 58 | loss: 0.64988 | val_0_mse: 0.7271599769592285|  0:00:37s\n","epoch 59 | loss: 0.66227 | val_0_mse: 0.9858899712562561|  0:00:38s\n","epoch 60 | loss: 0.66763 | val_0_mse: 0.6202099919319153|  0:00:38s\n","epoch 61 | loss: 0.57455 | val_0_mse: 0.7192100286483765|  0:00:39s\n","epoch 62 | loss: 0.5857  | val_0_mse: 0.6836900115013123|  0:00:40s\n","epoch 63 | loss: 0.6304  | val_0_mse: 0.7551199793815613|  0:00:40s\n","epoch 64 | loss: 0.55924 | val_0_mse: 0.710889995098114|  0:00:41s\n","epoch 65 | loss: 0.55968 | val_0_mse: 0.6128299832344055|  0:00:42s\n","epoch 66 | loss: 0.57091 | val_0_mse: 0.6428499817848206|  0:00:42s\n","epoch 67 | loss: 0.57436 | val_0_mse: 0.64410001039505|  0:00:43s\n","epoch 68 | loss: 0.55561 | val_0_mse: 0.6197599768638611|  0:00:43s\n","epoch 69 | loss: 0.5527  | val_0_mse: 0.6202200055122375|  0:00:44s\n","epoch 70 | loss: 0.62011 | val_0_mse: 0.6841800212860107|  0:00:45s\n","epoch 71 | loss: 0.55778 | val_0_mse: 0.6213700175285339|  0:00:45s\n","epoch 72 | loss: 0.57359 | val_0_mse: 0.6283000111579895|  0:00:46s\n","epoch 73 | loss: 0.55765 | val_0_mse: 0.5990800261497498|  0:00:47s\n","epoch 74 | loss: 0.55701 | val_0_mse: 0.6688799858093262|  0:00:47s\n","epoch 75 | loss: 0.55618 | val_0_mse: 0.5961899757385254|  0:00:48s\n","epoch 76 | loss: 0.56138 | val_0_mse: 0.5919100046157837|  0:00:49s\n","epoch 77 | loss: 0.5816  | val_0_mse: 0.7913100123405457|  0:00:49s\n","epoch 78 | loss: 0.66929 | val_0_mse: 0.8107699751853943|  0:00:50s\n","epoch 79 | loss: 0.71127 | val_0_mse: 0.7715399861335754|  0:00:50s\n","epoch 80 | loss: 0.62493 | val_0_mse: 0.6236500144004822|  0:00:51s\n","epoch 81 | loss: 0.60269 | val_0_mse: 0.6905900239944458|  0:00:52s\n","epoch 82 | loss: 0.57771 | val_0_mse: 0.6011599898338318|  0:00:52s\n","epoch 83 | loss: 0.57873 | val_0_mse: 0.608680009841919|  0:00:53s\n","epoch 84 | loss: 0.60026 | val_0_mse: 0.6372299790382385|  0:00:54s\n","epoch 85 | loss: 0.6129  | val_0_mse: 0.6699900031089783|  0:00:54s\n","epoch 86 | loss: 0.5894  | val_0_mse: 0.6223300099372864|  0:00:55s\n","\n","Early stopping occurred at epoch 86 with best_epoch = 76 and best_val_0_mse = 0.5919100046157837\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 15:56:51,360] Trial 6 finished with value: 0.5919058918952942 and parameters: {'n_d': 22, 'n_steps': 10, 'gamma': 1.4331357700152436, 'n_independent': 1, 'n_shared': 5, 'momentum': 0.08168136985971068}. Best is trial 6 with value: 0.5919058918952942.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 11.01032| val_0_mse: 175.31663513183594|  0:00:00s\n","epoch 1  | loss: 2.12619 | val_0_mse: 49.33205032348633|  0:00:00s\n","epoch 2  | loss: 1.44598 | val_0_mse: 46.687538146972656|  0:00:00s\n","epoch 3  | loss: 1.10644 | val_0_mse: 37.414180755615234|  0:00:01s\n","epoch 4  | loss: 1.36334 | val_0_mse: 17.530319213867188|  0:00:01s\n","epoch 5  | loss: 1.41707 | val_0_mse: 11.084939956665039|  0:00:01s\n","epoch 6  | loss: 1.27908 | val_0_mse: 26.34037971496582|  0:00:02s\n","epoch 7  | loss: 0.9308  | val_0_mse: 6.45605993270874|  0:00:02s\n","epoch 8  | loss: 0.85784 | val_0_mse: 11.916760444641113|  0:00:02s\n","epoch 9  | loss: 0.74509 | val_0_mse: 16.391279220581055|  0:00:02s\n","epoch 10 | loss: 0.69675 | val_0_mse: 7.333189964294434|  0:00:03s\n","epoch 11 | loss: 0.68764 | val_0_mse: 11.231889724731445|  0:00:03s\n","epoch 12 | loss: 0.65498 | val_0_mse: 8.317709922790527|  0:00:03s\n","epoch 13 | loss: 0.64397 | val_0_mse: 9.403630256652832|  0:00:04s\n","epoch 14 | loss: 0.65122 | val_0_mse: 4.249380111694336|  0:00:04s\n","epoch 15 | loss: 0.65904 | val_0_mse: 15.812970161437988|  0:00:04s\n","epoch 16 | loss: 0.63403 | val_0_mse: 4.130050182342529|  0:00:04s\n","epoch 17 | loss: 0.62074 | val_0_mse: 2.5594100952148438|  0:00:05s\n","epoch 18 | loss: 0.61809 | val_0_mse: 3.2606499195098877|  0:00:05s\n","epoch 19 | loss: 0.7156  | val_0_mse: 2.829440116882324|  0:00:05s\n","epoch 20 | loss: 0.67022 | val_0_mse: 2.007159948348999|  0:00:05s\n","epoch 21 | loss: 0.64099 | val_0_mse: 2.0902600288391113|  0:00:06s\n","epoch 22 | loss: 0.63506 | val_0_mse: 1.7569299936294556|  0:00:06s\n","epoch 23 | loss: 0.60789 | val_0_mse: 2.688339948654175|  0:00:06s\n","epoch 24 | loss: 0.57694 | val_0_mse: 2.5661299228668213|  0:00:07s\n","epoch 25 | loss: 0.63133 | val_0_mse: 1.8993699550628662|  0:00:07s\n","epoch 26 | loss: 0.6126  | val_0_mse: 1.4441699981689453|  0:00:07s\n","epoch 27 | loss: 0.60703 | val_0_mse: 1.5692499876022339|  0:00:08s\n","epoch 28 | loss: 0.59839 | val_0_mse: 1.5237400531768799|  0:00:08s\n","epoch 29 | loss: 0.57047 | val_0_mse: 2.068160057067871|  0:00:08s\n","epoch 30 | loss: 0.60906 | val_0_mse: 0.8984699845314026|  0:00:08s\n","epoch 31 | loss: 0.67984 | val_0_mse: 2.1336801052093506|  0:00:09s\n","epoch 32 | loss: 0.65695 | val_0_mse: 1.0253599882125854|  0:00:09s\n","epoch 33 | loss: 0.58487 | val_0_mse: 1.465809941291809|  0:00:09s\n","epoch 34 | loss: 0.55819 | val_0_mse: 1.3411699533462524|  0:00:10s\n","epoch 35 | loss: 0.56221 | val_0_mse: 1.1764899492263794|  0:00:10s\n","epoch 36 | loss: 0.53116 | val_0_mse: 1.080340027809143|  0:00:10s\n","epoch 37 | loss: 0.53044 | val_0_mse: 0.9946600198745728|  0:00:10s\n","epoch 38 | loss: 0.51403 | val_0_mse: 0.9970300197601318|  0:00:11s\n","epoch 39 | loss: 0.52798 | val_0_mse: 0.9534000158309937|  0:00:11s\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 15:57:03,243] Trial 7 finished with value: 0.8984678387641907 and parameters: {'n_d': 36, 'n_steps': 5, 'gamma': 1.4666885723245495, 'n_independent': 2, 'n_shared': 2, 'momentum': 0.062217004089899754}. Best is trial 6 with value: 0.5919058918952942.\n"]},{"output_type":"stream","name":"stdout","text":["epoch 40 | loss: 0.52724 | val_0_mse: 1.156599998474121|  0:00:11s\n","\n","Early stopping occurred at epoch 40 with best_epoch = 30 and best_val_0_mse = 0.8984699845314026\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 19.49907| val_0_mse: 1413.0498046875|  0:00:00s\n","epoch 1  | loss: 3.58288 | val_0_mse: 1577.1033935546875|  0:00:00s\n","epoch 2  | loss: 1.70954 | val_0_mse: 731.7402954101562|  0:00:00s\n","epoch 3  | loss: 1.13743 | val_0_mse: 321.29119873046875|  0:00:00s\n","epoch 4  | loss: 0.8523  | val_0_mse: 65.02549743652344|  0:00:01s\n","epoch 5  | loss: 0.75222 | val_0_mse: 73.8912582397461|  0:00:01s\n","epoch 6  | loss: 0.72096 | val_0_mse: 36.86547088623047|  0:00:01s\n","epoch 7  | loss: 0.68025 | val_0_mse: 21.03466033935547|  0:00:01s\n","epoch 8  | loss: 0.63585 | val_0_mse: 19.336660385131836|  0:00:01s\n","epoch 9  | loss: 0.63054 | val_0_mse: 6.656779766082764|  0:00:02s\n","epoch 10 | loss: 0.60802 | val_0_mse: 6.037610054016113|  0:00:02s\n","epoch 11 | loss: 0.60361 | val_0_mse: 2.749380111694336|  0:00:02s\n","epoch 12 | loss: 0.60469 | val_0_mse: 3.2817399501800537|  0:00:02s\n","epoch 13 | loss: 0.58705 | val_0_mse: 2.5090599060058594|  0:00:02s\n","epoch 14 | loss: 0.5719  | val_0_mse: 2.113149881362915|  0:00:03s\n","epoch 15 | loss: 0.57407 | val_0_mse: 1.1642199754714966|  0:00:03s\n","epoch 16 | loss: 0.57493 | val_0_mse: 1.4523799419403076|  0:00:03s\n","epoch 17 | loss: 0.54752 | val_0_mse: 1.32614004611969|  0:00:03s\n","epoch 18 | loss: 0.56012 | val_0_mse: 1.2903599739074707|  0:00:03s\n","epoch 19 | loss: 0.56757 | val_0_mse: 1.2403600215911865|  0:00:04s\n","epoch 20 | loss: 0.55661 | val_0_mse: 1.0740100145339966|  0:00:04s\n","epoch 21 | loss: 0.56257 | val_0_mse: 1.0503699779510498|  0:00:04s\n","epoch 22 | loss: 0.54712 | val_0_mse: 1.263260006904602|  0:00:04s\n","epoch 23 | loss: 0.53514 | val_0_mse: 1.0505499839782715|  0:00:04s\n","epoch 24 | loss: 0.55081 | val_0_mse: 1.4326900243759155|  0:00:05s\n","epoch 25 | loss: 0.53222 | val_0_mse: 1.4388600587844849|  0:00:05s\n","epoch 26 | loss: 0.5321  | val_0_mse: 1.1832499504089355|  0:00:05s\n","epoch 27 | loss: 0.51423 | val_0_mse: 1.2724900245666504|  0:00:05s\n","epoch 28 | loss: 0.51147 | val_0_mse: 1.1869200468063354|  0:00:05s\n","epoch 29 | loss: 0.51933 | val_0_mse: 1.0562100410461426|  0:00:06s\n","epoch 30 | loss: 0.50689 | val_0_mse: 1.0619800090789795|  0:00:06s\n","epoch 31 | loss: 0.49379 | val_0_mse: 1.113700032234192|  0:00:06s\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 15:57:09,949] Trial 8 finished with value: 1.0503731966018677 and parameters: {'n_d': 25, 'n_steps': 4, 'gamma': 1.4295438007983345, 'n_independent': 1, 'n_shared': 2, 'momentum': 0.22829780640110325}. Best is trial 6 with value: 0.5919058918952942.\n"]},{"output_type":"stream","name":"stdout","text":["\n","Early stopping occurred at epoch 31 with best_epoch = 21 and best_val_0_mse = 1.0503699779510498\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 16.46967| val_0_mse: 3977.358154296875|  0:00:00s\n","epoch 1  | loss: 5.93204 | val_0_mse: 562.7103881835938|  0:00:00s\n","epoch 2  | loss: 2.80674 | val_0_mse: 141.40304565429688|  0:00:00s\n","epoch 3  | loss: 1.86073 | val_0_mse: 48.823219299316406|  0:00:01s\n","epoch 4  | loss: 1.28589 | val_0_mse: 37.46902084350586|  0:00:01s\n","epoch 5  | loss: 1.03358 | val_0_mse: 9.661009788513184|  0:00:01s\n","epoch 6  | loss: 0.91231 | val_0_mse: 17.00901985168457|  0:00:02s\n","epoch 7  | loss: 0.94335 | val_0_mse: 18.83776092529297|  0:00:02s\n","epoch 8  | loss: 0.83465 | val_0_mse: 78.64399719238281|  0:00:02s\n","epoch 9  | loss: 0.8347  | val_0_mse: 64.61212921142578|  0:00:03s\n","epoch 10 | loss: 0.82295 | val_0_mse: 21.160280227661133|  0:00:03s\n","epoch 11 | loss: 0.75632 | val_0_mse: 7.480040073394775|  0:00:03s\n","epoch 12 | loss: 0.70649 | val_0_mse: 4.987549781799316|  0:00:04s\n","epoch 13 | loss: 0.70933 | val_0_mse: 17.186309814453125|  0:00:04s\n","epoch 14 | loss: 0.67583 | val_0_mse: 4.403220176696777|  0:00:04s\n","epoch 15 | loss: 0.63569 | val_0_mse: 3.670870065689087|  0:00:05s\n","epoch 16 | loss: 0.67882 | val_0_mse: 1.3689299821853638|  0:00:05s\n","epoch 17 | loss: 0.68367 | val_0_mse: 5.609189987182617|  0:00:05s\n","epoch 18 | loss: 0.64401 | val_0_mse: 2.96235990524292|  0:00:06s\n","epoch 19 | loss: 0.65699 | val_0_mse: 0.9335899949073792|  0:00:06s\n","epoch 20 | loss: 0.69915 | val_0_mse: 3.5678000450134277|  0:00:06s\n","epoch 21 | loss: 0.65606 | val_0_mse: 1.941159963607788|  0:00:07s\n","epoch 22 | loss: 0.60261 | val_0_mse: 4.121729850769043|  0:00:07s\n","epoch 23 | loss: 0.61736 | val_0_mse: 7.408559799194336|  0:00:07s\n","epoch 24 | loss: 0.61099 | val_0_mse: 3.132889986038208|  0:00:08s\n","epoch 25 | loss: 0.62194 | val_0_mse: 1.3666900396347046|  0:00:08s\n","epoch 26 | loss: 0.59455 | val_0_mse: 1.1560200452804565|  0:00:08s\n","epoch 27 | loss: 0.62201 | val_0_mse: 1.0969300270080566|  0:00:09s\n","epoch 28 | loss: 0.63126 | val_0_mse: 1.6417499780654907|  0:00:09s\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 15:57:19,804] Trial 9 finished with value: 0.9335858225822449 and parameters: {'n_d': 26, 'n_steps': 6, 'gamma': 1.7211494858180227, 'n_independent': 2, 'n_shared': 2, 'momentum': 0.14639484872663897}. Best is trial 6 with value: 0.5919058918952942.\n"]},{"output_type":"stream","name":"stdout","text":["epoch 29 | loss: 0.61156 | val_0_mse: 1.2489399909973145|  0:00:09s\n","\n","Early stopping occurred at epoch 29 with best_epoch = 19 and best_val_0_mse = 0.9335899949073792\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 54.92579| val_0_mse: 9917.603515625|  0:00:00s\n","epoch 1  | loss: 4.44832 | val_0_mse: 771.566650390625|  0:00:01s\n","epoch 2  | loss: 3.04318 | val_0_mse: 292.14093017578125|  0:00:02s\n","epoch 3  | loss: 3.32272 | val_0_mse: 237.2747344970703|  0:00:03s\n","epoch 4  | loss: 2.24446 | val_0_mse: 50.655941009521484|  0:00:04s\n","epoch 5  | loss: 1.70823 | val_0_mse: 368.868408203125|  0:00:04s\n","epoch 6  | loss: 5.9483  | val_0_mse: 46.75682067871094|  0:00:05s\n","epoch 7  | loss: 2.9429  | val_0_mse: 92.47518920898438|  0:00:06s\n","epoch 8  | loss: 1.3274  | val_0_mse: 94.24977111816406|  0:00:07s\n","epoch 9  | loss: 1.01782 | val_0_mse: 31.692779541015625|  0:00:08s\n","epoch 10 | loss: 0.80286 | val_0_mse: 45.05168151855469|  0:00:08s\n","epoch 11 | loss: 0.73051 | val_0_mse: 17.902740478515625|  0:00:09s\n","epoch 12 | loss: 0.77742 | val_0_mse: 8.46697998046875|  0:00:10s\n","epoch 13 | loss: 0.73807 | val_0_mse: 4.567379951477051|  0:00:11s\n","epoch 14 | loss: 0.80806 | val_0_mse: 21.473520278930664|  0:00:12s\n","epoch 15 | loss: 0.7416  | val_0_mse: 5.127079963684082|  0:00:12s\n","epoch 16 | loss: 0.6851  | val_0_mse: 4.001049995422363|  0:00:13s\n","epoch 17 | loss: 0.631   | val_0_mse: 6.6950201988220215|  0:00:14s\n","epoch 18 | loss: 0.5964  | val_0_mse: 3.360069990158081|  0:00:15s\n","epoch 19 | loss: 0.55456 | val_0_mse: 1.9574300050735474|  0:00:16s\n","epoch 20 | loss: 0.58219 | val_0_mse: 2.4328699111938477|  0:00:16s\n","epoch 21 | loss: 0.61383 | val_0_mse: 2.3106000423431396|  0:00:17s\n","epoch 22 | loss: 0.5913  | val_0_mse: 3.7809998989105225|  0:00:18s\n","epoch 23 | loss: 0.59655 | val_0_mse: 2.8781399726867676|  0:00:19s\n","epoch 24 | loss: 0.58013 | val_0_mse: 2.634200096130371|  0:00:20s\n","epoch 25 | loss: 0.59245 | val_0_mse: 3.79256010055542|  0:00:20s\n","epoch 26 | loss: 0.59804 | val_0_mse: 2.232340097427368|  0:00:21s\n","epoch 27 | loss: 0.56107 | val_0_mse: 2.0940799713134766|  0:00:22s\n","epoch 28 | loss: 0.58509 | val_0_mse: 4.144619941711426|  0:00:23s\n","epoch 29 | loss: 0.64814 | val_0_mse: 1.1140899658203125|  0:00:23s\n","epoch 30 | loss: 0.65966 | val_0_mse: 2.0385899543762207|  0:00:24s\n","epoch 31 | loss: 0.63158 | val_0_mse: 1.6779199838638306|  0:00:25s\n","epoch 32 | loss: 0.57742 | val_0_mse: 1.0300899744033813|  0:00:26s\n","epoch 33 | loss: 0.56875 | val_0_mse: 1.3961999416351318|  0:00:27s\n","epoch 34 | loss: 0.56314 | val_0_mse: 1.3217500448226929|  0:00:27s\n","epoch 35 | loss: 0.57059 | val_0_mse: 1.3272500038146973|  0:00:28s\n","epoch 36 | loss: 0.61879 | val_0_mse: 1.1062599420547485|  0:00:29s\n","epoch 37 | loss: 0.68627 | val_0_mse: 1.89506995677948|  0:00:30s\n","epoch 38 | loss: 0.62307 | val_0_mse: 1.8629000186920166|  0:00:31s\n","epoch 39 | loss: 0.63153 | val_0_mse: 1.1204500198364258|  0:00:31s\n","epoch 40 | loss: 0.58392 | val_0_mse: 1.1422100067138672|  0:00:32s\n","epoch 41 | loss: 0.54208 | val_0_mse: 1.4933500289916992|  0:00:33s\n","epoch 42 | loss: 0.53582 | val_0_mse: 1.2033499479293823|  0:00:34s\n","\n","Early stopping occurred at epoch 42 with best_epoch = 32 and best_val_0_mse = 1.0300899744033813\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 15:57:54,404] Trial 10 finished with value: 1.030089020729065 and parameters: {'n_d': 52, 'n_steps': 8, 'gamma': 1.0655380417018456, 'n_independent': 5, 'n_shared': 5, 'momentum': 0.35603398728134267}. Best is trial 6 with value: 0.5919058918952942.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 16.13394| val_0_mse: 1068.9952392578125|  0:00:00s\n","epoch 1  | loss: 5.75451 | val_0_mse: 425.7768249511719|  0:00:01s\n","epoch 2  | loss: 2.22531 | val_0_mse: 128.10340881347656|  0:00:01s\n","epoch 3  | loss: 1.74787 | val_0_mse: 92.46721649169922|  0:00:02s\n","epoch 4  | loss: 1.76955 | val_0_mse: 44.98421859741211|  0:00:02s\n","epoch 5  | loss: 2.76814 | val_0_mse: 33.75115966796875|  0:00:03s\n","epoch 6  | loss: 1.55285 | val_0_mse: 6.8338398933410645|  0:00:04s\n","epoch 7  | loss: 1.67412 | val_0_mse: 10.866800308227539|  0:00:04s\n","epoch 8  | loss: 1.00321 | val_0_mse: 14.397720336914062|  0:00:05s\n","epoch 9  | loss: 0.95226 | val_0_mse: 6.622819900512695|  0:00:05s\n","epoch 10 | loss: 0.86959 | val_0_mse: 10.238789558410645|  0:00:06s\n","epoch 11 | loss: 0.8659  | val_0_mse: 5.2880401611328125|  0:00:07s\n","epoch 12 | loss: 0.83515 | val_0_mse: 3.670099973678589|  0:00:07s\n","epoch 13 | loss: 0.74724 | val_0_mse: 5.422130107879639|  0:00:08s\n","epoch 14 | loss: 0.71948 | val_0_mse: 4.073060035705566|  0:00:09s\n","epoch 15 | loss: 0.80822 | val_0_mse: 3.9528400897979736|  0:00:09s\n","epoch 16 | loss: 0.78665 | val_0_mse: 1.8910499811172485|  0:00:10s\n","epoch 17 | loss: 0.83912 | val_0_mse: 4.907299995422363|  0:00:10s\n","epoch 18 | loss: 0.72047 | val_0_mse: 5.075150012969971|  0:00:11s\n","epoch 19 | loss: 0.69039 | val_0_mse: 9.16094970703125|  0:00:11s\n","epoch 20 | loss: 0.70812 | val_0_mse: 6.5011701583862305|  0:00:12s\n","epoch 21 | loss: 0.67278 | val_0_mse: 3.6919898986816406|  0:00:13s\n","epoch 22 | loss: 0.75197 | val_0_mse: 3.0402400493621826|  0:00:13s\n","epoch 23 | loss: 0.8075  | val_0_mse: 1.2638599872589111|  0:00:14s\n","epoch 24 | loss: 0.96186 | val_0_mse: 2.853019952774048|  0:00:14s\n","epoch 25 | loss: 0.81883 | val_0_mse: 1.8607399463653564|  0:00:15s\n","epoch 26 | loss: 0.7936  | val_0_mse: 2.208240032196045|  0:00:16s\n","epoch 27 | loss: 0.69807 | val_0_mse: 2.326479911804199|  0:00:16s\n","epoch 28 | loss: 0.71929 | val_0_mse: 1.4286199808120728|  0:00:17s\n","epoch 29 | loss: 0.77301 | val_0_mse: 2.1813299655914307|  0:00:17s\n","epoch 30 | loss: 0.65291 | val_0_mse: 2.4617700576782227|  0:00:18s\n","epoch 31 | loss: 0.60779 | val_0_mse: 1.7360399961471558|  0:00:18s\n","epoch 32 | loss: 0.58894 | val_0_mse: 1.430780053138733|  0:00:19s\n","epoch 33 | loss: 0.62323 | val_0_mse: 0.9265900254249573|  0:00:20s\n","epoch 34 | loss: 0.62004 | val_0_mse: 1.4291900396347046|  0:00:20s\n","epoch 35 | loss: 0.61321 | val_0_mse: 1.4816700220108032|  0:00:21s\n","epoch 36 | loss: 0.60948 | val_0_mse: 1.4929300546646118|  0:00:21s\n","epoch 37 | loss: 0.62994 | val_0_mse: 1.7193800210952759|  0:00:22s\n","epoch 38 | loss: 0.60521 | val_0_mse: 1.2970399856567383|  0:00:23s\n","epoch 39 | loss: 0.65346 | val_0_mse: 1.0131200551986694|  0:00:23s\n","epoch 40 | loss: 0.65275 | val_0_mse: 1.4968199729919434|  0:00:24s\n","epoch 41 | loss: 0.60835 | val_0_mse: 0.7671200037002563|  0:00:24s\n","epoch 42 | loss: 0.68971 | val_0_mse: 1.6604399681091309|  0:00:25s\n","epoch 43 | loss: 0.64916 | val_0_mse: 0.9644899964332581|  0:00:25s\n","epoch 44 | loss: 0.60481 | val_0_mse: 1.3409700393676758|  0:00:26s\n","epoch 45 | loss: 0.6351  | val_0_mse: 0.7087799906730652|  0:00:27s\n","epoch 46 | loss: 0.64041 | val_0_mse: 1.454759955406189|  0:00:27s\n","epoch 47 | loss: 0.62032 | val_0_mse: 0.8232700228691101|  0:00:28s\n","epoch 48 | loss: 0.61474 | val_0_mse: 1.4192800521850586|  0:00:28s\n","epoch 49 | loss: 0.57171 | val_0_mse: 0.875980019569397|  0:00:29s\n","epoch 50 | loss: 0.56548 | val_0_mse: 1.0984599590301514|  0:00:30s\n","epoch 51 | loss: 0.65732 | val_0_mse: 0.8865699768066406|  0:00:30s\n","epoch 52 | loss: 0.57494 | val_0_mse: 1.2551100254058838|  0:00:31s\n","epoch 53 | loss: 0.64394 | val_0_mse: 0.7383000254631042|  0:00:31s\n","epoch 54 | loss: 0.67551 | val_0_mse: 1.6051199436187744|  0:00:32s\n","epoch 55 | loss: 0.69278 | val_0_mse: 0.6972100138664246|  0:00:32s\n","epoch 56 | loss: 0.61934 | val_0_mse: 0.9308000206947327|  0:00:33s\n","epoch 57 | loss: 0.60716 | val_0_mse: 0.6710299849510193|  0:00:34s\n","epoch 58 | loss: 0.82872 | val_0_mse: 0.7198799848556519|  0:00:34s\n","epoch 59 | loss: 0.65196 | val_0_mse: 0.7854899764060974|  0:00:35s\n","epoch 60 | loss: 0.57887 | val_0_mse: 0.7119699716567993|  0:00:36s\n","epoch 61 | loss: 0.54269 | val_0_mse: 0.7160999774932861|  0:00:36s\n","epoch 62 | loss: 0.59603 | val_0_mse: 0.8196300268173218|  0:00:37s\n","epoch 63 | loss: 0.58444 | val_0_mse: 0.7866899967193604|  0:00:37s\n","epoch 64 | loss: 0.56685 | val_0_mse: 0.6413300037384033|  0:00:38s\n","epoch 65 | loss: 0.55212 | val_0_mse: 0.6914499998092651|  0:00:39s\n","epoch 66 | loss: 0.5415  | val_0_mse: 0.7354199886322021|  0:00:39s\n","epoch 67 | loss: 0.56398 | val_0_mse: 0.6505200266838074|  0:00:40s\n","epoch 68 | loss: 0.55054 | val_0_mse: 0.6653100252151489|  0:00:40s\n","epoch 69 | loss: 0.54971 | val_0_mse: 0.7642899751663208|  0:00:41s\n","epoch 70 | loss: 0.53809 | val_0_mse: 0.6470999717712402|  0:00:41s\n","epoch 71 | loss: 0.53303 | val_0_mse: 0.6485900282859802|  0:00:42s\n","epoch 72 | loss: 0.54809 | val_0_mse: 0.7106500267982483|  0:00:43s\n","epoch 73 | loss: 0.5586  | val_0_mse: 0.6139100193977356|  0:00:43s\n","epoch 74 | loss: 0.56705 | val_0_mse: 0.6357899904251099|  0:00:44s\n","epoch 75 | loss: 0.54392 | val_0_mse: 0.7416099905967712|  0:00:44s\n","epoch 76 | loss: 0.57864 | val_0_mse: 0.6057800054550171|  0:00:45s\n","epoch 77 | loss: 0.55839 | val_0_mse: 0.6764000058174133|  0:00:46s\n","epoch 78 | loss: 0.57342 | val_0_mse: 0.6031299829483032|  0:00:46s\n","epoch 79 | loss: 0.54813 | val_0_mse: 0.6111199855804443|  0:00:47s\n","epoch 80 | loss: 0.52379 | val_0_mse: 0.6202099919319153|  0:00:47s\n","epoch 81 | loss: 0.53674 | val_0_mse: 0.6292300224304199|  0:00:48s\n","epoch 82 | loss: 0.54268 | val_0_mse: 0.6091700196266174|  0:00:49s\n","epoch 83 | loss: 0.55333 | val_0_mse: 0.6375899910926819|  0:00:49s\n","epoch 84 | loss: 0.56865 | val_0_mse: 0.6593999862670898|  0:00:50s\n","epoch 85 | loss: 0.54953 | val_0_mse: 0.626259982585907|  0:00:50s\n","epoch 86 | loss: 0.55647 | val_0_mse: 0.6012099981307983|  0:00:51s\n","epoch 87 | loss: 0.53991 | val_0_mse: 0.6019700169563293|  0:00:51s\n","epoch 88 | loss: 0.52992 | val_0_mse: 0.6091399788856506|  0:00:52s\n","epoch 89 | loss: 0.53709 | val_0_mse: 0.61285001039505|  0:00:53s\n","epoch 90 | loss: 0.55175 | val_0_mse: 0.600409984588623|  0:00:53s\n","epoch 91 | loss: 0.53293 | val_0_mse: 0.6047800183296204|  0:00:54s\n","epoch 92 | loss: 0.52128 | val_0_mse: 0.5964099764823914|  0:00:54s\n","epoch 93 | loss: 0.51898 | val_0_mse: 0.6053799986839294|  0:00:55s\n","epoch 94 | loss: 0.52205 | val_0_mse: 0.5890700221061707|  0:00:56s\n","epoch 95 | loss: 0.52064 | val_0_mse: 0.5785899758338928|  0:00:56s\n","epoch 96 | loss: 0.51421 | val_0_mse: 0.5818799734115601|  0:00:57s\n","epoch 97 | loss: 0.50829 | val_0_mse: 0.5680800080299377|  0:00:57s\n","epoch 98 | loss: 0.51823 | val_0_mse: 0.5960900187492371|  0:00:58s\n","epoch 99 | loss: 0.53535 | val_0_mse: 0.5860099792480469|  0:00:59s\n","Stop training because you reached max_epochs = 100 with best_epoch = 97 and best_val_0_mse = 0.5680800080299377\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 15:58:54,020] Trial 11 finished with value: 0.5680848360061646 and parameters: {'n_d': 17, 'n_steps': 8, 'gamma': 1.305156955706627, 'n_independent': 3, 'n_shared': 4, 'momentum': 0.13521257146497662}. Best is trial 11 with value: 0.5680848360061646.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 28.57545| val_0_mse: 3146.269775390625|  0:00:00s\n","epoch 1  | loss: 5.79506 | val_0_mse: 1206.936279296875|  0:00:01s\n","epoch 2  | loss: 3.29821 | val_0_mse: 881.5896606445312|  0:00:01s\n","epoch 3  | loss: 2.74567 | val_0_mse: 120.59343719482422|  0:00:02s\n","epoch 4  | loss: 2.11463 | val_0_mse: 151.12216186523438|  0:00:03s\n","epoch 5  | loss: 1.75603 | val_0_mse: 51.39020919799805|  0:00:03s\n","epoch 6  | loss: 1.8495  | val_0_mse: 86.47142028808594|  0:00:04s\n","epoch 7  | loss: 1.54604 | val_0_mse: 41.71086883544922|  0:00:05s\n","epoch 8  | loss: 1.22753 | val_0_mse: 19.349769592285156|  0:00:06s\n","epoch 9  | loss: 1.01122 | val_0_mse: 43.92491149902344|  0:00:06s\n","epoch 10 | loss: 1.24539 | val_0_mse: 40.850128173828125|  0:00:07s\n","epoch 11 | loss: 1.23643 | val_0_mse: 10.426939964294434|  0:00:08s\n","epoch 12 | loss: 1.08913 | val_0_mse: 10.900609970092773|  0:00:08s\n","epoch 13 | loss: 1.2776  | val_0_mse: 4.87129020690918|  0:00:09s\n","epoch 14 | loss: 1.5733  | val_0_mse: 17.770740509033203|  0:00:10s\n","epoch 15 | loss: 2.22776 | val_0_mse: 8.250980377197266|  0:00:10s\n","epoch 16 | loss: 1.27704 | val_0_mse: 12.8648099899292|  0:00:11s\n","epoch 17 | loss: 1.20423 | val_0_mse: 6.29355001449585|  0:00:12s\n","epoch 18 | loss: 0.80898 | val_0_mse: 6.9352498054504395|  0:00:12s\n","epoch 19 | loss: 0.7696  | val_0_mse: 3.164489984512329|  0:00:13s\n","epoch 20 | loss: 0.72773 | val_0_mse: 1.917680025100708|  0:00:14s\n","epoch 21 | loss: 0.88957 | val_0_mse: 2.424870014190674|  0:00:14s\n","epoch 22 | loss: 0.76643 | val_0_mse: 1.44159996509552|  0:00:15s\n","epoch 23 | loss: 0.79217 | val_0_mse: 4.054850101470947|  0:00:16s\n","epoch 24 | loss: 0.80731 | val_0_mse: 1.4774099588394165|  0:00:16s\n","epoch 25 | loss: 0.74843 | val_0_mse: 1.5816600322723389|  0:00:17s\n","epoch 26 | loss: 0.68775 | val_0_mse: 1.0966299772262573|  0:00:18s\n","epoch 27 | loss: 0.60785 | val_0_mse: 1.0776100158691406|  0:00:18s\n","epoch 28 | loss: 0.60572 | val_0_mse: 1.1340299844741821|  0:00:19s\n","epoch 29 | loss: 0.5758  | val_0_mse: 1.625100016593933|  0:00:20s\n","epoch 30 | loss: 0.61046 | val_0_mse: 1.3009699583053589|  0:00:20s\n","epoch 31 | loss: 0.59005 | val_0_mse: 1.054960012435913|  0:00:21s\n","epoch 32 | loss: 0.66304 | val_0_mse: 1.7647299766540527|  0:00:22s\n","epoch 33 | loss: 0.76345 | val_0_mse: 0.8112099766731262|  0:00:22s\n","epoch 34 | loss: 0.90519 | val_0_mse: 2.0834600925445557|  0:00:23s\n","epoch 35 | loss: 0.7253  | val_0_mse: 1.076740026473999|  0:00:24s\n","epoch 36 | loss: 0.64648 | val_0_mse: 1.2775700092315674|  0:00:24s\n","epoch 37 | loss: 0.75169 | val_0_mse: 0.8961399793624878|  0:00:25s\n","epoch 38 | loss: 0.6763  | val_0_mse: 0.7279700040817261|  0:00:25s\n","epoch 39 | loss: 1.00234 | val_0_mse: 0.7568699717521667|  0:00:26s\n","epoch 40 | loss: 0.75762 | val_0_mse: 1.8223299980163574|  0:00:27s\n","epoch 41 | loss: 0.76989 | val_0_mse: 0.7451599836349487|  0:00:28s\n","epoch 42 | loss: 1.00942 | val_0_mse: 0.8059099912643433|  0:00:28s\n","epoch 43 | loss: 0.88798 | val_0_mse: 1.296120047569275|  0:00:29s\n","epoch 44 | loss: 0.68065 | val_0_mse: 0.7121400237083435|  0:00:29s\n","epoch 45 | loss: 0.7608  | val_0_mse: 1.7708200216293335|  0:00:30s\n","epoch 46 | loss: 0.83566 | val_0_mse: 0.808929979801178|  0:00:31s\n","epoch 47 | loss: 0.6525  | val_0_mse: 1.3697999715805054|  0:00:31s\n","epoch 48 | loss: 0.6181  | val_0_mse: 0.6728299856185913|  0:00:32s\n","epoch 49 | loss: 0.68904 | val_0_mse: 0.9294000267982483|  0:00:33s\n","epoch 50 | loss: 0.60187 | val_0_mse: 0.7308899760246277|  0:00:33s\n","epoch 51 | loss: 0.58089 | val_0_mse: 0.6856099963188171|  0:00:34s\n","epoch 52 | loss: 0.56974 | val_0_mse: 0.8024600148200989|  0:00:35s\n","epoch 53 | loss: 0.62076 | val_0_mse: 0.7802799940109253|  0:00:35s\n","epoch 54 | loss: 0.58246 | val_0_mse: 0.6573699712753296|  0:00:36s\n","epoch 55 | loss: 0.54962 | val_0_mse: 0.7128499746322632|  0:00:37s\n","epoch 56 | loss: 0.54215 | val_0_mse: 0.6897600293159485|  0:00:37s\n","epoch 57 | loss: 0.56805 | val_0_mse: 0.7353500127792358|  0:00:38s\n","epoch 58 | loss: 0.55209 | val_0_mse: 0.6544399857521057|  0:00:39s\n","epoch 59 | loss: 0.55941 | val_0_mse: 0.6482099890708923|  0:00:39s\n","epoch 60 | loss: 0.5815  | val_0_mse: 0.6713299751281738|  0:00:40s\n","epoch 61 | loss: 0.55519 | val_0_mse: 0.7876999974250793|  0:00:41s\n","epoch 62 | loss: 0.55565 | val_0_mse: 0.8006700277328491|  0:00:41s\n","epoch 63 | loss: 0.54736 | val_0_mse: 0.6569100022315979|  0:00:42s\n","epoch 64 | loss: 0.55809 | val_0_mse: 0.6048799753189087|  0:00:43s\n","epoch 65 | loss: 0.6014  | val_0_mse: 0.8316100239753723|  0:00:43s\n","epoch 66 | loss: 0.58822 | val_0_mse: 0.6057000160217285|  0:00:44s\n","epoch 67 | loss: 0.5872  | val_0_mse: 0.7114499807357788|  0:00:45s\n","epoch 68 | loss: 0.54958 | val_0_mse: 0.6457599997520447|  0:00:45s\n","epoch 69 | loss: 0.52438 | val_0_mse: 0.6238099932670593|  0:00:46s\n","epoch 70 | loss: 0.54008 | val_0_mse: 0.5922200083732605|  0:00:47s\n","epoch 71 | loss: 0.55827 | val_0_mse: 0.659500002861023|  0:00:47s\n","epoch 72 | loss: 0.56972 | val_0_mse: 0.6498900055885315|  0:00:48s\n","epoch 73 | loss: 0.59775 | val_0_mse: 0.5933799743652344|  0:00:49s\n","epoch 74 | loss: 0.59285 | val_0_mse: 0.6540899872779846|  0:00:49s\n","epoch 75 | loss: 0.53254 | val_0_mse: 0.6335800290107727|  0:00:50s\n","epoch 76 | loss: 0.545   | val_0_mse: 0.6700400114059448|  0:00:51s\n","epoch 77 | loss: 0.55687 | val_0_mse: 0.5979200005531311|  0:00:51s\n","epoch 78 | loss: 0.57083 | val_0_mse: 0.6421800255775452|  0:00:52s\n","epoch 79 | loss: 0.57601 | val_0_mse: 0.607200026512146|  0:00:53s\n","epoch 80 | loss: 0.56733 | val_0_mse: 0.6014400124549866|  0:00:53s\n","\n","Early stopping occurred at epoch 80 with best_epoch = 70 and best_val_0_mse = 0.5922200083732605\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 15:59:48,181] Trial 12 finished with value: 0.5922186970710754 and parameters: {'n_d': 23, 'n_steps': 9, 'gamma': 1.2866882511751552, 'n_independent': 3, 'n_shared': 4, 'momentum': 0.15890705259864457}. Best is trial 11 with value: 0.5680848360061646.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 21.55509| val_0_mse: 2362.81201171875|  0:00:00s\n","epoch 1  | loss: 5.19875 | val_0_mse: 1627.513427734375|  0:00:01s\n","epoch 2  | loss: 2.63463 | val_0_mse: 487.1712951660156|  0:00:02s\n","epoch 3  | loss: 1.63615 | val_0_mse: 91.52301025390625|  0:00:02s\n","epoch 4  | loss: 1.25248 | val_0_mse: 30.42494010925293|  0:00:03s\n","epoch 5  | loss: 1.24213 | val_0_mse: 77.09442138671875|  0:00:04s\n","epoch 6  | loss: 1.3949  | val_0_mse: 7.981750011444092|  0:00:05s\n","epoch 7  | loss: 1.2255  | val_0_mse: 15.387669563293457|  0:00:05s\n","epoch 8  | loss: 2.04187 | val_0_mse: 16.219350814819336|  0:00:06s\n","epoch 9  | loss: 2.18422 | val_0_mse: 17.61149024963379|  0:00:07s\n","epoch 10 | loss: 1.2611  | val_0_mse: 17.79776954650879|  0:00:08s\n","epoch 11 | loss: 0.84601 | val_0_mse: 39.1038818359375|  0:00:08s\n","epoch 12 | loss: 0.77666 | val_0_mse: 15.37654972076416|  0:00:09s\n","epoch 13 | loss: 0.7257  | val_0_mse: 6.7268500328063965|  0:00:10s\n","epoch 14 | loss: 0.72636 | val_0_mse: 7.14300012588501|  0:00:11s\n","epoch 15 | loss: 0.67419 | val_0_mse: 3.0710699558258057|  0:00:11s\n","epoch 16 | loss: 0.64698 | val_0_mse: 14.192729949951172|  0:00:12s\n","epoch 17 | loss: 0.74261 | val_0_mse: 16.209999084472656|  0:00:13s\n","epoch 18 | loss: 0.70775 | val_0_mse: 6.26977014541626|  0:00:13s\n","epoch 19 | loss: 0.7571  | val_0_mse: 2.594399929046631|  0:00:14s\n","epoch 20 | loss: 0.68612 | val_0_mse: 3.8779399394989014|  0:00:15s\n","epoch 21 | loss: 0.7264  | val_0_mse: 1.9339799880981445|  0:00:16s\n","epoch 22 | loss: 0.64445 | val_0_mse: 1.3347300291061401|  0:00:16s\n","epoch 23 | loss: 0.64223 | val_0_mse: 2.1030800342559814|  0:00:17s\n","epoch 24 | loss: 0.60768 | val_0_mse: 2.4516899585723877|  0:00:18s\n","epoch 25 | loss: 0.60844 | val_0_mse: 1.2734700441360474|  0:00:19s\n","epoch 26 | loss: 0.56198 | val_0_mse: 1.8022099733352661|  0:00:19s\n","epoch 27 | loss: 0.63141 | val_0_mse: 2.958940029144287|  0:00:20s\n","epoch 28 | loss: 0.62005 | val_0_mse: 6.287469863891602|  0:00:21s\n","epoch 29 | loss: 0.74266 | val_0_mse: 1.4538600444793701|  0:00:22s\n","epoch 30 | loss: 0.63899 | val_0_mse: 1.6904100179672241|  0:00:22s\n","epoch 31 | loss: 0.68424 | val_0_mse: 2.3147499561309814|  0:00:23s\n","epoch 32 | loss: 0.65105 | val_0_mse: 1.2275400161743164|  0:00:24s\n","epoch 33 | loss: 0.75998 | val_0_mse: 1.0941499471664429|  0:00:25s\n","epoch 34 | loss: 0.66444 | val_0_mse: 1.1836899518966675|  0:00:25s\n","epoch 35 | loss: 0.57287 | val_0_mse: 1.3921400308609009|  0:00:26s\n","epoch 36 | loss: 0.54227 | val_0_mse: 1.3236000537872314|  0:00:27s\n","epoch 37 | loss: 0.52686 | val_0_mse: 1.6356500387191772|  0:00:27s\n","epoch 38 | loss: 0.56065 | val_0_mse: 1.9834500551223755|  0:00:28s\n","epoch 39 | loss: 0.52566 | val_0_mse: 1.3220499753952026|  0:00:29s\n","epoch 40 | loss: 0.54441 | val_0_mse: 1.2544599771499634|  0:00:30s\n","epoch 41 | loss: 0.55244 | val_0_mse: 0.9768499732017517|  0:00:30s\n","epoch 42 | loss: 0.55285 | val_0_mse: 1.4651600122451782|  0:00:31s\n","epoch 43 | loss: 0.56361 | val_0_mse: 1.1947499513626099|  0:00:32s\n","epoch 44 | loss: 0.59903 | val_0_mse: 1.005270004272461|  0:00:33s\n","epoch 45 | loss: 0.5707  | val_0_mse: 0.7771900296211243|  0:00:33s\n","epoch 46 | loss: 0.60527 | val_0_mse: 1.3924599885940552|  0:00:34s\n","epoch 47 | loss: 0.5656  | val_0_mse: 1.0787099599838257|  0:00:35s\n","epoch 48 | loss: 0.55417 | val_0_mse: 0.8557599782943726|  0:00:36s\n","epoch 49 | loss: 0.54421 | val_0_mse: 0.8533599972724915|  0:00:36s\n","epoch 50 | loss: 0.55715 | val_0_mse: 1.0543800592422485|  0:00:37s\n","epoch 51 | loss: 0.56067 | val_0_mse: 0.6815500259399414|  0:00:38s\n","epoch 52 | loss: 0.58883 | val_0_mse: 0.8078799843788147|  0:00:38s\n","epoch 53 | loss: 0.6059  | val_0_mse: 0.6825900077819824|  0:00:39s\n","epoch 54 | loss: 0.55844 | val_0_mse: 0.7124900221824646|  0:00:40s\n","epoch 55 | loss: 0.56672 | val_0_mse: 0.8996099829673767|  0:00:41s\n","epoch 56 | loss: 0.54945 | val_0_mse: 0.768280029296875|  0:00:41s\n","epoch 57 | loss: 0.54189 | val_0_mse: 0.8006799817085266|  0:00:42s\n","epoch 58 | loss: 0.54599 | val_0_mse: 0.8452600240707397|  0:00:43s\n","epoch 59 | loss: 0.5353  | val_0_mse: 0.8072299957275391|  0:00:44s\n","epoch 60 | loss: 0.53116 | val_0_mse: 0.7171099781990051|  0:00:44s\n","epoch 61 | loss: 0.53523 | val_0_mse: 0.698140025138855|  0:00:45s\n","\n","Early stopping occurred at epoch 61 with best_epoch = 51 and best_val_0_mse = 0.6815500259399414\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 16:00:34,080] Trial 13 finished with value: 0.6815487146377563 and parameters: {'n_d': 18, 'n_steps': 9, 'gamma': 1.2673035496985448, 'n_independent': 4, 'n_shared': 4, 'momentum': 0.29032059750527256}. Best is trial 11 with value: 0.5680848360061646.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 10.74829| val_0_mse: 10023.9892578125|  0:00:00s\n","epoch 1  | loss: 5.03648 | val_0_mse: 2480.6748046875|  0:00:01s\n","epoch 2  | loss: 2.75552 | val_0_mse: 534.1138916015625|  0:00:02s\n","epoch 3  | loss: 2.13269 | val_0_mse: 94.46884155273438|  0:00:03s\n","epoch 4  | loss: 1.86162 | val_0_mse: 105.68636322021484|  0:00:04s\n","epoch 5  | loss: 1.52946 | val_0_mse: 137.72877502441406|  0:00:04s\n","epoch 6  | loss: 1.30274 | val_0_mse: 61.602081298828125|  0:00:05s\n","epoch 7  | loss: 1.14238 | val_0_mse: 21.706560134887695|  0:00:06s\n","epoch 8  | loss: 1.31917 | val_0_mse: 71.35871887207031|  0:00:07s\n","epoch 9  | loss: 1.17176 | val_0_mse: 64.93382263183594|  0:00:07s\n","epoch 10 | loss: 1.24584 | val_0_mse: 286.7311096191406|  0:00:08s\n","epoch 11 | loss: 1.63012 | val_0_mse: 53.703731536865234|  0:00:09s\n","epoch 12 | loss: 1.40517 | val_0_mse: 28.123849868774414|  0:00:10s\n","epoch 13 | loss: 1.40051 | val_0_mse: 49.70568084716797|  0:00:11s\n","epoch 14 | loss: 1.33269 | val_0_mse: 10.791999816894531|  0:00:11s\n","epoch 15 | loss: 1.21111 | val_0_mse: 2.7319600582122803|  0:00:12s\n","epoch 16 | loss: 0.96952 | val_0_mse: 2.896440029144287|  0:00:13s\n","epoch 17 | loss: 0.77268 | val_0_mse: 4.228010177612305|  0:00:14s\n","epoch 18 | loss: 0.76082 | val_0_mse: 3.4283900260925293|  0:00:15s\n","epoch 19 | loss: 0.73863 | val_0_mse: 1.7720199823379517|  0:00:15s\n","epoch 20 | loss: 0.99763 | val_0_mse: 12.14126968383789|  0:00:16s\n","epoch 21 | loss: 1.10958 | val_0_mse: 2.084049940109253|  0:00:17s\n","epoch 22 | loss: 0.72821 | val_0_mse: 4.826350212097168|  0:00:18s\n","epoch 23 | loss: 0.7975  | val_0_mse: 1.8369799852371216|  0:00:19s\n","epoch 24 | loss: 0.6728  | val_0_mse: 2.2954299449920654|  0:00:19s\n","epoch 25 | loss: 0.66531 | val_0_mse: 2.4926300048828125|  0:00:20s\n","epoch 26 | loss: 0.64623 | val_0_mse: 2.4044899940490723|  0:00:21s\n","epoch 27 | loss: 0.62791 | val_0_mse: 2.662909984588623|  0:00:22s\n","epoch 28 | loss: 0.64608 | val_0_mse: 5.30702018737793|  0:00:23s\n","epoch 29 | loss: 0.71359 | val_0_mse: 3.3821499347686768|  0:00:23s\n","\n","Early stopping occurred at epoch 29 with best_epoch = 19 and best_val_0_mse = 1.7720199823379517\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 16:00:58,347] Trial 14 finished with value: 1.7720210552215576 and parameters: {'n_d': 16, 'n_steps': 8, 'gamma': 1.6415328657039068, 'n_independent': 5, 'n_shared': 5, 'momentum': 0.11345571892099271}. Best is trial 11 with value: 0.5680848360061646.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 29.25567| val_0_mse: 2482.358642578125|  0:00:00s\n","epoch 1  | loss: 4.15462 | val_0_mse: 1629.223876953125|  0:00:01s\n","epoch 2  | loss: 2.21176 | val_0_mse: 2117.546142578125|  0:00:02s\n","epoch 3  | loss: 2.14624 | val_0_mse: 237.40512084960938|  0:00:03s\n","epoch 4  | loss: 1.59688 | val_0_mse: 63.98033905029297|  0:00:04s\n","epoch 5  | loss: 1.16315 | val_0_mse: 47.85586166381836|  0:00:04s\n","epoch 6  | loss: 1.13235 | val_0_mse: 26.889240264892578|  0:00:05s\n","epoch 7  | loss: 0.99918 | val_0_mse: 22.562400817871094|  0:00:06s\n","epoch 8  | loss: 0.94032 | val_0_mse: 32.66250991821289|  0:00:07s\n","epoch 9  | loss: 1.06326 | val_0_mse: 8.817919731140137|  0:00:08s\n","epoch 10 | loss: 0.96938 | val_0_mse: 5.085830211639404|  0:00:09s\n","epoch 11 | loss: 1.20301 | val_0_mse: 16.7580509185791|  0:00:09s\n","epoch 12 | loss: 0.87364 | val_0_mse: 14.385549545288086|  0:00:10s\n","epoch 13 | loss: 0.80957 | val_0_mse: 6.377230167388916|  0:00:11s\n","epoch 14 | loss: 0.68755 | val_0_mse: 17.652700424194336|  0:00:12s\n","epoch 15 | loss: 0.6723  | val_0_mse: 9.316410064697266|  0:00:13s\n","epoch 16 | loss: 0.63162 | val_0_mse: 13.688190460205078|  0:00:13s\n","epoch 17 | loss: 0.64237 | val_0_mse: 4.112539768218994|  0:00:14s\n","epoch 18 | loss: 0.68334 | val_0_mse: 5.061560153961182|  0:00:15s\n","epoch 19 | loss: 0.65857 | val_0_mse: 1.2271900177001953|  0:00:16s\n","epoch 20 | loss: 0.73611 | val_0_mse: 7.055540084838867|  0:00:17s\n","epoch 21 | loss: 0.67133 | val_0_mse: 5.522980213165283|  0:00:17s\n","epoch 22 | loss: 0.5681  | val_0_mse: 3.638580083847046|  0:00:18s\n","epoch 23 | loss: 0.59672 | val_0_mse: 3.6592400074005127|  0:00:19s\n","epoch 24 | loss: 0.66976 | val_0_mse: 3.404550075531006|  0:00:20s\n","epoch 25 | loss: 0.60085 | val_0_mse: 1.6643500328063965|  0:00:21s\n","epoch 26 | loss: 0.58432 | val_0_mse: 1.4907200336456299|  0:00:22s\n","epoch 27 | loss: 0.68641 | val_0_mse: 2.974900007247925|  0:00:22s\n","epoch 28 | loss: 0.70094 | val_0_mse: 0.9158899784088135|  0:00:23s\n","epoch 29 | loss: 0.67634 | val_0_mse: 4.643809795379639|  0:00:24s\n","epoch 30 | loss: 0.81436 | val_0_mse: 1.2595100402832031|  0:00:25s\n","epoch 31 | loss: 1.09317 | val_0_mse: 7.292719841003418|  0:00:26s\n","epoch 32 | loss: 1.28378 | val_0_mse: 5.48045015335083|  0:00:26s\n","epoch 33 | loss: 0.98321 | val_0_mse: 1.3124799728393555|  0:00:27s\n","epoch 34 | loss: 0.84675 | val_0_mse: 5.053760051727295|  0:00:28s\n","epoch 35 | loss: 0.79028 | val_0_mse: 1.5043699741363525|  0:00:29s\n","epoch 36 | loss: 0.83467 | val_0_mse: 6.073969841003418|  0:00:30s\n","epoch 37 | loss: 1.11034 | val_0_mse: 2.810689926147461|  0:00:30s\n","epoch 38 | loss: 0.81121 | val_0_mse: 2.8242099285125732|  0:00:31s\n","\n","Early stopping occurred at epoch 38 with best_epoch = 28 and best_val_0_mse = 0.9158899784088135\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 16:01:30,446] Trial 15 finished with value: 0.9158923029899597 and parameters: {'n_d': 30, 'n_steps': 10, 'gamma': 1.0103887717093225, 'n_independent': 4, 'n_shared': 4, 'momentum': 0.16853741121449192}. Best is trial 11 with value: 0.5680848360061646.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 29.96506| val_0_mse: 1439.197265625|  0:00:00s\n","epoch 1  | loss: 3.11997 | val_0_mse: 134.6332244873047|  0:00:00s\n","epoch 2  | loss: 1.76065 | val_0_mse: 84.44413757324219|  0:00:01s\n","epoch 3  | loss: 1.48539 | val_0_mse: 83.93006896972656|  0:00:01s\n","epoch 4  | loss: 1.3149  | val_0_mse: 34.79494094848633|  0:00:02s\n","epoch 5  | loss: 1.15349 | val_0_mse: 47.22560119628906|  0:00:02s\n","epoch 6  | loss: 0.92003 | val_0_mse: 55.43613052368164|  0:00:03s\n","epoch 7  | loss: 0.88692 | val_0_mse: 7.474269866943359|  0:00:03s\n","epoch 8  | loss: 0.88328 | val_0_mse: 10.633060455322266|  0:00:03s\n","epoch 9  | loss: 0.73392 | val_0_mse: 2.521399974822998|  0:00:04s\n","epoch 10 | loss: 0.71809 | val_0_mse: 6.068309783935547|  0:00:04s\n","epoch 11 | loss: 0.68109 | val_0_mse: 7.469019889831543|  0:00:05s\n","epoch 12 | loss: 0.95999 | val_0_mse: 3.7997899055480957|  0:00:05s\n","epoch 13 | loss: 0.75928 | val_0_mse: 1.6690599918365479|  0:00:06s\n","epoch 14 | loss: 0.69318 | val_0_mse: 5.688360214233398|  0:00:06s\n","epoch 15 | loss: 0.67922 | val_0_mse: 0.9583200216293335|  0:00:06s\n","epoch 16 | loss: 0.70777 | val_0_mse: 4.715640068054199|  0:00:07s\n","epoch 17 | loss: 0.65725 | val_0_mse: 9.037440299987793|  0:00:07s\n","epoch 18 | loss: 0.68292 | val_0_mse: 13.198180198669434|  0:00:08s\n","epoch 19 | loss: 0.60206 | val_0_mse: 5.791540145874023|  0:00:08s\n","epoch 20 | loss: 0.59975 | val_0_mse: 2.7412400245666504|  0:00:09s\n","epoch 21 | loss: 0.61864 | val_0_mse: 1.7854599952697754|  0:00:09s\n","epoch 22 | loss: 0.61463 | val_0_mse: 2.1381099224090576|  0:00:09s\n","epoch 23 | loss: 0.58639 | val_0_mse: 2.9610700607299805|  0:00:10s\n","epoch 24 | loss: 0.67135 | val_0_mse: 2.4028000831604004|  0:00:10s\n","epoch 25 | loss: 0.64296 | val_0_mse: 1.687309980392456|  0:00:11s\n","\n","Early stopping occurred at epoch 25 with best_epoch = 15 and best_val_0_mse = 0.9583200216293335\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 16:01:41,860] Trial 16 finished with value: 0.9583203792572021 and parameters: {'n_d': 48, 'n_steps': 7, 'gamma': 1.6005829172470376, 'n_independent': 2, 'n_shared': 3, 'momentum': 0.1005297228182645}. Best is trial 11 with value: 0.5680848360061646.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 38.29067| val_0_mse: 2373.97900390625|  0:00:00s\n","epoch 1  | loss: 6.34347 | val_0_mse: 2369.440673828125|  0:00:01s\n","epoch 2  | loss: 2.8552  | val_0_mse: 228.2571563720703|  0:00:01s\n","epoch 3  | loss: 1.62369 | val_0_mse: 162.74270629882812|  0:00:02s\n","epoch 4  | loss: 1.62445 | val_0_mse: 141.5191650390625|  0:00:02s\n","epoch 5  | loss: 1.81297 | val_0_mse: 38.32585906982422|  0:00:03s\n","epoch 6  | loss: 1.2309  | val_0_mse: 21.5389404296875|  0:00:03s\n","epoch 7  | loss: 1.04249 | val_0_mse: 35.703651428222656|  0:00:04s\n","epoch 8  | loss: 0.95285 | val_0_mse: 19.227680206298828|  0:00:05s\n","epoch 9  | loss: 0.78307 | val_0_mse: 27.034439086914062|  0:00:05s\n","epoch 10 | loss: 0.81622 | val_0_mse: 102.95913696289062|  0:00:06s\n","epoch 11 | loss: 0.92195 | val_0_mse: 18.990009307861328|  0:00:06s\n","epoch 12 | loss: 0.80061 | val_0_mse: 10.237859725952148|  0:00:07s\n","epoch 13 | loss: 0.76047 | val_0_mse: 5.309589862823486|  0:00:07s\n","epoch 14 | loss: 0.73936 | val_0_mse: 7.697070121765137|  0:00:08s\n","epoch 15 | loss: 0.68847 | val_0_mse: 6.079319953918457|  0:00:08s\n","epoch 16 | loss: 0.68913 | val_0_mse: 5.87037992477417|  0:00:09s\n","epoch 17 | loss: 0.66216 | val_0_mse: 4.000430107116699|  0:00:09s\n","epoch 18 | loss: 0.6244  | val_0_mse: 3.9776198863983154|  0:00:10s\n","epoch 19 | loss: 0.65793 | val_0_mse: 3.6249399185180664|  0:00:10s\n","epoch 20 | loss: 0.61938 | val_0_mse: 2.806260108947754|  0:00:11s\n","epoch 21 | loss: 0.5977  | val_0_mse: 5.211060047149658|  0:00:12s\n","epoch 22 | loss: 0.64508 | val_0_mse: 1.704949975013733|  0:00:12s\n","epoch 23 | loss: 0.66402 | val_0_mse: 4.8849101066589355|  0:00:13s\n","epoch 24 | loss: 0.60379 | val_0_mse: 5.189610004425049|  0:00:13s\n","epoch 25 | loss: 0.57984 | val_0_mse: 2.8806099891662598|  0:00:14s\n","epoch 26 | loss: 0.61703 | val_0_mse: 2.679189920425415|  0:00:14s\n","epoch 27 | loss: 0.58446 | val_0_mse: 2.1995999813079834|  0:00:15s\n","epoch 28 | loss: 0.58404 | val_0_mse: 2.7546401023864746|  0:00:15s\n","epoch 29 | loss: 0.59166 | val_0_mse: 2.5311200618743896|  0:00:16s\n","epoch 30 | loss: 0.56962 | val_0_mse: 1.4709399938583374|  0:00:16s\n","epoch 31 | loss: 0.57131 | val_0_mse: 2.1152400970458984|  0:00:17s\n","epoch 32 | loss: 0.62415 | val_0_mse: 1.8338199853897095|  0:00:17s\n","epoch 33 | loss: 0.56036 | val_0_mse: 1.639780044555664|  0:00:18s\n","epoch 34 | loss: 0.55764 | val_0_mse: 2.1535699367523193|  0:00:18s\n","epoch 35 | loss: 0.57849 | val_0_mse: 1.085819959640503|  0:00:19s\n","epoch 36 | loss: 0.67243 | val_0_mse: 2.2216200828552246|  0:00:19s\n","epoch 37 | loss: 0.69622 | val_0_mse: 0.7569299936294556|  0:00:20s\n","epoch 38 | loss: 0.71172 | val_0_mse: 2.3678998947143555|  0:00:21s\n","epoch 39 | loss: 0.68782 | val_0_mse: 0.763979971408844|  0:00:21s\n","epoch 40 | loss: 0.60711 | val_0_mse: 1.8606300354003906|  0:00:22s\n","epoch 41 | loss: 0.59765 | val_0_mse: 0.8717700242996216|  0:00:22s\n","epoch 42 | loss: 0.5718  | val_0_mse: 0.9531599879264832|  0:00:23s\n","epoch 43 | loss: 0.57349 | val_0_mse: 0.8205599784851074|  0:00:23s\n","epoch 44 | loss: 0.55876 | val_0_mse: 1.012120008468628|  0:00:24s\n","epoch 45 | loss: 0.54404 | val_0_mse: 0.9192100167274475|  0:00:24s\n","epoch 46 | loss: 0.55578 | val_0_mse: 0.9250100255012512|  0:00:25s\n","epoch 47 | loss: 0.56135 | val_0_mse: 0.8765299916267395|  0:00:25s\n","\n","Early stopping occurred at epoch 47 with best_epoch = 37 and best_val_0_mse = 0.7569299936294556\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 16:02:07,943] Trial 17 finished with value: 0.7569262385368347 and parameters: {'n_d': 17, 'n_steps': 8, 'gamma': 1.32301390363128, 'n_independent': 3, 'n_shared': 3, 'momentum': 0.21382110521310077}. Best is trial 11 with value: 0.5680848360061646.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 30.07809| val_0_mse: 3193.15673828125|  0:00:00s\n","epoch 1  | loss: 6.52181 | val_0_mse: 1872.0025634765625|  0:00:01s\n","epoch 2  | loss: 6.54661 | val_0_mse: 1429.8157958984375|  0:00:02s\n","epoch 3  | loss: 3.18147 | val_0_mse: 290.91986083984375|  0:00:03s\n","epoch 4  | loss: 2.2118  | val_0_mse: 68.9774398803711|  0:00:04s\n","epoch 5  | loss: 1.73287 | val_0_mse: 117.7014389038086|  0:00:04s\n","epoch 6  | loss: 1.80536 | val_0_mse: 38.39910125732422|  0:00:05s\n","epoch 7  | loss: 1.53246 | val_0_mse: 26.854320526123047|  0:00:06s\n","epoch 8  | loss: 1.71611 | val_0_mse: 21.737720489501953|  0:00:07s\n","epoch 9  | loss: 1.14721 | val_0_mse: 31.581310272216797|  0:00:08s\n","epoch 10 | loss: 1.12314 | val_0_mse: 20.66887092590332|  0:00:09s\n","epoch 11 | loss: 0.97014 | val_0_mse: 42.92021942138672|  0:00:10s\n","epoch 12 | loss: 1.37911 | val_0_mse: 82.21163940429688|  0:00:10s\n","epoch 13 | loss: 1.49634 | val_0_mse: 7.681459903717041|  0:00:11s\n","epoch 14 | loss: 1.08089 | val_0_mse: 17.64727020263672|  0:00:12s\n","epoch 15 | loss: 0.83858 | val_0_mse: 17.47154998779297|  0:00:13s\n","epoch 16 | loss: 1.07253 | val_0_mse: 7.565989971160889|  0:00:14s\n","epoch 17 | loss: 0.89169 | val_0_mse: 8.814920425415039|  0:00:15s\n","epoch 18 | loss: 0.70635 | val_0_mse: 7.256899833679199|  0:00:15s\n","epoch 19 | loss: 0.67527 | val_0_mse: 3.7527899742126465|  0:00:16s\n","epoch 20 | loss: 0.64262 | val_0_mse: 11.089159965515137|  0:00:17s\n","epoch 21 | loss: 0.65936 | val_0_mse: 3.1785500049591064|  0:00:18s\n","epoch 22 | loss: 0.62199 | val_0_mse: 1.8549400568008423|  0:00:19s\n","epoch 23 | loss: 0.6198  | val_0_mse: 2.286210060119629|  0:00:19s\n","epoch 24 | loss: 0.69534 | val_0_mse: 3.2575600147247314|  0:00:20s\n","epoch 25 | loss: 0.82617 | val_0_mse: 4.190629959106445|  0:00:21s\n","epoch 26 | loss: 0.97924 | val_0_mse: 1.6585099697113037|  0:00:22s\n","epoch 27 | loss: 0.7915  | val_0_mse: 1.6219600439071655|  0:00:23s\n","epoch 28 | loss: 0.96874 | val_0_mse: 1.8945000171661377|  0:00:23s\n","epoch 29 | loss: 0.72181 | val_0_mse: 1.4812699556350708|  0:00:24s\n","epoch 30 | loss: 0.75721 | val_0_mse: 1.0106899738311768|  0:00:25s\n","epoch 31 | loss: 0.77181 | val_0_mse: 2.2293601036071777|  0:00:26s\n","epoch 32 | loss: 0.88405 | val_0_mse: 0.9572200179100037|  0:00:27s\n","epoch 33 | loss: 0.89778 | val_0_mse: 2.070199966430664|  0:00:27s\n","epoch 34 | loss: 0.76093 | val_0_mse: 0.9728699922561646|  0:00:28s\n","epoch 35 | loss: 0.63362 | val_0_mse: 0.8304799795150757|  0:00:29s\n","epoch 36 | loss: 0.61996 | val_0_mse: 1.0071500539779663|  0:00:30s\n","epoch 37 | loss: 0.60618 | val_0_mse: 1.2214399576187134|  0:00:31s\n","epoch 38 | loss: 0.60706 | val_0_mse: 1.0011999607086182|  0:00:31s\n","epoch 39 | loss: 0.57988 | val_0_mse: 0.8019000291824341|  0:00:32s\n","epoch 40 | loss: 0.59431 | val_0_mse: 2.6978600025177|  0:00:33s\n","epoch 41 | loss: 0.60074 | val_0_mse: 2.082469940185547|  0:00:34s\n","epoch 42 | loss: 0.56262 | val_0_mse: 2.6813199520111084|  0:00:35s\n","epoch 43 | loss: 0.56181 | val_0_mse: 1.9012900590896606|  0:00:36s\n","epoch 44 | loss: 0.55992 | val_0_mse: 2.1530699729919434|  0:00:36s\n","epoch 45 | loss: 0.57762 | val_0_mse: 1.6052000522613525|  0:00:37s\n","epoch 46 | loss: 0.55593 | val_0_mse: 1.255810022354126|  0:00:38s\n","epoch 47 | loss: 0.5512  | val_0_mse: 1.1620800495147705|  0:00:39s\n","epoch 48 | loss: 0.56048 | val_0_mse: 1.261780023574829|  0:00:40s\n","epoch 49 | loss: 0.59654 | val_0_mse: 1.2934399843215942|  0:00:40s\n","\n","Early stopping occurred at epoch 49 with best_epoch = 39 and best_val_0_mse = 0.8019000291824341\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 16:02:49,370] Trial 18 finished with value: 0.8018967509269714 and parameters: {'n_d': 43, 'n_steps': 9, 'gamma': 1.1597843775514383, 'n_independent': 4, 'n_shared': 5, 'momentum': 0.28984163841774924}. Best is trial 11 with value: 0.5680848360061646.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 32.95679| val_0_mse: 3411.01513671875|  0:00:00s\n","epoch 1  | loss: 6.91513 | val_0_mse: 522.6234741210938|  0:00:01s\n","epoch 2  | loss: 3.17964 | val_0_mse: 203.0039825439453|  0:00:01s\n","epoch 3  | loss: 2.62527 | val_0_mse: 103.0528335571289|  0:00:02s\n","epoch 4  | loss: 2.04202 | val_0_mse: 108.22567749023438|  0:00:02s\n","epoch 5  | loss: 1.40319 | val_0_mse: 14.002639770507812|  0:00:03s\n","epoch 6  | loss: 1.10071 | val_0_mse: 12.928910255432129|  0:00:04s\n","epoch 7  | loss: 0.97081 | val_0_mse: 63.000099182128906|  0:00:04s\n","epoch 8  | loss: 1.008   | val_0_mse: 74.415771484375|  0:00:05s\n","epoch 9  | loss: 1.28799 | val_0_mse: 137.15213012695312|  0:00:05s\n","epoch 10 | loss: 1.61233 | val_0_mse: 30.50490951538086|  0:00:06s\n","epoch 11 | loss: 1.2307  | val_0_mse: 22.74728012084961|  0:00:07s\n","epoch 12 | loss: 0.97561 | val_0_mse: 19.499149322509766|  0:00:07s\n","epoch 13 | loss: 0.95028 | val_0_mse: 7.474130153656006|  0:00:08s\n","epoch 14 | loss: 1.11124 | val_0_mse: 4.479559898376465|  0:00:08s\n","epoch 15 | loss: 0.82937 | val_0_mse: 2.878000020980835|  0:00:09s\n","epoch 16 | loss: 0.80787 | val_0_mse: 2.2291998863220215|  0:00:09s\n","epoch 17 | loss: 0.82655 | val_0_mse: 3.342360019683838|  0:00:10s\n","epoch 18 | loss: 0.76818 | val_0_mse: 1.5578299760818481|  0:00:11s\n","epoch 19 | loss: 0.75078 | val_0_mse: 3.122040033340454|  0:00:11s\n","epoch 20 | loss: 0.84696 | val_0_mse: 2.4902899265289307|  0:00:12s\n","epoch 21 | loss: 0.84048 | val_0_mse: 5.379940032958984|  0:00:12s\n","epoch 22 | loss: 0.72588 | val_0_mse: 3.9508700370788574|  0:00:13s\n","epoch 23 | loss: 0.70784 | val_0_mse: 1.70933997631073|  0:00:14s\n","epoch 24 | loss: 0.68044 | val_0_mse: 1.4641900062561035|  0:00:14s\n","epoch 25 | loss: 0.69111 | val_0_mse: 3.402820110321045|  0:00:15s\n","epoch 26 | loss: 0.75347 | val_0_mse: 1.5205299854278564|  0:00:15s\n","epoch 27 | loss: 0.7398  | val_0_mse: 1.1425100564956665|  0:00:16s\n","epoch 28 | loss: 0.67781 | val_0_mse: 2.3227999210357666|  0:00:17s\n","epoch 29 | loss: 0.65219 | val_0_mse: 1.3683199882507324|  0:00:17s\n","epoch 30 | loss: 0.6613  | val_0_mse: 1.7460999488830566|  0:00:18s\n","epoch 31 | loss: 0.66529 | val_0_mse: 1.0262700319290161|  0:00:18s\n","epoch 32 | loss: 0.64138 | val_0_mse: 1.1361099481582642|  0:00:19s\n","epoch 33 | loss: 0.6572  | val_0_mse: 3.064500093460083|  0:00:19s\n","epoch 34 | loss: 0.65368 | val_0_mse: 2.262700080871582|  0:00:20s\n","epoch 35 | loss: 0.69811 | val_0_mse: 0.8092899918556213|  0:00:21s\n","epoch 36 | loss: 0.65507 | val_0_mse: 1.6203700304031372|  0:00:21s\n","epoch 37 | loss: 0.6636  | val_0_mse: 1.3168699741363525|  0:00:22s\n","epoch 38 | loss: 0.59826 | val_0_mse: 1.6375000476837158|  0:00:22s\n","epoch 39 | loss: 0.59014 | val_0_mse: 0.9752600193023682|  0:00:23s\n","epoch 40 | loss: 0.58206 | val_0_mse: 0.9031100273132324|  0:00:24s\n","epoch 41 | loss: 0.59049 | val_0_mse: 1.1674799919128418|  0:00:24s\n","epoch 42 | loss: 0.55886 | val_0_mse: 0.9678699970245361|  0:00:25s\n","epoch 43 | loss: 0.57315 | val_0_mse: 0.8162000179290771|  0:00:25s\n","epoch 44 | loss: 0.62799 | val_0_mse: 1.0794199705123901|  0:00:26s\n","epoch 45 | loss: 0.64634 | val_0_mse: 0.8216800093650818|  0:00:26s\n","\n","Early stopping occurred at epoch 45 with best_epoch = 35 and best_val_0_mse = 0.8092899918556213\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 16:03:16,833] Trial 19 finished with value: 0.8092862963676453 and parameters: {'n_d': 21, 'n_steps': 9, 'gamma': 1.3547179821051722, 'n_independent': 2, 'n_shared': 4, 'momentum': 0.18057370795474723}. Best is trial 11 with value: 0.5680848360061646.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 10.22609| val_0_mse: 6033.515625|  0:00:00s\n","epoch 1  | loss: 3.23548 | val_0_mse: 170.45358276367188|  0:00:01s\n","epoch 2  | loss: 2.2308  | val_0_mse: 158.29734802246094|  0:00:01s\n","epoch 3  | loss: 1.85942 | val_0_mse: 218.8143768310547|  0:00:02s\n","epoch 4  | loss: 1.43586 | val_0_mse: 99.42254638671875|  0:00:02s\n","epoch 5  | loss: 1.73748 | val_0_mse: 30.910419464111328|  0:00:03s\n","epoch 6  | loss: 1.28624 | val_0_mse: 14.57859992980957|  0:00:03s\n","epoch 7  | loss: 0.96805 | val_0_mse: 15.820289611816406|  0:00:04s\n","epoch 8  | loss: 0.89634 | val_0_mse: 10.367620468139648|  0:00:04s\n","epoch 9  | loss: 0.85244 | val_0_mse: 5.941649913787842|  0:00:05s\n","epoch 10 | loss: 0.8727  | val_0_mse: 3.244770050048828|  0:00:05s\n","epoch 11 | loss: 0.72233 | val_0_mse: 2.751460075378418|  0:00:06s\n","epoch 12 | loss: 0.70587 | val_0_mse: 5.7485198974609375|  0:00:06s\n","epoch 13 | loss: 0.7379  | val_0_mse: 3.2322499752044678|  0:00:07s\n","epoch 14 | loss: 0.68221 | val_0_mse: 5.633490085601807|  0:00:07s\n","epoch 15 | loss: 0.71442 | val_0_mse: 4.201300144195557|  0:00:08s\n","epoch 16 | loss: 0.62623 | val_0_mse: 4.95697021484375|  0:00:08s\n","epoch 17 | loss: 0.68886 | val_0_mse: 6.261630058288574|  0:00:09s\n","epoch 18 | loss: 0.68423 | val_0_mse: 1.8185700178146362|  0:00:10s\n","epoch 19 | loss: 0.70371 | val_0_mse: 4.886549949645996|  0:00:10s\n","epoch 20 | loss: 0.67113 | val_0_mse: 2.9698901176452637|  0:00:11s\n","epoch 21 | loss: 0.69193 | val_0_mse: 1.7430700063705444|  0:00:11s\n","epoch 22 | loss: 0.70235 | val_0_mse: 1.6403800249099731|  0:00:12s\n","epoch 23 | loss: 0.66178 | val_0_mse: 1.912660002708435|  0:00:12s\n","epoch 24 | loss: 0.6255  | val_0_mse: 3.764359951019287|  0:00:13s\n","epoch 25 | loss: 0.66956 | val_0_mse: 1.9737900495529175|  0:00:13s\n","epoch 26 | loss: 0.66954 | val_0_mse: 2.63811993598938|  0:00:14s\n","epoch 27 | loss: 0.72237 | val_0_mse: 0.8853099942207336|  0:00:14s\n","epoch 28 | loss: 0.62724 | val_0_mse: 1.0601600408554077|  0:00:15s\n","epoch 29 | loss: 0.62082 | val_0_mse: 1.7976499795913696|  0:00:15s\n","epoch 30 | loss: 0.57721 | val_0_mse: 1.4443299770355225|  0:00:16s\n","epoch 31 | loss: 0.57478 | val_0_mse: 1.1213799715042114|  0:00:16s\n","epoch 32 | loss: 0.56705 | val_0_mse: 1.6730400323867798|  0:00:17s\n","epoch 33 | loss: 0.63661 | val_0_mse: 1.0766700506210327|  0:00:17s\n","epoch 34 | loss: 0.64216 | val_0_mse: 1.125040054321289|  0:00:18s\n","epoch 35 | loss: 0.57809 | val_0_mse: 1.450279951095581|  0:00:18s\n","epoch 36 | loss: 0.58556 | val_0_mse: 1.187880039215088|  0:00:19s\n","epoch 37 | loss: 0.57266 | val_0_mse: 0.9480699896812439|  0:00:19s\n","\n","Early stopping occurred at epoch 37 with best_epoch = 27 and best_val_0_mse = 0.8853099942207336\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 16:03:37,066] Trial 20 finished with value: 0.8853092193603516 and parameters: {'n_d': 28, 'n_steps': 6, 'gamma': 1.6049153530082387, 'n_independent': 3, 'n_shared': 5, 'momentum': 0.08815348938401123}. Best is trial 11 with value: 0.5680848360061646.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 29.8106 | val_0_mse: 981.972412109375|  0:00:00s\n","epoch 1  | loss: 5.51883 | val_0_mse: 869.135986328125|  0:00:01s\n","epoch 2  | loss: 3.05949 | val_0_mse: 292.0103454589844|  0:00:02s\n","epoch 3  | loss: 2.28912 | val_0_mse: 139.23533630371094|  0:00:02s\n","epoch 4  | loss: 2.18878 | val_0_mse: 342.16864013671875|  0:00:03s\n","epoch 5  | loss: 2.07258 | val_0_mse: 103.84549713134766|  0:00:04s\n","epoch 6  | loss: 1.73892 | val_0_mse: 85.31861877441406|  0:00:04s\n","epoch 7  | loss: 1.41187 | val_0_mse: 67.2286605834961|  0:00:05s\n","epoch 8  | loss: 1.35062 | val_0_mse: 40.853939056396484|  0:00:06s\n","epoch 9  | loss: 0.99565 | val_0_mse: 28.629840850830078|  0:00:06s\n","epoch 10 | loss: 0.99033 | val_0_mse: 11.273920059204102|  0:00:07s\n","epoch 11 | loss: 1.0477  | val_0_mse: 6.441380023956299|  0:00:08s\n","epoch 12 | loss: 1.28219 | val_0_mse: 4.283629894256592|  0:00:09s\n","epoch 13 | loss: 1.13116 | val_0_mse: 20.056720733642578|  0:00:09s\n","epoch 14 | loss: 0.85374 | val_0_mse: 12.143589973449707|  0:00:10s\n","epoch 15 | loss: 0.75356 | val_0_mse: 9.115360260009766|  0:00:11s\n","epoch 16 | loss: 0.71211 | val_0_mse: 5.867809772491455|  0:00:11s\n","epoch 17 | loss: 0.66449 | val_0_mse: 2.694279909133911|  0:00:12s\n","epoch 18 | loss: 0.69124 | val_0_mse: 8.844539642333984|  0:00:13s\n","epoch 19 | loss: 0.67399 | val_0_mse: 5.03656005859375|  0:00:13s\n","epoch 20 | loss: 0.67704 | val_0_mse: 6.386260032653809|  0:00:14s\n","epoch 21 | loss: 0.65061 | val_0_mse: 5.390699863433838|  0:00:14s\n","epoch 22 | loss: 0.6284  | val_0_mse: 4.273099899291992|  0:00:15s\n","epoch 23 | loss: 0.63592 | val_0_mse: 3.4955499172210693|  0:00:16s\n","epoch 24 | loss: 0.62999 | val_0_mse: 3.295880079269409|  0:00:16s\n","epoch 25 | loss: 0.62602 | val_0_mse: 2.4787700176239014|  0:00:17s\n","epoch 26 | loss: 0.62528 | val_0_mse: 2.9292399883270264|  0:00:18s\n","epoch 27 | loss: 0.64718 | val_0_mse: 3.996040105819702|  0:00:18s\n","epoch 28 | loss: 0.69598 | val_0_mse: 1.7122100591659546|  0:00:19s\n","epoch 29 | loss: 0.62683 | val_0_mse: 1.4446899890899658|  0:00:20s\n","epoch 30 | loss: 0.73399 | val_0_mse: 3.741919994354248|  0:00:20s\n","epoch 31 | loss: 0.68494 | val_0_mse: 1.3483500480651855|  0:00:21s\n","epoch 32 | loss: 0.68637 | val_0_mse: 2.8232500553131104|  0:00:22s\n","epoch 33 | loss: 0.61649 | val_0_mse: 2.20563006401062|  0:00:22s\n","epoch 34 | loss: 0.56371 | val_0_mse: 1.9000400304794312|  0:00:23s\n","epoch 35 | loss: 0.57238 | val_0_mse: 1.2306900024414062|  0:00:24s\n","epoch 36 | loss: 0.54631 | val_0_mse: 1.3060599565505981|  0:00:24s\n","epoch 37 | loss: 0.61859 | val_0_mse: 0.7972300052642822|  0:00:25s\n","epoch 38 | loss: 0.64692 | val_0_mse: 0.9792199730873108|  0:00:26s\n","epoch 39 | loss: 0.59804 | val_0_mse: 1.4572900533676147|  0:00:26s\n","epoch 40 | loss: 0.56769 | val_0_mse: 1.736449956893921|  0:00:27s\n","epoch 41 | loss: 0.60723 | val_0_mse: 1.1555800437927246|  0:00:28s\n","epoch 42 | loss: 0.59816 | val_0_mse: 1.5934100151062012|  0:00:28s\n","epoch 43 | loss: 0.60242 | val_0_mse: 1.0247700214385986|  0:00:29s\n","epoch 44 | loss: 0.60774 | val_0_mse: 0.9644899964332581|  0:00:30s\n","epoch 45 | loss: 0.56965 | val_0_mse: 0.9212499856948853|  0:00:30s\n","epoch 46 | loss: 0.55983 | val_0_mse: 0.8380100131034851|  0:00:31s\n","epoch 47 | loss: 0.56874 | val_0_mse: 0.8498700261116028|  0:00:32s\n","\n","Early stopping occurred at epoch 47 with best_epoch = 37 and best_val_0_mse = 0.7972300052642822\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 16:04:09,624] Trial 21 finished with value: 0.7972254753112793 and parameters: {'n_d': 23, 'n_steps': 9, 'gamma': 1.232514805203641, 'n_independent': 3, 'n_shared': 4, 'momentum': 0.15386851624494197}. Best is trial 11 with value: 0.5680848360061646.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 28.95437| val_0_mse: 897.9391479492188|  0:00:00s\n","epoch 1  | loss: 8.60011 | val_0_mse: 1099.569091796875|  0:00:01s\n","epoch 2  | loss: 4.85946 | val_0_mse: 99.25935363769531|  0:00:02s\n","epoch 3  | loss: 2.47698 | val_0_mse: 188.55555725097656|  0:00:02s\n","epoch 4  | loss: 1.94637 | val_0_mse: 64.43312072753906|  0:00:03s\n","epoch 5  | loss: 1.489   | val_0_mse: 39.48611831665039|  0:00:04s\n","epoch 6  | loss: 1.23088 | val_0_mse: 35.916141510009766|  0:00:05s\n","epoch 7  | loss: 1.08734 | val_0_mse: 12.431929588317871|  0:00:05s\n","epoch 8  | loss: 1.00216 | val_0_mse: 4.339089870452881|  0:00:06s\n","epoch 9  | loss: 0.9505  | val_0_mse: 3.7314000129699707|  0:00:07s\n","epoch 10 | loss: 0.86995 | val_0_mse: 9.07178020477295|  0:00:08s\n","epoch 11 | loss: 0.99303 | val_0_mse: 4.571829795837402|  0:00:08s\n","epoch 12 | loss: 1.03039 | val_0_mse: 2.177649974822998|  0:00:09s\n","epoch 13 | loss: 1.56632 | val_0_mse: 11.937259674072266|  0:00:10s\n","epoch 14 | loss: 1.92625 | val_0_mse: 6.0198798179626465|  0:00:11s\n","epoch 15 | loss: 1.07304 | val_0_mse: 1.8917100429534912|  0:00:11s\n","epoch 16 | loss: 1.09503 | val_0_mse: 8.048800468444824|  0:00:12s\n","epoch 17 | loss: 0.82277 | val_0_mse: 2.186929941177368|  0:00:13s\n","epoch 18 | loss: 0.81454 | val_0_mse: 1.502709984779358|  0:00:13s\n","epoch 19 | loss: 0.73219 | val_0_mse: 3.494879961013794|  0:00:14s\n","epoch 20 | loss: 0.70173 | val_0_mse: 4.330619812011719|  0:00:15s\n","epoch 21 | loss: 0.70888 | val_0_mse: 1.9652199745178223|  0:00:16s\n","epoch 22 | loss: 0.68153 | val_0_mse: 3.5858399868011475|  0:00:16s\n","epoch 23 | loss: 0.69417 | val_0_mse: 1.866260051727295|  0:00:17s\n","epoch 24 | loss: 0.70372 | val_0_mse: 2.6505699157714844|  0:00:18s\n","epoch 25 | loss: 0.63758 | val_0_mse: 2.549030065536499|  0:00:18s\n","epoch 26 | loss: 0.64138 | val_0_mse: 1.8690500259399414|  0:00:19s\n","epoch 27 | loss: 0.66722 | val_0_mse: 1.4216300249099731|  0:00:20s\n","epoch 28 | loss: 0.66221 | val_0_mse: 2.163640022277832|  0:00:21s\n","epoch 29 | loss: 0.60785 | val_0_mse: 2.109189987182617|  0:00:21s\n","epoch 30 | loss: 0.61571 | val_0_mse: 1.8840899467468262|  0:00:22s\n","epoch 31 | loss: 0.61869 | val_0_mse: 2.399930000305176|  0:00:23s\n","epoch 32 | loss: 0.62739 | val_0_mse: 2.0848000049591064|  0:00:23s\n","epoch 33 | loss: 0.60489 | val_0_mse: 2.3527400493621826|  0:00:24s\n","epoch 34 | loss: 0.59741 | val_0_mse: 2.217519998550415|  0:00:25s\n","epoch 35 | loss: 0.56904 | val_0_mse: 1.1916799545288086|  0:00:26s\n","epoch 36 | loss: 0.56834 | val_0_mse: 0.9992899894714355|  0:00:26s\n","epoch 37 | loss: 0.71934 | val_0_mse: 1.3794499635696411|  0:00:27s\n","epoch 38 | loss: 0.66624 | val_0_mse: 1.6444400548934937|  0:00:28s\n","epoch 39 | loss: 0.71886 | val_0_mse: 0.9012100100517273|  0:00:28s\n","epoch 40 | loss: 0.56977 | val_0_mse: 1.1069200038909912|  0:00:29s\n","epoch 41 | loss: 0.56441 | val_0_mse: 0.884090006351471|  0:00:30s\n","epoch 42 | loss: 0.58909 | val_0_mse: 0.7328799962997437|  0:00:31s\n","epoch 43 | loss: 0.60828 | val_0_mse: 0.8555899858474731|  0:00:31s\n","epoch 44 | loss: 0.73308 | val_0_mse: 0.7827399969100952|  0:00:32s\n","epoch 45 | loss: 0.68749 | val_0_mse: 1.4310200214385986|  0:00:33s\n","epoch 46 | loss: 0.60876 | val_0_mse: 1.1447900533676147|  0:00:33s\n","epoch 47 | loss: 0.59561 | val_0_mse: 0.9857100248336792|  0:00:34s\n","epoch 48 | loss: 0.56638 | val_0_mse: 0.9405500292778015|  0:00:35s\n","epoch 49 | loss: 0.56178 | val_0_mse: 0.8671299815177917|  0:00:36s\n","epoch 50 | loss: 0.56977 | val_0_mse: 0.9628499746322632|  0:00:36s\n","epoch 51 | loss: 0.58486 | val_0_mse: 0.8188199996948242|  0:00:37s\n","epoch 52 | loss: 0.6096  | val_0_mse: 0.770609974861145|  0:00:38s\n","\n","Early stopping occurred at epoch 52 with best_epoch = 42 and best_val_0_mse = 0.7328799962997437\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 16:04:48,279] Trial 22 finished with value: 0.7328821420669556 and parameters: {'n_d': 14, 'n_steps': 10, 'gamma': 1.3194726600497924, 'n_independent': 3, 'n_shared': 4, 'momentum': 0.19291718056011237}. Best is trial 11 with value: 0.5680848360061646.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 103.10403| val_0_mse: 265.8672180175781|  0:00:00s\n","epoch 1  | loss: 18.95501| val_0_mse: 1180.420166015625|  0:00:01s\n","epoch 2  | loss: 5.41677 | val_0_mse: 159.18539428710938|  0:00:01s\n","epoch 3  | loss: 2.18629 | val_0_mse: 74.07218170166016|  0:00:02s\n","epoch 4  | loss: 1.24049 | val_0_mse: 18.858200073242188|  0:00:02s\n","epoch 5  | loss: 1.06368 | val_0_mse: 47.53252029418945|  0:00:03s\n","epoch 6  | loss: 0.92779 | val_0_mse: 11.38029956817627|  0:00:04s\n","epoch 7  | loss: 0.84512 | val_0_mse: 12.564800262451172|  0:00:04s\n","epoch 8  | loss: 0.73763 | val_0_mse: 7.513289928436279|  0:00:05s\n","epoch 9  | loss: 0.83558 | val_0_mse: 6.610469818115234|  0:00:06s\n","epoch 10 | loss: 0.7673  | val_0_mse: 2.66828989982605|  0:00:06s\n","epoch 11 | loss: 0.77229 | val_0_mse: 5.957479953765869|  0:00:07s\n","epoch 12 | loss: 0.80716 | val_0_mse: 5.2924699783325195|  0:00:07s\n","epoch 13 | loss: 0.68135 | val_0_mse: 10.403360366821289|  0:00:08s\n","epoch 14 | loss: 0.62324 | val_0_mse: 8.238699913024902|  0:00:09s\n","epoch 15 | loss: 0.58707 | val_0_mse: 3.782870054244995|  0:00:09s\n","epoch 16 | loss: 0.61445 | val_0_mse: 2.5463900566101074|  0:00:10s\n","epoch 17 | loss: 0.61037 | val_0_mse: 3.1894900798797607|  0:00:10s\n","epoch 18 | loss: 0.60398 | val_0_mse: 5.7014899253845215|  0:00:11s\n","epoch 19 | loss: 0.59522 | val_0_mse: 6.273680210113525|  0:00:11s\n","epoch 20 | loss: 0.57727 | val_0_mse: 6.668109893798828|  0:00:12s\n","epoch 21 | loss: 0.56121 | val_0_mse: 2.809689998626709|  0:00:13s\n","epoch 22 | loss: 0.56148 | val_0_mse: 2.3257598876953125|  0:00:13s\n","epoch 23 | loss: 0.55894 | val_0_mse: 4.444729804992676|  0:00:14s\n","epoch 24 | loss: 0.58271 | val_0_mse: 3.437000036239624|  0:00:14s\n","epoch 25 | loss: 0.62479 | val_0_mse: 1.80840003490448|  0:00:15s\n","epoch 26 | loss: 0.66614 | val_0_mse: 6.920730113983154|  0:00:16s\n","epoch 27 | loss: 0.89614 | val_0_mse: 3.423379898071289|  0:00:16s\n","epoch 28 | loss: 0.79683 | val_0_mse: 2.888819932937622|  0:00:17s\n","epoch 29 | loss: 0.7003  | val_0_mse: 3.1609299182891846|  0:00:17s\n","epoch 30 | loss: 0.65442 | val_0_mse: 1.012779951095581|  0:00:18s\n","epoch 31 | loss: 0.59268 | val_0_mse: 2.2434298992156982|  0:00:18s\n","epoch 32 | loss: 0.57662 | val_0_mse: 1.4653799533843994|  0:00:19s\n","epoch 33 | loss: 0.56335 | val_0_mse: 1.4973599910736084|  0:00:20s\n","epoch 34 | loss: 0.64045 | val_0_mse: 2.2236199378967285|  0:00:20s\n","epoch 35 | loss: 0.53991 | val_0_mse: 1.3119499683380127|  0:00:21s\n","epoch 36 | loss: 0.55055 | val_0_mse: 1.7782299518585205|  0:00:21s\n","epoch 37 | loss: 0.54651 | val_0_mse: 1.35971999168396|  0:00:22s\n","epoch 38 | loss: 0.52232 | val_0_mse: 1.4412699937820435|  0:00:22s\n","epoch 39 | loss: 0.53868 | val_0_mse: 1.3674700260162354|  0:00:23s\n","epoch 40 | loss: 0.52552 | val_0_mse: 0.8621799945831299|  0:00:24s\n","epoch 41 | loss: 0.5598  | val_0_mse: 1.5563900470733643|  0:00:24s\n","epoch 42 | loss: 0.5863  | val_0_mse: 0.7400400042533875|  0:00:25s\n","epoch 43 | loss: 0.60303 | val_0_mse: 1.6967400312423706|  0:00:25s\n","epoch 44 | loss: 0.62918 | val_0_mse: 0.8926900029182434|  0:00:26s\n","epoch 45 | loss: 0.53918 | val_0_mse: 1.0415799617767334|  0:00:27s\n","epoch 46 | loss: 0.54136 | val_0_mse: 0.835889995098114|  0:00:27s\n","epoch 47 | loss: 0.53709 | val_0_mse: 1.0665099620819092|  0:00:28s\n","epoch 48 | loss: 0.52819 | val_0_mse: 0.966480016708374|  0:00:28s\n","epoch 49 | loss: 0.5391  | val_0_mse: 0.725820004940033|  0:00:29s\n","epoch 50 | loss: 0.53388 | val_0_mse: 0.9085699915885925|  0:00:30s\n","epoch 51 | loss: 0.51424 | val_0_mse: 0.6518700122833252|  0:00:30s\n","epoch 52 | loss: 0.57846 | val_0_mse: 0.9658899903297424|  0:00:31s\n","epoch 53 | loss: 0.55949 | val_0_mse: 0.6940500140190125|  0:00:31s\n","epoch 54 | loss: 0.5221  | val_0_mse: 0.7338899970054626|  0:00:32s\n","epoch 55 | loss: 0.5246  | val_0_mse: 0.8362100124359131|  0:00:33s\n","epoch 56 | loss: 0.5807  | val_0_mse: 0.6345700025558472|  0:00:33s\n","epoch 57 | loss: 0.60909 | val_0_mse: 0.8827800154685974|  0:00:34s\n","epoch 58 | loss: 0.6021  | val_0_mse: 0.6417800188064575|  0:00:34s\n","epoch 59 | loss: 0.52733 | val_0_mse: 0.752780020236969|  0:00:35s\n","epoch 60 | loss: 0.50963 | val_0_mse: 0.6327000260353088|  0:00:35s\n","epoch 61 | loss: 0.48537 | val_0_mse: 0.6365699768066406|  0:00:36s\n","epoch 62 | loss: 0.49064 | val_0_mse: 0.6068500280380249|  0:00:37s\n","epoch 63 | loss: 0.4975  | val_0_mse: 0.6616600155830383|  0:00:37s\n","epoch 64 | loss: 0.50622 | val_0_mse: 0.7044000029563904|  0:00:38s\n","epoch 65 | loss: 0.51924 | val_0_mse: 0.7047299742698669|  0:00:38s\n","epoch 66 | loss: 0.54741 | val_0_mse: 0.612089991569519|  0:00:39s\n","epoch 67 | loss: 0.52696 | val_0_mse: 0.5957800149917603|  0:00:40s\n","epoch 68 | loss: 0.5467  | val_0_mse: 0.6669399738311768|  0:00:40s\n","epoch 69 | loss: 0.52325 | val_0_mse: 0.6147699952125549|  0:00:41s\n","epoch 70 | loss: 0.51891 | val_0_mse: 0.5866100192070007|  0:00:41s\n","epoch 71 | loss: 0.51925 | val_0_mse: 0.6312199831008911|  0:00:42s\n","epoch 72 | loss: 0.53674 | val_0_mse: 0.5918800234794617|  0:00:43s\n","epoch 73 | loss: 0.52127 | val_0_mse: 0.6236299872398376|  0:00:43s\n","epoch 74 | loss: 0.50324 | val_0_mse: 0.6683200001716614|  0:00:44s\n","epoch 75 | loss: 0.51948 | val_0_mse: 0.5987200140953064|  0:00:44s\n","epoch 76 | loss: 0.52112 | val_0_mse: 0.5970699787139893|  0:00:45s\n","epoch 77 | loss: 0.49326 | val_0_mse: 0.6557700037956238|  0:00:45s\n","epoch 78 | loss: 0.55661 | val_0_mse: 0.58992999792099|  0:00:46s\n","epoch 79 | loss: 0.54365 | val_0_mse: 0.6311500072479248|  0:00:47s\n","epoch 80 | loss: 0.55452 | val_0_mse: 0.5788099765777588|  0:00:47s\n","epoch 81 | loss: 0.51747 | val_0_mse: 0.5846400260925293|  0:00:48s\n","epoch 82 | loss: 0.48959 | val_0_mse: 0.5939300060272217|  0:00:48s\n","epoch 83 | loss: 0.4775  | val_0_mse: 0.5816799998283386|  0:00:49s\n","epoch 84 | loss: 0.4819  | val_0_mse: 0.581849992275238|  0:00:50s\n","epoch 85 | loss: 0.49488 | val_0_mse: 0.5530099868774414|  0:00:50s\n","epoch 86 | loss: 0.48517 | val_0_mse: 0.5719599723815918|  0:00:51s\n","epoch 87 | loss: 0.48813 | val_0_mse: 0.5769500136375427|  0:00:51s\n","epoch 88 | loss: 0.49716 | val_0_mse: 0.5606600046157837|  0:00:52s\n","epoch 89 | loss: 0.47516 | val_0_mse: 0.5537099838256836|  0:00:53s\n","epoch 90 | loss: 0.4863  | val_0_mse: 0.5585600137710571|  0:00:53s\n","epoch 91 | loss: 0.48744 | val_0_mse: 0.5634300112724304|  0:00:54s\n","epoch 92 | loss: 0.50538 | val_0_mse: 0.5508000254631042|  0:00:54s\n","epoch 93 | loss: 0.49599 | val_0_mse: 0.5826500058174133|  0:00:55s\n","epoch 94 | loss: 0.49557 | val_0_mse: 0.5559200048446655|  0:00:55s\n","epoch 95 | loss: 0.49055 | val_0_mse: 0.5958600044250488|  0:00:56s\n","epoch 96 | loss: 0.49733 | val_0_mse: 0.5797899961471558|  0:00:57s\n","epoch 97 | loss: 0.48573 | val_0_mse: 0.5984699726104736|  0:00:57s\n","epoch 98 | loss: 0.48765 | val_0_mse: 0.5690299868583679|  0:00:58s\n","epoch 99 | loss: 0.48686 | val_0_mse: 0.5894200205802917|  0:00:58s\n","Stop training because you reached max_epochs = 100 with best_epoch = 92 and best_val_0_mse = 0.5508000254631042\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 16:05:47,516] Trial 23 finished with value: 0.5507968664169312 and parameters: {'n_d': 21, 'n_steps': 9, 'gamma': 1.123051757515913, 'n_independent': 3, 'n_shared': 3, 'momentum': 0.13627108883225292}. Best is trial 23 with value: 0.5507968664169312.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 18.80041| val_0_mse: 706.107666015625|  0:00:00s\n","epoch 1  | loss: 3.18342 | val_0_mse: 340.18682861328125|  0:00:01s\n","epoch 2  | loss: 2.09798 | val_0_mse: 131.35882568359375|  0:00:01s\n","epoch 3  | loss: 1.41226 | val_0_mse: 108.205078125|  0:00:02s\n","epoch 4  | loss: 1.25627 | val_0_mse: 41.2510986328125|  0:00:02s\n","epoch 5  | loss: 1.14703 | val_0_mse: 83.10794830322266|  0:00:03s\n","epoch 6  | loss: 0.91871 | val_0_mse: 19.8439998626709|  0:00:03s\n","epoch 7  | loss: 0.82307 | val_0_mse: 6.9124298095703125|  0:00:04s\n","epoch 8  | loss: 0.85826 | val_0_mse: 6.130040168762207|  0:00:05s\n","epoch 9  | loss: 0.88138 | val_0_mse: 3.7616798877716064|  0:00:05s\n","epoch 10 | loss: 0.69433 | val_0_mse: 4.457330226898193|  0:00:06s\n","epoch 11 | loss: 0.69846 | val_0_mse: 6.062570095062256|  0:00:06s\n","epoch 12 | loss: 0.64499 | val_0_mse: 2.511539936065674|  0:00:07s\n","epoch 13 | loss: 0.66734 | val_0_mse: 4.3170599937438965|  0:00:07s\n","epoch 14 | loss: 0.62694 | val_0_mse: 5.789790153503418|  0:00:08s\n","epoch 15 | loss: 0.59577 | val_0_mse: 3.1951699256896973|  0:00:08s\n","epoch 16 | loss: 0.58945 | val_0_mse: 2.9507699012756348|  0:00:09s\n","epoch 17 | loss: 0.56691 | val_0_mse: 2.768310070037842|  0:00:09s\n","epoch 18 | loss: 0.59056 | val_0_mse: 5.735779762268066|  0:00:10s\n","epoch 19 | loss: 0.65424 | val_0_mse: 1.9193300008773804|  0:00:10s\n","epoch 20 | loss: 0.68944 | val_0_mse: 3.446010112762451|  0:00:11s\n","epoch 21 | loss: 0.64196 | val_0_mse: 1.5528600215911865|  0:00:11s\n","epoch 22 | loss: 0.5606  | val_0_mse: 1.831030011177063|  0:00:12s\n","epoch 23 | loss: 0.56277 | val_0_mse: 2.3919100761413574|  0:00:13s\n","epoch 24 | loss: 0.5734  | val_0_mse: 1.706089973449707|  0:00:13s\n","epoch 25 | loss: 0.54078 | val_0_mse: 1.7503700256347656|  0:00:14s\n","epoch 26 | loss: 0.60079 | val_0_mse: 3.2249600887298584|  0:00:14s\n","epoch 27 | loss: 0.57224 | val_0_mse: 1.199049949645996|  0:00:15s\n","epoch 28 | loss: 0.56333 | val_0_mse: 1.9397900104522705|  0:00:15s\n","epoch 29 | loss: 0.5418  | val_0_mse: 1.430609941482544|  0:00:16s\n","epoch 30 | loss: 0.53655 | val_0_mse: 1.563599944114685|  0:00:16s\n","epoch 31 | loss: 0.50907 | val_0_mse: 1.1664400100708008|  0:00:17s\n","epoch 32 | loss: 0.56891 | val_0_mse: 1.2392899990081787|  0:00:18s\n","epoch 33 | loss: 0.53714 | val_0_mse: 1.6775200366973877|  0:00:18s\n","epoch 34 | loss: 0.53462 | val_0_mse: 1.1068999767303467|  0:00:19s\n","epoch 35 | loss: 0.52098 | val_0_mse: 1.4029699563980103|  0:00:19s\n","epoch 36 | loss: 0.53606 | val_0_mse: 1.218150019645691|  0:00:20s\n","epoch 37 | loss: 0.5302  | val_0_mse: 1.3102799654006958|  0:00:20s\n","epoch 38 | loss: 0.52899 | val_0_mse: 1.2186000347137451|  0:00:21s\n","epoch 39 | loss: 0.53031 | val_0_mse: 1.3972599506378174|  0:00:21s\n","epoch 40 | loss: 0.53786 | val_0_mse: 0.873740017414093|  0:00:22s\n","epoch 41 | loss: 0.55199 | val_0_mse: 0.8293899893760681|  0:00:22s\n","epoch 42 | loss: 0.51199 | val_0_mse: 1.0427199602127075|  0:00:23s\n","epoch 43 | loss: 0.53679 | val_0_mse: 0.7403900027275085|  0:00:23s\n","epoch 44 | loss: 0.56187 | val_0_mse: 1.5151699781417847|  0:00:24s\n","epoch 45 | loss: 0.55037 | val_0_mse: 0.7238900065422058|  0:00:24s\n","epoch 46 | loss: 0.52487 | val_0_mse: 0.6502299904823303|  0:00:25s\n","epoch 47 | loss: 0.51891 | val_0_mse: 0.8446099758148193|  0:00:26s\n","epoch 48 | loss: 0.50552 | val_0_mse: 0.7294600009918213|  0:00:26s\n","epoch 49 | loss: 0.5176  | val_0_mse: 0.7122799754142761|  0:00:27s\n","epoch 50 | loss: 0.51336 | val_0_mse: 1.0660500526428223|  0:00:27s\n","epoch 51 | loss: 0.52632 | val_0_mse: 0.6958199739456177|  0:00:28s\n","epoch 52 | loss: 0.50201 | val_0_mse: 0.6696100234985352|  0:00:28s\n","epoch 53 | loss: 0.51294 | val_0_mse: 0.9554499983787537|  0:00:29s\n","epoch 54 | loss: 0.50135 | val_0_mse: 0.7236300110816956|  0:00:29s\n","epoch 55 | loss: 0.47267 | val_0_mse: 0.714169979095459|  0:00:30s\n","epoch 56 | loss: 0.47586 | val_0_mse: 0.6786100268363953|  0:00:30s\n","\n","Early stopping occurred at epoch 56 with best_epoch = 46 and best_val_0_mse = 0.6502299904823303\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 16:06:18,790] Trial 24 finished with value: 0.6502321362495422 and parameters: {'n_d': 32, 'n_steps': 7, 'gamma': 1.0856961503012332, 'n_independent': 4, 'n_shared': 3, 'momentum': 0.12426771272182717}. Best is trial 23 with value: 0.5507968664169312.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 16.278  | val_0_mse: 1834.763671875|  0:00:00s\n","epoch 1  | loss: 5.65692 | val_0_mse: 550.9295654296875|  0:00:00s\n","epoch 2  | loss: 2.82139 | val_0_mse: 150.8483428955078|  0:00:01s\n","epoch 3  | loss: 2.06255 | val_0_mse: 37.01087188720703|  0:00:01s\n","epoch 4  | loss: 1.46771 | val_0_mse: 19.179250717163086|  0:00:02s\n","epoch 5  | loss: 1.11426 | val_0_mse: 18.483779907226562|  0:00:02s\n","epoch 6  | loss: 1.00006 | val_0_mse: 19.640409469604492|  0:00:03s\n","epoch 7  | loss: 0.89332 | val_0_mse: 21.442110061645508|  0:00:03s\n","epoch 8  | loss: 0.8627  | val_0_mse: 8.733280181884766|  0:00:04s\n","epoch 9  | loss: 0.86871 | val_0_mse: 7.917240142822266|  0:00:04s\n","epoch 10 | loss: 0.80212 | val_0_mse: 12.816189765930176|  0:00:05s\n","epoch 11 | loss: 0.77115 | val_0_mse: 12.14465045928955|  0:00:05s\n","epoch 12 | loss: 0.81079 | val_0_mse: 6.056819915771484|  0:00:06s\n","epoch 13 | loss: 0.73489 | val_0_mse: 5.1677398681640625|  0:00:06s\n","epoch 14 | loss: 0.74064 | val_0_mse: 4.9096198081970215|  0:00:07s\n","epoch 15 | loss: 0.69487 | val_0_mse: 5.181280136108398|  0:00:07s\n","epoch 16 | loss: 0.68445 | val_0_mse: 8.423990249633789|  0:00:08s\n","epoch 17 | loss: 0.6717  | val_0_mse: 8.02439022064209|  0:00:08s\n","epoch 18 | loss: 0.71141 | val_0_mse: 4.5704498291015625|  0:00:09s\n","epoch 19 | loss: 0.71664 | val_0_mse: 3.5125699043273926|  0:00:09s\n","epoch 20 | loss: 0.64418 | val_0_mse: 3.6529901027679443|  0:00:10s\n","epoch 21 | loss: 0.65642 | val_0_mse: 4.788859844207764|  0:00:10s\n","epoch 22 | loss: 0.66737 | val_0_mse: 3.3787999153137207|  0:00:10s\n","epoch 23 | loss: 0.70924 | val_0_mse: 1.379930019378662|  0:00:11s\n","epoch 24 | loss: 0.64942 | val_0_mse: 1.1716400384902954|  0:00:12s\n","epoch 25 | loss: 0.66204 | val_0_mse: 1.626420021057129|  0:00:12s\n","epoch 26 | loss: 0.69432 | val_0_mse: 1.8604199886322021|  0:00:13s\n","epoch 27 | loss: 0.69784 | val_0_mse: 1.3779499530792236|  0:00:13s\n","epoch 28 | loss: 0.67559 | val_0_mse: 1.59906005859375|  0:00:13s\n","epoch 29 | loss: 0.61691 | val_0_mse: 1.1582800149917603|  0:00:14s\n","epoch 30 | loss: 0.61612 | val_0_mse: 1.2102199792861938|  0:00:14s\n","epoch 31 | loss: 0.63142 | val_0_mse: 0.9427599906921387|  0:00:15s\n","epoch 32 | loss: 0.61366 | val_0_mse: 0.8687800168991089|  0:00:15s\n","epoch 33 | loss: 0.62078 | val_0_mse: 0.8773599863052368|  0:00:16s\n","epoch 34 | loss: 0.61026 | val_0_mse: 1.0839799642562866|  0:00:16s\n","epoch 35 | loss: 0.57358 | val_0_mse: 1.5874099731445312|  0:00:17s\n","epoch 36 | loss: 0.60784 | val_0_mse: 1.5924999713897705|  0:00:17s\n","epoch 37 | loss: 0.58311 | val_0_mse: 1.629480004310608|  0:00:18s\n","epoch 38 | loss: 0.59035 | val_0_mse: 1.6345499753952026|  0:00:18s\n","epoch 39 | loss: 0.56383 | val_0_mse: 1.3459800481796265|  0:00:19s\n","epoch 40 | loss: 0.57327 | val_0_mse: 1.1191500425338745|  0:00:19s\n","epoch 41 | loss: 0.59641 | val_0_mse: 0.7889299988746643|  0:00:20s\n","epoch 42 | loss: 0.62081 | val_0_mse: 1.3167500495910645|  0:00:20s\n","epoch 43 | loss: 0.72893 | val_0_mse: 0.8902400135993958|  0:00:20s\n","epoch 44 | loss: 0.63713 | val_0_mse: 1.1309900283813477|  0:00:21s\n","epoch 45 | loss: 0.63785 | val_0_mse: 0.8825500011444092|  0:00:21s\n","epoch 46 | loss: 0.56089 | val_0_mse: 1.0119099617004395|  0:00:22s\n","epoch 47 | loss: 0.54312 | val_0_mse: 1.0345200300216675|  0:00:22s\n","epoch 48 | loss: 0.53725 | val_0_mse: 1.0473699569702148|  0:00:23s\n","epoch 49 | loss: 0.55778 | val_0_mse: 0.9968699812889099|  0:00:23s\n","epoch 50 | loss: 0.57994 | val_0_mse: 1.048140048980713|  0:00:24s\n","epoch 51 | loss: 0.57445 | val_0_mse: 0.728950023651123|  0:00:24s\n","epoch 52 | loss: 0.54962 | val_0_mse: 0.8700799942016602|  0:00:25s\n","epoch 53 | loss: 0.55184 | val_0_mse: 0.709309995174408|  0:00:25s\n","epoch 54 | loss: 0.53229 | val_0_mse: 0.7528899908065796|  0:00:26s\n","epoch 55 | loss: 0.52461 | val_0_mse: 0.7415000200271606|  0:00:26s\n","epoch 56 | loss: 0.52756 | val_0_mse: 0.7445200085639954|  0:00:26s\n","epoch 57 | loss: 0.52531 | val_0_mse: 0.7662400007247925|  0:00:27s\n","epoch 58 | loss: 0.51456 | val_0_mse: 0.7173200249671936|  0:00:27s\n","epoch 59 | loss: 0.50995 | val_0_mse: 0.8346199989318848|  0:00:28s\n","epoch 60 | loss: 0.52948 | val_0_mse: 0.7170500159263611|  0:00:28s\n","epoch 61 | loss: 0.51986 | val_0_mse: 0.6179999709129333|  0:00:29s\n","epoch 62 | loss: 0.54254 | val_0_mse: 0.7371699810028076|  0:00:29s\n","epoch 63 | loss: 0.52667 | val_0_mse: 0.734790027141571|  0:00:30s\n","epoch 64 | loss: 0.52979 | val_0_mse: 0.6755499839782715|  0:00:30s\n","epoch 65 | loss: 0.54795 | val_0_mse: 0.7103800177574158|  0:00:31s\n","epoch 66 | loss: 0.52698 | val_0_mse: 0.7032999992370605|  0:00:31s\n","epoch 67 | loss: 0.52362 | val_0_mse: 0.6366599798202515|  0:00:32s\n","epoch 68 | loss: 0.51751 | val_0_mse: 0.7753999829292297|  0:00:32s\n","epoch 69 | loss: 0.5608  | val_0_mse: 0.642769992351532|  0:00:33s\n","epoch 70 | loss: 0.52319 | val_0_mse: 0.6740999817848206|  0:00:33s\n","epoch 71 | loss: 0.51436 | val_0_mse: 0.7002300024032593|  0:00:34s\n","\n","Early stopping occurred at epoch 71 with best_epoch = 61 and best_val_0_mse = 0.6179999709129333\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 16:06:53,122] Trial 25 finished with value: 0.6179977059364319 and parameters: {'n_d': 13, 'n_steps': 8, 'gamma': 1.1387984585515099, 'n_independent': 2, 'n_shared': 3, 'momentum': 0.03564611227997552}. Best is trial 23 with value: 0.5507968664169312.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 13.53513| val_0_mse: 3208.615478515625|  0:00:00s\n","epoch 1  | loss: 5.95332 | val_0_mse: 1024.710205078125|  0:00:01s\n","epoch 2  | loss: 2.56486 | val_0_mse: 1187.8162841796875|  0:00:02s\n","epoch 3  | loss: 1.81557 | val_0_mse: 65.54022216796875|  0:00:03s\n","epoch 4  | loss: 1.51866 | val_0_mse: 121.60421752929688|  0:00:04s\n","epoch 5  | loss: 1.14842 | val_0_mse: 48.069488525390625|  0:00:05s\n","epoch 6  | loss: 1.14472 | val_0_mse: 65.0023193359375|  0:00:06s\n","epoch 7  | loss: 1.71685 | val_0_mse: 24.043800354003906|  0:00:07s\n","epoch 8  | loss: 2.38025 | val_0_mse: 46.10287857055664|  0:00:08s\n","epoch 9  | loss: 1.40995 | val_0_mse: 106.03629302978516|  0:00:09s\n","epoch 10 | loss: 3.08611 | val_0_mse: 39.04853820800781|  0:00:10s\n","epoch 11 | loss: 2.04475 | val_0_mse: 23.580720901489258|  0:00:11s\n","epoch 12 | loss: 1.64845 | val_0_mse: 22.770740509033203|  0:00:12s\n","epoch 13 | loss: 0.91964 | val_0_mse: 15.18317985534668|  0:00:13s\n","epoch 14 | loss: 0.83827 | val_0_mse: 24.219839096069336|  0:00:14s\n","epoch 15 | loss: 0.79507 | val_0_mse: 8.905159950256348|  0:00:15s\n","epoch 16 | loss: 0.80481 | val_0_mse: 5.382820129394531|  0:00:16s\n","epoch 17 | loss: 1.02443 | val_0_mse: 2.791759967803955|  0:00:17s\n","epoch 18 | loss: 0.72244 | val_0_mse: 2.778909921646118|  0:00:18s\n","epoch 19 | loss: 0.68765 | val_0_mse: 3.180150032043457|  0:00:19s\n","epoch 20 | loss: 0.74418 | val_0_mse: 3.2566099166870117|  0:00:20s\n","epoch 21 | loss: 0.67636 | val_0_mse: 1.5324900150299072|  0:00:21s\n","epoch 22 | loss: 0.66426 | val_0_mse: 3.548190116882324|  0:00:22s\n","epoch 23 | loss: 0.66488 | val_0_mse: 2.621999979019165|  0:00:23s\n","epoch 24 | loss: 0.94951 | val_0_mse: 1.8751200437545776|  0:00:24s\n","epoch 25 | loss: 0.84913 | val_0_mse: 1.1087499856948853|  0:00:25s\n","epoch 26 | loss: 1.45752 | val_0_mse: 1.0936800241470337|  0:00:26s\n","epoch 27 | loss: 0.99566 | val_0_mse: 2.7604498863220215|  0:00:27s\n","epoch 28 | loss: 1.33198 | val_0_mse: 1.2370200157165527|  0:00:28s\n","epoch 29 | loss: 1.34154 | val_0_mse: 1.3921600580215454|  0:00:29s\n","epoch 30 | loss: 1.18947 | val_0_mse: 1.9777300357818604|  0:00:30s\n","epoch 31 | loss: 0.80904 | val_0_mse: 0.9964799880981445|  0:00:30s\n","epoch 32 | loss: 0.71581 | val_0_mse: 1.6778600215911865|  0:00:31s\n","epoch 33 | loss: 0.65127 | val_0_mse: 1.031559944152832|  0:00:32s\n","epoch 34 | loss: 0.65871 | val_0_mse: 1.1129800081253052|  0:00:33s\n","epoch 35 | loss: 0.62773 | val_0_mse: 1.001289963722229|  0:00:34s\n","epoch 36 | loss: 0.62414 | val_0_mse: 1.1361700296401978|  0:00:35s\n","epoch 37 | loss: 0.61573 | val_0_mse: 0.9417499899864197|  0:00:36s\n","epoch 38 | loss: 0.63499 | val_0_mse: 0.9841099977493286|  0:00:37s\n","epoch 39 | loss: 0.69588 | val_0_mse: 1.1428500413894653|  0:00:38s\n","epoch 40 | loss: 0.65546 | val_0_mse: 0.8641999959945679|  0:00:39s\n","epoch 41 | loss: 0.61925 | val_0_mse: 0.8614400029182434|  0:00:40s\n","epoch 42 | loss: 0.63522 | val_0_mse: 1.2245500087738037|  0:00:41s\n","epoch 43 | loss: 0.66155 | val_0_mse: 0.727940022945404|  0:00:42s\n","epoch 44 | loss: 0.60664 | val_0_mse: 1.0370700359344482|  0:00:43s\n","epoch 45 | loss: 0.65379 | val_0_mse: 0.826479971408844|  0:00:44s\n","epoch 46 | loss: 0.69257 | val_0_mse: 1.407920002937317|  0:00:45s\n","epoch 47 | loss: 0.7288  | val_0_mse: 0.9445300102233887|  0:00:46s\n","epoch 48 | loss: 0.82215 | val_0_mse: 1.4415899515151978|  0:00:47s\n","epoch 49 | loss: 0.68064 | val_0_mse: 0.729420006275177|  0:00:48s\n","epoch 50 | loss: 0.62543 | val_0_mse: 0.8698999881744385|  0:00:49s\n","epoch 51 | loss: 0.61336 | val_0_mse: 1.0924299955368042|  0:00:50s\n","epoch 52 | loss: 0.58489 | val_0_mse: 0.8941400051116943|  0:00:51s\n","epoch 53 | loss: 0.57608 | val_0_mse: 0.7903100252151489|  0:00:51s\n","\n","Early stopping occurred at epoch 53 with best_epoch = 43 and best_val_0_mse = 0.727940022945404\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 16:07:45,659] Trial 26 finished with value: 0.727942168712616 and parameters: {'n_d': 20, 'n_steps': 10, 'gamma': 1.3906632992423436, 'n_independent': 5, 'n_shared': 5, 'momentum': 0.271329911917246}. Best is trial 23 with value: 0.5507968664169312.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 31.76999| val_0_mse: 1447.99169921875|  0:00:00s\n","epoch 1  | loss: 4.05602 | val_0_mse: 517.5020751953125|  0:00:01s\n","epoch 2  | loss: 2.6728  | val_0_mse: 194.6560821533203|  0:00:01s\n","epoch 3  | loss: 3.6551  | val_0_mse: 186.73782348632812|  0:00:02s\n","epoch 4  | loss: 2.68658 | val_0_mse: 68.06278228759766|  0:00:03s\n","epoch 5  | loss: 1.85361 | val_0_mse: 127.47498321533203|  0:00:03s\n","epoch 6  | loss: 2.36623 | val_0_mse: 51.2598991394043|  0:00:04s\n","epoch 7  | loss: 2.15165 | val_0_mse: 14.869529724121094|  0:00:04s\n","epoch 8  | loss: 1.25137 | val_0_mse: 56.042259216308594|  0:00:05s\n","epoch 9  | loss: 0.99216 | val_0_mse: 25.184419631958008|  0:00:06s\n","epoch 10 | loss: 0.85008 | val_0_mse: 24.892520904541016|  0:00:06s\n","epoch 11 | loss: 0.83533 | val_0_mse: 48.73817825317383|  0:00:07s\n","epoch 12 | loss: 0.73706 | val_0_mse: 64.37222290039062|  0:00:07s\n","epoch 13 | loss: 0.86891 | val_0_mse: 52.61069869995117|  0:00:08s\n","epoch 14 | loss: 0.85205 | val_0_mse: 9.698579788208008|  0:00:08s\n","epoch 15 | loss: 0.74504 | val_0_mse: 6.62775993347168|  0:00:09s\n","epoch 16 | loss: 0.86518 | val_0_mse: 3.292259931564331|  0:00:10s\n","epoch 17 | loss: 0.71014 | val_0_mse: 3.3208200931549072|  0:00:10s\n","epoch 18 | loss: 0.72108 | val_0_mse: 4.164050102233887|  0:00:11s\n","epoch 19 | loss: 0.7272  | val_0_mse: 7.204520225524902|  0:00:11s\n","epoch 20 | loss: 0.89791 | val_0_mse: 5.872290134429932|  0:00:12s\n","epoch 21 | loss: 0.71985 | val_0_mse: 4.5063300132751465|  0:00:13s\n","epoch 22 | loss: 0.64939 | val_0_mse: 4.50793981552124|  0:00:13s\n","epoch 23 | loss: 0.59081 | val_0_mse: 8.262459754943848|  0:00:14s\n","epoch 24 | loss: 0.6189  | val_0_mse: 5.693789958953857|  0:00:14s\n","epoch 25 | loss: 0.64389 | val_0_mse: 4.222410202026367|  0:00:15s\n","epoch 26 | loss: 0.6269  | val_0_mse: 2.3797600269317627|  0:00:16s\n","epoch 27 | loss: 0.61453 | val_0_mse: 3.2197299003601074|  0:00:16s\n","epoch 28 | loss: 0.61942 | val_0_mse: 4.128940105438232|  0:00:17s\n","epoch 29 | loss: 0.62517 | val_0_mse: 1.5438499450683594|  0:00:17s\n","epoch 30 | loss: 0.5689  | val_0_mse: 3.982069969177246|  0:00:18s\n","epoch 31 | loss: 0.5614  | val_0_mse: 0.967739999294281|  0:00:18s\n","epoch 32 | loss: 0.61849 | val_0_mse: 1.48225998878479|  0:00:19s\n","epoch 33 | loss: 0.58829 | val_0_mse: 1.827299952507019|  0:00:20s\n","epoch 34 | loss: 0.60758 | val_0_mse: 1.0030299425125122|  0:00:20s\n","epoch 35 | loss: 0.55809 | val_0_mse: 0.9651700258255005|  0:00:21s\n","epoch 36 | loss: 0.55914 | val_0_mse: 0.9767000079154968|  0:00:22s\n","epoch 37 | loss: 0.5657  | val_0_mse: 0.9168000221252441|  0:00:22s\n","epoch 38 | loss: 0.55284 | val_0_mse: 0.907800018787384|  0:00:23s\n","epoch 39 | loss: 0.54545 | val_0_mse: 0.9768400192260742|  0:00:23s\n","epoch 40 | loss: 0.57379 | val_0_mse: 0.7916399836540222|  0:00:24s\n","epoch 41 | loss: 0.67722 | val_0_mse: 1.0578099489212036|  0:00:25s\n","epoch 42 | loss: 0.80506 | val_0_mse: 1.1998300552368164|  0:00:25s\n","epoch 43 | loss: 0.58111 | val_0_mse: 1.039389967918396|  0:00:26s\n","epoch 44 | loss: 0.5639  | val_0_mse: 0.9552199840545654|  0:00:26s\n","epoch 45 | loss: 0.55156 | val_0_mse: 0.7717700004577637|  0:00:27s\n","epoch 46 | loss: 0.55552 | val_0_mse: 0.831849992275238|  0:00:28s\n","epoch 47 | loss: 0.52607 | val_0_mse: 0.7246299982070923|  0:00:28s\n","epoch 48 | loss: 0.52935 | val_0_mse: 0.697920024394989|  0:00:29s\n","epoch 49 | loss: 0.55568 | val_0_mse: 1.0062099695205688|  0:00:29s\n","epoch 50 | loss: 0.57985 | val_0_mse: 0.8147500157356262|  0:00:30s\n","epoch 51 | loss: 0.5629  | val_0_mse: 0.660830020904541|  0:00:31s\n","epoch 52 | loss: 0.53677 | val_0_mse: 0.6372299790382385|  0:00:31s\n","epoch 53 | loss: 0.52559 | val_0_mse: 0.6816999912261963|  0:00:32s\n","epoch 54 | loss: 0.53851 | val_0_mse: 0.7135800123214722|  0:00:32s\n","epoch 55 | loss: 0.53026 | val_0_mse: 0.8070499897003174|  0:00:33s\n","epoch 56 | loss: 0.53605 | val_0_mse: 0.7658299803733826|  0:00:34s\n","epoch 57 | loss: 0.54098 | val_0_mse: 0.7450900077819824|  0:00:34s\n","epoch 58 | loss: 0.53198 | val_0_mse: 0.704509973526001|  0:00:35s\n","epoch 59 | loss: 0.52545 | val_0_mse: 0.630649983882904|  0:00:35s\n","epoch 60 | loss: 0.55227 | val_0_mse: 0.7103599905967712|  0:00:36s\n","epoch 61 | loss: 0.52943 | val_0_mse: 0.8414599895477295|  0:00:36s\n","epoch 62 | loss: 0.55601 | val_0_mse: 0.7654299736022949|  0:00:37s\n","epoch 63 | loss: 0.55435 | val_0_mse: 0.7009599804878235|  0:00:38s\n","epoch 64 | loss: 0.54211 | val_0_mse: 0.6706200242042542|  0:00:38s\n","epoch 65 | loss: 0.52025 | val_0_mse: 0.6763899922370911|  0:00:39s\n","epoch 66 | loss: 0.53318 | val_0_mse: 0.6803600192070007|  0:00:39s\n","epoch 67 | loss: 0.54219 | val_0_mse: 0.6159899830818176|  0:00:40s\n","epoch 68 | loss: 0.5439  | val_0_mse: 0.6023899912834167|  0:00:41s\n","epoch 69 | loss: 0.51082 | val_0_mse: 0.6111900210380554|  0:00:41s\n","epoch 70 | loss: 0.52797 | val_0_mse: 0.5996999740600586|  0:00:42s\n","epoch 71 | loss: 0.52706 | val_0_mse: 0.6832000017166138|  0:00:42s\n","epoch 72 | loss: 0.51938 | val_0_mse: 0.6132299900054932|  0:00:43s\n","epoch 73 | loss: 0.51244 | val_0_mse: 0.6140499711036682|  0:00:44s\n","epoch 74 | loss: 0.53854 | val_0_mse: 0.6422500014305115|  0:00:44s\n","epoch 75 | loss: 0.52922 | val_0_mse: 0.6524400115013123|  0:00:45s\n","epoch 76 | loss: 0.53156 | val_0_mse: 0.636210024356842|  0:00:45s\n","epoch 77 | loss: 0.52519 | val_0_mse: 0.6395699977874756|  0:00:46s\n","epoch 78 | loss: 0.53157 | val_0_mse: 0.6302899718284607|  0:00:46s\n","epoch 79 | loss: 0.53581 | val_0_mse: 0.7617499828338623|  0:00:47s\n","epoch 80 | loss: 0.55194 | val_0_mse: 0.6863300204277039|  0:00:48s\n","\n","Early stopping occurred at epoch 80 with best_epoch = 70 and best_val_0_mse = 0.5996999740600586\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 16:08:34,198] Trial 27 finished with value: 0.599698007106781 and parameters: {'n_d': 40, 'n_steps': 9, 'gamma': 1.2104840440460292, 'n_independent': 3, 'n_shared': 3, 'momentum': 0.3780598636060697}. Best is trial 23 with value: 0.5507968664169312.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 7.49637 | val_0_mse: 990.5592041015625|  0:00:00s\n","epoch 1  | loss: 2.58793 | val_0_mse: 191.809814453125|  0:00:00s\n","epoch 2  | loss: 2.12676 | val_0_mse: 53.02231979370117|  0:00:00s\n","epoch 3  | loss: 1.80935 | val_0_mse: 413.4597473144531|  0:00:01s\n","epoch 4  | loss: 1.79771 | val_0_mse: 12.685279846191406|  0:00:01s\n","epoch 5  | loss: 2.52865 | val_0_mse: 19.320810317993164|  0:00:01s\n","epoch 6  | loss: 1.80746 | val_0_mse: 4.868000030517578|  0:00:01s\n","epoch 7  | loss: 1.02313 | val_0_mse: 29.906280517578125|  0:00:02s\n","epoch 8  | loss: 0.92542 | val_0_mse: 6.002049922943115|  0:00:02s\n","epoch 9  | loss: 0.78526 | val_0_mse: 7.090429782867432|  0:00:02s\n","epoch 10 | loss: 0.75417 | val_0_mse: 6.965740203857422|  0:00:03s\n","epoch 11 | loss: 0.72129 | val_0_mse: 3.2396399974823|  0:00:03s\n","epoch 12 | loss: 0.86661 | val_0_mse: 5.322470188140869|  0:00:03s\n","epoch 13 | loss: 0.84378 | val_0_mse: 10.231220245361328|  0:00:03s\n","epoch 14 | loss: 0.98115 | val_0_mse: 1.5825599431991577|  0:00:04s\n","epoch 15 | loss: 1.15793 | val_0_mse: 5.448780059814453|  0:00:04s\n","epoch 16 | loss: 0.84102 | val_0_mse: 1.8527599573135376|  0:00:04s\n","epoch 17 | loss: 1.09331 | val_0_mse: 12.185870170593262|  0:00:05s\n","epoch 18 | loss: 1.09716 | val_0_mse: 8.861889839172363|  0:00:05s\n","epoch 19 | loss: 0.82756 | val_0_mse: 2.3863298892974854|  0:00:05s\n","epoch 20 | loss: 0.77876 | val_0_mse: 4.301959991455078|  0:00:05s\n","epoch 21 | loss: 0.68403 | val_0_mse: 4.318339824676514|  0:00:06s\n","epoch 22 | loss: 0.73972 | val_0_mse: 1.0155400037765503|  0:00:06s\n","epoch 23 | loss: 0.73026 | val_0_mse: 1.2618900537490845|  0:00:06s\n","epoch 24 | loss: 0.68259 | val_0_mse: 1.1463799476623535|  0:00:07s\n","epoch 25 | loss: 0.6335  | val_0_mse: 1.372499942779541|  0:00:07s\n","epoch 26 | loss: 0.60577 | val_0_mse: 3.419909954071045|  0:00:07s\n","epoch 27 | loss: 0.58429 | val_0_mse: 3.817229986190796|  0:00:07s\n","epoch 28 | loss: 0.60523 | val_0_mse: 3.0747199058532715|  0:00:08s\n","epoch 29 | loss: 0.66586 | val_0_mse: 1.2700999975204468|  0:00:08s\n","epoch 30 | loss: 0.64613 | val_0_mse: 1.3852100372314453|  0:00:08s\n","epoch 31 | loss: 0.63338 | val_0_mse: 1.5862200260162354|  0:00:09s\n","epoch 32 | loss: 0.62861 | val_0_mse: 0.9439799785614014|  0:00:09s\n","epoch 33 | loss: 0.57974 | val_0_mse: 1.0807100534439087|  0:00:09s\n","epoch 34 | loss: 0.59486 | val_0_mse: 1.2112799882888794|  0:00:09s\n","epoch 35 | loss: 0.62088 | val_0_mse: 2.7248098850250244|  0:00:10s\n","epoch 36 | loss: 0.65941 | val_0_mse: 1.5417200326919556|  0:00:10s\n","epoch 37 | loss: 0.70404 | val_0_mse: 1.1088900566101074|  0:00:10s\n","epoch 38 | loss: 0.58852 | val_0_mse: 1.5102900266647339|  0:00:10s\n","epoch 39 | loss: 0.61302 | val_0_mse: 0.9675999879837036|  0:00:11s\n","epoch 40 | loss: 0.62373 | val_0_mse: 1.9681400060653687|  0:00:11s\n","epoch 41 | loss: 0.6371  | val_0_mse: 1.0735599994659424|  0:00:11s\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 16:08:46,430] Trial 28 finished with value: 0.943976104259491 and parameters: {'n_d': 29, 'n_steps': 8, 'gamma': 1.53649940832427, 'n_independent': 1, 'n_shared': 1, 'momentum': 0.09743527229028175}. Best is trial 23 with value: 0.5507968664169312.\n"]},{"output_type":"stream","name":"stdout","text":["epoch 42 | loss: 0.61546 | val_0_mse: 0.9778900146484375|  0:00:12s\n","\n","Early stopping occurred at epoch 42 with best_epoch = 32 and best_val_0_mse = 0.9439799785614014\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 63.49307| val_0_mse: 1492.5782470703125|  0:00:00s\n","epoch 1  | loss: 22.21687| val_0_mse: 632.9457397460938|  0:00:01s\n","epoch 2  | loss: 8.16423 | val_0_mse: 868.0067138671875|  0:00:01s\n","epoch 3  | loss: 5.03879 | val_0_mse: 839.8038940429688|  0:00:02s\n","epoch 4  | loss: 2.60661 | val_0_mse: 298.0123291015625|  0:00:03s\n","epoch 5  | loss: 2.19475 | val_0_mse: 314.7638244628906|  0:00:03s\n","epoch 6  | loss: 1.78369 | val_0_mse: 159.0340576171875|  0:00:04s\n","epoch 7  | loss: 1.47166 | val_0_mse: 97.78324127197266|  0:00:05s\n","epoch 8  | loss: 1.21455 | val_0_mse: 50.627418518066406|  0:00:05s\n","epoch 9  | loss: 1.00908 | val_0_mse: 38.301658630371094|  0:00:06s\n","epoch 10 | loss: 0.8815  | val_0_mse: 38.44887924194336|  0:00:07s\n","epoch 11 | loss: 0.79654 | val_0_mse: 56.4687614440918|  0:00:07s\n","epoch 12 | loss: 0.76647 | val_0_mse: 32.91477966308594|  0:00:08s\n","epoch 13 | loss: 0.69209 | val_0_mse: 7.973690032958984|  0:00:09s\n","epoch 14 | loss: 0.68541 | val_0_mse: 3.054529905319214|  0:00:09s\n","epoch 15 | loss: 0.69597 | val_0_mse: 3.2309999465942383|  0:00:10s\n","epoch 16 | loss: 0.67692 | val_0_mse: 3.2207999229431152|  0:00:10s\n","epoch 17 | loss: 0.66508 | val_0_mse: 4.345749855041504|  0:00:11s\n","epoch 18 | loss: 0.64761 | val_0_mse: 5.910120010375977|  0:00:12s\n","epoch 19 | loss: 0.64861 | val_0_mse: 6.625949859619141|  0:00:12s\n","epoch 20 | loss: 0.62595 | val_0_mse: 4.459670066833496|  0:00:13s\n","epoch 21 | loss: 0.66619 | val_0_mse: 4.774539947509766|  0:00:14s\n","epoch 22 | loss: 0.68774 | val_0_mse: 3.2836201190948486|  0:00:14s\n","epoch 23 | loss: 0.63402 | val_0_mse: 2.19566011428833|  0:00:15s\n","epoch 24 | loss: 0.64273 | val_0_mse: 3.675869941711426|  0:00:15s\n","epoch 25 | loss: 0.70976 | val_0_mse: 2.8212599754333496|  0:00:16s\n","epoch 26 | loss: 0.62959 | val_0_mse: 1.5799599885940552|  0:00:17s\n","epoch 27 | loss: 0.63287 | val_0_mse: 2.689340114593506|  0:00:17s\n","epoch 28 | loss: 0.64112 | val_0_mse: 1.6810799837112427|  0:00:18s\n","epoch 29 | loss: 0.99075 | val_0_mse: 2.329349994659424|  0:00:19s\n","epoch 30 | loss: 0.76296 | val_0_mse: 1.0999799966812134|  0:00:19s\n","epoch 31 | loss: 0.77372 | val_0_mse: 1.7921799421310425|  0:00:20s\n","epoch 32 | loss: 0.71574 | val_0_mse: 1.0200599431991577|  0:00:21s\n","epoch 33 | loss: 0.70447 | val_0_mse: 1.5739699602127075|  0:00:21s\n","epoch 34 | loss: 0.66131 | val_0_mse: 1.2106900215148926|  0:00:22s\n","epoch 35 | loss: 0.71226 | val_0_mse: 1.1274800300598145|  0:00:23s\n","epoch 36 | loss: 0.60397 | val_0_mse: 1.6384600400924683|  0:00:23s\n","epoch 37 | loss: 0.60998 | val_0_mse: 1.4416899681091309|  0:00:24s\n","epoch 38 | loss: 0.58475 | val_0_mse: 1.3306000232696533|  0:00:25s\n","epoch 39 | loss: 0.59591 | val_0_mse: 1.0875699520111084|  0:00:25s\n","epoch 40 | loss: 0.5727  | val_0_mse: 1.0615400075912476|  0:00:26s\n","epoch 41 | loss: 0.60068 | val_0_mse: 0.7918099761009216|  0:00:26s\n","epoch 42 | loss: 0.64284 | val_0_mse: 0.9450700283050537|  0:00:27s\n","epoch 43 | loss: 0.59128 | val_0_mse: 0.9251899719238281|  0:00:28s\n","epoch 44 | loss: 0.57068 | val_0_mse: 0.9705399870872498|  0:00:28s\n","epoch 45 | loss: 0.58073 | val_0_mse: 0.8652899861335754|  0:00:29s\n","epoch 46 | loss: 0.56861 | val_0_mse: 0.8887199759483337|  0:00:30s\n","epoch 47 | loss: 0.55944 | val_0_mse: 0.7884299755096436|  0:00:30s\n","epoch 48 | loss: 0.56045 | val_0_mse: 0.8527600169181824|  0:00:31s\n","epoch 49 | loss: 0.57229 | val_0_mse: 0.8709400296211243|  0:00:32s\n","epoch 50 | loss: 0.56284 | val_0_mse: 0.802299976348877|  0:00:32s\n","epoch 51 | loss: 0.55392 | val_0_mse: 0.7773200273513794|  0:00:33s\n","epoch 52 | loss: 0.53857 | val_0_mse: 0.781440019607544|  0:00:34s\n","epoch 53 | loss: 0.55713 | val_0_mse: 0.6958600282669067|  0:00:34s\n","epoch 54 | loss: 0.55972 | val_0_mse: 0.7177199721336365|  0:00:35s\n","epoch 55 | loss: 0.5649  | val_0_mse: 0.8226900100708008|  0:00:35s\n","epoch 56 | loss: 0.63998 | val_0_mse: 0.8199099898338318|  0:00:36s\n","epoch 57 | loss: 0.5953  | val_0_mse: 0.7506399750709534|  0:00:37s\n","epoch 58 | loss: 0.70352 | val_0_mse: 1.1804499626159668|  0:00:37s\n","epoch 59 | loss: 0.65423 | val_0_mse: 0.6304100155830383|  0:00:38s\n","epoch 60 | loss: 0.59675 | val_0_mse: 0.7368500232696533|  0:00:39s\n","epoch 61 | loss: 0.56171 | val_0_mse: 0.6524400115013123|  0:00:39s\n","epoch 62 | loss: 0.58705 | val_0_mse: 0.8021900057792664|  0:00:40s\n","epoch 63 | loss: 0.5799  | val_0_mse: 0.6328499913215637|  0:00:40s\n","epoch 64 | loss: 0.56011 | val_0_mse: 0.615339994430542|  0:00:41s\n","epoch 65 | loss: 0.55641 | val_0_mse: 0.7297599911689758|  0:00:42s\n","epoch 66 | loss: 0.55153 | val_0_mse: 0.5989199876785278|  0:00:42s\n","epoch 67 | loss: 0.53139 | val_0_mse: 0.6482899785041809|  0:00:43s\n","epoch 68 | loss: 0.54704 | val_0_mse: 0.659280002117157|  0:00:44s\n","epoch 69 | loss: 0.547   | val_0_mse: 0.6039599776268005|  0:00:44s\n","epoch 70 | loss: 0.56336 | val_0_mse: 0.7478500008583069|  0:00:45s\n","epoch 71 | loss: 0.5949  | val_0_mse: 0.636210024356842|  0:00:46s\n","epoch 72 | loss: 0.57731 | val_0_mse: 0.653190016746521|  0:00:46s\n","epoch 73 | loss: 0.54877 | val_0_mse: 0.6029599905014038|  0:00:47s\n","epoch 74 | loss: 0.55241 | val_0_mse: 0.5849400162696838|  0:00:47s\n","epoch 75 | loss: 0.54163 | val_0_mse: 0.6314700245857239|  0:00:48s\n","epoch 76 | loss: 0.53885 | val_0_mse: 0.5835999846458435|  0:00:49s\n","epoch 77 | loss: 0.52258 | val_0_mse: 0.5804700255393982|  0:00:49s\n","epoch 78 | loss: 0.54108 | val_0_mse: 0.6395099759101868|  0:00:50s\n","epoch 79 | loss: 0.54575 | val_0_mse: 0.5816100239753723|  0:00:51s\n","epoch 80 | loss: 0.5438  | val_0_mse: 0.5892000198364258|  0:00:51s\n","epoch 81 | loss: 0.53963 | val_0_mse: 0.585319995880127|  0:00:52s\n","epoch 82 | loss: 0.52903 | val_0_mse: 0.5896499752998352|  0:00:53s\n","epoch 83 | loss: 0.5281  | val_0_mse: 0.5863199830055237|  0:00:53s\n","epoch 84 | loss: 0.52696 | val_0_mse: 0.5876799821853638|  0:00:54s\n","epoch 85 | loss: 0.52683 | val_0_mse: 0.5970900058746338|  0:00:55s\n","epoch 86 | loss: 0.50859 | val_0_mse: 0.5896000266075134|  0:00:55s\n","epoch 87 | loss: 0.5132  | val_0_mse: 0.5844299793243408|  0:00:56s\n","\n","Early stopping occurred at epoch 87 with best_epoch = 77 and best_val_0_mse = 0.5804700255393982\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 16:09:43,125] Trial 29 finished with value: 0.5804734826087952 and parameters: {'n_d': 8, 'n_steps': 10, 'gamma': 1.1297417031830255, 'n_independent': 1, 'n_shared': 5, 'momentum': 0.07576561909160946}. Best is trial 23 with value: 0.5507968664169312.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 18.5525 | val_0_mse: 2155.16162109375|  0:00:00s\n","epoch 1  | loss: 7.18659 | val_0_mse: 1298.400390625|  0:00:00s\n","epoch 2  | loss: 3.62946 | val_0_mse: 280.9597473144531|  0:00:01s\n","epoch 3  | loss: 2.2145  | val_0_mse: 27.133310317993164|  0:00:01s\n","epoch 4  | loss: 1.63211 | val_0_mse: 32.776641845703125|  0:00:02s\n","epoch 5  | loss: 1.18138 | val_0_mse: 26.188060760498047|  0:00:02s\n","epoch 6  | loss: 0.96949 | val_0_mse: 28.80493927001953|  0:00:03s\n","epoch 7  | loss: 0.92209 | val_0_mse: 56.063621520996094|  0:00:03s\n","epoch 8  | loss: 0.7973  | val_0_mse: 126.10186004638672|  0:00:04s\n","epoch 9  | loss: 0.71425 | val_0_mse: 106.77438354492188|  0:00:04s\n","epoch 10 | loss: 0.70692 | val_0_mse: 84.89835357666016|  0:00:05s\n","epoch 11 | loss: 0.66106 | val_0_mse: 24.225439071655273|  0:00:05s\n","epoch 12 | loss: 0.66315 | val_0_mse: 11.787199974060059|  0:00:06s\n","epoch 13 | loss: 0.64181 | val_0_mse: 4.786570072174072|  0:00:06s\n","epoch 14 | loss: 0.66969 | val_0_mse: 7.268509864807129|  0:00:07s\n","epoch 15 | loss: 0.78866 | val_0_mse: 3.988879919052124|  0:00:07s\n","epoch 16 | loss: 0.75119 | val_0_mse: 4.527400016784668|  0:00:08s\n","epoch 17 | loss: 0.64391 | val_0_mse: 4.202980041503906|  0:00:08s\n","epoch 18 | loss: 0.62913 | val_0_mse: 6.639780044555664|  0:00:09s\n","epoch 19 | loss: 0.61867 | val_0_mse: 3.342180013656616|  0:00:09s\n","epoch 20 | loss: 0.67936 | val_0_mse: 2.2686500549316406|  0:00:10s\n","epoch 21 | loss: 0.66741 | val_0_mse: 2.285099983215332|  0:00:10s\n","epoch 22 | loss: 0.77751 | val_0_mse: 2.2543399333953857|  0:00:11s\n","epoch 23 | loss: 0.66927 | val_0_mse: 1.3489999771118164|  0:00:11s\n","epoch 24 | loss: 0.63966 | val_0_mse: 2.4130001068115234|  0:00:12s\n","epoch 25 | loss: 0.59045 | val_0_mse: 1.3195099830627441|  0:00:12s\n","epoch 26 | loss: 0.58361 | val_0_mse: 1.6005300283432007|  0:00:13s\n","epoch 27 | loss: 0.57002 | val_0_mse: 1.8846800327301025|  0:00:13s\n","epoch 28 | loss: 0.57002 | val_0_mse: 1.2101800441741943|  0:00:14s\n","epoch 29 | loss: 0.55715 | val_0_mse: 1.5125999450683594|  0:00:14s\n","epoch 30 | loss: 0.55867 | val_0_mse: 1.2462899684906006|  0:00:14s\n","epoch 31 | loss: 0.56299 | val_0_mse: 1.0984400510787964|  0:00:15s\n","epoch 32 | loss: 0.54859 | val_0_mse: 1.987779974937439|  0:00:15s\n","epoch 33 | loss: 0.55593 | val_0_mse: 1.2505899667739868|  0:00:16s\n","epoch 34 | loss: 0.55474 | val_0_mse: 1.5580899715423584|  0:00:16s\n","epoch 35 | loss: 0.56963 | val_0_mse: 1.1649500131607056|  0:00:17s\n","epoch 36 | loss: 0.57477 | val_0_mse: 1.1805299520492554|  0:00:17s\n","epoch 37 | loss: 0.54289 | val_0_mse: 1.2196999788284302|  0:00:18s\n","epoch 38 | loss: 0.56913 | val_0_mse: 1.0013699531555176|  0:00:18s\n","epoch 39 | loss: 0.52583 | val_0_mse: 1.3161100149154663|  0:00:19s\n","epoch 40 | loss: 0.52575 | val_0_mse: 0.7741600275039673|  0:00:19s\n","epoch 41 | loss: 0.5571  | val_0_mse: 0.937720000743866|  0:00:20s\n","epoch 42 | loss: 0.55161 | val_0_mse: 0.748520016670227|  0:00:20s\n","epoch 43 | loss: 0.51694 | val_0_mse: 0.9199000000953674|  0:00:21s\n","epoch 44 | loss: 0.49546 | val_0_mse: 0.8466399908065796|  0:00:21s\n","epoch 45 | loss: 0.50622 | val_0_mse: 0.8900799751281738|  0:00:22s\n","epoch 46 | loss: 0.49827 | val_0_mse: 0.8856599926948547|  0:00:22s\n","epoch 47 | loss: 0.51473 | val_0_mse: 0.8344299793243408|  0:00:23s\n","epoch 48 | loss: 0.52289 | val_0_mse: 0.8760899901390076|  0:00:23s\n","epoch 49 | loss: 0.51358 | val_0_mse: 0.6788899898529053|  0:00:23s\n","epoch 50 | loss: 0.5281  | val_0_mse: 0.7079899907112122|  0:00:24s\n","epoch 51 | loss: 0.49656 | val_0_mse: 0.6565799713134766|  0:00:24s\n","epoch 52 | loss: 0.51584 | val_0_mse: 0.6493899822235107|  0:00:25s\n","epoch 53 | loss: 0.51437 | val_0_mse: 0.6960099935531616|  0:00:25s\n","epoch 54 | loss: 0.51351 | val_0_mse: 0.695580005645752|  0:00:26s\n","epoch 55 | loss: 0.50643 | val_0_mse: 0.636680006980896|  0:00:26s\n","epoch 56 | loss: 0.52371 | val_0_mse: 0.7722600102424622|  0:00:27s\n","epoch 57 | loss: 0.52625 | val_0_mse: 0.6436799764633179|  0:00:27s\n","epoch 58 | loss: 0.53248 | val_0_mse: 0.7669900059700012|  0:00:28s\n","epoch 59 | loss: 0.50825 | val_0_mse: 0.6856899857521057|  0:00:28s\n","epoch 60 | loss: 0.51294 | val_0_mse: 0.641700029373169|  0:00:29s\n","epoch 61 | loss: 0.51712 | val_0_mse: 0.6122199892997742|  0:00:29s\n","epoch 62 | loss: 0.51127 | val_0_mse: 0.6035199761390686|  0:00:30s\n","epoch 63 | loss: 0.51275 | val_0_mse: 0.6007000207901001|  0:00:30s\n","epoch 64 | loss: 0.50268 | val_0_mse: 0.6083999872207642|  0:00:31s\n","epoch 65 | loss: 0.50484 | val_0_mse: 0.5880299806594849|  0:00:31s\n","epoch 66 | loss: 0.493   | val_0_mse: 0.5811100006103516|  0:00:32s\n","epoch 67 | loss: 0.51093 | val_0_mse: 0.5765100121498108|  0:00:32s\n","epoch 68 | loss: 0.50075 | val_0_mse: 0.5886600017547607|  0:00:33s\n","epoch 69 | loss: 0.48942 | val_0_mse: 0.5871099829673767|  0:00:33s\n","epoch 70 | loss: 0.49355 | val_0_mse: 0.5849400162696838|  0:00:34s\n","epoch 71 | loss: 0.49027 | val_0_mse: 0.5785599946975708|  0:00:34s\n","epoch 72 | loss: 0.49662 | val_0_mse: 0.5672699809074402|  0:00:35s\n","epoch 73 | loss: 0.48748 | val_0_mse: 0.579800009727478|  0:00:35s\n","epoch 74 | loss: 0.47493 | val_0_mse: 0.5680800080299377|  0:00:36s\n","epoch 75 | loss: 0.48303 | val_0_mse: 0.57955002784729|  0:00:36s\n","epoch 76 | loss: 0.48324 | val_0_mse: 0.5818899869918823|  0:00:37s\n","epoch 77 | loss: 0.48295 | val_0_mse: 0.5950400233268738|  0:00:37s\n","epoch 78 | loss: 0.48594 | val_0_mse: 0.5737900137901306|  0:00:38s\n","epoch 79 | loss: 0.47155 | val_0_mse: 0.5898100137710571|  0:00:38s\n","epoch 80 | loss: 0.476   | val_0_mse: 0.6167200207710266|  0:00:38s\n","epoch 81 | loss: 0.4869  | val_0_mse: 0.5883600115776062|  0:00:39s\n","epoch 82 | loss: 0.49972 | val_0_mse: 0.6289700269699097|  0:00:39s\n","\n","Early stopping occurred at epoch 82 with best_epoch = 72 and best_val_0_mse = 0.5672699809074402\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 16:10:23,310] Trial 30 finished with value: 0.5672705173492432 and parameters: {'n_d': 8, 'n_steps': 7, 'gamma': 1.0096722088497703, 'n_independent': 2, 'n_shared': 4, 'momentum': 0.010740476625355058}. Best is trial 23 with value: 0.5507968664169312.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 19.17937| val_0_mse: 642.2449951171875|  0:00:00s\n","epoch 1  | loss: 8.06062 | val_0_mse: 527.076171875|  0:00:00s\n","epoch 2  | loss: 3.94229 | val_0_mse: 114.17875671386719|  0:00:01s\n","epoch 3  | loss: 1.93573 | val_0_mse: 42.712059020996094|  0:00:01s\n","epoch 4  | loss: 1.43464 | val_0_mse: 72.14781951904297|  0:00:02s\n","epoch 5  | loss: 1.15741 | val_0_mse: 81.04329681396484|  0:00:02s\n","epoch 6  | loss: 0.90611 | val_0_mse: 36.97230911254883|  0:00:03s\n","epoch 7  | loss: 0.8063  | val_0_mse: 6.276869773864746|  0:00:03s\n","epoch 8  | loss: 0.79054 | val_0_mse: 13.979599952697754|  0:00:04s\n","epoch 9  | loss: 0.71539 | val_0_mse: 11.934889793395996|  0:00:04s\n","epoch 10 | loss: 0.71638 | val_0_mse: 7.542029857635498|  0:00:05s\n","epoch 11 | loss: 0.69341 | val_0_mse: 5.641910076141357|  0:00:05s\n","epoch 12 | loss: 0.64502 | val_0_mse: 3.4056599140167236|  0:00:06s\n","epoch 13 | loss: 0.64576 | val_0_mse: 2.319380044937134|  0:00:06s\n","epoch 14 | loss: 0.64041 | val_0_mse: 1.473960041999817|  0:00:07s\n","epoch 15 | loss: 0.62122 | val_0_mse: 1.5324000120162964|  0:00:07s\n","epoch 16 | loss: 0.6078  | val_0_mse: 1.6806800365447998|  0:00:08s\n","epoch 17 | loss: 0.59485 | val_0_mse: 3.2379798889160156|  0:00:08s\n","epoch 18 | loss: 0.5982  | val_0_mse: 1.9114999771118164|  0:00:09s\n","epoch 19 | loss: 0.58969 | val_0_mse: 1.5043200254440308|  0:00:09s\n","epoch 20 | loss: 0.59267 | val_0_mse: 1.4648100137710571|  0:00:10s\n","epoch 21 | loss: 0.58556 | val_0_mse: 2.3785300254821777|  0:00:10s\n","epoch 22 | loss: 0.58165 | val_0_mse: 2.2411999702453613|  0:00:10s\n","epoch 23 | loss: 0.57655 | val_0_mse: 1.6313600540161133|  0:00:11s\n","epoch 24 | loss: 0.56616 | val_0_mse: 2.7257800102233887|  0:00:11s\n","epoch 25 | loss: 0.5586  | val_0_mse: 2.5153300762176514|  0:00:12s\n","epoch 26 | loss: 0.57837 | val_0_mse: 3.4546499252319336|  0:00:12s\n","epoch 27 | loss: 0.57863 | val_0_mse: 1.8826299905776978|  0:00:13s\n","epoch 28 | loss: 0.53584 | val_0_mse: 1.6560399532318115|  0:00:13s\n","epoch 29 | loss: 0.53526 | val_0_mse: 1.8703500032424927|  0:00:14s\n","epoch 30 | loss: 0.52968 | val_0_mse: 1.6209100484848022|  0:00:14s\n","\n","Early stopping occurred at epoch 30 with best_epoch = 20 and best_val_0_mse = 1.4648100137710571\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 16:10:38,411] Trial 31 finished with value: 1.4648140668869019 and parameters: {'n_d': 8, 'n_steps': 7, 'gamma': 1.0106904619050339, 'n_independent': 2, 'n_shared': 4, 'momentum': 0.02311764167567619}. Best is trial 23 with value: 0.5507968664169312.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 21.22863| val_0_mse: 382.51123046875|  0:00:00s\n","epoch 1  | loss: 6.57136 | val_0_mse: 526.2479248046875|  0:00:01s\n","epoch 2  | loss: 3.51505 | val_0_mse: 272.73919677734375|  0:00:01s\n","epoch 3  | loss: 2.41349 | val_0_mse: 125.97180938720703|  0:00:02s\n","epoch 4  | loss: 1.48804 | val_0_mse: 43.2234992980957|  0:00:02s\n","epoch 5  | loss: 1.26539 | val_0_mse: 49.60776138305664|  0:00:03s\n","epoch 6  | loss: 1.07335 | val_0_mse: 26.985519409179688|  0:00:03s\n","epoch 7  | loss: 0.91809 | val_0_mse: 25.297019958496094|  0:00:04s\n","epoch 8  | loss: 0.84903 | val_0_mse: 33.188140869140625|  0:00:04s\n","epoch 9  | loss: 0.7954  | val_0_mse: 21.902929306030273|  0:00:05s\n","epoch 10 | loss: 0.74678 | val_0_mse: 17.93828010559082|  0:00:05s\n","epoch 11 | loss: 0.71439 | val_0_mse: 11.411529541015625|  0:00:06s\n","epoch 12 | loss: 0.70224 | val_0_mse: 6.195710182189941|  0:00:06s\n","epoch 13 | loss: 0.85895 | val_0_mse: 14.217960357666016|  0:00:07s\n","epoch 14 | loss: 0.73931 | val_0_mse: 7.5761799812316895|  0:00:07s\n","epoch 15 | loss: 0.63197 | val_0_mse: 4.940390110015869|  0:00:08s\n","epoch 16 | loss: 0.63146 | val_0_mse: 3.9288899898529053|  0:00:09s\n","epoch 17 | loss: 0.62616 | val_0_mse: 3.386159896850586|  0:00:09s\n","epoch 18 | loss: 0.641   | val_0_mse: 2.8731799125671387|  0:00:10s\n","epoch 19 | loss: 0.61621 | val_0_mse: 4.0001301765441895|  0:00:10s\n","epoch 20 | loss: 0.58087 | val_0_mse: 2.828160047531128|  0:00:11s\n","epoch 21 | loss: 0.56499 | val_0_mse: 2.0367000102996826|  0:00:11s\n","epoch 22 | loss: 0.57665 | val_0_mse: 1.8612600564956665|  0:00:12s\n","epoch 23 | loss: 0.57645 | val_0_mse: 1.97461998462677|  0:00:12s\n","epoch 24 | loss: 0.58509 | val_0_mse: 1.7221499681472778|  0:00:13s\n","epoch 25 | loss: 0.5915  | val_0_mse: 1.254580020904541|  0:00:13s\n","epoch 26 | loss: 0.5941  | val_0_mse: 1.352329969406128|  0:00:14s\n","epoch 27 | loss: 0.5971  | val_0_mse: 1.2327799797058105|  0:00:14s\n","epoch 28 | loss: 0.61632 | val_0_mse: 1.606119990348816|  0:00:15s\n","epoch 29 | loss: 0.57458 | val_0_mse: 1.8046300411224365|  0:00:15s\n","epoch 30 | loss: 0.55331 | val_0_mse: 1.5843900442123413|  0:00:16s\n","epoch 31 | loss: 0.54116 | val_0_mse: 1.444290041923523|  0:00:16s\n","epoch 32 | loss: 0.53365 | val_0_mse: 1.6828099489212036|  0:00:17s\n","epoch 33 | loss: 0.53312 | val_0_mse: 1.630210041999817|  0:00:17s\n","epoch 34 | loss: 0.53886 | val_0_mse: 1.255329966545105|  0:00:18s\n","epoch 35 | loss: 0.53185 | val_0_mse: 1.2325600385665894|  0:00:18s\n","epoch 36 | loss: 0.54773 | val_0_mse: 1.2758500576019287|  0:00:19s\n","epoch 37 | loss: 0.55781 | val_0_mse: 1.4211100339889526|  0:00:19s\n","epoch 38 | loss: 0.5706  | val_0_mse: 0.7718300223350525|  0:00:20s\n","epoch 39 | loss: 0.57316 | val_0_mse: 1.3807100057601929|  0:00:21s\n","epoch 40 | loss: 0.60121 | val_0_mse: 0.7445499897003174|  0:00:21s\n","epoch 41 | loss: 0.61529 | val_0_mse: 1.7130299806594849|  0:00:22s\n","epoch 42 | loss: 0.59654 | val_0_mse: 0.837090015411377|  0:00:22s\n","epoch 43 | loss: 0.56471 | val_0_mse: 1.2998600006103516|  0:00:23s\n","epoch 44 | loss: 0.53668 | val_0_mse: 1.01705002784729|  0:00:23s\n","epoch 45 | loss: 0.53608 | val_0_mse: 0.7781299948692322|  0:00:24s\n","epoch 46 | loss: 0.51654 | val_0_mse: 0.8153899908065796|  0:00:24s\n","epoch 47 | loss: 0.51502 | val_0_mse: 0.859969973564148|  0:00:25s\n","epoch 48 | loss: 0.52898 | val_0_mse: 0.7373999953269958|  0:00:25s\n","epoch 49 | loss: 0.51173 | val_0_mse: 0.6688500046730042|  0:00:26s\n","epoch 50 | loss: 0.51284 | val_0_mse: 0.7063199877738953|  0:00:26s\n","epoch 51 | loss: 0.51203 | val_0_mse: 0.735260009765625|  0:00:27s\n","epoch 52 | loss: 0.51553 | val_0_mse: 0.7016900181770325|  0:00:27s\n","epoch 53 | loss: 0.5169  | val_0_mse: 0.6866000294685364|  0:00:28s\n","epoch 54 | loss: 0.52436 | val_0_mse: 0.7518600225448608|  0:00:28s\n","epoch 55 | loss: 0.5297  | val_0_mse: 0.8133800029754639|  0:00:29s\n","epoch 56 | loss: 0.53348 | val_0_mse: 0.8176000118255615|  0:00:29s\n","epoch 57 | loss: 0.53028 | val_0_mse: 0.6798999905586243|  0:00:30s\n","epoch 58 | loss: 0.53037 | val_0_mse: 0.8857899904251099|  0:00:30s\n","epoch 59 | loss: 0.51732 | val_0_mse: 0.6628599762916565|  0:00:31s\n","epoch 60 | loss: 0.53028 | val_0_mse: 0.6526600122451782|  0:00:31s\n","epoch 61 | loss: 0.50318 | val_0_mse: 0.6980800032615662|  0:00:32s\n","epoch 62 | loss: 0.50784 | val_0_mse: 0.6363099813461304|  0:00:32s\n","epoch 63 | loss: 0.48908 | val_0_mse: 0.6643000245094299|  0:00:33s\n","epoch 64 | loss: 0.50555 | val_0_mse: 0.6623799800872803|  0:00:33s\n","epoch 65 | loss: 0.5141  | val_0_mse: 0.5928699970245361|  0:00:34s\n","epoch 66 | loss: 0.53773 | val_0_mse: 0.6693599820137024|  0:00:34s\n","epoch 67 | loss: 0.50895 | val_0_mse: 0.6079800128936768|  0:00:35s\n","epoch 68 | loss: 0.54956 | val_0_mse: 0.6947100162506104|  0:00:35s\n","epoch 69 | loss: 0.55253 | val_0_mse: 0.7210500240325928|  0:00:36s\n","epoch 70 | loss: 0.64039 | val_0_mse: 0.7458599805831909|  0:00:36s\n","epoch 71 | loss: 0.65845 | val_0_mse: 0.6870599985122681|  0:00:37s\n","epoch 72 | loss: 0.53897 | val_0_mse: 0.590470016002655|  0:00:37s\n","epoch 73 | loss: 0.52435 | val_0_mse: 0.7225300073623657|  0:00:38s\n","epoch 74 | loss: 0.52451 | val_0_mse: 0.5990399718284607|  0:00:39s\n","epoch 75 | loss: 0.49756 | val_0_mse: 0.5836799740791321|  0:00:39s\n","epoch 76 | loss: 0.51212 | val_0_mse: 0.6702200174331665|  0:00:40s\n","epoch 77 | loss: 0.54443 | val_0_mse: 0.6198499798774719|  0:00:40s\n","epoch 78 | loss: 0.49818 | val_0_mse: 0.6655600070953369|  0:00:41s\n","epoch 79 | loss: 0.54309 | val_0_mse: 0.5732499957084656|  0:00:41s\n","epoch 80 | loss: 0.50146 | val_0_mse: 0.623740017414093|  0:00:42s\n","epoch 81 | loss: 0.49864 | val_0_mse: 0.603190004825592|  0:00:42s\n","epoch 82 | loss: 0.49547 | val_0_mse: 0.5747100114822388|  0:00:43s\n","epoch 83 | loss: 0.49087 | val_0_mse: 0.5821400284767151|  0:00:43s\n","epoch 84 | loss: 0.4912  | val_0_mse: 0.594510018825531|  0:00:44s\n","epoch 85 | loss: 0.48629 | val_0_mse: 0.5872399806976318|  0:00:44s\n","epoch 86 | loss: 0.50479 | val_0_mse: 0.6250200271606445|  0:00:45s\n","epoch 87 | loss: 0.49062 | val_0_mse: 0.6132699847221375|  0:00:45s\n","epoch 88 | loss: 0.49231 | val_0_mse: 0.6066499948501587|  0:00:46s\n","epoch 89 | loss: 0.48362 | val_0_mse: 0.6034600138664246|  0:00:46s\n","\n","Early stopping occurred at epoch 89 with best_epoch = 79 and best_val_0_mse = 0.5732499957084656\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 16:11:25,483] Trial 32 finished with value: 0.5732516646385193 and parameters: {'n_d': 11, 'n_steps': 9, 'gamma': 1.1154018593374686, 'n_independent': 2, 'n_shared': 3, 'momentum': 0.04847965698488965}. Best is trial 23 with value: 0.5507968664169312.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 38.03433| val_0_mse: 453.9339294433594|  0:00:00s\n","epoch 1  | loss: 12.3557 | val_0_mse: 716.8282470703125|  0:00:00s\n","epoch 2  | loss: 6.28764 | val_0_mse: 213.96719360351562|  0:00:01s\n","epoch 3  | loss: 2.79307 | val_0_mse: 29.95149040222168|  0:00:01s\n","epoch 4  | loss: 1.3955  | val_0_mse: 8.694669723510742|  0:00:01s\n","epoch 5  | loss: 0.92775 | val_0_mse: 4.699729919433594|  0:00:02s\n","epoch 6  | loss: 0.76559 | val_0_mse: 3.068229913711548|  0:00:02s\n","epoch 7  | loss: 0.73498 | val_0_mse: 3.291379928588867|  0:00:03s\n","epoch 8  | loss: 0.67686 | val_0_mse: 2.446739912033081|  0:00:03s\n","epoch 9  | loss: 0.65261 | val_0_mse: 1.8228700160980225|  0:00:03s\n","epoch 10 | loss: 0.61808 | val_0_mse: 5.064929962158203|  0:00:04s\n","epoch 11 | loss: 0.60553 | val_0_mse: 3.416800022125244|  0:00:04s\n","epoch 12 | loss: 0.62318 | val_0_mse: 2.430039882659912|  0:00:04s\n","epoch 13 | loss: 0.60671 | val_0_mse: 2.377310037612915|  0:00:05s\n","epoch 14 | loss: 0.57831 | val_0_mse: 3.25462007522583|  0:00:05s\n","epoch 15 | loss: 0.58435 | val_0_mse: 3.7947399616241455|  0:00:05s\n","epoch 16 | loss: 0.54866 | val_0_mse: 3.4708499908447266|  0:00:06s\n","epoch 17 | loss: 0.54223 | val_0_mse: 4.305830001831055|  0:00:06s\n","epoch 18 | loss: 0.53584 | val_0_mse: 3.013580083847046|  0:00:07s\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 16:11:33,110] Trial 33 finished with value: 1.822874903678894 and parameters: {'n_d': 13, 'n_steps': 6, 'gamma': 1.0671246337629319, 'n_independent': 2, 'n_shared': 3, 'momentum': 0.010648169744982866}. Best is trial 23 with value: 0.5507968664169312.\n"]},{"output_type":"stream","name":"stdout","text":["epoch 19 | loss: 0.54264 | val_0_mse: 1.9756300449371338|  0:00:07s\n","\n","Early stopping occurred at epoch 19 with best_epoch = 9 and best_val_0_mse = 1.8228700160980225\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 10.58577| val_0_mse: 1842.2249755859375|  0:00:00s\n","epoch 1  | loss: 5.27308 | val_0_mse: 467.22442626953125|  0:00:00s\n","epoch 2  | loss: 2.65939 | val_0_mse: 206.8019256591797|  0:00:01s\n","epoch 3  | loss: 1.75695 | val_0_mse: 84.35395050048828|  0:00:01s\n","epoch 4  | loss: 1.29119 | val_0_mse: 152.26321411132812|  0:00:02s\n","epoch 5  | loss: 1.12204 | val_0_mse: 90.3979721069336|  0:00:02s\n","epoch 6  | loss: 0.95789 | val_0_mse: 51.63032150268555|  0:00:03s\n","epoch 7  | loss: 0.8289  | val_0_mse: 35.653560638427734|  0:00:03s\n","epoch 8  | loss: 0.83296 | val_0_mse: 72.09831237792969|  0:00:04s\n","epoch 9  | loss: 0.72456 | val_0_mse: 68.65422058105469|  0:00:04s\n","epoch 10 | loss: 0.6796  | val_0_mse: 33.49589920043945|  0:00:05s\n","epoch 11 | loss: 0.66093 | val_0_mse: 4.709199905395508|  0:00:05s\n","epoch 12 | loss: 0.63322 | val_0_mse: 2.5216000080108643|  0:00:06s\n","epoch 13 | loss: 0.64701 | val_0_mse: 1.3652700185775757|  0:00:06s\n","epoch 14 | loss: 0.69671 | val_0_mse: 4.26501989364624|  0:00:07s\n","epoch 15 | loss: 0.68582 | val_0_mse: 3.510240077972412|  0:00:07s\n","epoch 16 | loss: 0.62349 | val_0_mse: 4.891960144042969|  0:00:08s\n","epoch 17 | loss: 0.61162 | val_0_mse: 8.622949600219727|  0:00:08s\n","epoch 18 | loss: 0.59573 | val_0_mse: 8.698309898376465|  0:00:09s\n","epoch 19 | loss: 0.5955  | val_0_mse: 8.710610389709473|  0:00:09s\n","epoch 20 | loss: 0.60793 | val_0_mse: 4.464260101318359|  0:00:10s\n","epoch 21 | loss: 0.63516 | val_0_mse: 2.1060400009155273|  0:00:10s\n","epoch 22 | loss: 0.65117 | val_0_mse: 4.917490005493164|  0:00:10s\n","epoch 23 | loss: 0.61564 | val_0_mse: 2.482330083847046|  0:00:11s\n","\n","Early stopping occurred at epoch 23 with best_epoch = 13 and best_val_0_mse = 1.3652700185775757\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 16:11:44,970] Trial 34 finished with value: 1.365273356437683 and parameters: {'n_d': 11, 'n_steps': 7, 'gamma': 1.0838090301714558, 'n_independent': 3, 'n_shared': 3, 'momentum': 0.04911075517418542}. Best is trial 23 with value: 0.5507968664169312.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 24.31006| val_0_mse: 2865.69482421875|  0:00:00s\n","epoch 1  | loss: 4.98656 | val_0_mse: 276.14422607421875|  0:00:00s\n","epoch 2  | loss: 1.89729 | val_0_mse: 71.39498901367188|  0:00:01s\n","epoch 3  | loss: 1.1363  | val_0_mse: 23.20092010498047|  0:00:01s\n","epoch 4  | loss: 0.91712 | val_0_mse: 16.401039123535156|  0:00:02s\n","epoch 5  | loss: 0.74799 | val_0_mse: 14.52793025970459|  0:00:02s\n","epoch 6  | loss: 0.72783 | val_0_mse: 17.868040084838867|  0:00:02s\n","epoch 7  | loss: 0.68313 | val_0_mse: 20.408950805664062|  0:00:03s\n","epoch 8  | loss: 0.68912 | val_0_mse: 21.715740203857422|  0:00:03s\n","epoch 9  | loss: 0.65905 | val_0_mse: 14.907819747924805|  0:00:04s\n","epoch 10 | loss: 0.64302 | val_0_mse: 12.946060180664062|  0:00:04s\n","epoch 11 | loss: 0.64402 | val_0_mse: 9.35735034942627|  0:00:04s\n","epoch 12 | loss: 0.62697 | val_0_mse: 2.0171000957489014|  0:00:05s\n","epoch 13 | loss: 0.64148 | val_0_mse: 2.052299976348877|  0:00:05s\n","epoch 14 | loss: 0.61523 | val_0_mse: 1.4152699708938599|  0:00:06s\n","epoch 15 | loss: 0.60976 | val_0_mse: 1.0155099630355835|  0:00:06s\n","epoch 16 | loss: 0.57942 | val_0_mse: 1.0820499658584595|  0:00:07s\n","epoch 17 | loss: 0.57708 | val_0_mse: 0.9849799871444702|  0:00:07s\n","epoch 18 | loss: 0.56048 | val_0_mse: 1.088070034980774|  0:00:07s\n","epoch 19 | loss: 0.57915 | val_0_mse: 1.7258299589157104|  0:00:08s\n","epoch 20 | loss: 0.59318 | val_0_mse: 2.0408599376678467|  0:00:08s\n","epoch 21 | loss: 0.55813 | val_0_mse: 1.4581199884414673|  0:00:09s\n","epoch 22 | loss: 0.57094 | val_0_mse: 1.4715299606323242|  0:00:09s\n","epoch 23 | loss: 0.55457 | val_0_mse: 1.7486499547958374|  0:00:09s\n","epoch 24 | loss: 0.54712 | val_0_mse: 2.1165199279785156|  0:00:10s\n","epoch 25 | loss: 0.54088 | val_0_mse: 2.2947800159454346|  0:00:10s\n","epoch 26 | loss: 0.52894 | val_0_mse: 1.6045500040054321|  0:00:11s\n","epoch 27 | loss: 0.54277 | val_0_mse: 1.236240029335022|  0:00:11s\n","\n","Early stopping occurred at epoch 27 with best_epoch = 17 and best_val_0_mse = 0.9849799871444702\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 16:11:56,685] Trial 35 finished with value: 0.9849761724472046 and parameters: {'n_d': 17, 'n_steps': 5, 'gamma': 1.1795510553158641, 'n_independent': 3, 'n_shared': 4, 'momentum': 0.042407860205305084}. Best is trial 23 with value: 0.5507968664169312.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 18.80386| val_0_mse: 261.2957763671875|  0:00:00s\n","epoch 1  | loss: 5.41242 | val_0_mse: 398.7602844238281|  0:00:00s\n","epoch 2  | loss: 3.55243 | val_0_mse: 105.92404174804688|  0:00:01s\n","epoch 3  | loss: 5.41084 | val_0_mse: 213.94337463378906|  0:00:01s\n","epoch 4  | loss: 4.83858 | val_0_mse: 95.22821044921875|  0:00:02s\n","epoch 5  | loss: 2.77349 | val_0_mse: 55.686241149902344|  0:00:02s\n","epoch 6  | loss: 1.69425 | val_0_mse: 59.359901428222656|  0:00:03s\n","epoch 7  | loss: 1.4573  | val_0_mse: 22.31756019592285|  0:00:03s\n","epoch 8  | loss: 1.64383 | val_0_mse: 37.45138168334961|  0:00:04s\n","epoch 9  | loss: 1.25305 | val_0_mse: 14.487919807434082|  0:00:04s\n","epoch 10 | loss: 1.50448 | val_0_mse: 4.6841301918029785|  0:00:05s\n","epoch 11 | loss: 1.28966 | val_0_mse: 14.669899940490723|  0:00:05s\n","epoch 12 | loss: 1.30645 | val_0_mse: 8.868760108947754|  0:00:06s\n","epoch 13 | loss: 1.38178 | val_0_mse: 2.4632699489593506|  0:00:06s\n","epoch 14 | loss: 1.38468 | val_0_mse: 2.176069974899292|  0:00:07s\n","epoch 15 | loss: 1.13279 | val_0_mse: 6.575399875640869|  0:00:07s\n","epoch 16 | loss: 1.06162 | val_0_mse: 3.765470027923584|  0:00:08s\n","epoch 17 | loss: 0.96273 | val_0_mse: 4.568439960479736|  0:00:08s\n","epoch 18 | loss: 0.84083 | val_0_mse: 4.590660095214844|  0:00:08s\n","epoch 19 | loss: 1.00188 | val_0_mse: 1.8049800395965576|  0:00:09s\n","epoch 20 | loss: 0.7495  | val_0_mse: 1.4950200319290161|  0:00:09s\n","epoch 21 | loss: 0.69465 | val_0_mse: 0.9723100066184998|  0:00:10s\n","epoch 22 | loss: 0.71386 | val_0_mse: 1.072700023651123|  0:00:10s\n","epoch 23 | loss: 0.77899 | val_0_mse: 1.5832099914550781|  0:00:11s\n","epoch 24 | loss: 0.87487 | val_0_mse: 2.9644699096679688|  0:00:11s\n","epoch 25 | loss: 0.85263 | val_0_mse: 2.2850399017333984|  0:00:12s\n","epoch 26 | loss: 0.86537 | val_0_mse: 0.9625399708747864|  0:00:12s\n","epoch 27 | loss: 0.96445 | val_0_mse: 1.022760033607483|  0:00:13s\n","epoch 28 | loss: 0.78528 | val_0_mse: 1.067770004272461|  0:00:13s\n","epoch 29 | loss: 0.66502 | val_0_mse: 1.1632399559020996|  0:00:14s\n","epoch 30 | loss: 0.67524 | val_0_mse: 0.9433900117874146|  0:00:14s\n","epoch 31 | loss: 0.64749 | val_0_mse: 1.3273600339889526|  0:00:15s\n","epoch 32 | loss: 0.70426 | val_0_mse: 1.7858200073242188|  0:00:15s\n","epoch 33 | loss: 0.7712  | val_0_mse: 1.6923199892044067|  0:00:16s\n","epoch 34 | loss: 0.86561 | val_0_mse: 1.330430030822754|  0:00:16s\n","epoch 35 | loss: 0.61595 | val_0_mse: 1.8845200538635254|  0:00:17s\n","epoch 36 | loss: 0.59778 | val_0_mse: 1.1800299882888794|  0:00:17s\n","epoch 37 | loss: 0.65229 | val_0_mse: 1.2046899795532227|  0:00:18s\n","epoch 38 | loss: 0.5991  | val_0_mse: 1.155019998550415|  0:00:18s\n","epoch 39 | loss: 0.57917 | val_0_mse: 1.0652600526809692|  0:00:19s\n","epoch 40 | loss: 0.6013  | val_0_mse: 1.092710018157959|  0:00:19s\n","\n","Early stopping occurred at epoch 40 with best_epoch = 30 and best_val_0_mse = 0.9433900117874146\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 16:12:16,474] Trial 36 finished with value: 0.9433944225311279 and parameters: {'n_d': 60, 'n_steps': 8, 'gamma': 1.2511174996007277, 'n_independent': 2, 'n_shared': 3, 'momentum': 0.1354490629449131}. Best is trial 23 with value: 0.5507968664169312.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 35.40433| val_0_mse: 130.77346801757812|  0:00:00s\n","epoch 1  | loss: 13.70491| val_0_mse: 753.2479248046875|  0:00:00s\n","epoch 2  | loss: 4.60026 | val_0_mse: 880.8449096679688|  0:00:00s\n","epoch 3  | loss: 1.82262 | val_0_mse: 217.31544494628906|  0:00:00s\n","epoch 4  | loss: 1.38211 | val_0_mse: 37.786441802978516|  0:00:01s\n","epoch 5  | loss: 0.87069 | val_0_mse: 12.175559997558594|  0:00:01s\n","epoch 6  | loss: 0.71336 | val_0_mse: 2.207119941711426|  0:00:01s\n","epoch 7  | loss: 0.66382 | val_0_mse: 2.6213200092315674|  0:00:01s\n","epoch 8  | loss: 0.64336 | val_0_mse: 2.0996100902557373|  0:00:02s\n","epoch 9  | loss: 0.60732 | val_0_mse: 4.555890083312988|  0:00:02s\n","epoch 10 | loss: 0.57483 | val_0_mse: 1.8172800540924072|  0:00:02s\n","epoch 11 | loss: 0.58034 | val_0_mse: 1.9266400337219238|  0:00:02s\n","epoch 12 | loss: 0.56461 | val_0_mse: 1.8886300325393677|  0:00:02s\n","epoch 13 | loss: 0.54916 | val_0_mse: 1.8575999736785889|  0:00:03s\n","epoch 14 | loss: 0.54267 | val_0_mse: 1.8927700519561768|  0:00:03s\n","epoch 15 | loss: 0.53352 | val_0_mse: 2.197809934616089|  0:00:03s\n","epoch 16 | loss: 0.53274 | val_0_mse: 2.0037100315093994|  0:00:03s\n","epoch 17 | loss: 0.51953 | val_0_mse: 1.8028099536895752|  0:00:04s\n","epoch 18 | loss: 0.50976 | val_0_mse: 2.727950096130371|  0:00:04s\n","epoch 19 | loss: 0.52593 | val_0_mse: 2.2750799655914307|  0:00:04s\n","epoch 20 | loss: 0.52006 | val_0_mse: 1.902400016784668|  0:00:04s\n","epoch 21 | loss: 0.50375 | val_0_mse: 1.7898000478744507|  0:00:05s\n","epoch 22 | loss: 0.50582 | val_0_mse: 1.6603699922561646|  0:00:05s\n","epoch 23 | loss: 0.50128 | val_0_mse: 1.8550200462341309|  0:00:05s\n","epoch 24 | loss: 0.4925  | val_0_mse: 1.6645699739456177|  0:00:05s\n","epoch 25 | loss: 0.50622 | val_0_mse: 1.4129600524902344|  0:00:05s\n","epoch 26 | loss: 0.49088 | val_0_mse: 1.618749976158142|  0:00:06s\n","epoch 27 | loss: 0.4839  | val_0_mse: 1.4852800369262695|  0:00:06s\n","epoch 28 | loss: 0.48204 | val_0_mse: 1.3375699520111084|  0:00:06s\n","epoch 29 | loss: 0.48939 | val_0_mse: 1.4654799699783325|  0:00:06s\n","epoch 30 | loss: 0.48208 | val_0_mse: 1.1591700315475464|  0:00:07s\n","epoch 31 | loss: 0.4974  | val_0_mse: 1.377769947052002|  0:00:07s\n","epoch 32 | loss: 0.49371 | val_0_mse: 1.125480055809021|  0:00:07s\n","epoch 33 | loss: 0.48728 | val_0_mse: 1.258139967918396|  0:00:07s\n","epoch 34 | loss: 0.47814 | val_0_mse: 1.1208200454711914|  0:00:08s\n","epoch 35 | loss: 0.47992 | val_0_mse: 1.183590054512024|  0:00:08s\n","epoch 36 | loss: 0.48514 | val_0_mse: 1.1898900270462036|  0:00:08s\n","epoch 37 | loss: 0.47854 | val_0_mse: 1.0627199411392212|  0:00:08s\n","epoch 38 | loss: 0.47986 | val_0_mse: 1.1157900094985962|  0:00:08s\n","epoch 39 | loss: 0.46504 | val_0_mse: 1.0422799587249756|  0:00:09s\n","epoch 40 | loss: 0.46931 | val_0_mse: 1.0587300062179565|  0:00:09s\n","epoch 41 | loss: 0.47463 | val_0_mse: 1.0896899700164795|  0:00:09s\n","epoch 42 | loss: 0.46317 | val_0_mse: 1.002269983291626|  0:00:09s\n","epoch 43 | loss: 0.46481 | val_0_mse: 0.9827600121498108|  0:00:10s\n","epoch 44 | loss: 0.47111 | val_0_mse: 0.9660400152206421|  0:00:10s\n","epoch 45 | loss: 0.47289 | val_0_mse: 0.9307699799537659|  0:00:10s\n","epoch 46 | loss: 0.46252 | val_0_mse: 0.9189000129699707|  0:00:10s\n","epoch 47 | loss: 0.46735 | val_0_mse: 0.8682199716567993|  0:00:10s\n","epoch 48 | loss: 0.46927 | val_0_mse: 0.8718000054359436|  0:00:11s\n","epoch 49 | loss: 0.46398 | val_0_mse: 0.8800100088119507|  0:00:11s\n","epoch 50 | loss: 0.46667 | val_0_mse: 0.8148699998855591|  0:00:11s\n","epoch 51 | loss: 0.45719 | val_0_mse: 0.8306499719619751|  0:00:11s\n","epoch 52 | loss: 0.45877 | val_0_mse: 0.7911400198936462|  0:00:12s\n","epoch 53 | loss: 0.48174 | val_0_mse: 0.8346700072288513|  0:00:12s\n","epoch 54 | loss: 0.45757 | val_0_mse: 0.7956799864768982|  0:00:12s\n","epoch 55 | loss: 0.45292 | val_0_mse: 0.7814300060272217|  0:00:12s\n","epoch 56 | loss: 0.45145 | val_0_mse: 0.7762500047683716|  0:00:13s\n","epoch 57 | loss: 0.45611 | val_0_mse: 0.7363600134849548|  0:00:13s\n","epoch 58 | loss: 0.44626 | val_0_mse: 0.785290002822876|  0:00:13s\n","epoch 59 | loss: 0.44459 | val_0_mse: 0.7467799782752991|  0:00:13s\n","epoch 60 | loss: 0.44221 | val_0_mse: 0.7184399962425232|  0:00:13s\n","epoch 61 | loss: 0.44653 | val_0_mse: 0.743149995803833|  0:00:14s\n","epoch 62 | loss: 0.45385 | val_0_mse: 0.7063699960708618|  0:00:14s\n","epoch 63 | loss: 0.44532 | val_0_mse: 0.7280899882316589|  0:00:14s\n","epoch 64 | loss: 0.44565 | val_0_mse: 0.7150400280952454|  0:00:14s\n","epoch 65 | loss: 0.44776 | val_0_mse: 0.6927800178527832|  0:00:15s\n","epoch 66 | loss: 0.44906 | val_0_mse: 0.6992499828338623|  0:00:15s\n","epoch 67 | loss: 0.44612 | val_0_mse: 0.6969799995422363|  0:00:15s\n","epoch 68 | loss: 0.43935 | val_0_mse: 0.7166399955749512|  0:00:15s\n","epoch 69 | loss: 0.43268 | val_0_mse: 0.7453699707984924|  0:00:16s\n","epoch 70 | loss: 0.44706 | val_0_mse: 0.6860700249671936|  0:00:16s\n","epoch 71 | loss: 0.43933 | val_0_mse: 0.7053400278091431|  0:00:16s\n","epoch 72 | loss: 0.43356 | val_0_mse: 0.6925299763679504|  0:00:16s\n","epoch 73 | loss: 0.44122 | val_0_mse: 0.7047899961471558|  0:00:17s\n","epoch 74 | loss: 0.43724 | val_0_mse: 0.6942999958992004|  0:00:17s\n","epoch 75 | loss: 0.44482 | val_0_mse: 0.6971799731254578|  0:00:17s\n","epoch 76 | loss: 0.42812 | val_0_mse: 0.6889500021934509|  0:00:17s\n","epoch 77 | loss: 0.43556 | val_0_mse: 0.6874099969863892|  0:00:17s\n","epoch 78 | loss: 0.44044 | val_0_mse: 0.6813600063323975|  0:00:18s\n","epoch 79 | loss: 0.43917 | val_0_mse: 0.6741399765014648|  0:00:18s\n","epoch 80 | loss: 0.43583 | val_0_mse: 0.6822199821472168|  0:00:18s\n","epoch 81 | loss: 0.43271 | val_0_mse: 0.6502500176429749|  0:00:18s\n","epoch 82 | loss: 0.43144 | val_0_mse: 0.7044500112533569|  0:00:19s\n","epoch 83 | loss: 0.42807 | val_0_mse: 0.6847100257873535|  0:00:19s\n","epoch 84 | loss: 0.43379 | val_0_mse: 0.6716099977493286|  0:00:19s\n","epoch 85 | loss: 0.43107 | val_0_mse: 0.6577699780464172|  0:00:19s\n","epoch 86 | loss: 0.43089 | val_0_mse: 0.6434299945831299|  0:00:19s\n","epoch 87 | loss: 0.43748 | val_0_mse: 0.6299899816513062|  0:00:20s\n","epoch 88 | loss: 0.42651 | val_0_mse: 0.6431599855422974|  0:00:20s\n","epoch 89 | loss: 0.43267 | val_0_mse: 0.6502000093460083|  0:00:20s\n","epoch 90 | loss: 0.43854 | val_0_mse: 0.6494500041007996|  0:00:21s\n","epoch 91 | loss: 0.43251 | val_0_mse: 0.6521199941635132|  0:00:21s\n","epoch 92 | loss: 0.4296  | val_0_mse: 0.6422299742698669|  0:00:21s\n","epoch 93 | loss: 0.43136 | val_0_mse: 0.6506900191307068|  0:00:21s\n","epoch 94 | loss: 0.42991 | val_0_mse: 0.6650300025939941|  0:00:21s\n","epoch 95 | loss: 0.42914 | val_0_mse: 0.6622999906539917|  0:00:22s\n","epoch 96 | loss: 0.42357 | val_0_mse: 0.6628299951553345|  0:00:22s\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 16:12:39,239] Trial 37 finished with value: 0.6299858689308167 and parameters: {'n_d': 11, 'n_steps': 3, 'gamma': 1.002111474798757, 'n_independent': 2, 'n_shared': 3, 'momentum': 0.05942442553510754}. Best is trial 23 with value: 0.5507968664169312.\n"]},{"output_type":"stream","name":"stdout","text":["epoch 97 | loss: 0.42292 | val_0_mse: 0.661549985408783|  0:00:22s\n","\n","Early stopping occurred at epoch 97 with best_epoch = 87 and best_val_0_mse = 0.6299899816513062\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 16.63489| val_0_mse: 2544.35986328125|  0:00:00s\n","epoch 1  | loss: 8.95706 | val_0_mse: 1055.7471923828125|  0:00:01s\n","epoch 2  | loss: 4.35517 | val_0_mse: 125.8553237915039|  0:00:01s\n","epoch 3  | loss: 2.49707 | val_0_mse: 138.399658203125|  0:00:02s\n","epoch 4  | loss: 1.89152 | val_0_mse: 43.529170989990234|  0:00:03s\n","epoch 5  | loss: 1.48743 | val_0_mse: 24.52985954284668|  0:00:04s\n","epoch 6  | loss: 1.44678 | val_0_mse: 25.61117935180664|  0:00:04s\n","epoch 7  | loss: 1.38413 | val_0_mse: 47.888710021972656|  0:00:05s\n","epoch 8  | loss: 1.34877 | val_0_mse: 17.164119720458984|  0:00:06s\n","epoch 9  | loss: 1.50601 | val_0_mse: 7.007309913635254|  0:00:06s\n","epoch 10 | loss: 1.30298 | val_0_mse: 8.31054973602295|  0:00:07s\n","epoch 11 | loss: 1.05343 | val_0_mse: 11.461600303649902|  0:00:08s\n","epoch 12 | loss: 2.54244 | val_0_mse: 5.655509948730469|  0:00:08s\n","epoch 13 | loss: 1.36943 | val_0_mse: 26.674100875854492|  0:00:09s\n","epoch 14 | loss: 1.02203 | val_0_mse: 13.269929885864258|  0:00:09s\n","epoch 15 | loss: 0.87536 | val_0_mse: 5.866710186004639|  0:00:10s\n","epoch 16 | loss: 0.95904 | val_0_mse: 3.7970199584960938|  0:00:11s\n","epoch 17 | loss: 0.87219 | val_0_mse: 4.553239822387695|  0:00:11s\n","epoch 18 | loss: 0.7777  | val_0_mse: 2.7948501110076904|  0:00:12s\n","epoch 19 | loss: 0.83157 | val_0_mse: 1.9619899988174438|  0:00:13s\n","epoch 20 | loss: 0.91935 | val_0_mse: 2.170949935913086|  0:00:13s\n","epoch 21 | loss: 1.02367 | val_0_mse: 6.294939994812012|  0:00:14s\n","epoch 22 | loss: 1.00978 | val_0_mse: 7.202030181884766|  0:00:15s\n","epoch 23 | loss: 0.69503 | val_0_mse: 3.9358201026916504|  0:00:15s\n","epoch 24 | loss: 0.68084 | val_0_mse: 2.121890068054199|  0:00:16s\n","epoch 25 | loss: 0.6207  | val_0_mse: 3.1623098850250244|  0:00:17s\n","epoch 26 | loss: 0.64562 | val_0_mse: 5.181950092315674|  0:00:17s\n","epoch 27 | loss: 0.67759 | val_0_mse: 6.225279808044434|  0:00:18s\n","epoch 28 | loss: 0.72696 | val_0_mse: 2.8455300331115723|  0:00:19s\n","epoch 29 | loss: 0.68512 | val_0_mse: 4.77170991897583|  0:00:19s\n","\n","Early stopping occurred at epoch 29 with best_epoch = 19 and best_val_0_mse = 1.9619899988174438\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 16:12:59,370] Trial 38 finished with value: 1.9619896411895752 and parameters: {'n_d': 10, 'n_steps': 9, 'gamma': 1.9767147655674784, 'n_independent': 3, 'n_shared': 4, 'momentum': 0.011252364023935153}. Best is trial 23 with value: 0.5507968664169312.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 48.38761| val_0_mse: 65.75183868408203|  0:00:00s\n","epoch 1  | loss: 11.21453| val_0_mse: 49.46739959716797|  0:00:00s\n","epoch 2  | loss: 6.42235 | val_0_mse: 24.57818031311035|  0:00:00s\n","epoch 3  | loss: 2.92754 | val_0_mse: 21.292789459228516|  0:00:01s\n","epoch 4  | loss: 1.99881 | val_0_mse: 12.209839820861816|  0:00:01s\n","epoch 5  | loss: 1.38238 | val_0_mse: 11.951950073242188|  0:00:01s\n","epoch 6  | loss: 1.02071 | val_0_mse: 12.096050262451172|  0:00:02s\n","epoch 7  | loss: 0.89211 | val_0_mse: 6.160419940948486|  0:00:02s\n","epoch 8  | loss: 0.79069 | val_0_mse: 1.676609992980957|  0:00:02s\n","epoch 9  | loss: 0.75178 | val_0_mse: 2.21655011177063|  0:00:03s\n","epoch 10 | loss: 0.72221 | val_0_mse: 1.9898799657821655|  0:00:03s\n","epoch 11 | loss: 0.72745 | val_0_mse: 4.289569854736328|  0:00:03s\n","epoch 12 | loss: 0.65598 | val_0_mse: 3.305039882659912|  0:00:04s\n","epoch 13 | loss: 0.62342 | val_0_mse: 2.110369920730591|  0:00:04s\n","epoch 14 | loss: 0.5925  | val_0_mse: 5.437429904937744|  0:00:04s\n","epoch 15 | loss: 0.58901 | val_0_mse: 7.096459865570068|  0:00:04s\n","epoch 16 | loss: 0.57943 | val_0_mse: 4.308420181274414|  0:00:05s\n","epoch 17 | loss: 0.58901 | val_0_mse: 2.559459924697876|  0:00:05s\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 16:13:05,415] Trial 39 finished with value: 1.6766098737716675 and parameters: {'n_d': 15, 'n_steps': 7, 'gamma': 1.1275212432667847, 'n_independent': 1, 'n_shared': 2, 'momentum': 0.11489281258804251}. Best is trial 23 with value: 0.5507968664169312.\n"]},{"output_type":"stream","name":"stdout","text":["epoch 18 | loss: 0.57544 | val_0_mse: 2.816960096359253|  0:00:05s\n","\n","Early stopping occurred at epoch 18 with best_epoch = 8 and best_val_0_mse = 1.676609992980957\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 32.94993| val_0_mse: 923.626953125|  0:00:00s\n","epoch 1  | loss: 10.21229| val_0_mse: 1694.9063720703125|  0:00:01s\n","epoch 2  | loss: 5.01928 | val_0_mse: 1343.4534912109375|  0:00:02s\n","epoch 3  | loss: 3.10409 | val_0_mse: 308.07330322265625|  0:00:02s\n","epoch 4  | loss: 1.87697 | val_0_mse: 210.65383911132812|  0:00:03s\n","epoch 5  | loss: 2.06415 | val_0_mse: 135.9501953125|  0:00:04s\n","epoch 6  | loss: 1.67722 | val_0_mse: 19.295089721679688|  0:00:04s\n","epoch 7  | loss: 1.27739 | val_0_mse: 44.37815856933594|  0:00:05s\n","epoch 8  | loss: 1.11554 | val_0_mse: 16.807979583740234|  0:00:06s\n","epoch 9  | loss: 0.93124 | val_0_mse: 54.70259094238281|  0:00:06s\n","epoch 10 | loss: 0.93173 | val_0_mse: 78.395263671875|  0:00:07s\n","epoch 11 | loss: 0.86989 | val_0_mse: 9.163089752197266|  0:00:08s\n","epoch 12 | loss: 0.87457 | val_0_mse: 55.79581832885742|  0:00:08s\n","epoch 13 | loss: 0.9622  | val_0_mse: 88.08100891113281|  0:00:09s\n","epoch 14 | loss: 1.02324 | val_0_mse: 68.01612854003906|  0:00:09s\n","epoch 15 | loss: 0.9399  | val_0_mse: 15.81742000579834|  0:00:10s\n","epoch 16 | loss: 0.82476 | val_0_mse: 3.315500020980835|  0:00:11s\n","epoch 17 | loss: 0.64406 | val_0_mse: 2.4714701175689697|  0:00:11s\n","epoch 18 | loss: 0.66143 | val_0_mse: 3.8043200969696045|  0:00:12s\n","epoch 19 | loss: 0.70373 | val_0_mse: 5.774449825286865|  0:00:13s\n","epoch 20 | loss: 0.71529 | val_0_mse: 4.875609874725342|  0:00:13s\n","epoch 21 | loss: 0.66893 | val_0_mse: 2.2701199054718018|  0:00:14s\n","epoch 22 | loss: 0.6046  | val_0_mse: 1.8690099716186523|  0:00:15s\n","epoch 23 | loss: 0.62517 | val_0_mse: 1.8034299612045288|  0:00:15s\n","epoch 24 | loss: 0.59191 | val_0_mse: 1.8159799575805664|  0:00:16s\n","epoch 25 | loss: 0.59394 | val_0_mse: 3.8831799030303955|  0:00:17s\n","epoch 26 | loss: 0.58692 | val_0_mse: 4.693999767303467|  0:00:17s\n","epoch 27 | loss: 0.58986 | val_0_mse: 2.756890058517456|  0:00:18s\n","epoch 28 | loss: 0.58286 | val_0_mse: 1.985319972038269|  0:00:19s\n","epoch 29 | loss: 0.57366 | val_0_mse: 2.688960075378418|  0:00:19s\n","epoch 30 | loss: 0.57569 | val_0_mse: 1.8886300325393677|  0:00:20s\n","epoch 31 | loss: 0.59655 | val_0_mse: 1.3440699577331543|  0:00:21s\n","epoch 32 | loss: 0.57922 | val_0_mse: 1.2953599691390991|  0:00:21s\n","epoch 33 | loss: 0.55865 | val_0_mse: 1.371840000152588|  0:00:22s\n","epoch 34 | loss: 0.56512 | val_0_mse: 1.6220200061798096|  0:00:23s\n","epoch 35 | loss: 0.61034 | val_0_mse: 1.2994999885559082|  0:00:23s\n","epoch 36 | loss: 0.63426 | val_0_mse: 1.106410026550293|  0:00:24s\n","epoch 37 | loss: 0.59332 | val_0_mse: 1.5782999992370605|  0:00:25s\n","epoch 38 | loss: 0.60455 | val_0_mse: 0.8549799919128418|  0:00:25s\n","epoch 39 | loss: 0.57529 | val_0_mse: 1.0285700559616089|  0:00:26s\n","epoch 40 | loss: 0.54755 | val_0_mse: 1.1042100191116333|  0:00:27s\n","epoch 41 | loss: 0.5526  | val_0_mse: 1.0794700384140015|  0:00:27s\n","epoch 42 | loss: 0.56259 | val_0_mse: 0.8405600190162659|  0:00:28s\n","epoch 43 | loss: 0.56045 | val_0_mse: 0.7887099981307983|  0:00:29s\n","epoch 44 | loss: 0.55404 | val_0_mse: 0.7046099901199341|  0:00:29s\n","epoch 45 | loss: 0.58516 | val_0_mse: 1.0406500101089478|  0:00:30s\n","epoch 46 | loss: 0.56298 | val_0_mse: 1.0036100149154663|  0:00:31s\n","epoch 47 | loss: 0.56722 | val_0_mse: 0.7822200059890747|  0:00:31s\n","epoch 48 | loss: 0.57169 | val_0_mse: 0.9057599902153015|  0:00:32s\n","epoch 49 | loss: 0.55078 | val_0_mse: 0.7300699949264526|  0:00:32s\n","epoch 50 | loss: 0.55115 | val_0_mse: 0.9923800230026245|  0:00:33s\n","epoch 51 | loss: 0.54689 | val_0_mse: 0.8726000189781189|  0:00:34s\n","epoch 52 | loss: 0.5455  | val_0_mse: 0.7132599949836731|  0:00:35s\n","epoch 53 | loss: 0.54903 | val_0_mse: 0.7891799807548523|  0:00:35s\n","epoch 54 | loss: 0.53364 | val_0_mse: 0.7730600237846375|  0:00:36s\n","\n","Early stopping occurred at epoch 54 with best_epoch = 44 and best_val_0_mse = 0.7046099901199341\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 16:13:42,428] Trial 40 finished with value: 0.7046135067939758 and parameters: {'n_d': 13, 'n_steps': 8, 'gamma': 1.1900503044829116, 'n_independent': 4, 'n_shared': 4, 'momentum': 0.2575835548957728}. Best is trial 23 with value: 0.5507968664169312.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 70.14593| val_0_mse: 1651.7449951171875|  0:00:00s\n","epoch 1  | loss: 34.09884| val_0_mse: 250.21429443359375|  0:00:01s\n","epoch 2  | loss: 14.50866| val_0_mse: 211.1697540283203|  0:00:01s\n","epoch 3  | loss: 5.73101 | val_0_mse: 282.080810546875|  0:00:02s\n","epoch 4  | loss: 4.07942 | val_0_mse: 126.01322174072266|  0:00:03s\n","epoch 5  | loss: 2.37755 | val_0_mse: 97.14906311035156|  0:00:03s\n","epoch 6  | loss: 1.86168 | val_0_mse: 75.09042358398438|  0:00:04s\n","epoch 7  | loss: 1.41996 | val_0_mse: 46.15414810180664|  0:00:05s\n","epoch 8  | loss: 1.13046 | val_0_mse: 16.481449127197266|  0:00:05s\n","epoch 9  | loss: 0.98344 | val_0_mse: 21.289159774780273|  0:00:06s\n","epoch 10 | loss: 0.93269 | val_0_mse: 46.289669036865234|  0:00:07s\n","epoch 11 | loss: 0.93377 | val_0_mse: 20.333879470825195|  0:00:07s\n","epoch 12 | loss: 0.93655 | val_0_mse: 39.26205825805664|  0:00:08s\n","epoch 13 | loss: 1.03854 | val_0_mse: 28.201879501342773|  0:00:08s\n","epoch 14 | loss: 0.85647 | val_0_mse: 19.211280822753906|  0:00:09s\n","epoch 15 | loss: 0.981   | val_0_mse: 13.208600044250488|  0:00:10s\n","epoch 16 | loss: 0.94635 | val_0_mse: 6.345310211181641|  0:00:10s\n","epoch 17 | loss: 0.75961 | val_0_mse: 3.171639919281006|  0:00:11s\n","epoch 18 | loss: 0.72844 | val_0_mse: 4.131149768829346|  0:00:12s\n","epoch 19 | loss: 0.66705 | val_0_mse: 2.597640037536621|  0:00:12s\n","epoch 20 | loss: 0.69778 | val_0_mse: 2.456700086593628|  0:00:13s\n","epoch 21 | loss: 0.71036 | val_0_mse: 2.607759952545166|  0:00:14s\n","epoch 22 | loss: 0.72744 | val_0_mse: 2.9127399921417236|  0:00:14s\n","epoch 23 | loss: 0.80846 | val_0_mse: 6.393710136413574|  0:00:15s\n","epoch 24 | loss: 1.07356 | val_0_mse: 11.67134952545166|  0:00:16s\n","epoch 25 | loss: 2.63256 | val_0_mse: 11.260660171508789|  0:00:16s\n","epoch 26 | loss: 1.47299 | val_0_mse: 2.635960102081299|  0:00:17s\n","epoch 27 | loss: 1.30866 | val_0_mse: 1.8944000005722046|  0:00:18s\n","epoch 28 | loss: 0.76022 | val_0_mse: 3.789520025253296|  0:00:18s\n","epoch 29 | loss: 0.76872 | val_0_mse: 0.9775500297546387|  0:00:19s\n","epoch 30 | loss: 0.71431 | val_0_mse: 2.185810089111328|  0:00:19s\n","epoch 31 | loss: 0.75359 | val_0_mse: 0.8932899832725525|  0:00:20s\n","epoch 32 | loss: 0.91651 | val_0_mse: 1.0023599863052368|  0:00:21s\n","epoch 33 | loss: 0.77776 | val_0_mse: 2.4272899627685547|  0:00:21s\n","epoch 34 | loss: 0.68079 | val_0_mse: 1.0961799621582031|  0:00:22s\n","epoch 35 | loss: 0.88591 | val_0_mse: 1.100409984588623|  0:00:23s\n","epoch 36 | loss: 0.71181 | val_0_mse: 1.28125 |  0:00:23s\n","epoch 37 | loss: 0.74385 | val_0_mse: 1.0943100452423096|  0:00:24s\n","epoch 38 | loss: 0.68936 | val_0_mse: 0.6871799826622009|  0:00:25s\n","epoch 39 | loss: 0.72401 | val_0_mse: 1.6737300157546997|  0:00:25s\n","epoch 40 | loss: 0.7646  | val_0_mse: 0.6524199843406677|  0:00:26s\n","epoch 41 | loss: 0.72982 | val_0_mse: 0.7235999703407288|  0:00:27s\n","epoch 42 | loss: 0.61673 | val_0_mse: 0.9025899767875671|  0:00:27s\n","epoch 43 | loss: 0.69233 | val_0_mse: 0.7594500184059143|  0:00:28s\n","epoch 44 | loss: 0.67206 | val_0_mse: 1.1510900259017944|  0:00:28s\n","epoch 45 | loss: 0.66914 | val_0_mse: 0.6373400092124939|  0:00:29s\n","epoch 46 | loss: 0.61643 | val_0_mse: 0.8888499736785889|  0:00:30s\n","epoch 47 | loss: 0.6059  | val_0_mse: 0.6541200280189514|  0:00:31s\n","epoch 48 | loss: 0.67325 | val_0_mse: 0.6606900095939636|  0:00:31s\n","epoch 49 | loss: 0.58271 | val_0_mse: 0.845740020275116|  0:00:32s\n","epoch 50 | loss: 0.58855 | val_0_mse: 0.7216399908065796|  0:00:32s\n","epoch 51 | loss: 0.58397 | val_0_mse: 0.6999300122261047|  0:00:33s\n","epoch 52 | loss: 0.58019 | val_0_mse: 0.7458500266075134|  0:00:34s\n","epoch 53 | loss: 0.60686 | val_0_mse: 0.673770010471344|  0:00:34s\n","epoch 54 | loss: 0.5948  | val_0_mse: 0.7232999801635742|  0:00:35s\n","epoch 55 | loss: 0.57451 | val_0_mse: 0.7253599762916565|  0:00:36s\n","\n","Early stopping occurred at epoch 55 with best_epoch = 45 and best_val_0_mse = 0.6373400092124939\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 16:14:18,970] Trial 41 finished with value: 0.6373400688171387 and parameters: {'n_d': 9, 'n_steps': 10, 'gamma': 1.1198023744776973, 'n_independent': 1, 'n_shared': 5, 'momentum': 0.07350881369040428}. Best is trial 23 with value: 0.5507968664169312.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 60.76647| val_0_mse: 239.95443725585938|  0:00:00s\n","epoch 1  | loss: 25.40642| val_0_mse: 133.65237426757812|  0:00:00s\n","epoch 2  | loss: 13.6758 | val_0_mse: 125.23267364501953|  0:00:01s\n","epoch 3  | loss: 8.65986 | val_0_mse: 180.82481384277344|  0:00:01s\n","epoch 4  | loss: 6.08723 | val_0_mse: 222.0131072998047|  0:00:02s\n","epoch 5  | loss: 4.87019 | val_0_mse: 150.1356201171875|  0:00:02s\n","epoch 6  | loss: 3.49132 | val_0_mse: 187.31915283203125|  0:00:03s\n","epoch 7  | loss: 2.61794 | val_0_mse: 186.55787658691406|  0:00:03s\n","epoch 8  | loss: 1.84956 | val_0_mse: 143.69776916503906|  0:00:04s\n","epoch 9  | loss: 1.43237 | val_0_mse: 44.522518157958984|  0:00:04s\n","epoch 10 | loss: 1.23463 | val_0_mse: 23.6588191986084|  0:00:05s\n","epoch 11 | loss: 1.05573 | val_0_mse: 9.958470344543457|  0:00:05s\n","epoch 12 | loss: 0.87535 | val_0_mse: 4.797130107879639|  0:00:06s\n","epoch 13 | loss: 0.8044  | val_0_mse: 3.571619987487793|  0:00:06s\n","epoch 14 | loss: 0.81127 | val_0_mse: 2.0794200897216797|  0:00:07s\n","epoch 15 | loss: 0.75781 | val_0_mse: 2.4921200275421143|  0:00:07s\n","epoch 16 | loss: 0.69465 | val_0_mse: 2.4167299270629883|  0:00:08s\n","epoch 17 | loss: 0.67726 | val_0_mse: 1.772029995918274|  0:00:08s\n","epoch 18 | loss: 0.68836 | val_0_mse: 1.7519500255584717|  0:00:09s\n","epoch 19 | loss: 0.6473  | val_0_mse: 1.960010051727295|  0:00:09s\n","epoch 20 | loss: 0.6224  | val_0_mse: 2.253230094909668|  0:00:10s\n","epoch 21 | loss: 0.60857 | val_0_mse: 1.2357300519943237|  0:00:10s\n","epoch 22 | loss: 0.62846 | val_0_mse: 3.1374900341033936|  0:00:11s\n","epoch 23 | loss: 0.68987 | val_0_mse: 0.8514999747276306|  0:00:11s\n","epoch 24 | loss: 0.60303 | val_0_mse: 1.3720200061798096|  0:00:12s\n","epoch 25 | loss: 0.72482 | val_0_mse: 1.480370044708252|  0:00:12s\n","epoch 26 | loss: 0.60602 | val_0_mse: 1.186169981956482|  0:00:13s\n","epoch 27 | loss: 0.57089 | val_0_mse: 1.1347999572753906|  0:00:13s\n","epoch 28 | loss: 0.58052 | val_0_mse: 1.2963999509811401|  0:00:14s\n","epoch 29 | loss: 0.60212 | val_0_mse: 1.4405900239944458|  0:00:14s\n","epoch 30 | loss: 0.602   | val_0_mse: 1.1542999744415283|  0:00:15s\n","epoch 31 | loss: 0.57479 | val_0_mse: 1.9933799505233765|  0:00:15s\n","epoch 32 | loss: 0.58727 | val_0_mse: 1.1672699451446533|  0:00:16s\n","epoch 33 | loss: 0.5534  | val_0_mse: 1.2689800262451172|  0:00:16s\n","\n","Early stopping occurred at epoch 33 with best_epoch = 23 and best_val_0_mse = 0.8514999747276306\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 16:14:36,002] Trial 42 finished with value: 0.8514982461929321 and parameters: {'n_d': 8, 'n_steps': 10, 'gamma': 1.0569419398936668, 'n_independent': 1, 'n_shared': 3, 'momentum': 0.07207124010607814}. Best is trial 23 with value: 0.5507968664169312.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 24.70249| val_0_mse: 1462.16796875|  0:00:00s\n","epoch 1  | loss: 6.53116 | val_0_mse: 550.126708984375|  0:00:01s\n","epoch 2  | loss: 3.66853 | val_0_mse: 163.7927703857422|  0:00:02s\n","epoch 3  | loss: 1.94376 | val_0_mse: 63.0536003112793|  0:00:02s\n","epoch 4  | loss: 1.41392 | val_0_mse: 104.39662170410156|  0:00:03s\n","epoch 5  | loss: 1.15144 | val_0_mse: 18.46076011657715|  0:00:04s\n","epoch 6  | loss: 0.97149 | val_0_mse: 49.676090240478516|  0:00:04s\n","epoch 7  | loss: 0.85092 | val_0_mse: 38.835819244384766|  0:00:05s\n","epoch 8  | loss: 0.97385 | val_0_mse: 11.121919631958008|  0:00:06s\n","epoch 9  | loss: 1.12098 | val_0_mse: 7.999199867248535|  0:00:06s\n","epoch 10 | loss: 0.92996 | val_0_mse: 2.579479932785034|  0:00:07s\n","epoch 11 | loss: 0.77256 | val_0_mse: 2.8328800201416016|  0:00:08s\n","epoch 12 | loss: 0.90733 | val_0_mse: 3.942970037460327|  0:00:08s\n","epoch 13 | loss: 0.8638  | val_0_mse: 3.5271201133728027|  0:00:09s\n","epoch 14 | loss: 0.79605 | val_0_mse: 3.9171500205993652|  0:00:10s\n","epoch 15 | loss: 0.7561  | val_0_mse: 1.8731199502944946|  0:00:10s\n","epoch 16 | loss: 1.0278  | val_0_mse: 3.6372499465942383|  0:00:11s\n","epoch 17 | loss: 0.96331 | val_0_mse: 9.739540100097656|  0:00:12s\n","epoch 18 | loss: 0.84247 | val_0_mse: 2.856139898300171|  0:00:12s\n","epoch 19 | loss: 0.75034 | val_0_mse: 5.366889953613281|  0:00:13s\n","epoch 20 | loss: 0.66871 | val_0_mse: 1.5347700119018555|  0:00:14s\n","epoch 21 | loss: 0.68075 | val_0_mse: 2.362689971923828|  0:00:14s\n","epoch 22 | loss: 0.74142 | val_0_mse: 1.3607699871063232|  0:00:15s\n","epoch 23 | loss: 0.76155 | val_0_mse: 5.2862701416015625|  0:00:16s\n","epoch 24 | loss: 0.68035 | val_0_mse: 2.0451300144195557|  0:00:16s\n","epoch 25 | loss: 0.61637 | val_0_mse: 2.663640022277832|  0:00:17s\n","epoch 26 | loss: 0.59807 | val_0_mse: 2.2071800231933594|  0:00:18s\n","epoch 27 | loss: 0.60298 | val_0_mse: 1.5606800317764282|  0:00:18s\n","epoch 28 | loss: 0.6044  | val_0_mse: 2.6260499954223633|  0:00:19s\n","epoch 29 | loss: 0.61587 | val_0_mse: 1.957859992980957|  0:00:19s\n","epoch 30 | loss: 0.62018 | val_0_mse: 3.1071701049804688|  0:00:20s\n","epoch 31 | loss: 0.62757 | val_0_mse: 2.0403499603271484|  0:00:21s\n","epoch 32 | loss: 0.59584 | val_0_mse: 2.0350100994110107|  0:00:21s\n","\n","Early stopping occurred at epoch 32 with best_epoch = 22 and best_val_0_mse = 1.3607699871063232\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 16:14:58,332] Trial 43 finished with value: 1.3607661724090576 and parameters: {'n_d': 19, 'n_steps': 9, 'gamma': 1.135897361562454, 'n_independent': 2, 'n_shared': 5, 'momentum': 0.05337029613557736}. Best is trial 23 with value: 0.5507968664169312.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 16.69789| val_0_mse: 1939.45166015625|  0:00:00s\n","epoch 1  | loss: 5.3309  | val_0_mse: 1926.4869384765625|  0:00:00s\n","epoch 2  | loss: 3.44651 | val_0_mse: 186.18922424316406|  0:00:00s\n","epoch 3  | loss: 1.81067 | val_0_mse: 43.29207992553711|  0:00:00s\n","epoch 4  | loss: 1.33123 | val_0_mse: 23.857629776000977|  0:00:01s\n","epoch 5  | loss: 1.01154 | val_0_mse: 22.214279174804688|  0:00:01s\n","epoch 6  | loss: 0.85395 | val_0_mse: 16.365339279174805|  0:00:01s\n","epoch 7  | loss: 0.78389 | val_0_mse: 24.5545597076416|  0:00:01s\n","epoch 8  | loss: 0.73166 | val_0_mse: 28.473360061645508|  0:00:01s\n","epoch 9  | loss: 0.70947 | val_0_mse: 31.61157989501953|  0:00:02s\n","epoch 10 | loss: 0.65726 | val_0_mse: 28.232940673828125|  0:00:02s\n","epoch 11 | loss: 0.6432  | val_0_mse: 16.6971492767334|  0:00:02s\n","epoch 12 | loss: 0.60422 | val_0_mse: 44.77783966064453|  0:00:02s\n","epoch 13 | loss: 0.58311 | val_0_mse: 42.117008209228516|  0:00:03s\n","epoch 14 | loss: 0.59666 | val_0_mse: 38.686458587646484|  0:00:03s\n","epoch 15 | loss: 0.62419 | val_0_mse: 28.32714080810547|  0:00:03s\n","epoch 16 | loss: 0.59814 | val_0_mse: 8.023070335388184|  0:00:03s\n","epoch 17 | loss: 0.58219 | val_0_mse: 3.1841399669647217|  0:00:03s\n","epoch 18 | loss: 0.56769 | val_0_mse: 1.8657000064849854|  0:00:04s\n","epoch 19 | loss: 0.54975 | val_0_mse: 2.935800075531006|  0:00:04s\n","epoch 20 | loss: 0.54216 | val_0_mse: 2.220410108566284|  0:00:04s\n","epoch 21 | loss: 0.55993 | val_0_mse: 1.9082000255584717|  0:00:04s\n","epoch 22 | loss: 0.55014 | val_0_mse: 1.6602599620819092|  0:00:04s\n","epoch 23 | loss: 0.53787 | val_0_mse: 1.7233699560165405|  0:00:05s\n","epoch 24 | loss: 0.52879 | val_0_mse: 2.591320037841797|  0:00:05s\n","epoch 25 | loss: 0.54    | val_0_mse: 1.8948299884796143|  0:00:05s\n","epoch 26 | loss: 0.5449  | val_0_mse: 1.7340999841690063|  0:00:05s\n","epoch 27 | loss: 0.53288 | val_0_mse: 2.683850049972534|  0:00:05s\n","epoch 28 | loss: 0.54141 | val_0_mse: 2.9607999324798584|  0:00:06s\n","epoch 29 | loss: 0.53282 | val_0_mse: 2.0736799240112305|  0:00:06s\n","epoch 30 | loss: 0.52706 | val_0_mse: 2.589979887008667|  0:00:06s\n","epoch 31 | loss: 0.55323 | val_0_mse: 1.5203200578689575|  0:00:06s\n","epoch 32 | loss: 0.54499 | val_0_mse: 2.041759967803955|  0:00:06s\n","epoch 33 | loss: 0.54878 | val_0_mse: 2.4230198860168457|  0:00:07s\n","epoch 34 | loss: 0.53132 | val_0_mse: 1.7428699731826782|  0:00:07s\n","epoch 35 | loss: 0.53119 | val_0_mse: 1.6166000366210938|  0:00:07s\n","epoch 36 | loss: 0.52003 | val_0_mse: 1.2856700420379639|  0:00:07s\n","epoch 37 | loss: 0.53075 | val_0_mse: 1.420140027999878|  0:00:07s\n","epoch 38 | loss: 0.52818 | val_0_mse: 0.9935899972915649|  0:00:08s\n","epoch 39 | loss: 0.51442 | val_0_mse: 0.935920000076294|  0:00:08s\n","epoch 40 | loss: 0.52085 | val_0_mse: 0.9327999949455261|  0:00:08s\n","epoch 41 | loss: 0.53095 | val_0_mse: 0.8731799721717834|  0:00:08s\n","epoch 42 | loss: 0.50154 | val_0_mse: 0.8803200125694275|  0:00:08s\n","epoch 43 | loss: 0.51542 | val_0_mse: 1.102620005607605|  0:00:09s\n","epoch 44 | loss: 0.5176  | val_0_mse: 0.7838000059127808|  0:00:09s\n","epoch 45 | loss: 0.51312 | val_0_mse: 1.0119099617004395|  0:00:09s\n","epoch 46 | loss: 0.51092 | val_0_mse: 0.8424500226974487|  0:00:09s\n","epoch 47 | loss: 0.50263 | val_0_mse: 0.7030199766159058|  0:00:09s\n","epoch 48 | loss: 0.51005 | val_0_mse: 0.9484000205993652|  0:00:10s\n","epoch 49 | loss: 0.51635 | val_0_mse: 0.7297599911689758|  0:00:10s\n","epoch 50 | loss: 0.53079 | val_0_mse: 0.8112300038337708|  0:00:10s\n","epoch 51 | loss: 0.53377 | val_0_mse: 0.7852699756622314|  0:00:10s\n","epoch 52 | loss: 0.52996 | val_0_mse: 0.7006800174713135|  0:00:10s\n","epoch 53 | loss: 0.53535 | val_0_mse: 0.7789899706840515|  0:00:11s\n","epoch 54 | loss: 0.53309 | val_0_mse: 0.6872100234031677|  0:00:11s\n","epoch 55 | loss: 0.52867 | val_0_mse: 0.7078499794006348|  0:00:11s\n","epoch 56 | loss: 0.51389 | val_0_mse: 0.7404299974441528|  0:00:11s\n","epoch 57 | loss: 0.52133 | val_0_mse: 0.6597200036048889|  0:00:11s\n","epoch 58 | loss: 0.50552 | val_0_mse: 0.6777200102806091|  0:00:12s\n","epoch 59 | loss: 0.5073  | val_0_mse: 0.6575199961662292|  0:00:12s\n","epoch 60 | loss: 0.50053 | val_0_mse: 0.6618199944496155|  0:00:12s\n","epoch 61 | loss: 0.50155 | val_0_mse: 0.6308799982070923|  0:00:12s\n","epoch 62 | loss: 0.50308 | val_0_mse: 0.6452100276947021|  0:00:13s\n","epoch 63 | loss: 0.48737 | val_0_mse: 0.638729989528656|  0:00:13s\n","epoch 64 | loss: 0.49496 | val_0_mse: 0.6285899877548218|  0:00:13s\n","epoch 65 | loss: 0.48463 | val_0_mse: 0.6649500131607056|  0:00:13s\n","epoch 66 | loss: 0.49289 | val_0_mse: 0.6398599743843079|  0:00:13s\n","epoch 67 | loss: 0.4903  | val_0_mse: 0.6235299706459045|  0:00:14s\n","epoch 68 | loss: 0.48699 | val_0_mse: 0.6519100069999695|  0:00:14s\n","epoch 69 | loss: 0.4893  | val_0_mse: 0.6309800148010254|  0:00:14s\n","epoch 70 | loss: 0.49505 | val_0_mse: 0.6390699744224548|  0:00:14s\n","epoch 71 | loss: 0.49358 | val_0_mse: 0.6319500207901001|  0:00:15s\n","epoch 72 | loss: 0.47786 | val_0_mse: 0.6283100247383118|  0:00:15s\n","epoch 73 | loss: 0.48125 | val_0_mse: 0.6334599852561951|  0:00:15s\n","epoch 74 | loss: 0.49894 | val_0_mse: 0.6214900016784668|  0:00:15s\n","epoch 75 | loss: 0.49702 | val_0_mse: 0.6053000092506409|  0:00:15s\n","epoch 76 | loss: 0.48585 | val_0_mse: 0.618120014667511|  0:00:16s\n","epoch 77 | loss: 0.48879 | val_0_mse: 0.6063299775123596|  0:00:16s\n","epoch 78 | loss: 0.49654 | val_0_mse: 0.6158400177955627|  0:00:16s\n","epoch 79 | loss: 0.49041 | val_0_mse: 0.6144599914550781|  0:00:16s\n","epoch 80 | loss: 0.4841  | val_0_mse: 0.6072400212287903|  0:00:16s\n","epoch 81 | loss: 0.49577 | val_0_mse: 0.5992799997329712|  0:00:17s\n","epoch 82 | loss: 0.50705 | val_0_mse: 0.6053699851036072|  0:00:17s\n","epoch 83 | loss: 0.50626 | val_0_mse: 0.6479600071907043|  0:00:17s\n","epoch 84 | loss: 0.50676 | val_0_mse: 0.6116999983787537|  0:00:17s\n","epoch 85 | loss: 0.50459 | val_0_mse: 0.608519971370697|  0:00:17s\n","epoch 86 | loss: 0.49341 | val_0_mse: 0.6120499968528748|  0:00:18s\n","epoch 87 | loss: 0.49064 | val_0_mse: 0.6198099851608276|  0:00:18s\n","epoch 88 | loss: 0.4932  | val_0_mse: 0.6036499738693237|  0:00:18s\n","epoch 89 | loss: 0.48826 | val_0_mse: 0.5850600004196167|  0:00:18s\n","epoch 90 | loss: 0.49435 | val_0_mse: 0.6408699750900269|  0:00:18s\n","epoch 91 | loss: 0.49319 | val_0_mse: 0.5961300134658813|  0:00:19s\n","epoch 92 | loss: 0.48848 | val_0_mse: 0.6052299737930298|  0:00:19s\n","epoch 93 | loss: 0.49185 | val_0_mse: 0.645039975643158|  0:00:19s\n","epoch 94 | loss: 0.50151 | val_0_mse: 0.6136999726295471|  0:00:19s\n","epoch 95 | loss: 0.50747 | val_0_mse: 0.6409599781036377|  0:00:19s\n","epoch 96 | loss: 0.4916  | val_0_mse: 0.616919994354248|  0:00:20s\n","epoch 97 | loss: 0.48195 | val_0_mse: 0.6002600193023682|  0:00:20s\n","epoch 98 | loss: 0.49278 | val_0_mse: 0.5960900187492371|  0:00:20s\n","epoch 99 | loss: 0.50343 | val_0_mse: 0.6002200245857239|  0:00:20s\n","\n","Early stopping occurred at epoch 99 with best_epoch = 89 and best_val_0_mse = 0.5850600004196167\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 16:15:19,103] Trial 44 finished with value: 0.5850610733032227 and parameters: {'n_d': 11, 'n_steps': 4, 'gamma': 1.881985079851167, 'n_independent': 1, 'n_shared': 2, 'momentum': 0.087584596553348}. Best is trial 23 with value: 0.5507968664169312.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 9.10888 | val_0_mse: 2119.23291015625|  0:00:00s\n","epoch 1  | loss: 4.23448 | val_0_mse: 1356.644287109375|  0:00:01s\n","epoch 2  | loss: 2.27021 | val_0_mse: 550.2801513671875|  0:00:01s\n","epoch 3  | loss: 1.3211  | val_0_mse: 103.00837707519531|  0:00:02s\n","epoch 4  | loss: 1.19995 | val_0_mse: 162.9075469970703|  0:00:02s\n","epoch 5  | loss: 1.02311 | val_0_mse: 65.9617919921875|  0:00:03s\n","epoch 6  | loss: 0.96163 | val_0_mse: 30.290250778198242|  0:00:03s\n","epoch 7  | loss: 0.8144  | val_0_mse: 30.389339447021484|  0:00:04s\n","epoch 8  | loss: 0.74294 | val_0_mse: 19.20539093017578|  0:00:04s\n","epoch 9  | loss: 0.7593  | val_0_mse: 9.729780197143555|  0:00:05s\n","epoch 10 | loss: 0.67355 | val_0_mse: 6.601250171661377|  0:00:05s\n","epoch 11 | loss: 0.70899 | val_0_mse: 4.289070129394531|  0:00:06s\n","epoch 12 | loss: 0.69496 | val_0_mse: 5.718530178070068|  0:00:06s\n","epoch 13 | loss: 0.64417 | val_0_mse: 5.303150177001953|  0:00:07s\n","epoch 14 | loss: 0.64529 | val_0_mse: 6.0640997886657715|  0:00:07s\n","epoch 15 | loss: 0.63953 | val_0_mse: 6.259339809417725|  0:00:08s\n","epoch 16 | loss: 0.60345 | val_0_mse: 4.1612701416015625|  0:00:08s\n","epoch 17 | loss: 0.72752 | val_0_mse: 1.7483799457550049|  0:00:09s\n","epoch 18 | loss: 0.63252 | val_0_mse: 1.2648600339889526|  0:00:09s\n","epoch 19 | loss: 0.63088 | val_0_mse: 3.2494900226593018|  0:00:10s\n","epoch 20 | loss: 0.6405  | val_0_mse: 1.2266600131988525|  0:00:10s\n","epoch 21 | loss: 0.66416 | val_0_mse: 1.3489799499511719|  0:00:11s\n","epoch 22 | loss: 0.59211 | val_0_mse: 1.1472699642181396|  0:00:11s\n","epoch 23 | loss: 0.60783 | val_0_mse: 1.0297499895095825|  0:00:12s\n","epoch 24 | loss: 0.57295 | val_0_mse: 1.0361100435256958|  0:00:12s\n","epoch 25 | loss: 0.58505 | val_0_mse: 0.8924499750137329|  0:00:13s\n","epoch 26 | loss: 0.58811 | val_0_mse: 1.0015100240707397|  0:00:13s\n","epoch 27 | loss: 0.59593 | val_0_mse: 0.9080899953842163|  0:00:14s\n","epoch 28 | loss: 0.66554 | val_0_mse: 1.0505499839782715|  0:00:14s\n","epoch 29 | loss: 0.61967 | val_0_mse: 1.0279699563980103|  0:00:15s\n","epoch 30 | loss: 0.60597 | val_0_mse: 1.1774300336837769|  0:00:16s\n","epoch 31 | loss: 0.62745 | val_0_mse: 1.5565999746322632|  0:00:16s\n","epoch 32 | loss: 0.66238 | val_0_mse: 0.814520001411438|  0:00:17s\n","epoch 33 | loss: 0.6071  | val_0_mse: 1.3753999471664429|  0:00:17s\n","epoch 34 | loss: 0.61922 | val_0_mse: 0.8790900111198425|  0:00:18s\n","epoch 35 | loss: 0.60281 | val_0_mse: 1.3913300037384033|  0:00:18s\n","epoch 36 | loss: 0.55688 | val_0_mse: 1.578909993171692|  0:00:19s\n","epoch 37 | loss: 0.59487 | val_0_mse: 0.871969997882843|  0:00:19s\n","epoch 38 | loss: 0.59115 | val_0_mse: 1.543910026550293|  0:00:20s\n","epoch 39 | loss: 0.56622 | val_0_mse: 1.3685200214385986|  0:00:20s\n","epoch 40 | loss: 0.54386 | val_0_mse: 1.3289200067520142|  0:00:21s\n","epoch 41 | loss: 0.53451 | val_0_mse: 1.2026699781417847|  0:00:21s\n","epoch 42 | loss: 0.53378 | val_0_mse: 1.2836300134658813|  0:00:22s\n","\n","Early stopping occurred at epoch 42 with best_epoch = 32 and best_val_0_mse = 0.814520001411438\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 16:15:41,694] Trial 45 finished with value: 0.8145175576210022 and parameters: {'n_d': 15, 'n_steps': 9, 'gamma': 1.102551662835949, 'n_independent': 1, 'n_shared': 4, 'momentum': 0.02736310165972232}. Best is trial 23 with value: 0.5507968664169312.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 8.54623 | val_0_mse: 1381.6981201171875|  0:00:00s\n","epoch 1  | loss: 2.69869 | val_0_mse: 237.1036376953125|  0:00:01s\n","epoch 2  | loss: 1.82486 | val_0_mse: 109.40535736083984|  0:00:02s\n","epoch 3  | loss: 1.43846 | val_0_mse: 118.62283325195312|  0:00:02s\n","epoch 4  | loss: 1.50648 | val_0_mse: 134.2679443359375|  0:00:03s\n","epoch 5  | loss: 1.09234 | val_0_mse: 81.1977310180664|  0:00:04s\n","epoch 6  | loss: 0.9745  | val_0_mse: 20.793359756469727|  0:00:05s\n","epoch 7  | loss: 0.97305 | val_0_mse: 32.219661712646484|  0:00:05s\n","epoch 8  | loss: 1.26545 | val_0_mse: 49.158790588378906|  0:00:06s\n","epoch 9  | loss: 0.98606 | val_0_mse: 50.232398986816406|  0:00:07s\n","epoch 10 | loss: 0.83148 | val_0_mse: 40.99924850463867|  0:00:08s\n","epoch 11 | loss: 0.89223 | val_0_mse: 7.279109954833984|  0:00:08s\n","epoch 12 | loss: 0.83316 | val_0_mse: 12.031900405883789|  0:00:09s\n","epoch 13 | loss: 0.80275 | val_0_mse: 4.004499912261963|  0:00:10s\n","epoch 14 | loss: 0.9136  | val_0_mse: 9.136289596557617|  0:00:10s\n","epoch 15 | loss: 0.94997 | val_0_mse: 1.9152100086212158|  0:00:11s\n","epoch 16 | loss: 0.79579 | val_0_mse: 3.7488200664520264|  0:00:12s\n","epoch 17 | loss: 0.65397 | val_0_mse: 3.9433400630950928|  0:00:13s\n","epoch 18 | loss: 0.61788 | val_0_mse: 4.076449871063232|  0:00:13s\n","epoch 19 | loss: 0.64908 | val_0_mse: 3.3802099227905273|  0:00:14s\n","epoch 20 | loss: 0.59846 | val_0_mse: 2.3950400352478027|  0:00:15s\n","epoch 21 | loss: 0.77539 | val_0_mse: 4.730309963226318|  0:00:15s\n","epoch 22 | loss: 0.72893 | val_0_mse: 1.1357100009918213|  0:00:16s\n","epoch 23 | loss: 0.93783 | val_0_mse: 7.924910068511963|  0:00:17s\n","epoch 24 | loss: 0.77923 | val_0_mse: 1.4402799606323242|  0:00:18s\n","epoch 25 | loss: 0.71748 | val_0_mse: 4.793970108032227|  0:00:18s\n","epoch 26 | loss: 0.6522  | val_0_mse: 2.6969799995422363|  0:00:19s\n","epoch 27 | loss: 0.61038 | val_0_mse: 3.4155099391937256|  0:00:20s\n","epoch 28 | loss: 0.66308 | val_0_mse: 1.7611500024795532|  0:00:20s\n","epoch 29 | loss: 0.6286  | val_0_mse: 2.819689989089966|  0:00:21s\n","epoch 30 | loss: 0.66701 | val_0_mse: 1.4537999629974365|  0:00:22s\n","epoch 31 | loss: 0.60964 | val_0_mse: 1.9988600015640259|  0:00:23s\n","epoch 32 | loss: 0.58567 | val_0_mse: 1.8950400352478027|  0:00:23s\n","\n","Early stopping occurred at epoch 32 with best_epoch = 22 and best_val_0_mse = 1.1357100009918213\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 16:16:05,917] Trial 46 finished with value: 1.1357054710388184 and parameters: {'n_d': 24, 'n_steps': 10, 'gamma': 1.0557082265385924, 'n_independent': 2, 'n_shared': 5, 'momentum': 0.10484400693882864}. Best is trial 23 with value: 0.5507968664169312.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 31.85495| val_0_mse: 469.45721435546875|  0:00:00s\n","epoch 1  | loss: 6.4799  | val_0_mse: 424.6568908691406|  0:00:00s\n","epoch 2  | loss: 3.30761 | val_0_mse: 151.5614776611328|  0:00:01s\n","epoch 3  | loss: 1.77376 | val_0_mse: 101.4052963256836|  0:00:01s\n","epoch 4  | loss: 1.18628 | val_0_mse: 20.859130859375|  0:00:02s\n","epoch 5  | loss: 0.93184 | val_0_mse: 17.899049758911133|  0:00:02s\n","epoch 6  | loss: 0.98033 | val_0_mse: 5.61939001083374|  0:00:02s\n","epoch 7  | loss: 0.8043  | val_0_mse: 9.216349601745605|  0:00:03s\n","epoch 8  | loss: 0.74827 | val_0_mse: 5.273890018463135|  0:00:03s\n","epoch 9  | loss: 0.72041 | val_0_mse: 2.3933498859405518|  0:00:04s\n","epoch 10 | loss: 0.66307 | val_0_mse: 1.2855299711227417|  0:00:04s\n","epoch 11 | loss: 0.65042 | val_0_mse: 1.453879952430725|  0:00:04s\n","epoch 12 | loss: 0.63125 | val_0_mse: 3.0011301040649414|  0:00:05s\n","epoch 13 | loss: 0.62608 | val_0_mse: 3.224639892578125|  0:00:05s\n","epoch 14 | loss: 0.62397 | val_0_mse: 2.158479928970337|  0:00:05s\n","epoch 15 | loss: 0.5989  | val_0_mse: 1.3895299434661865|  0:00:06s\n","epoch 16 | loss: 0.6104  | val_0_mse: 1.170199990272522|  0:00:06s\n","epoch 17 | loss: 0.57356 | val_0_mse: 1.2866499423980713|  0:00:06s\n","epoch 18 | loss: 0.57111 | val_0_mse: 1.2678899765014648|  0:00:07s\n","epoch 19 | loss: 0.57007 | val_0_mse: 1.3387099504470825|  0:00:07s\n","epoch 20 | loss: 0.58918 | val_0_mse: 1.0724300146102905|  0:00:08s\n","epoch 21 | loss: 0.59084 | val_0_mse: 1.0657600164413452|  0:00:08s\n","epoch 22 | loss: 0.61663 | val_0_mse: 1.2062000036239624|  0:00:08s\n","epoch 23 | loss: 0.58822 | val_0_mse: 1.1435799598693848|  0:00:09s\n","epoch 24 | loss: 0.5758  | val_0_mse: 1.7772599458694458|  0:00:09s\n","epoch 25 | loss: 0.58782 | val_0_mse: 1.2315900325775146|  0:00:09s\n","epoch 26 | loss: 0.59734 | val_0_mse: 1.3931100368499756|  0:00:10s\n","epoch 27 | loss: 0.5521  | val_0_mse: 1.1901299953460693|  0:00:10s\n","epoch 28 | loss: 0.5579  | val_0_mse: 0.9160900115966797|  0:00:10s\n","epoch 29 | loss: 0.58498 | val_0_mse: 1.1294599771499634|  0:00:11s\n","epoch 30 | loss: 0.61787 | val_0_mse: 0.9697200059890747|  0:00:11s\n","epoch 31 | loss: 0.54497 | val_0_mse: 1.2846299409866333|  0:00:12s\n","epoch 32 | loss: 0.56022 | val_0_mse: 0.9512699842453003|  0:00:12s\n","epoch 33 | loss: 0.51938 | val_0_mse: 0.9383800029754639|  0:00:12s\n","epoch 34 | loss: 0.54784 | val_0_mse: 0.9517099857330322|  0:00:13s\n","epoch 35 | loss: 0.5235  | val_0_mse: 1.2292100191116333|  0:00:13s\n","epoch 36 | loss: 0.55552 | val_0_mse: 0.8873599767684937|  0:00:13s\n","epoch 37 | loss: 0.55018 | val_0_mse: 1.216130018234253|  0:00:14s\n","epoch 38 | loss: 0.54828 | val_0_mse: 1.0875200033187866|  0:00:14s\n","epoch 39 | loss: 0.53703 | val_0_mse: 0.8609399795532227|  0:00:15s\n","epoch 40 | loss: 0.55726 | val_0_mse: 1.1585299968719482|  0:00:15s\n","epoch 41 | loss: 0.52135 | val_0_mse: 0.9863200187683105|  0:00:15s\n","epoch 42 | loss: 0.5003  | val_0_mse: 0.8675400018692017|  0:00:16s\n","epoch 43 | loss: 0.51844 | val_0_mse: 0.8657900094985962|  0:00:16s\n","epoch 44 | loss: 0.53142 | val_0_mse: 0.9369099736213684|  0:00:16s\n","epoch 45 | loss: 0.53082 | val_0_mse: 0.7783399820327759|  0:00:17s\n","epoch 46 | loss: 0.52854 | val_0_mse: 0.9698600172996521|  0:00:17s\n","epoch 47 | loss: 0.52887 | val_0_mse: 0.9535099864006042|  0:00:18s\n","epoch 48 | loss: 0.52523 | val_0_mse: 0.8433300256729126|  0:00:18s\n","epoch 49 | loss: 0.52795 | val_0_mse: 0.7854200005531311|  0:00:18s\n","epoch 50 | loss: 0.51558 | val_0_mse: 0.7947499752044678|  0:00:19s\n","epoch 51 | loss: 0.51248 | val_0_mse: 0.7415599822998047|  0:00:19s\n","epoch 52 | loss: 0.51952 | val_0_mse: 0.8869500160217285|  0:00:19s\n","epoch 53 | loss: 0.52847 | val_0_mse: 0.8421900272369385|  0:00:20s\n","epoch 54 | loss: 0.51808 | val_0_mse: 0.6191800236701965|  0:00:20s\n","epoch 55 | loss: 0.54235 | val_0_mse: 0.8213300108909607|  0:00:20s\n","epoch 56 | loss: 0.51611 | val_0_mse: 0.7063199877738953|  0:00:21s\n","epoch 57 | loss: 0.52617 | val_0_mse: 0.667930006980896|  0:00:21s\n","epoch 58 | loss: 0.51054 | val_0_mse: 0.7214499711990356|  0:00:22s\n","epoch 59 | loss: 0.51059 | val_0_mse: 0.6743999719619751|  0:00:22s\n","epoch 60 | loss: 0.51025 | val_0_mse: 0.6662700176239014|  0:00:22s\n","epoch 61 | loss: 0.50721 | val_0_mse: 0.690530002117157|  0:00:23s\n","epoch 62 | loss: 0.51278 | val_0_mse: 0.707099974155426|  0:00:23s\n","epoch 63 | loss: 0.49427 | val_0_mse: 0.7066599726676941|  0:00:23s\n","epoch 64 | loss: 0.50916 | val_0_mse: 0.5971800088882446|  0:00:24s\n","epoch 65 | loss: 0.51157 | val_0_mse: 0.6459100246429443|  0:00:24s\n","epoch 66 | loss: 0.48242 | val_0_mse: 0.6363700032234192|  0:00:24s\n","epoch 67 | loss: 0.48588 | val_0_mse: 0.6352599859237671|  0:00:25s\n","epoch 68 | loss: 0.48877 | val_0_mse: 0.649649977684021|  0:00:25s\n","epoch 69 | loss: 0.47993 | val_0_mse: 0.6129800081253052|  0:00:26s\n","epoch 70 | loss: 0.47479 | val_0_mse: 0.6604700088500977|  0:00:26s\n","epoch 71 | loss: 0.48014 | val_0_mse: 0.6091700196266174|  0:00:26s\n","epoch 72 | loss: 0.46453 | val_0_mse: 0.6279900074005127|  0:00:27s\n","epoch 73 | loss: 0.4801  | val_0_mse: 0.6174499988555908|  0:00:27s\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 16:16:34,138] Trial 47 finished with value: 0.5971758961677551 and parameters: {'n_d': 19, 'n_steps': 6, 'gamma': 1.2867316593262554, 'n_independent': 2, 'n_shared': 3, 'momentum': 0.13064116591360905}. Best is trial 23 with value: 0.5507968664169312.\n"]},{"output_type":"stream","name":"stdout","text":["epoch 74 | loss: 0.48882 | val_0_mse: 0.6655799746513367|  0:00:27s\n","\n","Early stopping occurred at epoch 74 with best_epoch = 64 and best_val_0_mse = 0.5971800088882446\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 10.93875| val_0_mse: 770.0021362304688|  0:00:00s\n","epoch 1  | loss: 4.66644 | val_0_mse: 397.6286315917969|  0:00:00s\n","epoch 2  | loss: 3.07959 | val_0_mse: 156.56744384765625|  0:00:01s\n","epoch 3  | loss: 1.7878  | val_0_mse: 29.468339920043945|  0:00:01s\n","epoch 4  | loss: 1.39893 | val_0_mse: 18.304859161376953|  0:00:02s\n","epoch 5  | loss: 1.08314 | val_0_mse: 19.117860794067383|  0:00:02s\n","epoch 6  | loss: 0.89369 | val_0_mse: 14.517999649047852|  0:00:03s\n","epoch 7  | loss: 0.84321 | val_0_mse: 11.12909984588623|  0:00:03s\n","epoch 8  | loss: 0.8033  | val_0_mse: 7.266870021820068|  0:00:04s\n","epoch 9  | loss: 0.73167 | val_0_mse: 7.145949840545654|  0:00:04s\n","epoch 10 | loss: 0.68619 | val_0_mse: 10.798629760742188|  0:00:05s\n","epoch 11 | loss: 0.72175 | val_0_mse: 9.68828010559082|  0:00:05s\n","epoch 12 | loss: 0.70941 | val_0_mse: 6.2754998207092285|  0:00:06s\n","epoch 13 | loss: 0.95362 | val_0_mse: 5.257579803466797|  0:00:06s\n","epoch 14 | loss: 0.97051 | val_0_mse: 3.7390201091766357|  0:00:07s\n","epoch 15 | loss: 0.7998  | val_0_mse: 8.357179641723633|  0:00:07s\n","epoch 16 | loss: 0.74225 | val_0_mse: 3.4658799171447754|  0:00:08s\n","epoch 17 | loss: 0.77127 | val_0_mse: 7.025740146636963|  0:00:08s\n","epoch 18 | loss: 0.67138 | val_0_mse: 3.013590097427368|  0:00:09s\n","epoch 19 | loss: 0.70764 | val_0_mse: 3.0221099853515625|  0:00:09s\n","epoch 20 | loss: 0.65125 | val_0_mse: 2.6274900436401367|  0:00:10s\n","epoch 21 | loss: 0.6647  | val_0_mse: 2.1032299995422363|  0:00:10s\n","epoch 22 | loss: 0.65242 | val_0_mse: 2.761770009994507|  0:00:11s\n","epoch 23 | loss: 0.59712 | val_0_mse: 3.4649999141693115|  0:00:11s\n","epoch 24 | loss: 0.61753 | val_0_mse: 3.0290400981903076|  0:00:11s\n","epoch 25 | loss: 0.61156 | val_0_mse: 2.688380002975464|  0:00:12s\n","epoch 26 | loss: 0.61355 | val_0_mse: 3.0341899394989014|  0:00:12s\n","epoch 27 | loss: 0.61227 | val_0_mse: 2.290299892425537|  0:00:13s\n","epoch 28 | loss: 0.59635 | val_0_mse: 1.8019800186157227|  0:00:13s\n","epoch 29 | loss: 0.60525 | val_0_mse: 2.6621599197387695|  0:00:14s\n","epoch 30 | loss: 0.59412 | val_0_mse: 2.4345200061798096|  0:00:14s\n","epoch 31 | loss: 0.59434 | val_0_mse: 2.342129945755005|  0:00:15s\n","epoch 32 | loss: 0.59445 | val_0_mse: 2.2681100368499756|  0:00:15s\n","epoch 33 | loss: 0.63297 | val_0_mse: 1.7466200590133667|  0:00:16s\n","epoch 34 | loss: 0.63477 | val_0_mse: 1.2568000555038452|  0:00:16s\n","epoch 35 | loss: 0.61869 | val_0_mse: 1.682289958000183|  0:00:17s\n","epoch 36 | loss: 0.58771 | val_0_mse: 1.510509967803955|  0:00:17s\n","epoch 37 | loss: 0.55691 | val_0_mse: 1.4018800258636475|  0:00:18s\n","epoch 38 | loss: 0.59924 | val_0_mse: 2.2131600379943848|  0:00:18s\n","epoch 39 | loss: 0.57754 | val_0_mse: 1.663849949836731|  0:00:18s\n","epoch 40 | loss: 0.59893 | val_0_mse: 2.335360050201416|  0:00:19s\n","epoch 41 | loss: 0.5518  | val_0_mse: 1.5387699604034424|  0:00:19s\n","epoch 42 | loss: 0.55987 | val_0_mse: 1.4228299856185913|  0:00:20s\n","epoch 43 | loss: 0.56087 | val_0_mse: 1.198330044746399|  0:00:20s\n","epoch 44 | loss: 0.56576 | val_0_mse: 0.9084799885749817|  0:00:21s\n","epoch 45 | loss: 0.54715 | val_0_mse: 0.9941099882125854|  0:00:21s\n","epoch 46 | loss: 0.54358 | val_0_mse: 0.8108400106430054|  0:00:22s\n","epoch 47 | loss: 0.56946 | val_0_mse: 0.8697900176048279|  0:00:22s\n","epoch 48 | loss: 0.55003 | val_0_mse: 0.7300800085067749|  0:00:23s\n","epoch 49 | loss: 0.54733 | val_0_mse: 0.742929995059967|  0:00:23s\n","epoch 50 | loss: 0.54331 | val_0_mse: 0.760420024394989|  0:00:24s\n","epoch 51 | loss: 0.54819 | val_0_mse: 0.7220199704170227|  0:00:24s\n","epoch 52 | loss: 0.53722 | val_0_mse: 0.6989099979400635|  0:00:25s\n","epoch 53 | loss: 0.54553 | val_0_mse: 0.6993700265884399|  0:00:25s\n","epoch 54 | loss: 0.55683 | val_0_mse: 0.7607200145721436|  0:00:26s\n","epoch 55 | loss: 0.55067 | val_0_mse: 0.6716300249099731|  0:00:26s\n","epoch 56 | loss: 0.55647 | val_0_mse: 0.6783499717712402|  0:00:26s\n","epoch 57 | loss: 0.58314 | val_0_mse: 0.7790200114250183|  0:00:27s\n","epoch 58 | loss: 0.53467 | val_0_mse: 0.7491300106048584|  0:00:27s\n","epoch 59 | loss: 0.52646 | val_0_mse: 0.7059999704360962|  0:00:28s\n","epoch 60 | loss: 0.54848 | val_0_mse: 0.6604400277137756|  0:00:28s\n","epoch 61 | loss: 0.52375 | val_0_mse: 0.6707599759101868|  0:00:29s\n","epoch 62 | loss: 0.52077 | val_0_mse: 0.7050700187683105|  0:00:29s\n","epoch 63 | loss: 0.52424 | val_0_mse: 0.716480016708374|  0:00:30s\n","epoch 64 | loss: 0.52097 | val_0_mse: 0.717270016670227|  0:00:30s\n","epoch 65 | loss: 0.54107 | val_0_mse: 0.7569599747657776|  0:00:31s\n","epoch 66 | loss: 0.5377  | val_0_mse: 0.6331599950790405|  0:00:31s\n","epoch 67 | loss: 0.54159 | val_0_mse: 0.6593300104141235|  0:00:32s\n","epoch 68 | loss: 0.54534 | val_0_mse: 0.6523299813270569|  0:00:32s\n","epoch 69 | loss: 0.524   | val_0_mse: 0.6957799792289734|  0:00:33s\n","epoch 70 | loss: 0.53109 | val_0_mse: 0.6401399970054626|  0:00:33s\n","epoch 71 | loss: 0.52582 | val_0_mse: 0.6366400122642517|  0:00:33s\n","epoch 72 | loss: 0.54861 | val_0_mse: 0.7463799715042114|  0:00:34s\n","epoch 73 | loss: 0.55085 | val_0_mse: 0.6435199975967407|  0:00:34s\n","epoch 74 | loss: 0.53151 | val_0_mse: 0.6586700081825256|  0:00:35s\n","epoch 75 | loss: 0.51338 | val_0_mse: 0.6350600123405457|  0:00:35s\n","epoch 76 | loss: 0.52405 | val_0_mse: 0.6177999973297119|  0:00:36s\n","epoch 77 | loss: 0.56886 | val_0_mse: 0.6725900173187256|  0:00:36s\n","epoch 78 | loss: 0.59122 | val_0_mse: 0.6200699806213379|  0:00:37s\n","epoch 79 | loss: 0.54078 | val_0_mse: 0.6071400046348572|  0:00:37s\n","epoch 80 | loss: 0.54048 | val_0_mse: 0.6244300007820129|  0:00:38s\n","epoch 81 | loss: 0.53479 | val_0_mse: 0.5920500159263611|  0:00:38s\n","epoch 82 | loss: 0.53148 | val_0_mse: 0.626829981803894|  0:00:39s\n","epoch 83 | loss: 0.52145 | val_0_mse: 0.6111199855804443|  0:00:39s\n","epoch 84 | loss: 0.51933 | val_0_mse: 0.5975099802017212|  0:00:40s\n","epoch 85 | loss: 0.50697 | val_0_mse: 0.5992000102996826|  0:00:40s\n","epoch 86 | loss: 0.51805 | val_0_mse: 0.6077799797058105|  0:00:40s\n","epoch 87 | loss: 0.51606 | val_0_mse: 0.6040899753570557|  0:00:41s\n","epoch 88 | loss: 0.52162 | val_0_mse: 0.6144000291824341|  0:00:41s\n","epoch 89 | loss: 0.54255 | val_0_mse: 0.6531400084495544|  0:00:42s\n","epoch 90 | loss: 0.55219 | val_0_mse: 0.6383299827575684|  0:00:42s\n","epoch 91 | loss: 0.56079 | val_0_mse: 0.6673700213432312|  0:00:43s\n","\n","Early stopping occurred at epoch 91 with best_epoch = 81 and best_val_0_mse = 0.5920500159263611\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 16:17:17,747] Trial 48 finished with value: 0.5920462608337402 and parameters: {'n_d': 8, 'n_steps': 8, 'gamma': 1.203544971596887, 'n_independent': 3, 'n_shared': 2, 'momentum': 0.06929057200953435}. Best is trial 23 with value: 0.5507968664169312.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 14.34444| val_0_mse: 3073.024658203125|  0:00:00s\n","epoch 1  | loss: 3.15709 | val_0_mse: 419.5343322753906|  0:00:01s\n","epoch 2  | loss: 1.72196 | val_0_mse: 129.46255493164062|  0:00:02s\n","epoch 3  | loss: 1.43513 | val_0_mse: 60.95431900024414|  0:00:02s\n","epoch 4  | loss: 1.12743 | val_0_mse: 24.781370162963867|  0:00:03s\n","epoch 5  | loss: 0.96871 | val_0_mse: 27.591760635375977|  0:00:04s\n","epoch 6  | loss: 0.89837 | val_0_mse: 28.471879959106445|  0:00:04s\n","epoch 7  | loss: 0.78106 | val_0_mse: 21.605239868164062|  0:00:05s\n","epoch 8  | loss: 0.87412 | val_0_mse: 24.586259841918945|  0:00:06s\n","epoch 9  | loss: 0.93518 | val_0_mse: 48.458831787109375|  0:00:06s\n","epoch 10 | loss: 1.2954  | val_0_mse: 15.810330390930176|  0:00:07s\n","epoch 11 | loss: 1.10485 | val_0_mse: 24.30389976501465|  0:00:08s\n","epoch 12 | loss: 0.99289 | val_0_mse: 34.35443878173828|  0:00:08s\n","epoch 13 | loss: 0.95061 | val_0_mse: 17.036190032958984|  0:00:09s\n","epoch 14 | loss: 1.12704 | val_0_mse: 4.432469844818115|  0:00:10s\n","epoch 15 | loss: 0.77935 | val_0_mse: 5.810349941253662|  0:00:10s\n","epoch 16 | loss: 0.63289 | val_0_mse: 6.29433012008667|  0:00:11s\n","epoch 17 | loss: 0.62722 | val_0_mse: 7.849259853363037|  0:00:12s\n","epoch 18 | loss: 0.62518 | val_0_mse: 3.669610023498535|  0:00:12s\n","epoch 19 | loss: 0.64982 | val_0_mse: 6.88362979888916|  0:00:13s\n","epoch 20 | loss: 0.62884 | val_0_mse: 9.012920379638672|  0:00:14s\n","epoch 21 | loss: 0.66916 | val_0_mse: 3.7777099609375|  0:00:14s\n","epoch 22 | loss: 0.61022 | val_0_mse: 2.6780800819396973|  0:00:15s\n","epoch 23 | loss: 0.58289 | val_0_mse: 3.0845398902893066|  0:00:16s\n","epoch 24 | loss: 0.55353 | val_0_mse: 2.847259998321533|  0:00:16s\n","epoch 25 | loss: 0.55576 | val_0_mse: 2.1772100925445557|  0:00:17s\n","epoch 26 | loss: 0.56914 | val_0_mse: 1.7838900089263916|  0:00:18s\n","epoch 27 | loss: 0.54348 | val_0_mse: 1.7291500568389893|  0:00:18s\n","epoch 28 | loss: 0.55449 | val_0_mse: 3.0928399562835693|  0:00:19s\n","epoch 29 | loss: 0.66245 | val_0_mse: 1.2309399843215942|  0:00:20s\n","epoch 30 | loss: 0.74002 | val_0_mse: 6.69720983505249|  0:00:20s\n","epoch 31 | loss: 0.6379  | val_0_mse: 2.332740068435669|  0:00:21s\n","epoch 32 | loss: 0.59815 | val_0_mse: 1.5399099588394165|  0:00:22s\n","epoch 33 | loss: 0.58022 | val_0_mse: 2.021239995956421|  0:00:22s\n","epoch 34 | loss: 0.61177 | val_0_mse: 0.9448699951171875|  0:00:23s\n","epoch 35 | loss: 0.57222 | val_0_mse: 1.0745500326156616|  0:00:24s\n","epoch 36 | loss: 0.54772 | val_0_mse: 1.3239400386810303|  0:00:24s\n","epoch 37 | loss: 0.53652 | val_0_mse: 2.087430000305176|  0:00:25s\n","epoch 38 | loss: 0.53073 | val_0_mse: 1.8459700345993042|  0:00:26s\n","epoch 39 | loss: 0.53102 | val_0_mse: 0.9813100099563599|  0:00:26s\n","epoch 40 | loss: 0.5148  | val_0_mse: 1.1697200536727905|  0:00:27s\n","epoch 41 | loss: 0.52359 | val_0_mse: 1.1422100067138672|  0:00:28s\n","epoch 42 | loss: 0.52146 | val_0_mse: 0.8636999726295471|  0:00:28s\n","epoch 43 | loss: 0.50591 | val_0_mse: 0.9671000242233276|  0:00:29s\n","epoch 44 | loss: 0.51529 | val_0_mse: 1.0461699962615967|  0:00:30s\n","epoch 45 | loss: 0.50252 | val_0_mse: 0.766569972038269|  0:00:30s\n","epoch 46 | loss: 0.50187 | val_0_mse: 0.77538001537323|  0:00:31s\n","epoch 47 | loss: 0.48863 | val_0_mse: 1.2998600006103516|  0:00:32s\n","epoch 48 | loss: 0.5297  | val_0_mse: 0.912060022354126|  0:00:32s\n","epoch 49 | loss: 0.52934 | val_0_mse: 0.8300700187683105|  0:00:33s\n","epoch 50 | loss: 0.52604 | val_0_mse: 1.2850899696350098|  0:00:34s\n","epoch 51 | loss: 0.53666 | val_0_mse: 0.7529399991035461|  0:00:34s\n","epoch 52 | loss: 0.52561 | val_0_mse: 0.6804599761962891|  0:00:35s\n","epoch 53 | loss: 0.51858 | val_0_mse: 0.8548799753189087|  0:00:36s\n","epoch 54 | loss: 0.51923 | val_0_mse: 0.6423100233078003|  0:00:36s\n","epoch 55 | loss: 0.49488 | val_0_mse: 0.6611800193786621|  0:00:37s\n","epoch 56 | loss: 0.52766 | val_0_mse: 0.8453500270843506|  0:00:38s\n","epoch 57 | loss: 0.49795 | val_0_mse: 0.6160600185394287|  0:00:38s\n","epoch 58 | loss: 0.5048  | val_0_mse: 0.6083999872207642|  0:00:39s\n","epoch 59 | loss: 0.48068 | val_0_mse: 0.9000899791717529|  0:00:40s\n","epoch 60 | loss: 0.53107 | val_0_mse: 0.6614099740982056|  0:00:40s\n","epoch 61 | loss: 0.55243 | val_0_mse: 1.1116100549697876|  0:00:41s\n","epoch 62 | loss: 0.62339 | val_0_mse: 0.6217399835586548|  0:00:42s\n","epoch 63 | loss: 0.49813 | val_0_mse: 0.652400016784668|  0:00:42s\n","epoch 64 | loss: 0.46715 | val_0_mse: 0.6598299741744995|  0:00:43s\n","epoch 65 | loss: 0.47826 | val_0_mse: 0.6254799962043762|  0:00:44s\n","epoch 66 | loss: 0.47197 | val_0_mse: 0.6080499887466431|  0:00:44s\n","epoch 67 | loss: 0.47258 | val_0_mse: 0.6046800017356873|  0:00:45s\n","epoch 68 | loss: 0.48862 | val_0_mse: 0.6276100277900696|  0:00:46s\n","epoch 69 | loss: 0.46559 | val_0_mse: 0.6041200160980225|  0:00:46s\n","epoch 70 | loss: 0.48778 | val_0_mse: 0.6225699782371521|  0:00:47s\n","epoch 71 | loss: 0.51501 | val_0_mse: 0.7011200189590454|  0:00:48s\n","epoch 72 | loss: 0.55169 | val_0_mse: 0.7562199831008911|  0:00:48s\n","epoch 73 | loss: 0.57024 | val_0_mse: 0.7465000152587891|  0:00:49s\n","epoch 74 | loss: 0.59686 | val_0_mse: 0.6707299947738647|  0:00:49s\n","epoch 75 | loss: 0.48287 | val_0_mse: 0.5931900143623352|  0:00:50s\n","epoch 76 | loss: 0.45768 | val_0_mse: 0.6175699830055237|  0:00:51s\n","epoch 77 | loss: 0.4857  | val_0_mse: 0.6501700282096863|  0:00:51s\n","epoch 78 | loss: 0.51797 | val_0_mse: 0.6425099968910217|  0:00:52s\n","epoch 79 | loss: 0.50966 | val_0_mse: 0.5907599925994873|  0:00:53s\n","epoch 80 | loss: 0.55241 | val_0_mse: 0.6040499806404114|  0:00:53s\n","epoch 81 | loss: 0.5638  | val_0_mse: 0.6216899752616882|  0:00:54s\n","epoch 82 | loss: 0.59398 | val_0_mse: 0.715749979019165|  0:00:55s\n","epoch 83 | loss: 0.57718 | val_0_mse: 0.7186200022697449|  0:00:55s\n","epoch 84 | loss: 0.52953 | val_0_mse: 0.60944002866745|  0:00:56s\n","epoch 85 | loss: 0.47425 | val_0_mse: 0.5542600154876709|  0:00:57s\n","epoch 86 | loss: 0.45619 | val_0_mse: 0.5947399735450745|  0:00:57s\n","epoch 87 | loss: 0.46308 | val_0_mse: 0.5985299944877625|  0:00:58s\n","epoch 88 | loss: 0.47541 | val_0_mse: 0.6010199785232544|  0:00:59s\n","epoch 89 | loss: 0.46862 | val_0_mse: 0.5640400052070618|  0:00:59s\n","epoch 90 | loss: 0.48321 | val_0_mse: 0.5770599842071533|  0:01:00s\n","epoch 91 | loss: 0.47538 | val_0_mse: 0.6021000146865845|  0:01:01s\n","epoch 92 | loss: 0.46925 | val_0_mse: 0.6109099984169006|  0:01:01s\n","epoch 93 | loss: 0.48781 | val_0_mse: 0.5924500226974487|  0:01:02s\n","epoch 94 | loss: 0.4925  | val_0_mse: 0.61285001039505|  0:01:03s\n","epoch 95 | loss: 0.49149 | val_0_mse: 0.579010009765625|  0:01:03s\n","\n","Early stopping occurred at epoch 95 with best_epoch = 85 and best_val_0_mse = 0.5542600154876709\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 16:18:21,871] Trial 49 finished with value: 0.554256796836853 and parameters: {'n_d': 26, 'n_steps': 9, 'gamma': 1.0346502739139871, 'n_independent': 3, 'n_shared': 4, 'momentum': 0.0350391567796028}. Best is trial 23 with value: 0.5507968664169312.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 15.1966 | val_0_mse: 5781.95263671875|  0:00:00s\n","epoch 1  | loss: 4.64424 | val_0_mse: 443.1249694824219|  0:00:01s\n","epoch 2  | loss: 2.68117 | val_0_mse: 71.48526763916016|  0:00:01s\n","epoch 3  | loss: 2.04309 | val_0_mse: 332.6463623046875|  0:00:02s\n","epoch 4  | loss: 2.27614 | val_0_mse: 38.84062957763672|  0:00:03s\n","epoch 5  | loss: 1.73327 | val_0_mse: 134.0181884765625|  0:00:03s\n","epoch 6  | loss: 1.3644  | val_0_mse: 138.260009765625|  0:00:04s\n","epoch 7  | loss: 1.07733 | val_0_mse: 36.54983139038086|  0:00:05s\n","epoch 8  | loss: 0.96033 | val_0_mse: 14.716150283813477|  0:00:06s\n","epoch 9  | loss: 1.03321 | val_0_mse: 30.575109481811523|  0:00:06s\n","epoch 10 | loss: 1.45928 | val_0_mse: 25.657339096069336|  0:00:07s\n","epoch 11 | loss: 1.0778  | val_0_mse: 16.567169189453125|  0:00:08s\n","epoch 12 | loss: 0.83121 | val_0_mse: 8.327210426330566|  0:00:08s\n","epoch 13 | loss: 0.97699 | val_0_mse: 2.9419500827789307|  0:00:09s\n","epoch 14 | loss: 0.7939  | val_0_mse: 5.155660152435303|  0:00:10s\n","epoch 15 | loss: 0.88888 | val_0_mse: 7.6573100090026855|  0:00:10s\n","epoch 16 | loss: 0.97408 | val_0_mse: 2.4856200218200684|  0:00:11s\n","epoch 17 | loss: 0.80207 | val_0_mse: 6.459980010986328|  0:00:11s\n","epoch 18 | loss: 0.75099 | val_0_mse: 1.282189965248108|  0:00:12s\n","epoch 19 | loss: 0.86059 | val_0_mse: 5.066919803619385|  0:00:13s\n","epoch 20 | loss: 0.95131 | val_0_mse: 1.6108200550079346|  0:00:13s\n","epoch 21 | loss: 0.85882 | val_0_mse: 7.774960041046143|  0:00:14s\n","epoch 22 | loss: 0.69871 | val_0_mse: 4.613540172576904|  0:00:15s\n","epoch 23 | loss: 0.65541 | val_0_mse: 1.666290044784546|  0:00:15s\n","epoch 24 | loss: 0.63504 | val_0_mse: 3.058190107345581|  0:00:16s\n","epoch 25 | loss: 0.61297 | val_0_mse: 2.2989799976348877|  0:00:17s\n","epoch 26 | loss: 0.59838 | val_0_mse: 1.2694200277328491|  0:00:17s\n","epoch 27 | loss: 0.60121 | val_0_mse: 1.9839400053024292|  0:00:18s\n","epoch 28 | loss: 0.59093 | val_0_mse: 1.9402400255203247|  0:00:19s\n","epoch 29 | loss: 0.62068 | val_0_mse: 1.5043599605560303|  0:00:19s\n","epoch 30 | loss: 0.56968 | val_0_mse: 1.6066299676895142|  0:00:20s\n","epoch 31 | loss: 0.55782 | val_0_mse: 1.2587599754333496|  0:00:21s\n","epoch 32 | loss: 0.57189 | val_0_mse: 1.2620600461959839|  0:00:21s\n","epoch 33 | loss: 0.60675 | val_0_mse: 1.7821099758148193|  0:00:22s\n","epoch 34 | loss: 0.59124 | val_0_mse: 1.2619400024414062|  0:00:23s\n","epoch 35 | loss: 0.66664 | val_0_mse: 2.363029956817627|  0:00:23s\n","epoch 36 | loss: 0.58724 | val_0_mse: 1.7914199829101562|  0:00:24s\n","epoch 37 | loss: 0.59302 | val_0_mse: 1.3807599544525146|  0:00:25s\n","epoch 38 | loss: 0.54432 | val_0_mse: 1.2511600255966187|  0:00:25s\n","epoch 39 | loss: 0.54753 | val_0_mse: 1.0991100072860718|  0:00:26s\n","epoch 40 | loss: 0.52803 | val_0_mse: 1.170490026473999|  0:00:27s\n","epoch 41 | loss: 0.55044 | val_0_mse: 1.1885900497436523|  0:00:27s\n","epoch 42 | loss: 0.57018 | val_0_mse: 0.7853699922561646|  0:00:28s\n","epoch 43 | loss: 0.56284 | val_0_mse: 0.9827899932861328|  0:00:29s\n","epoch 44 | loss: 0.54306 | val_0_mse: 0.992579996585846|  0:00:29s\n","epoch 45 | loss: 0.53416 | val_0_mse: 0.8234000205993652|  0:00:30s\n","epoch 46 | loss: 0.53164 | val_0_mse: 0.7850199937820435|  0:00:31s\n","epoch 47 | loss: 0.52563 | val_0_mse: 0.7630100250244141|  0:00:31s\n","epoch 48 | loss: 0.52564 | val_0_mse: 0.7130299806594849|  0:00:32s\n","epoch 49 | loss: 0.53065 | val_0_mse: 0.7195199728012085|  0:00:33s\n","epoch 50 | loss: 0.52545 | val_0_mse: 0.780430018901825|  0:00:33s\n","epoch 51 | loss: 0.52061 | val_0_mse: 0.7373300194740295|  0:00:34s\n","epoch 52 | loss: 0.53117 | val_0_mse: 0.649940013885498|  0:00:34s\n","epoch 53 | loss: 0.55546 | val_0_mse: 1.020419955253601|  0:00:35s\n","epoch 54 | loss: 0.53681 | val_0_mse: 0.7151600122451782|  0:00:36s\n","epoch 55 | loss: 0.61201 | val_0_mse: 1.034309983253479|  0:00:37s\n","epoch 56 | loss: 0.55516 | val_0_mse: 0.7770100235939026|  0:00:37s\n","epoch 57 | loss: 0.51305 | val_0_mse: 0.6731699705123901|  0:00:38s\n","epoch 58 | loss: 0.51981 | val_0_mse: 0.7281100153923035|  0:00:39s\n","epoch 59 | loss: 0.55673 | val_0_mse: 0.7772200107574463|  0:00:39s\n","epoch 60 | loss: 0.50452 | val_0_mse: 0.602840006351471|  0:00:40s\n","epoch 61 | loss: 0.51869 | val_0_mse: 0.7532600164413452|  0:00:41s\n","epoch 62 | loss: 0.56641 | val_0_mse: 0.678380012512207|  0:00:41s\n","epoch 63 | loss: 0.51529 | val_0_mse: 0.6026600003242493|  0:00:42s\n","epoch 64 | loss: 0.50601 | val_0_mse: 0.6998599767684937|  0:00:43s\n","epoch 65 | loss: 0.49498 | val_0_mse: 0.6264899969100952|  0:00:43s\n","epoch 66 | loss: 0.49868 | val_0_mse: 0.6732199788093567|  0:00:44s\n","epoch 67 | loss: 0.50485 | val_0_mse: 0.6404500007629395|  0:00:44s\n","epoch 68 | loss: 0.51691 | val_0_mse: 0.6426900029182434|  0:00:45s\n","epoch 69 | loss: 0.4925  | val_0_mse: 0.6356800198554993|  0:00:46s\n","epoch 70 | loss: 0.52346 | val_0_mse: 0.663670003414154|  0:00:46s\n","epoch 71 | loss: 0.51821 | val_0_mse: 0.639270007610321|  0:00:47s\n","epoch 72 | loss: 0.52222 | val_0_mse: 0.7529399991035461|  0:00:48s\n","epoch 73 | loss: 0.5145  | val_0_mse: 0.6723499894142151|  0:00:48s\n","\n","Early stopping occurred at epoch 73 with best_epoch = 63 and best_val_0_mse = 0.6026600003242493\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 16:19:11,218] Trial 50 finished with value: 0.6026580333709717 and parameters: {'n_d': 26, 'n_steps': 9, 'gamma': 1.0360801419318129, 'n_independent': 3, 'n_shared': 4, 'momentum': 0.03107419630483494}. Best is trial 23 with value: 0.5507968664169312.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 20.0286 | val_0_mse: 2509.458984375|  0:00:00s\n","epoch 1  | loss: 6.04505 | val_0_mse: 281.4534606933594|  0:00:01s\n","epoch 2  | loss: 2.65149 | val_0_mse: 169.66543579101562|  0:00:02s\n","epoch 3  | loss: 1.66144 | val_0_mse: 88.60363006591797|  0:00:02s\n","epoch 4  | loss: 1.32738 | val_0_mse: 37.37253952026367|  0:00:03s\n","epoch 5  | loss: 1.05611 | val_0_mse: 26.077579498291016|  0:00:04s\n","epoch 6  | loss: 0.94518 | val_0_mse: 8.668359756469727|  0:00:04s\n","epoch 7  | loss: 0.8767  | val_0_mse: 13.19845962524414|  0:00:05s\n","epoch 8  | loss: 0.9341  | val_0_mse: 12.391349792480469|  0:00:06s\n","epoch 9  | loss: 0.8642  | val_0_mse: 16.2733097076416|  0:00:06s\n","epoch 10 | loss: 0.97721 | val_0_mse: 7.771719932556152|  0:00:07s\n","epoch 11 | loss: 0.90544 | val_0_mse: 7.495989799499512|  0:00:08s\n","epoch 12 | loss: 0.72479 | val_0_mse: 4.70920991897583|  0:00:08s\n","epoch 13 | loss: 0.74257 | val_0_mse: 6.271669864654541|  0:00:09s\n","epoch 14 | loss: 0.66269 | val_0_mse: 5.537869930267334|  0:00:10s\n","epoch 15 | loss: 0.63251 | val_0_mse: 5.481410026550293|  0:00:10s\n","epoch 16 | loss: 0.61757 | val_0_mse: 3.8262100219726562|  0:00:11s\n","epoch 17 | loss: 0.60941 | val_0_mse: 3.638590097427368|  0:00:11s\n","epoch 18 | loss: 0.58458 | val_0_mse: 4.218299865722656|  0:00:12s\n","epoch 19 | loss: 0.59972 | val_0_mse: 6.088250160217285|  0:00:13s\n","epoch 20 | loss: 0.58047 | val_0_mse: 5.252029895782471|  0:00:14s\n","epoch 21 | loss: 0.58324 | val_0_mse: 6.55525016784668|  0:00:14s\n","epoch 22 | loss: 0.5836  | val_0_mse: 3.740760087966919|  0:00:15s\n","epoch 23 | loss: 0.56993 | val_0_mse: 2.477289915084839|  0:00:15s\n","epoch 24 | loss: 0.60285 | val_0_mse: 1.5239399671554565|  0:00:16s\n","epoch 25 | loss: 0.58508 | val_0_mse: 1.7953699827194214|  0:00:17s\n","epoch 26 | loss: 0.5667  | val_0_mse: 2.6364400386810303|  0:00:17s\n","epoch 27 | loss: 0.57017 | val_0_mse: 1.4074699878692627|  0:00:18s\n","epoch 28 | loss: 0.63546 | val_0_mse: 2.5766000747680664|  0:00:19s\n","epoch 29 | loss: 0.64283 | val_0_mse: 1.2779099941253662|  0:00:20s\n","epoch 30 | loss: 0.64181 | val_0_mse: 1.2758400440216064|  0:00:20s\n","epoch 31 | loss: 0.64388 | val_0_mse: 2.29544997215271|  0:00:21s\n","epoch 32 | loss: 0.60376 | val_0_mse: 2.1104400157928467|  0:00:22s\n","epoch 33 | loss: 0.56207 | val_0_mse: 1.3212900161743164|  0:00:22s\n","epoch 34 | loss: 0.59624 | val_0_mse: 1.287310004234314|  0:00:23s\n","epoch 35 | loss: 0.60978 | val_0_mse: 1.6081600189208984|  0:00:24s\n","epoch 36 | loss: 0.59991 | val_0_mse: 0.9047999978065491|  0:00:24s\n","epoch 37 | loss: 0.59738 | val_0_mse: 1.0967400074005127|  0:00:25s\n","epoch 38 | loss: 0.58319 | val_0_mse: 1.1234699487686157|  0:00:26s\n","epoch 39 | loss: 0.54166 | val_0_mse: 1.5625799894332886|  0:00:26s\n","epoch 40 | loss: 0.54964 | val_0_mse: 1.5387500524520874|  0:00:27s\n","epoch 41 | loss: 0.57672 | val_0_mse: 1.2265599966049194|  0:00:27s\n","epoch 42 | loss: 0.57312 | val_0_mse: 0.8108400106430054|  0:00:28s\n","epoch 43 | loss: 0.59026 | val_0_mse: 1.3885600566864014|  0:00:29s\n","epoch 44 | loss: 0.59315 | val_0_mse: 1.6360599994659424|  0:00:29s\n","epoch 45 | loss: 0.5919  | val_0_mse: 0.7442600131034851|  0:00:30s\n","epoch 46 | loss: 0.60703 | val_0_mse: 1.5751399993896484|  0:00:31s\n","epoch 47 | loss: 0.61231 | val_0_mse: 0.7264999747276306|  0:00:31s\n","epoch 48 | loss: 0.64348 | val_0_mse: 1.7435799837112427|  0:00:32s\n","epoch 49 | loss: 0.66296 | val_0_mse: 0.6927199959754944|  0:00:33s\n","epoch 50 | loss: 0.67913 | val_0_mse: 1.486549973487854|  0:00:33s\n","epoch 51 | loss: 0.63494 | val_0_mse: 0.7212799787521362|  0:00:34s\n","epoch 52 | loss: 0.57302 | val_0_mse: 1.0694500207901|  0:00:35s\n","epoch 53 | loss: 0.62298 | val_0_mse: 0.6680399775505066|  0:00:35s\n","epoch 54 | loss: 0.70764 | val_0_mse: 1.2958500385284424|  0:00:36s\n","epoch 55 | loss: 0.64736 | val_0_mse: 0.6516299843788147|  0:00:37s\n","epoch 56 | loss: 0.62144 | val_0_mse: 1.2541799545288086|  0:00:37s\n","epoch 57 | loss: 0.64562 | val_0_mse: 0.6571800112724304|  0:00:38s\n","epoch 58 | loss: 0.60622 | val_0_mse: 0.9457499980926514|  0:00:39s\n","epoch 59 | loss: 0.58309 | val_0_mse: 0.6585999727249146|  0:00:39s\n","epoch 60 | loss: 0.62541 | val_0_mse: 0.9233400225639343|  0:00:40s\n","epoch 61 | loss: 0.59401 | val_0_mse: 0.724370002746582|  0:00:41s\n","epoch 62 | loss: 0.71467 | val_0_mse: 0.7206599712371826|  0:00:41s\n","epoch 63 | loss: 0.64167 | val_0_mse: 0.7223399877548218|  0:00:42s\n","epoch 64 | loss: 0.61777 | val_0_mse: 0.6678299903869629|  0:00:43s\n","epoch 65 | loss: 0.59765 | val_0_mse: 0.7592899799346924|  0:00:43s\n","\n","Early stopping occurred at epoch 65 with best_epoch = 55 and best_val_0_mse = 0.6516299843788147\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 16:19:55,331] Trial 51 finished with value: 0.6516291499137878 and parameters: {'n_d': 21, 'n_steps': 9, 'gamma': 1.1656357140727192, 'n_independent': 3, 'n_shared': 4, 'momentum': 0.044430844642891126}. Best is trial 23 with value: 0.5507968664169312.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 16.80429| val_0_mse: 1050.7899169921875|  0:00:00s\n","epoch 1  | loss: 4.76714 | val_0_mse: 334.4390563964844|  0:00:01s\n","epoch 2  | loss: 2.60443 | val_0_mse: 149.53846740722656|  0:00:02s\n","epoch 3  | loss: 1.94052 | val_0_mse: 121.75914764404297|  0:00:02s\n","epoch 4  | loss: 1.57514 | val_0_mse: 59.458988189697266|  0:00:03s\n","epoch 5  | loss: 1.29649 | val_0_mse: 264.9696044921875|  0:00:04s\n","epoch 6  | loss: 1.14766 | val_0_mse: 80.71849822998047|  0:00:05s\n","epoch 7  | loss: 1.2736  | val_0_mse: 115.45189666748047|  0:00:05s\n","epoch 8  | loss: 1.75832 | val_0_mse: 18.613040924072266|  0:00:06s\n","epoch 9  | loss: 1.61635 | val_0_mse: 31.413890838623047|  0:00:07s\n","epoch 10 | loss: 1.93036 | val_0_mse: 16.170040130615234|  0:00:08s\n","epoch 11 | loss: 0.95541 | val_0_mse: 19.449039459228516|  0:00:08s\n","epoch 12 | loss: 0.83871 | val_0_mse: 14.131560325622559|  0:00:09s\n","epoch 13 | loss: 0.8242  | val_0_mse: 18.68242073059082|  0:00:10s\n","epoch 14 | loss: 0.84116 | val_0_mse: 7.491209983825684|  0:00:11s\n","epoch 15 | loss: 1.38217 | val_0_mse: 17.806249618530273|  0:00:11s\n","epoch 16 | loss: 1.47395 | val_0_mse: 6.318610191345215|  0:00:12s\n","epoch 17 | loss: 1.52195 | val_0_mse: 29.635299682617188|  0:00:13s\n","epoch 18 | loss: 1.48375 | val_0_mse: 18.161659240722656|  0:00:14s\n","epoch 19 | loss: 0.85731 | val_0_mse: 19.328580856323242|  0:00:14s\n","epoch 20 | loss: 0.9269  | val_0_mse: 11.619460105895996|  0:00:15s\n","epoch 21 | loss: 0.92355 | val_0_mse: 2.22367000579834|  0:00:16s\n","epoch 22 | loss: 0.90985 | val_0_mse: 10.37401008605957|  0:00:17s\n","epoch 23 | loss: 0.83774 | val_0_mse: 1.6035399436950684|  0:00:17s\n","epoch 24 | loss: 0.87914 | val_0_mse: 3.265820026397705|  0:00:18s\n","epoch 25 | loss: 0.70834 | val_0_mse: 1.2217600345611572|  0:00:19s\n","epoch 26 | loss: 0.73019 | val_0_mse: 2.8329598903656006|  0:00:19s\n","epoch 27 | loss: 0.6458  | val_0_mse: 1.3599900007247925|  0:00:20s\n","epoch 28 | loss: 0.64139 | val_0_mse: 2.350950002670288|  0:00:21s\n","epoch 29 | loss: 0.56591 | val_0_mse: 2.0215799808502197|  0:00:22s\n","epoch 30 | loss: 0.56624 | val_0_mse: 1.3585000038146973|  0:00:22s\n","epoch 31 | loss: 0.56743 | val_0_mse: 1.4216699600219727|  0:00:23s\n","epoch 32 | loss: 0.59863 | val_0_mse: 1.2983100414276123|  0:00:24s\n","epoch 33 | loss: 0.57278 | val_0_mse: 1.2053600549697876|  0:00:24s\n","epoch 34 | loss: 0.58661 | val_0_mse: 1.666509985923767|  0:00:25s\n","epoch 35 | loss: 0.58341 | val_0_mse: 1.9951000213623047|  0:00:26s\n","epoch 36 | loss: 0.57863 | val_0_mse: 1.16975998878479|  0:00:27s\n","epoch 37 | loss: 0.57894 | val_0_mse: 2.030639886856079|  0:00:27s\n","epoch 38 | loss: 0.57272 | val_0_mse: 1.0536400079727173|  0:00:28s\n","epoch 39 | loss: 0.58609 | val_0_mse: 1.2387499809265137|  0:00:29s\n","epoch 40 | loss: 0.5673  | val_0_mse: 1.4080100059509277|  0:00:29s\n","epoch 41 | loss: 0.60439 | val_0_mse: 0.8513000011444092|  0:00:30s\n","epoch 42 | loss: 0.60715 | val_0_mse: 1.680359959602356|  0:00:31s\n","epoch 43 | loss: 0.57655 | val_0_mse: 0.873740017414093|  0:00:32s\n","epoch 44 | loss: 0.55152 | val_0_mse: 1.3250600099563599|  0:00:32s\n","epoch 45 | loss: 0.55228 | val_0_mse: 0.8458399772644043|  0:00:33s\n","epoch 46 | loss: 0.5521  | val_0_mse: 0.9605699777603149|  0:00:34s\n","epoch 47 | loss: 0.53795 | val_0_mse: 1.0759400129318237|  0:00:34s\n","epoch 48 | loss: 0.52068 | val_0_mse: 0.8957499861717224|  0:00:35s\n","epoch 49 | loss: 0.52591 | val_0_mse: 0.9503999948501587|  0:00:36s\n","epoch 50 | loss: 0.54051 | val_0_mse: 0.8919699788093567|  0:00:37s\n","epoch 51 | loss: 0.53865 | val_0_mse: 1.238379955291748|  0:00:37s\n","epoch 52 | loss: 0.62738 | val_0_mse: 0.7623100280761719|  0:00:38s\n","epoch 53 | loss: 0.53112 | val_0_mse: 0.8970299959182739|  0:00:39s\n","epoch 54 | loss: 0.53902 | val_0_mse: 0.9720500111579895|  0:00:39s\n","epoch 55 | loss: 0.52867 | val_0_mse: 0.6542500257492065|  0:00:40s\n","epoch 56 | loss: 0.56661 | val_0_mse: 1.1170200109481812|  0:00:41s\n","epoch 57 | loss: 0.57055 | val_0_mse: 0.6816800236701965|  0:00:42s\n","epoch 58 | loss: 0.56301 | val_0_mse: 1.0604599714279175|  0:00:42s\n","epoch 59 | loss: 0.58105 | val_0_mse: 0.6447499990463257|  0:00:43s\n","epoch 60 | loss: 0.57824 | val_0_mse: 1.1975300312042236|  0:00:44s\n","epoch 61 | loss: 0.59313 | val_0_mse: 0.6218600273132324|  0:00:44s\n","epoch 62 | loss: 0.54841 | val_0_mse: 0.7633699774742126|  0:00:45s\n","epoch 63 | loss: 0.51849 | val_0_mse: 0.7750899791717529|  0:00:46s\n","epoch 64 | loss: 0.50827 | val_0_mse: 0.7002400159835815|  0:00:47s\n","epoch 65 | loss: 0.49618 | val_0_mse: 0.7141500115394592|  0:00:47s\n","epoch 66 | loss: 0.49283 | val_0_mse: 0.6386100053787231|  0:00:48s\n","epoch 67 | loss: 0.48588 | val_0_mse: 0.660040020942688|  0:00:49s\n","epoch 68 | loss: 0.49741 | val_0_mse: 0.6532300114631653|  0:00:49s\n","epoch 69 | loss: 0.49105 | val_0_mse: 0.6688299775123596|  0:00:50s\n","epoch 70 | loss: 0.51561 | val_0_mse: 0.6172099709510803|  0:00:51s\n","epoch 71 | loss: 0.54339 | val_0_mse: 0.7536200284957886|  0:00:52s\n","epoch 72 | loss: 0.5227  | val_0_mse: 0.6332499980926514|  0:00:52s\n","epoch 73 | loss: 0.52715 | val_0_mse: 0.7205399870872498|  0:00:53s\n","epoch 74 | loss: 0.50759 | val_0_mse: 0.5887500047683716|  0:00:54s\n","epoch 75 | loss: 0.50124 | val_0_mse: 0.6209099888801575|  0:00:55s\n","epoch 76 | loss: 0.48074 | val_0_mse: 0.6307100057601929|  0:00:55s\n","epoch 77 | loss: 0.4922  | val_0_mse: 0.6462799906730652|  0:00:56s\n","epoch 78 | loss: 0.49286 | val_0_mse: 0.6252599954605103|  0:00:57s\n","epoch 79 | loss: 0.48105 | val_0_mse: 0.5937899947166443|  0:00:57s\n","epoch 80 | loss: 0.48018 | val_0_mse: 0.6479700207710266|  0:00:58s\n","epoch 81 | loss: 0.48545 | val_0_mse: 0.5986700057983398|  0:00:59s\n","epoch 82 | loss: 0.48784 | val_0_mse: 0.6095399856567383|  0:01:00s\n","epoch 83 | loss: 0.48407 | val_0_mse: 0.5759599804878235|  0:01:00s\n","epoch 84 | loss: 0.48906 | val_0_mse: 0.6018099784851074|  0:01:01s\n","epoch 85 | loss: 0.50452 | val_0_mse: 0.6033599972724915|  0:01:02s\n","epoch 86 | loss: 0.4919  | val_0_mse: 0.6269299983978271|  0:01:02s\n","epoch 87 | loss: 0.48318 | val_0_mse: 0.5760200023651123|  0:01:03s\n","epoch 88 | loss: 0.4773  | val_0_mse: 0.5748900175094604|  0:01:04s\n","epoch 89 | loss: 0.49289 | val_0_mse: 0.5680000185966492|  0:01:05s\n","epoch 90 | loss: 0.48268 | val_0_mse: 0.5667999982833862|  0:01:05s\n","epoch 91 | loss: 0.47747 | val_0_mse: 0.5925599932670593|  0:01:06s\n","epoch 92 | loss: 0.48635 | val_0_mse: 0.5848600268363953|  0:01:07s\n","epoch 93 | loss: 0.48043 | val_0_mse: 0.5700200200080872|  0:01:07s\n","epoch 94 | loss: 0.472   | val_0_mse: 0.587939977645874|  0:01:08s\n","epoch 95 | loss: 0.47847 | val_0_mse: 0.567300021648407|  0:01:09s\n","epoch 96 | loss: 0.48111 | val_0_mse: 0.580299973487854|  0:01:10s\n","epoch 97 | loss: 0.49122 | val_0_mse: 0.573170006275177|  0:01:10s\n","epoch 98 | loss: 0.46927 | val_0_mse: 0.5866100192070007|  0:01:11s\n","epoch 99 | loss: 0.47817 | val_0_mse: 0.5606399774551392|  0:01:12s\n","Stop training because you reached max_epochs = 100 with best_epoch = 99 and best_val_0_mse = 0.5606399774551392\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 16:21:08,081] Trial 52 finished with value: 0.560636579990387 and parameters: {'n_d': 17, 'n_steps': 10, 'gamma': 1.032898098836825, 'n_independent': 4, 'n_shared': 3, 'momentum': 0.057427814372847316}. Best is trial 23 with value: 0.5507968664169312.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 20.73033| val_0_mse: 6316.09130859375|  0:00:00s\n","epoch 1  | loss: 4.61574 | val_0_mse: 472.7593078613281|  0:00:01s\n","epoch 2  | loss: 2.06287 | val_0_mse: 396.4068908691406|  0:00:01s\n","epoch 3  | loss: 1.42786 | val_0_mse: 45.79486083984375|  0:00:02s\n","epoch 4  | loss: 1.15972 | val_0_mse: 48.14894104003906|  0:00:03s\n","epoch 5  | loss: 1.0416  | val_0_mse: 68.24842071533203|  0:00:03s\n","epoch 6  | loss: 0.85903 | val_0_mse: 87.16439819335938|  0:00:04s\n","epoch 7  | loss: 0.81707 | val_0_mse: 31.011550903320312|  0:00:04s\n","epoch 8  | loss: 0.74151 | val_0_mse: 35.41205978393555|  0:00:05s\n","epoch 9  | loss: 0.80387 | val_0_mse: 57.26993942260742|  0:00:06s\n","epoch 10 | loss: 0.74143 | val_0_mse: 22.786819458007812|  0:00:06s\n","epoch 11 | loss: 0.72361 | val_0_mse: 13.250840187072754|  0:00:07s\n","epoch 12 | loss: 0.67063 | val_0_mse: 16.092140197753906|  0:00:07s\n","epoch 13 | loss: 0.6986  | val_0_mse: 11.951080322265625|  0:00:08s\n","epoch 14 | loss: 0.81607 | val_0_mse: 7.8338398933410645|  0:00:09s\n","epoch 15 | loss: 0.67768 | val_0_mse: 8.805089950561523|  0:00:09s\n","epoch 16 | loss: 0.68228 | val_0_mse: 5.121779918670654|  0:00:10s\n","epoch 17 | loss: 0.74379 | val_0_mse: 8.292149543762207|  0:00:11s\n","epoch 18 | loss: 0.6433  | val_0_mse: 6.0884599685668945|  0:00:11s\n","epoch 19 | loss: 0.59516 | val_0_mse: 5.1363301277160645|  0:00:12s\n","epoch 20 | loss: 0.58502 | val_0_mse: 4.944640159606934|  0:00:12s\n","epoch 21 | loss: 0.59755 | val_0_mse: 2.261359930038452|  0:00:13s\n","epoch 22 | loss: 0.62104 | val_0_mse: 2.1961100101470947|  0:00:14s\n","epoch 23 | loss: 0.59154 | val_0_mse: 2.9123899936676025|  0:00:14s\n","epoch 24 | loss: 0.6474  | val_0_mse: 1.738420009613037|  0:00:15s\n","epoch 25 | loss: 0.56672 | val_0_mse: 2.0303399562835693|  0:00:15s\n","epoch 26 | loss: 0.55357 | val_0_mse: 1.5617200136184692|  0:00:16s\n","epoch 27 | loss: 0.55728 | val_0_mse: 1.3963199853897095|  0:00:17s\n","epoch 28 | loss: 0.53697 | val_0_mse: 0.909600019454956|  0:00:17s\n","epoch 29 | loss: 0.54647 | val_0_mse: 1.6629300117492676|  0:00:18s\n","epoch 30 | loss: 0.54624 | val_0_mse: 1.1408599615097046|  0:00:18s\n","epoch 31 | loss: 0.53862 | val_0_mse: 1.166599988937378|  0:00:19s\n","epoch 32 | loss: 0.52136 | val_0_mse: 1.3077499866485596|  0:00:20s\n","epoch 33 | loss: 0.52361 | val_0_mse: 1.0918999910354614|  0:00:20s\n","epoch 34 | loss: 0.5233  | val_0_mse: 0.9220799803733826|  0:00:21s\n","epoch 35 | loss: 0.52742 | val_0_mse: 1.2766599655151367|  0:00:21s\n","epoch 36 | loss: 0.53546 | val_0_mse: 1.9022200107574463|  0:00:22s\n","epoch 37 | loss: 0.58544 | val_0_mse: 1.113420009613037|  0:00:23s\n","epoch 38 | loss: 0.55652 | val_0_mse: 1.093999981880188|  0:00:23s\n","\n","Early stopping occurred at epoch 38 with best_epoch = 28 and best_val_0_mse = 0.909600019454956\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 16:21:32,109] Trial 53 finished with value: 0.909604549407959 and parameters: {'n_d': 18, 'n_steps': 8, 'gamma': 1.0305617472110298, 'n_independent': 4, 'n_shared': 3, 'momentum': 0.02006848505611578}. Best is trial 23 with value: 0.5507968664169312.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 26.12999| val_0_mse: 936.1632690429688|  0:00:00s\n","epoch 1  | loss: 5.35746 | val_0_mse: 341.6122741699219|  0:00:01s\n","epoch 2  | loss: 2.62804 | val_0_mse: 113.41773223876953|  0:00:02s\n","epoch 3  | loss: 1.71496 | val_0_mse: 169.92648315429688|  0:00:02s\n","epoch 4  | loss: 1.59855 | val_0_mse: 45.37733840942383|  0:00:03s\n","epoch 5  | loss: 1.60089 | val_0_mse: 59.00873947143555|  0:00:03s\n","epoch 6  | loss: 1.18524 | val_0_mse: 34.01959991455078|  0:00:04s\n","epoch 7  | loss: 1.07867 | val_0_mse: 33.79545974731445|  0:00:05s\n","epoch 8  | loss: 0.91136 | val_0_mse: 37.087371826171875|  0:00:05s\n","epoch 9  | loss: 0.80019 | val_0_mse: 12.547050476074219|  0:00:06s\n","epoch 10 | loss: 0.79021 | val_0_mse: 2.6758298873901367|  0:00:07s\n","epoch 11 | loss: 0.72886 | val_0_mse: 1.6722899675369263|  0:00:07s\n","epoch 12 | loss: 0.72274 | val_0_mse: 35.42790985107422|  0:00:08s\n","epoch 13 | loss: 0.80359 | val_0_mse: 18.82887077331543|  0:00:09s\n","epoch 14 | loss: 0.77283 | val_0_mse: 13.999580383300781|  0:00:10s\n","epoch 15 | loss: 0.73308 | val_0_mse: 11.369409561157227|  0:00:10s\n","epoch 16 | loss: 0.77719 | val_0_mse: 3.8657500743865967|  0:00:11s\n","epoch 17 | loss: 0.90919 | val_0_mse: 4.98652982711792|  0:00:11s\n","epoch 18 | loss: 0.64605 | val_0_mse: 4.537179946899414|  0:00:12s\n","epoch 19 | loss: 0.61523 | val_0_mse: 5.797460079193115|  0:00:13s\n","epoch 20 | loss: 0.59159 | val_0_mse: 3.4888999462127686|  0:00:13s\n","epoch 21 | loss: 0.58241 | val_0_mse: 4.590939998626709|  0:00:14s\n","\n","Early stopping occurred at epoch 21 with best_epoch = 11 and best_val_0_mse = 1.6722899675369263\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 16:21:47,111] Trial 54 finished with value: 1.672293782234192 and parameters: {'n_d': 27, 'n_steps': 9, 'gamma': 1.1014551973329127, 'n_independent': 4, 'n_shared': 3, 'momentum': 0.059605240705861796}. Best is trial 23 with value: 0.5507968664169312.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 32.35325| val_0_mse: 1664.94482421875|  0:00:00s\n","epoch 1  | loss: 6.16345 | val_0_mse: 431.38397216796875|  0:00:01s\n","epoch 2  | loss: 3.07905 | val_0_mse: 277.53668212890625|  0:00:01s\n","epoch 3  | loss: 1.88642 | val_0_mse: 69.98648071289062|  0:00:02s\n","epoch 4  | loss: 1.73828 | val_0_mse: 67.66502380371094|  0:00:03s\n","epoch 5  | loss: 2.39086 | val_0_mse: 134.12799072265625|  0:00:03s\n","epoch 6  | loss: 2.46767 | val_0_mse: 21.664119720458984|  0:00:04s\n","epoch 7  | loss: 1.26118 | val_0_mse: 54.42729949951172|  0:00:05s\n","epoch 8  | loss: 1.12043 | val_0_mse: 26.332250595092773|  0:00:05s\n","epoch 9  | loss: 0.87517 | val_0_mse: 31.86595916748047|  0:00:06s\n","epoch 10 | loss: 0.80533 | val_0_mse: 20.457979202270508|  0:00:06s\n","epoch 11 | loss: 1.03108 | val_0_mse: 15.2298002243042|  0:00:07s\n","epoch 12 | loss: 0.85215 | val_0_mse: 8.923430442810059|  0:00:08s\n","epoch 13 | loss: 0.88017 | val_0_mse: 6.298689842224121|  0:00:08s\n","epoch 14 | loss: 0.96457 | val_0_mse: 12.371060371398926|  0:00:09s\n","epoch 15 | loss: 0.72835 | val_0_mse: 4.609280109405518|  0:00:09s\n","epoch 16 | loss: 0.64589 | val_0_mse: 5.925149917602539|  0:00:10s\n","epoch 17 | loss: 0.61997 | val_0_mse: 9.342840194702148|  0:00:11s\n","epoch 18 | loss: 0.69013 | val_0_mse: 6.316659927368164|  0:00:11s\n","epoch 19 | loss: 0.66058 | val_0_mse: 5.269979953765869|  0:00:12s\n","epoch 20 | loss: 0.6427  | val_0_mse: 2.522979974746704|  0:00:12s\n","epoch 21 | loss: 0.64093 | val_0_mse: 2.2139699459075928|  0:00:13s\n","epoch 22 | loss: 0.62025 | val_0_mse: 1.5865800380706787|  0:00:14s\n","epoch 23 | loss: 0.6816  | val_0_mse: 2.1736700534820557|  0:00:14s\n","epoch 24 | loss: 0.60917 | val_0_mse: 2.338469982147217|  0:00:15s\n","epoch 25 | loss: 0.58043 | val_0_mse: 2.4729299545288086|  0:00:15s\n","epoch 26 | loss: 0.56359 | val_0_mse: 2.6570401191711426|  0:00:16s\n","epoch 27 | loss: 0.55733 | val_0_mse: 1.662559986114502|  0:00:17s\n","epoch 28 | loss: 0.53415 | val_0_mse: 1.2395800352096558|  0:00:17s\n","epoch 29 | loss: 0.56232 | val_0_mse: 1.6866199970245361|  0:00:18s\n","epoch 30 | loss: 0.56307 | val_0_mse: 1.6053800582885742|  0:00:18s\n","epoch 31 | loss: 0.57418 | val_0_mse: 1.1600500345230103|  0:00:19s\n","epoch 32 | loss: 0.57365 | val_0_mse: 1.9487199783325195|  0:00:20s\n","epoch 33 | loss: 0.53495 | val_0_mse: 1.7262200117111206|  0:00:20s\n","epoch 34 | loss: 0.55843 | val_0_mse: 1.115090012550354|  0:00:21s\n","epoch 35 | loss: 0.53255 | val_0_mse: 1.3594599962234497|  0:00:21s\n","epoch 36 | loss: 0.52564 | val_0_mse: 1.482800006866455|  0:00:22s\n","epoch 37 | loss: 0.5111  | val_0_mse: 1.1500300168991089|  0:00:22s\n","epoch 38 | loss: 0.52205 | val_0_mse: 1.3547600507736206|  0:00:23s\n","epoch 39 | loss: 0.55817 | val_0_mse: 0.9597600102424622|  0:00:24s\n","epoch 40 | loss: 0.52727 | val_0_mse: 1.0067399740219116|  0:00:24s\n","epoch 41 | loss: 0.53648 | val_0_mse: 1.2986899614334106|  0:00:25s\n","epoch 42 | loss: 0.52155 | val_0_mse: 1.0174700021743774|  0:00:25s\n","epoch 43 | loss: 0.55802 | val_0_mse: 1.1587200164794922|  0:00:26s\n","epoch 44 | loss: 0.52101 | val_0_mse: 1.0811799764633179|  0:00:27s\n","epoch 45 | loss: 0.50766 | val_0_mse: 0.9724199771881104|  0:00:27s\n","epoch 46 | loss: 0.49043 | val_0_mse: 0.9315099716186523|  0:00:28s\n","epoch 47 | loss: 0.50741 | val_0_mse: 0.7846999764442444|  0:00:28s\n","epoch 48 | loss: 0.49357 | val_0_mse: 0.7593299746513367|  0:00:29s\n","epoch 49 | loss: 0.49795 | val_0_mse: 0.8167200088500977|  0:00:30s\n","epoch 50 | loss: 0.48116 | val_0_mse: 0.8593500256538391|  0:00:30s\n","epoch 51 | loss: 0.49546 | val_0_mse: 0.8634600043296814|  0:00:31s\n","epoch 52 | loss: 0.49769 | val_0_mse: 0.8176000118255615|  0:00:31s\n","epoch 53 | loss: 0.49463 | val_0_mse: 0.7033399939537048|  0:00:32s\n","epoch 54 | loss: 0.51169 | val_0_mse: 0.8242599964141846|  0:00:33s\n","epoch 55 | loss: 0.52428 | val_0_mse: 0.6679099798202515|  0:00:33s\n","epoch 56 | loss: 0.51776 | val_0_mse: 0.8536800146102905|  0:00:34s\n","epoch 57 | loss: 0.51289 | val_0_mse: 0.7430599927902222|  0:00:34s\n","epoch 58 | loss: 0.48452 | val_0_mse: 0.752590000629425|  0:00:35s\n","epoch 59 | loss: 0.47934 | val_0_mse: 0.7045000195503235|  0:00:36s\n","epoch 60 | loss: 0.47701 | val_0_mse: 0.7196900248527527|  0:00:36s\n","epoch 61 | loss: 0.4834  | val_0_mse: 0.658079981803894|  0:00:37s\n","epoch 62 | loss: 0.49906 | val_0_mse: 0.6526200175285339|  0:00:38s\n","epoch 63 | loss: 0.48461 | val_0_mse: 0.6864799857139587|  0:00:38s\n","epoch 64 | loss: 0.47466 | val_0_mse: 0.6277400255203247|  0:00:39s\n","epoch 65 | loss: 0.47227 | val_0_mse: 0.6331499814987183|  0:00:39s\n","epoch 66 | loss: 0.46795 | val_0_mse: 0.6144000291824341|  0:00:40s\n","epoch 67 | loss: 0.47311 | val_0_mse: 0.7295399904251099|  0:00:41s\n","epoch 68 | loss: 0.49294 | val_0_mse: 0.649179995059967|  0:00:41s\n","epoch 69 | loss: 0.52003 | val_0_mse: 0.7941700220108032|  0:00:42s\n","epoch 70 | loss: 0.56358 | val_0_mse: 0.6200000047683716|  0:00:42s\n","epoch 71 | loss: 0.47761 | val_0_mse: 0.6172000169754028|  0:00:43s\n","epoch 72 | loss: 0.46528 | val_0_mse: 0.648829996585846|  0:00:44s\n","epoch 73 | loss: 0.49942 | val_0_mse: 0.5931000113487244|  0:00:44s\n","epoch 74 | loss: 0.49917 | val_0_mse: 0.6581199765205383|  0:00:45s\n","epoch 75 | loss: 0.48363 | val_0_mse: 0.5839099884033203|  0:00:45s\n","epoch 76 | loss: 0.48087 | val_0_mse: 0.5890200138092041|  0:00:46s\n","epoch 77 | loss: 0.46598 | val_0_mse: 0.613290011882782|  0:00:47s\n","epoch 78 | loss: 0.45434 | val_0_mse: 0.5690299868583679|  0:00:47s\n","epoch 79 | loss: 0.45194 | val_0_mse: 0.5882599949836731|  0:00:48s\n","epoch 80 | loss: 0.45313 | val_0_mse: 0.5748100280761719|  0:00:48s\n","epoch 81 | loss: 0.45836 | val_0_mse: 0.5821499824523926|  0:00:49s\n","epoch 82 | loss: 0.46667 | val_0_mse: 0.5717999935150146|  0:00:49s\n","epoch 83 | loss: 0.47143 | val_0_mse: 0.5881699919700623|  0:00:50s\n","epoch 84 | loss: 0.4634  | val_0_mse: 0.5689399838447571|  0:00:51s\n","epoch 85 | loss: 0.44682 | val_0_mse: 0.5742499828338623|  0:00:51s\n","epoch 86 | loss: 0.46361 | val_0_mse: 0.5512199997901917|  0:00:52s\n","epoch 87 | loss: 0.43848 | val_0_mse: 0.5559499859809875|  0:00:52s\n","epoch 88 | loss: 0.45364 | val_0_mse: 0.6003199815750122|  0:00:53s\n","epoch 89 | loss: 0.44892 | val_0_mse: 0.5681800246238708|  0:00:54s\n","epoch 90 | loss: 0.4456  | val_0_mse: 0.5691199898719788|  0:00:54s\n","epoch 91 | loss: 0.43756 | val_0_mse: 0.5461699962615967|  0:00:55s\n","epoch 92 | loss: 0.43181 | val_0_mse: 0.5835599899291992|  0:00:55s\n","epoch 93 | loss: 0.44345 | val_0_mse: 0.5480899810791016|  0:00:56s\n","epoch 94 | loss: 0.4316  | val_0_mse: 0.5671600103378296|  0:00:57s\n","epoch 95 | loss: 0.43671 | val_0_mse: 0.5396900177001953|  0:00:57s\n","epoch 96 | loss: 0.43551 | val_0_mse: 0.5402799844741821|  0:00:58s\n","epoch 97 | loss: 0.41999 | val_0_mse: 0.5428699851036072|  0:00:58s\n","epoch 98 | loss: 0.41827 | val_0_mse: 0.5528299808502197|  0:00:59s\n","epoch 99 | loss: 0.42768 | val_0_mse: 0.5610299706459045|  0:01:00s\n","Stop training because you reached max_epochs = 100 with best_epoch = 95 and best_val_0_mse = 0.5396900177001953\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 16:22:47,517] Trial 55 finished with value: 0.5396906733512878 and parameters: {'n_d': 22, 'n_steps': 8, 'gamma': 1.0024727718401805, 'n_independent': 4, 'n_shared': 3, 'momentum': 0.21152216304738897}. Best is trial 55 with value: 0.5396906733512878.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 14.6949 | val_0_mse: 6921.29296875|  0:00:00s\n","epoch 1  | loss: 3.50068 | val_0_mse: 581.5052490234375|  0:00:01s\n","epoch 2  | loss: 2.10886 | val_0_mse: 851.5057373046875|  0:00:01s\n","epoch 3  | loss: 1.61597 | val_0_mse: 1711.93115234375|  0:00:02s\n","epoch 4  | loss: 1.45515 | val_0_mse: 234.26925659179688|  0:00:03s\n","epoch 5  | loss: 1.25836 | val_0_mse: 55.797550201416016|  0:00:03s\n","epoch 6  | loss: 1.10177 | val_0_mse: 59.52513885498047|  0:00:04s\n","epoch 7  | loss: 0.9396  | val_0_mse: 24.600730895996094|  0:00:04s\n","epoch 8  | loss: 0.89437 | val_0_mse: 65.15242767333984|  0:00:05s\n","epoch 9  | loss: 0.75293 | val_0_mse: 19.655210494995117|  0:00:06s\n","epoch 10 | loss: 0.73038 | val_0_mse: 16.334909439086914|  0:00:06s\n","epoch 11 | loss: 0.69957 | val_0_mse: 14.622650146484375|  0:00:07s\n","epoch 12 | loss: 0.6797  | val_0_mse: 32.521881103515625|  0:00:08s\n","epoch 13 | loss: 0.69229 | val_0_mse: 8.991339683532715|  0:00:08s\n","epoch 14 | loss: 0.67167 | val_0_mse: 7.318240165710449|  0:00:09s\n","epoch 15 | loss: 0.64729 | val_0_mse: 6.175940036773682|  0:00:09s\n","epoch 16 | loss: 0.68765 | val_0_mse: 9.479940414428711|  0:00:10s\n","epoch 17 | loss: 0.62809 | val_0_mse: 4.777560234069824|  0:00:11s\n","epoch 18 | loss: 0.58107 | val_0_mse: 5.515729904174805|  0:00:11s\n","epoch 19 | loss: 0.56996 | val_0_mse: 4.364840030670166|  0:00:12s\n","epoch 20 | loss: 0.58068 | val_0_mse: 1.230180025100708|  0:00:12s\n","epoch 21 | loss: 0.55997 | val_0_mse: 1.4745899438858032|  0:00:13s\n","epoch 22 | loss: 0.57241 | val_0_mse: 1.6578400135040283|  0:00:14s\n","epoch 23 | loss: 0.54245 | val_0_mse: 2.547139883041382|  0:00:14s\n","epoch 24 | loss: 0.53563 | val_0_mse: 2.6214499473571777|  0:00:15s\n","epoch 25 | loss: 0.54972 | val_0_mse: 2.37568998336792|  0:00:15s\n","epoch 26 | loss: 0.52307 | val_0_mse: 1.9191099405288696|  0:00:16s\n","epoch 27 | loss: 0.51434 | val_0_mse: 1.7256699800491333|  0:00:17s\n","epoch 28 | loss: 0.52186 | val_0_mse: 1.2531100511550903|  0:00:17s\n","epoch 29 | loss: 0.52704 | val_0_mse: 1.2863099575042725|  0:00:18s\n","epoch 30 | loss: 0.50553 | val_0_mse: 1.5516599416732788|  0:00:18s\n","\n","Early stopping occurred at epoch 30 with best_epoch = 20 and best_val_0_mse = 1.230180025100708\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 16:23:06,670] Trial 56 finished with value: 1.2301843166351318 and parameters: {'n_d': 23, 'n_steps': 7, 'gamma': 1.001553826462716, 'n_independent': 4, 'n_shared': 4, 'momentum': 0.20686668345596826}. Best is trial 55 with value: 0.5396906733512878.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 17.7334 | val_0_mse: 422.00732421875|  0:00:00s\n","epoch 1  | loss: 4.30272 | val_0_mse: 259.19482421875|  0:00:01s\n","epoch 2  | loss: 3.39558 | val_0_mse: 43.07844161987305|  0:00:01s\n","epoch 3  | loss: 1.84366 | val_0_mse: 77.73754119873047|  0:00:02s\n","epoch 4  | loss: 1.38775 | val_0_mse: 68.18775177001953|  0:00:03s\n","epoch 5  | loss: 1.34388 | val_0_mse: 12.775110244750977|  0:00:03s\n","epoch 6  | loss: 1.05332 | val_0_mse: 5.535679817199707|  0:00:04s\n","epoch 7  | loss: 0.88064 | val_0_mse: 9.259779930114746|  0:00:04s\n","epoch 8  | loss: 0.81924 | val_0_mse: 3.4228599071502686|  0:00:05s\n","epoch 9  | loss: 0.82628 | val_0_mse: 4.279759883880615|  0:00:06s\n","epoch 10 | loss: 0.8315  | val_0_mse: 2.4457099437713623|  0:00:06s\n","epoch 11 | loss: 0.77649 | val_0_mse: 8.634929656982422|  0:00:07s\n","epoch 12 | loss: 0.76595 | val_0_mse: 3.460969924926758|  0:00:07s\n","epoch 13 | loss: 0.71941 | val_0_mse: 3.5296099185943604|  0:00:08s\n","epoch 14 | loss: 0.68931 | val_0_mse: 1.4744700193405151|  0:00:09s\n","epoch 15 | loss: 0.65826 | val_0_mse: 1.9975899457931519|  0:00:09s\n","epoch 16 | loss: 0.73734 | val_0_mse: 6.831120014190674|  0:00:10s\n","epoch 17 | loss: 0.80373 | val_0_mse: 2.4580399990081787|  0:00:10s\n","epoch 18 | loss: 0.80751 | val_0_mse: 7.61476993560791|  0:00:11s\n","epoch 19 | loss: 1.04229 | val_0_mse: 1.9056999683380127|  0:00:12s\n","epoch 20 | loss: 0.94313 | val_0_mse: 4.9267802238464355|  0:00:12s\n","epoch 21 | loss: 0.75754 | val_0_mse: 1.349020004272461|  0:00:13s\n","epoch 22 | loss: 0.61042 | val_0_mse: 1.7818399667739868|  0:00:13s\n","epoch 23 | loss: 0.58491 | val_0_mse: 1.335569977760315|  0:00:14s\n","epoch 24 | loss: 0.63063 | val_0_mse: 3.7573800086975098|  0:00:15s\n","epoch 25 | loss: 0.73773 | val_0_mse: 1.0899100303649902|  0:00:15s\n","epoch 26 | loss: 0.63538 | val_0_mse: 0.9548799991607666|  0:00:16s\n","epoch 27 | loss: 0.64214 | val_0_mse: 1.0665199756622314|  0:00:16s\n","epoch 28 | loss: 0.59285 | val_0_mse: 0.9654499888420105|  0:00:17s\n","epoch 29 | loss: 0.60996 | val_0_mse: 4.271910190582275|  0:00:18s\n","epoch 30 | loss: 0.59    | val_0_mse: 2.4521000385284424|  0:00:18s\n","epoch 31 | loss: 0.55426 | val_0_mse: 0.8826500177383423|  0:00:19s\n","epoch 32 | loss: 0.56724 | val_0_mse: 1.6721800565719604|  0:00:20s\n","epoch 33 | loss: 0.5353  | val_0_mse: 1.8159899711608887|  0:00:20s\n","epoch 34 | loss: 0.50756 | val_0_mse: 2.0268399715423584|  0:00:21s\n","epoch 35 | loss: 0.50904 | val_0_mse: 1.1701799631118774|  0:00:21s\n","epoch 36 | loss: 0.50526 | val_0_mse: 1.4687000513076782|  0:00:22s\n","epoch 37 | loss: 0.53209 | val_0_mse: 1.267199993133545|  0:00:22s\n","epoch 38 | loss: 0.53704 | val_0_mse: 1.2338999509811401|  0:00:23s\n","epoch 39 | loss: 0.50166 | val_0_mse: 1.029129981994629|  0:00:24s\n","epoch 40 | loss: 0.51069 | val_0_mse: 1.15625 |  0:00:24s\n","epoch 41 | loss: 0.51253 | val_0_mse: 1.1948200464248657|  0:00:25s\n","\n","Early stopping occurred at epoch 41 with best_epoch = 31 and best_val_0_mse = 0.8826500177383423\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 16:23:32,369] Trial 57 finished with value: 0.8826496601104736 and parameters: {'n_d': 34, 'n_steps': 8, 'gamma': 1.0395379244160061, 'n_independent': 5, 'n_shared': 2, 'momentum': 0.228438164197328}. Best is trial 55 with value: 0.5396906733512878.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 18.87138| val_0_mse: 1755.351318359375|  0:00:00s\n","epoch 1  | loss: 4.43784 | val_0_mse: 105.26753234863281|  0:00:01s\n","epoch 2  | loss: 2.35757 | val_0_mse: 263.55810546875|  0:00:01s\n","epoch 3  | loss: 1.6101  | val_0_mse: 63.66896057128906|  0:00:02s\n","epoch 4  | loss: 1.17337 | val_0_mse: 51.37321090698242|  0:00:02s\n","epoch 5  | loss: 1.46709 | val_0_mse: 20.316219329833984|  0:00:03s\n","epoch 6  | loss: 0.98489 | val_0_mse: 15.640460014343262|  0:00:04s\n","epoch 7  | loss: 0.85543 | val_0_mse: 60.095481872558594|  0:00:04s\n","epoch 8  | loss: 0.76649 | val_0_mse: 15.569379806518555|  0:00:05s\n","epoch 9  | loss: 0.76248 | val_0_mse: 8.31857967376709|  0:00:06s\n","epoch 10 | loss: 0.6994  | val_0_mse: 6.78587007522583|  0:00:06s\n","epoch 11 | loss: 0.73797 | val_0_mse: 5.819509983062744|  0:00:07s\n","epoch 12 | loss: 0.6697  | val_0_mse: 6.599410057067871|  0:00:07s\n","epoch 13 | loss: 0.67212 | val_0_mse: 3.8473401069641113|  0:00:08s\n","epoch 14 | loss: 0.6385  | val_0_mse: 3.080430030822754|  0:00:09s\n","epoch 15 | loss: 0.68836 | val_0_mse: 2.253920078277588|  0:00:09s\n","epoch 16 | loss: 0.71725 | val_0_mse: 6.1202898025512695|  0:00:10s\n","epoch 17 | loss: 0.71044 | val_0_mse: 5.235300064086914|  0:00:10s\n","epoch 18 | loss: 0.61549 | val_0_mse: 5.209270000457764|  0:00:11s\n","epoch 19 | loss: 0.60081 | val_0_mse: 10.409979820251465|  0:00:11s\n","epoch 20 | loss: 0.60604 | val_0_mse: 4.187570095062256|  0:00:12s\n","epoch 21 | loss: 0.56599 | val_0_mse: 8.098159790039062|  0:00:13s\n","epoch 22 | loss: 0.57864 | val_0_mse: 5.0415802001953125|  0:00:13s\n","epoch 23 | loss: 0.59887 | val_0_mse: 2.346290111541748|  0:00:14s\n","epoch 24 | loss: 0.74213 | val_0_mse: 1.579800009727478|  0:00:14s\n","epoch 25 | loss: 0.77792 | val_0_mse: 1.0339200496673584|  0:00:15s\n","epoch 26 | loss: 0.63881 | val_0_mse: 3.7670600414276123|  0:00:16s\n","epoch 27 | loss: 0.56605 | val_0_mse: 1.9292800426483154|  0:00:16s\n","epoch 28 | loss: 0.55236 | val_0_mse: 2.1700000762939453|  0:00:17s\n","epoch 29 | loss: 0.51489 | val_0_mse: 1.7735400199890137|  0:00:17s\n","epoch 30 | loss: 0.52561 | val_0_mse: 1.8590600490570068|  0:00:18s\n","epoch 31 | loss: 0.5521  | val_0_mse: 1.1581000089645386|  0:00:19s\n","epoch 32 | loss: 0.56863 | val_0_mse: 2.4541499614715576|  0:00:19s\n","epoch 33 | loss: 0.54073 | val_0_mse: 2.3463099002838135|  0:00:20s\n","epoch 34 | loss: 0.55981 | val_0_mse: 1.103760004043579|  0:00:20s\n","epoch 35 | loss: 0.59264 | val_0_mse: 1.8196300268173218|  0:00:21s\n","\n","Early stopping occurred at epoch 35 with best_epoch = 25 and best_val_0_mse = 1.0339200496673584\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 16:23:54,139] Trial 58 finished with value: 1.0339242219924927 and parameters: {'n_d': 30, 'n_steps': 7, 'gamma': 1.0760821321302172, 'n_independent': 4, 'n_shared': 4, 'momentum': 0.1614568115007169}. Best is trial 55 with value: 0.5396906733512878.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 10.33746| val_0_mse: 1145.03515625|  0:00:00s\n","epoch 1  | loss: 3.30347 | val_0_mse: 218.99684143066406|  0:00:01s\n","epoch 2  | loss: 2.48331 | val_0_mse: 858.0574951171875|  0:00:02s\n","epoch 3  | loss: 1.89818 | val_0_mse: 165.06982421875|  0:00:03s\n","epoch 4  | loss: 1.89891 | val_0_mse: 282.19696044921875|  0:00:03s\n","epoch 5  | loss: 2.04661 | val_0_mse: 89.46806335449219|  0:00:04s\n","epoch 6  | loss: 1.60643 | val_0_mse: 105.94213104248047|  0:00:05s\n","epoch 7  | loss: 1.23591 | val_0_mse: 195.0795440673828|  0:00:06s\n","epoch 8  | loss: 1.17671 | val_0_mse: 56.86286163330078|  0:00:06s\n","epoch 9  | loss: 1.10802 | val_0_mse: 41.433441162109375|  0:00:07s\n","epoch 10 | loss: 1.15085 | val_0_mse: 39.01327896118164|  0:00:08s\n","epoch 11 | loss: 0.99367 | val_0_mse: 20.621219635009766|  0:00:09s\n","epoch 12 | loss: 0.884   | val_0_mse: 35.80271911621094|  0:00:09s\n","epoch 13 | loss: 0.97736 | val_0_mse: 51.04446029663086|  0:00:10s\n","epoch 14 | loss: 1.05031 | val_0_mse: 12.236809730529785|  0:00:11s\n","epoch 15 | loss: 1.43096 | val_0_mse: 17.079259872436523|  0:00:12s\n","epoch 16 | loss: 1.03975 | val_0_mse: 20.401920318603516|  0:00:12s\n","epoch 17 | loss: 0.95829 | val_0_mse: 4.548419952392578|  0:00:13s\n","epoch 18 | loss: 0.79413 | val_0_mse: 4.959690093994141|  0:00:14s\n","epoch 19 | loss: 0.94002 | val_0_mse: 1.6997900009155273|  0:00:14s\n","epoch 20 | loss: 0.79706 | val_0_mse: 5.914569854736328|  0:00:15s\n","epoch 21 | loss: 0.86916 | val_0_mse: 4.296390056610107|  0:00:16s\n","epoch 22 | loss: 0.74372 | val_0_mse: 1.7099599838256836|  0:00:17s\n","epoch 23 | loss: 0.68869 | val_0_mse: 2.134769916534424|  0:00:17s\n","epoch 24 | loss: 0.6621  | val_0_mse: 4.06397008895874|  0:00:18s\n","epoch 25 | loss: 0.69091 | val_0_mse: 6.263269901275635|  0:00:19s\n","epoch 26 | loss: 0.92092 | val_0_mse: 1.6623400449752808|  0:00:20s\n","epoch 27 | loss: 1.17519 | val_0_mse: 2.2095799446105957|  0:00:20s\n","epoch 28 | loss: 0.99393 | val_0_mse: 1.5978200435638428|  0:00:21s\n","epoch 29 | loss: 1.18829 | val_0_mse: 7.838369846343994|  0:00:22s\n","epoch 30 | loss: 1.8078  | val_0_mse: 1.6369500160217285|  0:00:22s\n","epoch 31 | loss: 1.59835 | val_0_mse: 1.2931599617004395|  0:00:23s\n","epoch 32 | loss: 1.09059 | val_0_mse: 4.289760112762451|  0:00:24s\n","epoch 33 | loss: 1.0709  | val_0_mse: 0.9400399923324585|  0:00:25s\n","epoch 34 | loss: 0.86621 | val_0_mse: 1.9772000312805176|  0:00:25s\n","epoch 35 | loss: 0.97904 | val_0_mse: 1.2033300399780273|  0:00:26s\n","epoch 36 | loss: 0.99606 | val_0_mse: 0.86913001537323|  0:00:27s\n","epoch 37 | loss: 0.85511 | val_0_mse: 1.7092700004577637|  0:00:28s\n","epoch 38 | loss: 0.64197 | val_0_mse: 0.9574199914932251|  0:00:28s\n","epoch 39 | loss: 0.61792 | val_0_mse: 1.3954099416732788|  0:00:29s\n","epoch 40 | loss: 0.69987 | val_0_mse: 1.7656500339508057|  0:00:30s\n","epoch 41 | loss: 0.6189  | val_0_mse: 1.5916199684143066|  0:00:31s\n","epoch 42 | loss: 0.59207 | val_0_mse: 1.6481000185012817|  0:00:31s\n","epoch 43 | loss: 0.60394 | val_0_mse: 0.944890022277832|  0:00:32s\n","epoch 44 | loss: 0.60612 | val_0_mse: 1.2050399780273438|  0:00:33s\n","epoch 45 | loss: 0.60771 | val_0_mse: 0.8957800269126892|  0:00:33s\n","epoch 46 | loss: 0.6329  | val_0_mse: 1.2842700481414795|  0:00:34s\n","\n","Early stopping occurred at epoch 46 with best_epoch = 36 and best_val_0_mse = 0.86913001537323\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 16:24:29,169] Trial 59 finished with value: 0.8691285252571106 and parameters: {'n_d': 25, 'n_steps': 10, 'gamma': 1.3897069963994662, 'n_independent': 4, 'n_shared': 3, 'momentum': 0.18715797617514962}. Best is trial 55 with value: 0.5396906733512878.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 16.42772| val_0_mse: 2904.666015625|  0:00:00s\n","epoch 1  | loss: 4.9729  | val_0_mse: 667.4417724609375|  0:00:01s\n","epoch 2  | loss: 2.61114 | val_0_mse: 343.373291015625|  0:00:02s\n","epoch 3  | loss: 2.51798 | val_0_mse: 162.49844360351562|  0:00:03s\n","epoch 4  | loss: 2.30704 | val_0_mse: 199.15423583984375|  0:00:03s\n","epoch 5  | loss: 1.91153 | val_0_mse: 45.9571418762207|  0:00:04s\n","epoch 6  | loss: 2.06169 | val_0_mse: 126.16567993164062|  0:00:05s\n","epoch 7  | loss: 1.30015 | val_0_mse: 160.94993591308594|  0:00:06s\n","epoch 8  | loss: 1.14777 | val_0_mse: 35.020870208740234|  0:00:06s\n","epoch 9  | loss: 1.17945 | val_0_mse: 47.77362823486328|  0:00:07s\n","epoch 10 | loss: 0.96898 | val_0_mse: 58.93484115600586|  0:00:08s\n","epoch 11 | loss: 0.88895 | val_0_mse: 17.674840927124023|  0:00:08s\n","epoch 12 | loss: 0.82573 | val_0_mse: 8.243499755859375|  0:00:09s\n","epoch 13 | loss: 0.81578 | val_0_mse: 16.49268913269043|  0:00:10s\n","epoch 14 | loss: 1.13802 | val_0_mse: 4.891180038452148|  0:00:11s\n","epoch 15 | loss: 0.86232 | val_0_mse: 10.60657024383545|  0:00:11s\n","epoch 16 | loss: 0.77411 | val_0_mse: 17.283180236816406|  0:00:12s\n","epoch 17 | loss: 0.87736 | val_0_mse: 1.4503999948501587|  0:00:13s\n","epoch 18 | loss: 1.14559 | val_0_mse: 8.780409812927246|  0:00:14s\n","epoch 19 | loss: 1.0674  | val_0_mse: 5.005119800567627|  0:00:14s\n","epoch 20 | loss: 0.94051 | val_0_mse: 6.497590065002441|  0:00:15s\n","epoch 21 | loss: 0.69052 | val_0_mse: 3.937350034713745|  0:00:16s\n","epoch 22 | loss: 0.6801  | val_0_mse: 1.555109977722168|  0:00:16s\n","epoch 23 | loss: 0.63152 | val_0_mse: 3.2648398876190186|  0:00:17s\n","epoch 24 | loss: 0.61318 | val_0_mse: 5.679830074310303|  0:00:18s\n","epoch 25 | loss: 0.61167 | val_0_mse: 4.725339889526367|  0:00:19s\n","epoch 26 | loss: 0.69264 | val_0_mse: 1.8378000259399414|  0:00:19s\n","epoch 27 | loss: 0.60185 | val_0_mse: 2.451240062713623|  0:00:20s\n","\n","Early stopping occurred at epoch 27 with best_epoch = 17 and best_val_0_mse = 1.4503999948501587\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 16:24:50,090] Trial 60 finished with value: 1.4504035711288452 and parameters: {'n_d': 21, 'n_steps': 8, 'gamma': 1.2325809450352199, 'n_independent': 5, 'n_shared': 4, 'momentum': 0.3207687298245867}. Best is trial 55 with value: 0.5396906733512878.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 28.98933| val_0_mse: 2504.3935546875|  0:00:00s\n","epoch 1  | loss: 8.38056 | val_0_mse: 488.6197509765625|  0:00:01s\n","epoch 2  | loss: 3.56883 | val_0_mse: 680.5027465820312|  0:00:01s\n","epoch 3  | loss: 2.22816 | val_0_mse: 96.52496337890625|  0:00:02s\n","epoch 4  | loss: 1.83626 | val_0_mse: 61.45233917236328|  0:00:02s\n","epoch 5  | loss: 1.54149 | val_0_mse: 32.89453125|  0:00:03s\n","epoch 6  | loss: 1.10312 | val_0_mse: 32.743499755859375|  0:00:04s\n","epoch 7  | loss: 0.93299 | val_0_mse: 55.876380920410156|  0:00:04s\n","epoch 8  | loss: 0.81628 | val_0_mse: 18.42588996887207|  0:00:05s\n","epoch 9  | loss: 0.80987 | val_0_mse: 14.662019729614258|  0:00:06s\n","epoch 10 | loss: 0.76823 | val_0_mse: 30.8617000579834|  0:00:06s\n","epoch 11 | loss: 0.73955 | val_0_mse: 24.967060089111328|  0:00:07s\n","epoch 12 | loss: 0.75977 | val_0_mse: 30.261709213256836|  0:00:07s\n","epoch 13 | loss: 0.72421 | val_0_mse: 20.128459930419922|  0:00:08s\n","epoch 14 | loss: 0.62434 | val_0_mse: 7.330639839172363|  0:00:08s\n","epoch 15 | loss: 0.64642 | val_0_mse: 12.032859802246094|  0:00:09s\n","epoch 16 | loss: 0.62172 | val_0_mse: 8.628210067749023|  0:00:10s\n","epoch 17 | loss: 0.61231 | val_0_mse: 13.278860092163086|  0:00:10s\n","epoch 18 | loss: 0.58445 | val_0_mse: 4.796350002288818|  0:00:11s\n","epoch 19 | loss: 0.56348 | val_0_mse: 5.646269798278809|  0:00:11s\n","epoch 20 | loss: 0.57522 | val_0_mse: 4.325570106506348|  0:00:12s\n","epoch 21 | loss: 0.566   | val_0_mse: 5.760779857635498|  0:00:13s\n","epoch 22 | loss: 0.58457 | val_0_mse: 3.6029300689697266|  0:00:13s\n","epoch 23 | loss: 0.59198 | val_0_mse: 5.534140110015869|  0:00:14s\n","epoch 24 | loss: 0.6161  | val_0_mse: 3.537980079650879|  0:00:15s\n","epoch 25 | loss: 0.63042 | val_0_mse: 4.583950042724609|  0:00:15s\n","epoch 26 | loss: 0.57114 | val_0_mse: 2.3245699405670166|  0:00:16s\n","epoch 27 | loss: 0.5316  | val_0_mse: 2.14601993560791|  0:00:16s\n","epoch 28 | loss: 0.52972 | val_0_mse: 1.7129600048065186|  0:00:17s\n","epoch 29 | loss: 0.54615 | val_0_mse: 1.5812499523162842|  0:00:18s\n","epoch 30 | loss: 0.55629 | val_0_mse: 1.5864299535751343|  0:00:18s\n","epoch 31 | loss: 0.58342 | val_0_mse: 2.51134991645813|  0:00:19s\n","epoch 32 | loss: 0.5657  | val_0_mse: 1.3809499740600586|  0:00:19s\n","epoch 33 | loss: 0.5402  | val_0_mse: 1.2527400255203247|  0:00:20s\n","epoch 34 | loss: 0.54866 | val_0_mse: 1.2156399488449097|  0:00:21s\n","epoch 35 | loss: 0.54339 | val_0_mse: 1.1312400102615356|  0:00:21s\n","epoch 36 | loss: 0.53916 | val_0_mse: 1.1872400045394897|  0:00:22s\n","epoch 37 | loss: 0.52346 | val_0_mse: 1.195930004119873|  0:00:22s\n","epoch 38 | loss: 0.5466  | val_0_mse: 1.2300599813461304|  0:00:23s\n","epoch 39 | loss: 0.57665 | val_0_mse: 1.6488499641418457|  0:00:23s\n","epoch 40 | loss: 0.54483 | val_0_mse: 0.958329975605011|  0:00:24s\n","epoch 41 | loss: 0.55569 | val_0_mse: 1.736549973487854|  0:00:25s\n","epoch 42 | loss: 0.59994 | val_0_mse: 0.9065700173377991|  0:00:25s\n","epoch 43 | loss: 0.58927 | val_0_mse: 1.6814099550247192|  0:00:26s\n","epoch 44 | loss: 0.56053 | val_0_mse: 0.9777699708938599|  0:00:26s\n","epoch 45 | loss: 0.59524 | val_0_mse: 0.8243799805641174|  0:00:27s\n","epoch 46 | loss: 0.63877 | val_0_mse: 0.6635000109672546|  0:00:28s\n","epoch 47 | loss: 0.65067 | val_0_mse: 1.1673699617385864|  0:00:28s\n","epoch 48 | loss: 0.6418  | val_0_mse: 0.6472799777984619|  0:00:29s\n","epoch 49 | loss: 0.61345 | val_0_mse: 1.046090006828308|  0:00:29s\n","epoch 50 | loss: 0.52368 | val_0_mse: 0.8094900250434875|  0:00:30s\n","epoch 51 | loss: 0.51225 | val_0_mse: 0.7205899953842163|  0:00:31s\n","epoch 52 | loss: 0.51506 | val_0_mse: 0.7688800096511841|  0:00:31s\n","epoch 53 | loss: 0.51343 | val_0_mse: 0.7857199907302856|  0:00:32s\n","epoch 54 | loss: 0.52251 | val_0_mse: 0.7246699929237366|  0:00:32s\n","epoch 55 | loss: 0.51397 | val_0_mse: 0.720740020275116|  0:00:33s\n","epoch 56 | loss: 0.52301 | val_0_mse: 0.7018499970436096|  0:00:33s\n","epoch 57 | loss: 0.51066 | val_0_mse: 0.6316199898719788|  0:00:34s\n","epoch 58 | loss: 0.51881 | val_0_mse: 0.6733400225639343|  0:00:35s\n","epoch 59 | loss: 0.52681 | val_0_mse: 0.6909899711608887|  0:00:35s\n","epoch 60 | loss: 0.52509 | val_0_mse: 0.6712300181388855|  0:00:36s\n","epoch 61 | loss: 0.52269 | val_0_mse: 0.8553500175476074|  0:00:36s\n","epoch 62 | loss: 0.54341 | val_0_mse: 0.7366200089454651|  0:00:37s\n","epoch 63 | loss: 0.51438 | val_0_mse: 0.642009973526001|  0:00:37s\n","epoch 64 | loss: 0.54447 | val_0_mse: 0.6586300134658813|  0:00:38s\n","epoch 65 | loss: 0.53287 | val_0_mse: 0.7204700112342834|  0:00:39s\n","epoch 66 | loss: 0.50964 | val_0_mse: 0.6429200172424316|  0:00:39s\n","epoch 67 | loss: 0.51603 | val_0_mse: 0.764519989490509|  0:00:40s\n","\n","Early stopping occurred at epoch 67 with best_epoch = 57 and best_val_0_mse = 0.6316199898719788\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 16:25:30,797] Trial 61 finished with value: 0.6316222548484802 and parameters: {'n_d': 16, 'n_steps': 9, 'gamma': 1.034799750008568, 'n_independent': 3, 'n_shared': 3, 'momentum': 0.17446216172389944}. Best is trial 55 with value: 0.5396906733512878.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 20.64286| val_0_mse: 220.51995849609375|  0:00:00s\n","epoch 1  | loss: 6.36597 | val_0_mse: 441.9950866699219|  0:00:01s\n","epoch 2  | loss: 3.23837 | val_0_mse: 121.48896789550781|  0:00:01s\n","epoch 3  | loss: 2.14299 | val_0_mse: 124.91665649414062|  0:00:02s\n","epoch 4  | loss: 2.02352 | val_0_mse: 31.28104019165039|  0:00:02s\n","epoch 5  | loss: 1.84096 | val_0_mse: 26.525869369506836|  0:00:03s\n","epoch 6  | loss: 1.2708  | val_0_mse: 14.15923023223877|  0:00:04s\n","epoch 7  | loss: 1.12919 | val_0_mse: 15.680139541625977|  0:00:04s\n","epoch 8  | loss: 0.87751 | val_0_mse: 13.45125961303711|  0:00:05s\n","epoch 9  | loss: 0.84201 | val_0_mse: 7.9552998542785645|  0:00:06s\n","epoch 10 | loss: 0.84908 | val_0_mse: 5.557260036468506|  0:00:06s\n","epoch 11 | loss: 0.8001  | val_0_mse: 2.562119960784912|  0:00:07s\n","epoch 12 | loss: 0.7889  | val_0_mse: 3.52197003364563|  0:00:07s\n","epoch 13 | loss: 0.77155 | val_0_mse: 2.1104400157928467|  0:00:08s\n","epoch 14 | loss: 0.73972 | val_0_mse: 9.643879890441895|  0:00:09s\n","epoch 15 | loss: 0.6748  | val_0_mse: 10.607780456542969|  0:00:09s\n","epoch 16 | loss: 0.65466 | val_0_mse: 3.1349000930786133|  0:00:10s\n","epoch 17 | loss: 0.65337 | val_0_mse: 2.2973499298095703|  0:00:10s\n","epoch 18 | loss: 0.65253 | val_0_mse: 1.7552499771118164|  0:00:11s\n","epoch 19 | loss: 0.69024 | val_0_mse: 1.0744099617004395|  0:00:12s\n","epoch 20 | loss: 0.66401 | val_0_mse: 0.9857500195503235|  0:00:12s\n","epoch 21 | loss: 0.6578  | val_0_mse: 1.4874199628829956|  0:00:13s\n","epoch 22 | loss: 0.61624 | val_0_mse: 1.2572499513626099|  0:00:13s\n","epoch 23 | loss: 0.63424 | val_0_mse: 1.138350009918213|  0:00:14s\n","epoch 24 | loss: 0.57148 | val_0_mse: 1.2092100381851196|  0:00:15s\n","epoch 25 | loss: 0.59617 | val_0_mse: 1.4776099920272827|  0:00:15s\n","epoch 26 | loss: 0.57253 | val_0_mse: 1.2065800428390503|  0:00:16s\n","epoch 27 | loss: 0.562   | val_0_mse: 0.967199981212616|  0:00:16s\n","epoch 28 | loss: 0.56401 | val_0_mse: 1.0848499536514282|  0:00:17s\n","epoch 29 | loss: 0.5608  | val_0_mse: 1.0223300457000732|  0:00:17s\n","epoch 30 | loss: 0.55772 | val_0_mse: 1.3641200065612793|  0:00:18s\n","epoch 31 | loss: 0.56154 | val_0_mse: 0.8058000206947327|  0:00:19s\n","epoch 32 | loss: 0.61123 | val_0_mse: 1.0692100524902344|  0:00:19s\n","epoch 33 | loss: 0.61345 | val_0_mse: 0.9741500020027161|  0:00:20s\n","epoch 34 | loss: 0.58858 | val_0_mse: 0.8021100163459778|  0:00:20s\n","epoch 35 | loss: 0.55658 | val_0_mse: 0.8415499925613403|  0:00:21s\n","epoch 36 | loss: 0.57333 | val_0_mse: 1.1732800006866455|  0:00:21s\n","epoch 37 | loss: 0.56677 | val_0_mse: 1.0043400526046753|  0:00:22s\n","epoch 38 | loss: 0.5609  | val_0_mse: 0.7368999719619751|  0:00:23s\n","epoch 39 | loss: 0.65516 | val_0_mse: 1.6723899841308594|  0:00:23s\n","epoch 40 | loss: 0.62946 | val_0_mse: 0.7347000241279602|  0:00:24s\n","epoch 41 | loss: 0.6118  | val_0_mse: 1.1017400026321411|  0:00:24s\n","epoch 42 | loss: 0.60863 | val_0_mse: 0.7413899898529053|  0:00:25s\n","epoch 43 | loss: 0.59156 | val_0_mse: 0.8931400179862976|  0:00:26s\n","epoch 44 | loss: 0.59496 | val_0_mse: 0.8514900207519531|  0:00:26s\n","epoch 45 | loss: 0.53694 | val_0_mse: 0.7280700206756592|  0:00:27s\n","epoch 46 | loss: 0.55255 | val_0_mse: 0.9027100205421448|  0:00:27s\n","epoch 47 | loss: 0.54587 | val_0_mse: 0.8156599998474121|  0:00:28s\n","epoch 48 | loss: 0.53134 | val_0_mse: 0.6670699715614319|  0:00:28s\n","epoch 49 | loss: 0.56214 | val_0_mse: 0.8447800278663635|  0:00:29s\n","epoch 50 | loss: 0.52204 | val_0_mse: 0.7386599779129028|  0:00:30s\n","epoch 51 | loss: 0.51814 | val_0_mse: 0.6634299755096436|  0:00:30s\n","epoch 52 | loss: 0.51695 | val_0_mse: 0.6718599796295166|  0:00:31s\n","epoch 53 | loss: 0.52391 | val_0_mse: 0.786270022392273|  0:00:31s\n","epoch 54 | loss: 0.52437 | val_0_mse: 0.7400100231170654|  0:00:32s\n","epoch 55 | loss: 0.55166 | val_0_mse: 0.6150500178337097|  0:00:33s\n","epoch 56 | loss: 0.54931 | val_0_mse: 0.6324800252914429|  0:00:33s\n","epoch 57 | loss: 0.53805 | val_0_mse: 0.690530002117157|  0:00:34s\n","epoch 58 | loss: 0.5226  | val_0_mse: 0.6258400082588196|  0:00:34s\n","epoch 59 | loss: 0.52638 | val_0_mse: 0.6200199723243713|  0:00:35s\n","epoch 60 | loss: 0.53331 | val_0_mse: 0.641539990901947|  0:00:36s\n","epoch 61 | loss: 0.54956 | val_0_mse: 0.6141800284385681|  0:00:36s\n","epoch 62 | loss: 0.53999 | val_0_mse: 0.6537399888038635|  0:00:37s\n","epoch 63 | loss: 0.51179 | val_0_mse: 0.6422799825668335|  0:00:37s\n","epoch 64 | loss: 0.53194 | val_0_mse: 0.6615599989891052|  0:00:38s\n","epoch 65 | loss: 0.5345  | val_0_mse: 0.6535699963569641|  0:00:39s\n","epoch 66 | loss: 0.51765 | val_0_mse: 0.6597899794578552|  0:00:39s\n","epoch 67 | loss: 0.5295  | val_0_mse: 0.5904800295829773|  0:00:40s\n","epoch 68 | loss: 0.54445 | val_0_mse: 0.6334199905395508|  0:00:40s\n","epoch 69 | loss: 0.52681 | val_0_mse: 0.6663100123405457|  0:00:41s\n","epoch 70 | loss: 0.54094 | val_0_mse: 0.6948500275611877|  0:00:41s\n","epoch 71 | loss: 0.53056 | val_0_mse: 0.6272600293159485|  0:00:42s\n","epoch 72 | loss: 0.52686 | val_0_mse: 0.6446899771690369|  0:00:43s\n","epoch 73 | loss: 0.60509 | val_0_mse: 0.5992900133132935|  0:00:43s\n","epoch 74 | loss: 0.61675 | val_0_mse: 0.6912400126457214|  0:00:44s\n","epoch 75 | loss: 0.55342 | val_0_mse: 0.654770016670227|  0:00:44s\n","epoch 76 | loss: 0.60314 | val_0_mse: 0.7224599719047546|  0:00:45s\n","epoch 77 | loss: 0.57469 | val_0_mse: 0.6560999751091003|  0:00:46s\n","\n","Early stopping occurred at epoch 77 with best_epoch = 67 and best_val_0_mse = 0.5904800295829773\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 16:26:17,216] Trial 62 finished with value: 0.5904822945594788 and parameters: {'n_d': 13, 'n_steps': 9, 'gamma': 1.0965975917313917, 'n_independent': 3, 'n_shared': 3, 'momentum': 0.1446368592021096}. Best is trial 55 with value: 0.5396906733512878.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 39.02305| val_0_mse: 626.8414306640625|  0:00:00s\n","epoch 1  | loss: 6.72392 | val_0_mse: 1139.8466796875|  0:00:01s\n","epoch 2  | loss: 2.58    | val_0_mse: 568.9989013671875|  0:00:01s\n","epoch 3  | loss: 1.97721 | val_0_mse: 282.0613708496094|  0:00:02s\n","epoch 4  | loss: 1.33088 | val_0_mse: 45.01451110839844|  0:00:02s\n","epoch 5  | loss: 1.04188 | val_0_mse: 36.39537811279297|  0:00:03s\n","epoch 6  | loss: 0.99586 | val_0_mse: 43.8831787109375|  0:00:03s\n","epoch 7  | loss: 0.92362 | val_0_mse: 72.43357849121094|  0:00:04s\n","epoch 8  | loss: 0.81157 | val_0_mse: 33.41120147705078|  0:00:04s\n","epoch 9  | loss: 0.7052  | val_0_mse: 43.510398864746094|  0:00:05s\n","epoch 10 | loss: 0.73828 | val_0_mse: 26.120859146118164|  0:00:05s\n","epoch 11 | loss: 0.78071 | val_0_mse: 21.59705924987793|  0:00:06s\n","epoch 12 | loss: 0.81301 | val_0_mse: 58.87472152709961|  0:00:06s\n","epoch 13 | loss: 0.77291 | val_0_mse: 32.393558502197266|  0:00:07s\n","epoch 14 | loss: 0.83871 | val_0_mse: 36.98115921020508|  0:00:08s\n","epoch 15 | loss: 0.82216 | val_0_mse: 8.80226993560791|  0:00:08s\n","epoch 16 | loss: 0.84875 | val_0_mse: 13.983280181884766|  0:00:09s\n","epoch 17 | loss: 0.84973 | val_0_mse: 4.322609901428223|  0:00:09s\n","epoch 18 | loss: 0.8225  | val_0_mse: 11.274239540100098|  0:00:10s\n","epoch 19 | loss: 0.76668 | val_0_mse: 2.464139938354492|  0:00:10s\n","epoch 20 | loss: 0.75044 | val_0_mse: 5.603099822998047|  0:00:11s\n","epoch 21 | loss: 0.84897 | val_0_mse: 2.955090045928955|  0:00:11s\n","epoch 22 | loss: 0.59806 | val_0_mse: 2.936919927597046|  0:00:12s\n","epoch 23 | loss: 0.58175 | val_0_mse: 2.7780399322509766|  0:00:12s\n","epoch 24 | loss: 0.57559 | val_0_mse: 3.8804900646209717|  0:00:13s\n","epoch 25 | loss: 0.5538  | val_0_mse: 2.7846601009368896|  0:00:13s\n","epoch 26 | loss: 0.56212 | val_0_mse: 3.324470043182373|  0:00:14s\n","epoch 27 | loss: 0.5879  | val_0_mse: 2.8501200675964355|  0:00:15s\n","epoch 28 | loss: 0.5654  | val_0_mse: 2.1689200401306152|  0:00:15s\n","epoch 29 | loss: 0.57542 | val_0_mse: 1.874150037765503|  0:00:16s\n","epoch 30 | loss: 0.56531 | val_0_mse: 1.3311200141906738|  0:00:16s\n","epoch 31 | loss: 0.55412 | val_0_mse: 1.1626100540161133|  0:00:17s\n","epoch 32 | loss: 0.56341 | val_0_mse: 2.1002399921417236|  0:00:17s\n","epoch 33 | loss: 0.55891 | val_0_mse: 1.6454700231552124|  0:00:18s\n","epoch 34 | loss: 0.53473 | val_0_mse: 1.600559949874878|  0:00:18s\n","epoch 35 | loss: 0.53794 | val_0_mse: 1.2416800260543823|  0:00:19s\n","epoch 36 | loss: 0.52007 | val_0_mse: 1.076740026473999|  0:00:19s\n","epoch 37 | loss: 0.55689 | val_0_mse: 1.6290700435638428|  0:00:20s\n","epoch 38 | loss: 0.5428  | val_0_mse: 1.372230052947998|  0:00:20s\n","epoch 39 | loss: 0.54479 | val_0_mse: 1.162719964981079|  0:00:21s\n","epoch 40 | loss: 0.54386 | val_0_mse: 1.3597700595855713|  0:00:21s\n","epoch 41 | loss: 0.51721 | val_0_mse: 1.2347500324249268|  0:00:22s\n","epoch 42 | loss: 0.52789 | val_0_mse: 1.134809970855713|  0:00:23s\n","epoch 43 | loss: 0.55838 | val_0_mse: 1.107890009880066|  0:00:23s\n","epoch 44 | loss: 0.53763 | val_0_mse: 0.9127200245857239|  0:00:24s\n","epoch 45 | loss: 0.52672 | val_0_mse: 0.8831200003623962|  0:00:24s\n","epoch 46 | loss: 0.53011 | val_0_mse: 0.8357099890708923|  0:00:25s\n","epoch 47 | loss: 0.53952 | val_0_mse: 1.048550009727478|  0:00:25s\n","epoch 48 | loss: 0.54712 | val_0_mse: 1.0359599590301514|  0:00:26s\n","epoch 49 | loss: 0.5233  | val_0_mse: 0.6955699920654297|  0:00:26s\n","epoch 50 | loss: 0.55259 | val_0_mse: 0.8336499929428101|  0:00:27s\n","epoch 51 | loss: 0.52822 | val_0_mse: 0.8640000224113464|  0:00:28s\n","epoch 52 | loss: 0.5278  | val_0_mse: 0.7268499732017517|  0:00:28s\n","epoch 53 | loss: 0.52551 | val_0_mse: 0.8167600035667419|  0:00:29s\n","epoch 54 | loss: 0.53609 | val_0_mse: 0.811460018157959|  0:00:29s\n","epoch 55 | loss: 0.5289  | val_0_mse: 0.6977499723434448|  0:00:30s\n","epoch 56 | loss: 0.53372 | val_0_mse: 0.658240020275116|  0:00:30s\n","epoch 57 | loss: 0.54069 | val_0_mse: 0.7226200103759766|  0:00:31s\n","epoch 58 | loss: 0.51762 | val_0_mse: 0.6865299940109253|  0:00:31s\n","epoch 59 | loss: 0.51009 | val_0_mse: 0.6778200268745422|  0:00:32s\n","epoch 60 | loss: 0.5153  | val_0_mse: 0.6234700083732605|  0:00:32s\n","epoch 61 | loss: 0.51677 | val_0_mse: 0.614080011844635|  0:00:33s\n","epoch 62 | loss: 0.52577 | val_0_mse: 0.6290900111198425|  0:00:33s\n","epoch 63 | loss: 0.51381 | val_0_mse: 0.6499000191688538|  0:00:34s\n","epoch 64 | loss: 0.53158 | val_0_mse: 0.6380000114440918|  0:00:34s\n","epoch 65 | loss: 0.52817 | val_0_mse: 0.6198400259017944|  0:00:35s\n","epoch 66 | loss: 0.51835 | val_0_mse: 0.6372399926185608|  0:00:36s\n","epoch 67 | loss: 0.53011 | val_0_mse: 0.5972499847412109|  0:00:36s\n","epoch 68 | loss: 0.50648 | val_0_mse: 0.61735999584198|  0:00:37s\n","epoch 69 | loss: 0.50376 | val_0_mse: 0.6236699819564819|  0:00:37s\n","epoch 70 | loss: 0.51281 | val_0_mse: 0.6231300234794617|  0:00:38s\n","epoch 71 | loss: 0.50614 | val_0_mse: 0.648930013179779|  0:00:38s\n","epoch 72 | loss: 0.50354 | val_0_mse: 0.6358500123023987|  0:00:39s\n","epoch 73 | loss: 0.50441 | val_0_mse: 0.639549970626831|  0:00:39s\n","epoch 74 | loss: 0.52896 | val_0_mse: 0.66211998462677|  0:00:40s\n","epoch 75 | loss: 0.51775 | val_0_mse: 0.6189000010490417|  0:00:40s\n","epoch 76 | loss: 0.50181 | val_0_mse: 0.6168000102043152|  0:00:41s\n","epoch 77 | loss: 0.50306 | val_0_mse: 0.5902900099754333|  0:00:41s\n","epoch 78 | loss: 0.48353 | val_0_mse: 0.5994700193405151|  0:00:42s\n","epoch 79 | loss: 0.5005  | val_0_mse: 0.5992000102996826|  0:00:42s\n","epoch 80 | loss: 0.48748 | val_0_mse: 0.6063500046730042|  0:00:43s\n","epoch 81 | loss: 0.48664 | val_0_mse: 0.6000199913978577|  0:00:43s\n","epoch 82 | loss: 0.48342 | val_0_mse: 0.6305500268936157|  0:00:44s\n","epoch 83 | loss: 0.50375 | val_0_mse: 0.613290011882782|  0:00:45s\n","epoch 84 | loss: 0.50005 | val_0_mse: 0.5984500050544739|  0:00:45s\n","epoch 85 | loss: 0.48429 | val_0_mse: 0.6504300236701965|  0:00:46s\n","epoch 86 | loss: 0.49163 | val_0_mse: 0.6212999820709229|  0:00:46s\n","epoch 87 | loss: 0.48725 | val_0_mse: 0.6258900165557861|  0:00:47s\n","\n","Early stopping occurred at epoch 87 with best_epoch = 77 and best_val_0_mse = 0.5902900099754333\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 16:27:04,684] Trial 63 finished with value: 0.5902869701385498 and parameters: {'n_d': 17, 'n_steps': 8, 'gamma': 1.1417933389276944, 'n_independent': 3, 'n_shared': 3, 'momentum': 0.03902944515090657}. Best is trial 55 with value: 0.5396906733512878.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 102.6027| val_0_mse: 1768.8162841796875|  0:00:00s\n","epoch 1  | loss: 14.44581| val_0_mse: 432.829833984375|  0:00:01s\n","epoch 2  | loss: 3.66697 | val_0_mse: 370.4205322265625|  0:00:01s\n","epoch 3  | loss: 2.15514 | val_0_mse: 99.99011993408203|  0:00:02s\n","epoch 4  | loss: 1.80371 | val_0_mse: 83.75173950195312|  0:00:03s\n","epoch 5  | loss: 1.26676 | val_0_mse: 133.66212463378906|  0:00:04s\n","epoch 6  | loss: 1.23424 | val_0_mse: 89.078857421875|  0:00:04s\n","epoch 7  | loss: 1.06969 | val_0_mse: 27.899560928344727|  0:00:05s\n","epoch 8  | loss: 1.00427 | val_0_mse: 47.65399932861328|  0:00:05s\n","epoch 9  | loss: 0.86133 | val_0_mse: 8.62185001373291|  0:00:06s\n","epoch 10 | loss: 0.83622 | val_0_mse: 7.312819957733154|  0:00:07s\n","epoch 11 | loss: 0.7303  | val_0_mse: 2.6775999069213867|  0:00:08s\n","epoch 12 | loss: 0.75587 | val_0_mse: 13.366009712219238|  0:00:08s\n","epoch 13 | loss: 0.71911 | val_0_mse: 6.656839847564697|  0:00:09s\n","epoch 14 | loss: 0.75033 | val_0_mse: 5.766359806060791|  0:00:10s\n","epoch 15 | loss: 0.6878  | val_0_mse: 2.658440113067627|  0:00:10s\n","epoch 16 | loss: 0.71138 | val_0_mse: 9.24020004272461|  0:00:11s\n","epoch 17 | loss: 0.66663 | val_0_mse: 4.028130054473877|  0:00:12s\n","epoch 18 | loss: 0.64238 | val_0_mse: 2.377470016479492|  0:00:12s\n","epoch 19 | loss: 0.8359  | val_0_mse: 1.9192899465560913|  0:00:13s\n","epoch 20 | loss: 0.75128 | val_0_mse: 1.669569969177246|  0:00:14s\n","epoch 21 | loss: 0.64402 | val_0_mse: 1.8339600563049316|  0:00:14s\n","epoch 22 | loss: 0.68905 | val_0_mse: 2.4756898880004883|  0:00:15s\n","epoch 23 | loss: 0.60432 | val_0_mse: 3.056720018386841|  0:00:16s\n","epoch 24 | loss: 0.65194 | val_0_mse: 1.632390022277832|  0:00:16s\n","epoch 25 | loss: 0.60219 | val_0_mse: 1.571470022201538|  0:00:17s\n","epoch 26 | loss: 0.58006 | val_0_mse: 2.367889881134033|  0:00:18s\n","epoch 27 | loss: 0.55776 | val_0_mse: 1.9365299940109253|  0:00:18s\n","epoch 28 | loss: 0.58877 | val_0_mse: 1.4330799579620361|  0:00:19s\n","epoch 29 | loss: 0.55345 | val_0_mse: 2.2032101154327393|  0:00:20s\n","epoch 30 | loss: 0.56809 | val_0_mse: 1.2059799432754517|  0:00:20s\n","epoch 31 | loss: 0.54747 | val_0_mse: 1.2369999885559082|  0:00:21s\n","epoch 32 | loss: 0.52044 | val_0_mse: 1.9623299837112427|  0:00:22s\n","epoch 33 | loss: 0.52525 | val_0_mse: 1.0552599430084229|  0:00:22s\n","epoch 34 | loss: 0.51049 | val_0_mse: 1.005519986152649|  0:00:23s\n","epoch 35 | loss: 0.50054 | val_0_mse: 0.8944500088691711|  0:00:24s\n","epoch 36 | loss: 0.5357  | val_0_mse: 1.0872900485992432|  0:00:24s\n","epoch 37 | loss: 0.51574 | val_0_mse: 0.8383600115776062|  0:00:25s\n","epoch 38 | loss: 0.50359 | val_0_mse: 0.7257599830627441|  0:00:26s\n","epoch 39 | loss: 0.51752 | val_0_mse: 1.1138499975204468|  0:00:26s\n","epoch 40 | loss: 0.53028 | val_0_mse: 0.8114100098609924|  0:00:27s\n","epoch 41 | loss: 0.53414 | val_0_mse: 1.051800012588501|  0:00:28s\n","epoch 42 | loss: 0.51082 | val_0_mse: 0.9150800108909607|  0:00:28s\n","epoch 43 | loss: 0.50333 | val_0_mse: 0.7985299825668335|  0:00:29s\n","epoch 44 | loss: 0.52631 | val_0_mse: 1.1021300554275513|  0:00:30s\n","epoch 45 | loss: 0.52923 | val_0_mse: 0.8909000158309937|  0:00:30s\n","epoch 46 | loss: 0.50978 | val_0_mse: 0.7283499836921692|  0:00:31s\n","epoch 47 | loss: 0.52294 | val_0_mse: 1.0298000574111938|  0:00:32s\n","epoch 48 | loss: 0.50479 | val_0_mse: 0.9274600148200989|  0:00:32s\n","\n","Early stopping occurred at epoch 48 with best_epoch = 38 and best_val_0_mse = 0.7257599830627441\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 16:27:37,774] Trial 64 finished with value: 0.725757896900177 and parameters: {'n_d': 22, 'n_steps': 9, 'gamma': 1.000328709200529, 'n_independent': 4, 'n_shared': 3, 'momentum': 0.2554836729224866}. Best is trial 55 with value: 0.5396906733512878.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 22.48632| val_0_mse: 2188.439208984375|  0:00:00s\n","epoch 1  | loss: 5.43643 | val_0_mse: 1313.0809326171875|  0:00:01s\n","epoch 2  | loss: 3.76494 | val_0_mse: 1197.217041015625|  0:00:01s\n","epoch 3  | loss: 2.32411 | val_0_mse: 106.84764099121094|  0:00:02s\n","epoch 4  | loss: 1.88231 | val_0_mse: 54.4651985168457|  0:00:03s\n","epoch 5  | loss: 1.42101 | val_0_mse: 146.6061553955078|  0:00:03s\n","epoch 6  | loss: 1.22168 | val_0_mse: 64.1749496459961|  0:00:04s\n","epoch 7  | loss: 0.98641 | val_0_mse: 23.488000869750977|  0:00:05s\n","epoch 8  | loss: 0.92778 | val_0_mse: 25.634380340576172|  0:00:05s\n","epoch 9  | loss: 0.86248 | val_0_mse: 59.94847869873047|  0:00:06s\n","epoch 10 | loss: 0.78844 | val_0_mse: 53.668418884277344|  0:00:07s\n","epoch 11 | loss: 0.75768 | val_0_mse: 8.723150253295898|  0:00:07s\n","epoch 12 | loss: 0.97549 | val_0_mse: 30.754289627075195|  0:00:08s\n","epoch 13 | loss: 0.90586 | val_0_mse: 11.02968978881836|  0:00:09s\n","epoch 14 | loss: 0.92312 | val_0_mse: 19.678070068359375|  0:00:09s\n","epoch 15 | loss: 0.77046 | val_0_mse: 17.833049774169922|  0:00:10s\n","epoch 16 | loss: 0.78055 | val_0_mse: 7.7137298583984375|  0:00:11s\n","epoch 17 | loss: 0.68046 | val_0_mse: 2.790440082550049|  0:00:11s\n","epoch 18 | loss: 0.68269 | val_0_mse: 6.735779762268066|  0:00:12s\n","epoch 19 | loss: 0.6345  | val_0_mse: 3.8033299446105957|  0:00:13s\n","epoch 20 | loss: 0.61707 | val_0_mse: 1.967479944229126|  0:00:13s\n","epoch 21 | loss: 0.6333  | val_0_mse: 1.4223500490188599|  0:00:14s\n","epoch 22 | loss: 0.60731 | val_0_mse: 1.7862600088119507|  0:00:15s\n","epoch 23 | loss: 0.60035 | val_0_mse: 3.126189947128296|  0:00:15s\n","epoch 24 | loss: 0.62348 | val_0_mse: 2.2214999198913574|  0:00:16s\n","epoch 25 | loss: 0.6489  | val_0_mse: 4.759280204772949|  0:00:16s\n","epoch 26 | loss: 0.60855 | val_0_mse: 3.311110019683838|  0:00:17s\n","epoch 27 | loss: 0.58311 | val_0_mse: 1.4497300386428833|  0:00:18s\n","epoch 28 | loss: 0.55579 | val_0_mse: 2.125380039215088|  0:00:18s\n","epoch 29 | loss: 0.55526 | val_0_mse: 2.394279956817627|  0:00:19s\n","epoch 30 | loss: 0.56163 | val_0_mse: 1.0588799715042114|  0:00:20s\n","epoch 31 | loss: 0.54781 | val_0_mse: 1.6243300437927246|  0:00:20s\n","epoch 32 | loss: 0.58079 | val_0_mse: 1.113070011138916|  0:00:21s\n","epoch 33 | loss: 0.58004 | val_0_mse: 0.7615699768066406|  0:00:22s\n","epoch 34 | loss: 0.564   | val_0_mse: 1.0068399906158447|  0:00:22s\n","epoch 35 | loss: 0.58748 | val_0_mse: 1.920490026473999|  0:00:23s\n","epoch 36 | loss: 0.57551 | val_0_mse: 1.1352699995040894|  0:00:23s\n","epoch 37 | loss: 0.55684 | val_0_mse: 1.2686400413513184|  0:00:24s\n","epoch 38 | loss: 0.54908 | val_0_mse: 1.350640058517456|  0:00:25s\n","epoch 39 | loss: 0.54784 | val_0_mse: 1.0956799983978271|  0:00:25s\n","epoch 40 | loss: 0.56307 | val_0_mse: 1.5941200256347656|  0:00:26s\n","epoch 41 | loss: 0.54177 | val_0_mse: 1.372480034828186|  0:00:27s\n","epoch 42 | loss: 0.54502 | val_0_mse: 1.6098999977111816|  0:00:27s\n","epoch 43 | loss: 0.59316 | val_0_mse: 0.6701700091362|  0:00:28s\n","epoch 44 | loss: 0.70951 | val_0_mse: 1.1950099468231201|  0:00:29s\n","epoch 45 | loss: 0.62794 | val_0_mse: 0.7287899851799011|  0:00:29s\n","epoch 46 | loss: 0.59909 | val_0_mse: 1.2182400226593018|  0:00:30s\n","epoch 47 | loss: 0.55514 | val_0_mse: 0.7397900223731995|  0:00:30s\n","epoch 48 | loss: 0.51833 | val_0_mse: 0.762719988822937|  0:00:31s\n","epoch 49 | loss: 0.52335 | val_0_mse: 0.6887099742889404|  0:00:32s\n","epoch 50 | loss: 0.52415 | val_0_mse: 0.7311999797821045|  0:00:32s\n","epoch 51 | loss: 0.51217 | val_0_mse: 0.7029299736022949|  0:00:33s\n","epoch 52 | loss: 0.52818 | val_0_mse: 0.702459990978241|  0:00:34s\n","epoch 53 | loss: 0.52572 | val_0_mse: 0.7098000049591064|  0:00:34s\n","\n","Early stopping occurred at epoch 53 with best_epoch = 43 and best_val_0_mse = 0.6701700091362\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 16:28:12,896] Trial 65 finished with value: 0.6701656579971313 and parameters: {'n_d': 19, 'n_steps': 10, 'gamma': 1.0615575823454426, 'n_independent': 3, 'n_shared': 3, 'momentum': 0.19458749980740725}. Best is trial 55 with value: 0.5396906733512878.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 63.50195| val_0_mse: 880.4093017578125|  0:00:00s\n","epoch 1  | loss: 18.16112| val_0_mse: 611.9293823242188|  0:00:01s\n","epoch 2  | loss: 5.08897 | val_0_mse: 1132.710205078125|  0:00:01s\n","epoch 3  | loss: 3.9862  | val_0_mse: 215.88302612304688|  0:00:02s\n","epoch 4  | loss: 1.85767 | val_0_mse: 71.25263977050781|  0:00:02s\n","epoch 5  | loss: 1.46486 | val_0_mse: 64.57772064208984|  0:00:03s\n","epoch 6  | loss: 2.54507 | val_0_mse: 126.5059585571289|  0:00:03s\n","epoch 7  | loss: 1.96886 | val_0_mse: 27.24020004272461|  0:00:04s\n","epoch 8  | loss: 1.16159 | val_0_mse: 15.466489791870117|  0:00:04s\n","epoch 9  | loss: 0.92527 | val_0_mse: 8.111809730529785|  0:00:05s\n","epoch 10 | loss: 0.99098 | val_0_mse: 5.2271199226379395|  0:00:06s\n","epoch 11 | loss: 0.99371 | val_0_mse: 16.470230102539062|  0:00:06s\n","epoch 12 | loss: 1.37036 | val_0_mse: 3.9961400032043457|  0:00:07s\n","epoch 13 | loss: 1.7848  | val_0_mse: 3.1225600242614746|  0:00:07s\n","epoch 14 | loss: 1.17448 | val_0_mse: 20.390560150146484|  0:00:08s\n","epoch 15 | loss: 1.64753 | val_0_mse: 9.35828971862793|  0:00:08s\n","epoch 16 | loss: 1.11362 | val_0_mse: 2.537450075149536|  0:00:09s\n","epoch 17 | loss: 1.27367 | val_0_mse: 4.710770130157471|  0:00:09s\n","epoch 18 | loss: 1.12982 | val_0_mse: 5.239560127258301|  0:00:10s\n","epoch 19 | loss: 0.77553 | val_0_mse: 1.731760025024414|  0:00:10s\n","epoch 20 | loss: 0.74217 | val_0_mse: 4.058380126953125|  0:00:11s\n","epoch 21 | loss: 0.75265 | val_0_mse: 2.903559923171997|  0:00:12s\n","epoch 22 | loss: 0.91061 | val_0_mse: 1.498039960861206|  0:00:12s\n","epoch 23 | loss: 0.82902 | val_0_mse: 2.732140064239502|  0:00:13s\n","epoch 24 | loss: 0.76207 | val_0_mse: 1.1545900106430054|  0:00:13s\n","epoch 25 | loss: 0.76442 | val_0_mse: 1.293969988822937|  0:00:14s\n","epoch 26 | loss: 0.83305 | val_0_mse: 1.3785899877548218|  0:00:14s\n","epoch 27 | loss: 0.73011 | val_0_mse: 1.1589800119400024|  0:00:15s\n","epoch 28 | loss: 0.79751 | val_0_mse: 1.1412099599838257|  0:00:15s\n","epoch 29 | loss: 0.73873 | val_0_mse: 1.1076500415802002|  0:00:16s\n","epoch 30 | loss: 0.68446 | val_0_mse: 1.033270001411438|  0:00:16s\n","epoch 31 | loss: 0.64293 | val_0_mse: 1.0311800241470337|  0:00:17s\n","epoch 32 | loss: 0.62633 | val_0_mse: 1.279729962348938|  0:00:17s\n","epoch 33 | loss: 0.63807 | val_0_mse: 1.1025700569152832|  0:00:18s\n","epoch 34 | loss: 0.63841 | val_0_mse: 1.1117700338363647|  0:00:18s\n","epoch 35 | loss: 0.62855 | val_0_mse: 0.8246899843215942|  0:00:19s\n","epoch 36 | loss: 0.59997 | val_0_mse: 0.8197500109672546|  0:00:20s\n","epoch 37 | loss: 0.59538 | val_0_mse: 0.8738499879837036|  0:00:20s\n","epoch 38 | loss: 0.62124 | val_0_mse: 0.8333899974822998|  0:00:21s\n","epoch 39 | loss: 0.62565 | val_0_mse: 0.962909996509552|  0:00:21s\n","epoch 40 | loss: 0.62129 | val_0_mse: 0.9151600003242493|  0:00:22s\n","epoch 41 | loss: 0.60985 | val_0_mse: 0.8532900214195251|  0:00:22s\n","epoch 42 | loss: 0.59911 | val_0_mse: 0.8451600074768066|  0:00:23s\n","epoch 43 | loss: 0.61476 | val_0_mse: 0.904420018196106|  0:00:23s\n","epoch 44 | loss: 0.64872 | val_0_mse: 1.0126999616622925|  0:00:24s\n","epoch 45 | loss: 0.64956 | val_0_mse: 0.8392400145530701|  0:00:24s\n","epoch 46 | loss: 0.59704 | val_0_mse: 0.7692400217056274|  0:00:25s\n","epoch 47 | loss: 0.58517 | val_0_mse: 0.7303400039672852|  0:00:25s\n","epoch 48 | loss: 0.6208  | val_0_mse: 0.6986500024795532|  0:00:26s\n","epoch 49 | loss: 0.62427 | val_0_mse: 0.7765499949455261|  0:00:26s\n","epoch 50 | loss: 0.68548 | val_0_mse: 0.7468000054359436|  0:00:27s\n","epoch 51 | loss: 0.84045 | val_0_mse: 0.9176599979400635|  0:00:27s\n","epoch 52 | loss: 0.76097 | val_0_mse: 1.0353399515151978|  0:00:28s\n","epoch 53 | loss: 0.75649 | val_0_mse: 0.7266499996185303|  0:00:28s\n","epoch 54 | loss: 0.72052 | val_0_mse: 0.7185699939727783|  0:00:29s\n","epoch 55 | loss: 0.62174 | val_0_mse: 0.7052800059318542|  0:00:30s\n","epoch 56 | loss: 0.77748 | val_0_mse: 0.8768900036811829|  0:00:30s\n","epoch 57 | loss: 0.68393 | val_0_mse: 0.8654599785804749|  0:00:31s\n","epoch 58 | loss: 0.67975 | val_0_mse: 0.7691799998283386|  0:00:31s\n","\n","Early stopping occurred at epoch 58 with best_epoch = 48 and best_val_0_mse = 0.6986500024795532\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 16:28:44,897] Trial 66 finished with value: 0.698646605014801 and parameters: {'n_d': 14, 'n_steps': 8, 'gamma': 1.7569331037334484, 'n_independent': 4, 'n_shared': 2, 'momentum': 0.08932405368835686}. Best is trial 55 with value: 0.5396906733512878.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 10.98336| val_0_mse: 3170.900390625|  0:00:00s\n","epoch 1  | loss: 4.27118 | val_0_mse: 1112.7318115234375|  0:00:01s\n","epoch 2  | loss: 1.87481 | val_0_mse: 108.03077697753906|  0:00:01s\n","epoch 3  | loss: 1.35896 | val_0_mse: 69.79857635498047|  0:00:02s\n","epoch 4  | loss: 0.98251 | val_0_mse: 57.83538818359375|  0:00:02s\n","epoch 5  | loss: 0.87647 | val_0_mse: 32.75038146972656|  0:00:02s\n","epoch 6  | loss: 0.79879 | val_0_mse: 37.807010650634766|  0:00:03s\n","epoch 7  | loss: 0.77888 | val_0_mse: 18.188400268554688|  0:00:04s\n","epoch 8  | loss: 0.71658 | val_0_mse: 6.365509986877441|  0:00:04s\n","epoch 9  | loss: 0.74551 | val_0_mse: 8.297140121459961|  0:00:05s\n","epoch 10 | loss: 0.70051 | val_0_mse: 8.513540267944336|  0:00:05s\n","epoch 11 | loss: 0.65991 | val_0_mse: 5.444690227508545|  0:00:06s\n","epoch 12 | loss: 0.64741 | val_0_mse: 4.045949935913086|  0:00:06s\n","epoch 13 | loss: 0.66464 | val_0_mse: 2.6173999309539795|  0:00:06s\n","epoch 14 | loss: 0.67958 | val_0_mse: 3.4312000274658203|  0:00:07s\n","epoch 15 | loss: 0.66616 | val_0_mse: 1.7575500011444092|  0:00:07s\n","epoch 16 | loss: 0.70219 | val_0_mse: 1.1926599740982056|  0:00:08s\n","epoch 17 | loss: 0.64112 | val_0_mse: 1.1853200197219849|  0:00:08s\n","epoch 18 | loss: 0.6692  | val_0_mse: 1.2000099420547485|  0:00:09s\n","epoch 19 | loss: 0.66857 | val_0_mse: 2.426340103149414|  0:00:09s\n","epoch 20 | loss: 0.63983 | val_0_mse: 1.7473000288009644|  0:00:10s\n","epoch 21 | loss: 0.57014 | val_0_mse: 1.9392399787902832|  0:00:10s\n","epoch 22 | loss: 0.59077 | val_0_mse: 3.470979928970337|  0:00:11s\n","epoch 23 | loss: 0.57744 | val_0_mse: 3.5002200603485107|  0:00:11s\n","epoch 24 | loss: 0.57417 | val_0_mse: 3.321579933166504|  0:00:12s\n","epoch 25 | loss: 0.58869 | val_0_mse: 0.9147700071334839|  0:00:12s\n","epoch 26 | loss: 0.59318 | val_0_mse: 1.7032999992370605|  0:00:13s\n","epoch 27 | loss: 0.56489 | val_0_mse: 1.488510012626648|  0:00:13s\n","epoch 28 | loss: 0.54241 | val_0_mse: 1.003909945487976|  0:00:14s\n","epoch 29 | loss: 0.53555 | val_0_mse: 1.276170015335083|  0:00:14s\n","epoch 30 | loss: 0.56851 | val_0_mse: 1.4134700298309326|  0:00:15s\n","epoch 31 | loss: 0.54783 | val_0_mse: 1.1515300273895264|  0:00:15s\n","epoch 32 | loss: 0.54876 | val_0_mse: 1.2265599966049194|  0:00:16s\n","epoch 33 | loss: 0.53049 | val_0_mse: 1.0706499814987183|  0:00:16s\n","epoch 34 | loss: 0.53533 | val_0_mse: 1.180359959602356|  0:00:16s\n","epoch 35 | loss: 0.5375  | val_0_mse: 0.921720027923584|  0:00:17s\n","\n","Early stopping occurred at epoch 35 with best_epoch = 25 and best_val_0_mse = 0.9147700071334839\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 16:29:02,656] Trial 67 finished with value: 0.9147696495056152 and parameters: {'n_d': 15, 'n_steps': 7, 'gamma': 1.165270616633519, 'n_independent': 2, 'n_shared': 4, 'momentum': 0.22469029617896477}. Best is trial 55 with value: 0.5396906733512878.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 34.63482| val_0_mse: 164.12759399414062|  0:00:00s\n","epoch 1  | loss: 4.89344 | val_0_mse: 247.1404266357422|  0:00:00s\n","epoch 2  | loss: 1.97051 | val_0_mse: 139.7386016845703|  0:00:01s\n","epoch 3  | loss: 1.35829 | val_0_mse: 80.9981689453125|  0:00:01s\n","epoch 4  | loss: 0.96452 | val_0_mse: 53.355621337890625|  0:00:02s\n","epoch 5  | loss: 0.79811 | val_0_mse: 14.470100402832031|  0:00:02s\n","epoch 6  | loss: 0.72118 | val_0_mse: 7.338659763336182|  0:00:02s\n","epoch 7  | loss: 0.74306 | val_0_mse: 9.842599868774414|  0:00:03s\n","epoch 8  | loss: 0.70388 | val_0_mse: 12.183289527893066|  0:00:03s\n","epoch 9  | loss: 0.68537 | val_0_mse: 9.59358024597168|  0:00:04s\n","epoch 10 | loss: 0.67551 | val_0_mse: 6.659780025482178|  0:00:04s\n","epoch 11 | loss: 0.71268 | val_0_mse: 5.588560104370117|  0:00:05s\n","epoch 12 | loss: 0.65631 | val_0_mse: 2.7797200679779053|  0:00:05s\n","epoch 13 | loss: 0.64906 | val_0_mse: 2.067729949951172|  0:00:06s\n","epoch 14 | loss: 0.65214 | val_0_mse: 2.8696699142456055|  0:00:06s\n","epoch 15 | loss: 0.64339 | val_0_mse: 2.788059949874878|  0:00:06s\n","epoch 16 | loss: 0.61124 | val_0_mse: 2.513979911804199|  0:00:07s\n","epoch 17 | loss: 0.60664 | val_0_mse: 2.5230600833892822|  0:00:07s\n","epoch 18 | loss: 0.5901  | val_0_mse: 2.558150053024292|  0:00:08s\n","epoch 19 | loss: 0.61761 | val_0_mse: 2.1465001106262207|  0:00:08s\n","epoch 20 | loss: 0.61377 | val_0_mse: 1.8894200325012207|  0:00:08s\n","epoch 21 | loss: 0.58591 | val_0_mse: 2.387860059738159|  0:00:09s\n","epoch 22 | loss: 0.57776 | val_0_mse: 2.0513699054718018|  0:00:09s\n","epoch 23 | loss: 0.60092 | val_0_mse: 2.8089098930358887|  0:00:10s\n","epoch 24 | loss: 0.64442 | val_0_mse: 1.2286200523376465|  0:00:10s\n","epoch 25 | loss: 0.59639 | val_0_mse: 1.5396900177001953|  0:00:11s\n","epoch 26 | loss: 0.56772 | val_0_mse: 1.5263999700546265|  0:00:11s\n","epoch 27 | loss: 0.54946 | val_0_mse: 2.747580051422119|  0:00:11s\n","epoch 28 | loss: 0.53916 | val_0_mse: 3.238960027694702|  0:00:12s\n","epoch 29 | loss: 0.55367 | val_0_mse: 2.012079954147339|  0:00:12s\n","epoch 30 | loss: 0.5549  | val_0_mse: 3.3854598999023438|  0:00:13s\n","epoch 31 | loss: 0.54562 | val_0_mse: 1.3047000169754028|  0:00:13s\n","epoch 32 | loss: 0.52713 | val_0_mse: 1.4415899515151978|  0:00:14s\n","epoch 33 | loss: 0.53168 | val_0_mse: 1.5127300024032593|  0:00:14s\n","epoch 34 | loss: 0.52741 | val_0_mse: 1.7962599992752075|  0:00:14s\n","\n","Early stopping occurred at epoch 34 with best_epoch = 24 and best_val_0_mse = 1.2286200523376465\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 16:29:17,897] Trial 68 finished with value: 1.228621244430542 and parameters: {'n_d': 32, 'n_steps': 6, 'gamma': 1.3162751421180956, 'n_independent': 3, 'n_shared': 3, 'momentum': 0.11262872080309641}. Best is trial 55 with value: 0.5396906733512878.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 23.61791| val_0_mse: 2138.690185546875|  0:00:00s\n","epoch 1  | loss: 9.39689 | val_0_mse: 639.5490112304688|  0:00:01s\n","epoch 2  | loss: 5.82209 | val_0_mse: 237.63180541992188|  0:00:01s\n","epoch 3  | loss: 3.65405 | val_0_mse: 76.7965087890625|  0:00:02s\n","epoch 4  | loss: 2.41893 | val_0_mse: 39.67639923095703|  0:00:03s\n","epoch 5  | loss: 1.45762 | val_0_mse: 4.611649990081787|  0:00:03s\n","epoch 6  | loss: 1.19069 | val_0_mse: 3.375159978866577|  0:00:04s\n","epoch 7  | loss: 0.95811 | val_0_mse: 8.510979652404785|  0:00:04s\n","epoch 8  | loss: 0.87911 | val_0_mse: 6.561860084533691|  0:00:05s\n","epoch 9  | loss: 0.80451 | val_0_mse: 5.274419784545898|  0:00:05s\n","epoch 10 | loss: 0.91679 | val_0_mse: 6.998640060424805|  0:00:06s\n","epoch 11 | loss: 0.78057 | val_0_mse: 12.19081974029541|  0:00:07s\n","epoch 12 | loss: 0.87384 | val_0_mse: 3.274199962615967|  0:00:07s\n","epoch 13 | loss: 1.06126 | val_0_mse: 3.7664499282836914|  0:00:08s\n","epoch 14 | loss: 0.82799 | val_0_mse: 4.655099868774414|  0:00:08s\n","epoch 15 | loss: 0.82276 | val_0_mse: 1.6892199516296387|  0:00:09s\n","epoch 16 | loss: 0.7507  | val_0_mse: 2.9493300914764404|  0:00:10s\n","epoch 17 | loss: 0.77478 | val_0_mse: 1.8776799440383911|  0:00:10s\n","epoch 18 | loss: 0.92297 | val_0_mse: 1.7750999927520752|  0:00:11s\n","epoch 19 | loss: 1.08008 | val_0_mse: 1.7102199792861938|  0:00:11s\n","epoch 20 | loss: 0.76691 | val_0_mse: 1.7848800420761108|  0:00:12s\n","epoch 21 | loss: 0.66973 | val_0_mse: 1.3960299491882324|  0:00:12s\n","epoch 22 | loss: 0.62453 | val_0_mse: 1.1031299829483032|  0:00:13s\n","epoch 23 | loss: 0.62091 | val_0_mse: 1.9152799844741821|  0:00:14s\n","epoch 24 | loss: 0.64055 | val_0_mse: 2.0232200622558594|  0:00:14s\n","epoch 25 | loss: 0.6232  | val_0_mse: 3.6054999828338623|  0:00:15s\n","epoch 26 | loss: 0.62033 | val_0_mse: 1.8929599523544312|  0:00:15s\n","epoch 27 | loss: 0.6189  | val_0_mse: 1.3337899446487427|  0:00:16s\n","epoch 28 | loss: 0.64939 | val_0_mse: 2.027740001678467|  0:00:16s\n","epoch 29 | loss: 0.66562 | val_0_mse: 1.0438100099563599|  0:00:17s\n","epoch 30 | loss: 0.61639 | val_0_mse: 1.3820899724960327|  0:00:18s\n","epoch 31 | loss: 0.58145 | val_0_mse: 1.4024800062179565|  0:00:18s\n","epoch 32 | loss: 0.61837 | val_0_mse: 1.7298500537872314|  0:00:19s\n","epoch 33 | loss: 0.60364 | val_0_mse: 1.00068998336792|  0:00:19s\n","epoch 34 | loss: 0.60783 | val_0_mse: 1.280769944190979|  0:00:20s\n","epoch 35 | loss: 0.58383 | val_0_mse: 1.121899962425232|  0:00:21s\n","epoch 36 | loss: 0.62218 | val_0_mse: 1.3167099952697754|  0:00:21s\n","epoch 37 | loss: 0.6341  | val_0_mse: 1.0190900564193726|  0:00:22s\n","epoch 38 | loss: 0.62311 | val_0_mse: 1.0230599641799927|  0:00:22s\n","epoch 39 | loss: 0.6195  | val_0_mse: 1.163290023803711|  0:00:23s\n","epoch 40 | loss: 0.62318 | val_0_mse: 1.1089199781417847|  0:00:23s\n","epoch 41 | loss: 0.61206 | val_0_mse: 1.1828099489212036|  0:00:24s\n","epoch 42 | loss: 0.6346  | val_0_mse: 1.223870038986206|  0:00:25s\n","epoch 43 | loss: 0.67679 | val_0_mse: 1.255769968032837|  0:00:25s\n","\n","Early stopping occurred at epoch 43 with best_epoch = 33 and best_val_0_mse = 1.00068998336792\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 16:29:43,920] Trial 69 finished with value: 1.0006874799728394 and parameters: {'n_d': 11, 'n_steps': 9, 'gamma': 1.4784877876406604, 'n_independent': 2, 'n_shared': 4, 'momentum': 0.010718479597890053}. Best is trial 55 with value: 0.5396906733512878.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 18.63981| val_0_mse: 2364.776611328125|  0:00:00s\n","epoch 1  | loss: 6.68594 | val_0_mse: 1444.2684326171875|  0:00:01s\n","epoch 2  | loss: 5.48633 | val_0_mse: 383.3540344238281|  0:00:02s\n","epoch 3  | loss: 8.74992 | val_0_mse: 626.6837768554688|  0:00:03s\n","epoch 4  | loss: 9.89653 | val_0_mse: 205.3439178466797|  0:00:04s\n","epoch 5  | loss: 9.28295 | val_0_mse: 234.43275451660156|  0:00:05s\n","epoch 6  | loss: 5.6877  | val_0_mse: 389.6133728027344|  0:00:05s\n","epoch 7  | loss: 2.46673 | val_0_mse: 65.9303970336914|  0:00:06s\n","epoch 8  | loss: 2.05829 | val_0_mse: 48.33882141113281|  0:00:07s\n","epoch 9  | loss: 1.36069 | val_0_mse: 54.643959045410156|  0:00:08s\n","epoch 10 | loss: 0.9603  | val_0_mse: 122.93875885009766|  0:00:09s\n","epoch 11 | loss: 1.01966 | val_0_mse: 48.78942108154297|  0:00:09s\n","epoch 12 | loss: 0.9115  | val_0_mse: 13.591730117797852|  0:00:10s\n","epoch 13 | loss: 1.50781 | val_0_mse: 33.101810455322266|  0:00:11s\n","epoch 14 | loss: 2.16236 | val_0_mse: 16.762859344482422|  0:00:12s\n","epoch 15 | loss: 1.30828 | val_0_mse: 11.017970085144043|  0:00:13s\n","epoch 16 | loss: 0.9385  | val_0_mse: 4.6621599197387695|  0:00:13s\n","epoch 17 | loss: 0.91953 | val_0_mse: 8.210089683532715|  0:00:14s\n","epoch 18 | loss: 0.76206 | val_0_mse: 4.568880081176758|  0:00:15s\n","epoch 19 | loss: 0.7071  | val_0_mse: 3.8243401050567627|  0:00:16s\n","epoch 20 | loss: 0.68867 | val_0_mse: 3.073820114135742|  0:00:17s\n","epoch 21 | loss: 0.74144 | val_0_mse: 2.98471999168396|  0:00:18s\n","epoch 22 | loss: 0.66224 | val_0_mse: 4.581809997558594|  0:00:18s\n","epoch 23 | loss: 0.80088 | val_0_mse: 4.367760181427002|  0:00:19s\n","epoch 24 | loss: 0.72671 | val_0_mse: 3.188230037689209|  0:00:20s\n","epoch 25 | loss: 0.67771 | val_0_mse: 3.1904399394989014|  0:00:21s\n","epoch 26 | loss: 0.65836 | val_0_mse: 1.901039958000183|  0:00:22s\n","epoch 27 | loss: 0.75798 | val_0_mse: 1.5908700227737427|  0:00:22s\n","epoch 28 | loss: 0.72779 | val_0_mse: 2.463779926300049|  0:00:23s\n","epoch 29 | loss: 0.69483 | val_0_mse: 1.6991300582885742|  0:00:24s\n","epoch 30 | loss: 0.63613 | val_0_mse: 1.4444400072097778|  0:00:25s\n","epoch 31 | loss: 0.60099 | val_0_mse: 2.2955100536346436|  0:00:26s\n","epoch 32 | loss: 0.70769 | val_0_mse: 1.0614299774169922|  0:00:26s\n","epoch 33 | loss: 0.68362 | val_0_mse: 1.682420015335083|  0:00:27s\n","epoch 34 | loss: 0.61906 | val_0_mse: 1.1420899629592896|  0:00:28s\n","epoch 35 | loss: 0.63812 | val_0_mse: 0.7882400155067444|  0:00:29s\n","epoch 36 | loss: 0.58516 | val_0_mse: 0.8057500123977661|  0:00:30s\n","epoch 37 | loss: 0.58463 | val_0_mse: 1.3770300149917603|  0:00:31s\n","epoch 38 | loss: 0.58499 | val_0_mse: 1.1970900297164917|  0:00:31s\n","epoch 39 | loss: 0.55679 | val_0_mse: 1.2666499614715576|  0:00:32s\n","epoch 40 | loss: 0.5853  | val_0_mse: 1.5674099922180176|  0:00:33s\n","epoch 41 | loss: 0.55346 | val_0_mse: 1.045549988746643|  0:00:34s\n","epoch 42 | loss: 0.55752 | val_0_mse: 1.1699299812316895|  0:00:35s\n","epoch 43 | loss: 0.59723 | val_0_mse: 0.7721899747848511|  0:00:35s\n","epoch 44 | loss: 0.67444 | val_0_mse: 1.2419999837875366|  0:00:36s\n","epoch 45 | loss: 0.59356 | val_0_mse: 1.0430200099945068|  0:00:37s\n","epoch 46 | loss: 0.56251 | val_0_mse: 0.7802299857139587|  0:00:38s\n","epoch 47 | loss: 0.51774 | val_0_mse: 0.9544100165367126|  0:00:39s\n","epoch 48 | loss: 0.56373 | val_0_mse: 1.0250600576400757|  0:00:39s\n","epoch 49 | loss: 0.58749 | val_0_mse: 0.7462999820709229|  0:00:40s\n","epoch 50 | loss: 0.64878 | val_0_mse: 1.3508000373840332|  0:00:41s\n","epoch 51 | loss: 0.70312 | val_0_mse: 0.6877599954605103|  0:00:42s\n","epoch 52 | loss: 0.62651 | val_0_mse: 1.082419991493225|  0:00:43s\n","epoch 53 | loss: 0.64379 | val_0_mse: 0.6599199771881104|  0:00:43s\n","epoch 54 | loss: 0.55706 | val_0_mse: 0.7271699905395508|  0:00:44s\n","epoch 55 | loss: 0.52666 | val_0_mse: 0.6864699721336365|  0:00:45s\n","epoch 56 | loss: 0.53289 | val_0_mse: 0.736840009689331|  0:00:46s\n","epoch 57 | loss: 0.53485 | val_0_mse: 0.8209999799728394|  0:00:47s\n","epoch 58 | loss: 0.52449 | val_0_mse: 0.8672299981117249|  0:00:47s\n","epoch 59 | loss: 0.54878 | val_0_mse: 0.979390025138855|  0:00:48s\n","epoch 60 | loss: 0.54636 | val_0_mse: 0.7096199989318848|  0:00:49s\n","epoch 61 | loss: 0.59213 | val_0_mse: 0.6477599740028381|  0:00:50s\n","epoch 62 | loss: 0.56525 | val_0_mse: 0.6976500153541565|  0:00:51s\n","epoch 63 | loss: 0.56366 | val_0_mse: 0.7080399990081787|  0:00:51s\n","epoch 64 | loss: 0.52769 | val_0_mse: 0.6764100193977356|  0:00:52s\n","epoch 65 | loss: 0.55207 | val_0_mse: 0.7123000025749207|  0:00:53s\n","epoch 66 | loss: 0.53347 | val_0_mse: 0.7215499877929688|  0:00:54s\n","epoch 67 | loss: 0.53717 | val_0_mse: 0.618910014629364|  0:00:55s\n","epoch 68 | loss: 0.50811 | val_0_mse: 0.6475899815559387|  0:00:55s\n","epoch 69 | loss: 0.51518 | val_0_mse: 0.6662399768829346|  0:00:56s\n","epoch 70 | loss: 0.5012  | val_0_mse: 0.6786500215530396|  0:00:57s\n","epoch 71 | loss: 0.51117 | val_0_mse: 0.6388000249862671|  0:00:58s\n","epoch 72 | loss: 0.53371 | val_0_mse: 0.6876800060272217|  0:00:59s\n","epoch 73 | loss: 0.60842 | val_0_mse: 0.6782199740409851|  0:00:59s\n","epoch 74 | loss: 0.52349 | val_0_mse: 0.6318399906158447|  0:01:00s\n","epoch 75 | loss: 0.51366 | val_0_mse: 0.5830399990081787|  0:01:01s\n","epoch 76 | loss: 0.52252 | val_0_mse: 0.6236199736595154|  0:01:02s\n","epoch 77 | loss: 0.52424 | val_0_mse: 0.6545799970626831|  0:01:03s\n","epoch 78 | loss: 0.5776  | val_0_mse: 0.7076500058174133|  0:01:03s\n","epoch 79 | loss: 0.58974 | val_0_mse: 0.7430499792098999|  0:01:04s\n","epoch 80 | loss: 0.58978 | val_0_mse: 0.7002300024032593|  0:01:05s\n","epoch 81 | loss: 0.59605 | val_0_mse: 0.7510799765586853|  0:01:06s\n","epoch 82 | loss: 0.59561 | val_0_mse: 0.682420015335083|  0:01:07s\n","epoch 83 | loss: 0.60779 | val_0_mse: 0.7768200039863586|  0:01:07s\n","epoch 84 | loss: 0.61563 | val_0_mse: 0.7971900105476379|  0:01:08s\n","epoch 85 | loss: 0.5542  | val_0_mse: 0.6002399921417236|  0:01:09s\n","\n","Early stopping occurred at epoch 85 with best_epoch = 75 and best_val_0_mse = 0.5830399990081787\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 16:30:53,926] Trial 70 finished with value: 0.5830413103103638 and parameters: {'n_d': 41, 'n_steps': 10, 'gamma': 1.1056121197318445, 'n_independent': 5, 'n_shared': 3, 'momentum': 0.048241615023072414}. Best is trial 55 with value: 0.5396906733512878.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 25.18797| val_0_mse: 847.593505859375|  0:00:00s\n","epoch 1  | loss: 9.49193 | val_0_mse: 939.53271484375|  0:00:01s\n","epoch 2  | loss: 4.89527 | val_0_mse: 219.0194549560547|  0:00:02s\n","epoch 3  | loss: 2.64282 | val_0_mse: 166.10549926757812|  0:00:03s\n","epoch 4  | loss: 1.84902 | val_0_mse: 182.0488739013672|  0:00:04s\n","epoch 5  | loss: 1.34886 | val_0_mse: 228.88026428222656|  0:00:04s\n","epoch 6  | loss: 1.15132 | val_0_mse: 41.99293899536133|  0:00:05s\n","epoch 7  | loss: 1.04157 | val_0_mse: 34.21538162231445|  0:00:06s\n","epoch 8  | loss: 1.07996 | val_0_mse: 12.630359649658203|  0:00:07s\n","epoch 9  | loss: 1.23882 | val_0_mse: 36.23426055908203|  0:00:08s\n","epoch 10 | loss: 1.00463 | val_0_mse: 15.068010330200195|  0:00:09s\n","epoch 11 | loss: 0.85946 | val_0_mse: 10.537039756774902|  0:00:09s\n","epoch 12 | loss: 1.68908 | val_0_mse: 22.83527946472168|  0:00:10s\n","epoch 13 | loss: 1.27305 | val_0_mse: 8.77184009552002|  0:00:11s\n","epoch 14 | loss: 0.96608 | val_0_mse: 36.59577941894531|  0:00:12s\n","epoch 15 | loss: 0.81779 | val_0_mse: 9.086509704589844|  0:00:13s\n","epoch 16 | loss: 0.81329 | val_0_mse: 4.930210113525391|  0:00:13s\n","epoch 17 | loss: 0.94562 | val_0_mse: 4.532760143280029|  0:00:14s\n","epoch 18 | loss: 0.80039 | val_0_mse: 2.61434006690979|  0:00:15s\n","epoch 19 | loss: 0.83876 | val_0_mse: 3.949039936065674|  0:00:16s\n","epoch 20 | loss: 0.70016 | val_0_mse: 2.6536900997161865|  0:00:17s\n","epoch 21 | loss: 0.67529 | val_0_mse: 2.722630023956299|  0:00:17s\n","epoch 22 | loss: 0.63111 | val_0_mse: 3.058069944381714|  0:00:18s\n","epoch 23 | loss: 0.61584 | val_0_mse: 3.8552799224853516|  0:00:19s\n","epoch 24 | loss: 0.65493 | val_0_mse: 2.283669948577881|  0:00:20s\n","epoch 25 | loss: 0.79485 | val_0_mse: 3.290980100631714|  0:00:21s\n","epoch 26 | loss: 0.85066 | val_0_mse: 1.254930019378662|  0:00:21s\n","epoch 27 | loss: 0.91547 | val_0_mse: 2.194269895553589|  0:00:22s\n","epoch 28 | loss: 0.80135 | val_0_mse: 1.2325400114059448|  0:00:23s\n","epoch 29 | loss: 0.91964 | val_0_mse: 3.5940499305725098|  0:00:24s\n","epoch 30 | loss: 0.75226 | val_0_mse: 1.5342799425125122|  0:00:24s\n","epoch 31 | loss: 0.63333 | val_0_mse: 0.9576200246810913|  0:00:25s\n","epoch 32 | loss: 0.65562 | val_0_mse: 3.9890899658203125|  0:00:26s\n","epoch 33 | loss: 0.74041 | val_0_mse: 0.8026000261306763|  0:00:27s\n","epoch 34 | loss: 0.72447 | val_0_mse: 1.6684099435806274|  0:00:28s\n","epoch 35 | loss: 0.6349  | val_0_mse: 0.7720699906349182|  0:00:28s\n","epoch 36 | loss: 0.6326  | val_0_mse: 1.6899199485778809|  0:00:29s\n","epoch 37 | loss: 0.5933  | val_0_mse: 1.086210012435913|  0:00:30s\n","epoch 38 | loss: 0.66587 | val_0_mse: 1.9153000116348267|  0:00:31s\n","epoch 39 | loss: 0.69105 | val_0_mse: 0.8582500219345093|  0:00:32s\n","epoch 40 | loss: 0.6361  | val_0_mse: 0.9594699740409851|  0:00:33s\n","epoch 41 | loss: 0.6394  | val_0_mse: 0.6791700124740601|  0:00:33s\n","epoch 42 | loss: 0.58413 | val_0_mse: 1.0212700366973877|  0:00:34s\n","epoch 43 | loss: 0.56516 | val_0_mse: 1.3651399612426758|  0:00:35s\n","epoch 44 | loss: 0.61686 | val_0_mse: 0.7185699939727783|  0:00:36s\n","epoch 45 | loss: 0.67707 | val_0_mse: 1.173449993133545|  0:00:36s\n","epoch 46 | loss: 0.72808 | val_0_mse: 1.0547200441360474|  0:00:37s\n","epoch 47 | loss: 0.60076 | val_0_mse: 0.7814599871635437|  0:00:38s\n","epoch 48 | loss: 0.63691 | val_0_mse: 0.7192000150680542|  0:00:39s\n","epoch 49 | loss: 0.57358 | val_0_mse: 1.0370700359344482|  0:00:40s\n","epoch 50 | loss: 0.56292 | val_0_mse: 0.6858699917793274|  0:00:40s\n","epoch 51 | loss: 0.54747 | val_0_mse: 0.7136200070381165|  0:00:41s\n","\n","Early stopping occurred at epoch 51 with best_epoch = 41 and best_val_0_mse = 0.6791700124740601\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 16:31:36,060] Trial 71 finished with value: 0.6791737675666809 and parameters: {'n_d': 10, 'n_steps': 10, 'gamma': 1.0314073836741775, 'n_independent': 3, 'n_shared': 5, 'momentum': 0.07790836277815302}. Best is trial 55 with value: 0.5396906733512878.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 19.33034| val_0_mse: 4254.3984375|  0:00:00s\n","epoch 1  | loss: 7.6833  | val_0_mse: 247.37826538085938|  0:00:01s\n","epoch 2  | loss: 3.83756 | val_0_mse: 167.48025512695312|  0:00:02s\n","epoch 3  | loss: 2.52901 | val_0_mse: 43.1351318359375|  0:00:02s\n","epoch 4  | loss: 1.60568 | val_0_mse: 44.90699005126953|  0:00:03s\n","epoch 5  | loss: 1.19336 | val_0_mse: 43.526798248291016|  0:00:03s\n","epoch 6  | loss: 1.12444 | val_0_mse: 16.523439407348633|  0:00:04s\n","epoch 7  | loss: 1.27971 | val_0_mse: 18.134410858154297|  0:00:05s\n","epoch 8  | loss: 1.32214 | val_0_mse: 47.81597900390625|  0:00:05s\n","epoch 9  | loss: 1.55258 | val_0_mse: 53.53384017944336|  0:00:06s\n","epoch 10 | loss: 1.22406 | val_0_mse: 9.354809761047363|  0:00:07s\n","epoch 11 | loss: 1.06422 | val_0_mse: 8.009650230407715|  0:00:07s\n","epoch 12 | loss: 0.90235 | val_0_mse: 4.989389896392822|  0:00:08s\n","epoch 13 | loss: 0.9813  | val_0_mse: 6.224219799041748|  0:00:09s\n","epoch 14 | loss: 0.74704 | val_0_mse: 5.158299922943115|  0:00:09s\n","epoch 15 | loss: 0.70084 | val_0_mse: 12.92883014678955|  0:00:10s\n","epoch 16 | loss: 0.69939 | val_0_mse: 11.159520149230957|  0:00:11s\n","epoch 17 | loss: 0.66607 | val_0_mse: 3.7429399490356445|  0:00:11s\n","epoch 18 | loss: 0.69888 | val_0_mse: 3.293060064315796|  0:00:12s\n","epoch 19 | loss: 0.73184 | val_0_mse: 1.4890300035476685|  0:00:13s\n","epoch 20 | loss: 0.76041 | val_0_mse: 1.6431100368499756|  0:00:13s\n","epoch 21 | loss: 0.70429 | val_0_mse: 1.232890009880066|  0:00:14s\n","epoch 22 | loss: 0.61371 | val_0_mse: 1.317710041999817|  0:00:15s\n","epoch 23 | loss: 0.63818 | val_0_mse: 1.0683399438858032|  0:00:15s\n","epoch 24 | loss: 0.65752 | val_0_mse: 1.1280399560928345|  0:00:16s\n","epoch 25 | loss: 0.58351 | val_0_mse: 0.8981599807739258|  0:00:17s\n","epoch 26 | loss: 0.58175 | val_0_mse: 1.2185300588607788|  0:00:17s\n","epoch 27 | loss: 0.6086  | val_0_mse: 1.4442399740219116|  0:00:18s\n","epoch 28 | loss: 0.60589 | val_0_mse: 1.2656999826431274|  0:00:18s\n","epoch 29 | loss: 0.59469 | val_0_mse: 0.9610400199890137|  0:00:19s\n","epoch 30 | loss: 0.6132  | val_0_mse: 0.9638299942016602|  0:00:20s\n","epoch 31 | loss: 0.65182 | val_0_mse: 0.756820023059845|  0:00:21s\n","epoch 32 | loss: 0.71893 | val_0_mse: 1.0718499422073364|  0:00:21s\n","epoch 33 | loss: 0.73337 | val_0_mse: 0.7847099900245667|  0:00:22s\n","epoch 34 | loss: 0.75347 | val_0_mse: 1.1100200414657593|  0:00:22s\n","epoch 35 | loss: 0.69541 | val_0_mse: 0.7387800216674805|  0:00:23s\n","epoch 36 | loss: 0.69478 | val_0_mse: 0.9066100120544434|  0:00:24s\n","epoch 37 | loss: 0.68696 | val_0_mse: 0.7382100224494934|  0:00:24s\n","epoch 38 | loss: 0.62401 | val_0_mse: 0.7366899847984314|  0:00:25s\n","epoch 39 | loss: 0.58606 | val_0_mse: 0.7437499761581421|  0:00:26s\n","epoch 40 | loss: 0.58537 | val_0_mse: 0.7496600151062012|  0:00:26s\n","epoch 41 | loss: 0.61121 | val_0_mse: 0.9305099844932556|  0:00:27s\n","epoch 42 | loss: 0.60362 | val_0_mse: 0.7912200093269348|  0:00:28s\n","epoch 43 | loss: 0.59357 | val_0_mse: 0.7634099721908569|  0:00:28s\n","epoch 44 | loss: 0.54767 | val_0_mse: 0.7085800170898438|  0:00:29s\n","epoch 45 | loss: 0.56893 | val_0_mse: 0.801360011100769|  0:00:30s\n","epoch 46 | loss: 0.56259 | val_0_mse: 0.7367900013923645|  0:00:30s\n","epoch 47 | loss: 0.57432 | val_0_mse: 0.7296900153160095|  0:00:31s\n","epoch 48 | loss: 0.55258 | val_0_mse: 0.7313600182533264|  0:00:32s\n","epoch 49 | loss: 0.56411 | val_0_mse: 0.7170000076293945|  0:00:32s\n","epoch 50 | loss: 0.56975 | val_0_mse: 0.6444500088691711|  0:00:33s\n","epoch 51 | loss: 0.55013 | val_0_mse: 0.681659996509552|  0:00:33s\n","epoch 52 | loss: 0.55923 | val_0_mse: 0.7400699853897095|  0:00:34s\n","epoch 53 | loss: 0.55564 | val_0_mse: 0.690850019454956|  0:00:35s\n","epoch 54 | loss: 0.5639  | val_0_mse: 0.6793500185012817|  0:00:35s\n","epoch 55 | loss: 0.55608 | val_0_mse: 0.7299100160598755|  0:00:36s\n","epoch 56 | loss: 0.5573  | val_0_mse: 0.8756800293922424|  0:00:37s\n","epoch 57 | loss: 0.56672 | val_0_mse: 0.6941699981689453|  0:00:37s\n","epoch 58 | loss: 0.53535 | val_0_mse: 0.7134100198745728|  0:00:38s\n","epoch 59 | loss: 0.54835 | val_0_mse: 0.715499997138977|  0:00:39s\n","epoch 60 | loss: 0.554   | val_0_mse: 0.7169700264930725|  0:00:39s\n","\n","Early stopping occurred at epoch 60 with best_epoch = 50 and best_val_0_mse = 0.6444500088691711\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 16:32:16,201] Trial 72 finished with value: 0.6444473266601562 and parameters: {'n_d': 12, 'n_steps': 10, 'gamma': 1.1527873754032885, 'n_independent': 3, 'n_shared': 3, 'momentum': 0.02704121259241787}. Best is trial 55 with value: 0.5396906733512878.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 50.55169| val_0_mse: 954.1348266601562|  0:00:00s\n","epoch 1  | loss: 16.85914| val_0_mse: 3096.935791015625|  0:00:01s\n","epoch 2  | loss: 8.01868 | val_0_mse: 631.2493286132812|  0:00:02s\n","epoch 3  | loss: 3.941   | val_0_mse: 158.46302795410156|  0:00:03s\n","epoch 4  | loss: 2.7389  | val_0_mse: 133.05101013183594|  0:00:04s\n","epoch 5  | loss: 1.7862  | val_0_mse: 121.21851348876953|  0:00:05s\n","epoch 6  | loss: 1.64613 | val_0_mse: 99.18537902832031|  0:00:06s\n","epoch 7  | loss: 1.34728 | val_0_mse: 38.789241790771484|  0:00:07s\n","epoch 8  | loss: 1.1025  | val_0_mse: 37.67884063720703|  0:00:08s\n","epoch 9  | loss: 0.99752 | val_0_mse: 30.863100051879883|  0:00:08s\n","epoch 10 | loss: 0.99787 | val_0_mse: 16.987659454345703|  0:00:09s\n","epoch 11 | loss: 0.99621 | val_0_mse: 15.536100387573242|  0:00:10s\n","epoch 12 | loss: 0.9685  | val_0_mse: 50.606380462646484|  0:00:11s\n","epoch 13 | loss: 1.10445 | val_0_mse: 19.573619842529297|  0:00:12s\n","epoch 14 | loss: 1.18313 | val_0_mse: 6.644869804382324|  0:00:13s\n","epoch 15 | loss: 1.73437 | val_0_mse: 3.187730073928833|  0:00:14s\n","epoch 16 | loss: 1.08199 | val_0_mse: 18.381940841674805|  0:00:15s\n","epoch 17 | loss: 0.78032 | val_0_mse: 16.9298095703125|  0:00:16s\n","epoch 18 | loss: 0.73167 | val_0_mse: 4.394649982452393|  0:00:17s\n","epoch 19 | loss: 0.71814 | val_0_mse: 3.9070498943328857|  0:00:17s\n","epoch 20 | loss: 0.69632 | val_0_mse: 3.2630600929260254|  0:00:18s\n","epoch 21 | loss: 0.67154 | val_0_mse: 2.5122299194335938|  0:00:19s\n","epoch 22 | loss: 0.71265 | val_0_mse: 1.30731999874115|  0:00:20s\n","epoch 23 | loss: 0.72757 | val_0_mse: 4.674769878387451|  0:00:21s\n","epoch 24 | loss: 0.72726 | val_0_mse: 6.073929786682129|  0:00:22s\n","epoch 25 | loss: 0.93485 | val_0_mse: 3.7667601108551025|  0:00:23s\n","epoch 26 | loss: 0.78053 | val_0_mse: 7.9529500007629395|  0:00:24s\n","epoch 27 | loss: 0.69889 | val_0_mse: 3.9910600185394287|  0:00:24s\n","epoch 28 | loss: 0.63364 | val_0_mse: 3.03518009185791|  0:00:25s\n","epoch 29 | loss: 0.65772 | val_0_mse: 1.4388600587844849|  0:00:26s\n","epoch 30 | loss: 0.62545 | val_0_mse: 1.8053100109100342|  0:00:27s\n","epoch 31 | loss: 0.62756 | val_0_mse: 1.1386799812316895|  0:00:28s\n","epoch 32 | loss: 0.6261  | val_0_mse: 1.542680025100708|  0:00:29s\n","epoch 33 | loss: 0.61747 | val_0_mse: 1.6145999431610107|  0:00:30s\n","epoch 34 | loss: 0.5835  | val_0_mse: 1.6676000356674194|  0:00:31s\n","epoch 35 | loss: 0.62338 | val_0_mse: 0.8364700078964233|  0:00:31s\n","epoch 36 | loss: 0.60992 | val_0_mse: 1.080989956855774|  0:00:32s\n","epoch 37 | loss: 0.57092 | val_0_mse: 1.4839199781417847|  0:00:33s\n","epoch 38 | loss: 0.61903 | val_0_mse: 1.0016900300979614|  0:00:34s\n","epoch 39 | loss: 0.60959 | val_0_mse: 0.9939000010490417|  0:00:35s\n","epoch 40 | loss: 0.59694 | val_0_mse: 1.0154000520706177|  0:00:36s\n","epoch 41 | loss: 0.62359 | val_0_mse: 0.7591800093650818|  0:00:37s\n","epoch 42 | loss: 0.58452 | val_0_mse: 0.9621599912643433|  0:00:38s\n","epoch 43 | loss: 0.563   | val_0_mse: 0.7661100029945374|  0:00:38s\n","epoch 44 | loss: 0.5877  | val_0_mse: 1.0320299863815308|  0:00:39s\n","epoch 45 | loss: 0.58229 | val_0_mse: 0.751800000667572|  0:00:40s\n","epoch 46 | loss: 0.63021 | val_0_mse: 0.9995700120925903|  0:00:41s\n","epoch 47 | loss: 0.57155 | val_0_mse: 0.812720000743866|  0:00:42s\n","epoch 48 | loss: 0.55175 | val_0_mse: 0.7738400101661682|  0:00:43s\n","epoch 49 | loss: 0.54956 | val_0_mse: 0.9863499999046326|  0:00:44s\n","epoch 50 | loss: 0.57792 | val_0_mse: 0.6801499724388123|  0:00:44s\n","epoch 51 | loss: 0.61035 | val_0_mse: 0.9302099943161011|  0:00:45s\n","epoch 52 | loss: 0.56489 | val_0_mse: 0.6992999911308289|  0:00:46s\n","epoch 53 | loss: 0.54035 | val_0_mse: 0.6906700134277344|  0:00:47s\n","epoch 54 | loss: 0.55823 | val_0_mse: 0.7805200219154358|  0:00:48s\n","epoch 55 | loss: 0.5428  | val_0_mse: 0.8870099782943726|  0:00:49s\n","epoch 56 | loss: 0.54212 | val_0_mse: 0.6873199939727783|  0:00:50s\n","epoch 57 | loss: 0.54465 | val_0_mse: 0.7352100014686584|  0:00:51s\n","epoch 58 | loss: 0.56221 | val_0_mse: 0.7567800283432007|  0:00:52s\n","epoch 59 | loss: 0.54092 | val_0_mse: 0.6692500114440918|  0:00:52s\n","epoch 60 | loss: 0.52922 | val_0_mse: 0.6419500112533569|  0:00:53s\n","epoch 61 | loss: 0.53839 | val_0_mse: 0.651639997959137|  0:00:54s\n","epoch 62 | loss: 0.55148 | val_0_mse: 0.7336500287055969|  0:00:55s\n","epoch 63 | loss: 0.55941 | val_0_mse: 0.6047899723052979|  0:00:56s\n","epoch 64 | loss: 0.53058 | val_0_mse: 0.6421899795532227|  0:00:57s\n","epoch 65 | loss: 0.51895 | val_0_mse: 0.6518300175666809|  0:00:58s\n","epoch 66 | loss: 0.51486 | val_0_mse: 0.66593998670578|  0:00:59s\n","epoch 67 | loss: 0.51374 | val_0_mse: 0.6489999890327454|  0:00:59s\n","epoch 68 | loss: 0.51479 | val_0_mse: 0.6292799711227417|  0:01:00s\n","epoch 69 | loss: 0.51705 | val_0_mse: 0.5843300223350525|  0:01:01s\n","epoch 70 | loss: 0.51485 | val_0_mse: 0.629069983959198|  0:01:02s\n","epoch 71 | loss: 0.52132 | val_0_mse: 0.6334400177001953|  0:01:03s\n","epoch 72 | loss: 0.52845 | val_0_mse: 0.596589982509613|  0:01:04s\n","epoch 73 | loss: 0.51496 | val_0_mse: 0.606249988079071|  0:01:05s\n","epoch 74 | loss: 0.52156 | val_0_mse: 0.6166499853134155|  0:01:06s\n","epoch 75 | loss: 0.53115 | val_0_mse: 0.6127099990844727|  0:01:07s\n","epoch 76 | loss: 0.53069 | val_0_mse: 0.6066200137138367|  0:01:07s\n","epoch 77 | loss: 0.52598 | val_0_mse: 0.6124600172042847|  0:01:08s\n","epoch 78 | loss: 0.54177 | val_0_mse: 0.6270300149917603|  0:01:09s\n","epoch 79 | loss: 0.54249 | val_0_mse: 0.60971999168396|  0:01:10s\n","\n","Early stopping occurred at epoch 79 with best_epoch = 69 and best_val_0_mse = 0.5843300223350525\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 16:33:27,248] Trial 73 finished with value: 0.5843273401260376 and parameters: {'n_d': 9, 'n_steps': 10, 'gamma': 1.0868256099641345, 'n_independent': 4, 'n_shared': 5, 'momentum': 0.06496126330618215}. Best is trial 55 with value: 0.5396906733512878.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 9.61225 | val_0_mse: 1123.672119140625|  0:00:00s\n","epoch 1  | loss: 3.43006 | val_0_mse: 247.89686584472656|  0:00:01s\n","epoch 2  | loss: 2.10116 | val_0_mse: 146.5391845703125|  0:00:01s\n","epoch 3  | loss: 1.48607 | val_0_mse: 135.44482421875|  0:00:02s\n","epoch 4  | loss: 1.32721 | val_0_mse: 64.88249969482422|  0:00:02s\n","epoch 5  | loss: 1.06946 | val_0_mse: 64.63272857666016|  0:00:03s\n","epoch 6  | loss: 0.90979 | val_0_mse: 63.52824020385742|  0:00:03s\n","epoch 7  | loss: 0.93945 | val_0_mse: 83.27388000488281|  0:00:04s\n","epoch 8  | loss: 0.80587 | val_0_mse: 8.90956974029541|  0:00:04s\n","epoch 9  | loss: 0.82172 | val_0_mse: 4.013199806213379|  0:00:05s\n","epoch 10 | loss: 0.79659 | val_0_mse: 2.611419916152954|  0:00:05s\n","epoch 11 | loss: 0.7841  | val_0_mse: 11.134719848632812|  0:00:06s\n","epoch 12 | loss: 0.90744 | val_0_mse: 3.548460006713867|  0:00:06s\n","epoch 13 | loss: 0.97329 | val_0_mse: 15.180549621582031|  0:00:07s\n","epoch 14 | loss: 0.75599 | val_0_mse: 12.362420082092285|  0:00:07s\n","epoch 15 | loss: 0.70078 | val_0_mse: 3.7261099815368652|  0:00:08s\n","epoch 16 | loss: 0.72664 | val_0_mse: 8.932669639587402|  0:00:08s\n","epoch 17 | loss: 0.76989 | val_0_mse: 2.014580011367798|  0:00:09s\n","epoch 18 | loss: 0.7578  | val_0_mse: 9.821000099182129|  0:00:10s\n","epoch 19 | loss: 0.72664 | val_0_mse: 6.1681599617004395|  0:00:10s\n","epoch 20 | loss: 0.61061 | val_0_mse: 2.9291698932647705|  0:00:11s\n","epoch 21 | loss: 0.65243 | val_0_mse: 3.561340093612671|  0:00:11s\n","epoch 22 | loss: 0.68489 | val_0_mse: 3.5594398975372314|  0:00:12s\n","epoch 23 | loss: 0.7475  | val_0_mse: 2.968130111694336|  0:00:12s\n","epoch 24 | loss: 0.648   | val_0_mse: 2.1660099029541016|  0:00:13s\n","epoch 25 | loss: 0.63314 | val_0_mse: 2.432029962539673|  0:00:13s\n","epoch 26 | loss: 0.5984  | val_0_mse: 1.88618004322052|  0:00:14s\n","epoch 27 | loss: 0.61776 | val_0_mse: 2.646120071411133|  0:00:14s\n","epoch 28 | loss: 0.60589 | val_0_mse: 2.7176599502563477|  0:00:15s\n","epoch 29 | loss: 0.63742 | val_0_mse: 3.2810299396514893|  0:00:15s\n","epoch 30 | loss: 0.64654 | val_0_mse: 1.8103599548339844|  0:00:16s\n","epoch 31 | loss: 0.64231 | val_0_mse: 1.2787100076675415|  0:00:16s\n","epoch 32 | loss: 0.62572 | val_0_mse: 1.5034300088882446|  0:00:17s\n","epoch 33 | loss: 0.64819 | val_0_mse: 1.232740044593811|  0:00:17s\n","epoch 34 | loss: 0.63832 | val_0_mse: 1.3937400579452515|  0:00:18s\n","epoch 35 | loss: 0.65786 | val_0_mse: 1.3331999778747559|  0:00:18s\n","epoch 36 | loss: 0.66855 | val_0_mse: 0.9373999834060669|  0:00:19s\n","epoch 37 | loss: 0.79303 | val_0_mse: 0.9820799827575684|  0:00:20s\n","epoch 38 | loss: 0.77139 | val_0_mse: 1.828879952430725|  0:00:20s\n","epoch 39 | loss: 0.62765 | val_0_mse: 0.890529990196228|  0:00:21s\n","epoch 40 | loss: 0.57629 | val_0_mse: 1.0919500589370728|  0:00:21s\n","epoch 41 | loss: 0.5825  | val_0_mse: 0.9800999760627747|  0:00:22s\n","epoch 42 | loss: 0.57499 | val_0_mse: 1.1144499778747559|  0:00:22s\n","epoch 43 | loss: 0.58402 | val_0_mse: 1.3798600435256958|  0:00:23s\n","epoch 44 | loss: 0.6015  | val_0_mse: 0.8694400191307068|  0:00:23s\n","epoch 45 | loss: 0.6176  | val_0_mse: 1.066640019416809|  0:00:24s\n","epoch 46 | loss: 0.63084 | val_0_mse: 0.8317599892616272|  0:00:24s\n","epoch 47 | loss: 0.60288 | val_0_mse: 0.9399999976158142|  0:00:25s\n","epoch 48 | loss: 0.5759  | val_0_mse: 0.8214300274848938|  0:00:25s\n","epoch 49 | loss: 0.56897 | val_0_mse: 0.9564399719238281|  0:00:26s\n","epoch 50 | loss: 0.56474 | val_0_mse: 0.8941699862480164|  0:00:26s\n","epoch 51 | loss: 0.57132 | val_0_mse: 1.033460021018982|  0:00:27s\n","epoch 52 | loss: 0.58137 | val_0_mse: 0.7940700054168701|  0:00:27s\n","epoch 53 | loss: 0.54973 | val_0_mse: 0.795490026473999|  0:00:28s\n","epoch 54 | loss: 0.54318 | val_0_mse: 0.7585600018501282|  0:00:28s\n","epoch 55 | loss: 0.55476 | val_0_mse: 0.7482600212097168|  0:00:29s\n","epoch 56 | loss: 0.53806 | val_0_mse: 0.7544500231742859|  0:00:29s\n","epoch 57 | loss: 0.55946 | val_0_mse: 0.7153400182723999|  0:00:30s\n","epoch 58 | loss: 0.54064 | val_0_mse: 0.6959699988365173|  0:00:30s\n","epoch 59 | loss: 0.52374 | val_0_mse: 0.776170015335083|  0:00:31s\n","epoch 60 | loss: 0.54114 | val_0_mse: 0.791670024394989|  0:00:31s\n","epoch 61 | loss: 0.52778 | val_0_mse: 0.7322700023651123|  0:00:32s\n","epoch 62 | loss: 0.51755 | val_0_mse: 0.6690400242805481|  0:00:33s\n","epoch 63 | loss: 0.55021 | val_0_mse: 0.6945400238037109|  0:00:33s\n","epoch 64 | loss: 0.5399  | val_0_mse: 0.7396199703216553|  0:00:34s\n","epoch 65 | loss: 0.55112 | val_0_mse: 0.6761400103569031|  0:00:34s\n","epoch 66 | loss: 0.52975 | val_0_mse: 0.6517000198364258|  0:00:35s\n","epoch 67 | loss: 0.5391  | val_0_mse: 0.6366900205612183|  0:00:35s\n","epoch 68 | loss: 0.5592  | val_0_mse: 0.7166600227355957|  0:00:36s\n","epoch 69 | loss: 0.58838 | val_0_mse: 0.6859700083732605|  0:00:36s\n","epoch 70 | loss: 0.54024 | val_0_mse: 0.6086300015449524|  0:00:37s\n","epoch 71 | loss: 0.56596 | val_0_mse: 0.6931099891662598|  0:00:37s\n","epoch 72 | loss: 0.5408  | val_0_mse: 0.7764300107955933|  0:00:38s\n","epoch 73 | loss: 0.55154 | val_0_mse: 0.6574199795722961|  0:00:38s\n","epoch 74 | loss: 0.52351 | val_0_mse: 0.6391800045967102|  0:00:39s\n","epoch 75 | loss: 0.52646 | val_0_mse: 0.667110025882721|  0:00:39s\n","epoch 76 | loss: 0.51978 | val_0_mse: 0.6389999985694885|  0:00:40s\n","epoch 77 | loss: 0.51963 | val_0_mse: 0.6488999724388123|  0:00:40s\n","epoch 78 | loss: 0.5075  | val_0_mse: 0.6627500057220459|  0:00:41s\n","epoch 79 | loss: 0.52888 | val_0_mse: 0.6255000233650208|  0:00:41s\n","epoch 80 | loss: 0.53722 | val_0_mse: 0.6287099719047546|  0:00:42s\n","\n","Early stopping occurred at epoch 80 with best_epoch = 70 and best_val_0_mse = 0.6086300015449524\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 16:34:10,072] Trial 74 finished with value: 0.6086271405220032 and parameters: {'n_d': 16, 'n_steps': 9, 'gamma': 1.2208885373429201, 'n_independent': 2, 'n_shared': 3, 'momentum': 0.09761871638722437}. Best is trial 55 with value: 0.5396906733512878.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 7.05162 | val_0_mse: 471.30615234375|  0:00:00s\n","epoch 1  | loss: 2.64218 | val_0_mse: 54.62902069091797|  0:00:01s\n","epoch 2  | loss: 1.43987 | val_0_mse: 61.22901153564453|  0:00:01s\n","epoch 3  | loss: 0.99205 | val_0_mse: 137.67303466796875|  0:00:02s\n","epoch 4  | loss: 0.84332 | val_0_mse: 51.639278411865234|  0:00:02s\n","epoch 5  | loss: 0.79091 | val_0_mse: 48.19430160522461|  0:00:03s\n","epoch 6  | loss: 0.74912 | val_0_mse: 18.212459564208984|  0:00:03s\n","epoch 7  | loss: 0.72532 | val_0_mse: 5.162710189819336|  0:00:04s\n","epoch 8  | loss: 0.69205 | val_0_mse: 9.883099555969238|  0:00:04s\n","epoch 9  | loss: 0.69877 | val_0_mse: 7.955080032348633|  0:00:05s\n","epoch 10 | loss: 0.755   | val_0_mse: 6.134429931640625|  0:00:05s\n","epoch 11 | loss: 0.76385 | val_0_mse: 2.4067299365997314|  0:00:06s\n","epoch 12 | loss: 0.67991 | val_0_mse: 2.68284010887146|  0:00:06s\n","epoch 13 | loss: 0.62858 | val_0_mse: 3.5513100624084473|  0:00:07s\n","epoch 14 | loss: 0.61874 | val_0_mse: 6.287109851837158|  0:00:07s\n","epoch 15 | loss: 0.61489 | val_0_mse: 6.201499938964844|  0:00:08s\n","epoch 16 | loss: 0.6275  | val_0_mse: 1.6714600324630737|  0:00:08s\n","epoch 17 | loss: 0.70093 | val_0_mse: 2.945859909057617|  0:00:09s\n","epoch 18 | loss: 0.65991 | val_0_mse: 2.0373599529266357|  0:00:09s\n","epoch 19 | loss: 0.63029 | val_0_mse: 5.845170021057129|  0:00:10s\n","epoch 20 | loss: 0.68497 | val_0_mse: 2.9765899181365967|  0:00:10s\n","epoch 21 | loss: 0.69198 | val_0_mse: 3.0781099796295166|  0:00:11s\n","epoch 22 | loss: 0.60864 | val_0_mse: 2.8696799278259277|  0:00:11s\n","epoch 23 | loss: 0.60646 | val_0_mse: 1.3449699878692627|  0:00:12s\n","epoch 24 | loss: 0.60974 | val_0_mse: 1.7166399955749512|  0:00:12s\n","epoch 25 | loss: 0.57609 | val_0_mse: 2.603800058364868|  0:00:13s\n","epoch 26 | loss: 0.59768 | val_0_mse: 2.0720300674438477|  0:00:13s\n","epoch 27 | loss: 0.56425 | val_0_mse: 2.2821600437164307|  0:00:14s\n","epoch 28 | loss: 0.55653 | val_0_mse: 1.3202099800109863|  0:00:14s\n","epoch 29 | loss: 0.57883 | val_0_mse: 1.448240041732788|  0:00:15s\n","epoch 30 | loss: 0.58963 | val_0_mse: 1.24468994140625|  0:00:16s\n","epoch 31 | loss: 0.59002 | val_0_mse: 0.9672600030899048|  0:00:16s\n","epoch 32 | loss: 0.57865 | val_0_mse: 1.3867199420928955|  0:00:17s\n","epoch 33 | loss: 0.54272 | val_0_mse: 1.98117995262146|  0:00:17s\n","epoch 34 | loss: 0.57779 | val_0_mse: 1.0178699493408203|  0:00:18s\n","epoch 35 | loss: 0.55878 | val_0_mse: 1.0246000289916992|  0:00:18s\n","epoch 36 | loss: 0.55288 | val_0_mse: 1.2373900413513184|  0:00:19s\n","epoch 37 | loss: 0.56159 | val_0_mse: 0.8833000063896179|  0:00:19s\n","epoch 38 | loss: 0.65175 | val_0_mse: 1.610129952430725|  0:00:20s\n","epoch 39 | loss: 0.64759 | val_0_mse: 0.881879985332489|  0:00:20s\n","epoch 40 | loss: 0.63892 | val_0_mse: 1.7466299533843994|  0:00:21s\n","epoch 41 | loss: 0.60656 | val_0_mse: 0.983959972858429|  0:00:21s\n","epoch 42 | loss: 0.57647 | val_0_mse: 1.0000499486923218|  0:00:22s\n","epoch 43 | loss: 0.5736  | val_0_mse: 1.1504900455474854|  0:00:22s\n","epoch 44 | loss: 0.65899 | val_0_mse: 0.7678700089454651|  0:00:23s\n","epoch 45 | loss: 0.70871 | val_0_mse: 0.7800700068473816|  0:00:23s\n","epoch 46 | loss: 0.65018 | val_0_mse: 1.044450044631958|  0:00:24s\n","epoch 47 | loss: 0.56624 | val_0_mse: 0.9101200103759766|  0:00:24s\n","epoch 48 | loss: 0.52174 | val_0_mse: 0.8217200040817261|  0:00:25s\n","epoch 49 | loss: 0.50599 | val_0_mse: 0.7311400175094604|  0:00:25s\n","epoch 50 | loss: 0.52606 | val_0_mse: 0.8545899987220764|  0:00:26s\n","epoch 51 | loss: 0.52615 | val_0_mse: 0.8569999933242798|  0:00:26s\n","epoch 52 | loss: 0.58809 | val_0_mse: 0.6539999842643738|  0:00:27s\n","epoch 53 | loss: 0.61837 | val_0_mse: 0.7678400278091431|  0:00:27s\n","epoch 54 | loss: 0.58412 | val_0_mse: 0.7282400131225586|  0:00:28s\n","epoch 55 | loss: 0.51973 | val_0_mse: 0.7060099840164185|  0:00:28s\n","epoch 56 | loss: 0.51842 | val_0_mse: 0.7209600210189819|  0:00:29s\n","epoch 57 | loss: 0.5227  | val_0_mse: 0.6539700031280518|  0:00:29s\n","epoch 58 | loss: 0.55597 | val_0_mse: 0.7001299858093262|  0:00:30s\n","epoch 59 | loss: 0.52585 | val_0_mse: 0.6783900260925293|  0:00:31s\n","epoch 60 | loss: 0.51827 | val_0_mse: 0.6371999979019165|  0:00:31s\n","epoch 61 | loss: 0.50133 | val_0_mse: 0.6790500283241272|  0:00:32s\n","epoch 62 | loss: 0.50645 | val_0_mse: 0.7980200052261353|  0:00:32s\n","epoch 63 | loss: 0.5295  | val_0_mse: 0.710640013217926|  0:00:33s\n","epoch 64 | loss: 0.51226 | val_0_mse: 0.686460018157959|  0:00:33s\n","epoch 65 | loss: 0.51508 | val_0_mse: 0.6762300133705139|  0:00:34s\n","epoch 66 | loss: 0.51817 | val_0_mse: 0.6304100155830383|  0:00:34s\n","epoch 67 | loss: 0.50766 | val_0_mse: 0.6058700084686279|  0:00:35s\n","epoch 68 | loss: 0.57937 | val_0_mse: 0.803409993648529|  0:00:35s\n","epoch 69 | loss: 0.5265  | val_0_mse: 0.6794700026512146|  0:00:36s\n","epoch 70 | loss: 0.50288 | val_0_mse: 0.6287800073623657|  0:00:36s\n","epoch 71 | loss: 0.49555 | val_0_mse: 0.602940022945404|  0:00:37s\n","epoch 72 | loss: 0.52143 | val_0_mse: 0.6641899943351746|  0:00:37s\n","epoch 73 | loss: 0.49801 | val_0_mse: 0.6240800023078918|  0:00:38s\n","epoch 74 | loss: 0.49087 | val_0_mse: 0.6140300035476685|  0:00:38s\n","epoch 75 | loss: 0.48612 | val_0_mse: 0.6248999834060669|  0:00:39s\n","epoch 76 | loss: 0.50357 | val_0_mse: 0.6223400235176086|  0:00:39s\n","epoch 77 | loss: 0.4993  | val_0_mse: 0.6707900166511536|  0:00:40s\n","epoch 78 | loss: 0.51616 | val_0_mse: 0.6317099928855896|  0:00:40s\n","epoch 79 | loss: 0.51634 | val_0_mse: 0.6275200247764587|  0:00:41s\n","epoch 80 | loss: 0.49421 | val_0_mse: 0.6539599895477295|  0:00:41s\n","epoch 81 | loss: 0.49127 | val_0_mse: 0.6153500080108643|  0:00:42s\n","\n","Early stopping occurred at epoch 81 with best_epoch = 71 and best_val_0_mse = 0.602940022945404\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 16:34:52,916] Trial 75 finished with value: 0.602937638759613 and parameters: {'n_d': 20, 'n_steps': 9, 'gamma': 1.1156212341183407, 'n_independent': 1, 'n_shared': 4, 'momentum': 0.03630886950770357}. Best is trial 55 with value: 0.5396906733512878.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 23.12311| val_0_mse: 9501.2451171875|  0:00:00s\n","epoch 1  | loss: 7.41636 | val_0_mse: 2624.243896484375|  0:00:01s\n","epoch 2  | loss: 3.50719 | val_0_mse: 271.4608459472656|  0:00:02s\n","epoch 3  | loss: 2.27624 | val_0_mse: 193.4105224609375|  0:00:03s\n","epoch 4  | loss: 1.6714  | val_0_mse: 117.59834289550781|  0:00:04s\n","epoch 5  | loss: 1.72077 | val_0_mse: 106.40696716308594|  0:00:05s\n","epoch 6  | loss: 1.19155 | val_0_mse: 137.4975128173828|  0:00:06s\n","epoch 7  | loss: 1.17917 | val_0_mse: 88.81239318847656|  0:00:07s\n","epoch 8  | loss: 0.93776 | val_0_mse: 95.21011352539062|  0:00:08s\n","epoch 9  | loss: 0.85313 | val_0_mse: 19.91526985168457|  0:00:08s\n","epoch 10 | loss: 1.00388 | val_0_mse: 71.73197937011719|  0:00:09s\n","epoch 11 | loss: 1.29233 | val_0_mse: 7.532899856567383|  0:00:10s\n","epoch 12 | loss: 0.92873 | val_0_mse: 20.005760192871094|  0:00:11s\n","epoch 13 | loss: 0.7892  | val_0_mse: 17.79084014892578|  0:00:12s\n","epoch 14 | loss: 0.76398 | val_0_mse: 12.534899711608887|  0:00:13s\n","epoch 15 | loss: 0.78026 | val_0_mse: 11.93649959564209|  0:00:14s\n","epoch 16 | loss: 0.66251 | val_0_mse: 7.163909912109375|  0:00:15s\n","epoch 17 | loss: 0.64067 | val_0_mse: 4.541709899902344|  0:00:16s\n","epoch 18 | loss: 0.81042 | val_0_mse: 4.917610168457031|  0:00:17s\n","epoch 19 | loss: 0.87396 | val_0_mse: 8.73447036743164|  0:00:17s\n","epoch 20 | loss: 0.76664 | val_0_mse: 6.43874979019165|  0:00:18s\n","epoch 21 | loss: 0.58262 | val_0_mse: 3.924259901046753|  0:00:19s\n","epoch 22 | loss: 0.65104 | val_0_mse: 5.664400100708008|  0:00:20s\n","epoch 23 | loss: 0.6129  | val_0_mse: 1.4258099794387817|  0:00:21s\n","epoch 24 | loss: 0.58889 | val_0_mse: 3.0093400478363037|  0:00:22s\n","epoch 25 | loss: 0.55968 | val_0_mse: 2.7197399139404297|  0:00:23s\n","epoch 26 | loss: 0.56199 | val_0_mse: 2.6233301162719727|  0:00:24s\n","epoch 27 | loss: 0.55849 | val_0_mse: 2.671999931335449|  0:00:24s\n","epoch 28 | loss: 0.61834 | val_0_mse: 2.32600998878479|  0:00:25s\n","epoch 29 | loss: 0.60549 | val_0_mse: 3.998110055923462|  0:00:26s\n","epoch 30 | loss: 0.57634 | val_0_mse: 4.984119892120361|  0:00:27s\n","epoch 31 | loss: 0.63514 | val_0_mse: 4.915939807891846|  0:00:28s\n","epoch 32 | loss: 0.6208  | val_0_mse: 2.6910400390625|  0:00:29s\n","epoch 33 | loss: 0.6251  | val_0_mse: 1.49836003780365|  0:00:30s\n","\n","Early stopping occurred at epoch 33 with best_epoch = 23 and best_val_0_mse = 1.4258099794387817\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 16:35:23,626] Trial 76 finished with value: 1.4258087873458862 and parameters: {'n_d': 24, 'n_steps': 10, 'gamma': 1.0612509895517386, 'n_independent': 4, 'n_shared': 5, 'momentum': 0.05162890672816514}. Best is trial 55 with value: 0.5396906733512878.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 22.76994| val_0_mse: 816.9705810546875|  0:00:00s\n","epoch 1  | loss: 6.91017 | val_0_mse: 281.5768127441406|  0:00:00s\n","epoch 2  | loss: 3.99699 | val_0_mse: 412.4720764160156|  0:00:01s\n","epoch 3  | loss: 3.87257 | val_0_mse: 47.362789154052734|  0:00:01s\n","epoch 4  | loss: 3.05617 | val_0_mse: 32.43885040283203|  0:00:02s\n","epoch 5  | loss: 2.05124 | val_0_mse: 128.92820739746094|  0:00:02s\n","epoch 6  | loss: 1.74242 | val_0_mse: 51.35744857788086|  0:00:03s\n","epoch 7  | loss: 1.31606 | val_0_mse: 7.176919937133789|  0:00:03s\n","epoch 8  | loss: 1.03217 | val_0_mse: 11.606789588928223|  0:00:04s\n","epoch 9  | loss: 0.83901 | val_0_mse: 5.73121976852417|  0:00:04s\n","epoch 10 | loss: 0.82813 | val_0_mse: 4.280920028686523|  0:00:05s\n","epoch 11 | loss: 0.95336 | val_0_mse: 3.7132298946380615|  0:00:05s\n","epoch 12 | loss: 1.17046 | val_0_mse: 3.8818399906158447|  0:00:06s\n","epoch 13 | loss: 0.98675 | val_0_mse: 2.4199700355529785|  0:00:06s\n","epoch 14 | loss: 0.9179  | val_0_mse: 1.992169976234436|  0:00:07s\n","epoch 15 | loss: 0.75575 | val_0_mse: 2.121259927749634|  0:00:07s\n","epoch 16 | loss: 0.75259 | val_0_mse: 3.8888800144195557|  0:00:08s\n","epoch 17 | loss: 0.849   | val_0_mse: 3.054640054702759|  0:00:08s\n","epoch 18 | loss: 0.74531 | val_0_mse: 1.6653300523757935|  0:00:09s\n","epoch 19 | loss: 0.74787 | val_0_mse: 2.1610100269317627|  0:00:09s\n","epoch 20 | loss: 0.76353 | val_0_mse: 3.472059965133667|  0:00:10s\n","epoch 21 | loss: 0.86423 | val_0_mse: 1.6249899864196777|  0:00:10s\n","epoch 22 | loss: 0.76475 | val_0_mse: 3.826479911804199|  0:00:11s\n","epoch 23 | loss: 0.70672 | val_0_mse: 1.7012100219726562|  0:00:11s\n","epoch 24 | loss: 0.79739 | val_0_mse: 1.0827000141143799|  0:00:11s\n","epoch 25 | loss: 0.75508 | val_0_mse: 1.3702800273895264|  0:00:12s\n","epoch 26 | loss: 0.642   | val_0_mse: 1.1885499954223633|  0:00:12s\n","epoch 27 | loss: 0.70646 | val_0_mse: 1.962839961051941|  0:00:13s\n","epoch 28 | loss: 0.80933 | val_0_mse: 2.409830093383789|  0:00:13s\n","epoch 29 | loss: 0.72388 | val_0_mse: 2.962779998779297|  0:00:14s\n","epoch 30 | loss: 0.72809 | val_0_mse: 1.982890009880066|  0:00:14s\n","epoch 31 | loss: 0.84182 | val_0_mse: 1.9048500061035156|  0:00:15s\n","epoch 32 | loss: 0.84905 | val_0_mse: 1.4728399515151978|  0:00:15s\n","epoch 33 | loss: 0.69718 | val_0_mse: 0.8821700215339661|  0:00:16s\n","epoch 34 | loss: 0.71507 | val_0_mse: 1.520009994506836|  0:00:16s\n","epoch 35 | loss: 0.64169 | val_0_mse: 0.827239990234375|  0:00:17s\n","epoch 36 | loss: 0.73098 | val_0_mse: 1.5139100551605225|  0:00:17s\n","epoch 37 | loss: 0.78608 | val_0_mse: 1.0617200136184692|  0:00:18s\n","epoch 38 | loss: 0.6379  | val_0_mse: 0.8609600067138672|  0:00:18s\n","epoch 39 | loss: 0.72281 | val_0_mse: 1.5572400093078613|  0:00:19s\n","epoch 40 | loss: 0.71232 | val_0_mse: 0.8026300072669983|  0:00:19s\n","epoch 41 | loss: 0.69963 | val_0_mse: 1.2153700590133667|  0:00:20s\n","epoch 42 | loss: 0.60713 | val_0_mse: 0.8993899822235107|  0:00:20s\n","epoch 43 | loss: 0.60215 | val_0_mse: 0.7687100172042847|  0:00:21s\n","epoch 44 | loss: 0.74709 | val_0_mse: 1.2106399536132812|  0:00:21s\n","epoch 45 | loss: 0.75386 | val_0_mse: 0.9093599915504456|  0:00:22s\n","epoch 46 | loss: 0.62056 | val_0_mse: 1.2569700479507446|  0:00:22s\n","epoch 47 | loss: 0.57132 | val_0_mse: 1.0486299991607666|  0:00:23s\n","epoch 48 | loss: 0.54614 | val_0_mse: 0.8303899765014648|  0:00:23s\n","epoch 49 | loss: 0.54801 | val_0_mse: 0.9755799770355225|  0:00:23s\n","epoch 50 | loss: 0.58603 | val_0_mse: 0.7978100180625916|  0:00:24s\n","epoch 51 | loss: 0.69707 | val_0_mse: 1.1268800497055054|  0:00:24s\n","epoch 52 | loss: 0.69071 | val_0_mse: 0.7526000142097473|  0:00:25s\n","epoch 53 | loss: 0.58346 | val_0_mse: 0.807699978351593|  0:00:25s\n","epoch 54 | loss: 0.57648 | val_0_mse: 0.7576500177383423|  0:00:26s\n","epoch 55 | loss: 0.60807 | val_0_mse: 1.0889500379562378|  0:00:26s\n","epoch 56 | loss: 0.6175  | val_0_mse: 0.8529599905014038|  0:00:27s\n","epoch 57 | loss: 0.55843 | val_0_mse: 0.7537000179290771|  0:00:27s\n","epoch 58 | loss: 0.55726 | val_0_mse: 0.7058299779891968|  0:00:28s\n","epoch 59 | loss: 0.58297 | val_0_mse: 0.7516599893569946|  0:00:28s\n","epoch 60 | loss: 0.56687 | val_0_mse: 0.9977499842643738|  0:00:29s\n","epoch 61 | loss: 0.59004 | val_0_mse: 0.7132700085639954|  0:00:29s\n","epoch 62 | loss: 0.54837 | val_0_mse: 0.7422000169754028|  0:00:30s\n","epoch 63 | loss: 0.65    | val_0_mse: 0.89028000831604|  0:00:30s\n","epoch 64 | loss: 0.59558 | val_0_mse: 0.6803799867630005|  0:00:31s\n","epoch 65 | loss: 0.56934 | val_0_mse: 0.692300021648407|  0:00:31s\n","epoch 66 | loss: 0.58934 | val_0_mse: 0.8963500261306763|  0:00:31s\n","epoch 67 | loss: 0.64643 | val_0_mse: 0.7322800159454346|  0:00:32s\n","epoch 68 | loss: 0.75394 | val_0_mse: 0.9907100200653076|  0:00:32s\n","epoch 69 | loss: 0.60036 | val_0_mse: 0.7263799905776978|  0:00:33s\n","epoch 70 | loss: 0.51945 | val_0_mse: 0.7369199991226196|  0:00:33s\n","epoch 71 | loss: 0.5489  | val_0_mse: 0.6960499882698059|  0:00:34s\n","epoch 72 | loss: 0.54651 | val_0_mse: 0.6777099967002869|  0:00:34s\n","epoch 73 | loss: 0.5391  | val_0_mse: 0.6745100021362305|  0:00:35s\n","epoch 74 | loss: 0.55658 | val_0_mse: 0.655430018901825|  0:00:35s\n","epoch 75 | loss: 0.54985 | val_0_mse: 0.61735999584198|  0:00:36s\n","epoch 76 | loss: 0.53589 | val_0_mse: 0.5999299883842468|  0:00:36s\n","epoch 77 | loss: 0.54852 | val_0_mse: 0.67221999168396|  0:00:37s\n","epoch 78 | loss: 0.56431 | val_0_mse: 0.7025799751281738|  0:00:37s\n","epoch 79 | loss: 0.65083 | val_0_mse: 0.6210600137710571|  0:00:38s\n","epoch 80 | loss: 0.52529 | val_0_mse: 0.6370900273323059|  0:00:38s\n","epoch 81 | loss: 0.53371 | val_0_mse: 0.6655399799346924|  0:00:39s\n","epoch 82 | loss: 0.56788 | val_0_mse: 0.6487900018692017|  0:00:39s\n","epoch 83 | loss: 0.54899 | val_0_mse: 0.6641299724578857|  0:00:40s\n","epoch 84 | loss: 0.54138 | val_0_mse: 0.6223300099372864|  0:00:40s\n","epoch 85 | loss: 0.53398 | val_0_mse: 0.6389700174331665|  0:00:41s\n","epoch 86 | loss: 0.52112 | val_0_mse: 0.6482300162315369|  0:00:41s\n","\n","Early stopping occurred at epoch 86 with best_epoch = 76 and best_val_0_mse = 0.5999299883842468\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 16:36:05,471] Trial 77 finished with value: 0.5999284386634827 and parameters: {'n_d': 48, 'n_steps': 8, 'gamma': 1.5210150129560571, 'n_independent': 2, 'n_shared': 3, 'momentum': 0.14466234193819155}. Best is trial 55 with value: 0.5396906733512878.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 22.04877| val_0_mse: 569.2006225585938|  0:00:00s\n","epoch 1  | loss: 6.11656 | val_0_mse: 554.594970703125|  0:00:00s\n","epoch 2  | loss: 2.8128  | val_0_mse: 113.5716323852539|  0:00:01s\n","epoch 3  | loss: 1.75199 | val_0_mse: 133.0340576171875|  0:00:01s\n","epoch 4  | loss: 1.32349 | val_0_mse: 25.789819717407227|  0:00:02s\n","epoch 5  | loss: 1.02871 | val_0_mse: 14.423060417175293|  0:00:02s\n","epoch 6  | loss: 0.88886 | val_0_mse: 7.007309913635254|  0:00:03s\n","epoch 7  | loss: 0.83382 | val_0_mse: 6.77918004989624|  0:00:03s\n","epoch 8  | loss: 0.81523 | val_0_mse: 5.558609962463379|  0:00:04s\n","epoch 9  | loss: 0.76638 | val_0_mse: 4.558290004730225|  0:00:04s\n","epoch 10 | loss: 0.88177 | val_0_mse: 4.2253499031066895|  0:00:05s\n","epoch 11 | loss: 0.69596 | val_0_mse: 6.265820026397705|  0:00:05s\n","epoch 12 | loss: 0.88173 | val_0_mse: 3.6033198833465576|  0:00:06s\n","epoch 13 | loss: 0.69612 | val_0_mse: 2.27308988571167|  0:00:06s\n","epoch 14 | loss: 0.65241 | val_0_mse: 1.936959981918335|  0:00:07s\n","epoch 15 | loss: 0.62459 | val_0_mse: 1.8758200407028198|  0:00:07s\n","epoch 16 | loss: 0.62988 | val_0_mse: 1.2870999574661255|  0:00:07s\n","epoch 17 | loss: 0.63102 | val_0_mse: 1.6732399463653564|  0:00:08s\n","epoch 18 | loss: 0.61549 | val_0_mse: 1.3933299779891968|  0:00:08s\n","epoch 19 | loss: 0.58523 | val_0_mse: 1.3585200309753418|  0:00:09s\n","epoch 20 | loss: 0.61228 | val_0_mse: 1.4889700412750244|  0:00:09s\n","epoch 21 | loss: 0.61298 | val_0_mse: 2.0849599838256836|  0:00:10s\n","epoch 22 | loss: 0.63144 | val_0_mse: 1.540809988975525|  0:00:10s\n","epoch 23 | loss: 0.59975 | val_0_mse: 1.3415299654006958|  0:00:11s\n","epoch 24 | loss: 0.60707 | val_0_mse: 1.6458899974822998|  0:00:11s\n","epoch 25 | loss: 0.60965 | val_0_mse: 1.134220004081726|  0:00:11s\n","epoch 26 | loss: 0.57135 | val_0_mse: 1.2511299848556519|  0:00:12s\n","epoch 27 | loss: 0.59007 | val_0_mse: 1.7215399742126465|  0:00:12s\n","epoch 28 | loss: 0.64535 | val_0_mse: 1.1290199756622314|  0:00:13s\n","epoch 29 | loss: 0.61899 | val_0_mse: 1.1900500059127808|  0:00:13s\n","epoch 30 | loss: 0.59169 | val_0_mse: 1.3532899618148804|  0:00:14s\n","epoch 31 | loss: 0.56845 | val_0_mse: 1.3270399570465088|  0:00:14s\n","epoch 32 | loss: 0.61279 | val_0_mse: 0.9513300061225891|  0:00:15s\n","epoch 33 | loss: 0.54665 | val_0_mse: 0.82191002368927|  0:00:15s\n","epoch 34 | loss: 0.55227 | val_0_mse: 0.920799970626831|  0:00:16s\n","epoch 35 | loss: 0.53876 | val_0_mse: 0.9100199937820435|  0:00:16s\n","epoch 36 | loss: 0.53665 | val_0_mse: 0.9670699834823608|  0:00:16s\n","epoch 37 | loss: 0.53409 | val_0_mse: 0.8759599924087524|  0:00:17s\n","epoch 38 | loss: 0.52984 | val_0_mse: 0.7693600058555603|  0:00:17s\n","epoch 39 | loss: 0.642   | val_0_mse: 0.7742800116539001|  0:00:18s\n","epoch 40 | loss: 0.56018 | val_0_mse: 0.7228599786758423|  0:00:18s\n","epoch 41 | loss: 0.5401  | val_0_mse: 0.8815199732780457|  0:00:19s\n","epoch 42 | loss: 0.53892 | val_0_mse: 0.8446900248527527|  0:00:19s\n","epoch 43 | loss: 0.52188 | val_0_mse: 0.7723399996757507|  0:00:20s\n","epoch 44 | loss: 0.50926 | val_0_mse: 0.7478100061416626|  0:00:20s\n","epoch 45 | loss: 0.51033 | val_0_mse: 0.7745599746704102|  0:00:20s\n","epoch 46 | loss: 0.51741 | val_0_mse: 0.7003999948501587|  0:00:21s\n","epoch 47 | loss: 0.51734 | val_0_mse: 0.7335299849510193|  0:00:21s\n","epoch 48 | loss: 0.51535 | val_0_mse: 0.7537599802017212|  0:00:22s\n","epoch 49 | loss: 0.50805 | val_0_mse: 0.77947998046875|  0:00:22s\n","epoch 50 | loss: 0.52398 | val_0_mse: 0.6806300282478333|  0:00:23s\n","epoch 51 | loss: 0.51194 | val_0_mse: 0.7315400242805481|  0:00:23s\n","epoch 52 | loss: 0.51184 | val_0_mse: 0.7292199730873108|  0:00:24s\n","epoch 53 | loss: 0.51825 | val_0_mse: 0.7153900265693665|  0:00:24s\n","epoch 54 | loss: 0.53225 | val_0_mse: 0.7277200222015381|  0:00:24s\n","epoch 55 | loss: 0.55502 | val_0_mse: 0.6585999727249146|  0:00:25s\n","epoch 56 | loss: 0.54885 | val_0_mse: 0.720229983329773|  0:00:25s\n","epoch 57 | loss: 0.5515  | val_0_mse: 0.6790300011634827|  0:00:26s\n","epoch 58 | loss: 0.5218  | val_0_mse: 0.6275799870491028|  0:00:26s\n","epoch 59 | loss: 0.5015  | val_0_mse: 0.6259700059890747|  0:00:27s\n","epoch 60 | loss: 0.5077  | val_0_mse: 0.6689500212669373|  0:00:27s\n","epoch 61 | loss: 0.53009 | val_0_mse: 0.6530500054359436|  0:00:28s\n","epoch 62 | loss: 0.5292  | val_0_mse: 0.6355999708175659|  0:00:28s\n","epoch 63 | loss: 0.50425 | val_0_mse: 0.6268100142478943|  0:00:28s\n","epoch 64 | loss: 0.50288 | val_0_mse: 0.6358299851417542|  0:00:29s\n","epoch 65 | loss: 0.50283 | val_0_mse: 0.642270028591156|  0:00:29s\n","epoch 66 | loss: 0.50736 | val_0_mse: 0.6484799981117249|  0:00:30s\n","epoch 67 | loss: 0.51473 | val_0_mse: 0.6473699808120728|  0:00:30s\n","epoch 68 | loss: 0.52425 | val_0_mse: 0.6633599996566772|  0:00:31s\n","epoch 69 | loss: 0.52702 | val_0_mse: 0.6457700133323669|  0:00:31s\n","\n","Early stopping occurred at epoch 69 with best_epoch = 59 and best_val_0_mse = 0.6259700059890747\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 16:36:37,457] Trial 78 finished with value: 0.6259666085243225 and parameters: {'n_d': 12, 'n_steps': 9, 'gamma': 1.1893383273887779, 'n_independent': 3, 'n_shared': 1, 'momentum': 0.08306378021615295}. Best is trial 55 with value: 0.5396906733512878.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 10.33639| val_0_mse: 438.8594665527344|  0:00:00s\n","epoch 1  | loss: 4.01943 | val_0_mse: 291.17047119140625|  0:00:01s\n","epoch 2  | loss: 2.86482 | val_0_mse: 111.12373352050781|  0:00:01s\n","epoch 3  | loss: 2.05086 | val_0_mse: 81.97235870361328|  0:00:02s\n","epoch 4  | loss: 1.48885 | val_0_mse: 90.21217346191406|  0:00:02s\n","epoch 5  | loss: 1.08578 | val_0_mse: 50.10177993774414|  0:00:03s\n","epoch 6  | loss: 0.97243 | val_0_mse: 28.429750442504883|  0:00:04s\n","epoch 7  | loss: 0.84806 | val_0_mse: 41.14680862426758|  0:00:04s\n","epoch 8  | loss: 0.88465 | val_0_mse: 32.12981033325195|  0:00:05s\n","epoch 9  | loss: 0.95436 | val_0_mse: 33.16468811035156|  0:00:05s\n","epoch 10 | loss: 0.99577 | val_0_mse: 4.482999801635742|  0:00:06s\n","epoch 11 | loss: 1.00529 | val_0_mse: 12.05193042755127|  0:00:06s\n","epoch 12 | loss: 0.9433  | val_0_mse: 6.10915994644165|  0:00:07s\n","epoch 13 | loss: 0.7893  | val_0_mse: 12.092789649963379|  0:00:08s\n","epoch 14 | loss: 0.75558 | val_0_mse: 4.512159824371338|  0:00:08s\n","epoch 15 | loss: 0.76749 | val_0_mse: 11.536060333251953|  0:00:09s\n","epoch 16 | loss: 0.71188 | val_0_mse: 7.172939777374268|  0:00:09s\n","epoch 17 | loss: 0.67375 | val_0_mse: 3.5256900787353516|  0:00:10s\n","epoch 18 | loss: 0.65702 | val_0_mse: 3.7142300605773926|  0:00:10s\n","epoch 19 | loss: 0.67253 | val_0_mse: 2.7126901149749756|  0:00:11s\n","epoch 20 | loss: 0.60811 | val_0_mse: 2.271130084991455|  0:00:11s\n","epoch 21 | loss: 0.64547 | val_0_mse: 2.207629919052124|  0:00:12s\n","epoch 22 | loss: 0.62442 | val_0_mse: 1.9910199642181396|  0:00:13s\n","epoch 23 | loss: 0.61976 | val_0_mse: 1.6897300481796265|  0:00:13s\n","epoch 24 | loss: 0.58271 | val_0_mse: 1.4038499593734741|  0:00:14s\n","epoch 25 | loss: 0.55885 | val_0_mse: 1.1408699750900269|  0:00:14s\n","epoch 26 | loss: 0.57103 | val_0_mse: 0.9847000241279602|  0:00:15s\n","epoch 27 | loss: 0.57921 | val_0_mse: 1.2134699821472168|  0:00:16s\n","epoch 28 | loss: 0.54599 | val_0_mse: 1.3194799423217773|  0:00:16s\n","epoch 29 | loss: 0.55932 | val_0_mse: 1.4990400075912476|  0:00:17s\n","epoch 30 | loss: 0.57053 | val_0_mse: 1.8985099792480469|  0:00:17s\n","epoch 31 | loss: 0.57575 | val_0_mse: 2.0460801124572754|  0:00:18s\n","epoch 32 | loss: 0.58265 | val_0_mse: 2.3346400260925293|  0:00:18s\n","epoch 33 | loss: 0.58903 | val_0_mse: 0.9643300175666809|  0:00:19s\n","epoch 34 | loss: 0.69183 | val_0_mse: 3.4962899684906006|  0:00:19s\n","epoch 35 | loss: 0.83271 | val_0_mse: 0.8214300274848938|  0:00:20s\n","epoch 36 | loss: 0.68322 | val_0_mse: 1.9794600009918213|  0:00:21s\n","epoch 37 | loss: 0.71001 | val_0_mse: 0.9512199759483337|  0:00:21s\n","epoch 38 | loss: 0.59582 | val_0_mse: 1.7941800355911255|  0:00:22s\n","epoch 39 | loss: 0.57965 | val_0_mse: 1.0785499811172485|  0:00:22s\n","epoch 40 | loss: 0.54875 | val_0_mse: 1.2869900465011597|  0:00:23s\n","epoch 41 | loss: 0.55008 | val_0_mse: 1.756350040435791|  0:00:23s\n","epoch 42 | loss: 0.57205 | val_0_mse: 0.9083899855613708|  0:00:24s\n","epoch 43 | loss: 0.67977 | val_0_mse: 1.6605600118637085|  0:00:25s\n","epoch 44 | loss: 0.62384 | val_0_mse: 0.7523499727249146|  0:00:25s\n","epoch 45 | loss: 0.59366 | val_0_mse: 1.0499500036239624|  0:00:26s\n","epoch 46 | loss: 0.56283 | val_0_mse: 0.9313200116157532|  0:00:26s\n","epoch 47 | loss: 0.5406  | val_0_mse: 0.7686100006103516|  0:00:27s\n","epoch 48 | loss: 0.54423 | val_0_mse: 1.016510009765625|  0:00:27s\n","epoch 49 | loss: 0.55551 | val_0_mse: 0.7513999938964844|  0:00:28s\n","epoch 50 | loss: 0.53522 | val_0_mse: 0.685949981212616|  0:00:28s\n","epoch 51 | loss: 0.51755 | val_0_mse: 0.8415899872779846|  0:00:29s\n","epoch 52 | loss: 0.51742 | val_0_mse: 0.8854699730873108|  0:00:30s\n","epoch 53 | loss: 0.51873 | val_0_mse: 1.054900050163269|  0:00:30s\n","epoch 54 | loss: 0.51915 | val_0_mse: 0.8025699853897095|  0:00:31s\n","epoch 55 | loss: 0.53375 | val_0_mse: 0.6408600211143494|  0:00:31s\n","epoch 56 | loss: 0.56305 | val_0_mse: 0.853630006313324|  0:00:32s\n","epoch 57 | loss: 0.53783 | val_0_mse: 0.6236799955368042|  0:00:32s\n","epoch 58 | loss: 0.54791 | val_0_mse: 0.6741099953651428|  0:00:33s\n","epoch 59 | loss: 0.55867 | val_0_mse: 0.6477100253105164|  0:00:34s\n","epoch 60 | loss: 0.50047 | val_0_mse: 0.6499599814414978|  0:00:34s\n","epoch 61 | loss: 0.5087  | val_0_mse: 0.8164399862289429|  0:00:35s\n","epoch 62 | loss: 0.53762 | val_0_mse: 0.6556699872016907|  0:00:35s\n","epoch 63 | loss: 0.55629 | val_0_mse: 0.847790002822876|  0:00:36s\n","epoch 64 | loss: 0.57105 | val_0_mse: 0.625760018825531|  0:00:36s\n","epoch 65 | loss: 0.53533 | val_0_mse: 0.8797500133514404|  0:00:37s\n","epoch 66 | loss: 0.55645 | val_0_mse: 0.621999979019165|  0:00:38s\n","epoch 67 | loss: 0.54161 | val_0_mse: 0.7398899793624878|  0:00:38s\n","epoch 68 | loss: 0.53145 | val_0_mse: 0.6075900197029114|  0:00:39s\n","epoch 69 | loss: 0.52984 | val_0_mse: 0.6947299838066101|  0:00:39s\n","epoch 70 | loss: 0.54538 | val_0_mse: 0.6480799913406372|  0:00:40s\n","epoch 71 | loss: 0.52757 | val_0_mse: 0.621649980545044|  0:00:40s\n","epoch 72 | loss: 0.4826  | val_0_mse: 0.635200023651123|  0:00:41s\n","epoch 73 | loss: 0.48528 | val_0_mse: 0.6164399981498718|  0:00:41s\n","epoch 74 | loss: 0.49587 | val_0_mse: 0.6509699821472168|  0:00:42s\n","epoch 75 | loss: 0.56904 | val_0_mse: 0.7307699918746948|  0:00:43s\n","epoch 76 | loss: 0.5508  | val_0_mse: 0.6696299910545349|  0:00:43s\n","epoch 77 | loss: 0.56018 | val_0_mse: 0.6930099725723267|  0:00:44s\n","epoch 78 | loss: 0.56285 | val_0_mse: 0.6968899965286255|  0:00:44s\n","\n","Early stopping occurred at epoch 78 with best_epoch = 68 and best_val_0_mse = 0.6075900197029114\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 16:37:22,562] Trial 79 finished with value: 0.6075925230979919 and parameters: {'n_d': 14, 'n_steps': 10, 'gamma': 1.024203626617409, 'n_independent': 1, 'n_shared': 4, 'momentum': 0.06360939721481784}. Best is trial 55 with value: 0.5396906733512878.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 30.7812 | val_0_mse: 863.4639892578125|  0:00:00s\n","epoch 1  | loss: 9.25648 | val_0_mse: 1055.6497802734375|  0:00:00s\n","epoch 2  | loss: 4.54637 | val_0_mse: 146.7933807373047|  0:00:01s\n","epoch 3  | loss: 2.55704 | val_0_mse: 33.89889907836914|  0:00:01s\n","epoch 4  | loss: 1.88784 | val_0_mse: 25.479320526123047|  0:00:02s\n","epoch 5  | loss: 1.42379 | val_0_mse: 32.68777847290039|  0:00:02s\n","epoch 6  | loss: 1.10328 | val_0_mse: 62.76913833618164|  0:00:03s\n","epoch 7  | loss: 0.92341 | val_0_mse: 46.01530838012695|  0:00:03s\n","epoch 8  | loss: 0.80914 | val_0_mse: 16.022560119628906|  0:00:04s\n","epoch 9  | loss: 0.7867  | val_0_mse: 10.987950325012207|  0:00:04s\n","epoch 10 | loss: 0.70642 | val_0_mse: 8.042610168457031|  0:00:05s\n","epoch 11 | loss: 0.67826 | val_0_mse: 5.5067901611328125|  0:00:05s\n","epoch 12 | loss: 0.7157  | val_0_mse: 5.416470050811768|  0:00:06s\n","epoch 13 | loss: 0.67425 | val_0_mse: 4.79794979095459|  0:00:06s\n","epoch 14 | loss: 0.64082 | val_0_mse: 3.880460023880005|  0:00:07s\n","epoch 15 | loss: 0.66815 | val_0_mse: 6.056009769439697|  0:00:07s\n","epoch 16 | loss: 0.63386 | val_0_mse: 5.777359962463379|  0:00:07s\n","epoch 17 | loss: 0.60477 | val_0_mse: 4.017630100250244|  0:00:08s\n","epoch 18 | loss: 0.62784 | val_0_mse: 3.3371500968933105|  0:00:08s\n","epoch 19 | loss: 0.64162 | val_0_mse: 3.7148900032043457|  0:00:09s\n","epoch 20 | loss: 0.62651 | val_0_mse: 1.3168100118637085|  0:00:09s\n","epoch 21 | loss: 0.62581 | val_0_mse: 4.186399936676025|  0:00:10s\n","epoch 22 | loss: 0.71241 | val_0_mse: 1.2458499670028687|  0:00:10s\n","epoch 23 | loss: 0.63837 | val_0_mse: 2.9894399642944336|  0:00:11s\n","epoch 24 | loss: 0.5733  | val_0_mse: 1.8236500024795532|  0:00:11s\n","epoch 25 | loss: 0.55566 | val_0_mse: 1.4449199438095093|  0:00:12s\n","epoch 26 | loss: 0.57258 | val_0_mse: 1.1195499897003174|  0:00:12s\n","epoch 27 | loss: 0.55717 | val_0_mse: 1.1626700162887573|  0:00:13s\n","epoch 28 | loss: 0.56659 | val_0_mse: 1.2899999618530273|  0:00:13s\n","epoch 29 | loss: 0.57232 | val_0_mse: 1.0271199941635132|  0:00:14s\n","epoch 30 | loss: 0.55829 | val_0_mse: 1.065809965133667|  0:00:14s\n","epoch 31 | loss: 0.55142 | val_0_mse: 0.843559980392456|  0:00:14s\n","epoch 32 | loss: 0.54863 | val_0_mse: 0.7759400010108948|  0:00:15s\n","epoch 33 | loss: 0.55278 | val_0_mse: 1.074620008468628|  0:00:15s\n","epoch 34 | loss: 0.58357 | val_0_mse: 0.9393200278282166|  0:00:16s\n","epoch 35 | loss: 0.5859  | val_0_mse: 1.0164599418640137|  0:00:16s\n","epoch 36 | loss: 0.6074  | val_0_mse: 0.8674200177192688|  0:00:17s\n","epoch 37 | loss: 0.58204 | val_0_mse: 1.027459979057312|  0:00:17s\n","epoch 38 | loss: 0.57435 | val_0_mse: 0.9890499711036682|  0:00:18s\n","epoch 39 | loss: 0.55125 | val_0_mse: 0.7358899712562561|  0:00:18s\n","epoch 40 | loss: 0.57132 | val_0_mse: 0.9070500135421753|  0:00:19s\n","epoch 41 | loss: 0.54714 | val_0_mse: 0.8887100219726562|  0:00:19s\n","epoch 42 | loss: 0.55027 | val_0_mse: 0.742110013961792|  0:00:20s\n","epoch 43 | loss: 0.56533 | val_0_mse: 0.8599900007247925|  0:00:20s\n","epoch 44 | loss: 0.54054 | val_0_mse: 0.7082499861717224|  0:00:21s\n","epoch 45 | loss: 0.52689 | val_0_mse: 0.7501000165939331|  0:00:21s\n","epoch 46 | loss: 0.52688 | val_0_mse: 0.6783400177955627|  0:00:22s\n","epoch 47 | loss: 0.51616 | val_0_mse: 0.7001799941062927|  0:00:22s\n","epoch 48 | loss: 0.52412 | val_0_mse: 0.7458900213241577|  0:00:23s\n","epoch 49 | loss: 0.51331 | val_0_mse: 0.7562000155448914|  0:00:23s\n","epoch 50 | loss: 0.52522 | val_0_mse: 0.6732000112533569|  0:00:24s\n","epoch 51 | loss: 0.54214 | val_0_mse: 0.6383100152015686|  0:00:24s\n","epoch 52 | loss: 0.53783 | val_0_mse: 0.8354099988937378|  0:00:25s\n","epoch 53 | loss: 0.55514 | val_0_mse: 0.6357100009918213|  0:00:25s\n","epoch 54 | loss: 0.56777 | val_0_mse: 0.8802800178527832|  0:00:25s\n","epoch 55 | loss: 0.59562 | val_0_mse: 0.6295300126075745|  0:00:26s\n","epoch 56 | loss: 0.54428 | val_0_mse: 0.807200014591217|  0:00:26s\n","epoch 57 | loss: 0.55023 | val_0_mse: 0.6295700073242188|  0:00:27s\n","epoch 58 | loss: 0.5163  | val_0_mse: 0.6600599884986877|  0:00:27s\n","epoch 59 | loss: 0.50525 | val_0_mse: 0.6552500128746033|  0:00:28s\n","epoch 60 | loss: 0.49994 | val_0_mse: 0.7094699740409851|  0:00:28s\n","epoch 61 | loss: 0.49851 | val_0_mse: 0.7417700290679932|  0:00:29s\n","epoch 62 | loss: 0.5037  | val_0_mse: 0.6182299852371216|  0:00:29s\n","epoch 63 | loss: 0.52618 | val_0_mse: 0.7950199842453003|  0:00:30s\n","epoch 64 | loss: 0.52153 | val_0_mse: 0.6180999875068665|  0:00:30s\n","epoch 65 | loss: 0.50259 | val_0_mse: 0.6229000091552734|  0:00:31s\n","epoch 66 | loss: 0.50812 | val_0_mse: 0.6477000117301941|  0:00:31s\n","epoch 67 | loss: 0.51181 | val_0_mse: 0.6818600296974182|  0:00:32s\n","epoch 68 | loss: 0.52347 | val_0_mse: 0.6413999795913696|  0:00:32s\n","epoch 69 | loss: 0.50564 | val_0_mse: 0.633109986782074|  0:00:32s\n","epoch 70 | loss: 0.51895 | val_0_mse: 0.61285001039505|  0:00:33s\n","epoch 71 | loss: 0.51015 | val_0_mse: 0.614139974117279|  0:00:33s\n","epoch 72 | loss: 0.51505 | val_0_mse: 0.6794999837875366|  0:00:34s\n","epoch 73 | loss: 0.51508 | val_0_mse: 0.6227999925613403|  0:00:34s\n","epoch 74 | loss: 0.5136  | val_0_mse: 0.596589982509613|  0:00:35s\n","epoch 75 | loss: 0.54148 | val_0_mse: 0.7405499815940857|  0:00:35s\n","epoch 76 | loss: 0.5366  | val_0_mse: 0.6011099815368652|  0:00:36s\n","epoch 77 | loss: 0.52554 | val_0_mse: 0.6022099852561951|  0:00:36s\n","epoch 78 | loss: 0.50921 | val_0_mse: 0.6442800164222717|  0:00:37s\n","epoch 79 | loss: 0.50424 | val_0_mse: 0.6224899888038635|  0:00:37s\n","epoch 80 | loss: 0.51155 | val_0_mse: 0.6050500273704529|  0:00:38s\n","epoch 81 | loss: 0.529   | val_0_mse: 0.7414900064468384|  0:00:38s\n","epoch 82 | loss: 0.56783 | val_0_mse: 0.6195300221443176|  0:00:39s\n","epoch 83 | loss: 0.54402 | val_0_mse: 0.6834999918937683|  0:00:39s\n","epoch 84 | loss: 0.52521 | val_0_mse: 0.5960599780082703|  0:00:39s\n","epoch 85 | loss: 0.49573 | val_0_mse: 0.5750399827957153|  0:00:40s\n","epoch 86 | loss: 0.49929 | val_0_mse: 0.5882999897003174|  0:00:40s\n","epoch 87 | loss: 0.50463 | val_0_mse: 0.6050400137901306|  0:00:41s\n","epoch 88 | loss: 0.50593 | val_0_mse: 0.6391500234603882|  0:00:41s\n","epoch 89 | loss: 0.54549 | val_0_mse: 0.6150500178337097|  0:00:42s\n","epoch 90 | loss: 0.58014 | val_0_mse: 0.5854200124740601|  0:00:42s\n","epoch 91 | loss: 0.51536 | val_0_mse: 0.6050400137901306|  0:00:43s\n","epoch 92 | loss: 0.51547 | val_0_mse: 0.5976700186729431|  0:00:43s\n","epoch 93 | loss: 0.49962 | val_0_mse: 0.5870199799537659|  0:00:44s\n","epoch 94 | loss: 0.4974  | val_0_mse: 0.5956000089645386|  0:00:44s\n","epoch 95 | loss: 0.51295 | val_0_mse: 0.6224300265312195|  0:00:45s\n","\n","Early stopping occurred at epoch 95 with best_epoch = 85 and best_val_0_mse = 0.5750399827957153\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 16:38:08,105] Trial 80 finished with value: 0.575041651725769 and parameters: {'n_d': 10, 'n_steps': 8, 'gamma': 1.1289114995426965, 'n_independent': 2, 'n_shared': 3, 'momentum': 0.020516813449249403}. Best is trial 55 with value: 0.5396906733512878.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 25.09785| val_0_mse: 449.738037109375|  0:00:00s\n","epoch 1  | loss: 7.53745 | val_0_mse: 280.4378662109375|  0:00:00s\n","epoch 2  | loss: 4.11585 | val_0_mse: 53.02156066894531|  0:00:01s\n","epoch 3  | loss: 2.19738 | val_0_mse: 16.06287956237793|  0:00:01s\n","epoch 4  | loss: 1.3878  | val_0_mse: 9.067489624023438|  0:00:02s\n","epoch 5  | loss: 1.05208 | val_0_mse: 3.9629299640655518|  0:00:02s\n","epoch 6  | loss: 0.99062 | val_0_mse: 3.4227800369262695|  0:00:03s\n","epoch 7  | loss: 0.94124 | val_0_mse: 11.334779739379883|  0:00:03s\n","epoch 8  | loss: 0.90186 | val_0_mse: 4.256760120391846|  0:00:04s\n","epoch 9  | loss: 0.74639 | val_0_mse: 5.985809803009033|  0:00:04s\n","epoch 10 | loss: 0.72948 | val_0_mse: 8.129910469055176|  0:00:05s\n","epoch 11 | loss: 0.72358 | val_0_mse: 3.8834099769592285|  0:00:05s\n","epoch 12 | loss: 0.698   | val_0_mse: 4.055019855499268|  0:00:06s\n","epoch 13 | loss: 0.7145  | val_0_mse: 5.160359859466553|  0:00:06s\n","epoch 14 | loss: 0.66184 | val_0_mse: 2.231529951095581|  0:00:07s\n","epoch 15 | loss: 0.65155 | val_0_mse: 2.458240032196045|  0:00:07s\n","epoch 16 | loss: 0.64809 | val_0_mse: 2.5642499923706055|  0:00:08s\n","epoch 17 | loss: 0.61516 | val_0_mse: 2.035490036010742|  0:00:08s\n","epoch 18 | loss: 0.59443 | val_0_mse: 4.308740139007568|  0:00:09s\n","epoch 19 | loss: 0.59515 | val_0_mse: 4.741569995880127|  0:00:09s\n","epoch 20 | loss: 0.58926 | val_0_mse: 6.251239776611328|  0:00:10s\n","epoch 21 | loss: 0.5961  | val_0_mse: 5.156149864196777|  0:00:10s\n","epoch 22 | loss: 0.5903  | val_0_mse: 3.2321200370788574|  0:00:11s\n","epoch 23 | loss: 0.60756 | val_0_mse: 3.6158199310302734|  0:00:11s\n","epoch 24 | loss: 0.6083  | val_0_mse: 3.790260076522827|  0:00:12s\n","epoch 25 | loss: 0.55993 | val_0_mse: 4.20058012008667|  0:00:12s\n","epoch 26 | loss: 0.58479 | val_0_mse: 2.5565099716186523|  0:00:13s\n","epoch 27 | loss: 0.56179 | val_0_mse: 2.3086400032043457|  0:00:13s\n","\n","Early stopping occurred at epoch 27 with best_epoch = 17 and best_val_0_mse = 2.035490036010742\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 16:38:22,153] Trial 81 finished with value: 2.035494327545166 and parameters: {'n_d': 9, 'n_steps': 8, 'gamma': 1.1253324883540072, 'n_independent': 2, 'n_shared': 3, 'momentum': 0.025306826358101126}. Best is trial 55 with value: 0.5396906733512878.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 37.40266| val_0_mse: 169.95103454589844|  0:00:00s\n","epoch 1  | loss: 13.88374| val_0_mse: 91.70084381103516|  0:00:00s\n","epoch 2  | loss: 6.3549  | val_0_mse: 382.9633483886719|  0:00:01s\n","epoch 3  | loss: 4.2882  | val_0_mse: 241.1811065673828|  0:00:01s\n","epoch 4  | loss: 2.39422 | val_0_mse: 108.54754638671875|  0:00:02s\n","epoch 5  | loss: 1.59933 | val_0_mse: 99.88990020751953|  0:00:02s\n","epoch 6  | loss: 1.13461 | val_0_mse: 46.87200927734375|  0:00:02s\n","epoch 7  | loss: 0.92596 | val_0_mse: 30.63150978088379|  0:00:03s\n","epoch 8  | loss: 0.85056 | val_0_mse: 13.091830253601074|  0:00:03s\n","epoch 9  | loss: 0.762   | val_0_mse: 11.099820137023926|  0:00:04s\n","epoch 10 | loss: 0.71923 | val_0_mse: 21.30068016052246|  0:00:04s\n","epoch 11 | loss: 0.68688 | val_0_mse: 18.30866050720215|  0:00:05s\n","epoch 12 | loss: 0.67796 | val_0_mse: 27.11186981201172|  0:00:05s\n","epoch 13 | loss: 0.67251 | val_0_mse: 24.55147933959961|  0:00:05s\n","epoch 14 | loss: 0.64977 | val_0_mse: 15.537260055541992|  0:00:06s\n","epoch 15 | loss: 0.64229 | val_0_mse: 3.3092200756073|  0:00:06s\n","epoch 16 | loss: 0.64851 | val_0_mse: 6.045499801635742|  0:00:07s\n","epoch 17 | loss: 0.65425 | val_0_mse: 9.255900382995605|  0:00:07s\n","epoch 18 | loss: 0.67865 | val_0_mse: 9.475899696350098|  0:00:08s\n","epoch 19 | loss: 0.65377 | val_0_mse: 14.356049537658691|  0:00:08s\n","epoch 20 | loss: 0.61766 | val_0_mse: 11.944279670715332|  0:00:08s\n","epoch 21 | loss: 0.60842 | val_0_mse: 8.346329689025879|  0:00:09s\n","epoch 22 | loss: 0.61308 | val_0_mse: 5.295199871063232|  0:00:09s\n","epoch 23 | loss: 0.60386 | val_0_mse: 5.9429497718811035|  0:00:10s\n","epoch 24 | loss: 0.63506 | val_0_mse: 2.5887999534606934|  0:00:10s\n","epoch 25 | loss: 0.59187 | val_0_mse: 2.6007800102233887|  0:00:11s\n","epoch 26 | loss: 0.596   | val_0_mse: 2.9626500606536865|  0:00:11s\n","epoch 27 | loss: 0.58239 | val_0_mse: 3.5117599964141846|  0:00:11s\n","epoch 28 | loss: 0.55721 | val_0_mse: 3.6068899631500244|  0:00:12s\n","epoch 29 | loss: 0.57375 | val_0_mse: 2.752929925918579|  0:00:12s\n","epoch 30 | loss: 0.56429 | val_0_mse: 2.566699981689453|  0:00:13s\n","epoch 31 | loss: 0.59216 | val_0_mse: 2.678950071334839|  0:00:13s\n","epoch 32 | loss: 0.57188 | val_0_mse: 1.7702300548553467|  0:00:14s\n","epoch 33 | loss: 0.57963 | val_0_mse: 1.6780099868774414|  0:00:14s\n","epoch 34 | loss: 0.57136 | val_0_mse: 1.6481200456619263|  0:00:14s\n","epoch 35 | loss: 0.57706 | val_0_mse: 1.1303999423980713|  0:00:15s\n","epoch 36 | loss: 0.57205 | val_0_mse: 1.411370038986206|  0:00:15s\n","epoch 37 | loss: 0.56463 | val_0_mse: 1.1783299446105957|  0:00:16s\n","epoch 38 | loss: 0.54645 | val_0_mse: 0.9594600200653076|  0:00:16s\n","epoch 39 | loss: 0.54424 | val_0_mse: 0.9006800055503845|  0:00:17s\n","epoch 40 | loss: 0.54176 | val_0_mse: 0.8581699728965759|  0:00:17s\n","epoch 41 | loss: 0.55553 | val_0_mse: 0.8577499985694885|  0:00:17s\n","epoch 42 | loss: 0.55313 | val_0_mse: 0.8968999981880188|  0:00:18s\n","epoch 43 | loss: 0.57132 | val_0_mse: 0.7665799856185913|  0:00:18s\n","epoch 44 | loss: 0.56163 | val_0_mse: 0.7062100172042847|  0:00:19s\n","epoch 45 | loss: 0.57322 | val_0_mse: 0.8779199719429016|  0:00:19s\n","epoch 46 | loss: 0.55282 | val_0_mse: 0.692330002784729|  0:00:20s\n","epoch 47 | loss: 0.55285 | val_0_mse: 0.6761000156402588|  0:00:20s\n","epoch 48 | loss: 0.53175 | val_0_mse: 0.7738500237464905|  0:00:21s\n","epoch 49 | loss: 0.5364  | val_0_mse: 0.7697399854660034|  0:00:21s\n","epoch 50 | loss: 0.53095 | val_0_mse: 0.8225499987602234|  0:00:21s\n","epoch 51 | loss: 0.53311 | val_0_mse: 0.7451800107955933|  0:00:22s\n","epoch 52 | loss: 0.53461 | val_0_mse: 0.6985200047492981|  0:00:22s\n","epoch 53 | loss: 0.52473 | val_0_mse: 0.6832699775695801|  0:00:23s\n","epoch 54 | loss: 0.52941 | val_0_mse: 0.7537199854850769|  0:00:23s\n","epoch 55 | loss: 0.54893 | val_0_mse: 0.7848799824714661|  0:00:23s\n","epoch 56 | loss: 0.53379 | val_0_mse: 0.7016900181770325|  0:00:24s\n","epoch 57 | loss: 0.55191 | val_0_mse: 0.7229599952697754|  0:00:24s\n","\n","Early stopping occurred at epoch 57 with best_epoch = 47 and best_val_0_mse = 0.6761000156402588\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 16:38:47,169] Trial 82 finished with value: 0.676095724105835 and parameters: {'n_d': 10, 'n_steps': 7, 'gamma': 1.2654103934161807, 'n_independent': 2, 'n_shared': 3, 'momentum': 0.03614865803468256}. Best is trial 55 with value: 0.5396906733512878.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 44.2435 | val_0_mse: 1315.554931640625|  0:00:00s\n","epoch 1  | loss: 10.71952| val_0_mse: 550.0953979492188|  0:00:01s\n","epoch 2  | loss: 4.8882  | val_0_mse: 335.7263488769531|  0:00:01s\n","epoch 3  | loss: 2.93431 | val_0_mse: 203.38841247558594|  0:00:02s\n","epoch 4  | loss: 1.75286 | val_0_mse: 73.86414337158203|  0:00:02s\n","epoch 5  | loss: 1.2563  | val_0_mse: 41.231571197509766|  0:00:03s\n","epoch 6  | loss: 0.977   | val_0_mse: 118.75792694091797|  0:00:03s\n","epoch 7  | loss: 0.82844 | val_0_mse: 38.98540115356445|  0:00:04s\n","epoch 8  | loss: 0.78838 | val_0_mse: 26.69732093811035|  0:00:04s\n","epoch 9  | loss: 0.75627 | val_0_mse: 31.520109176635742|  0:00:05s\n","epoch 10 | loss: 0.6735  | val_0_mse: 23.49272918701172|  0:00:05s\n","epoch 11 | loss: 0.70018 | val_0_mse: 5.544000148773193|  0:00:06s\n","epoch 12 | loss: 0.63143 | val_0_mse: 3.9142000675201416|  0:00:07s\n","epoch 13 | loss: 0.6128  | val_0_mse: 2.0488100051879883|  0:00:07s\n","epoch 14 | loss: 0.60697 | val_0_mse: 27.50653076171875|  0:00:08s\n","epoch 15 | loss: 0.59352 | val_0_mse: 23.62965965270996|  0:00:08s\n","epoch 16 | loss: 0.574   | val_0_mse: 28.782760620117188|  0:00:09s\n","epoch 17 | loss: 0.58686 | val_0_mse: 9.413809776306152|  0:00:09s\n","epoch 18 | loss: 0.58128 | val_0_mse: 10.770999908447266|  0:00:10s\n","epoch 19 | loss: 0.57145 | val_0_mse: 10.208020210266113|  0:00:10s\n","epoch 20 | loss: 0.57106 | val_0_mse: 6.175290107727051|  0:00:11s\n","epoch 21 | loss: 0.58185 | val_0_mse: 8.918290138244629|  0:00:11s\n","epoch 22 | loss: 0.56841 | val_0_mse: 8.347350120544434|  0:00:12s\n","epoch 23 | loss: 0.56335 | val_0_mse: 24.71409034729004|  0:00:12s\n","\n","Early stopping occurred at epoch 23 with best_epoch = 13 and best_val_0_mse = 2.0488100051879883\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 16:39:00,341] Trial 83 finished with value: 2.048807144165039 and parameters: {'n_d': 8, 'n_steps': 8, 'gamma': 1.053323089570555, 'n_independent': 3, 'n_shared': 3, 'momentum': 0.016775057072608013}. Best is trial 55 with value: 0.5396906733512878.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 39.4601 | val_0_mse: 1480.5430908203125|  0:00:00s\n","epoch 1  | loss: 8.70096 | val_0_mse: 283.3102111816406|  0:00:01s\n","epoch 2  | loss: 4.14352 | val_0_mse: 96.4661865234375|  0:00:01s\n","epoch 3  | loss: 2.20364 | val_0_mse: 224.121337890625|  0:00:02s\n","epoch 4  | loss: 1.7803  | val_0_mse: 178.58114624023438|  0:00:02s\n","epoch 5  | loss: 1.53237 | val_0_mse: 121.9593734741211|  0:00:03s\n","epoch 6  | loss: 1.35099 | val_0_mse: 20.70490074157715|  0:00:03s\n","epoch 7  | loss: 1.24292 | val_0_mse: 30.93906021118164|  0:00:04s\n","epoch 8  | loss: 1.85963 | val_0_mse: 29.547740936279297|  0:00:04s\n","epoch 9  | loss: 1.99083 | val_0_mse: 6.940249919891357|  0:00:05s\n","epoch 10 | loss: 2.82615 | val_0_mse: 15.373200416564941|  0:00:05s\n","epoch 11 | loss: 1.9656  | val_0_mse: 9.719849586486816|  0:00:06s\n","epoch 12 | loss: 1.21704 | val_0_mse: 6.032400131225586|  0:00:06s\n","epoch 13 | loss: 1.02816 | val_0_mse: 9.08508014678955|  0:00:07s\n","epoch 14 | loss: 0.88967 | val_0_mse: 15.070710182189941|  0:00:07s\n","epoch 15 | loss: 0.83103 | val_0_mse: 4.712560176849365|  0:00:08s\n","epoch 16 | loss: 0.85392 | val_0_mse: 4.703979969024658|  0:00:08s\n","epoch 17 | loss: 0.80394 | val_0_mse: 3.887779951095581|  0:00:09s\n","epoch 18 | loss: 0.77743 | val_0_mse: 2.550139904022217|  0:00:10s\n","epoch 19 | loss: 0.77927 | val_0_mse: 2.445080041885376|  0:00:10s\n","epoch 20 | loss: 0.73405 | val_0_mse: 2.9558000564575195|  0:00:11s\n","epoch 21 | loss: 0.72372 | val_0_mse: 3.1756300926208496|  0:00:11s\n","epoch 22 | loss: 0.7439  | val_0_mse: 1.8124500513076782|  0:00:12s\n","epoch 23 | loss: 0.72179 | val_0_mse: 2.675220012664795|  0:00:12s\n","epoch 24 | loss: 0.66439 | val_0_mse: 2.1386098861694336|  0:00:13s\n","epoch 25 | loss: 0.66778 | val_0_mse: 1.4448599815368652|  0:00:13s\n","epoch 26 | loss: 0.66136 | val_0_mse: 1.3760000467300415|  0:00:14s\n","epoch 27 | loss: 0.61399 | val_0_mse: 1.7562099695205688|  0:00:14s\n","epoch 28 | loss: 0.6216  | val_0_mse: 1.6494100093841553|  0:00:15s\n","epoch 29 | loss: 0.63474 | val_0_mse: 1.4872299432754517|  0:00:15s\n","epoch 30 | loss: 0.64085 | val_0_mse: 1.7553199529647827|  0:00:16s\n","epoch 31 | loss: 0.64352 | val_0_mse: 1.0428500175476074|  0:00:16s\n","epoch 32 | loss: 0.71146 | val_0_mse: 1.688789963722229|  0:00:17s\n","epoch 33 | loss: 0.81449 | val_0_mse: 0.9480800032615662|  0:00:17s\n","epoch 34 | loss: 0.66625 | val_0_mse: 1.5354399681091309|  0:00:18s\n","epoch 35 | loss: 0.74922 | val_0_mse: 0.7851099967956543|  0:00:18s\n","epoch 36 | loss: 0.70029 | val_0_mse: 0.8412100076675415|  0:00:19s\n","epoch 37 | loss: 0.69624 | val_0_mse: 1.0840100049972534|  0:00:19s\n","epoch 38 | loss: 0.63178 | val_0_mse: 0.8343899846076965|  0:00:20s\n","epoch 39 | loss: 0.64063 | val_0_mse: 1.0764800310134888|  0:00:20s\n","epoch 40 | loss: 0.6059  | val_0_mse: 1.1134400367736816|  0:00:21s\n","epoch 41 | loss: 0.60094 | val_0_mse: 1.0257699489593506|  0:00:21s\n","epoch 42 | loss: 0.59878 | val_0_mse: 1.078969955444336|  0:00:22s\n","epoch 43 | loss: 0.56482 | val_0_mse: 0.9812700152397156|  0:00:22s\n","epoch 44 | loss: 0.55366 | val_0_mse: 1.3019700050354004|  0:00:23s\n","epoch 45 | loss: 0.57026 | val_0_mse: 1.1390600204467773|  0:00:23s\n","\n","Early stopping occurred at epoch 45 with best_epoch = 35 and best_val_0_mse = 0.7851099967956543\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 16:39:24,623] Trial 84 finished with value: 0.7851119041442871 and parameters: {'n_d': 17, 'n_steps': 9, 'gamma': 1.1750442754888302, 'n_independent': 2, 'n_shared': 3, 'momentum': 0.05192477314525019}. Best is trial 55 with value: 0.5396906733512878.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 58.43035| val_0_mse: 141.92591857910156|  0:00:00s\n","epoch 1  | loss: 20.02769| val_0_mse: 203.3461456298828|  0:00:00s\n","epoch 2  | loss: 6.42459 | val_0_mse: 226.87254333496094|  0:00:01s\n","epoch 3  | loss: 4.32253 | val_0_mse: 163.97415161132812|  0:00:01s\n","epoch 4  | loss: 1.94961 | val_0_mse: 53.990760803222656|  0:00:02s\n","epoch 5  | loss: 1.51912 | val_0_mse: 63.456138610839844|  0:00:02s\n","epoch 6  | loss: 1.21428 | val_0_mse: 38.6656608581543|  0:00:02s\n","epoch 7  | loss: 0.98071 | val_0_mse: 11.696649551391602|  0:00:03s\n","epoch 8  | loss: 0.93676 | val_0_mse: 39.72637939453125|  0:00:03s\n","epoch 9  | loss: 0.98373 | val_0_mse: 15.371600151062012|  0:00:04s\n","epoch 10 | loss: 1.09284 | val_0_mse: 9.364729881286621|  0:00:04s\n","epoch 11 | loss: 0.80408 | val_0_mse: 12.447979927062988|  0:00:04s\n","epoch 12 | loss: 0.67799 | val_0_mse: 3.0819199085235596|  0:00:05s\n","epoch 13 | loss: 0.64352 | val_0_mse: 3.6823999881744385|  0:00:05s\n","epoch 14 | loss: 0.62132 | val_0_mse: 2.524139881134033|  0:00:06s\n","epoch 15 | loss: 0.61988 | val_0_mse: 2.347870111465454|  0:00:06s\n","epoch 16 | loss: 0.59943 | val_0_mse: 3.2869200706481934|  0:00:06s\n","epoch 17 | loss: 0.59061 | val_0_mse: 2.8868699073791504|  0:00:07s\n","epoch 18 | loss: 0.58654 | val_0_mse: 3.181220054626465|  0:00:07s\n","epoch 19 | loss: 0.56845 | val_0_mse: 3.0411999225616455|  0:00:08s\n","epoch 20 | loss: 0.57451 | val_0_mse: 2.6941699981689453|  0:00:08s\n","epoch 21 | loss: 0.54771 | val_0_mse: 2.9626100063323975|  0:00:08s\n","epoch 22 | loss: 0.56525 | val_0_mse: 2.9693799018859863|  0:00:09s\n","epoch 23 | loss: 0.5506  | val_0_mse: 3.3292500972747803|  0:00:09s\n","epoch 24 | loss: 0.54863 | val_0_mse: 2.2251999378204346|  0:00:10s\n","epoch 25 | loss: 0.56092 | val_0_mse: 2.3598599433898926|  0:00:10s\n","epoch 26 | loss: 0.54382 | val_0_mse: 1.792799949645996|  0:00:10s\n","epoch 27 | loss: 0.53732 | val_0_mse: 1.617550015449524|  0:00:11s\n","epoch 28 | loss: 0.54514 | val_0_mse: 1.8140499591827393|  0:00:11s\n","epoch 29 | loss: 0.54219 | val_0_mse: 1.7997100353240967|  0:00:12s\n","epoch 30 | loss: 0.53702 | val_0_mse: 1.123710036277771|  0:00:12s\n","epoch 31 | loss: 0.53582 | val_0_mse: 1.6320199966430664|  0:00:12s\n","epoch 32 | loss: 0.57994 | val_0_mse: 1.04721999168396|  0:00:13s\n","epoch 33 | loss: 0.56505 | val_0_mse: 2.0890700817108154|  0:00:13s\n","epoch 34 | loss: 0.53372 | val_0_mse: 1.5027400255203247|  0:00:14s\n","epoch 35 | loss: 0.50395 | val_0_mse: 1.5968799591064453|  0:00:14s\n","epoch 36 | loss: 0.51355 | val_0_mse: 1.739300012588501|  0:00:15s\n","epoch 37 | loss: 0.51711 | val_0_mse: 1.1103299856185913|  0:00:15s\n","epoch 38 | loss: 0.53139 | val_0_mse: 1.0628299713134766|  0:00:15s\n","epoch 39 | loss: 0.52538 | val_0_mse: 1.1714199781417847|  0:00:16s\n","epoch 40 | loss: 0.52182 | val_0_mse: 0.8690299987792969|  0:00:16s\n","epoch 41 | loss: 0.52851 | val_0_mse: 1.1741199493408203|  0:00:17s\n","epoch 42 | loss: 0.55199 | val_0_mse: 0.7739800214767456|  0:00:17s\n","epoch 43 | loss: 0.52673 | val_0_mse: 1.1082099676132202|  0:00:17s\n","epoch 44 | loss: 0.53068 | val_0_mse: 0.8294699788093567|  0:00:18s\n","epoch 45 | loss: 0.5117  | val_0_mse: 0.8556699752807617|  0:00:18s\n","epoch 46 | loss: 0.51214 | val_0_mse: 0.925059974193573|  0:00:19s\n","epoch 47 | loss: 0.5361  | val_0_mse: 0.7201600074768066|  0:00:19s\n","epoch 48 | loss: 0.49399 | val_0_mse: 0.8337000012397766|  0:00:19s\n","epoch 49 | loss: 0.50135 | val_0_mse: 0.782289981842041|  0:00:20s\n","epoch 50 | loss: 0.50331 | val_0_mse: 0.6362500190734863|  0:00:20s\n","epoch 51 | loss: 0.5089  | val_0_mse: 0.6571599841117859|  0:00:21s\n","epoch 52 | loss: 0.48608 | val_0_mse: 0.7160900235176086|  0:00:21s\n","epoch 53 | loss: 0.50063 | val_0_mse: 0.7480499744415283|  0:00:21s\n","epoch 54 | loss: 0.4968  | val_0_mse: 0.6830300092697144|  0:00:22s\n","epoch 55 | loss: 0.49741 | val_0_mse: 0.6482700109481812|  0:00:22s\n","epoch 56 | loss: 0.4807  | val_0_mse: 0.7256199717521667|  0:00:23s\n","epoch 57 | loss: 0.49612 | val_0_mse: 0.76323002576828|  0:00:23s\n","epoch 58 | loss: 0.48856 | val_0_mse: 0.654990017414093|  0:00:23s\n","epoch 59 | loss: 0.49532 | val_0_mse: 0.7094799876213074|  0:00:24s\n","epoch 60 | loss: 0.51925 | val_0_mse: 0.6529499888420105|  0:00:24s\n","\n","Early stopping occurred at epoch 60 with best_epoch = 50 and best_val_0_mse = 0.6362500190734863\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 16:39:49,700] Trial 85 finished with value: 0.6362478137016296 and parameters: {'n_d': 12, 'n_steps': 8, 'gamma': 1.0709621434270027, 'n_independent': 1, 'n_shared': 3, 'momentum': 0.01815113394062729}. Best is trial 55 with value: 0.5396906733512878.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 28.11102| val_0_mse: 3340.341552734375|  0:00:00s\n","epoch 1  | loss: 4.56599 | val_0_mse: 709.18994140625|  0:00:00s\n","epoch 2  | loss: 2.44255 | val_0_mse: 148.5735626220703|  0:00:01s\n","epoch 3  | loss: 1.66689 | val_0_mse: 132.54881286621094|  0:00:01s\n","epoch 4  | loss: 1.57952 | val_0_mse: 83.73645782470703|  0:00:02s\n","epoch 5  | loss: 1.1322  | val_0_mse: 57.262298583984375|  0:00:02s\n","epoch 6  | loss: 0.9533  | val_0_mse: 25.174230575561523|  0:00:03s\n","epoch 7  | loss: 0.90288 | val_0_mse: 40.062110900878906|  0:00:03s\n","epoch 8  | loss: 0.82555 | val_0_mse: 3.689189910888672|  0:00:04s\n","epoch 9  | loss: 0.75044 | val_0_mse: 20.520360946655273|  0:00:04s\n","epoch 10 | loss: 0.69413 | val_0_mse: 18.183399200439453|  0:00:05s\n","epoch 11 | loss: 0.73716 | val_0_mse: 21.349519729614258|  0:00:05s\n","epoch 12 | loss: 0.74365 | val_0_mse: 16.74056053161621|  0:00:06s\n","epoch 13 | loss: 0.63823 | val_0_mse: 6.367030143737793|  0:00:06s\n","epoch 14 | loss: 0.68087 | val_0_mse: 12.563119888305664|  0:00:07s\n","epoch 15 | loss: 0.64815 | val_0_mse: 5.573669910430908|  0:00:07s\n","epoch 16 | loss: 0.63151 | val_0_mse: 20.75596046447754|  0:00:08s\n","epoch 17 | loss: 0.62545 | val_0_mse: 2.764009952545166|  0:00:08s\n","epoch 18 | loss: 0.69445 | val_0_mse: 2.3730599880218506|  0:00:09s\n","epoch 19 | loss: 0.67476 | val_0_mse: 3.126840114593506|  0:00:09s\n","epoch 20 | loss: 0.64804 | val_0_mse: 2.5984699726104736|  0:00:10s\n","epoch 21 | loss: 0.62337 | val_0_mse: 1.5927000045776367|  0:00:10s\n","epoch 22 | loss: 0.5926  | val_0_mse: 3.264130115509033|  0:00:11s\n","epoch 23 | loss: 0.57429 | val_0_mse: 1.265030026435852|  0:00:11s\n","epoch 24 | loss: 0.56428 | val_0_mse: 1.428689956665039|  0:00:12s\n","epoch 25 | loss: 0.57845 | val_0_mse: 1.8890600204467773|  0:00:12s\n","epoch 26 | loss: 0.57836 | val_0_mse: 1.7183799743652344|  0:00:13s\n","epoch 27 | loss: 0.60497 | val_0_mse: 1.4365700483322144|  0:00:13s\n","epoch 28 | loss: 0.53704 | val_0_mse: 1.8042000532150269|  0:00:13s\n","epoch 29 | loss: 0.53226 | val_0_mse: 1.8642100095748901|  0:00:14s\n","epoch 30 | loss: 0.54006 | val_0_mse: 1.0694199800491333|  0:00:14s\n","epoch 31 | loss: 0.55058 | val_0_mse: 0.8916000127792358|  0:00:15s\n","epoch 32 | loss: 0.57663 | val_0_mse: 1.3673299551010132|  0:00:15s\n","epoch 33 | loss: 0.53532 | val_0_mse: 0.9018200039863586|  0:00:16s\n","epoch 34 | loss: 0.55465 | val_0_mse: 1.868399977684021|  0:00:16s\n","epoch 35 | loss: 0.56502 | val_0_mse: 0.929610013961792|  0:00:17s\n","epoch 36 | loss: 0.52845 | val_0_mse: 1.0947699546813965|  0:00:17s\n","epoch 37 | loss: 0.51089 | val_0_mse: 1.2286499738693237|  0:00:18s\n","epoch 38 | loss: 0.51391 | val_0_mse: 1.235260009765625|  0:00:18s\n","epoch 39 | loss: 0.51591 | val_0_mse: 0.9610300064086914|  0:00:19s\n","epoch 40 | loss: 0.51432 | val_0_mse: 0.9342700242996216|  0:00:19s\n","epoch 41 | loss: 0.52314 | val_0_mse: 1.236649990081787|  0:00:20s\n","\n","Early stopping occurred at epoch 41 with best_epoch = 31 and best_val_0_mse = 0.8916000127792358\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 16:40:10,072] Trial 86 finished with value: 0.8915989398956299 and parameters: {'n_d': 28, 'n_steps': 7, 'gamma': 1.0888452887516928, 'n_independent': 2, 'n_shared': 4, 'momentum': 0.2127272058346072}. Best is trial 55 with value: 0.5396906733512878.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 55.08341| val_0_mse: 2598.182373046875|  0:00:00s\n","epoch 1  | loss: 7.83578 | val_0_mse: 368.4645080566406|  0:00:01s\n","epoch 2  | loss: 3.29682 | val_0_mse: 511.9895324707031|  0:00:01s\n","epoch 3  | loss: 2.08667 | val_0_mse: 236.29434204101562|  0:00:02s\n","epoch 4  | loss: 1.50876 | val_0_mse: 338.6103515625|  0:00:03s\n","epoch 5  | loss: 1.28401 | val_0_mse: 97.92562866210938|  0:00:03s\n","epoch 6  | loss: 1.22285 | val_0_mse: 69.48091888427734|  0:00:04s\n","epoch 7  | loss: 1.27862 | val_0_mse: 18.717369079589844|  0:00:04s\n","epoch 8  | loss: 1.09275 | val_0_mse: 24.69944953918457|  0:00:05s\n","epoch 9  | loss: 1.06174 | val_0_mse: 20.519479751586914|  0:00:06s\n","epoch 10 | loss: 0.9743  | val_0_mse: 45.79214859008789|  0:00:06s\n","epoch 11 | loss: 0.91132 | val_0_mse: 6.57459020614624|  0:00:07s\n","epoch 12 | loss: 1.12425 | val_0_mse: 55.28329086303711|  0:00:07s\n","epoch 13 | loss: 0.85422 | val_0_mse: 25.328340530395508|  0:00:08s\n","epoch 14 | loss: 0.73542 | val_0_mse: 3.5725300312042236|  0:00:09s\n","epoch 15 | loss: 0.6739  | val_0_mse: 3.444770097732544|  0:00:09s\n","epoch 16 | loss: 0.70115 | val_0_mse: 2.230259895324707|  0:00:10s\n","epoch 17 | loss: 0.66985 | val_0_mse: 2.343100070953369|  0:00:10s\n","epoch 18 | loss: 0.64812 | val_0_mse: 1.701490044593811|  0:00:11s\n","epoch 19 | loss: 0.82513 | val_0_mse: 3.1150600910186768|  0:00:12s\n","epoch 20 | loss: 0.91526 | val_0_mse: 3.0366599559783936|  0:00:12s\n","epoch 21 | loss: 0.70078 | val_0_mse: 1.6373800039291382|  0:00:13s\n","epoch 22 | loss: 0.78966 | val_0_mse: 2.9168100357055664|  0:00:13s\n","epoch 23 | loss: 0.76853 | val_0_mse: 1.4245200157165527|  0:00:14s\n","epoch 24 | loss: 0.65621 | val_0_mse: 1.8425099849700928|  0:00:15s\n","epoch 25 | loss: 0.58911 | val_0_mse: 1.8540699481964111|  0:00:15s\n","epoch 26 | loss: 0.5785  | val_0_mse: 1.258489966392517|  0:00:16s\n","epoch 27 | loss: 0.55504 | val_0_mse: 1.3734500408172607|  0:00:16s\n","epoch 28 | loss: 0.60614 | val_0_mse: 1.9065300226211548|  0:00:17s\n","epoch 29 | loss: 0.56829 | val_0_mse: 2.305799961090088|  0:00:17s\n","epoch 30 | loss: 0.55086 | val_0_mse: 1.992650032043457|  0:00:18s\n","epoch 31 | loss: 0.56827 | val_0_mse: 1.4854899644851685|  0:00:19s\n","epoch 32 | loss: 0.55503 | val_0_mse: 1.6500999927520752|  0:00:19s\n","epoch 33 | loss: 0.58254 | val_0_mse: 1.586959958076477|  0:00:20s\n","epoch 34 | loss: 0.56833 | val_0_mse: 0.7752199769020081|  0:00:20s\n","epoch 35 | loss: 0.58804 | val_0_mse: 1.2549699544906616|  0:00:21s\n","epoch 36 | loss: 0.56301 | val_0_mse: 1.2432899475097656|  0:00:22s\n","epoch 37 | loss: 0.58032 | val_0_mse: 1.2684500217437744|  0:00:22s\n","epoch 38 | loss: 0.58343 | val_0_mse: 1.1142699718475342|  0:00:23s\n","epoch 39 | loss: 0.56419 | val_0_mse: 1.2268799543380737|  0:00:23s\n","epoch 40 | loss: 0.561   | val_0_mse: 1.1185599565505981|  0:00:24s\n","epoch 41 | loss: 0.56967 | val_0_mse: 1.1559799909591675|  0:00:24s\n","epoch 42 | loss: 0.56208 | val_0_mse: 1.1513299942016602|  0:00:25s\n","epoch 43 | loss: 0.56917 | val_0_mse: 0.8805099725723267|  0:00:26s\n","epoch 44 | loss: 0.54399 | val_0_mse: 0.8992699980735779|  0:00:26s\n","\n","Early stopping occurred at epoch 44 with best_epoch = 34 and best_val_0_mse = 0.7752199769020081\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 16:40:37,132] Trial 87 finished with value: 0.7752165198326111 and parameters: {'n_d': 22, 'n_steps': 9, 'gamma': 1.1478447441866475, 'n_independent': 3, 'n_shared': 3, 'momentum': 0.24365070989926388}. Best is trial 55 with value: 0.5396906733512878.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 26.41626| val_0_mse: 2690.8701171875|  0:00:00s\n","epoch 1  | loss: 8.17327 | val_0_mse: 187.77340698242188|  0:00:01s\n","epoch 2  | loss: 5.52452 | val_0_mse: 435.9350280761719|  0:00:01s\n","epoch 3  | loss: 4.45704 | val_0_mse: 67.61190032958984|  0:00:02s\n","epoch 4  | loss: 3.37847 | val_0_mse: 123.36392974853516|  0:00:02s\n","epoch 5  | loss: 1.75307 | val_0_mse: 186.7476806640625|  0:00:03s\n","epoch 6  | loss: 1.90014 | val_0_mse: 90.07087707519531|  0:00:04s\n","epoch 7  | loss: 2.05326 | val_0_mse: 66.70523834228516|  0:00:04s\n","epoch 8  | loss: 2.03409 | val_0_mse: 32.91883850097656|  0:00:05s\n","epoch 9  | loss: 1.56353 | val_0_mse: 24.718469619750977|  0:00:06s\n","epoch 10 | loss: 1.15193 | val_0_mse: 16.514530181884766|  0:00:06s\n","epoch 11 | loss: 1.10284 | val_0_mse: 14.67743968963623|  0:00:07s\n","epoch 12 | loss: 0.79851 | val_0_mse: 2.559119939804077|  0:00:07s\n","epoch 13 | loss: 0.90896 | val_0_mse: 6.905360221862793|  0:00:08s\n","epoch 14 | loss: 0.97761 | val_0_mse: 5.458000183105469|  0:00:09s\n","epoch 15 | loss: 0.95639 | val_0_mse: 1.7947299480438232|  0:00:09s\n","epoch 16 | loss: 0.91739 | val_0_mse: 8.0770902633667|  0:00:10s\n","epoch 17 | loss: 0.69379 | val_0_mse: 5.878990173339844|  0:00:10s\n","epoch 18 | loss: 0.64495 | val_0_mse: 6.699619770050049|  0:00:11s\n","epoch 19 | loss: 0.67788 | val_0_mse: 1.0266400575637817|  0:00:12s\n","epoch 20 | loss: 0.78454 | val_0_mse: 1.6047799587249756|  0:00:12s\n","epoch 21 | loss: 0.73304 | val_0_mse: 2.5701799392700195|  0:00:13s\n","epoch 22 | loss: 1.0783  | val_0_mse: 1.2087899446487427|  0:00:13s\n","epoch 23 | loss: 1.17105 | val_0_mse: 1.2695800065994263|  0:00:14s\n","epoch 24 | loss: 1.01162 | val_0_mse: 2.6059699058532715|  0:00:14s\n","epoch 25 | loss: 0.71711 | val_0_mse: 1.0558700561523438|  0:00:15s\n","epoch 26 | loss: 0.76268 | val_0_mse: 5.003870010375977|  0:00:16s\n","epoch 27 | loss: 0.74409 | val_0_mse: 2.280829906463623|  0:00:16s\n","epoch 28 | loss: 0.76567 | val_0_mse: 1.1632100343704224|  0:00:17s\n","epoch 29 | loss: 0.71307 | val_0_mse: 1.666509985923767|  0:00:17s\n","\n","Early stopping occurred at epoch 29 with best_epoch = 19 and best_val_0_mse = 1.0266400575637817\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 16:40:55,343] Trial 88 finished with value: 1.0266414880752563 and parameters: {'n_d': 62, 'n_steps': 9, 'gamma': 1.0100495509289305, 'n_independent': 4, 'n_shared': 2, 'momentum': 0.11961661106906549}. Best is trial 55 with value: 0.5396906733512878.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 19.59689| val_0_mse: 11095.80078125|  0:00:00s\n","epoch 1  | loss: 6.42227 | val_0_mse: 3496.754638671875|  0:00:01s\n","epoch 2  | loss: 3.12081 | val_0_mse: 511.2706298828125|  0:00:02s\n","epoch 3  | loss: 1.77892 | val_0_mse: 257.7085876464844|  0:00:02s\n","epoch 4  | loss: 1.2573  | val_0_mse: 112.43653869628906|  0:00:03s\n","epoch 5  | loss: 1.02303 | val_0_mse: 133.86041259765625|  0:00:04s\n","epoch 6  | loss: 0.95522 | val_0_mse: 72.37870025634766|  0:00:04s\n","epoch 7  | loss: 0.79055 | val_0_mse: 20.666000366210938|  0:00:05s\n","epoch 8  | loss: 0.74255 | val_0_mse: 43.56364059448242|  0:00:06s\n","epoch 9  | loss: 0.68567 | val_0_mse: 38.322509765625|  0:00:06s\n","epoch 10 | loss: 0.71258 | val_0_mse: 53.21184158325195|  0:00:07s\n","epoch 11 | loss: 0.70845 | val_0_mse: 31.464139938354492|  0:00:08s\n","epoch 12 | loss: 0.65042 | val_0_mse: 5.725220203399658|  0:00:08s\n","epoch 13 | loss: 0.66877 | val_0_mse: 3.2876698970794678|  0:00:09s\n","epoch 14 | loss: 0.67979 | val_0_mse: 15.912460327148438|  0:00:10s\n","epoch 15 | loss: 0.75055 | val_0_mse: 10.034549713134766|  0:00:10s\n","epoch 16 | loss: 0.69033 | val_0_mse: 23.138059616088867|  0:00:11s\n","epoch 17 | loss: 0.59294 | val_0_mse: 11.858960151672363|  0:00:11s\n","epoch 18 | loss: 0.60479 | val_0_mse: 10.659520149230957|  0:00:12s\n","epoch 19 | loss: 0.58892 | val_0_mse: 6.344130039215088|  0:00:13s\n","epoch 20 | loss: 0.62364 | val_0_mse: 6.993959903717041|  0:00:13s\n","epoch 21 | loss: 0.60061 | val_0_mse: 4.862120151519775|  0:00:14s\n","epoch 22 | loss: 0.56858 | val_0_mse: 2.864039897918701|  0:00:15s\n","epoch 23 | loss: 0.56658 | val_0_mse: 3.534320116043091|  0:00:15s\n","epoch 24 | loss: 0.5581  | val_0_mse: 2.4000799655914307|  0:00:16s\n","epoch 25 | loss: 0.56728 | val_0_mse: 1.9373799562454224|  0:00:17s\n","epoch 26 | loss: 0.52498 | val_0_mse: 1.9572800397872925|  0:00:17s\n","epoch 27 | loss: 0.55325 | val_0_mse: 2.9932000637054443|  0:00:18s\n","epoch 28 | loss: 0.60985 | val_0_mse: 1.7581100463867188|  0:00:19s\n","epoch 29 | loss: 0.56504 | val_0_mse: 1.2796000242233276|  0:00:20s\n","epoch 30 | loss: 0.55319 | val_0_mse: 1.9296799898147583|  0:00:20s\n","epoch 31 | loss: 0.55317 | val_0_mse: 1.0525200366973877|  0:00:21s\n","epoch 32 | loss: 0.52838 | val_0_mse: 0.9368900060653687|  0:00:22s\n","epoch 33 | loss: 0.54115 | val_0_mse: 1.6366900205612183|  0:00:22s\n","epoch 34 | loss: 0.54567 | val_0_mse: 1.337399959564209|  0:00:23s\n","epoch 35 | loss: 0.54715 | val_0_mse: 0.966949999332428|  0:00:24s\n","epoch 36 | loss: 0.5552  | val_0_mse: 1.2368299961090088|  0:00:24s\n","epoch 37 | loss: 0.52929 | val_0_mse: 1.3296300172805786|  0:00:25s\n","epoch 38 | loss: 0.52493 | val_0_mse: 0.9337499737739563|  0:00:26s\n","epoch 39 | loss: 0.57214 | val_0_mse: 1.4615399837493896|  0:00:26s\n","epoch 40 | loss: 0.54702 | val_0_mse: 0.9169999957084656|  0:00:27s\n","epoch 41 | loss: 0.50406 | val_0_mse: 0.9860900044441223|  0:00:28s\n","epoch 42 | loss: 0.52184 | val_0_mse: 0.8676400184631348|  0:00:28s\n","epoch 43 | loss: 0.50866 | val_0_mse: 0.9966899752616882|  0:00:29s\n","epoch 44 | loss: 0.51795 | val_0_mse: 0.8997700214385986|  0:00:29s\n","epoch 45 | loss: 0.52434 | val_0_mse: 1.052109956741333|  0:00:30s\n","epoch 46 | loss: 0.54141 | val_0_mse: 0.889710009098053|  0:00:31s\n","epoch 47 | loss: 0.53693 | val_0_mse: 0.7769799828529358|  0:00:31s\n","epoch 48 | loss: 0.52384 | val_0_mse: 0.7683600187301636|  0:00:32s\n","epoch 49 | loss: 0.51341 | val_0_mse: 0.8949800133705139|  0:00:33s\n","epoch 50 | loss: 0.50116 | val_0_mse: 0.798229992389679|  0:00:33s\n","epoch 51 | loss: 0.50944 | val_0_mse: 0.8351600170135498|  0:00:34s\n","epoch 52 | loss: 0.52609 | val_0_mse: 0.6411299705505371|  0:00:35s\n","epoch 53 | loss: 0.51463 | val_0_mse: 0.6977900266647339|  0:00:35s\n","epoch 54 | loss: 0.48919 | val_0_mse: 0.7200199961662292|  0:00:36s\n","epoch 55 | loss: 0.5099  | val_0_mse: 0.756630003452301|  0:00:37s\n","epoch 56 | loss: 0.50609 | val_0_mse: 0.6922100186347961|  0:00:37s\n","epoch 57 | loss: 0.51539 | val_0_mse: 0.7247300148010254|  0:00:38s\n","epoch 58 | loss: 0.51115 | val_0_mse: 0.7128300070762634|  0:00:39s\n","epoch 59 | loss: 0.50343 | val_0_mse: 0.7738999724388123|  0:00:39s\n","epoch 60 | loss: 0.50917 | val_0_mse: 0.6710000038146973|  0:00:40s\n","epoch 61 | loss: 0.50548 | val_0_mse: 0.6000800132751465|  0:00:41s\n","epoch 62 | loss: 0.49492 | val_0_mse: 0.6416299939155579|  0:00:41s\n","epoch 63 | loss: 0.51276 | val_0_mse: 0.713949978351593|  0:00:42s\n","epoch 64 | loss: 0.54162 | val_0_mse: 0.6550999879837036|  0:00:43s\n","epoch 65 | loss: 0.54496 | val_0_mse: 0.6931399703025818|  0:00:43s\n","epoch 66 | loss: 0.52574 | val_0_mse: 0.6312299966812134|  0:00:44s\n","epoch 67 | loss: 0.50969 | val_0_mse: 0.6006399989128113|  0:00:45s\n","epoch 68 | loss: 0.54957 | val_0_mse: 0.7239300012588501|  0:00:45s\n","epoch 69 | loss: 0.54617 | val_0_mse: 0.6393799781799316|  0:00:46s\n","epoch 70 | loss: 0.57743 | val_0_mse: 0.6454600095748901|  0:00:46s\n","epoch 71 | loss: 0.52857 | val_0_mse: 0.597000002861023|  0:00:47s\n","epoch 72 | loss: 0.51849 | val_0_mse: 0.7759699821472168|  0:00:48s\n","epoch 73 | loss: 0.49254 | val_0_mse: 0.635450005531311|  0:00:49s\n","epoch 74 | loss: 0.50028 | val_0_mse: 0.6014999747276306|  0:00:49s\n","epoch 75 | loss: 0.5042  | val_0_mse: 0.6977199912071228|  0:00:50s\n","epoch 76 | loss: 0.5159  | val_0_mse: 0.602940022945404|  0:00:50s\n","epoch 77 | loss: 0.48576 | val_0_mse: 0.6263599991798401|  0:00:51s\n","epoch 78 | loss: 0.49722 | val_0_mse: 0.6235499978065491|  0:00:52s\n","epoch 79 | loss: 0.47209 | val_0_mse: 0.6190099716186523|  0:00:52s\n","epoch 80 | loss: 0.49163 | val_0_mse: 0.6288300156593323|  0:00:53s\n","epoch 81 | loss: 0.48964 | val_0_mse: 0.6450499892234802|  0:00:54s\n","\n","Early stopping occurred at epoch 81 with best_epoch = 71 and best_val_0_mse = 0.597000002861023\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 16:41:49,899] Trial 89 finished with value: 0.5970020890235901 and parameters: {'n_d': 18, 'n_steps': 8, 'gamma': 1.0441780594369172, 'n_independent': 3, 'n_shared': 5, 'momentum': 0.04054596838580798}. Best is trial 55 with value: 0.5396906733512878.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 61.63855| val_0_mse: 745.4699096679688|  0:00:00s\n","epoch 1  | loss: 18.72279| val_0_mse: 8061.521484375|  0:00:01s\n","epoch 2  | loss: 8.40885 | val_0_mse: 373.33123779296875|  0:00:02s\n","epoch 3  | loss: 4.43793 | val_0_mse: 246.46087646484375|  0:00:02s\n","epoch 4  | loss: 2.66341 | val_0_mse: 90.10636901855469|  0:00:03s\n","epoch 5  | loss: 2.14213 | val_0_mse: 44.91957092285156|  0:00:04s\n","epoch 6  | loss: 1.67659 | val_0_mse: 53.2458610534668|  0:00:04s\n","epoch 7  | loss: 1.24899 | val_0_mse: 54.518409729003906|  0:00:05s\n","epoch 8  | loss: 1.14064 | val_0_mse: 17.173809051513672|  0:00:06s\n","epoch 9  | loss: 0.96874 | val_0_mse: 8.977310180664062|  0:00:06s\n","epoch 10 | loss: 1.06428 | val_0_mse: 8.413249969482422|  0:00:07s\n","epoch 11 | loss: 1.11833 | val_0_mse: 5.879260063171387|  0:00:08s\n","epoch 12 | loss: 1.44804 | val_0_mse: 5.632130146026611|  0:00:08s\n","epoch 13 | loss: 0.86106 | val_0_mse: 2.342439889907837|  0:00:09s\n","epoch 14 | loss: 1.11431 | val_0_mse: 2.9009299278259277|  0:00:09s\n","epoch 15 | loss: 1.52851 | val_0_mse: 3.597249984741211|  0:00:10s\n","epoch 16 | loss: 0.83373 | val_0_mse: 3.4102001190185547|  0:00:11s\n","epoch 17 | loss: 0.8821  | val_0_mse: 1.5575000047683716|  0:00:11s\n","epoch 18 | loss: 0.79019 | val_0_mse: 1.9950599670410156|  0:00:12s\n","epoch 19 | loss: 0.73532 | val_0_mse: 2.462290048599243|  0:00:13s\n","epoch 20 | loss: 0.70023 | val_0_mse: 1.6321899890899658|  0:00:13s\n","epoch 21 | loss: 0.69935 | val_0_mse: 1.437600016593933|  0:00:14s\n","epoch 22 | loss: 0.70159 | val_0_mse: 1.2265000343322754|  0:00:15s\n","epoch 23 | loss: 0.70023 | val_0_mse: 1.8414299488067627|  0:00:15s\n","epoch 24 | loss: 0.71279 | val_0_mse: 1.2702200412750244|  0:00:16s\n","epoch 25 | loss: 0.65363 | val_0_mse: 0.9905099868774414|  0:00:17s\n","epoch 26 | loss: 0.66264 | val_0_mse: 0.858680009841919|  0:00:17s\n","epoch 27 | loss: 0.76106 | val_0_mse: 1.4948099851608276|  0:00:18s\n","epoch 28 | loss: 0.82354 | val_0_mse: 1.2687400579452515|  0:00:19s\n","epoch 29 | loss: 0.81017 | val_0_mse: 1.8184499740600586|  0:00:19s\n","epoch 30 | loss: 0.67043 | val_0_mse: 1.6601500511169434|  0:00:20s\n","epoch 31 | loss: 0.68297 | val_0_mse: 1.19582998752594|  0:00:20s\n","epoch 32 | loss: 0.64819 | val_0_mse: 0.9320099949836731|  0:00:21s\n","epoch 33 | loss: 0.75796 | val_0_mse: 1.2490099668502808|  0:00:22s\n","epoch 34 | loss: 0.65677 | val_0_mse: 1.4249399900436401|  0:00:22s\n","epoch 35 | loss: 0.63534 | val_0_mse: 0.999239981174469|  0:00:23s\n","epoch 36 | loss: 0.6508  | val_0_mse: 0.7925099730491638|  0:00:24s\n","epoch 37 | loss: 0.61998 | val_0_mse: 0.7960900068283081|  0:00:24s\n","epoch 38 | loss: 0.5948  | val_0_mse: 0.7702699899673462|  0:00:25s\n","epoch 39 | loss: 0.60747 | val_0_mse: 0.8999699950218201|  0:00:26s\n","epoch 40 | loss: 0.6519  | val_0_mse: 0.7986299991607666|  0:00:26s\n","epoch 41 | loss: 0.6191  | val_0_mse: 0.8253700137138367|  0:00:27s\n","epoch 42 | loss: 0.61561 | val_0_mse: 0.9119499921798706|  0:00:27s\n","epoch 43 | loss: 0.58678 | val_0_mse: 0.8834900259971619|  0:00:28s\n","epoch 44 | loss: 0.58898 | val_0_mse: 0.949400007724762|  0:00:29s\n","epoch 45 | loss: 0.59431 | val_0_mse: 0.8616600036621094|  0:00:29s\n","epoch 46 | loss: 0.6037  | val_0_mse: 0.7195299863815308|  0:00:30s\n","epoch 47 | loss: 0.65563 | val_0_mse: 1.3942699432373047|  0:00:31s\n","epoch 48 | loss: 0.8146  | val_0_mse: 0.7960100173950195|  0:00:31s\n","epoch 49 | loss: 0.66186 | val_0_mse: 0.9579899907112122|  0:00:32s\n","epoch 50 | loss: 0.67048 | val_0_mse: 0.6832299828529358|  0:00:33s\n","epoch 51 | loss: 0.82843 | val_0_mse: 0.7374399900436401|  0:00:33s\n","epoch 52 | loss: 0.71783 | val_0_mse: 0.8661199808120728|  0:00:34s\n","epoch 53 | loss: 0.63595 | val_0_mse: 0.7270699739456177|  0:00:35s\n","epoch 54 | loss: 0.6173  | val_0_mse: 0.8208000063896179|  0:00:35s\n","epoch 55 | loss: 0.60108 | val_0_mse: 0.7576000094413757|  0:00:36s\n","epoch 56 | loss: 0.69375 | val_0_mse: 0.9600800275802612|  0:00:36s\n","epoch 57 | loss: 0.72437 | val_0_mse: 0.737309992313385|  0:00:37s\n","epoch 58 | loss: 0.65961 | val_0_mse: 0.7921500205993652|  0:00:38s\n","epoch 59 | loss: 0.67535 | val_0_mse: 0.809939980506897|  0:00:38s\n","epoch 60 | loss: 0.68851 | val_0_mse: 0.7289299964904785|  0:00:39s\n","\n","Early stopping occurred at epoch 60 with best_epoch = 50 and best_val_0_mse = 0.6832299828529358\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 16:42:29,945] Trial 90 finished with value: 0.683230996131897 and parameters: {'n_d': 14, 'n_steps': 10, 'gamma': 1.6819153185182307, 'n_independent': 2, 'n_shared': 4, 'momentum': 0.10395264736906412}. Best is trial 55 with value: 0.5396906733512878.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 14.55617| val_0_mse: 3097.4775390625|  0:00:00s\n","epoch 1  | loss: 7.6271  | val_0_mse: 3044.946533203125|  0:00:01s\n","epoch 2  | loss: 5.37293 | val_0_mse: 599.0435791015625|  0:00:02s\n","epoch 3  | loss: 3.64593 | val_0_mse: 96.68891906738281|  0:00:03s\n","epoch 4  | loss: 3.60828 | val_0_mse: 106.45197296142578|  0:00:04s\n","epoch 5  | loss: 3.62011 | val_0_mse: 55.27933883666992|  0:00:04s\n","epoch 6  | loss: 2.25051 | val_0_mse: 76.79773712158203|  0:00:05s\n","epoch 7  | loss: 1.77214 | val_0_mse: 266.33551025390625|  0:00:06s\n","epoch 8  | loss: 1.41677 | val_0_mse: 612.8471069335938|  0:00:07s\n","epoch 9  | loss: 1.66919 | val_0_mse: 22.91629981994629|  0:00:08s\n","epoch 10 | loss: 3.26495 | val_0_mse: 78.69930267333984|  0:00:08s\n","epoch 11 | loss: 2.53492 | val_0_mse: 24.514680862426758|  0:00:09s\n","epoch 12 | loss: 2.1301  | val_0_mse: 64.49366760253906|  0:00:10s\n","epoch 13 | loss: 1.72167 | val_0_mse: 11.649239540100098|  0:00:11s\n","epoch 14 | loss: 1.18854 | val_0_mse: 26.963220596313477|  0:00:12s\n","epoch 15 | loss: 1.09962 | val_0_mse: 115.0636215209961|  0:00:13s\n","epoch 16 | loss: 1.44672 | val_0_mse: 21.147769927978516|  0:00:13s\n","epoch 17 | loss: 0.93219 | val_0_mse: 2.7703299522399902|  0:00:14s\n","epoch 18 | loss: 1.00812 | val_0_mse: 6.805449962615967|  0:00:15s\n","epoch 19 | loss: 1.32754 | val_0_mse: 9.4591703414917|  0:00:16s\n","epoch 20 | loss: 1.47445 | val_0_mse: 3.3457601070404053|  0:00:17s\n","epoch 21 | loss: 1.154   | val_0_mse: 5.84807014465332|  0:00:17s\n","epoch 22 | loss: 0.78943 | val_0_mse: 1.2640600204467773|  0:00:18s\n","epoch 23 | loss: 0.68874 | val_0_mse: 5.460780143737793|  0:00:19s\n","epoch 24 | loss: 0.75448 | val_0_mse: 1.9251799583435059|  0:00:20s\n","epoch 25 | loss: 0.87784 | val_0_mse: 3.933799982070923|  0:00:20s\n","epoch 26 | loss: 0.65919 | val_0_mse: 9.828590393066406|  0:00:21s\n","epoch 27 | loss: 0.64917 | val_0_mse: 2.0599400997161865|  0:00:22s\n","epoch 28 | loss: 0.68228 | val_0_mse: 5.516349792480469|  0:00:23s\n","epoch 29 | loss: 0.74821 | val_0_mse: 4.888360023498535|  0:00:24s\n","epoch 30 | loss: 0.63426 | val_0_mse: 1.350640058517456|  0:00:25s\n","epoch 31 | loss: 0.59022 | val_0_mse: 1.3672200441360474|  0:00:25s\n","epoch 32 | loss: 0.56716 | val_0_mse: 1.9847999811172485|  0:00:26s\n","\n","Early stopping occurred at epoch 32 with best_epoch = 22 and best_val_0_mse = 1.2640600204467773\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 16:42:57,069] Trial 91 finished with value: 1.2640595436096191 and parameters: {'n_d': 46, 'n_steps': 10, 'gamma': 1.114570208617932, 'n_independent': 5, 'n_shared': 3, 'momentum': 0.04909246896761965}. Best is trial 55 with value: 0.5396906733512878.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 12.54706| val_0_mse: 2843.56298828125|  0:00:00s\n","epoch 1  | loss: 5.66665 | val_0_mse: 548.9027709960938|  0:00:01s\n","epoch 2  | loss: 3.76809 | val_0_mse: 428.07232666015625|  0:00:02s\n","epoch 3  | loss: 2.62645 | val_0_mse: 255.6758270263672|  0:00:03s\n","epoch 4  | loss: 2.78332 | val_0_mse: 242.52647399902344|  0:00:04s\n","epoch 5  | loss: 3.25751 | val_0_mse: 143.68084716796875|  0:00:05s\n","epoch 6  | loss: 2.28921 | val_0_mse: 44.692848205566406|  0:00:05s\n","epoch 7  | loss: 1.66041 | val_0_mse: 14.331769943237305|  0:00:06s\n","epoch 8  | loss: 1.39876 | val_0_mse: 25.10502052307129|  0:00:07s\n","epoch 9  | loss: 1.65625 | val_0_mse: 16.406869888305664|  0:00:08s\n","epoch 10 | loss: 1.71636 | val_0_mse: 5.029230117797852|  0:00:09s\n","epoch 11 | loss: 1.20786 | val_0_mse: 42.94327926635742|  0:00:10s\n","epoch 12 | loss: 1.53295 | val_0_mse: 7.60584020614624|  0:00:10s\n","epoch 13 | loss: 1.29259 | val_0_mse: 8.776800155639648|  0:00:11s\n","epoch 14 | loss: 0.96481 | val_0_mse: 38.41556930541992|  0:00:12s\n","epoch 15 | loss: 1.03634 | val_0_mse: 11.127180099487305|  0:00:13s\n","epoch 16 | loss: 1.01383 | val_0_mse: 6.80226993560791|  0:00:14s\n","epoch 17 | loss: 0.78658 | val_0_mse: 15.303239822387695|  0:00:14s\n","epoch 18 | loss: 0.74839 | val_0_mse: 3.98934006690979|  0:00:15s\n","epoch 19 | loss: 0.65804 | val_0_mse: 14.041780471801758|  0:00:16s\n","epoch 20 | loss: 0.67687 | val_0_mse: 3.88988995552063|  0:00:17s\n","epoch 21 | loss: 0.69681 | val_0_mse: 1.9082800149917603|  0:00:18s\n","epoch 22 | loss: 0.73612 | val_0_mse: 1.7693099975585938|  0:00:18s\n","epoch 23 | loss: 0.68347 | val_0_mse: 2.264940023422241|  0:00:19s\n","epoch 24 | loss: 0.63542 | val_0_mse: 2.7476699352264404|  0:00:20s\n","epoch 25 | loss: 0.7396  | val_0_mse: 2.085629940032959|  0:00:21s\n","epoch 26 | loss: 0.66382 | val_0_mse: 1.5210700035095215|  0:00:22s\n","epoch 27 | loss: 0.6811  | val_0_mse: 2.3336799144744873|  0:00:23s\n","epoch 28 | loss: 0.67766 | val_0_mse: 2.2276499271392822|  0:00:23s\n","epoch 29 | loss: 0.68244 | val_0_mse: 2.1270699501037598|  0:00:24s\n","epoch 30 | loss: 0.57848 | val_0_mse: 1.6227799654006958|  0:00:25s\n","epoch 31 | loss: 0.58555 | val_0_mse: 1.546049952507019|  0:00:26s\n","epoch 32 | loss: 0.55903 | val_0_mse: 2.1643900871276855|  0:00:26s\n","epoch 33 | loss: 0.62809 | val_0_mse: 1.0865600109100342|  0:00:27s\n","epoch 34 | loss: 0.63058 | val_0_mse: 1.809939980506897|  0:00:28s\n","epoch 35 | loss: 0.60698 | val_0_mse: 1.503290057182312|  0:00:29s\n","epoch 36 | loss: 0.68792 | val_0_mse: 0.9157400131225586|  0:00:30s\n","epoch 37 | loss: 0.63839 | val_0_mse: 0.7765899896621704|  0:00:31s\n","epoch 38 | loss: 0.6167  | val_0_mse: 0.8081200122833252|  0:00:32s\n","epoch 39 | loss: 0.68885 | val_0_mse: 1.9084500074386597|  0:00:32s\n","epoch 40 | loss: 0.59714 | val_0_mse: 1.1237000226974487|  0:00:33s\n","epoch 41 | loss: 0.57728 | val_0_mse: 0.9966199994087219|  0:00:34s\n","epoch 42 | loss: 0.55913 | val_0_mse: 0.7560799717903137|  0:00:35s\n","epoch 43 | loss: 0.6147  | val_0_mse: 1.2350000143051147|  0:00:36s\n","epoch 44 | loss: 0.63002 | val_0_mse: 0.6236799955368042|  0:00:36s\n","epoch 45 | loss: 0.61514 | val_0_mse: 1.0568499565124512|  0:00:37s\n","epoch 46 | loss: 0.57031 | val_0_mse: 0.765250027179718|  0:00:38s\n","epoch 47 | loss: 0.55475 | val_0_mse: 0.6664100289344788|  0:00:39s\n","epoch 48 | loss: 0.57592 | val_0_mse: 0.8566499948501587|  0:00:40s\n","epoch 49 | loss: 0.55274 | val_0_mse: 1.1225800514221191|  0:00:40s\n","epoch 50 | loss: 0.6534  | val_0_mse: 0.6505500078201294|  0:00:41s\n","epoch 51 | loss: 0.56558 | val_0_mse: 0.7494099736213684|  0:00:42s\n","epoch 52 | loss: 0.56775 | val_0_mse: 0.6678299903869629|  0:00:43s\n","epoch 53 | loss: 0.52093 | val_0_mse: 0.6693999767303467|  0:00:44s\n","epoch 54 | loss: 0.52411 | val_0_mse: 0.7723699808120728|  0:00:44s\n","\n","Early stopping occurred at epoch 54 with best_epoch = 44 and best_val_0_mse = 0.6236799955368042\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 16:43:42,468] Trial 92 finished with value: 0.6236774921417236 and parameters: {'n_d': 43, 'n_steps': 10, 'gamma': 1.1039594176562695, 'n_independent': 5, 'n_shared': 3, 'momentum': 0.07609816067689164}. Best is trial 55 with value: 0.5396906733512878.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 10.49412| val_0_mse: 7835.91552734375|  0:00:00s\n","epoch 1  | loss: 5.78227 | val_0_mse: 1849.3250732421875|  0:00:01s\n","epoch 2  | loss: 5.03633 | val_0_mse: 618.3896484375|  0:00:02s\n","epoch 3  | loss: 3.33347 | val_0_mse: 405.34320068359375|  0:00:03s\n","epoch 4  | loss: 1.975   | val_0_mse: 133.97781372070312|  0:00:04s\n","epoch 5  | loss: 1.87703 | val_0_mse: 39.978851318359375|  0:00:04s\n","epoch 6  | loss: 1.39471 | val_0_mse: 31.75684928894043|  0:00:05s\n","epoch 7  | loss: 1.53813 | val_0_mse: 18.066570281982422|  0:00:06s\n","epoch 8  | loss: 1.73328 | val_0_mse: 23.364370346069336|  0:00:07s\n","epoch 9  | loss: 1.28307 | val_0_mse: 17.505149841308594|  0:00:08s\n","epoch 10 | loss: 0.96035 | val_0_mse: 5.54463005065918|  0:00:09s\n","epoch 11 | loss: 1.0771  | val_0_mse: 6.809790134429932|  0:00:09s\n","epoch 12 | loss: 1.19266 | val_0_mse: 39.328121185302734|  0:00:10s\n","epoch 13 | loss: 1.0009  | val_0_mse: 11.772689819335938|  0:00:11s\n","epoch 14 | loss: 1.08956 | val_0_mse: 9.574310302734375|  0:00:12s\n","epoch 15 | loss: 0.99792 | val_0_mse: 11.630829811096191|  0:00:13s\n","epoch 16 | loss: 0.88503 | val_0_mse: 17.76852035522461|  0:00:13s\n","epoch 17 | loss: 0.77925 | val_0_mse: 7.2286601066589355|  0:00:14s\n","epoch 18 | loss: 0.66391 | val_0_mse: 2.129349946975708|  0:00:15s\n","epoch 19 | loss: 0.87747 | val_0_mse: 5.846789836883545|  0:00:16s\n","epoch 20 | loss: 1.02174 | val_0_mse: 1.1698499917984009|  0:00:17s\n","epoch 21 | loss: 1.18125 | val_0_mse: 13.127189636230469|  0:00:18s\n","epoch 22 | loss: 1.74505 | val_0_mse: 2.5144500732421875|  0:00:19s\n","epoch 23 | loss: 0.76886 | val_0_mse: 6.054870128631592|  0:00:19s\n","epoch 24 | loss: 0.92184 | val_0_mse: 1.7099699974060059|  0:00:20s\n","epoch 25 | loss: 0.90557 | val_0_mse: 2.0617599487304688|  0:00:21s\n","epoch 26 | loss: 0.65922 | val_0_mse: 2.194269895553589|  0:00:22s\n","epoch 27 | loss: 0.66847 | val_0_mse: 1.5328400135040283|  0:00:22s\n","epoch 28 | loss: 0.76758 | val_0_mse: 2.6386799812316895|  0:00:23s\n","epoch 29 | loss: 0.7817  | val_0_mse: 1.2820899486541748|  0:00:24s\n","epoch 30 | loss: 0.6428  | val_0_mse: 1.0846699476242065|  0:00:25s\n","epoch 31 | loss: 0.77246 | val_0_mse: 2.113100051879883|  0:00:26s\n","epoch 32 | loss: 0.66748 | val_0_mse: 0.9560700058937073|  0:00:27s\n","epoch 33 | loss: 0.70159 | val_0_mse: 2.06358003616333|  0:00:27s\n","epoch 34 | loss: 0.67801 | val_0_mse: 0.8477699756622314|  0:00:28s\n","epoch 35 | loss: 0.67598 | val_0_mse: 2.9488298892974854|  0:00:29s\n","epoch 36 | loss: 0.70264 | val_0_mse: 0.9634299874305725|  0:00:30s\n","epoch 37 | loss: 0.54072 | val_0_mse: 1.0264699459075928|  0:00:31s\n","epoch 38 | loss: 0.53456 | val_0_mse: 0.806190013885498|  0:00:31s\n","epoch 39 | loss: 0.54354 | val_0_mse: 1.0073800086975098|  0:00:32s\n","epoch 40 | loss: 0.51223 | val_0_mse: 0.8937100172042847|  0:00:33s\n","epoch 41 | loss: 0.53093 | val_0_mse: 1.4755500555038452|  0:00:34s\n","epoch 42 | loss: 0.58331 | val_0_mse: 0.760129988193512|  0:00:35s\n","epoch 43 | loss: 0.69805 | val_0_mse: 1.1060099601745605|  0:00:36s\n","epoch 44 | loss: 0.66261 | val_0_mse: 0.7308599948883057|  0:00:36s\n","epoch 45 | loss: 0.63188 | val_0_mse: 0.8133400082588196|  0:00:37s\n","epoch 46 | loss: 0.5561  | val_0_mse: 0.7694500088691711|  0:00:38s\n","epoch 47 | loss: 0.5325  | val_0_mse: 1.084190011024475|  0:00:39s\n","epoch 48 | loss: 0.5855  | val_0_mse: 0.7652599811553955|  0:00:40s\n","epoch 49 | loss: 0.54898 | val_0_mse: 0.7072299718856812|  0:00:40s\n","epoch 50 | loss: 0.52404 | val_0_mse: 0.7266899943351746|  0:00:41s\n","epoch 51 | loss: 0.53737 | val_0_mse: 0.7896299958229065|  0:00:42s\n","epoch 52 | loss: 0.52059 | val_0_mse: 0.7422299981117249|  0:00:43s\n","epoch 53 | loss: 0.52575 | val_0_mse: 0.7125499844551086|  0:00:44s\n","epoch 54 | loss: 0.51356 | val_0_mse: 0.7763699889183044|  0:00:44s\n","epoch 55 | loss: 0.5248  | val_0_mse: 0.8707000017166138|  0:00:45s\n","epoch 56 | loss: 0.58993 | val_0_mse: 0.6171799898147583|  0:00:46s\n","epoch 57 | loss: 0.58842 | val_0_mse: 0.7983400225639343|  0:00:47s\n","epoch 58 | loss: 0.56373 | val_0_mse: 0.6856600046157837|  0:00:48s\n","epoch 59 | loss: 0.51844 | val_0_mse: 0.6443600058555603|  0:00:48s\n","epoch 60 | loss: 0.52611 | val_0_mse: 0.6339799761772156|  0:00:49s\n","epoch 61 | loss: 0.52546 | val_0_mse: 0.6172800064086914|  0:00:50s\n","epoch 62 | loss: 0.54359 | val_0_mse: 0.761709988117218|  0:00:51s\n","epoch 63 | loss: 0.56036 | val_0_mse: 0.610230028629303|  0:00:52s\n","epoch 64 | loss: 0.59604 | val_0_mse: 0.7343599796295166|  0:00:53s\n","epoch 65 | loss: 0.58217 | val_0_mse: 0.5862699747085571|  0:00:53s\n","epoch 66 | loss: 0.64403 | val_0_mse: 0.6491199731826782|  0:00:54s\n","epoch 67 | loss: 0.63611 | val_0_mse: 0.6211400032043457|  0:00:55s\n","epoch 68 | loss: 0.53768 | val_0_mse: 0.6095799803733826|  0:00:56s\n","epoch 69 | loss: 0.49987 | val_0_mse: 0.6822900176048279|  0:00:57s\n","epoch 70 | loss: 0.51107 | val_0_mse: 0.6139299869537354|  0:00:57s\n","epoch 71 | loss: 0.53784 | val_0_mse: 0.6237800121307373|  0:00:58s\n","epoch 72 | loss: 0.56551 | val_0_mse: 0.679889976978302|  0:00:59s\n","epoch 73 | loss: 0.51047 | val_0_mse: 0.6194999814033508|  0:01:00s\n","epoch 74 | loss: 0.5093  | val_0_mse: 0.6127300262451172|  0:01:01s\n","epoch 75 | loss: 0.49802 | val_0_mse: 0.6036900281906128|  0:01:01s\n","\n","Early stopping occurred at epoch 75 with best_epoch = 65 and best_val_0_mse = 0.5862699747085571\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 16:44:44,892] Trial 93 finished with value: 0.5862656235694885 and parameters: {'n_d': 40, 'n_steps': 10, 'gamma': 1.076981212582776, 'n_independent': 5, 'n_shared': 3, 'momentum': 0.029461597025941248}. Best is trial 55 with value: 0.5396906733512878.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 11.18861| val_0_mse: 2388.63916015625|  0:00:00s\n","epoch 1  | loss: 5.29888 | val_0_mse: 1276.1844482421875|  0:00:01s\n","epoch 2  | loss: 4.59962 | val_0_mse: 235.62594604492188|  0:00:02s\n","epoch 3  | loss: 3.98347 | val_0_mse: 174.21530151367188|  0:00:03s\n","epoch 4  | loss: 5.85292 | val_0_mse: 447.4601135253906|  0:00:04s\n","epoch 5  | loss: 3.15615 | val_0_mse: 40.346378326416016|  0:00:04s\n","epoch 6  | loss: 1.86588 | val_0_mse: 34.063751220703125|  0:00:05s\n","epoch 7  | loss: 1.27372 | val_0_mse: 20.373029708862305|  0:00:06s\n","epoch 8  | loss: 1.37061 | val_0_mse: 48.61077117919922|  0:00:07s\n","epoch 9  | loss: 1.611   | val_0_mse: 13.149970054626465|  0:00:08s\n","epoch 10 | loss: 2.25609 | val_0_mse: 49.68547821044922|  0:00:09s\n","epoch 11 | loss: 1.36042 | val_0_mse: 11.057889938354492|  0:00:09s\n","epoch 12 | loss: 1.03451 | val_0_mse: 7.829830169677734|  0:00:10s\n","epoch 13 | loss: 1.11508 | val_0_mse: 5.739699840545654|  0:00:11s\n","epoch 14 | loss: 1.39273 | val_0_mse: 11.633440017700195|  0:00:12s\n","epoch 15 | loss: 1.67511 | val_0_mse: 2.888590097427368|  0:00:13s\n","epoch 16 | loss: 1.50423 | val_0_mse: 16.201139450073242|  0:00:14s\n","epoch 17 | loss: 1.80568 | val_0_mse: 3.7208499908447266|  0:00:14s\n","epoch 18 | loss: 1.35386 | val_0_mse: 6.986690044403076|  0:00:15s\n","epoch 19 | loss: 0.88314 | val_0_mse: 3.724600076675415|  0:00:16s\n","epoch 20 | loss: 0.82608 | val_0_mse: 6.425179958343506|  0:00:17s\n","epoch 21 | loss: 0.88657 | val_0_mse: 7.678420066833496|  0:00:18s\n","epoch 22 | loss: 0.71261 | val_0_mse: 5.8341898918151855|  0:00:18s\n","epoch 23 | loss: 0.76489 | val_0_mse: 1.88864004611969|  0:00:19s\n","epoch 24 | loss: 0.61257 | val_0_mse: 1.8848299980163574|  0:00:20s\n","epoch 25 | loss: 0.63896 | val_0_mse: 2.0403800010681152|  0:00:21s\n","epoch 26 | loss: 0.66834 | val_0_mse: 1.8849799633026123|  0:00:22s\n","epoch 27 | loss: 0.58678 | val_0_mse: 1.8236700296401978|  0:00:23s\n","epoch 28 | loss: 0.58897 | val_0_mse: 1.5446399450302124|  0:00:23s\n","epoch 29 | loss: 0.66639 | val_0_mse: 2.311569929122925|  0:00:24s\n","epoch 30 | loss: 0.62217 | val_0_mse: 2.1198298931121826|  0:00:25s\n","epoch 31 | loss: 0.62446 | val_0_mse: 1.1656800508499146|  0:00:26s\n","epoch 32 | loss: 0.63203 | val_0_mse: 1.3911399841308594|  0:00:27s\n","epoch 33 | loss: 0.58057 | val_0_mse: 1.7766300439834595|  0:00:28s\n","epoch 34 | loss: 0.57733 | val_0_mse: 2.5375099182128906|  0:00:28s\n","epoch 35 | loss: 0.59013 | val_0_mse: 0.9734799861907959|  0:00:29s\n","epoch 36 | loss: 0.63809 | val_0_mse: 1.303339958190918|  0:00:30s\n","epoch 37 | loss: 0.61302 | val_0_mse: 1.1100900173187256|  0:00:31s\n","epoch 38 | loss: 0.56851 | val_0_mse: 0.8479200005531311|  0:00:32s\n","epoch 39 | loss: 0.56408 | val_0_mse: 0.8168200254440308|  0:00:32s\n","epoch 40 | loss: 0.52529 | val_0_mse: 1.2470500469207764|  0:00:33s\n","epoch 41 | loss: 0.53337 | val_0_mse: 0.924340009689331|  0:00:34s\n","epoch 42 | loss: 0.51682 | val_0_mse: 0.7630400061607361|  0:00:35s\n","epoch 43 | loss: 0.52391 | val_0_mse: 0.9401599764823914|  0:00:36s\n","epoch 44 | loss: 0.53178 | val_0_mse: 0.8421199917793274|  0:00:36s\n","epoch 45 | loss: 0.51128 | val_0_mse: 0.9096199870109558|  0:00:37s\n","epoch 46 | loss: 0.54745 | val_0_mse: 0.9185400009155273|  0:00:38s\n","epoch 47 | loss: 0.51418 | val_0_mse: 0.8083500266075134|  0:00:39s\n","epoch 48 | loss: 0.5251  | val_0_mse: 0.7049099802970886|  0:00:40s\n","epoch 49 | loss: 0.50207 | val_0_mse: 0.720579981803894|  0:00:40s\n","epoch 50 | loss: 0.5024  | val_0_mse: 0.7128000259399414|  0:00:41s\n","epoch 51 | loss: 0.51215 | val_0_mse: 0.8574900031089783|  0:00:42s\n","epoch 52 | loss: 0.51319 | val_0_mse: 0.7833499908447266|  0:00:43s\n","epoch 53 | loss: 0.5392  | val_0_mse: 0.705049991607666|  0:00:44s\n","epoch 54 | loss: 0.52493 | val_0_mse: 0.7791900038719177|  0:00:44s\n","epoch 55 | loss: 0.51778 | val_0_mse: 0.6606500148773193|  0:00:45s\n","epoch 56 | loss: 0.5197  | val_0_mse: 0.6822199821472168|  0:00:46s\n","epoch 57 | loss: 0.52544 | val_0_mse: 0.7128099799156189|  0:00:47s\n","epoch 58 | loss: 0.52734 | val_0_mse: 0.7470899820327759|  0:00:48s\n","epoch 59 | loss: 0.55467 | val_0_mse: 0.6376299858093262|  0:00:49s\n","epoch 60 | loss: 0.53783 | val_0_mse: 0.6718599796295166|  0:00:49s\n","epoch 61 | loss: 0.51197 | val_0_mse: 0.6424800157546997|  0:00:50s\n","epoch 62 | loss: 0.52559 | val_0_mse: 0.6699000000953674|  0:00:51s\n","epoch 63 | loss: 0.48793 | val_0_mse: 0.6761299967765808|  0:00:52s\n","epoch 64 | loss: 0.49229 | val_0_mse: 0.6294100284576416|  0:00:53s\n","epoch 65 | loss: 0.52426 | val_0_mse: 0.6860600113868713|  0:00:53s\n","epoch 66 | loss: 0.50001 | val_0_mse: 0.6553699970245361|  0:00:54s\n","epoch 67 | loss: 0.48543 | val_0_mse: 0.6197999715805054|  0:00:55s\n","epoch 68 | loss: 0.48938 | val_0_mse: 0.6162800192832947|  0:00:56s\n","epoch 69 | loss: 0.48543 | val_0_mse: 0.6027799844741821|  0:00:57s\n","epoch 70 | loss: 0.48294 | val_0_mse: 0.5945600271224976|  0:00:58s\n","epoch 71 | loss: 0.49798 | val_0_mse: 0.6013699769973755|  0:00:58s\n","epoch 72 | loss: 0.47061 | val_0_mse: 0.6207299828529358|  0:00:59s\n","epoch 73 | loss: 0.49739 | val_0_mse: 0.6480900049209595|  0:01:00s\n","epoch 74 | loss: 0.47671 | val_0_mse: 0.6160699725151062|  0:01:01s\n","epoch 75 | loss: 0.47992 | val_0_mse: 0.5948200225830078|  0:01:02s\n","epoch 76 | loss: 0.47335 | val_0_mse: 0.5895299911499023|  0:01:02s\n","epoch 77 | loss: 0.49403 | val_0_mse: 0.5551400184631348|  0:01:03s\n","epoch 78 | loss: 0.47624 | val_0_mse: 0.6111999750137329|  0:01:04s\n","epoch 79 | loss: 0.50717 | val_0_mse: 0.6773200035095215|  0:01:05s\n","epoch 80 | loss: 0.53262 | val_0_mse: 0.6349499821662903|  0:01:06s\n","epoch 81 | loss: 0.54185 | val_0_mse: 0.6777099967002869|  0:01:07s\n","epoch 82 | loss: 0.59833 | val_0_mse: 0.7747899889945984|  0:01:07s\n","epoch 83 | loss: 0.54871 | val_0_mse: 0.6027899980545044|  0:01:08s\n","epoch 84 | loss: 0.46952 | val_0_mse: 0.5773400068283081|  0:01:09s\n","epoch 85 | loss: 0.45869 | val_0_mse: 0.6026700139045715|  0:01:10s\n","epoch 86 | loss: 0.45153 | val_0_mse: 0.593209981918335|  0:01:11s\n","epoch 87 | loss: 0.43915 | val_0_mse: 0.5860599875450134|  0:01:11s\n","\n","Early stopping occurred at epoch 87 with best_epoch = 77 and best_val_0_mse = 0.5551400184631348\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 16:45:57,266] Trial 94 finished with value: 0.5551376938819885 and parameters: {'n_d': 36, 'n_steps': 10, 'gamma': 1.0189519337040158, 'n_independent': 5, 'n_shared': 3, 'momentum': 0.06079800590575889}. Best is trial 55 with value: 0.5396906733512878.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 11.50769| val_0_mse: 1439.71044921875|  0:00:00s\n","epoch 1  | loss: 5.11379 | val_0_mse: 244.48736572265625|  0:00:01s\n","epoch 2  | loss: 3.96481 | val_0_mse: 223.5913543701172|  0:00:01s\n","epoch 3  | loss: 2.66826 | val_0_mse: 378.5827331542969|  0:00:02s\n","epoch 4  | loss: 3.16897 | val_0_mse: 40.31232833862305|  0:00:03s\n","epoch 5  | loss: 1.65581 | val_0_mse: 40.325008392333984|  0:00:03s\n","epoch 6  | loss: 1.41988 | val_0_mse: 31.381959915161133|  0:00:04s\n","epoch 7  | loss: 1.05699 | val_0_mse: 19.43762969970703|  0:00:04s\n","epoch 8  | loss: 0.98113 | val_0_mse: 30.504289627075195|  0:00:05s\n","epoch 9  | loss: 0.90751 | val_0_mse: 17.888240814208984|  0:00:06s\n","epoch 10 | loss: 0.81662 | val_0_mse: 33.18465042114258|  0:00:06s\n","epoch 11 | loss: 0.74081 | val_0_mse: 47.334659576416016|  0:00:07s\n","epoch 12 | loss: 0.7538  | val_0_mse: 77.2542495727539|  0:00:07s\n","epoch 13 | loss: 0.68234 | val_0_mse: 5.801149845123291|  0:00:08s\n","epoch 14 | loss: 0.80327 | val_0_mse: 24.73358917236328|  0:00:08s\n","epoch 15 | loss: 0.7319  | val_0_mse: 14.476759910583496|  0:00:09s\n","epoch 16 | loss: 0.70579 | val_0_mse: 8.081089973449707|  0:00:10s\n","epoch 17 | loss: 0.6827  | val_0_mse: 6.480090141296387|  0:00:10s\n","epoch 18 | loss: 0.61945 | val_0_mse: 4.058199882507324|  0:00:11s\n","epoch 19 | loss: 0.60445 | val_0_mse: 1.8518799543380737|  0:00:11s\n","epoch 20 | loss: 0.60945 | val_0_mse: 3.648400068283081|  0:00:12s\n","epoch 21 | loss: 0.59433 | val_0_mse: 3.9204599857330322|  0:00:13s\n","epoch 22 | loss: 0.58046 | val_0_mse: 4.506040096282959|  0:00:13s\n","epoch 23 | loss: 0.55208 | val_0_mse: 2.0831899642944336|  0:00:14s\n","epoch 24 | loss: 0.60465 | val_0_mse: 8.97070026397705|  0:00:15s\n","epoch 25 | loss: 0.63268 | val_0_mse: 4.247869968414307|  0:00:15s\n","epoch 26 | loss: 0.55523 | val_0_mse: 1.8121999502182007|  0:00:16s\n","epoch 27 | loss: 0.5648  | val_0_mse: 2.385819911956787|  0:00:16s\n","epoch 28 | loss: 0.61934 | val_0_mse: 1.7698500156402588|  0:00:17s\n","epoch 29 | loss: 0.64031 | val_0_mse: 1.244320034980774|  0:00:18s\n","epoch 30 | loss: 0.61076 | val_0_mse: 2.8676300048828125|  0:00:18s\n","epoch 31 | loss: 0.62342 | val_0_mse: 1.0174599885940552|  0:00:19s\n","epoch 32 | loss: 0.57134 | val_0_mse: 1.6223900318145752|  0:00:19s\n","epoch 33 | loss: 0.55233 | val_0_mse: 2.199280023574829|  0:00:20s\n","epoch 34 | loss: 0.60316 | val_0_mse: 1.0002000331878662|  0:00:21s\n","epoch 35 | loss: 0.54616 | val_0_mse: 1.7218400239944458|  0:00:21s\n","epoch 36 | loss: 0.5255  | val_0_mse: 1.1484800577163696|  0:00:22s\n","epoch 37 | loss: 0.55174 | val_0_mse: 1.435379981994629|  0:00:22s\n","epoch 38 | loss: 0.5521  | val_0_mse: 1.6375900506973267|  0:00:23s\n","epoch 39 | loss: 0.59221 | val_0_mse: 1.3527899980545044|  0:00:24s\n","epoch 40 | loss: 0.55692 | val_0_mse: 1.566290020942688|  0:00:24s\n","epoch 41 | loss: 0.56414 | val_0_mse: 1.2364200353622437|  0:00:25s\n","epoch 42 | loss: 0.53128 | val_0_mse: 1.3238999843597412|  0:00:25s\n","epoch 43 | loss: 0.52266 | val_0_mse: 0.991569995880127|  0:00:26s\n","epoch 44 | loss: 0.52859 | val_0_mse: 1.022879958152771|  0:00:26s\n","epoch 45 | loss: 0.52893 | val_0_mse: 0.8786699771881104|  0:00:27s\n","epoch 46 | loss: 0.51482 | val_0_mse: 1.048050045967102|  0:00:28s\n","epoch 47 | loss: 0.5163  | val_0_mse: 0.7465199828147888|  0:00:28s\n","epoch 48 | loss: 0.53798 | val_0_mse: 0.8881800174713135|  0:00:29s\n","epoch 49 | loss: 0.55879 | val_0_mse: 1.235509991645813|  0:00:29s\n","epoch 50 | loss: 0.56645 | val_0_mse: 0.6607699990272522|  0:00:30s\n","epoch 51 | loss: 0.53622 | val_0_mse: 0.7488600015640259|  0:00:31s\n","epoch 52 | loss: 0.51175 | val_0_mse: 0.7969899773597717|  0:00:31s\n","epoch 53 | loss: 0.5248  | val_0_mse: 0.6233100295066833|  0:00:32s\n","epoch 54 | loss: 0.51136 | val_0_mse: 0.67426997423172|  0:00:33s\n","epoch 55 | loss: 0.49758 | val_0_mse: 0.638480007648468|  0:00:33s\n","epoch 56 | loss: 0.49587 | val_0_mse: 0.6609299778938293|  0:00:34s\n","epoch 57 | loss: 0.49772 | val_0_mse: 0.6060500144958496|  0:00:34s\n","epoch 58 | loss: 0.49933 | val_0_mse: 0.6382200121879578|  0:00:35s\n","epoch 59 | loss: 0.50723 | val_0_mse: 0.7367799878120422|  0:00:35s\n","epoch 60 | loss: 0.50546 | val_0_mse: 0.6344199776649475|  0:00:36s\n","epoch 61 | loss: 0.49562 | val_0_mse: 0.6064000129699707|  0:00:37s\n","epoch 62 | loss: 0.52505 | val_0_mse: 1.001889944076538|  0:00:37s\n","epoch 63 | loss: 0.60365 | val_0_mse: 0.6509299874305725|  0:00:38s\n","epoch 64 | loss: 0.59019 | val_0_mse: 0.8381100296974182|  0:00:38s\n","epoch 65 | loss: 0.57022 | val_0_mse: 0.644540011882782|  0:00:39s\n","epoch 66 | loss: 0.57563 | val_0_mse: 0.8252300024032593|  0:00:40s\n","epoch 67 | loss: 0.58412 | val_0_mse: 0.6603800058364868|  0:00:40s\n","\n","Early stopping occurred at epoch 67 with best_epoch = 57 and best_val_0_mse = 0.6060500144958496\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 16:46:38,262] Trial 95 finished with value: 0.6060500741004944 and parameters: {'n_d': 34, 'n_steps': 9, 'gamma': 1.021969000294256, 'n_independent': 3, 'n_shared': 3, 'momentum': 0.05725034823105532}. Best is trial 55 with value: 0.5396906733512878.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 57.95308| val_0_mse: 286.2876892089844|  0:00:00s\n","epoch 1  | loss: 18.07742| val_0_mse: 237.14920043945312|  0:00:00s\n","epoch 2  | loss: 7.68409 | val_0_mse: 260.8427429199219|  0:00:00s\n","epoch 3  | loss: 4.29482 | val_0_mse: 164.3593292236328|  0:00:01s\n","epoch 4  | loss: 2.38917 | val_0_mse: 26.510929107666016|  0:00:01s\n","epoch 5  | loss: 1.57073 | val_0_mse: 10.982569694519043|  0:00:01s\n","epoch 6  | loss: 1.22954 | val_0_mse: 6.662909984588623|  0:00:02s\n","epoch 7  | loss: 0.99361 | val_0_mse: 2.8124399185180664|  0:00:02s\n","epoch 8  | loss: 0.84917 | val_0_mse: 2.521850109100342|  0:00:03s\n","epoch 9  | loss: 0.76817 | val_0_mse: 1.9373600482940674|  0:00:03s\n","epoch 10 | loss: 0.74104 | val_0_mse: 2.0600500106811523|  0:00:03s\n","epoch 11 | loss: 0.71844 | val_0_mse: 1.7081999778747559|  0:00:04s\n","epoch 12 | loss: 0.66797 | val_0_mse: 2.7976200580596924|  0:00:04s\n","epoch 13 | loss: 0.65309 | val_0_mse: 2.560689926147461|  0:00:04s\n","epoch 14 | loss: 0.61045 | val_0_mse: 1.9655799865722656|  0:00:05s\n","epoch 15 | loss: 0.60935 | val_0_mse: 3.3029000759124756|  0:00:05s\n","epoch 16 | loss: 0.60669 | val_0_mse: 3.745529890060425|  0:00:05s\n","epoch 17 | loss: 0.60058 | val_0_mse: 5.076340198516846|  0:00:06s\n","epoch 18 | loss: 0.58376 | val_0_mse: 4.70635986328125|  0:00:06s\n","epoch 19 | loss: 0.55715 | val_0_mse: 3.5868101119995117|  0:00:06s\n","epoch 20 | loss: 0.55427 | val_0_mse: 2.370810031890869|  0:00:07s\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 16:46:45,862] Trial 96 finished with value: 1.708202600479126 and parameters: {'n_d': 10, 'n_steps': 6, 'gamma': 1.0470644967240954, 'n_independent': 1, 'n_shared': 3, 'momentum': 0.06898935084703338}. Best is trial 55 with value: 0.5396906733512878.\n"]},{"output_type":"stream","name":"stdout","text":["epoch 21 | loss: 0.5459  | val_0_mse: 1.8812400102615356|  0:00:07s\n","\n","Early stopping occurred at epoch 21 with best_epoch = 11 and best_val_0_mse = 1.7081999778747559\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 76.32733| val_0_mse: 1380.191650390625|  0:00:00s\n","epoch 1  | loss: 7.48243 | val_0_mse: 264.8216857910156|  0:00:01s\n","epoch 2  | loss: 4.20787 | val_0_mse: 164.80184936523438|  0:00:01s\n","epoch 3  | loss: 7.91125 | val_0_mse: 620.6650390625|  0:00:02s\n","epoch 4  | loss: 2.98062 | val_0_mse: 208.4569854736328|  0:00:03s\n","epoch 5  | loss: 1.97312 | val_0_mse: 28.410400390625|  0:00:03s\n","epoch 6  | loss: 1.79998 | val_0_mse: 33.97093963623047|  0:00:04s\n","epoch 7  | loss: 1.54882 | val_0_mse: 33.822120666503906|  0:00:05s\n","epoch 8  | loss: 1.51135 | val_0_mse: 16.720619201660156|  0:00:05s\n","epoch 9  | loss: 1.36642 | val_0_mse: 8.307909965515137|  0:00:06s\n","epoch 10 | loss: 1.16001 | val_0_mse: 11.86067008972168|  0:00:07s\n","epoch 11 | loss: 0.9553  | val_0_mse: 16.77635955810547|  0:00:07s\n","epoch 12 | loss: 1.74967 | val_0_mse: 9.560449600219727|  0:00:08s\n","epoch 13 | loss: 4.76799 | val_0_mse: 15.42356014251709|  0:00:09s\n","epoch 14 | loss: 2.13593 | val_0_mse: 57.02143859863281|  0:00:09s\n","epoch 15 | loss: 2.98785 | val_0_mse: 9.036709785461426|  0:00:10s\n","epoch 16 | loss: 3.57417 | val_0_mse: 21.280580520629883|  0:00:10s\n","epoch 17 | loss: 1.29083 | val_0_mse: 4.933199882507324|  0:00:11s\n","epoch 18 | loss: 1.82215 | val_0_mse: 7.222700119018555|  0:00:12s\n","epoch 19 | loss: 1.64192 | val_0_mse: 1.8171000480651855|  0:00:12s\n","epoch 20 | loss: 1.31646 | val_0_mse: 5.8475799560546875|  0:00:13s\n","epoch 21 | loss: 0.81458 | val_0_mse: 1.9266999959945679|  0:00:14s\n","epoch 22 | loss: 0.76627 | val_0_mse: 1.883810043334961|  0:00:14s\n","epoch 23 | loss: 1.3948  | val_0_mse: 2.266700029373169|  0:00:15s\n","epoch 24 | loss: 1.09628 | val_0_mse: 2.943959951400757|  0:00:16s\n","epoch 25 | loss: 0.98659 | val_0_mse: 2.6728899478912354|  0:00:16s\n","epoch 26 | loss: 0.90153 | val_0_mse: 2.293600082397461|  0:00:17s\n","epoch 27 | loss: 1.14436 | val_0_mse: 3.4753201007843018|  0:00:18s\n","epoch 28 | loss: 1.81061 | val_0_mse: 1.2573599815368652|  0:00:18s\n","epoch 29 | loss: 2.13832 | val_0_mse: 3.5623600482940674|  0:00:19s\n","epoch 30 | loss: 1.48784 | val_0_mse: 2.1671600341796875|  0:00:20s\n","epoch 31 | loss: 1.48215 | val_0_mse: 1.0488699674606323|  0:00:20s\n","epoch 32 | loss: 0.74282 | val_0_mse: 1.2660599946975708|  0:00:21s\n","epoch 33 | loss: 0.79963 | val_0_mse: 0.9128699898719788|  0:00:22s\n","epoch 34 | loss: 0.69152 | val_0_mse: 1.0121999979019165|  0:00:22s\n","epoch 35 | loss: 0.71663 | val_0_mse: 0.8525800108909607|  0:00:23s\n","epoch 36 | loss: 0.65469 | val_0_mse: 0.93954998254776|  0:00:23s\n","epoch 37 | loss: 0.61829 | val_0_mse: 0.7925300002098083|  0:00:24s\n","epoch 38 | loss: 0.58536 | val_0_mse: 0.7623999714851379|  0:00:25s\n","epoch 39 | loss: 0.59662 | val_0_mse: 1.1227999925613403|  0:00:25s\n","epoch 40 | loss: 0.60127 | val_0_mse: 0.8762000203132629|  0:00:26s\n","epoch 41 | loss: 0.64086 | val_0_mse: 0.8992499709129333|  0:00:27s\n","epoch 42 | loss: 0.63702 | val_0_mse: 0.8176100254058838|  0:00:27s\n","epoch 43 | loss: 0.68602 | val_0_mse: 0.8999300003051758|  0:00:28s\n","epoch 44 | loss: 0.703   | val_0_mse: 0.8357599973678589|  0:00:29s\n","epoch 45 | loss: 0.73852 | val_0_mse: 1.0858299732208252|  0:00:29s\n","epoch 46 | loss: 0.63922 | val_0_mse: 0.717710018157959|  0:00:30s\n","epoch 47 | loss: 0.57897 | val_0_mse: 0.7657600045204163|  0:00:31s\n","epoch 48 | loss: 0.59321 | val_0_mse: 1.1546000242233276|  0:00:31s\n","epoch 49 | loss: 0.62877 | val_0_mse: 0.7191500067710876|  0:00:32s\n","epoch 50 | loss: 0.60052 | val_0_mse: 0.8547499775886536|  0:00:33s\n","epoch 51 | loss: 0.60152 | val_0_mse: 0.6922500133514404|  0:00:33s\n","epoch 52 | loss: 0.60859 | val_0_mse: 0.7653700113296509|  0:00:34s\n","epoch 53 | loss: 0.65025 | val_0_mse: 0.7016199827194214|  0:00:35s\n","epoch 54 | loss: 0.60257 | val_0_mse: 0.8317999839782715|  0:00:35s\n","epoch 55 | loss: 0.60437 | val_0_mse: 0.6645399928092957|  0:00:36s\n","epoch 56 | loss: 0.56778 | val_0_mse: 0.7652999758720398|  0:00:37s\n","epoch 57 | loss: 0.57941 | val_0_mse: 0.7211999893188477|  0:00:37s\n","epoch 58 | loss: 0.54571 | val_0_mse: 0.7237300276756287|  0:00:38s\n","epoch 59 | loss: 0.53356 | val_0_mse: 0.6956999897956848|  0:00:39s\n","epoch 60 | loss: 0.56812 | val_0_mse: 0.7304199934005737|  0:00:39s\n","epoch 61 | loss: 0.57363 | val_0_mse: 0.6347900032997131|  0:00:40s\n","epoch 62 | loss: 0.56355 | val_0_mse: 0.6861500144004822|  0:00:41s\n","epoch 63 | loss: 0.57212 | val_0_mse: 0.7347999811172485|  0:00:41s\n","epoch 64 | loss: 0.5949  | val_0_mse: 0.6513800024986267|  0:00:42s\n","epoch 65 | loss: 0.58646 | val_0_mse: 0.7065200209617615|  0:00:42s\n","epoch 66 | loss: 0.55295 | val_0_mse: 0.643339991569519|  0:00:43s\n","epoch 67 | loss: 0.54499 | val_0_mse: 0.7246500253677368|  0:00:44s\n","epoch 68 | loss: 0.53825 | val_0_mse: 0.7397599816322327|  0:00:44s\n","epoch 69 | loss: 0.5596  | val_0_mse: 0.6863999962806702|  0:00:45s\n","epoch 70 | loss: 0.55663 | val_0_mse: 0.6599000096321106|  0:00:46s\n","epoch 71 | loss: 0.56179 | val_0_mse: 0.6559799909591675|  0:00:46s\n","\n","Early stopping occurred at epoch 71 with best_epoch = 61 and best_val_0_mse = 0.6347900032997131\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 16:47:33,073] Trial 97 finished with value: 0.6347939968109131 and parameters: {'n_d': 37, 'n_steps': 10, 'gamma': 1.410453552714422, 'n_independent': 3, 'n_shared': 3, 'momentum': 0.0903128917387238}. Best is trial 55 with value: 0.5396906733512878.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 12.04499| val_0_mse: 30683.8671875|  0:00:00s\n","epoch 1  | loss: 4.19567 | val_0_mse: 1363.7755126953125|  0:00:01s\n","epoch 2  | loss: 2.76913 | val_0_mse: 325.46942138671875|  0:00:02s\n","epoch 3  | loss: 1.80674 | val_0_mse: 254.77392578125|  0:00:02s\n","epoch 4  | loss: 1.55554 | val_0_mse: 137.9087677001953|  0:00:03s\n","epoch 5  | loss: 2.72502 | val_0_mse: 15.145620346069336|  0:00:04s\n","epoch 6  | loss: 1.99635 | val_0_mse: 8.390460014343262|  0:00:05s\n","epoch 7  | loss: 1.24235 | val_0_mse: 25.53251075744629|  0:00:05s\n","epoch 8  | loss: 1.31304 | val_0_mse: 6.088550090789795|  0:00:06s\n","epoch 9  | loss: 1.09747 | val_0_mse: 5.291820049285889|  0:00:07s\n","epoch 10 | loss: 0.87873 | val_0_mse: 6.451469898223877|  0:00:08s\n","epoch 11 | loss: 0.84732 | val_0_mse: 6.780930042266846|  0:00:08s\n","epoch 12 | loss: 0.79726 | val_0_mse: 4.210319995880127|  0:00:09s\n","epoch 13 | loss: 0.76938 | val_0_mse: 2.077660083770752|  0:00:10s\n","epoch 14 | loss: 0.90768 | val_0_mse: 2.013969898223877|  0:00:11s\n","epoch 15 | loss: 0.74173 | val_0_mse: 1.5641000270843506|  0:00:11s\n","epoch 16 | loss: 0.68635 | val_0_mse: 1.133489966392517|  0:00:12s\n","epoch 17 | loss: 0.68858 | val_0_mse: 1.78780996799469|  0:00:13s\n","epoch 18 | loss: 0.64837 | val_0_mse: 1.8365399837493896|  0:00:14s\n","epoch 19 | loss: 0.65932 | val_0_mse: 1.7404999732971191|  0:00:14s\n","epoch 20 | loss: 0.63611 | val_0_mse: 1.9006600379943848|  0:00:15s\n","epoch 21 | loss: 0.62748 | val_0_mse: 1.7893699407577515|  0:00:16s\n","epoch 22 | loss: 0.64384 | val_0_mse: 2.7832300662994385|  0:00:16s\n","epoch 23 | loss: 0.64076 | val_0_mse: 2.891900062561035|  0:00:17s\n","epoch 24 | loss: 0.62838 | val_0_mse: 1.4916800260543823|  0:00:18s\n","epoch 25 | loss: 0.63455 | val_0_mse: 1.8471599817276|  0:00:19s\n","epoch 26 | loss: 0.64699 | val_0_mse: 1.8169200420379639|  0:00:19s\n","\n","Early stopping occurred at epoch 26 with best_epoch = 16 and best_val_0_mse = 1.133489966392517\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 16:47:53,478] Trial 98 finished with value: 1.1334867477416992 and parameters: {'n_d': 26, 'n_steps': 8, 'gamma': 1.3560456573032977, 'n_independent': 5, 'n_shared': 4, 'momentum': 0.019442338691741227}. Best is trial 55 with value: 0.5396906733512878.\n","/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 34.55073| val_0_mse: 539.8766479492188|  0:00:00s\n","epoch 1  | loss: 5.47622 | val_0_mse: 111.63764953613281|  0:00:00s\n","epoch 2  | loss: 1.81457 | val_0_mse: 46.87055969238281|  0:00:01s\n","epoch 3  | loss: 1.0463  | val_0_mse: 34.02497863769531|  0:00:01s\n","epoch 4  | loss: 0.80029 | val_0_mse: 48.44776153564453|  0:00:01s\n","epoch 5  | loss: 0.74558 | val_0_mse: 18.767559051513672|  0:00:02s\n","epoch 6  | loss: 0.66862 | val_0_mse: 13.710240364074707|  0:00:02s\n","epoch 7  | loss: 0.64835 | val_0_mse: 8.425909996032715|  0:00:03s\n","epoch 8  | loss: 0.63267 | val_0_mse: 11.515890121459961|  0:00:03s\n","epoch 9  | loss: 0.60909 | val_0_mse: 9.732799530029297|  0:00:03s\n","epoch 10 | loss: 0.63027 | val_0_mse: 6.175899982452393|  0:00:04s\n","epoch 11 | loss: 0.55872 | val_0_mse: 3.9307899475097656|  0:00:04s\n","epoch 12 | loss: 0.55969 | val_0_mse: 4.865530014038086|  0:00:04s\n","epoch 13 | loss: 0.59116 | val_0_mse: 2.91828989982605|  0:00:05s\n","epoch 14 | loss: 0.55966 | val_0_mse: 3.4690799713134766|  0:00:05s\n","epoch 15 | loss: 0.56584 | val_0_mse: 2.0625100135803223|  0:00:05s\n","epoch 16 | loss: 0.56058 | val_0_mse: 3.3129100799560547|  0:00:06s\n","epoch 17 | loss: 0.53025 | val_0_mse: 10.882410049438477|  0:00:06s\n","epoch 18 | loss: 0.52742 | val_0_mse: 3.795490026473999|  0:00:07s\n","epoch 19 | loss: 0.52598 | val_0_mse: 3.0352699756622314|  0:00:07s\n","epoch 20 | loss: 0.53169 | val_0_mse: 5.731760025024414|  0:00:07s\n","epoch 21 | loss: 0.52616 | val_0_mse: 6.52957010269165|  0:00:08s\n","epoch 22 | loss: 0.51229 | val_0_mse: 3.7695798873901367|  0:00:08s\n","epoch 23 | loss: 0.51845 | val_0_mse: 2.258650064468384|  0:00:09s\n","epoch 24 | loss: 0.52229 | val_0_mse: 1.9213999509811401|  0:00:09s\n","epoch 25 | loss: 0.51931 | val_0_mse: 1.8799899816513062|  0:00:09s\n","epoch 26 | loss: 0.52984 | val_0_mse: 1.669819951057434|  0:00:10s\n","epoch 27 | loss: 0.53078 | val_0_mse: 1.7814699411392212|  0:00:10s\n","epoch 28 | loss: 0.5481  | val_0_mse: 1.4073100090026855|  0:00:10s\n","epoch 29 | loss: 0.51874 | val_0_mse: 1.3742200136184692|  0:00:11s\n","epoch 30 | loss: 0.52209 | val_0_mse: 1.420009970664978|  0:00:11s\n","epoch 31 | loss: 0.51214 | val_0_mse: 1.7441799640655518|  0:00:12s\n","epoch 32 | loss: 0.48982 | val_0_mse: 1.3981200456619263|  0:00:12s\n","epoch 33 | loss: 0.49863 | val_0_mse: 1.242709994316101|  0:00:12s\n","epoch 34 | loss: 0.49218 | val_0_mse: 1.3913999795913696|  0:00:13s\n","epoch 35 | loss: 0.49728 | val_0_mse: 1.4951800107955933|  0:00:13s\n","epoch 36 | loss: 0.48625 | val_0_mse: 1.2831799983978271|  0:00:13s\n","epoch 37 | loss: 0.49055 | val_0_mse: 1.4248700141906738|  0:00:14s\n","epoch 38 | loss: 0.50048 | val_0_mse: 1.1931899785995483|  0:00:14s\n","epoch 39 | loss: 0.50674 | val_0_mse: 1.1035100221633911|  0:00:15s\n","epoch 40 | loss: 0.5055  | val_0_mse: 1.2582000494003296|  0:00:15s\n","epoch 41 | loss: 0.50883 | val_0_mse: 1.1061099767684937|  0:00:15s\n","epoch 42 | loss: 0.51427 | val_0_mse: 1.1186000108718872|  0:00:16s\n","epoch 43 | loss: 0.50338 | val_0_mse: 1.0254299640655518|  0:00:16s\n","epoch 44 | loss: 0.50655 | val_0_mse: 1.1722099781036377|  0:00:16s\n","epoch 45 | loss: 0.49563 | val_0_mse: 0.9914500117301941|  0:00:17s\n","epoch 46 | loss: 0.50176 | val_0_mse: 0.9456300139427185|  0:00:17s\n","epoch 47 | loss: 0.48884 | val_0_mse: 1.0443700551986694|  0:00:17s\n","epoch 48 | loss: 0.47119 | val_0_mse: 0.8596000075340271|  0:00:18s\n","epoch 49 | loss: 0.47356 | val_0_mse: 0.8841400146484375|  0:00:18s\n","epoch 50 | loss: 0.48603 | val_0_mse: 0.8470600247383118|  0:00:19s\n","epoch 51 | loss: 0.50725 | val_0_mse: 0.9242299795150757|  0:00:19s\n","epoch 52 | loss: 0.48854 | val_0_mse: 0.8129299879074097|  0:00:19s\n","epoch 53 | loss: 0.48827 | val_0_mse: 0.7628099918365479|  0:00:20s\n","epoch 54 | loss: 0.48813 | val_0_mse: 0.7821400165557861|  0:00:20s\n","epoch 55 | loss: 0.4964  | val_0_mse: 0.8375499844551086|  0:00:21s\n","epoch 56 | loss: 0.49899 | val_0_mse: 0.762719988822937|  0:00:21s\n","epoch 57 | loss: 0.49116 | val_0_mse: 0.6985700130462646|  0:00:21s\n","epoch 58 | loss: 0.48953 | val_0_mse: 0.6514599919319153|  0:00:22s\n","epoch 59 | loss: 0.49026 | val_0_mse: 0.7424200177192688|  0:00:22s\n","epoch 60 | loss: 0.48911 | val_0_mse: 0.7445499897003174|  0:00:22s\n","epoch 61 | loss: 0.47478 | val_0_mse: 0.676639974117279|  0:00:23s\n","epoch 62 | loss: 0.4729  | val_0_mse: 0.6551600098609924|  0:00:23s\n","epoch 63 | loss: 0.47524 | val_0_mse: 0.6621900200843811|  0:00:24s\n","epoch 64 | loss: 0.46243 | val_0_mse: 0.650950014591217|  0:00:24s\n","epoch 65 | loss: 0.47476 | val_0_mse: 0.6542800068855286|  0:00:24s\n","epoch 66 | loss: 0.48325 | val_0_mse: 0.6977300047874451|  0:00:25s\n","epoch 67 | loss: 0.48062 | val_0_mse: 0.7097899913787842|  0:00:25s\n","epoch 68 | loss: 0.4701  | val_0_mse: 0.6170899868011475|  0:00:25s\n","epoch 69 | loss: 0.47882 | val_0_mse: 0.6635599732398987|  0:00:26s\n","epoch 70 | loss: 0.47202 | val_0_mse: 0.6754299998283386|  0:00:26s\n","epoch 71 | loss: 0.46381 | val_0_mse: 0.6480500102043152|  0:00:26s\n","epoch 72 | loss: 0.47306 | val_0_mse: 0.6212599873542786|  0:00:27s\n","epoch 73 | loss: 0.47242 | val_0_mse: 0.5960800051689148|  0:00:27s\n","epoch 74 | loss: 0.45824 | val_0_mse: 0.6465799808502197|  0:00:28s\n","epoch 75 | loss: 0.46378 | val_0_mse: 0.5929800271987915|  0:00:28s\n","epoch 76 | loss: 0.46743 | val_0_mse: 0.5944899916648865|  0:00:28s\n","epoch 77 | loss: 0.456   | val_0_mse: 0.6018999814987183|  0:00:29s\n","epoch 78 | loss: 0.46793 | val_0_mse: 0.5934900045394897|  0:00:29s\n","epoch 79 | loss: 0.459   | val_0_mse: 0.6159499883651733|  0:00:30s\n","epoch 80 | loss: 0.46028 | val_0_mse: 0.576229989528656|  0:00:30s\n","epoch 81 | loss: 0.45592 | val_0_mse: 0.5649799704551697|  0:00:30s\n","epoch 82 | loss: 0.45003 | val_0_mse: 0.5781700015068054|  0:00:31s\n","epoch 83 | loss: 0.45076 | val_0_mse: 0.571590006351471|  0:00:31s\n","epoch 84 | loss: 0.45695 | val_0_mse: 0.5799300074577332|  0:00:31s\n","epoch 85 | loss: 0.45395 | val_0_mse: 0.5924599766731262|  0:00:32s\n","epoch 86 | loss: 0.4552  | val_0_mse: 0.5952600240707397|  0:00:32s\n","epoch 87 | loss: 0.45732 | val_0_mse: 0.5846999883651733|  0:00:33s\n","epoch 88 | loss: 0.44913 | val_0_mse: 0.5945600271224976|  0:00:33s\n","epoch 89 | loss: 0.45163 | val_0_mse: 0.5845699906349182|  0:00:33s\n","epoch 90 | loss: 0.45222 | val_0_mse: 0.5771499872207642|  0:00:34s\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n","[I 2024-10-15 16:48:28,251] Trial 99 finished with value: 0.5649807453155518 and parameters: {'n_d': 20, 'n_steps': 5, 'gamma': 1.1396443561154468, 'n_independent': 3, 'n_shared': 3, 'momentum': 0.04293448383189654}. Best is trial 55 with value: 0.5396906733512878.\n"]},{"output_type":"stream","name":"stdout","text":["epoch 91 | loss: 0.46684 | val_0_mse: 0.5735599994659424|  0:00:34s\n","\n","Early stopping occurred at epoch 91 with best_epoch = 81 and best_val_0_mse = 0.5649799704551697\n"]}]},{"cell_type":"code","source":["best_params"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sg7oYTivFBGe","executionInfo":{"status":"ok","timestamp":1729010909199,"user_tz":-480,"elapsed":55,"user":{"displayName":"Jonindo Pasaribu","userId":"10958990953097471082"}},"outputId":"710671f8-fb09-44d8-f5a2-72f8be1a61aa"},"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'n_d': 22,\n"," 'n_steps': 8,\n"," 'gamma': 1.0024727718401805,\n"," 'n_independent': 4,\n"," 'n_shared': 3,\n"," 'momentum': 0.21152216304738897}"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["from pytorch_tabnet.callbacks import Callback\n","\n","def print_memory_usage():\n","    process = psutil.Process()\n","    mem_info = process.memory_info()\n","    print(f\"Memory Usage: {mem_info.rss / (1024 ** 2):.2f} MB\")\n","\n","class MemoryUsageCallback(Callback):\n","    def on_epoch_end(self, epoch, logs=None):\n","        print_memory_usage()"],"metadata":{"id":"Tc2ueju9nSae","executionInfo":{"status":"ok","timestamp":1729010909199,"user_tz":-480,"elapsed":3,"user":{"displayName":"Jonindo Pasaribu","userId":"10958990953097471082"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["# Train final model using best hyperparameters\n","best_model = TabNetRegressor(**best_params,\n","                             n_a=best_params['n_d'],\n","                             optimizer_fn=torch.optim.Adam,\n","                             optimizer_params=dict(lr=2e-2)\n","                             )\n","best_model.fit(\n","    X_train, y_train,\n","    eval_set=[(X_train, y_train), (X_valid, y_valid)],\n","    eval_name=['train', 'valid'],\n","    eval_metric=['mae', 'rmse'],\n","    callbacks=[MemoryUsageCallback()]\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rLdfMkJXw_Xl","executionInfo":{"status":"ok","timestamp":1729010982751,"user_tz":-480,"elapsed":73555,"user":{"displayName":"Jonindo Pasaribu","userId":"10958990953097471082"}},"outputId":"746c3cd8-5efc-4a46-99b5-06f73b0ad8ca"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 32.35325| train_mae: 31.872840881347656| train_rmse: 40.6939582824707| valid_mae: 32.70574188232422| valid_rmse: 40.803741455078125|  0:00:00s\n","Memory Usage: 1220.35 MB\n","epoch 1  | loss: 6.44051 | train_mae: 18.75840950012207| train_rmse: 23.151399612426758| valid_mae: 17.871320724487305| valid_rmse: 22.612689971923828|  0:00:01s\n","Memory Usage: 1220.35 MB\n","epoch 2  | loss: 2.69357 | train_mae: 9.461380004882812| train_rmse: 12.223620414733887| valid_mae: 8.726519584655762| valid_rmse: 11.145540237426758|  0:00:02s\n","Memory Usage: 1220.35 MB\n","epoch 3  | loss: 1.93454 | train_mae: 6.577139854431152| train_rmse: 8.240909576416016| valid_mae: 6.5924201011657715| valid_rmse: 8.047380447387695|  0:00:03s\n","Memory Usage: 1220.35 MB\n","epoch 4  | loss: 1.51149 | train_mae: 6.042840003967285| train_rmse: 7.866779804229736| valid_mae: 6.204770088195801| valid_rmse: 8.143560409545898|  0:00:04s\n","Memory Usage: 1220.35 MB\n","epoch 5  | loss: 1.30606 | train_mae: 7.513189792633057| train_rmse: 10.375140190124512| valid_mae: 7.413269996643066| valid_rmse: 10.354889869689941|  0:00:05s\n","Memory Usage: 1220.35 MB\n","epoch 6  | loss: 1.1436  | train_mae: 9.902219772338867| train_rmse: 12.474390029907227| valid_mae: 10.142040252685547| valid_rmse: 12.799839973449707|  0:00:06s\n","Memory Usage: 1220.35 MB\n","epoch 7  | loss: 1.0038  | train_mae: 4.078670024871826| train_rmse: 6.3114800453186035| valid_mae: 3.9598300457000732| valid_rmse: 6.434579849243164|  0:00:07s\n","Memory Usage: 1220.35 MB\n","epoch 8  | loss: 0.97667 | train_mae: 4.112720012664795| train_rmse: 4.937849998474121| valid_mae: 4.093200206756592| valid_rmse: 4.864130020141602|  0:00:08s\n","Memory Usage: 1220.35 MB\n","epoch 9  | loss: 0.86422 | train_mae: 5.23084020614624| train_rmse: 6.789629936218262| valid_mae: 5.247960090637207| valid_rmse: 6.681250095367432|  0:00:09s\n","Memory Usage: 1220.35 MB\n","epoch 10 | loss: 0.98304 | train_mae: 3.820359945297241| train_rmse: 4.810229778289795| valid_mae: 3.6806800365448| valid_rmse: 4.5920000076293945|  0:00:10s\n","Memory Usage: 1220.35 MB\n","epoch 11 | loss: 0.99371 | train_mae: 1.8076000213623047| train_rmse: 2.528630018234253| valid_mae: 1.7033900022506714| valid_rmse: 2.3572700023651123|  0:00:10s\n","Memory Usage: 1220.35 MB\n","epoch 12 | loss: 0.78462 | train_mae: 1.8607200384140015| train_rmse: 2.3504199981689453| valid_mae: 1.924739956855774| valid_rmse: 2.361020088195801|  0:00:11s\n","Memory Usage: 1220.35 MB\n","epoch 13 | loss: 0.76007 | train_mae: 2.07709002494812| train_rmse: 2.5305700302124023| valid_mae: 2.0548999309539795| valid_rmse: 2.4840400218963623|  0:00:12s\n","Memory Usage: 1220.35 MB\n","epoch 14 | loss: 0.71314 | train_mae: 1.957110047340393| train_rmse: 2.822510004043579| valid_mae: 1.9714000225067139| valid_rmse: 2.7597999572753906|  0:00:13s\n","Memory Usage: 1220.35 MB\n","epoch 15 | loss: 0.72097 | train_mae: 2.499660015106201| train_rmse: 3.30853009223938| valid_mae: 2.4565300941467285| valid_rmse: 3.245840072631836|  0:00:14s\n","Memory Usage: 1220.35 MB\n","epoch 16 | loss: 0.66421 | train_mae: 1.4649399518966675| train_rmse: 1.8764699697494507| valid_mae: 1.5341099500656128| valid_rmse: 1.9347399473190308|  0:00:15s\n","Memory Usage: 1220.35 MB\n","epoch 17 | loss: 0.64645 | train_mae: 2.824579954147339| train_rmse: 3.157170057296753| valid_mae: 2.820050001144409| valid_rmse: 3.1713199615478516|  0:00:16s\n","Memory Usage: 1220.35 MB\n","epoch 18 | loss: 0.62315 | train_mae: 2.3614699840545654| train_rmse: 2.6040899753570557| valid_mae: 2.3874399662017822| valid_rmse: 2.635349988937378|  0:00:17s\n","Memory Usage: 1220.35 MB\n","epoch 19 | loss: 0.57898 | train_mae: 2.414170026779175| train_rmse: 2.670639991760254| valid_mae: 2.413719892501831| valid_rmse: 2.668100118637085|  0:00:18s\n","Memory Usage: 1220.35 MB\n","epoch 20 | loss: 0.57984 | train_mae: 2.0159499645233154| train_rmse: 2.2754099369049072| valid_mae: 2.041300058364868| valid_rmse: 2.317620038986206|  0:00:19s\n","Memory Usage: 1220.35 MB\n","epoch 21 | loss: 0.54748 | train_mae: 1.4323999881744385| train_rmse: 1.6817200183868408| valid_mae: 1.450369954109192| valid_rmse: 1.7061599493026733|  0:00:19s\n","Memory Usage: 1220.35 MB\n","epoch 22 | loss: 0.54484 | train_mae: 1.2108900547027588| train_rmse: 1.4841699600219727| valid_mae: 1.2223700284957886| valid_rmse: 1.5024499893188477|  0:00:20s\n","Memory Usage: 1220.35 MB\n","epoch 23 | loss: 0.56773 | train_mae: 1.5256600379943848| train_rmse: 1.7962599992752075| valid_mae: 1.562190055847168| valid_rmse: 1.8427499532699585|  0:00:21s\n","Memory Usage: 1220.35 MB\n","epoch 24 | loss: 0.56815 | train_mae: 1.3703700304031372| train_rmse: 1.6300400495529175| valid_mae: 1.405519962310791| valid_rmse: 1.6886299848556519|  0:00:22s\n","Memory Usage: 1220.35 MB\n","epoch 25 | loss: 0.54396 | train_mae: 1.2786500453948975| train_rmse: 1.5103700160980225| valid_mae: 1.3136399984359741| valid_rmse: 1.551110029220581|  0:00:23s\n","Memory Usage: 1220.35 MB\n","epoch 26 | loss: 0.54808 | train_mae: 0.9967700242996216| train_rmse: 1.2230700254440308| valid_mae: 1.0187100172042847| valid_rmse: 1.2406699657440186|  0:00:24s\n","Memory Usage: 1220.35 MB\n","epoch 27 | loss: 0.53622 | train_mae: 0.9405199885368347| train_rmse: 1.1562399864196777| valid_mae: 0.9603099822998047| valid_rmse: 1.1716899871826172|  0:00:25s\n","Memory Usage: 1220.35 MB\n","epoch 28 | loss: 0.52585 | train_mae: 0.9584500193595886| train_rmse: 1.1815099716186523| valid_mae: 0.9815999865531921| valid_rmse: 1.2153799533843994|  0:00:26s\n","Memory Usage: 1220.35 MB\n","epoch 29 | loss: 0.54251 | train_mae: 0.9262199997901917| train_rmse: 1.1407699584960938| valid_mae: 0.9855200052261353| valid_rmse: 1.19868004322052|  0:00:27s\n","Memory Usage: 1220.35 MB\n","epoch 30 | loss: 0.53269 | train_mae: 0.8912299871444702| train_rmse: 1.0869699716567993| valid_mae: 0.905460000038147| valid_rmse: 1.1116299629211426|  0:00:28s\n","Memory Usage: 1220.35 MB\n","epoch 31 | loss: 0.52643 | train_mae: 1.0045700073242188| train_rmse: 1.2147200107574463| valid_mae: 1.03193998336792| valid_rmse: 1.2411199808120728|  0:00:29s\n","Memory Usage: 1220.35 MB\n","epoch 32 | loss: 0.50168 | train_mae: 0.9452999830245972| train_rmse: 1.147070050239563| valid_mae: 0.9734100103378296| valid_rmse: 1.169950008392334|  0:00:30s\n","Memory Usage: 1220.35 MB\n","epoch 33 | loss: 0.51851 | train_mae: 0.9336299896240234| train_rmse: 1.1193599700927734| valid_mae: 0.9424099922180176| valid_rmse: 1.1365100145339966|  0:00:31s\n","Memory Usage: 1220.35 MB\n","epoch 34 | loss: 0.50458 | train_mae: 0.9203699827194214| train_rmse: 1.1178699731826782| valid_mae: 0.9500899910926819| valid_rmse: 1.148010015487671|  0:00:31s\n","Memory Usage: 1220.35 MB\n","epoch 35 | loss: 0.50579 | train_mae: 1.0358400344848633| train_rmse: 1.2402499914169312| valid_mae: 1.0609300136566162| valid_rmse: 1.274359941482544|  0:00:32s\n","Memory Usage: 1220.35 MB\n","epoch 36 | loss: 0.54038 | train_mae: 0.7930399775505066| train_rmse: 0.9860399961471558| valid_mae: 0.7898300290107727| valid_rmse: 0.9955300092697144|  0:00:33s\n","Memory Usage: 1220.35 MB\n","epoch 37 | loss: 0.5684  | train_mae: 1.0716700553894043| train_rmse: 1.2847000360488892| valid_mae: 1.055050015449524| valid_rmse: 1.2692999839782715|  0:00:34s\n","Memory Usage: 1220.35 MB\n","epoch 38 | loss: 0.58328 | train_mae: 0.7627300024032593| train_rmse: 0.9640200138092041| valid_mae: 0.7593100070953369| valid_rmse: 0.9750300049781799|  0:00:35s\n","Memory Usage: 1220.35 MB\n","epoch 39 | loss: 0.5315  | train_mae: 0.873740017414093| train_rmse: 1.075819969177246| valid_mae: 0.8660699725151062| valid_rmse: 1.0882699489593506|  0:00:36s\n","Memory Usage: 1220.35 MB\n","epoch 40 | loss: 0.5281  | train_mae: 0.9925100207328796| train_rmse: 1.1888699531555176| valid_mae: 0.9974200129508972| valid_rmse: 1.2095099687576294|  0:00:37s\n","Memory Usage: 1220.35 MB\n","epoch 41 | loss: 0.50424 | train_mae: 0.9188500046730042| train_rmse: 1.114150047302246| valid_mae: 0.9227100014686584| valid_rmse: 1.127150058746338|  0:00:38s\n","Memory Usage: 1220.35 MB\n","epoch 42 | loss: 0.5142  | train_mae: 0.8996700048446655| train_rmse: 1.092360019683838| valid_mae: 0.9104999899864197| valid_rmse: 1.114490032196045|  0:00:39s\n","Memory Usage: 1220.35 MB\n","epoch 43 | loss: 0.50297 | train_mae: 0.8285899758338928| train_rmse: 1.010010004043579| valid_mae: 0.8460400104522705| valid_rmse: 1.0464199781417847|  0:00:40s\n","Memory Usage: 1220.35 MB\n","epoch 44 | loss: 0.49774 | train_mae: 0.8484799861907959| train_rmse: 1.0445599555969238| valid_mae: 0.8699300289154053| valid_rmse: 1.0765600204467773|  0:00:40s\n","Memory Usage: 1220.35 MB\n","epoch 45 | loss: 0.51505 | train_mae: 0.7040899991989136| train_rmse: 0.8827499747276306| valid_mae: 0.7141799926757812| valid_rmse: 0.8986999988555908|  0:00:41s\n","Memory Usage: 1220.35 MB\n","epoch 46 | loss: 0.48697 | train_mae: 0.713699996471405| train_rmse: 0.8910599946975708| valid_mae: 0.7209500074386597| valid_rmse: 0.910260021686554|  0:00:42s\n","Memory Usage: 1220.35 MB\n","epoch 47 | loss: 0.50743 | train_mae: 0.7798600196838379| train_rmse: 0.9612299799919128| valid_mae: 0.7990000247955322| valid_rmse: 0.9999300241470337|  0:00:43s\n","Memory Usage: 1220.35 MB\n","epoch 48 | loss: 0.49484 | train_mae: 0.7283899784088135| train_rmse: 0.9018099904060364| valid_mae: 0.743690013885498| valid_rmse: 0.9297500252723694|  0:00:44s\n","Memory Usage: 1220.35 MB\n","epoch 49 | loss: 0.49302 | train_mae: 0.8147799968719482| train_rmse: 1.0052299499511719| valid_mae: 0.8216500282287598| valid_rmse: 1.0259300470352173|  0:00:45s\n","Memory Usage: 1220.35 MB\n","epoch 50 | loss: 0.49915 | train_mae: 0.7368599772453308| train_rmse: 0.9152100086212158| valid_mae: 0.7485399842262268| valid_rmse: 0.9326500296592712|  0:00:46s\n","Memory Usage: 1220.35 MB\n","epoch 51 | loss: 0.51367 | train_mae: 0.6795600056648254| train_rmse: 0.851639986038208| valid_mae: 0.6904699802398682| valid_rmse: 0.8687800168991089|  0:00:47s\n","Memory Usage: 1220.35 MB\n","epoch 52 | loss: 0.49228 | train_mae: 0.7422000169754028| train_rmse: 0.9172700047492981| valid_mae: 0.7663999795913696| valid_rmse: 0.958840012550354|  0:00:48s\n","Memory Usage: 1220.35 MB\n","epoch 53 | loss: 0.50595 | train_mae: 0.7023199796676636| train_rmse: 0.8740299940109253| valid_mae: 0.7244600057601929| valid_rmse: 0.9057300090789795|  0:00:49s\n","Memory Usage: 1220.35 MB\n","epoch 54 | loss: 0.48325 | train_mae: 0.7080299854278564| train_rmse: 0.8836699724197388| valid_mae: 0.7310600280761719| valid_rmse: 0.921779990196228|  0:00:49s\n","Memory Usage: 1220.35 MB\n","epoch 55 | loss: 0.50798 | train_mae: 0.6094099879264832| train_rmse: 0.7733299732208252| valid_mae: 0.6360700130462646| valid_rmse: 0.8170700073242188|  0:00:50s\n","Memory Usage: 1220.35 MB\n","epoch 56 | loss: 0.52149 | train_mae: 0.7003700137138367| train_rmse: 0.8767499923706055| valid_mae: 0.7196499705314636| valid_rmse: 0.9035000205039978|  0:00:51s\n","Memory Usage: 1220.35 MB\n","epoch 57 | loss: 0.49621 | train_mae: 0.6624299883842468| train_rmse: 0.8299199938774109| valid_mae: 0.6846299767494202| valid_rmse: 0.8626899719238281|  0:00:52s\n","Memory Usage: 1220.35 MB\n","epoch 58 | loss: 0.49978 | train_mae: 0.5882300138473511| train_rmse: 0.7451800107955933| valid_mae: 0.6190900206565857| valid_rmse: 0.7869099974632263|  0:00:53s\n","Memory Usage: 1220.35 MB\n","epoch 59 | loss: 0.53958 | train_mae: 0.7875800132751465| train_rmse: 0.9670500159263611| valid_mae: 0.8144800066947937| valid_rmse: 0.9987300038337708|  0:00:54s\n","Memory Usage: 1220.35 MB\n","epoch 60 | loss: 0.55498 | train_mae: 0.5972700119018555| train_rmse: 0.7688699960708618| valid_mae: 0.6238200068473816| valid_rmse: 0.7990000247955322|  0:00:55s\n","Memory Usage: 1220.35 MB\n","epoch 61 | loss: 0.62625 | train_mae: 0.7077100276947021| train_rmse: 0.8811100125312805| valid_mae: 0.7358599901199341| valid_rmse: 0.9158099889755249|  0:00:56s\n","Memory Usage: 1220.35 MB\n","epoch 62 | loss: 0.60839 | train_mae: 0.6131100058555603| train_rmse: 0.770799994468689| valid_mae: 0.6480200290679932| valid_rmse: 0.8093500137329102|  0:00:57s\n","Memory Usage: 1220.35 MB\n","epoch 63 | loss: 0.50824 | train_mae: 0.6477100253105164| train_rmse: 0.8141400218009949| valid_mae: 0.6795099973678589| valid_rmse: 0.8517900109291077|  0:00:58s\n","Memory Usage: 1220.35 MB\n","epoch 64 | loss: 0.49141 | train_mae: 0.5913100242614746| train_rmse: 0.7424499988555908| valid_mae: 0.6316400170326233| valid_rmse: 0.7927799820899963|  0:00:59s\n","Memory Usage: 1220.35 MB\n","epoch 65 | loss: 0.50842 | train_mae: 0.6333000063896179| train_rmse: 0.7970499992370605| valid_mae: 0.6662200093269348| valid_rmse: 0.8328400254249573|  0:01:00s\n","Memory Usage: 1220.35 MB\n","epoch 66 | loss: 0.49236 | train_mae: 0.6201500296592712| train_rmse: 0.7771900296211243| valid_mae: 0.6457099914550781| valid_rmse: 0.8086699843406677|  0:01:00s\n","Memory Usage: 1220.35 MB\n","epoch 67 | loss: 0.48391 | train_mae: 0.5752500295639038| train_rmse: 0.7261199951171875| valid_mae: 0.6032400131225586| valid_rmse: 0.7598299980163574|  0:01:01s\n","Memory Usage: 1220.35 MB\n","epoch 68 | loss: 0.48447 | train_mae: 0.6253700256347656| train_rmse: 0.784500002861023| valid_mae: 0.6502400040626526| valid_rmse: 0.8238199949264526|  0:01:02s\n","Memory Usage: 1220.35 MB\n","epoch 69 | loss: 0.47246 | train_mae: 0.6455000042915344| train_rmse: 0.8070799708366394| valid_mae: 0.6655700206756592| valid_rmse: 0.8391199707984924|  0:01:03s\n","Memory Usage: 1220.35 MB\n","epoch 70 | loss: 0.48063 | train_mae: 0.568560004234314| train_rmse: 0.7217000126838684| valid_mae: 0.5934000015258789| valid_rmse: 0.7565100193023682|  0:01:04s\n","Memory Usage: 1220.35 MB\n","epoch 71 | loss: 0.47671 | train_mae: 0.5868600010871887| train_rmse: 0.7356200218200684| valid_mae: 0.6107800006866455| valid_rmse: 0.7709900140762329|  0:01:05s\n","Memory Usage: 1220.35 MB\n","epoch 72 | loss: 0.45267 | train_mae: 0.582319974899292| train_rmse: 0.7320899963378906| valid_mae: 0.6071799993515015| valid_rmse: 0.7663400173187256|  0:01:06s\n","Memory Usage: 1220.35 MB\n","epoch 73 | loss: 0.46722 | train_mae: 0.5709800124168396| train_rmse: 0.726170003414154| valid_mae: 0.609790027141571| valid_rmse: 0.7745500206947327|  0:01:07s\n","Memory Usage: 1220.35 MB\n","epoch 74 | loss: 0.48546 | train_mae: 0.6143100261688232| train_rmse: 0.7742000222206116| valid_mae: 0.6470999717712402| valid_rmse: 0.8189600110054016|  0:01:08s\n","Memory Usage: 1220.35 MB\n","epoch 75 | loss: 0.49282 | train_mae: 0.584559977054596| train_rmse: 0.7464799880981445| valid_mae: 0.6256600022315979| valid_rmse: 0.7910400032997131|  0:01:09s\n","Memory Usage: 1220.35 MB\n","epoch 76 | loss: 0.49081 | train_mae: 0.5816299915313721| train_rmse: 0.7353500127792358| valid_mae: 0.6234400272369385| valid_rmse: 0.7843400239944458|  0:01:09s\n","Memory Usage: 1220.35 MB\n","epoch 77 | loss: 0.49161 | train_mae: 0.5824599862098694| train_rmse: 0.7358199954032898| valid_mae: 0.6212900280952454| valid_rmse: 0.789110004901886|  0:01:10s\n","Memory Usage: 1220.35 MB\n","epoch 78 | loss: 0.47476 | train_mae: 0.5759699940681458| train_rmse: 0.7360100150108337| valid_mae: 0.6166899800300598| valid_rmse: 0.7864300012588501|  0:01:11s\n","Memory Usage: 1220.35 MB\n","epoch 79 | loss: 0.49836 | train_mae: 0.6371899843215942| train_rmse: 0.799340009689331| valid_mae: 0.6756100058555603| valid_rmse: 0.847000002861023|  0:01:12s\n","Memory Usage: 1220.35 MB\n","epoch 80 | loss: 0.53057 | train_mae: 0.5932400226593018| train_rmse: 0.7722100019454956| valid_mae: 0.6338099837303162| valid_rmse: 0.8250700235366821|  0:01:13s\n","Memory Usage: 1220.35 MB\n","\n","Early stopping occurred at epoch 80 with best_epoch = 70 and best_valid_rmse = 0.7565100193023682\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n"]}]},{"cell_type":"code","source":["from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, classification_report\n","\n","preds = best_model.predict(X_test)\n","y_true = y_test\n","\n","mae_test = mean_absolute_error(y_pred=preds, y_true=y_true)\n","mse = mean_squared_error(y_pred=preds, y_true=y_true)\n","rmse_test = np.sqrt(mean_squared_error(y_true, y_pred=preds))\n","r2_test = r2_score(y_true=y_true, y_pred=preds)\n","\n","print(\"Best Valid RMSE:\", best_model.best_cost)\n","print(\"Test MAE:\", mae_test)\n","print(\"Test RMSE:\", rmse_test)\n","print(\"R-squared:\", r2_test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"o3TYXT_o_6oS","executionInfo":{"status":"ok","timestamp":1729010982751,"user_tz":-480,"elapsed":22,"user":{"displayName":"Jonindo Pasaribu","userId":"10958990953097471082"}},"outputId":"7c505b3c-4547-456f-be5c-61768026f1cf"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Best Valid RMSE: 0.7565146\n","Test MAE: 0.5904497\n","Test RMSE: 0.7580382\n","R-squared: 0.24010467529296875\n"]}]},{"cell_type":"code","source":["base_preds = tnr.predict(X_test)\n","\n","base_mae_test = mean_absolute_error(y_pred=base_preds, y_true=y_true)\n","base_mse = mean_squared_error(y_pred=base_preds, y_true=y_true)\n","base_rmse_test = np.sqrt(mean_squared_error(y_true, y_pred=base_preds))\n","\n","print(\"Best Valid Score:\", tnr.best_cost)\n","print(\"Test MAE:\", base_mae_test)\n","print(\"Test RMSE:\", base_rmse_test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8nW4N4ls2O6R","executionInfo":{"status":"ok","timestamp":1719643596639,"user_tz":-420,"elapsed":506,"user":{"displayName":"Jonindo Pasaribu","userId":"10958990953097471082"}},"outputId":"d4c42bdf-0bdf-484c-a38f-b9abad4bdfbb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Best Valid Score: 0.8317855\n","Test MAE: 0.6088446\n","Test RMSE: 0.78108466\n"]}]},{"cell_type":"code","source":["from matplotlib import pyplot as plt"],"metadata":{"id":"sxa64ArkAahN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.plot(tnr.history['loss'])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":448},"id":"zqkBaf7btWFx","executionInfo":{"status":"ok","timestamp":1716965025700,"user_tz":-420,"elapsed":705,"user":{"displayName":"Jonindo Pasaribu","userId":"10958990953097471082"}},"outputId":"89efb4b7-f63d-43a3-f190-cfe48cfbc358"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[<matplotlib.lines.Line2D at 0x7c111013a6b0>]"]},"metadata":{},"execution_count":23},{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"code","source":["plt.plot(best_model.history['loss'])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":448},"id":"j7OdxaVNtYNt","executionInfo":{"status":"ok","timestamp":1716965029034,"user_tz":-420,"elapsed":403,"user":{"displayName":"Jonindo Pasaribu","userId":"10958990953097471082"}},"outputId":"30318817-264e-4a1c-84b8-5f4a3431f055"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[<matplotlib.lines.Line2D at 0x7c10c4119f00>]"]},"metadata":{},"execution_count":24},{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]}]}